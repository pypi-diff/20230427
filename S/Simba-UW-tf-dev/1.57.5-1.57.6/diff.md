# Comparing `tmp/Simba-UW-tf-dev-1.57.5.tar.gz` & `tmp/Simba-UW-tf-dev-1.57.6.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "dist/Simba-UW-tf-dev-1.57.5.tar", last modified: Sun Apr 23 12:52:10 2023, max compression
+gzip compressed data, was "dist/Simba-UW-tf-dev-1.57.6.tar", last modified: Thu Apr 27 18:05:07 2023, max compression
```

## Comparing `Simba-UW-tf-dev-1.57.5.tar` & `Simba-UW-tf-dev-1.57.6.tar`

### file list

```diff
@@ -1,396 +1,398 @@
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/
--rw-r--r--   0 simon      (501) staff       (20)      579 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/PKG-INFO
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/
--rw-r--r--   0 simon      (501) staff       (20)    38767 2023-04-15 18:44:14.000000 Simba-UW-tf-dev-1.57.5/simba/video_processing.py
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/blob_storage/
--rw-r--r--   0 simon      (501) staff       (20)     6148 2023-03-21 20:39:46.000000 Simba-UW-tf-dev-1.57.5/simba/blob_storage/.DS_Store
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/unsupervised/
--rw-r--r--   0 simon      (501) staff       (20)    11938 2023-04-20 14:29:24.000000 Simba-UW-tf-dev-1.57.5/simba/unsupervised/dbcv_calculator.py
--rw-r--r--   0 simon      (501) staff       (20)    10960 2023-04-19 14:59:03.000000 Simba-UW-tf-dev-1.57.5/simba/unsupervised/unsupervised_ui.py
--rw-r--r--   0 simon      (501) staff       (20)     3354 2023-04-20 14:05:40.000000 Simba-UW-tf-dev-1.57.5/simba/unsupervised/enums.py
--rw-r--r--   0 simon      (501) staff       (20)     6148 2023-04-20 13:38:50.000000 Simba-UW-tf-dev-1.57.5/simba/unsupervised/.DS_Store
--rw-r--r--   0 simon      (501) staff       (20)     7569 2023-04-20 15:20:31.000000 Simba-UW-tf-dev-1.57.5/simba/unsupervised/dataset_creator.py
--rw-r--r--   0 simon      (501) staff       (20)     4812 2023-04-20 14:48:41.000000 Simba-UW-tf-dev-1.57.5/simba/unsupervised/grid_search_visualizers.py
--rw-r--r--   0 simon      (501) staff       (20)     6687 2023-04-20 15:04:13.000000 Simba-UW-tf-dev-1.57.5/simba/unsupervised/data_extractor.py
--rw-r--r--   0 simon      (501) staff       (20)     9907 2023-04-20 12:55:14.000000 Simba-UW-tf-dev-1.57.5/simba/unsupervised/ui.py
--rw-r--r--   0 simon      (501) staff       (20)     8375 2023-04-19 18:35:33.000000 Simba-UW-tf-dev-1.57.5/simba/unsupervised/umap_embedder.py
--rw-r--r--   0 simon      (501) staff       (20)    41552 2023-04-20 14:49:52.000000 Simba-UW-tf-dev-1.57.5/simba/unsupervised/pop_up_classes.py
--rw-r--r--   0 simon      (501) staff       (20)     2331 2023-04-20 12:56:44.000000 Simba-UW-tf-dev-1.57.5/simba/unsupervised/bout_aggregator.py
--rw-r--r--   0 simon      (501) staff       (20)    18472 2023-04-19 23:04:27.000000 Simba-UW-tf-dev-1.57.5/simba/unsupervised/cluster_statistics.py
--rw-r--r--   0 simon      (501) staff       (20)     2188 2023-04-18 23:25:29.000000 Simba-UW-tf-dev-1.57.5/simba/unsupervised/data_map.yaml
--rw-r--r--   0 simon      (501) staff       (20)     8421 2023-04-20 13:33:19.000000 Simba-UW-tf-dev-1.57.5/simba/unsupervised/hdbscan_clusterer.py
--rw-r--r--   0 simon      (501) staff       (20)     3931 2023-04-19 18:21:47.000000 Simba-UW-tf-dev-1.57.5/simba/unsupervised/tsne.py
--rw-r--r--   0 simon      (501) staff       (20)     5895 2023-04-18 19:12:52.000000 Simba-UW-tf-dev-1.57.5/simba/unsupervised/cluster_visualizer.py
--rw-r--r--   0 simon      (501) staff       (20)    19486 2023-04-18 14:10:55.000000 Simba-UW-tf-dev-1.57.5/simba/enums.py
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/bounding_box_tools/
--rw-r--r--   0 simon      (501) staff       (20)     6148 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/bounding_box_tools/.DS_Store
--rw-r--r--   0 simon      (501) staff       (20)     7520 2023-04-10 13:29:17.000000 Simba-UW-tf-dev-1.57.5/simba/bounding_box_tools/agg_boundary_stats.py
--rw-r--r--   0 simon      (501) staff       (20)     8596 2023-04-10 13:29:16.000000 Simba-UW-tf-dev-1.57.5/simba/bounding_box_tools/find_bounderies.py
--rw-r--r--   0 simon      (501) staff       (20)    24561 2023-04-06 11:22:38.000000 Simba-UW-tf-dev-1.57.5/simba/bounding_box_tools/boundary_menus.py
--rw-r--r--   0 simon      (501) staff       (20)     9536 2023-04-10 13:29:17.000000 Simba-UW-tf-dev-1.57.5/simba/bounding_box_tools/boundary_statistics.py
--rw-r--r--   0 simon      (501) staff       (20)    12664 2023-04-10 13:29:16.000000 Simba-UW-tf-dev-1.57.5/simba/bounding_box_tools/visualize_boundaries.py
--rw-r--r--   0 simon      (501) staff       (20)    32772 2023-04-22 15:14:38.000000 Simba-UW-tf-dev-1.57.5/simba/.DS_Store
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/
--rw-r--r--   0 simon      (501) staff       (20)    42823 2023-04-15 18:48:24.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/feature_extractor_14bp.py
--rw-r--r--   0 simon      (501) staff       (20)    21575 2023-04-15 18:48:24.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/feature_extractor_7bp.py
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/
--rw-r--r--   0 simon      (501) staff       (20)     1685 2023-04-14 17:52:01.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/doctests.py
--rw-r--r--   0 simon      (501) staff       (20)    23850 2023-04-17 18:48:40.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/fish_feature_extractor_2023_version_3.py
--rw-r--r--   0 simon      (501) staff       (20)     2732 2023-04-04 19:46:36.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/read_in_mp.py
--rw-r--r--   0 simon      (501) staff       (20)     2460 2023-04-22 18:02:29.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/peaks.py
--rw-r--r--   0 simon      (501) staff       (20)    14141 2023-03-15 17:20:08.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/fish_feature_extractor_2022.py
--rw-r--r--   0 simon      (501) staff       (20)     2053 2023-04-04 03:00:41.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/convex_hull_3_scratch_3.py
--rw-r--r--   0 simon      (501) staff       (20)     5762 2023-04-04 01:54:33.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/convex_hull_scratch_1.py
--rw-r--r--   0 simon      (501) staff       (20)     6148 2023-03-14 19:36:02.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/.DS_Store
--rw-r--r--   0 simon      (501) staff       (20)    21398 2023-04-16 17:03:37.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/fish_feature_extractor_2023_version_2.py
--rw-r--r--   0 simon      (501) staff       (20)     7127 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/egocentrical_aligner.py
--rw-r--r--   0 simon      (501) staff       (20)     1213 2023-04-11 20:12:47.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/count_values_in_range.py
--rw-r--r--   0 simon      (501) staff       (20)     4708 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/graph_creator.py
--rw-r--r--   0 simon      (501) staff       (20)     3954 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/termite_rois.csv
--rw-r--r--   0 simon      (501) staff       (20)      732 2023-03-20 12:13:51.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/mutual_exclusive.py
--rw-r--r--   0 simon      (501) staff       (20)     2841 2023-04-14 15:16:23.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/video_color.py
--rw-r--r--   0 simon      (501) staff       (20)     1862 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/graph_3d_plotter.py
--rw-r--r--   0 simon      (501) staff       (20)     5232 2023-04-13 14:05:29.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/video_rotator.py
--rw-r--r--   0 simon      (501) staff       (20)     2692 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/add_probability_cnt_features.py
--rw-r--r--   0 simon      (501) staff       (20)     1619 2023-04-08 20:02:08.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/make_splash.py
--rw-r--r--   0 simon      (501) staff       (20)     1658 2023-04-22 19:16:28.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/time_stamp_calculator.py
--rw-r--r--   0 simon      (501) staff       (20)     5232 2023-04-15 19:24:18.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/video_rotator_mp.py
--rw-r--r--   0 simon      (501) staff       (20)    30331 2023-04-23 12:30:57.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/fish_feature_extractor_2023_version_4.py
--rw-r--r--   0 simon      (501) staff       (20)     2058 2023-04-03 23:51:37.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/convex_hull_scratch_2.py
--rw-r--r--   0 simon      (501) staff       (20)    28003 2023-04-15 18:48:24.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/feature_extractor_8bps_2_animals.py
--rw-r--r--   0 simon      (501) staff       (20)    10244 2023-04-22 19:19:45.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/.DS_Store
--rw-r--r--   0 simon      (501) staff       (20)     2293 2023-04-13 15:35:56.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/perimeter_jit.py
--rw-r--r--   0 simon      (501) staff       (20)    10774 2023-04-10 13:29:17.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/feature_subsets.py
--rw-r--r--   0 simon      (501) staff       (20)        0 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/__init__.py
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/__pycache__/
--rw-r--r--   0 simon      (501) staff       (20)      905 2023-04-04 11:31:57.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/__pycache__/perimeter_jit.quickhull_2d-16.py36m.nbi
--rw-r--r--   0 simon      (501) staff       (20)   238196 2023-04-04 11:31:57.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/__pycache__/perimeter_jit.quickhull_2d-16.py36m.1.nbc
--rw-r--r--   0 simon      (501) staff       (20)    69038 2023-04-04 11:32:25.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/__pycache__/perimeter_jit.process-7.py36m.1.nbc
--rw-r--r--   0 simon      (501) staff       (20)   238298 2023-04-04 11:32:29.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/__pycache__/perimeter_jit.convex_hull_perimeter_2d-16.py36m.1.nbc
--rw-r--r--   0 simon      (501) staff       (20)    69338 2023-04-04 11:32:26.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/__pycache__/perimeter_jit.process-7.py36m.2.nbc
--rw-r--r--   0 simon      (501) staff       (20)      917 2023-04-04 11:32:29.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/__pycache__/perimeter_jit.convex_hull_perimeter_2d-16.py36m.nbi
--rw-r--r--   0 simon      (501) staff       (20)     2179 2023-04-04 11:32:26.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/__pycache__/perimeter_jit.process-7.py36m.nbi
--rw-r--r--   0 simon      (501) staff       (20)    36728 2023-04-17 19:25:13.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/extract_features_9bp.py
--rw-r--r--   0 simon      (501) staff       (20)     8483 2023-04-22 17:31:56.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/feature_extractor_user_defined.py
--rw-r--r--   0 simon      (501) staff       (20)     5380 2023-04-10 16:32:30.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/unit_tests.py
--rw-r--r--   0 simon      (501) staff       (20)    46489 2023-04-15 18:48:24.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/feature_extractor_16bp.py
--rw-r--r--   0 simon      (501) staff       (20)    24076 2023-04-15 18:48:24.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/feature_extractor_8bp.py
--rw-r--r--   0 simon      (501) staff       (20)    16793 2023-04-15 18:48:24.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/feature_extractor_4bp.py
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/.idea/
--rw-r--r--   0 simon      (501) staff       (20)      617 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/.idea/features_scripts.iml
--rw-r--r--   0 simon      (501) staff       (20)      138 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/.idea/encodings.xml
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/.idea/inspectionProfiles/
--rw-r--r--   0 simon      (501) staff       (20)      822 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/.idea/inspectionProfiles/Project_Default.xml
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/.idea/libraries/
--rw-r--r--   0 simon      (501) staff       (20)      128 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/.idea/libraries/R_User_Library.xml
--rw-r--r--   0 simon      (501) staff       (20)      273 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/.idea/.gitignore
--rw-r--r--   0 simon      (501) staff       (20)     8081 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/.idea/workspace.xml
--rw-r--r--   0 simon      (501) staff       (20)      291 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/.idea/modules.xml
--rw-r--r--   0 simon      (501) staff       (20)       23 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/.idea/.name
--rw-r--r--   0 simon      (501) staff       (20)      294 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/feature_extractors/.idea/misc.xml
--rw-r--r--   0 simon      (501) staff       (20)     6044 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/plotly_create_h5.py
--rw-r--r--   0 simon      (501) staff       (20)    15351 2023-04-06 14:48:36.000000 Simba-UW-tf-dev-1.57.5/simba/requirements.txt
--rw-r--r--   0 simon      (501) staff       (20)     5928 2023-04-10 15:43:18.000000 Simba-UW-tf-dev-1.57.5/simba/severity_processor.py
--rw-r--r--   0 simon      (501) staff       (20)     5900 2023-04-10 16:12:09.000000 Simba-UW-tf-dev-1.57.5/simba/user_pose_config_creator.py
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/mixins/
--rw-r--r--   0 simon      (501) staff       (20)     6148 2023-03-15 17:26:03.000000 Simba-UW-tf-dev-1.57.5/simba/mixins/.DS_Store
--rw-r--r--   0 simon      (501) staff       (20)    42063 2023-04-19 23:53:37.000000 Simba-UW-tf-dev-1.57.5/simba/mixins/pop_up_mixin.py
--rw-r--r--   0 simon      (501) staff       (20)     8351 2023-04-22 13:11:36.000000 Simba-UW-tf-dev-1.57.5/simba/mixins/config_reader.py
--rw-r--r--   0 simon      (501) staff       (20)     9048 2023-04-22 18:03:18.000000 Simba-UW-tf-dev-1.57.5/simba/mixins/feature_extraction_mixin.py
--rw-r--r--   0 simon      (501) staff       (20)     6092 2023-04-19 18:08:18.000000 Simba-UW-tf-dev-1.57.5/simba/mixins/unsupervised_mixin.py
--rw-r--r--   0 simon      (501) staff       (20)    34586 2023-04-15 19:04:12.000000 Simba-UW-tf-dev-1.57.5/simba/machine_model_settings_pop_up.py
--rw-r--r--   0 simon      (501) staff       (20)     5231 2023-04-10 15:22:21.000000 Simba-UW-tf-dev-1.57.5/simba/remove_keypoints_in_pose.py
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/third_party_label_appenders/
--rw-r--r--   0 simon      (501) staff       (20)     6400 2023-04-10 13:29:16.000000 Simba-UW-tf-dev-1.57.5/simba/third_party_label_appenders/deepethogram_importer.py
--rw-r--r--   0 simon      (501) staff       (20)     9984 2023-04-10 18:32:39.000000 Simba-UW-tf-dev-1.57.5/simba/third_party_label_appenders/BORIS_appender.py
--rw-r--r--   0 simon      (501) staff       (20)     9242 2023-04-10 13:29:16.000000 Simba-UW-tf-dev-1.57.5/simba/third_party_label_appenders/observer_importer.py
--rw-r--r--   0 simon      (501) staff       (20)    16922 2023-03-28 20:30:38.000000 Simba-UW-tf-dev-1.57.5/simba/third_party_label_appenders/tools.py
--rw-r--r--   0 simon      (501) staff       (20)        0 2023-04-01 14:10:06.000000 Simba-UW-tf-dev-1.57.5/simba/third_party_label_appenders/__init__.py
--rw-r--r--   0 simon      (501) staff       (20)    18322 2023-04-10 13:29:16.000000 Simba-UW-tf-dev-1.57.5/simba/third_party_label_appenders/third_party_appender.py
--rw-r--r--   0 simon      (501) staff       (20)     8372 2023-04-10 13:29:16.000000 Simba-UW-tf-dev-1.57.5/simba/third_party_label_appenders/ethovision_import.py
--rw-r--r--   0 simon      (501) staff       (20)     6964 2023-04-10 13:29:16.000000 Simba-UW-tf-dev-1.57.5/simba/third_party_label_appenders/BENTO_appender.py
--rw-r--r--   0 simon      (501) staff       (20)     5471 2023-04-10 13:29:17.000000 Simba-UW-tf-dev-1.57.5/simba/third_party_label_appenders/solomon_importer.py
--rw-r--r--   0 simon      (501) staff       (20)     7286 2023-04-10 13:29:16.000000 Simba-UW-tf-dev-1.57.5/simba/multi_cropper.py
--rw-r--r--   0 simon      (501) staff       (20)    12867 2023-04-18 20:27:02.000000 Simba-UW-tf-dev-1.57.5/simba/FSTTC_calculator.py
--rw-r--r--   0 simon      (501) staff       (20)    12575 2023-04-10 12:13:26.000000 Simba-UW-tf-dev-1.57.5/simba/create_project_pop_up.py
--rw-r--r--   0 simon      (501) staff       (20)    13377 2023-04-10 16:32:30.000000 Simba-UW-tf-dev-1.57.5/simba/video_info_table.py
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/cue_light_tools/
--rw-r--r--   0 simon      (501) staff       (20)     6148 2023-03-15 17:25:58.000000 Simba-UW-tf-dev-1.57.5/simba/cue_light_tools/.DS_Store
--rw-r--r--   0 simon      (501) staff       (20)     8632 2023-04-10 13:29:16.000000 Simba-UW-tf-dev-1.57.5/simba/cue_light_tools/cue_light_clf_statistics.py
--rw-r--r--   0 simon      (501) staff       (20)    13564 2023-04-10 13:29:17.000000 Simba-UW-tf-dev-1.57.5/simba/cue_light_tools/cue_light_analyzer.py
--rw-r--r--   0 simon      (501) staff       (20)    18253 2023-04-06 11:29:26.000000 Simba-UW-tf-dev-1.57.5/simba/cue_light_tools/cue_light_menues.py
--rw-r--r--   0 simon      (501) staff       (20)        0 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/cue_light_tools/__init__.py
--rw-r--r--   0 simon      (501) staff       (20)     1660 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/cue_light_tools/cue_light_tools.py
--rw-r--r--   0 simon      (501) staff       (20)    16427 2023-04-10 13:29:16.000000 Simba-UW-tf-dev-1.57.5/simba/cue_light_tools/cue_light_visualizer.py
--rw-r--r--   0 simon      (501) staff       (20)    13265 2023-04-10 13:29:16.000000 Simba-UW-tf-dev-1.57.5/simba/cue_light_tools/cue_light_movement_statistics.py
--rw-r--r--   0 simon      (501) staff       (20)        0 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/__init__.py
--rw-r--r--   0 simon      (501) staff       (20)     2813 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/extract_frames_fast.py
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/utils/
--rw-r--r--   0 simon      (501) staff       (20)     6148 2023-03-14 20:15:03.000000 Simba-UW-tf-dev-1.57.5/simba/utils/.DS_Store
--rw-r--r--   0 simon      (501) staff       (20)     7335 2023-04-10 18:32:39.000000 Simba-UW-tf-dev-1.57.5/simba/utils/warnings.py
--rw-r--r--   0 simon      (501) staff       (20)     5345 2023-04-14 15:36:09.000000 Simba-UW-tf-dev-1.57.5/simba/utils/lookups.py
--rw-r--r--   0 simon      (501) staff       (20)    14631 2023-04-16 19:52:37.000000 Simba-UW-tf-dev-1.57.5/simba/utils/errors.py
--rw-r--r--   0 simon      (501) staff       (20)     1045 2023-04-12 13:34:48.000000 Simba-UW-tf-dev-1.57.5/simba/utils/printing.py
--rw-r--r--   0 simon      (501) staff       (20)    21641 2023-04-10 13:29:17.000000 Simba-UW-tf-dev-1.57.5/simba/labelling_interface.py
--rw-r--r--   0 simon      (501) staff       (20)     9980 2023-04-10 15:43:18.000000 Simba-UW-tf-dev-1.57.5/simba/timebins_movement_analyzer.py
--rw-r--r--   0 simon      (501) staff       (20)    47395 2023-04-20 01:59:56.000000 Simba-UW-tf-dev-1.57.5/simba/train_model_functions.py
--rw-r--r--   0 simon      (501) staff       (20)    49699 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/SimBA_dash_app.py
--rw-r--r--   0 simon      (501) staff       (20)     7556 2023-04-10 15:43:18.000000 Simba-UW-tf-dev-1.57.5/simba/timebins_clf_analyzer.py
--rw-r--r--   0 simon      (501) staff       (20)     8240 2023-03-17 16:23:58.000000 Simba-UW-tf-dev-1.57.5/simba/calculate_px_dist.py
--rw-r--r--   0 simon      (501) staff       (20)     6566 2023-04-10 15:22:21.000000 Simba-UW-tf-dev-1.57.5/simba/movement_processor.py
--rw-r--r--   0 simon      (501) staff       (20)     2904 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/pybursts.py
--rw-r--r--   0 simon      (501) staff       (20)     4154 2023-04-23 12:50:46.000000 Simba-UW-tf-dev-1.57.5/simba/rw_dfs.py
--rw-r--r--   0 simon      (501) staff       (20)     6536 2023-04-10 13:29:17.000000 Simba-UW-tf-dev-1.57.5/simba/reverse_2_animal_tracking.py
--rw-r--r--   0 simon      (501) staff       (20)     9770 2023-04-10 14:38:06.000000 Simba-UW-tf-dev-1.57.5/simba/Directing_animals_analyzer.py
--rw-r--r--   0 simon      (501) staff       (20)     3570 2023-04-10 23:04:08.000000 Simba-UW-tf-dev-1.57.5/simba/Validate_model_one_video_run_clf.py
--rw-r--r--   0 simon      (501) staff       (20)    10872 2023-04-21 16:14:46.000000 Simba-UW-tf-dev-1.57.5/simba/tkinter_functions.py
--rw-r--r--   0 simon      (501) staff       (20)    13767 2023-03-24 12:49:19.000000 Simba-UW-tf-dev-1.57.5/simba/setting_menu.py
--rw-r--r--   0 simon      (501) staff       (20)     6614 2023-03-19 16:33:17.000000 Simba-UW-tf-dev-1.57.5/simba/interpolate_pose.py
--rw-r--r--   0 simon      (501) staff       (20)     4771 2023-04-10 19:17:14.000000 Simba-UW-tf-dev-1.57.5/simba/run_inference.py
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/
--rw-r--r--   0 simon      (501) staff       (20)     8634 2023-04-10 13:29:16.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/gantt_creator.py
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/tools/
--rw-r--r--   0 simon      (501) staff       (20)     5353 2023-03-30 15:38:37.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/tools/tkinter_tools.py
--rw-r--r--   0 simon      (501) staff       (20)    18101 2023-04-10 17:14:05.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/ROI_plotter_mp.py
--rw-r--r--   0 simon      (501) staff       (20)    15262 2023-04-19 14:54:02.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/shap_agg_stats_visualizer.py
--rw-r--r--   0 simon      (501) staff       (20)    12985 2023-04-10 13:29:17.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/gantt_creator_mp.py
--rw-r--r--   0 simon      (501) staff       (20)    15811 2023-04-10 13:29:17.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/heat_mapper_clf_mp.py
--rw-r--r--   0 simon      (501) staff       (20)     8839 2023-04-10 17:06:45.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/probability_plot_creator.py
--rw-r--r--   0 simon      (501) staff       (20)    16036 2023-04-10 13:29:17.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/misc_visualizations.py
--rw-r--r--   0 simon      (501) staff       (20)    13533 2023-04-10 13:29:17.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/plot_clf_results.py
--rw-r--r--   0 simon      (501) staff       (20)    17734 2023-04-10 13:29:16.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/plot_clf_results_mp.py
--rw-r--r--   0 simon      (501) staff       (20)    16340 2023-04-10 13:29:16.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/ROI_feature_visualizer.py
--rw-r--r--   0 simon      (501) staff       (20)    12691 2023-04-10 13:29:16.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/heat_mapper_location.py
--rw-r--r--   0 simon      (501) staff       (20)    12646 2023-04-10 13:29:17.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/probability_plot_creator_mp.py
--rw-r--r--   0 simon      (501) staff       (20)     5341 2023-03-30 15:46:49.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/interactive_probability_grapher.py
--rw-r--r--   0 simon      (501) staff       (20)     5896 2023-04-10 13:29:17.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/plot_pose_in_dir.py
--rw-r--r--   0 simon      (501) staff       (20)    12256 2023-04-10 13:29:17.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/single_run_model_validation_video.py
--rw-r--r--   0 simon      (501) staff       (20)    11246 2023-04-10 17:06:45.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/frame_mergerer_ffmpeg.py
--rw-r--r--   0 simon      (501) staff       (20)    12570 2023-04-10 16:40:38.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/Directing_animals_visualizer_mp.py
--rw-r--r--   0 simon      (501) staff       (20)     9979 2023-04-10 16:36:45.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/clf_validator.py
--rw-r--r--   0 simon      (501) staff       (20)    17891 2023-04-22 14:54:57.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/path_plotter_mp.py
--rw-r--r--   0 simon      (501) staff       (20)    20037 2023-04-10 13:29:16.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/ROI_feature_visualizer_mp.py
--rw-r--r--   0 simon      (501) staff       (20)    10219 2023-04-10 13:29:17.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/data_plotter.py
--rw-r--r--   0 simon      (501) staff       (20)    12889 2023-04-22 14:51:45.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/path_plotter.py
--rw-r--r--   0 simon      (501) staff       (20)     8685 2023-04-10 17:02:33.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/ez_lineplot.py
--rw-r--r--   0 simon      (501) staff       (20)    13027 2023-04-10 13:29:16.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/distance_plotter_mp.py
--rw-r--r--   0 simon      (501) staff       (20)    15890 2023-04-10 17:14:05.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/ROI_plotter.py
--rw-r--r--   0 simon      (501) staff       (20)    13230 2023-04-10 13:29:17.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/heat_mapper_clf.py
--rw-r--r--   0 simon      (501) staff       (20)     8951 2023-04-10 13:29:17.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/distance_plotter.py
--rw-r--r--   0 simon      (501) staff       (20)    13625 2023-04-10 13:29:16.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/single_run_model_validation_video_mp.py
--rw-r--r--   0 simon      (501) staff       (20)    10005 2023-04-10 16:38:59.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/Directing_animals_visualizer.py
--rw-r--r--   0 simon      (501) staff       (20)    16189 2023-04-10 13:29:17.000000 Simba-UW-tf-dev-1.57.5/simba/plotting/heat_mapper_location_mp.py
--rw-r--r--   0 simon      (501) staff       (20)     5029 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/run_dash_tkinter.py
--rw-r--r--   0 simon      (501) staff       (20)     7609 2023-04-10 13:29:17.000000 Simba-UW-tf-dev-1.57.5/simba/interpolate_smooth_post_hoc.py
--rw-r--r--   0 simon      (501) staff       (20)    24474 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/dash_app.py
--rw-r--r--   0 simon      (501) staff       (20)     6350 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/reverse_tracking_order.py
--rw-r--r--   0 simon      (501) staff       (20)     5772 2023-03-20 13:55:20.000000 Simba-UW-tf-dev-1.57.5/simba/concatenator_pop_up.py
--rw-r--r--   0 simon      (501) staff       (20)     2863 2023-04-10 13:29:16.000000 Simba-UW-tf-dev-1.57.5/simba/extract_annotation_frames.py
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/roi_tools/
--rw-r--r--   0 simon      (501) staff       (20)     7437 2023-04-10 13:29:17.000000 Simba-UW-tf-dev-1.57.5/simba/roi_tools/ROI_time_bin_calculator.py
--rw-r--r--   0 simon      (501) staff       (20)     2166 2023-04-10 13:29:16.000000 Simba-UW-tf-dev-1.57.5/simba/roi_tools/ROI_movement_analyzer.py
--rw-r--r--   0 simon      (501) staff       (20)     6148 2023-03-20 12:47:56.000000 Simba-UW-tf-dev-1.57.5/simba/roi_tools/.DS_Store
--rw-r--r--   0 simon      (501) staff       (20)    43921 2023-04-10 18:21:25.000000 Simba-UW-tf-dev-1.57.5/simba/roi_tools/ROI_define.py
--rw-r--r--   0 simon      (501) staff       (20)     3384 2023-03-20 12:41:16.000000 Simba-UW-tf-dev-1.57.5/simba/roi_tools/ROI_reset.py
--rw-r--r--   0 simon      (501) staff       (20)        0 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/roi_tools/__init__.py
--rw-r--r--   0 simon      (501) staff       (20)    21277 2023-04-10 18:12:26.000000 Simba-UW-tf-dev-1.57.5/simba/roi_tools/ROI_analyzer.py
--rw-r--r--   0 simon      (501) staff       (20)    11934 2023-04-10 18:32:39.000000 Simba-UW-tf-dev-1.57.5/simba/roi_tools/ROI_feature_analyzer.py
--rw-r--r--   0 simon      (501) staff       (20)     3537 2023-03-15 17:12:38.000000 Simba-UW-tf-dev-1.57.5/simba/roi_tools/ROI_multiply.py
--rw-r--r--   0 simon      (501) staff       (20)      961 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/roi_tools/ROI_size_calculations.py
--rw-r--r--   0 simon      (501) staff       (20)     3505 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/roi_tools/ROI_zoom.py
--rw-r--r--   0 simon      (501) staff       (20)    11335 2023-04-05 11:07:42.000000 Simba-UW-tf-dev-1.57.5/simba/roi_tools/ROI_directing_analyzer.py
--rw-r--r--   0 simon      (501) staff       (20)    10128 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/roi_tools/ROI_move_shape.py
--rw-r--r--   0 simon      (501) staff       (20)     5097 2023-04-05 20:01:02.000000 Simba-UW-tf-dev-1.57.5/simba/roi_tools/ROI_menus.py
--rw-r--r--   0 simon      (501) staff       (20)    15290 2023-04-10 18:12:26.000000 Simba-UW-tf-dev-1.57.5/simba/roi_tools/ROI_clf_calculator.py
--rw-r--r--   0 simon      (501) staff       (20)    22682 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/roi_tools/ROI_image.py
--rw-r--r--   0 simon      (501) staff       (20)    56353 2023-04-20 15:18:16.000000 Simba-UW-tf-dev-1.57.5/simba/misc_tools.py
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/pose_importers/
--rw-r--r--   0 simon      (501) staff       (20)     2494 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/pose_importers/read_DANNCE_mat.py
--rw-r--r--   0 simon      (501) staff       (20)    25864 2023-04-10 13:29:17.000000 Simba-UW-tf-dev-1.57.5/simba/pose_importers/sleap_importer_slp.py
--rw-r--r--   0 simon      (501) staff       (20)    24665 2023-04-10 18:12:26.000000 Simba-UW-tf-dev-1.57.5/simba/pose_importers/sleap_importer_h5.py
--rw-r--r--   0 simon      (501) staff       (20)    26731 2023-04-10 17:34:37.000000 Simba-UW-tf-dev-1.57.5/simba/pose_importers/dlc_multi_animal_importer.py
--rw-r--r--   0 simon      (501) staff       (20)    23776 2023-04-10 18:12:26.000000 Simba-UW-tf-dev-1.57.5/simba/pose_importers/sleap_importer_csv.py
--rw-r--r--   0 simon      (501) staff       (20)    16483 2023-04-14 16:41:29.000000 Simba-UW-tf-dev-1.57.5/simba/pose_importers/import_trk.py
--rw-r--r--   0 simon      (501) staff       (20)     7924 2023-04-10 17:34:37.000000 Simba-UW-tf-dev-1.57.5/simba/pose_importers/import_mars.py
--rw-r--r--   0 simon      (501) staff       (20)     8919 2023-04-10 17:29:32.000000 Simba-UW-tf-dev-1.57.5/simba/pose_importers/dlc_importer_csv.py
--rw-r--r--   0 simon      (501) staff       (20)     7828 2023-04-10 18:12:26.000000 Simba-UW-tf-dev-1.57.5/simba/pose_importers/trk_importer.py
--rw-r--r--   0 simon      (501) staff       (20)   236359 2023-04-22 15:26:04.000000 Simba-UW-tf-dev-1.57.5/simba/pop_up_classes.py
--rw-r--r--   0 simon      (501) staff       (20)     4692 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/extract_seqframes.py
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/pose_configurations/
--rw-r--r--   0 simon      (501) staff       (20)    14340 2023-03-30 11:05:37.000000 Simba-UW-tf-dev-1.57.5/simba/pose_configurations/.DS_Store
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/pose_configurations/bp_names/
--rw-r--r--   0 simon      (501) staff       (20)     6148 2023-03-16 13:26:00.000000 Simba-UW-tf-dev-1.57.5/simba/pose_configurations/bp_names/.DS_Store
--rw-r--r--   0 simon      (501) staff       (20)     1316 2023-04-10 12:22:28.000000 Simba-UW-tf-dev-1.57.5/simba/pose_configurations/bp_names/bp_names.csv
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/pose_configurations/no_animals/
--rw-r--r--   0 simon      (501) staff       (20)       24 2023-03-20 15:55:45.000000 Simba-UW-tf-dev-1.57.5/simba/pose_configurations/no_animals/no_animals.csv
--rw-r--r--   0 simon      (501) staff       (20)     6148 2023-03-16 13:26:19.000000 Simba-UW-tf-dev-1.57.5/simba/pose_configurations/no_animals/.DS_Store
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/pose_configurations/configuration_names/
--rw-r--r--   0 simon      (501) staff       (20)     6148 2023-03-16 13:26:14.000000 Simba-UW-tf-dev-1.57.5/simba/pose_configurations/configuration_names/.DS_Store
--rw-r--r--   0 simon      (501) staff       (20)      267 2023-03-20 15:55:45.000000 Simba-UW-tf-dev-1.57.5/simba/pose_configurations/configuration_names/pose_config_names.csv
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/pose_configurations/schematics/
--rw-r--r--   0 simon      (501) staff       (20)     8196 2023-03-30 10:45:10.000000 Simba-UW-tf-dev-1.57.5/simba/pose_configurations/schematics/.DS_Store
--rw-r--r--   0 simon      (501) staff       (20)    39805 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/pose_configurations/schematics/8.png
--rw-r--r--   0 simon      (501) staff       (20)    62501 2023-03-30 10:39:05.000000 Simba-UW-tf-dev-1.57.5/simba/pose_configurations/schematics/9.png
--rw-r--r--   0 simon      (501) staff       (20)     6172 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/pose_configurations/schematics/12.png
--rw-r--r--   0 simon      (501) staff       (20)    69501 2023-03-30 10:44:04.000000 Simba-UW-tf-dev-1.57.5/simba/pose_configurations/schematics/11.png
--rw-r--r--   0 simon      (501) staff       (20)    69410 2023-03-30 10:40:01.000000 Simba-UW-tf-dev-1.57.5/simba/pose_configurations/schematics/10.png
--rw-r--r--   0 simon      (501) staff       (20)    16000 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/pose_configurations/schematics/4.png
--rw-r--r--   0 simon      (501) staff       (20)    28150 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/pose_configurations/schematics/5.png
--rw-r--r--   0 simon      (501) staff       (20)    31140 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/pose_configurations/schematics/7.png
--rw-r--r--   0 simon      (501) staff       (20)    30634 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/pose_configurations/schematics/6.png
--rw-r--r--   0 simon      (501) staff       (20)    15417 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/pose_configurations/schematics/2.png
--rw-r--r--   0 simon      (501) staff       (20)    15786 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/pose_configurations/schematics/3.png
--rw-r--r--   0 simon      (501) staff       (20)    18939 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/pose_configurations/schematics/1.png
--rw-r--r--   0 simon      (501) staff       (20)     7273 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/get_coordinates_tools_v2.py
--rw-r--r--   0 simon      (501) staff       (20)    16252 2023-03-15 19:16:56.000000 Simba-UW-tf-dev-1.57.5/simba/pup_retrieval_protocol.py
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/outlier_tools/
--rw-r--r--   0 simon      (501) staff       (20)     7822 2023-04-10 16:32:30.000000 Simba-UW-tf-dev-1.57.5/simba/outlier_tools/outlier_corrector_movement.py
--rw-r--r--   0 simon      (501) staff       (20)     8196 2023-03-15 17:05:05.000000 Simba-UW-tf-dev-1.57.5/simba/outlier_tools/.DS_Store
--rw-r--r--   0 simon      (501) staff       (20)        0 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/outlier_tools/__init__.py
--rw-r--r--   0 simon      (501) staff       (20)     8304 2023-04-10 13:29:16.000000 Simba-UW-tf-dev-1.57.5/simba/outlier_tools/outlier_corrector_location.py
--rw-r--r--   0 simon      (501) staff       (20)     4584 2023-04-23 12:51:22.000000 Simba-UW-tf-dev-1.57.5/simba/outlier_tools/skip_outlier_correction.py
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/outlier_tools/.idea/
--rw-r--r--   0 simon      (501) staff       (20)      617 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/outlier_tools/.idea/outlier_scripts.iml
--rw-r--r--   0 simon      (501) staff       (20)      138 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/outlier_tools/.idea/encodings.xml
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/outlier_tools/.idea/inspectionProfiles/
--rw-r--r--   0 simon      (501) staff       (20)      668 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/outlier_tools/.idea/inspectionProfiles/Project_Default.xml
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/outlier_tools/.idea/libraries/
--rw-r--r--   0 simon      (501) staff       (20)      128 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/outlier_tools/.idea/libraries/R_User_Library.xml
--rw-r--r--   0 simon      (501) staff       (20)     8102 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/outlier_tools/.idea/workspace.xml
--rw-r--r--   0 simon      (501) staff       (20)      289 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/outlier_tools/.idea/modules.xml
--rw-r--r--   0 simon      (501) staff       (20)      294 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/outlier_tools/.idea/misc.xml
--rw-r--r--   0 simon      (501) staff       (20)     2610 2023-04-10 15:22:21.000000 Simba-UW-tf-dev-1.57.5/simba/pose_reset.py
--rw-r--r--   0 simon      (501) staff       (20)    19358 2023-04-21 19:25:08.000000 Simba-UW-tf-dev-1.57.5/simba/train_mutiple_models.py
--rw-r--r--   0 simon      (501) staff       (20)    64554 2023-04-22 15:14:52.000000 Simba-UW-tf-dev-1.57.5/simba/SimBA.py
--rw-r--r--   0 simon      (501) staff       (20)    27472 2023-04-10 13:29:17.000000 Simba-UW-tf-dev-1.57.5/simba/labelling_advanced_interface.py
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/assets/
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/assets/unsupervised/
--rw-r--r--   0 simon      (501) staff       (20)     6148 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/unsupervised/.DS_Store
--rw-r--r--   0 simon      (501) staff       (20)   109483 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/unsupervised/model_names.parquet
--rw-r--r--   0 simon      (501) staff       (20)    14175 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/unsupervised/features.csv
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/assets/shap/
--rw-r--r--   0 simon      (501) staff       (20)     1177 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/shap/down_arrow.jpg
--rw-r--r--   0 simon      (501) staff       (20)     1733 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/shap/intruder_shape.jpg
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/assets/shap/feature_categories/
--rw-r--r--   0 simon      (501) staff       (20)      109 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/shap/feature_categories/.~lock.shap_feature_categories.csv#
--rw-r--r--   0 simon      (501) staff       (20)    17420 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/shap/feature_categories/shap_feature_categories.csv
--rw-r--r--   0 simon      (501) staff       (20)     8196 2023-04-10 20:37:13.000000 Simba-UW-tf-dev-1.57.5/simba/assets/shap/.DS_Store
--rw-r--r--   0 simon      (501) staff       (20)     1665 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/shap/resident_shape.jpg
--rw-r--r--   0 simon      (501) staff       (20)     2415 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/shap/resident_intruder_shape.jpg
--rw-r--r--   0 simon      (501) staff       (20)     2012 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/shap/animal_distances.jpg
--rw-r--r--   0 simon      (501) staff       (20)     4422 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/shap/baseline_scale.jpg
--rw-r--r--   0 simon      (501) staff       (20)   353824 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/shap/ubuntu.regular.ttf
--rw-r--r--   0 simon      (501) staff       (20)     6672 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/shap/side_scale.jpg
--rw-r--r--   0 simon      (501) staff       (20)   189004 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/shap/UbuntuMono-Regular.ttf
--rw-r--r--   0 simon      (501) staff       (20)     2737 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/shap/side_scale_5.jpg
--rw-r--r--   0 simon      (501) staff       (20)     1785 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/shap/intruder_movement.jpg
--rw-r--r--   0 simon      (501) staff       (20)     1435 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/shap/resident_movement.jpg
--rw-r--r--   0 simon      (501) staff       (20)     3134 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/shap/color_bar.jpg
--rw-r--r--   0 simon      (501) staff       (20)     2120 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/shap/resident_intruder_movement.jpg
--rw-r--r--   0 simon      (501) staff       (20)    16388 2023-04-22 15:52:42.000000 Simba-UW-tf-dev-1.57.5/simba/assets/.DS_Store
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/assets/lookups/
--rw-r--r--   0 simon      (501) staff       (20)     6148 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/lookups/.DS_Store
--rw-r--r--   0 simon      (501) staff       (20)   270783 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/lookups/model_names.parquet
--rw-r--r--   0 simon      (501) staff       (20)     2426 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/lookups/feature_extraction_headers.csv
--rw-r--r--   0 simon      (501) staff       (20)    14175 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/lookups/features.csv
--rw-r--r--   0 simon      (501) staff       (20)    14175 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/lookups/unsupervised_example_x.csv
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/assets/stl/
--rw-r--r--   0 simon      (501) staff       (20)   551576 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/stl/operant_tray.stl
--rw-r--r--   0 simon      (501) staff       (20)    67647 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/stl/operant_lever.stl
--rw-r--r--   0 simon      (501) staff       (20)    92896 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/stl/operant_walls.stl
--rw-r--r--   0 simon      (501) staff       (20)  4759984 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/stl/grid_floor.stl
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/assets/img/
--rw-r--r--   0 simon      (501) staff       (20)     6148 2023-04-10 23:20:37.000000 Simba-UW-tf-dev-1.57.5/simba/assets/img/.DS_Store
--rw-r--r--   0 simon      (501) staff       (20)   399272 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/img/about_me.png
--rw-r--r--   0 simon      (501) staff       (20)   117108 2023-04-10 23:06:31.000000 Simba-UW-tf-dev-1.57.5/simba/assets/img/splash.mp4
--rw-r--r--   0 simon      (501) staff       (20)   322242 2023-04-06 16:38:51.000000 Simba-UW-tf-dev-1.57.5/simba/assets/img/bg_2.png
--rw-r--r--   0 simon      (501) staff       (20)    69267 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/img/splash.pptx
--rw-r--r--   0 simon      (501) staff       (20)   204362 2023-04-06 15:01:45.000000 Simba-UW-tf-dev-1.57.5/simba/assets/img/bg.png
--rw-r--r--   0 simon      (501) staff       (20)   189004 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/UbuntuMono-Regular.ttf
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/
--rw-r--r--   0 simon      (501) staff       (20)     1350 2023-03-17 17:59:27.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/factory.png
--rw-r--r--   0 simon      (501) staff       (20)     1413 2023-03-21 13:03:06.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/cluster.png
--rw-r--r--   0 simon      (501) staff       (20)     1340 2023-03-17 16:51:08.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/load.png
--rw-r--r--   0 simon      (501) staff       (20)     4507 2023-03-20 14:13:48.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/gif.png
--rw-rw-r--   0 simon      (501) staff       (20)     4566 2023-03-18 18:12:27.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/pose.png
--rw-rw-r--   0 simon      (501) staff       (20)     1943 2023-03-18 18:14:10.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/features.png
--rw-r--r--   0 simon      (501) staff       (20)     6148 2023-04-05 17:25:36.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/.DS_Store
--rw-rw-r--   0 simon      (501) staff       (20)     4896 2023-03-17 19:17:29.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/settings.png
--rw-r--r--   0 simon      (501) staff       (20)     2090 2023-04-22 15:14:17.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/stopwatch.png
--rw-r--r--   0 simon      (501) staff       (20)     1252 2023-03-19 16:48:40.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/link.png
--rw-r--r--   0 simon      (501) staff       (20)    14250 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/dash_simba.css
--rw-r--r--   0 simon      (501) staff       (20)      917 2023-04-05 16:43:13.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/documentation.png
--rw-r--r--   0 simon      (501) staff       (20)     4503 2023-03-20 14:08:00.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/fps.png
--rw-r--r--   0 simon      (501) staff       (20)     1299 2023-03-21 13:02:07.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/dimensionality_reduction.png
--rw-rw-r--   0 simon      (501) staff       (20)     4823 2023-03-17 19:03:29.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/roi.png
--rw-r--r--   0 simon      (501) staff       (20)      920 2023-03-20 14:25:03.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/superimpose.png
--rw-r--r--   0 simon      (501) staff       (20)     1136 2023-03-18 20:25:31.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/label.png
--rw-r--r--   0 simon      (501) staff       (20)     1016 2023-03-20 14:28:47.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/change.png
--rw-r--r--   0 simon      (501) staff       (20)     1124 2023-03-17 18:05:26.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/crop.png
--rw-r--r--   0 simon      (501) staff       (20)     2146 2023-04-13 14:09:23.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/rotate.png
--rw-r--r--   0 simon      (501) staff       (20)     1057 2023-03-20 14:03:42.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/path.png
--rw-r--r--   0 simon      (501) staff       (20)      950 2023-03-17 18:07:33.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/clip.png
--rw-r--r--   0 simon      (501) staff       (20)     2121 2023-04-04 14:37:43.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/restart.png
--rw-rw-r--   0 simon      (501) staff       (20)     4653 2023-03-17 18:11:59.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/calipher.png
--rw-r--r--   0 simon      (501) staff       (20)     1291 2023-03-21 20:16:55.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/add_on.png
--rw-rw-r--   0 simon      (501) staff       (20)     4695 2023-03-17 17:57:16.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/create.png
--rw-r--r--   0 simon      (501) staff       (20)    78182 2023-03-20 16:35:36.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/SimBA_logo.ico
--rw-r--r--   0 simon      (501) staff       (20)     1067 2023-03-20 14:22:44.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/print.png
--rw-rw-r--   0 simon      (501) staff       (20)     4653 2023-03-18 20:27:58.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/clf.png
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/concat_icons/
--rw-r--r--   0 simon      (501) staff       (20)     6027 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/concat_icons/mosaic.png
--rw-r--r--   0 simon      (501) staff       (20)     5654 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/concat_icons/vertical.png
--rw-r--r--   0 simon      (501) staff       (20)     5542 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/concat_icons/horizontal.png
--rw-r--r--   0 simon      (501) staff       (20)     5939 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/concat_icons/mixed_mosaic.png
--rw-r--r--   0 simon      (501) staff       (20)     2060 2023-03-20 14:26:12.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/merge.png
--rw-r--r--   0 simon      (501) staff       (20)     1252 2023-04-07 11:25:59.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/clean.png
--rw-------   0 simon      (501) staff       (20)     4725 2023-03-18 20:27:47.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/clf_2.png
--rw-rw-r--   0 simon      (501) staff       (20)     4795 2023-03-17 18:10:10.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/visualize.png
--rw-r--r--   0 simon      (501) staff       (20)     2142 2023-03-20 14:10:28.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/concat.png
--rw-r--r--   0 simon      (501) staff       (20)     1474 2023-03-17 19:20:24.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/boris.png
--rw-rw-r--   0 simon      (501) staff       (20)     4804 2023-03-19 16:43:01.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/frames.png
--rw-r--r--   0 simon      (501) staff       (20)     2425 2023-03-19 16:44:55.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/video.png
--rw-r--r--   0 simon      (501) staff       (20)     2089 2023-03-20 14:05:58.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/sample.png
--rw-r--r--   0 simon      (501) staff       (20)     1471 2023-03-21 13:04:02.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/metrics.png
--rw-r--r--   0 simon      (501) staff       (20)     4555 2023-03-20 14:21:02.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/grey.png
--rw-r--r--   0 simon      (501) staff       (20)      930 2023-03-18 18:07:29.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/exit.png
--rw-r--r--   0 simon      (501) staff       (20)     4751 2023-03-18 20:31:58.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/outlier.png
--rw-r--r--   0 simon      (501) staff       (20)     4392 2023-03-20 14:16:15.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/clahe.png
--rw-rw-r--   0 simon      (501) staff       (20)     4637 2023-03-17 19:03:55.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/trash.png
--rw-r--r--   0 simon      (501) staff       (20)     1239 2023-03-19 16:51:21.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/about.png
--rw-rw-r--   0 simon      (501) staff       (20)     4666 2023-03-17 18:01:21.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/convert.png
--rw-r--r--   0 simon      (501) staff       (20)    93229 2023-03-20 16:01:42.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/SimBA_logo.icns
--rw-r--r--   0 simon      (501) staff       (20)      991 2023-03-20 19:02:33.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/reorganize.png
--rw-rw-r--   0 simon      (501) staff       (20)     4784 2023-03-17 18:50:35.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/browse.png
--rw-r--r--   0 simon      (501) staff       (20)    30707 2023-03-20 16:33:38.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/SimBA_logo.png
--rw-r--r--   0 simon      (501) staff       (20)     2293 2023-03-17 19:24:38.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/ethovision.png
--rw-r--r--   0 simon      (501) staff       (20)     1018 2023-04-05 15:24:49.000000 Simba-UW-tf-dev-1.57.5/simba/assets/icons/close.png
--rw-r--r--   0 simon      (501) staff       (20)    13672 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/dash_simba_base.css
--rw-r--r--   0 simon      (501) staff       (20)    31812 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/assets/TheGoldenLab.PNG
--rw-r--r--   0 simon      (501) staff       (20)    15545 2023-04-14 16:40:51.000000 Simba-UW-tf-dev-1.57.5/simba/drop_bp_cords.py
--rw-r--r--   0 simon      (501) staff       (20)     9460 2023-04-21 14:18:35.000000 Simba-UW-tf-dev-1.57.5/simba/read_config_unit_tests.py
--rw-r--r--   0 simon      (501) staff       (20)    11742 2023-04-10 13:29:17.000000 Simba-UW-tf-dev-1.57.5/simba/project_config_creator.py
--rw-r--r--   0 simon      (501) staff       (20)    27444 2023-03-15 15:58:40.000000 Simba-UW-tf-dev-1.57.5/simba/set_hyperparameters.py
--rw-r--r--   0 simon      (501) staff       (20)    20756 2023-04-19 14:41:07.000000 Simba-UW-tf-dev-1.57.5/simba/train_single_model.py
--rw-r--r--   0 simon      (501) staff       (20)     6467 2023-04-10 13:29:16.000000 Simba-UW-tf-dev-1.57.5/simba/create_clf_log.py
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/simba/batch_process_videos/
--rw-r--r--   0 simon      (501) staff       (20)     8196 2023-03-17 14:43:38.000000 Simba-UW-tf-dev-1.57.5/simba/batch_process_videos/.DS_Store
--rw-r--r--   0 simon      (501) staff       (20)    24911 2023-04-17 19:39:19.000000 Simba-UW-tf-dev-1.57.5/simba/batch_process_videos/batch_process_menus.py
--rw-r--r--   0 simon      (501) staff       (20)        0 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/batch_process_videos/__init__.py
--rw-r--r--   0 simon      (501) staff       (20)    10930 2023-04-17 19:35:15.000000 Simba-UW-tf-dev-1.57.5/simba/batch_process_videos/batch_process_create_ffmpeg_commands.py
--rw-r--r--   0 simon      (501) staff       (20)     9585 2023-04-10 13:29:16.000000 Simba-UW-tf-dev-1.57.5/simba/Kleinberg_calculator.py
--rw-r--r--   0 simon      (501) staff       (20)     8349 2023-04-10 13:29:17.000000 Simba-UW-tf-dev-1.57.5/simba/reorganize_keypoint_in_pose.py
--rw-r--r--   0 simon      (501) staff       (20)      165 2023-03-25 11:18:21.000000 Simba-UW-tf-dev-1.57.5/simba/~$features.pptx
--rw-r--r--   0 simon      (501) staff       (20)     6557 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.5/simba/play_annotation_video.py
-drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/Simba_UW_tf_dev.egg-info/
--rw-rw-r--   0 simon      (501) staff       (20)      579 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/Simba_UW_tf_dev.egg-info/PKG-INFO
--rw-rw-r--   0 simon      (501) staff       (20)    13588 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/Simba_UW_tf_dev.egg-info/SOURCES.txt
--rw-rw-r--   0 simon      (501) staff       (20)       44 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/Simba_UW_tf_dev.egg-info/entry_points.txt
--rw-rw-r--   0 simon      (501) staff       (20)      639 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/Simba_UW_tf_dev.egg-info/requires.txt
--rw-rw-r--   0 simon      (501) staff       (20)        6 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/Simba_UW_tf_dev.egg-info/top_level.txt
--rw-rw-r--   0 simon      (501) staff       (20)        1 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/Simba_UW_tf_dev.egg-info/dependency_links.txt
--rw-rw-r--   0 simon      (501) staff       (20)     7652 2020-05-13 13:27:38.000000 Simba-UW-tf-dev-1.57.5/LICENSE.md
--rw-rw-r--   0 simon      (501) staff       (20)      136 2021-04-10 10:44:06.000000 Simba-UW-tf-dev-1.57.5/MANIFEST.in
--rw-rw-r--   0 simon      (501) staff       (20)     9598 2020-05-13 13:27:40.000000 Simba-UW-tf-dev-1.57.5/README.md
--rw-rw-r--   0 simon      (501) staff       (20)     1897 2023-04-23 12:51:22.000000 Simba-UW-tf-dev-1.57.5/setup.py
--rw-r--r--   0 simon      (501) staff       (20)       38 2023-04-23 12:52:10.000000 Simba-UW-tf-dev-1.57.5/setup.cfg
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/
+-rw-r--r--   0 simon      (501) staff       (20)      579 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/PKG-INFO
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/
+-rw-r--r--   0 simon      (501) staff       (20)    41423 2023-04-27 12:44:27.000000 Simba-UW-tf-dev-1.57.6/simba/video_processing.py
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/blob_storage/
+-rw-r--r--   0 simon      (501) staff       (20)     6148 2023-03-21 20:39:46.000000 Simba-UW-tf-dev-1.57.6/simba/blob_storage/.DS_Store
+-rw-r--r--   0 simon      (501) staff       (20)    11539 2023-04-27 15:22:30.000000 Simba-UW-tf-dev-1.57.6/simba/interpolate_smooth.py
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/unsupervised/
+-rw-r--r--   0 simon      (501) staff       (20)    11902 2023-04-25 01:50:43.000000 Simba-UW-tf-dev-1.57.6/simba/unsupervised/dbcv_calculator.py
+-rw-r--r--   0 simon      (501) staff       (20)     3354 2023-04-20 14:05:40.000000 Simba-UW-tf-dev-1.57.6/simba/unsupervised/enums.py
+-rw-r--r--   0 simon      (501) staff       (20)     6148 2023-04-23 19:55:32.000000 Simba-UW-tf-dev-1.57.6/simba/unsupervised/.DS_Store
+-rw-r--r--   0 simon      (501) staff       (20)     7412 2023-04-25 14:58:07.000000 Simba-UW-tf-dev-1.57.6/simba/unsupervised/dataset_creator.py
+-rw-r--r--   0 simon      (501) staff       (20)     4775 2023-04-25 14:58:07.000000 Simba-UW-tf-dev-1.57.6/simba/unsupervised/grid_search_visualizers.py
+-rw-r--r--   0 simon      (501) staff       (20)     6649 2023-04-25 14:58:07.000000 Simba-UW-tf-dev-1.57.6/simba/unsupervised/data_extractor.py
+-rw-r--r--   0 simon      (501) staff       (20)     9907 2023-04-20 12:55:14.000000 Simba-UW-tf-dev-1.57.6/simba/unsupervised/ui.py
+-rw-r--r--   0 simon      (501) staff       (20)     8337 2023-04-25 11:06:37.000000 Simba-UW-tf-dev-1.57.6/simba/unsupervised/umap_embedder.py
+-rw-r--r--   0 simon      (501) staff       (20)    41476 2023-04-25 14:58:07.000000 Simba-UW-tf-dev-1.57.6/simba/unsupervised/pop_up_classes.py
+-rw-r--r--   0 simon      (501) staff       (20)     2317 2023-04-25 14:58:07.000000 Simba-UW-tf-dev-1.57.6/simba/unsupervised/bout_aggregator.py
+-rw-r--r--   0 simon      (501) staff       (20)    18443 2023-04-25 14:58:07.000000 Simba-UW-tf-dev-1.57.6/simba/unsupervised/cluster_statistics.py
+-rw-r--r--   0 simon      (501) staff       (20)     2188 2023-04-18 23:25:29.000000 Simba-UW-tf-dev-1.57.6/simba/unsupervised/data_map.yaml
+-rw-r--r--   0 simon      (501) staff       (20)     8301 2023-04-25 11:05:05.000000 Simba-UW-tf-dev-1.57.6/simba/unsupervised/hdbscan_clusterer.py
+-rw-r--r--   0 simon      (501) staff       (20)     3931 2023-04-19 18:21:47.000000 Simba-UW-tf-dev-1.57.6/simba/unsupervised/tsne.py
+-rw-r--r--   0 simon      (501) staff       (20)     5871 2023-04-25 01:50:43.000000 Simba-UW-tf-dev-1.57.6/simba/unsupervised/cluster_visualizer.py
+-rw-r--r--   0 simon      (501) staff       (20)    19720 2023-04-27 15:13:49.000000 Simba-UW-tf-dev-1.57.6/simba/enums.py
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/bounding_box_tools/
+-rw-r--r--   0 simon      (501) staff       (20)     6148 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/bounding_box_tools/.DS_Store
+-rw-r--r--   0 simon      (501) staff       (20)     6794 2023-04-25 13:26:59.000000 Simba-UW-tf-dev-1.57.6/simba/bounding_box_tools/agg_boundary_stats.py
+-rw-r--r--   0 simon      (501) staff       (20)    23483 2023-04-25 19:00:39.000000 Simba-UW-tf-dev-1.57.6/simba/bounding_box_tools/boundary_menus.py
+-rw-r--r--   0 simon      (501) staff       (20)     8485 2023-04-25 13:26:59.000000 Simba-UW-tf-dev-1.57.6/simba/bounding_box_tools/boundary_statistics.py
+-rw-r--r--   0 simon      (501) staff       (20)     6037 2023-04-25 15:53:12.000000 Simba-UW-tf-dev-1.57.6/simba/bounding_box_tools/find_boundaries.py
+-rw-r--r--   0 simon      (501) staff       (20)    10470 2023-04-25 13:27:00.000000 Simba-UW-tf-dev-1.57.6/simba/bounding_box_tools/visualize_boundaries.py
+-rw-r--r--   0 simon      (501) staff       (20)    32772 2023-04-26 18:25:34.000000 Simba-UW-tf-dev-1.57.6/simba/.DS_Store
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/
+-rw-r--r--   0 simon      (501) staff       (20)    42247 2023-04-26 01:31:26.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/feature_extractor_14bp.py
+-rw-r--r--   0 simon      (501) staff       (20)    21376 2023-04-26 01:31:26.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/feature_extractor_7bp.py
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/
+-rw-r--r--   0 simon      (501) staff       (20)     1685 2023-04-14 17:52:01.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/doctests.py
+-rw-r--r--   0 simon      (501) staff       (20)    23850 2023-04-17 18:48:40.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/fish_feature_extractor_2023_version_3.py
+-rw-r--r--   0 simon      (501) staff       (20)     2732 2023-04-04 19:46:36.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/read_in_mp.py
+-rw-r--r--   0 simon      (501) staff       (20)     2460 2023-04-22 18:02:29.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/peaks.py
+-rw-r--r--   0 simon      (501) staff       (20)    14141 2023-03-15 17:20:08.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/fish_feature_extractor_2022.py
+-rw-r--r--   0 simon      (501) staff       (20)     2053 2023-04-04 03:00:41.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/convex_hull_3_scratch_3.py
+-rw-r--r--   0 simon      (501) staff       (20)     5762 2023-04-04 01:54:33.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/convex_hull_scratch_1.py
+-rw-r--r--   0 simon      (501) staff       (20)     6148 2023-03-14 19:36:02.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/.DS_Store
+-rw-r--r--   0 simon      (501) staff       (20)    21398 2023-04-16 17:03:37.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/fish_feature_extractor_2023_version_2.py
+-rw-r--r--   0 simon      (501) staff       (20)     7127 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/egocentrical_aligner.py
+-rw-r--r--   0 simon      (501) staff       (20)     1213 2023-04-11 20:12:47.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/count_values_in_range.py
+-rw-r--r--   0 simon      (501) staff       (20)     4708 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/graph_creator.py
+-rw-r--r--   0 simon      (501) staff       (20)     3954 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/termite_rois.csv
+-rw-r--r--   0 simon      (501) staff       (20)      732 2023-03-20 12:13:51.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/mutual_exclusive.py
+-rw-r--r--   0 simon      (501) staff       (20)     2841 2023-04-14 15:16:23.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/video_color.py
+-rw-r--r--   0 simon      (501) staff       (20)     1862 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/graph_3d_plotter.py
+-rw-r--r--   0 simon      (501) staff       (20)     5232 2023-04-13 14:05:29.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/video_rotator.py
+-rw-r--r--   0 simon      (501) staff       (20)     2692 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/add_probability_cnt_features.py
+-rw-r--r--   0 simon      (501) staff       (20)     1619 2023-04-08 20:02:08.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/make_splash.py
+-rw-r--r--   0 simon      (501) staff       (20)     1658 2023-04-22 19:16:28.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/time_stamp_calculator.py
+-rw-r--r--   0 simon      (501) staff       (20)     5232 2023-04-15 19:24:18.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/video_rotator_mp.py
+-rw-r--r--   0 simon      (501) staff       (20)    30677 2023-04-27 01:57:28.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/fish_feature_extractor_2023_version_4.py
+-rw-r--r--   0 simon      (501) staff       (20)     2058 2023-04-03 23:51:37.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/convex_hull_scratch_2.py
+-rw-r--r--   0 simon      (501) staff       (20)    27709 2023-04-26 01:31:26.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/feature_extractor_8bps_2_animals.py
+-rw-r--r--   0 simon      (501) staff       (20)    10244 2023-04-25 21:03:39.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/.DS_Store
+-rw-r--r--   0 simon      (501) staff       (20)     2293 2023-04-24 20:15:27.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/perimeter_jit.py
+-rw-r--r--   0 simon      (501) staff       (20)    10762 2023-04-25 21:03:09.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/feature_subsets.py
+-rw-r--r--   0 simon      (501) staff       (20)        0 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/__init__.py
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/__pycache__/
+-rw-r--r--   0 simon      (501) staff       (20)      905 2023-04-04 11:31:57.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/__pycache__/perimeter_jit.quickhull_2d-16.py36m.nbi
+-rw-r--r--   0 simon      (501) staff       (20)   238196 2023-04-04 11:31:57.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/__pycache__/perimeter_jit.quickhull_2d-16.py36m.1.nbc
+-rw-r--r--   0 simon      (501) staff       (20)    69038 2023-04-04 11:32:25.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/__pycache__/perimeter_jit.process-7.py36m.1.nbc
+-rw-r--r--   0 simon      (501) staff       (20)   238298 2023-04-04 11:32:29.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/__pycache__/perimeter_jit.convex_hull_perimeter_2d-16.py36m.1.nbc
+-rw-r--r--   0 simon      (501) staff       (20)    69338 2023-04-04 11:32:26.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/__pycache__/perimeter_jit.process-7.py36m.2.nbc
+-rw-r--r--   0 simon      (501) staff       (20)      917 2023-04-04 11:32:29.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/__pycache__/perimeter_jit.convex_hull_perimeter_2d-16.py36m.nbi
+-rw-r--r--   0 simon      (501) staff       (20)     2179 2023-04-04 11:32:26.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/__pycache__/perimeter_jit.process-7.py36m.nbi
+-rw-r--r--   0 simon      (501) staff       (20)     8248 2023-04-26 01:31:25.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/feature_extractor_user_defined.py
+-rw-r--r--   0 simon      (501) staff       (20)    46191 2023-04-26 01:31:25.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/feature_extractor_16bp.py
+-rw-r--r--   0 simon      (501) staff       (20)    27391 2023-04-25 20:57:10.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/feature_extractor_9bp.py
+-rw-r--r--   0 simon      (501) staff       (20)    23873 2023-04-26 01:31:26.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/feature_extractor_8bp.py
+-rw-r--r--   0 simon      (501) staff       (20)    16793 2023-04-26 01:31:26.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/feature_extractor_4bp.py
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/.idea/
+-rw-r--r--   0 simon      (501) staff       (20)      617 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/.idea/features_scripts.iml
+-rw-r--r--   0 simon      (501) staff       (20)      138 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/.idea/encodings.xml
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/.idea/inspectionProfiles/
+-rw-r--r--   0 simon      (501) staff       (20)      822 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/.idea/inspectionProfiles/Project_Default.xml
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/.idea/libraries/
+-rw-r--r--   0 simon      (501) staff       (20)      128 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/.idea/libraries/R_User_Library.xml
+-rw-r--r--   0 simon      (501) staff       (20)      273 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/.idea/.gitignore
+-rw-r--r--   0 simon      (501) staff       (20)     8081 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/.idea/workspace.xml
+-rw-r--r--   0 simon      (501) staff       (20)      291 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/.idea/modules.xml
+-rw-r--r--   0 simon      (501) staff       (20)       23 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/.idea/.name
+-rw-r--r--   0 simon      (501) staff       (20)      294 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/feature_extractors/.idea/misc.xml
+-rw-r--r--   0 simon      (501) staff       (20)    15351 2023-04-06 14:48:36.000000 Simba-UW-tf-dev-1.57.6/simba/requirements.txt
+-rw-r--r--   0 simon      (501) staff       (20)     4827 2023-04-27 02:10:00.000000 Simba-UW-tf-dev-1.57.6/simba/severity_processor.py
+-rw-r--r--   0 simon      (501) staff       (20)     5942 2023-04-25 15:16:24.000000 Simba-UW-tf-dev-1.57.6/simba/user_pose_config_creator.py
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/mixins/
+-rw-r--r--   0 simon      (501) staff       (20)     6148 2023-03-15 17:26:03.000000 Simba-UW-tf-dev-1.57.6/simba/mixins/.DS_Store
+-rw-r--r--   0 simon      (501) staff       (20)    40244 2023-04-26 00:44:45.000000 Simba-UW-tf-dev-1.57.6/simba/mixins/pop_up_mixin.py
+-rw-r--r--   0 simon      (501) staff       (20)    28874 2023-04-26 19:15:07.000000 Simba-UW-tf-dev-1.57.6/simba/mixins/config_reader.py
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/mixins/__pycache__/
+-rw-r--r--   0 simon      (501) staff       (20)     1223 2023-04-25 20:46:51.000000 Simba-UW-tf-dev-1.57.6/simba/mixins/__pycache__/feature_extraction_mixin.FeatureExtractionMixin.cdist-182.py36m.nbi
+-rw-r--r--   0 simon      (501) staff       (20)    49894 2023-04-24 19:51:34.000000 Simba-UW-tf-dev-1.57.6/simba/mixins/__pycache__/feature_extraction_mixin.FeatureExtractionMixin.cdist-183.py36m.1.nbc
+-rw-r--r--   0 simon      (501) staff       (20)     1223 2023-04-24 19:51:34.000000 Simba-UW-tf-dev-1.57.6/simba/mixins/__pycache__/feature_extraction_mixin.FeatureExtractionMixin.cdist-183.py36m.nbi
+-rw-r--r--   0 simon      (501) staff       (20)    49894 2023-04-25 20:46:51.000000 Simba-UW-tf-dev-1.57.6/simba/mixins/__pycache__/feature_extraction_mixin.FeatureExtractionMixin.cdist-182.py36m.1.nbc
+-rw-r--r--   0 simon      (501) staff       (20)    49894 2023-04-24 19:06:57.000000 Simba-UW-tf-dev-1.57.6/simba/mixins/__pycache__/feature_extraction_mixin.FeatureExtractionMixin.cdist-181.py36m.1.nbc
+-rw-r--r--   0 simon      (501) staff       (20)     1223 2023-04-24 19:06:57.000000 Simba-UW-tf-dev-1.57.6/simba/mixins/__pycache__/feature_extraction_mixin.FeatureExtractionMixin.cdist-181.py36m.nbi
+-rw-r--r--   0 simon      (501) staff       (20)    22078 2023-04-27 01:56:00.000000 Simba-UW-tf-dev-1.57.6/simba/mixins/feature_extraction_mixin.py
+-rw-r--r--   0 simon      (501) staff       (20)    52214 2023-04-27 17:55:13.000000 Simba-UW-tf-dev-1.57.6/simba/mixins/plotting_mixin.py
+-rw-r--r--   0 simon      (501) staff       (20)     6063 2023-04-24 20:15:27.000000 Simba-UW-tf-dev-1.57.6/simba/mixins/unsupervised_mixin.py
+-rw-r--r--   0 simon      (501) staff       (20)    55244 2023-04-27 01:40:24.000000 Simba-UW-tf-dev-1.57.6/simba/mixins/train_model_mixin.py
+-rw-r--r--   0 simon      (501) staff       (20)    33917 2023-04-27 16:59:00.000000 Simba-UW-tf-dev-1.57.6/simba/machine_model_settings_pop_up.py
+-rw-r--r--   0 simon      (501) staff       (20)     5193 2023-04-25 12:41:52.000000 Simba-UW-tf-dev-1.57.6/simba/remove_keypoints_in_pose.py
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/third_party_label_appenders/
+-rw-r--r--   0 simon      (501) staff       (20)     6228 2023-04-26 18:27:58.000000 Simba-UW-tf-dev-1.57.6/simba/third_party_label_appenders/deepethogram_importer.py
+-rw-r--r--   0 simon      (501) staff       (20)     9945 2023-04-25 01:50:43.000000 Simba-UW-tf-dev-1.57.6/simba/third_party_label_appenders/BORIS_appender.py
+-rw-r--r--   0 simon      (501) staff       (20)     9063 2023-04-25 01:50:43.000000 Simba-UW-tf-dev-1.57.6/simba/third_party_label_appenders/observer_importer.py
+-rw-r--r--   0 simon      (501) staff       (20)    16888 2023-04-25 14:58:07.000000 Simba-UW-tf-dev-1.57.6/simba/third_party_label_appenders/tools.py
+-rw-r--r--   0 simon      (501) staff       (20)        0 2023-04-01 14:10:06.000000 Simba-UW-tf-dev-1.57.6/simba/third_party_label_appenders/__init__.py
+-rw-r--r--   0 simon      (501) staff       (20)    18242 2023-04-25 01:50:43.000000 Simba-UW-tf-dev-1.57.6/simba/third_party_label_appenders/third_party_appender.py
+-rw-r--r--   0 simon      (501) staff       (20)     8186 2023-04-25 01:50:43.000000 Simba-UW-tf-dev-1.57.6/simba/third_party_label_appenders/ethovision_import.py
+-rw-r--r--   0 simon      (501) staff       (20)     6859 2023-04-25 01:50:43.000000 Simba-UW-tf-dev-1.57.6/simba/third_party_label_appenders/BENTO_appender.py
+-rw-r--r--   0 simon      (501) staff       (20)     5331 2023-04-25 01:50:43.000000 Simba-UW-tf-dev-1.57.6/simba/third_party_label_appenders/solomon_importer.py
+-rw-r--r--   0 simon      (501) staff       (20)     7168 2023-04-25 11:55:36.000000 Simba-UW-tf-dev-1.57.6/simba/multi_cropper.py
+-rw-r--r--   0 simon      (501) staff       (20)    12720 2023-04-25 15:08:49.000000 Simba-UW-tf-dev-1.57.6/simba/FSTTC_calculator.py
+-rw-r--r--   0 simon      (501) staff       (20)    12570 2023-04-25 15:08:48.000000 Simba-UW-tf-dev-1.57.6/simba/create_project_pop_up.py
+-rw-r--r--   0 simon      (501) staff       (20)    13056 2023-04-26 18:37:46.000000 Simba-UW-tf-dev-1.57.6/simba/video_info_table.py
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/cue_light_tools/
+-rw-r--r--   0 simon      (501) staff       (20)     6148 2023-03-15 17:25:58.000000 Simba-UW-tf-dev-1.57.6/simba/cue_light_tools/.DS_Store
+-rw-r--r--   0 simon      (501) staff       (20)     7558 2023-04-25 13:26:59.000000 Simba-UW-tf-dev-1.57.6/simba/cue_light_tools/cue_light_clf_statistics.py
+-rw-r--r--   0 simon      (501) staff       (20)    12017 2023-04-25 13:26:59.000000 Simba-UW-tf-dev-1.57.6/simba/cue_light_tools/cue_light_analyzer.py
+-rw-r--r--   0 simon      (501) staff       (20)    17695 2023-04-25 13:27:00.000000 Simba-UW-tf-dev-1.57.6/simba/cue_light_tools/cue_light_menues.py
+-rw-r--r--   0 simon      (501) staff       (20)        0 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/cue_light_tools/__init__.py
+-rw-r--r--   0 simon      (501) staff       (20)     1660 2023-04-25 15:53:12.000000 Simba-UW-tf-dev-1.57.6/simba/cue_light_tools/cue_light_tools.py
+-rw-r--r--   0 simon      (501) staff       (20)    15253 2023-04-25 15:26:48.000000 Simba-UW-tf-dev-1.57.6/simba/cue_light_tools/cue_light_visualizer.py
+-rw-r--r--   0 simon      (501) staff       (20)    11922 2023-04-25 18:38:05.000000 Simba-UW-tf-dev-1.57.6/simba/cue_light_tools/cue_light_movement_statistics.py
+-rw-r--r--   0 simon      (501) staff       (20)        0 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/__init__.py
+-rw-r--r--   0 simon      (501) staff       (20)     2799 2023-04-25 11:23:20.000000 Simba-UW-tf-dev-1.57.6/simba/extract_frames_fast.py
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/utils/
+-rw-r--r--   0 simon      (501) staff       (20)     6148 2023-03-14 20:15:03.000000 Simba-UW-tf-dev-1.57.6/simba/utils/.DS_Store
+-rw-r--r--   0 simon      (501) staff       (20)     7335 2023-04-10 18:32:39.000000 Simba-UW-tf-dev-1.57.6/simba/utils/warnings.py
+-rw-r--r--   0 simon      (501) staff       (20)     5562 2023-04-25 21:03:09.000000 Simba-UW-tf-dev-1.57.6/simba/utils/checks.py
+-rw-r--r--   0 simon      (501) staff       (20)    33727 2023-04-27 15:02:22.000000 Simba-UW-tf-dev-1.57.6/simba/utils/read_write.py
+-rw-r--r--   0 simon      (501) staff       (20)     6998 2023-04-25 20:57:10.000000 Simba-UW-tf-dev-1.57.6/simba/utils/lookups.py
+-rw-r--r--   0 simon      (501) staff       (20)    14630 2023-04-26 12:39:28.000000 Simba-UW-tf-dev-1.57.6/simba/utils/errors.py
+-rw-r--r--   0 simon      (501) staff       (20)    13823 2023-04-27 13:07:16.000000 Simba-UW-tf-dev-1.57.6/simba/utils/data.py
+-rw-r--r--   0 simon      (501) staff       (20)     1537 2023-04-24 18:39:34.000000 Simba-UW-tf-dev-1.57.6/simba/utils/printing.py
+-rw-r--r--   0 simon      (501) staff       (20)    20580 2023-04-25 15:08:48.000000 Simba-UW-tf-dev-1.57.6/simba/labelling_interface.py
+-rw-r--r--   0 simon      (501) staff       (20)     9371 2023-04-26 20:31:09.000000 Simba-UW-tf-dev-1.57.6/simba/timebins_movement_analyzer.py
+-rw-r--r--   0 simon      (501) staff       (20)    49699 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/SimBA_dash_app.py
+-rw-r--r--   0 simon      (501) staff       (20)     7421 2023-04-27 02:02:22.000000 Simba-UW-tf-dev-1.57.6/simba/timebins_clf_analyzer.py
+-rw-r--r--   0 simon      (501) staff       (20)     8215 2023-04-25 11:06:37.000000 Simba-UW-tf-dev-1.57.6/simba/calculate_px_dist.py
+-rw-r--r--   0 simon      (501) staff       (20)     6411 2023-04-25 18:52:57.000000 Simba-UW-tf-dev-1.57.6/simba/movement_processor.py
+-rw-r--r--   0 simon      (501) staff       (20)     2904 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/pybursts.py
+-rw-r--r--   0 simon      (501) staff       (20)     5630 2023-04-25 15:16:24.000000 Simba-UW-tf-dev-1.57.6/simba/reverse_2_animal_tracking.py
+-rw-r--r--   0 simon      (501) staff       (20)     9654 2023-04-25 11:22:07.000000 Simba-UW-tf-dev-1.57.6/simba/Directing_animals_analyzer.py
+-rw-r--r--   0 simon      (501) staff       (20)     3170 2023-04-25 13:13:10.000000 Simba-UW-tf-dev-1.57.6/simba/Validate_model_one_video_run_clf.py
+-rw-r--r--   0 simon      (501) staff       (20)    10874 2023-04-25 13:05:45.000000 Simba-UW-tf-dev-1.57.6/simba/tkinter_functions.py
+-rw-r--r--   0 simon      (501) staff       (20)    13112 2023-04-26 21:09:13.000000 Simba-UW-tf-dev-1.57.6/simba/setting_menu.py
+-rw-r--r--   0 simon      (501) staff       (20)     6317 2023-04-25 18:03:32.000000 Simba-UW-tf-dev-1.57.6/simba/interpolate_pose.py
+-rw-r--r--   0 simon      (501) staff       (20)     3557 2023-04-25 15:16:24.000000 Simba-UW-tf-dev-1.57.6/simba/run_inference.py
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/
+-rw-r--r--   0 simon      (501) staff       (20)     9137 2023-04-26 02:10:59.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/gantt_creator.py
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/tools/
+-rw-r--r--   0 simon      (501) staff       (20)     5358 2023-04-24 20:41:26.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/tools/tkinter_tools.py
+-rw-r--r--   0 simon      (501) staff       (20)    13244 2023-04-26 19:34:04.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/ROI_plotter_mp.py
+-rw-r--r--   0 simon      (501) staff       (20)     6148 2023-04-25 23:35:57.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/.DS_Store
+-rw-r--r--   0 simon      (501) staff       (20)    14600 2023-04-26 14:02:58.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/shap_agg_stats_visualizer.py
+-rw-r--r--   0 simon      (501) staff       (20)    10167 2023-04-26 15:08:19.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/gantt_creator_mp.py
+-rw-r--r--   0 simon      (501) staff       (20)    15975 2023-04-26 13:44:02.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/heat_mapper_clf_mp.py
+-rw-r--r--   0 simon      (501) staff       (20)     8557 2023-04-26 12:36:28.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/probability_plot_creator.py
+-rw-r--r--   0 simon      (501) staff       (20)    12267 2023-04-26 11:18:28.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/plot_clf_results.py
+-rw-r--r--   0 simon      (501) staff       (20)    16556 2023-04-26 11:24:45.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/plot_clf_results_mp.py
+-rw-r--r--   0 simon      (501) staff       (20)    15885 2023-04-26 12:47:24.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/ROI_feature_visualizer.py
+-rw-r--r--   0 simon      (501) staff       (20)    12746 2023-04-26 20:06:54.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/heat_mapper_location.py
+-rw-r--r--   0 simon      (501) staff       (20)    12507 2023-04-26 12:41:15.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/probability_plot_creator_mp.py
+-rw-r--r--   0 simon      (501) staff       (20)     5239 2023-04-26 02:56:05.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/interactive_probability_grapher.py
+-rw-r--r--   0 simon      (501) staff       (20)     5748 2023-04-26 11:37:28.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/plot_pose_in_dir.py
+-rw-r--r--   0 simon      (501) staff       (20)    12771 2023-04-26 14:16:42.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/single_run_model_validation_video.py
+-rw-r--r--   0 simon      (501) staff       (20)    12236 2023-04-27 12:57:18.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/frame_mergerer_ffmpeg.py
+-rw-r--r--   0 simon      (501) staff       (20)     7887 2023-04-26 13:22:21.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/Directing_animals_visualizer_mp.py
+-rw-r--r--   0 simon      (501) staff       (20)    11204 2023-04-27 12:38:21.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/clf_validator.py
+-rw-r--r--   0 simon      (501) staff       (20)    16708 2023-04-26 15:09:39.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/path_plotter_mp.py
+-rw-r--r--   0 simon      (501) staff       (20)    11324 2023-04-26 13:09:33.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/ROI_feature_visualizer_mp.py
+-rw-r--r--   0 simon      (501) staff       (20)     9876 2023-04-25 23:33:34.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/data_plotter.py
+-rw-r--r--   0 simon      (501) staff       (20)    12920 2023-04-26 10:57:46.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/path_plotter.py
+-rw-r--r--   0 simon      (501) staff       (20)     8506 2023-04-25 13:35:52.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/ez_lineplot.py
+-rw-r--r--   0 simon      (501) staff       (20)    11494 2023-04-26 13:25:36.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/distance_plotter_mp.py
+-rw-r--r--   0 simon      (501) staff       (20)    15604 2023-04-26 13:46:25.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/ROI_plotter.py
+-rw-r--r--   0 simon      (501) staff       (20)    13127 2023-04-25 13:50:19.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/heat_mapper_clf.py
+-rw-r--r--   0 simon      (501) staff       (20)     8973 2023-04-26 00:37:26.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/distance_plotter.py
+-rw-r--r--   0 simon      (501) staff       (20)    13560 2023-04-27 18:03:45.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/single_run_model_validation_video_mp.py
+-rw-r--r--   0 simon      (501) staff       (20)     9744 2023-04-25 18:55:04.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/Directing_animals_visualizer.py
+-rw-r--r--   0 simon      (501) staff       (20)    16328 2023-04-26 20:12:38.000000 Simba-UW-tf-dev-1.57.6/simba/plotting/heat_mapper_location_mp.py
+-rw-r--r--   0 simon      (501) staff       (20)     5029 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/run_dash_tkinter.py
+-rw-r--r--   0 simon      (501) staff       (20)    24474 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/dash_app.py
+-rw-r--r--   0 simon      (501) staff       (20)     2877 2023-04-25 15:08:48.000000 Simba-UW-tf-dev-1.57.6/simba/extract_annotation_frames.py
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/roi_tools/
+-rw-r--r--   0 simon      (501) staff       (20)     6501 2023-04-25 18:50:18.000000 Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_time_bin_calculator.py
+-rw-r--r--   0 simon      (501) staff       (20)     1766 2023-04-25 18:48:44.000000 Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_movement_analyzer.py
+-rw-r--r--   0 simon      (501) staff       (20)     6148 2023-03-20 12:47:56.000000 Simba-UW-tf-dev-1.57.6/simba/roi_tools/.DS_Store
+-rw-r--r--   0 simon      (501) staff       (20)    43128 2023-04-26 19:19:44.000000 Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_define.py
+-rw-r--r--   0 simon      (501) staff       (20)     3402 2023-04-26 19:25:50.000000 Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_reset.py
+-rw-r--r--   0 simon      (501) staff       (20)        0 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/roi_tools/__init__.py
+-rw-r--r--   0 simon      (501) staff       (20)    19703 2023-04-26 14:59:42.000000 Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_analyzer.py
+-rw-r--r--   0 simon      (501) staff       (20)    11332 2023-04-26 21:13:20.000000 Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_feature_analyzer.py
+-rw-r--r--   0 simon      (501) staff       (20)     3651 2023-04-26 19:22:41.000000 Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_multiply.py
+-rw-r--r--   0 simon      (501) staff       (20)      961 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_size_calculations.py
+-rw-r--r--   0 simon      (501) staff       (20)     3505 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_zoom.py
+-rw-r--r--   0 simon      (501) staff       (20)    11397 2023-04-26 15:12:12.000000 Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_directing_analyzer.py
+-rw-r--r--   0 simon      (501) staff       (20)    10128 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_move_shape.py
+-rw-r--r--   0 simon      (501) staff       (20)     5073 2023-04-25 14:55:41.000000 Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_menus.py
+-rw-r--r--   0 simon      (501) staff       (20)    13793 2023-04-26 14:59:42.000000 Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_clf_calculator.py
+-rw-r--r--   0 simon      (501) staff       (20)    22685 2023-04-25 14:55:41.000000 Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_image.py
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/pose_importers/
+-rw-r--r--   0 simon      (501) staff       (20)     2477 2023-04-26 18:25:13.000000 Simba-UW-tf-dev-1.57.6/simba/pose_importers/read_DANNCE_mat.py
+-rw-r--r--   0 simon      (501) staff       (20)    21991 2023-04-27 15:50:07.000000 Simba-UW-tf-dev-1.57.6/simba/pose_importers/sleap_importer_slp.py
+-rw-r--r--   0 simon      (501) staff       (20)    23507 2023-04-27 15:45:27.000000 Simba-UW-tf-dev-1.57.6/simba/pose_importers/sleap_importer_h5.py
+-rw-r--r--   0 simon      (501) staff       (20)    23592 2023-04-27 15:41:32.000000 Simba-UW-tf-dev-1.57.6/simba/pose_importers/dlc_multi_animal_importer.py
+-rw-r--r--   0 simon      (501) staff       (20)     6148 2023-04-25 16:49:14.000000 Simba-UW-tf-dev-1.57.6/simba/pose_importers/.DS_Store
+-rw-r--r--   0 simon      (501) staff       (20)    20973 2023-04-27 15:41:32.000000 Simba-UW-tf-dev-1.57.6/simba/pose_importers/sleap_importer_csv.py
+-rw-r--r--   0 simon      (501) staff       (20)     7761 2023-04-25 18:26:26.000000 Simba-UW-tf-dev-1.57.6/simba/pose_importers/import_mars.py
+-rw-r--r--   0 simon      (501) staff       (20)     6935 2023-04-27 14:57:59.000000 Simba-UW-tf-dev-1.57.6/simba/pose_importers/dlc_importer_csv.py
+-rw-r--r--   0 simon      (501) staff       (20)     6705 2023-04-25 18:51:56.000000 Simba-UW-tf-dev-1.57.6/simba/pose_importers/trk_importer.py
+-rw-r--r--   0 simon      (501) staff       (20)   236946 2023-04-27 16:42:18.000000 Simba-UW-tf-dev-1.57.6/simba/pop_up_classes.py
+-rw-r--r--   0 simon      (501) staff       (20)     4695 2023-04-26 18:17:53.000000 Simba-UW-tf-dev-1.57.6/simba/extract_seqframes.py
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/pose_configurations/
+-rw-r--r--   0 simon      (501) staff       (20)    14340 2023-03-30 11:05:37.000000 Simba-UW-tf-dev-1.57.6/simba/pose_configurations/.DS_Store
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/pose_configurations/bp_names/
+-rw-r--r--   0 simon      (501) staff       (20)     6148 2023-03-16 13:26:00.000000 Simba-UW-tf-dev-1.57.6/simba/pose_configurations/bp_names/.DS_Store
+-rw-r--r--   0 simon      (501) staff       (20)     1316 2023-04-10 12:22:28.000000 Simba-UW-tf-dev-1.57.6/simba/pose_configurations/bp_names/bp_names.csv
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/pose_configurations/no_animals/
+-rw-r--r--   0 simon      (501) staff       (20)       24 2023-03-20 15:55:45.000000 Simba-UW-tf-dev-1.57.6/simba/pose_configurations/no_animals/no_animals.csv
+-rw-r--r--   0 simon      (501) staff       (20)     6148 2023-03-16 13:26:19.000000 Simba-UW-tf-dev-1.57.6/simba/pose_configurations/no_animals/.DS_Store
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/pose_configurations/configuration_names/
+-rw-r--r--   0 simon      (501) staff       (20)     6148 2023-03-16 13:26:14.000000 Simba-UW-tf-dev-1.57.6/simba/pose_configurations/configuration_names/.DS_Store
+-rw-r--r--   0 simon      (501) staff       (20)      267 2023-03-20 15:55:45.000000 Simba-UW-tf-dev-1.57.6/simba/pose_configurations/configuration_names/pose_config_names.csv
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/pose_configurations/schematics/
+-rw-r--r--   0 simon      (501) staff       (20)     8196 2023-03-30 10:45:10.000000 Simba-UW-tf-dev-1.57.6/simba/pose_configurations/schematics/.DS_Store
+-rw-r--r--   0 simon      (501) staff       (20)    39805 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/pose_configurations/schematics/8.png
+-rw-r--r--   0 simon      (501) staff       (20)    62501 2023-03-30 10:39:05.000000 Simba-UW-tf-dev-1.57.6/simba/pose_configurations/schematics/9.png
+-rw-r--r--   0 simon      (501) staff       (20)     6172 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/pose_configurations/schematics/12.png
+-rw-r--r--   0 simon      (501) staff       (20)    69501 2023-03-30 10:44:04.000000 Simba-UW-tf-dev-1.57.6/simba/pose_configurations/schematics/11.png
+-rw-r--r--   0 simon      (501) staff       (20)    69410 2023-03-30 10:40:01.000000 Simba-UW-tf-dev-1.57.6/simba/pose_configurations/schematics/10.png
+-rw-r--r--   0 simon      (501) staff       (20)    16000 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/pose_configurations/schematics/4.png
+-rw-r--r--   0 simon      (501) staff       (20)    28150 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/pose_configurations/schematics/5.png
+-rw-r--r--   0 simon      (501) staff       (20)    31140 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/pose_configurations/schematics/7.png
+-rw-r--r--   0 simon      (501) staff       (20)    30634 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/pose_configurations/schematics/6.png
+-rw-r--r--   0 simon      (501) staff       (20)    15417 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/pose_configurations/schematics/2.png
+-rw-r--r--   0 simon      (501) staff       (20)    15786 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/pose_configurations/schematics/3.png
+-rw-r--r--   0 simon      (501) staff       (20)    18939 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/pose_configurations/schematics/1.png
+-rw-r--r--   0 simon      (501) staff       (20)     7184 2023-04-25 11:24:28.000000 Simba-UW-tf-dev-1.57.6/simba/get_coordinates_tools_v2.py
+-rw-r--r--   0 simon      (501) staff       (20)    15731 2023-04-25 15:16:24.000000 Simba-UW-tf-dev-1.57.6/simba/pup_retrieval_protocol.py
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/outlier_tools/
+-rw-r--r--   0 simon      (501) staff       (20)     7397 2023-04-26 19:04:38.000000 Simba-UW-tf-dev-1.57.6/simba/outlier_tools/outlier_corrector_movement.py
+-rw-r--r--   0 simon      (501) staff       (20)     8196 2023-03-15 17:05:05.000000 Simba-UW-tf-dev-1.57.6/simba/outlier_tools/.DS_Store
+-rw-r--r--   0 simon      (501) staff       (20)        0 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/outlier_tools/__init__.py
+-rw-r--r--   0 simon      (501) staff       (20)     8161 2023-04-26 19:05:15.000000 Simba-UW-tf-dev-1.57.6/simba/outlier_tools/outlier_corrector_location.py
+-rw-r--r--   0 simon      (501) staff       (20)     2674 2023-04-26 19:01:06.000000 Simba-UW-tf-dev-1.57.6/simba/outlier_tools/skip_outlier_correction.py
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/outlier_tools/.idea/
+-rw-r--r--   0 simon      (501) staff       (20)      617 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/outlier_tools/.idea/outlier_scripts.iml
+-rw-r--r--   0 simon      (501) staff       (20)      138 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/outlier_tools/.idea/encodings.xml
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/outlier_tools/.idea/inspectionProfiles/
+-rw-r--r--   0 simon      (501) staff       (20)      668 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/outlier_tools/.idea/inspectionProfiles/Project_Default.xml
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/outlier_tools/.idea/libraries/
+-rw-r--r--   0 simon      (501) staff       (20)      128 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/outlier_tools/.idea/libraries/R_User_Library.xml
+-rw-r--r--   0 simon      (501) staff       (20)     8102 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/outlier_tools/.idea/workspace.xml
+-rw-r--r--   0 simon      (501) staff       (20)      289 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/outlier_tools/.idea/modules.xml
+-rw-r--r--   0 simon      (501) staff       (20)      294 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/outlier_tools/.idea/misc.xml
+-rw-r--r--   0 simon      (501) staff       (20)     2613 2023-04-25 15:16:24.000000 Simba-UW-tf-dev-1.57.6/simba/pose_reset.py
+-rw-r--r--   0 simon      (501) staff       (20)    18234 2023-04-27 17:03:57.000000 Simba-UW-tf-dev-1.57.6/simba/train_mutiple_models.py
+-rw-r--r--   0 simon      (501) staff       (20)    63977 2023-04-27 16:44:54.000000 Simba-UW-tf-dev-1.57.6/simba/SimBA.py
+-rw-r--r--   0 simon      (501) staff       (20)    26572 2023-04-25 11:49:41.000000 Simba-UW-tf-dev-1.57.6/simba/labelling_advanced_interface.py
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/assets/
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/assets/unsupervised/
+-rw-r--r--   0 simon      (501) staff       (20)     6148 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/unsupervised/.DS_Store
+-rw-r--r--   0 simon      (501) staff       (20)   109483 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/unsupervised/model_names.parquet
+-rw-r--r--   0 simon      (501) staff       (20)    14175 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/unsupervised/features.csv
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/assets/shap/
+-rw-r--r--   0 simon      (501) staff       (20)     1177 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/shap/down_arrow.jpg
+-rw-r--r--   0 simon      (501) staff       (20)     1733 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/shap/intruder_shape.jpg
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/assets/shap/feature_categories/
+-rw-r--r--   0 simon      (501) staff       (20)      109 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/shap/feature_categories/.~lock.shap_feature_categories.csv#
+-rw-r--r--   0 simon      (501) staff       (20)    17420 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/shap/feature_categories/shap_feature_categories.csv
+-rw-r--r--   0 simon      (501) staff       (20)     8196 2023-04-10 20:37:13.000000 Simba-UW-tf-dev-1.57.6/simba/assets/shap/.DS_Store
+-rw-r--r--   0 simon      (501) staff       (20)     1665 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/shap/resident_shape.jpg
+-rw-r--r--   0 simon      (501) staff       (20)     2415 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/shap/resident_intruder_shape.jpg
+-rw-r--r--   0 simon      (501) staff       (20)     2012 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/shap/animal_distances.jpg
+-rw-r--r--   0 simon      (501) staff       (20)     4422 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/shap/baseline_scale.jpg
+-rw-r--r--   0 simon      (501) staff       (20)   353824 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/shap/ubuntu.regular.ttf
+-rw-r--r--   0 simon      (501) staff       (20)     6672 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/shap/side_scale.jpg
+-rw-r--r--   0 simon      (501) staff       (20)   189004 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/shap/UbuntuMono-Regular.ttf
+-rw-r--r--   0 simon      (501) staff       (20)     2737 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/shap/side_scale_5.jpg
+-rw-r--r--   0 simon      (501) staff       (20)     1785 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/shap/intruder_movement.jpg
+-rw-r--r--   0 simon      (501) staff       (20)     1435 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/shap/resident_movement.jpg
+-rw-r--r--   0 simon      (501) staff       (20)     3134 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/shap/color_bar.jpg
+-rw-r--r--   0 simon      (501) staff       (20)     2120 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/shap/resident_intruder_movement.jpg
+-rw-r--r--   0 simon      (501) staff       (20)    16388 2023-04-25 19:14:34.000000 Simba-UW-tf-dev-1.57.6/simba/assets/.DS_Store
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/assets/lookups/
+-rw-r--r--   0 simon      (501) staff       (20)     6148 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/lookups/.DS_Store
+-rw-r--r--   0 simon      (501) staff       (20)   270783 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/lookups/model_names.parquet
+-rw-r--r--   0 simon      (501) staff       (20)     2987 2023-04-25 20:39:03.000000 Simba-UW-tf-dev-1.57.6/simba/assets/lookups/feature_extraction_headers.csv
+-rw-r--r--   0 simon      (501) staff       (20)    14175 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/lookups/features.csv
+-rw-r--r--   0 simon      (501) staff       (20)    14175 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/lookups/unsupervised_example_x.csv
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/assets/stl/
+-rw-r--r--   0 simon      (501) staff       (20)   551576 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/stl/operant_tray.stl
+-rw-r--r--   0 simon      (501) staff       (20)    67647 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/stl/operant_lever.stl
+-rw-r--r--   0 simon      (501) staff       (20)    92896 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/stl/operant_walls.stl
+-rw-r--r--   0 simon      (501) staff       (20)  4759984 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/stl/grid_floor.stl
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/assets/img/
+-rw-r--r--   0 simon      (501) staff       (20)     6148 2023-04-10 23:20:37.000000 Simba-UW-tf-dev-1.57.6/simba/assets/img/.DS_Store
+-rw-r--r--   0 simon      (501) staff       (20)   399272 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/img/about_me.png
+-rw-r--r--   0 simon      (501) staff       (20)   117108 2023-04-10 23:06:31.000000 Simba-UW-tf-dev-1.57.6/simba/assets/img/splash.mp4
+-rw-r--r--   0 simon      (501) staff       (20)   322242 2023-04-06 16:38:51.000000 Simba-UW-tf-dev-1.57.6/simba/assets/img/bg_2.png
+-rw-r--r--   0 simon      (501) staff       (20)    69267 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/img/splash.pptx
+-rw-r--r--   0 simon      (501) staff       (20)   204362 2023-04-06 15:01:45.000000 Simba-UW-tf-dev-1.57.6/simba/assets/img/bg.png
+-rw-r--r--   0 simon      (501) staff       (20)   189004 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/UbuntuMono-Regular.ttf
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/
+-rw-r--r--   0 simon      (501) staff       (20)     1350 2023-03-17 17:59:27.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/factory.png
+-rw-r--r--   0 simon      (501) staff       (20)     1413 2023-03-21 13:03:06.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/cluster.png
+-rw-r--r--   0 simon      (501) staff       (20)     1340 2023-03-17 16:51:08.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/load.png
+-rw-r--r--   0 simon      (501) staff       (20)     4507 2023-03-20 14:13:48.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/gif.png
+-rw-rw-r--   0 simon      (501) staff       (20)     4566 2023-03-18 18:12:27.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/pose.png
+-rw-rw-r--   0 simon      (501) staff       (20)     1943 2023-03-18 18:14:10.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/features.png
+-rw-r--r--   0 simon      (501) staff       (20)     6148 2023-04-05 17:25:36.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/.DS_Store
+-rw-rw-r--   0 simon      (501) staff       (20)     4896 2023-03-17 19:17:29.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/settings.png
+-rw-r--r--   0 simon      (501) staff       (20)     2090 2023-04-22 15:14:17.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/stopwatch.png
+-rw-r--r--   0 simon      (501) staff       (20)     1252 2023-03-19 16:48:40.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/link.png
+-rw-r--r--   0 simon      (501) staff       (20)    14250 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/dash_simba.css
+-rw-r--r--   0 simon      (501) staff       (20)      917 2023-04-05 16:43:13.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/documentation.png
+-rw-r--r--   0 simon      (501) staff       (20)     4503 2023-03-20 14:08:00.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/fps.png
+-rw-r--r--   0 simon      (501) staff       (20)     1299 2023-03-21 13:02:07.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/dimensionality_reduction.png
+-rw-rw-r--   0 simon      (501) staff       (20)     4823 2023-03-17 19:03:29.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/roi.png
+-rw-r--r--   0 simon      (501) staff       (20)      920 2023-03-20 14:25:03.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/superimpose.png
+-rw-r--r--   0 simon      (501) staff       (20)     1136 2023-03-18 20:25:31.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/label.png
+-rw-r--r--   0 simon      (501) staff       (20)     1016 2023-03-20 14:28:47.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/change.png
+-rw-r--r--   0 simon      (501) staff       (20)     1124 2023-03-17 18:05:26.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/crop.png
+-rw-r--r--   0 simon      (501) staff       (20)     2146 2023-04-13 14:09:23.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/rotate.png
+-rw-r--r--   0 simon      (501) staff       (20)     1057 2023-03-20 14:03:42.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/path.png
+-rw-r--r--   0 simon      (501) staff       (20)      950 2023-03-17 18:07:33.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/clip.png
+-rw-r--r--   0 simon      (501) staff       (20)     2121 2023-04-04 14:37:43.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/restart.png
+-rw-rw-r--   0 simon      (501) staff       (20)     4653 2023-03-17 18:11:59.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/calipher.png
+-rw-r--r--   0 simon      (501) staff       (20)     1291 2023-03-21 20:16:55.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/add_on.png
+-rw-rw-r--   0 simon      (501) staff       (20)     4695 2023-03-17 17:57:16.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/create.png
+-rw-r--r--   0 simon      (501) staff       (20)    78182 2023-03-20 16:35:36.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/SimBA_logo.ico
+-rw-r--r--   0 simon      (501) staff       (20)     1067 2023-03-20 14:22:44.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/print.png
+-rw-rw-r--   0 simon      (501) staff       (20)     4653 2023-03-18 20:27:58.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/clf.png
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/concat_icons/
+-rw-r--r--   0 simon      (501) staff       (20)     6027 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/concat_icons/mosaic.png
+-rw-r--r--   0 simon      (501) staff       (20)     5654 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/concat_icons/vertical.png
+-rw-r--r--   0 simon      (501) staff       (20)     5542 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/concat_icons/horizontal.png
+-rw-r--r--   0 simon      (501) staff       (20)     5939 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/concat_icons/mixed_mosaic.png
+-rw-r--r--   0 simon      (501) staff       (20)     2060 2023-03-20 14:26:12.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/merge.png
+-rw-r--r--   0 simon      (501) staff       (20)     1252 2023-04-07 11:25:59.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/clean.png
+-rw-------   0 simon      (501) staff       (20)     4725 2023-03-18 20:27:47.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/clf_2.png
+-rw-rw-r--   0 simon      (501) staff       (20)     4795 2023-03-17 18:10:10.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/visualize.png
+-rw-r--r--   0 simon      (501) staff       (20)     2142 2023-03-20 14:10:28.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/concat.png
+-rw-r--r--   0 simon      (501) staff       (20)     1474 2023-03-17 19:20:24.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/boris.png
+-rw-rw-r--   0 simon      (501) staff       (20)     4804 2023-03-19 16:43:01.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/frames.png
+-rw-r--r--   0 simon      (501) staff       (20)     2425 2023-03-19 16:44:55.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/video.png
+-rw-r--r--   0 simon      (501) staff       (20)     2089 2023-03-20 14:05:58.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/sample.png
+-rw-r--r--   0 simon      (501) staff       (20)     1471 2023-03-21 13:04:02.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/metrics.png
+-rw-r--r--   0 simon      (501) staff       (20)     4555 2023-03-20 14:21:02.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/grey.png
+-rw-r--r--   0 simon      (501) staff       (20)      930 2023-03-18 18:07:29.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/exit.png
+-rw-r--r--   0 simon      (501) staff       (20)     4751 2023-03-18 20:31:58.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/outlier.png
+-rw-r--r--   0 simon      (501) staff       (20)     4392 2023-03-20 14:16:15.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/clahe.png
+-rw-rw-r--   0 simon      (501) staff       (20)     4637 2023-03-17 19:03:55.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/trash.png
+-rw-r--r--   0 simon      (501) staff       (20)     1239 2023-03-19 16:51:21.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/about.png
+-rw-rw-r--   0 simon      (501) staff       (20)     4666 2023-03-17 18:01:21.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/convert.png
+-rw-r--r--   0 simon      (501) staff       (20)    93229 2023-03-20 16:01:42.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/SimBA_logo.icns
+-rw-r--r--   0 simon      (501) staff       (20)      991 2023-03-20 19:02:33.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/reorganize.png
+-rw-rw-r--   0 simon      (501) staff       (20)     4784 2023-03-17 18:50:35.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/browse.png
+-rw-r--r--   0 simon      (501) staff       (20)    30707 2023-03-20 16:33:38.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/SimBA_logo.png
+-rw-r--r--   0 simon      (501) staff       (20)     2293 2023-03-17 19:24:38.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/ethovision.png
+-rw-r--r--   0 simon      (501) staff       (20)     1018 2023-04-05 15:24:49.000000 Simba-UW-tf-dev-1.57.6/simba/assets/icons/close.png
+-rw-r--r--   0 simon      (501) staff       (20)    13672 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/dash_simba_base.css
+-rw-r--r--   0 simon      (501) staff       (20)    31812 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/assets/TheGoldenLab.PNG
+-rw-r--r--   0 simon      (501) staff       (20)     9491 2023-04-25 16:28:55.000000 Simba-UW-tf-dev-1.57.6/simba/read_config_unit_tests.py
+-rw-r--r--   0 simon      (501) staff       (20)    11645 2023-04-25 15:16:24.000000 Simba-UW-tf-dev-1.57.6/simba/project_config_creator.py
+-rw-r--r--   0 simon      (501) staff       (20)    19000 2023-04-26 18:08:54.000000 Simba-UW-tf-dev-1.57.6/simba/train_single_model.py
+-rw-r--r--   0 simon      (501) staff       (20)     6321 2023-04-25 15:08:48.000000 Simba-UW-tf-dev-1.57.6/simba/create_clf_log.py
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/simba/batch_process_videos/
+-rw-r--r--   0 simon      (501) staff       (20)     8196 2023-03-17 14:43:38.000000 Simba-UW-tf-dev-1.57.6/simba/batch_process_videos/.DS_Store
+-rw-r--r--   0 simon      (501) staff       (20)    24639 2023-04-25 13:26:59.000000 Simba-UW-tf-dev-1.57.6/simba/batch_process_videos/batch_process_menus.py
+-rw-r--r--   0 simon      (501) staff       (20)        0 2023-03-10 20:04:56.000000 Simba-UW-tf-dev-1.57.6/simba/batch_process_videos/__init__.py
+-rw-r--r--   0 simon      (501) staff       (20)    11106 2023-04-25 13:26:59.000000 Simba-UW-tf-dev-1.57.6/simba/batch_process_videos/batch_process_create_ffmpeg_commands.py
+-rw-r--r--   0 simon      (501) staff       (20)     9520 2023-04-25 19:02:08.000000 Simba-UW-tf-dev-1.57.6/simba/Kleinberg_calculator.py
+-rw-r--r--   0 simon      (501) staff       (20)     8311 2023-04-25 15:16:24.000000 Simba-UW-tf-dev-1.57.6/simba/reorganize_keypoint_in_pose.py
+-rw-r--r--   0 simon      (501) staff       (20)      165 2023-03-25 11:18:21.000000 Simba-UW-tf-dev-1.57.6/simba/~$features.pptx
+-rw-r--r--   0 simon      (501) staff       (20)     6556 2023-04-25 12:27:22.000000 Simba-UW-tf-dev-1.57.6/simba/play_annotation_video.py
+drwxr-xr-x   0 simon      (501) staff       (20)        0 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/Simba_UW_tf_dev.egg-info/
+-rw-rw-r--   0 simon      (501) staff       (20)      579 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/Simba_UW_tf_dev.egg-info/PKG-INFO
+-rw-rw-r--   0 simon      (501) staff       (20)    13977 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/Simba_UW_tf_dev.egg-info/SOURCES.txt
+-rw-rw-r--   0 simon      (501) staff       (20)       44 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/Simba_UW_tf_dev.egg-info/entry_points.txt
+-rw-rw-r--   0 simon      (501) staff       (20)      639 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/Simba_UW_tf_dev.egg-info/requires.txt
+-rw-rw-r--   0 simon      (501) staff       (20)        6 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/Simba_UW_tf_dev.egg-info/top_level.txt
+-rw-rw-r--   0 simon      (501) staff       (20)        1 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/Simba_UW_tf_dev.egg-info/dependency_links.txt
+-rw-rw-r--   0 simon      (501) staff       (20)     7652 2020-05-13 13:27:38.000000 Simba-UW-tf-dev-1.57.6/LICENSE.md
+-rw-rw-r--   0 simon      (501) staff       (20)      136 2021-04-10 10:44:06.000000 Simba-UW-tf-dev-1.57.6/MANIFEST.in
+-rw-rw-r--   0 simon      (501) staff       (20)     9598 2020-05-13 13:27:40.000000 Simba-UW-tf-dev-1.57.6/README.md
+-rw-rw-r--   0 simon      (501) staff       (20)     1897 2023-04-27 18:04:56.000000 Simba-UW-tf-dev-1.57.6/setup.py
+-rw-r--r--   0 simon      (501) staff       (20)       38 2023-04-27 18:05:07.000000 Simba-UW-tf-dev-1.57.6/setup.cfg
```

### Comparing `Simba-UW-tf-dev-1.57.5/PKG-INFO` & `Simba-UW-tf-dev-1.57.6/PKG-INFO`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: Simba-UW-tf-dev
-Version: 1.57.5
+Version: 1.57.6
 Summary: Toolkit for computer classification of complex social behaviors in experimental animals
 Home-page: https://github.com/sgoldenlab/simba
 Author: Simon Nilsson, Jia Jie Choong, Sophia Hwang
 Author-email: sronilsson@gmail.com
 License: GNU Lesser General Public License v3 (LGPLv3)
 Platform: UNKNOWN
 Classifier: Programming Language :: Python :: 3
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/video_processing.py` & `Simba-UW-tf-dev-1.57.6/simba/video_processing.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,41 +1,40 @@
 __author__ = "Simon Nilsson"
 
 import glob, os
-from simba.read_config_unit_tests import (check_file_exist_and_readable,
-                                          check_int, check_if_filepath_list_is_empty)
-import threading
-from simba.misc_tools import (get_fn_ext,
-                              get_video_meta_data,
-                              find_all_videos_in_directory,
-                              find_core_cnt)
-from simba.utils.printing import stdout_success
 import cv2
 from pathlib import Path
 import numpy as np
-from simba.extract_frames_fast import video_to_frames
-from simba.enums import Formats
+import shutil
 import re
 import subprocess
 import simba
 from simba.mixins.config_reader import ConfigReader
 from tkinter import *
 from datetime import datetime
 import time
 from PIL import Image, ImageTk
+import multiprocessing
+
+from simba.utils.checks import (check_file_exist_and_readable, check_int, check_if_filepath_list_is_empty)
+from simba.read_config_unit_tests import read_config_file, read_config_entry
+from simba.utils.read_write import get_fn_ext, get_video_meta_data, find_all_videos_in_directory, find_core_cnt
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.extract_frames_fast import video_to_frames
+from simba.enums import Formats, Paths, ReadConfig
+
 from simba.utils.errors import (NotDirectoryError,
                                 NoFilesFoundError,
                                 FileExistError,
                                 CountError,
-                                InvalidInputError)
+                                InvalidInputError,
+                                DirectoryExistError)
 from simba.utils.warnings import (SameInputAndOutputWarning,
                                   FileExistWarning)
-from concurrent.futures import ProcessPoolExecutor
-import multiprocessing
-import functools
+
 
 MAX_FRM_SIZE = 1080, 650
 
 def change_img_format(directory: str,
                       file_type_in: str,
                       file_type_out: str):
     """
@@ -711,42 +710,19 @@
     else:
         command = 'ffmpeg -y -i "{}" -i "{}" -filter_complex "[0:v]scale={}:-1[v0];[v0][1:v]vstack=inputs=2" "{}"'.format(video_one_path, video_two_path, video_meta_data['width'], save_path)
     subprocess.call(command, shell=True, stdout=subprocess.PIPE)
     stdout_success(msg=f'Videos concatenated and saved at {save_path}')
 
 
 
-
-def _rotate_video(data: list,
-                  video_meta_info: dict,
-                  input_path: str,
-                  save_path: str,
-                  rotation_matrix: np.array):
-
-
-    cap = cv2.VideoCapture(input_path)
-
-    img_cnt = 0
-    while True:
-        ret, img = cap.read()
-        if not ret:
-            break
-        img = cv2.warpAffine(img, rotation_matrix, (video_meta_info['width'], video_meta_info['height']))
-        print(img)
-        writer.write(img)
-        img_cnt+=1
-        print(f'Rotating frame {img_cnt}/{video_meta_info["frame_count"]}')
-    cap.release()
-    writer.release()
-
-
 class VideoRotator(ConfigReader):
     def __init__(self,
                  input_path: str,
                  output_dir: str):
+
         _, self.cpu_cnt  = find_core_cnt()
         self.save_dir = output_dir
         self.datetime = datetime.now().strftime('%Y%m%d%H%M%S')
         if os.path.isfile(input_path):
             self.video_paths = [input_path]
         else:
             self.video_paths = find_all_videos_in_directory(directory=input_path, as_dict=True).values()
@@ -836,14 +812,87 @@
     def run(self):
         self.results = {}
         for video_path in self.video_paths:
             self.__run_interface(video_path)
         self.main_frm.mainloop()
 
 
+def extract_frames_from_all_videos_in_directory(config_path: str,
+                                                directory: str) -> None:
+
+    """
+    Helper to extract all frames from all videos in a directory. The results are saved in the project_folder/frames/input
+    directory of the SimBa project
+
+    Parameters
+    ----------
+    config_path: str
+        path to SimBA project config file in Configparser format
+    directory: str
+        path to file or folder containing videos in mp4 and/or avi format
+
+    :return
+    ----------
+    list
+
+    Examples
+    ----------
+    >>> extract_frames_from_all_videos_in_directory(config_path='project_folder/project_config.ini', source='/tests/test_data/video_tests')
+    """
+
+    timer = SimbaTimer()
+    timer.start_timer()
+    video_paths, video_types = [], ['.avi', '.mp4']
+    files_in_folder = glob.glob(directory + '/*')
+    for file_path in files_in_folder:
+        _, _, ext = get_fn_ext(filepath=file_path)
+        if ext.lower() in video_types:
+            video_paths.append(file_path)
+    if len(video_paths) == 0:
+        raise NoFilesFoundError(msg='SIMBA ERROR: 0 video files in mp4 or avi format found in {}'.format(directory))
+    config = read_config_file(config_path)
+    project_path = read_config_entry(config, 'General settings', 'project_path', data_type='folder_path')
+
+    print('Extracting frames for {} videos into project_folder/frames/input directory...'.format(len(video_paths)))
+    for video_path in video_paths:
+        dir_name, video_name, ext = get_fn_ext(video_path)
+        save_path = os.path.join(project_path, 'frames', 'input', video_name)
+        if not os.path.exists(save_path): os.makedirs(save_path)
+        else: print(f'Frames for video {video_name} already extracted. SimBA is overwriting prior frames...')
+        video_to_frames(video_path, save_path, overwrite=True, every=1, chunk_size=1000)
+    timer.stop_timer()
+    stdout_success(f'Frames created for {str(len(video_paths))} videos', elapsed_time=timer.elapsed_time_str)
+
+
+def copy_img_folder(config_path: str, source: str) -> None:
+    """
+    Copy directory of png files to the SimBA project. The directory is stored in the project_folder/frames/input
+    folder of the SimBA project.
+    """
+    timer = SimbaTimer()
+    timer.start_timer()
+    if not os.path.isdir(source):
+        raise NotDirectoryError(msg=f'SIMBA ERROR: source {source} is not a directory.')
+    if len(glob.glob(source + '/*.png')) == 0:
+        raise NoFilesFoundError(msg=f'SIMBA ERROR: source {source} does not contain any .png files.')
+    input_basename = os.path.basename(source)
+    config = read_config_file(config_path)
+    project_path = read_config_entry(config, ReadConfig.GENERAL_SETTINGS.value, ReadConfig.PROJECT_PATH.value, data_type='folder_path')
+    input_frames_dir = os.path.join(project_path, Paths.INPUT_FRAMES_DIR.value)
+    destination = os.path.join(input_frames_dir, input_basename)
+    if os.path.isdir(destination):
+        raise DirectoryExistError(msg=f'SIMBA ERROR: {destination} already exist in SimBA project.')
+    print(f'Importing image files for {input_basename}...')
+    shutil.copytree(source, destination)
+    timer.stop_timer()
+    stdout_success(msg=f'{destination} imported to SimBA project', elapsed_time=timer.elapsed_time_str)
+
+
+
+
 
 # r = VideoRotator(input_path=r'/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/videos/Testing/Together_1_downsampled.mp4',
 #              output_dir='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/videos/Blah')
 # r.run()
 
 
 # video_concatenator(video_one_path='/Users/simon/Desktop/troubleshooting/Open_field_5/project_folder/frames/output/gantt_plots/SI_DAY3_308_CD1_PRESENT_2.mp4',
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/blob_storage/.DS_Store` & `Simba-UW-tf-dev-1.57.6/simba/blob_storage/.DS_Store`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/unsupervised/dbcv_calculator.py` & `Simba-UW-tf-dev-1.57.6/simba/unsupervised/dbcv_calculator.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 import os.path
 import pandas as pd
-from simba.train_model_functions import check_if_dir_exists
-from simba.misc_tools import SimbaTimer, check_file_exist_and_readable
 import numpy as np
 from numba import jit, prange
 from numba.typed import List
 from scipy.sparse.csgraph import minimum_spanning_tree
 from scipy.sparse import csgraph
 from simba.unsupervised.enums import Unsupervised, Clustering
 from simba.mixins.unsupervised_mixin import UnsupervisedMixin
 from simba.mixins.config_reader import ConfigReader
-from simba.utils.printing import stdout_success, stdout_warning
+from simba.utils.printing import stdout_success, stdout_warning, SimbaTimer
+from simba.utils.checks import check_if_dir_exists, check_file_exist_and_readable
+
 
 
 CLUSTERER_NAME = 'CLUSTERER_NAME'
 CLUSTER_COUNT = 'CLUSTER_COUNT'
 EMBEDDER_NAME = 'EMBEDDER_NAME'
 DBCV = 'DBCV'
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/unsupervised/unsupervised_ui.py` & `Simba-UW-tf-dev-1.57.6/simba/unsupervised/ui.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,158 +1,136 @@
-from simba.read_config_unit_tests import (read_config_entry,
-                                          read_config_file,
-                                          read_project_path_and_file_type)
 from tkinter import *
 from simba.tkinter_functions import (hxtScrollbar,
                                      Entry_Box,
                                      DropDownMenu,
                                      FileSelect)
-from PIL import ImageTk
-import PIL.Image
-import os
-from simba.utils.lookups import get_icons_paths
 import tkinter.ttk as ttk
 from simba.enums import Formats
 from simba.mixins.config_reader import ConfigReader
-from simba.enums import ReadConfig, Dtypes
-from simba.train_model_functions import get_all_clf_names
+from simba.mixins.pop_up_mixin import PopUpMixin
+from simba.unsupervised.enums import UnsupervisedOptions, Unsupervised
 from simba.unsupervised.dataset_creator import DatasetCreator
-from simba.unsupervised.pop_up_classes import (GridSearchClusterVisualizerPopUp,
-                                               BatchDataExtractorPopUp,
+from simba.unsupervised.pop_up_classes import (GridSearchVisualizerPopUp,
+                                               DataExtractorPopUp,
                                                FitDimReductionPopUp,
                                                FitClusterModelsPopUp,
                                                TransformDimReductionPopUp,
                                                TransformClustererPopUp,
                                                ClusterVisualizerPopUp,
                                                ClusterFrequentistStatisticsPopUp,
-                                               ClusterMLStatisticsPopUp,
+                                               ClusterXAIPopUp,
                                                EmbedderCorrelationsPopUp,
                                                PrintEmBeddingInfoPopUp,
                                                DBCVPopUp)
 
-class UnsupervisedGUI(ConfigReader):
+class UnsupervisedGUI(ConfigReader, PopUpMixin):
     def __init__(self,
                  config_path: str):
 
-        super().__init__(config_path=config_path)
-
-        self.config, self.config_path = read_config_file(config_path), config_path
-        self.project_path, self.file_type = read_project_path_and_file_type(config=self.config)
-        self.main = Toplevel()
-        self.main.minsize(1000, 800)
-        self.main.wm_title("UNSUPERVISED ANALYSIS")
-        self.main.columnconfigure(0, weight=1)
-        self.main.rowconfigure(0, weight=1)
-        self.model_cnt = read_config_entry(self.config, ReadConfig.SML_SETTINGS.value, ReadConfig.TARGET_CNT.value, data_type=Dtypes.INT.value)
-        self.clf_names = get_all_clf_names(config=self.config, target_cnt=self.model_cnt)
-        self.data_slice_options = ['ALL FEATURES (EXCLUDING POSE)',
-                                   'ALL FEATURES (INCLUDING POSE)',
-                                   'USER-DEFINED FEATURE SET']
-
-        self.clf_slice_options = [f'ALL CLASSIFIERS ({str(len(self.clf_names))})']
-        for clf_name in self.clf_names:
-            self.clf_slice_options.append(f'{clf_name}')
-        self.btn_icons = get_icons_paths()
-        for k in self.btn_icons.keys():
-            self.btn_icons[k]['img'] = ImageTk.PhotoImage(image=PIL.Image.open(os.path.join(os.path.dirname('__file__'), self.btn_icons[k]['icon_path'])))
-
-        self.bout_aggregation_options = ['MEAN', 'MEDIAN']
-        self.main = ttk.Notebook(hxtScrollbar(self.main))
-        self.create_dataset_tab = ttk.Frame(self.main)
-        self.dimensionality_reduction_tab = ttk.Frame(self.main)
-        self.clustering_tab = ttk.Frame(self.main)
-        self.visualization_tab = ttk.Frame(self.main)
-        self.metrics_tab = ttk.Frame(self.main)
-        self.main.add(self.create_dataset_tab, text=f'{"[CREATE DATASET]": ^20s}', compound='left', image=self.btn_icons['features']['img'])
-        self.main.add(self.dimensionality_reduction_tab, text=f'{"[DIMENSIONALITY REDUCTION]": ^20s}', compound='left', image=self.btn_icons['dimensionality_reduction']['img'])
-        self.main.add(self.clustering_tab, text=f'{"[CLUSTERING]": ^20s}', compound='left', image=self.btn_icons['cluster']['img'])
-        self.main.add(self.visualization_tab, text=f'{"[VISUALIZATION]": ^20s}', compound='left', image=self.btn_icons['visualize']['img'])
-        self.main.add(self.metrics_tab, text=f'{"[METRICS]": ^20s}', compound='left', image=self.btn_icons['metrics']['img'])
-        self.main.grid(row=0)
+        ConfigReader.__init__(self, config_path=config_path)
+        PopUpMixin.__init__(self, title="UNSUPERVISED ANALYSIS", config_path=config_path, size=(1000, 800))
+        self.main_frm = Toplevel()
+        self.main_frm.minsize(1000, 800)
+        self.main_frm.wm_title("UNSUPERVISED ANALYSIS")
+        self.main_frm.columnconfigure(0, weight=1)
+        self.main_frm.rowconfigure(0, weight=1)
+        self.main_frm = ttk.Notebook(hxtScrollbar(self.main_frm))
+        self.create_dataset_tab = ttk.Frame(self.main_frm)
+        self.dimensionality_reduction_tab = ttk.Frame(self.main_frm)
+        self.clustering_tab = ttk.Frame(self.main_frm)
+        self.visualization_tab = ttk.Frame(self.main_frm)
+        self.metrics_tab = ttk.Frame(self.main_frm)
+
+        self.main_frm.add(self.create_dataset_tab, text=f'{"[CREATE DATASET]": ^20s}', compound='left', image=self.menu_icons['features']['img'])
+        self.main_frm.add(self.dimensionality_reduction_tab, text=f'{"[DIMENSIONALITY REDUCTION]": ^20s}', compound='left', image=self.menu_icons['dimensionality_reduction']['img'])
+        self.main_frm.add(self.clustering_tab, text=f'{"[CLUSTERING]": ^20s}', compound='left', image=self.menu_icons['cluster']['img'])
+        self.main_frm.add(self.visualization_tab, text=f'{"[VISUALIZATION]": ^20s}', compound='left', image=self.menu_icons['visualize']['img'])
+        self.main_frm.add(self.metrics_tab, text=f'{"[METRICS]": ^20s}', compound='left', image=self.menu_icons['metrics']['img'])
+        self.main_frm.grid(row=0)
 
+        self.clf_slice_options = [f'ALL CLASSIFIERS ({len(self.clf_names)})']
+        for clf_name in self.clf_names: self.clf_slice_options.append(f'{clf_name}')
         create_dataset_frm = LabelFrame(self.create_dataset_tab, text='CREATE DATASET', pady=5, padx=5,font=Formats.LABELFRAME_HEADER_FORMAT.value,fg='black')
         self.feature_file_selected = FileSelect(create_dataset_frm, "FEATURE FILE (CSV)", lblwidth=25)
 
-        self.data_slice_dropdown = DropDownMenu(create_dataset_frm, 'FEATURE SLICE:', self.data_slice_options, '25', com= lambda x: self.change_status_of_file_select())
-        self.data_slice_dropdown.setChoices(self.data_slice_options[0])
+        self.data_slice_dropdown = DropDownMenu(create_dataset_frm, 'FEATURE SLICE:', UnsupervisedOptions.FEATURE_SLICE_OPTIONS.value, '25', com= lambda x: self.change_status_of_file_select())
+        self.data_slice_dropdown.setChoices(UnsupervisedOptions.FEATURE_SLICE_OPTIONS.value[0])
         self.clf_slice_dropdown = DropDownMenu(create_dataset_frm, 'CLASSIFIER SLICE:', self.clf_slice_options, '25')
         self.clf_slice_dropdown.setChoices(self.clf_slice_options[0])
         self.change_status_of_file_select()
-        self.bout_dropdown = DropDownMenu(create_dataset_frm, 'BOUT AGGREGATION:', self.bout_aggregation_options, '25')
-        self.bout_dropdown.setChoices(choice='MEAN')
+        self.bout_dropdown = DropDownMenu(create_dataset_frm, 'BOUT AGGREGATION METHOD:', UnsupervisedOptions.BOUT_AGGREGATION_METHODS.value, '25')
+        self.bout_dropdown.setChoices(choice=UnsupervisedOptions.BOUT_AGGREGATION_METHODS.value[0])
         self.min_bout_length = Entry_Box(create_dataset_frm, 'MINIMUM BOUT LENGTH (MS): ', '25', validation='numeric')
         self.min_bout_length.entry_set(val=0)
         self.create_btn = Button(create_dataset_frm, text='CREATE DATASET', fg='blue', command= lambda: self.create_dataset())
 
         create_dataset_frm.grid(row=0, column=0, sticky=NW)
         self.data_slice_dropdown.grid(row=0, column=0, sticky=NW)
         self.clf_slice_dropdown.grid(row=1, column=0, sticky=NW)
         self.bout_dropdown.grid(row=2, column=0, sticky=NW)
         self.feature_file_selected.grid(row=3, column=0, sticky=NW)
         self.min_bout_length.grid(row=4, column=0, sticky=NW)
         self.create_btn.grid(row=5, column=0, sticky=NW)
 
         self.dim_reduction_frm = LabelFrame(self.dimensionality_reduction_tab, text='DIMENSIONALITY REDUCTION', pady=5, padx=5,font=Formats.LABELFRAME_HEADER_FORMAT.value,fg='black')
-        self.dim_reduction_fit_btn = Button(self.dim_reduction_frm, text='DIMENSIONALITY REDUCTION MODELS: FIT', fg='blue', command= lambda: FitDimReductionPopUp())
-        self.dim_reduction_transform_btn = Button(self.dim_reduction_frm, text='DIMENSIONALITY REDUCTION MODELS: TRANSFORM', fg='red', command= lambda: TransformDimReductionPopUp())
-
+        self.dim_reduction_fit_btn = Button(self.dim_reduction_frm, text='DIMENSIONALITY REDUCTION: FIT', fg='blue', command= lambda: FitDimReductionPopUp())
+        self.dim_reduction_transform_btn = Button(self.dim_reduction_frm, text='DIMENSIONALITY REDUCTION: TRANSFORM', fg='red', command= lambda: TransformDimReductionPopUp())
         self.dim_reduction_frm.grid(row=0, column=0, sticky=NW)
         self.dim_reduction_fit_btn.grid(row=1, column=0, sticky=NW)
         self.dim_reduction_transform_btn.grid(row=2, column=0, sticky=NW)
 
         self.clustering_frm = LabelFrame(self.clustering_tab, text='CLUSTERING', pady=5, padx=5,font=Formats.LABELFRAME_HEADER_FORMAT.value,fg='black')
-        self.cluster_fit_btn = Button(self.clustering_frm, text='CLUSTERING MODELS: FIT ', fg='blue', command= lambda: FitClusterModelsPopUp())
-        self.cluster_transform_btn = Button(self.clustering_frm, text='CLUSTERING MODELS: TRANSFORM ', fg='red', command=lambda: TransformClustererPopUp())
+        self.cluster_fit_btn = Button(self.clustering_frm, text='CLUSTERING: FIT ', fg='blue', command= lambda: FitClusterModelsPopUp())
+        self.cluster_transform_btn = Button(self.clustering_frm, text='CLUSTERING: TRANSFORM ', fg='red', command=lambda: TransformClustererPopUp())
         self.clustering_frm.grid(row=0, column=0, sticky=NW)
         self.cluster_fit_btn.grid(row=1, column=0, sticky=NW)
         self.cluster_transform_btn.grid(row=2, column=0, sticky=NW)
 
         self.visualization_frm = LabelFrame(self.visualization_tab, text='VISUALIZATIONS', pady=5, padx=5, font=Formats.LABELFRAME_HEADER_FORMAT.value, fg='black')
-        self.grid_search_visualization_btn = Button(self.visualization_frm, text='GRID-SEARCH VISUALIZATION', fg='blue', command= lambda: self.launch_grid_search_visualization_pop_up())
-        self.cluster_visualizer = Button(self.visualization_frm, text='CLUSTER VISUALIZER', fg='red', command= lambda: ClusterVisualizerPopUp(config_path=self.config_path))
+        self.grid_search_visualization_btn = Button(self.visualization_frm, text='GRID-SEARCH VISUALIZATION', fg='blue', command= lambda: GridSearchVisualizerPopUp(config_path=self.config_path))
+        self.cluster_visualizer = Button(self.visualization_frm, text='DATA VISUALIZERS', fg='red', command= lambda: ClusterVisualizerPopUp(config_path=self.config_path))
         self.visualization_frm.grid(row=0, column=0, sticky='NW')
         self.grid_search_visualization_btn.grid(row=0, column=0, sticky='NW')
         self.cluster_visualizer.grid(row=1, column=0, sticky='NW')
 
         self.metrics_frm = LabelFrame(self.metrics_tab, text='METRICS', pady=5, padx=5, font=Formats.LABELFRAME_HEADER_FORMAT.value, fg='black')
         self.dbcv_btn = Button(self.metrics_frm, text='DENSITY-BASED CLUSTER VALIDATION', fg='blue', command=lambda: DBCVPopUp(config_path=self.config_path))
-        self.extract_single_metrics_btn = Button(self.metrics_frm, text='EXTRACT UNSUPERVISED RESULTS (MULTIPLE MODELS)', fg='red', command=lambda: BatchDataExtractorPopUp())
+        self.extract_single_metrics_btn = Button(self.metrics_frm, text='EXTRACT DATA', fg='red', command=lambda: DataExtractorPopUp(config_path=self.config_path))
         self.cluster_descriptives_btn = Button(self.metrics_frm, text='CLUSTER FREQUENTIST STATISTICS', fg='green', command=lambda: ClusterFrequentistStatisticsPopUp(config_path=self.config_path))
-        self.cluster_xai_btn = Button(self.metrics_frm, text='CLUSTER XAI STATISTICS', fg='blue', command=lambda: ClusterMLStatisticsPopUp(config_path=self.config_path))
+        self.cluster_xai_btn = Button(self.metrics_frm, text='CLUSTER XAI STATISTICS', fg='blue', command=lambda: ClusterXAIPopUp(config_path=self.config_path))
         self.embedding_corr_btn = Button(self.metrics_frm, text='EMBEDDING CORRELATIONS', fg='orange', command=lambda: EmbedderCorrelationsPopUp(config_path=self.config_path))
         self.print_embedding_info_btn = Button(self.metrics_frm, text='PRINT MODEL INFO', fg='black', command=lambda: PrintEmBeddingInfoPopUp(config_path=self.config_path))
 
         self.metrics_frm.grid(row=0, column=0, sticky='NW')
         self.dbcv_btn.grid(row=0, column=0, sticky='NW')
         self.extract_single_metrics_btn.grid(row=1, column=0, sticky='NW')
         self.cluster_descriptives_btn.grid(row=2, column=0, sticky='NW')
         self.cluster_xai_btn.grid(row=3, column=0, sticky='NW')
         self.embedding_corr_btn.grid(row=4, column=0, sticky='NW')
         self.print_embedding_info_btn.grid(row=5, column=0, sticky='NW')
 
-        self.main.mainloop()
+        self.main_frm.mainloop()
 
     def change_status_of_file_select(self):
         if self.data_slice_dropdown.getChoices() == 'USER-DEFINED FEATURE SET':
             self.feature_file_selected.set_state(setstatus=NORMAL)
         else:
             self.feature_file_selected.set_state(setstatus=DISABLED)
 
     def create_dataset(self):
         data_slice_type = self.data_slice_dropdown.getChoices()
         classifier_slice_type = self.clf_slice_dropdown.getChoices()
         bout_selection = self.bout_dropdown.getChoices()
         bout_length = self.min_bout_length.entry_get
         feature_file_path = None
-        if data_slice_type is 'USER-DEFINED FEATURE SET':
+        if data_slice_type is Unsupervised.USER_DEFINED_SET.value:
             feature_file_path = self.feature_file_selected.file_path
+
         settings = {'data_slice': data_slice_type,
                     'clf_slice': classifier_slice_type,
-                    'bout_aggregation': bout_selection,
+                    'bout_aggregation_type': bout_selection,
                     'min_bout_length': bout_length,
-                    'feature_path': feature_file_path}
+                    'feature_file_path': feature_file_path}
         _ = DatasetCreator(settings=settings, config_path=self.config_path)
 
-    def launch_grid_search_visualization_pop_up(self):
-        _ = GridSearchClusterVisualizerPopUp(config_path=self.config_path)
 
-# _ = UnsupervisedGUI(config_path='/Users/simon/Desktop/envs/troubleshooting/Nastacia_unsupervised/project_folder/project_config.ini')
+_ = UnsupervisedGUI(config_path='/Users/simon/Desktop/envs/troubleshooting/unsupervised/project_folder/project_config.ini')
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/unsupervised/enums.py` & `Simba-UW-tf-dev-1.57.6/simba/unsupervised/enums.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/unsupervised/.DS_Store` & `Simba-UW-tf-dev-1.57.6/simba/unsupervised/.DS_Store`

 * *Files 18% similar despite different names*

```diff
@@ -1,37 +1,37 @@
 00000000: 0000 0001 4275 6431 0000 1000 0000 0800  ....Bud1........
 00000010: 0000 1000 0000 0108 0000 0000 0000 0000  ................
 00000020: 0000 0000 0000 0000 0000 0000 0000 0800  ................
 00000030: 0000 0800 0000 0000 0000 0000 0000 0000  ................
-00000040: 0000 0000 0000 0002 0000 0000 0000 0004  ................
+00000040: 0000 0000 0000 0002 0000 0000 0000 0005  ................
 00000050: 0000 0001 0000 1000 0063 0061 0063 0068  .........c.a.c.h
 00000060: 0065 005f 0000 0000 0000 0000 0000 0000  .e._............
 00000070: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00000080: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00000090: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 000000a0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 000000b0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 000000c0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 000000d0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 000000e0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 000000f0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
-00000100: 0000 0000 0000 0000 0000 0004 0000 000b  ................
+00000100: 0000 0000 0000 0000 0000 0005 0000 000b  ................
 00000110: 005f 005f 0070 0079 0063 0061 0063 0068  ._._.p.y.c.a.c.h
-00000120: 0065 005f 005f 6c67 3153 636f 6d70 0000  .e._._lg1Scomp..
-00000130: 0000 0003 855e 0000 000b 005f 005f 0070  .....^....._._.p
-00000140: 0079 0063 0061 0063 0068 0065 005f 005f  .y.c.a.c.h.e._._
-00000150: 6d6f 4444 626c 6f62 0000 0008 4d55 fc8e  moDDblob....MU..
-00000160: bbf8 c441 0000 000b 005f 005f 0070 0079  ...A....._._.p.y
-00000170: 0063 0061 0063 0068 0065 005f 005f 6d6f  .c.a.c.h.e._._mo
-00000180: 6444 626c 6f62 0000 0008 4d55 fc8e bbf8  dDblob....MU....
-00000190: c441 0000 000b 005f 005f 0070 0079 0063  .A....._._.p.y.c
-000001a0: 0061 0063 0068 0065 005f 005f 7068 3153  .a.c.h.e._._ph1S
-000001b0: 636f 6d70 0000 0000 0004 a000 0000 0000  comp............
-000001c0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
-000001d0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
+00000120: 0065 005f 005f 6473 636c 626f 6f6c 0100  .e._._dsclbool..
+00000130: 0000 0b00 5f00 5f00 7000 7900 6300 6100  ...._._.p.y.c.a.
+00000140: 6300 6800 6500 5f00 5f6c 6731 5363 6f6d  c.h.e._._lg1Scom
+00000150: 7000 0000 0000 0384 b200 0000 0b00 5f00  p............._.
+00000160: 5f00 7000 7900 6300 6100 6300 6800 6500  _.p.y.c.a.c.h.e.
+00000170: 5f00 5f6d 6f44 4462 6c6f 6200 0000 08f2  _._moDDblob.....
+00000180: 30a5 26c4 f8c4 4100 0000 0b00 5f00 5f00  0.&...A....._._.
+00000190: 7000 7900 6300 6100 6300 6800 6500 5f00  p.y.c.a.c.h.e._.
+000001a0: 5f6d 6f64 4462 6c6f 6200 0000 08f2 30a5  _modDblob.....0.
+000001b0: 26c4 f8c4 4100 0000 0b00 5f00 5f00 7000  &...A....._._.p.
+000001c0: 7900 6300 6100 6300 6800 6500 5f00 5f70  y.c.a.c.h.e._._p
+000001d0: 6831 5363 6f6d 7000 0000 0000 0490 0000  h1Scomp.........
 000001e0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 000001f0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00000200: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00000210: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00000220: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00000230: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00000240: 0000 0000 0000 0000 0000 0000 0000 0000  ................
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/unsupervised/dataset_creator.py` & `Simba-UW-tf-dev-1.57.6/simba/unsupervised/dataset_creator.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,24 +1,18 @@
 import os
 import pandas as pd
 import numpy as np
-from simba.read_config_unit_tests import (check_if_filepath_list_is_empty,
-                                          check_file_exist_and_readable)
 from simba.unsupervised.bout_aggregator import bout_aggregator
-from simba.misc_tools import get_fn_ext
 from simba.unsupervised.enums import Unsupervised
 from simba.mixins.config_reader import ConfigReader
 from simba.mixins.unsupervised_mixin import UnsupervisedMixin
-from simba.drop_bp_cords import getBpNames
-from simba.rw_dfs import read_df
+from simba.utils.read_write import read_df, get_fn_ext
+from simba.utils.checks import check_if_filepath_list_is_empty, check_file_exist_and_readable
 from simba.utils.errors import NoDataError
 from simba.utils.printing import stdout_success
-import pickle
-import sys
-
 
 class DatasetCreator(ConfigReader, UnsupervisedMixin):
     def __init__(self,
                  config_path: str,
                  settings: dict):
 
         print('Creating unsupervised learning dataset...')
@@ -27,15 +21,15 @@
         check_if_filepath_list_is_empty(filepaths=self.machine_results_paths, error_msg='NO MACHINE LEARNING DATA FOUND')
         self.settings = settings
         self.clf_type, self.feature_lst = None, None
         self.save_path = os.path.join(self.logs_path, 'unsupervised_data_{}.pickle'.format(self.datetime))
         self.log_save_path = os.path.join(self.logs_path, 'unsupervised_data_log_{}.csv'.format(self.datetime))
         self.clf_probability_cols = ['Probability_' + x for x in self.clf_names]
         self.clf_cols = self.clf_names + self.clf_probability_cols
-        self.bp_names = list(getBpNames(inifile=self.config_path))
+        self.bp_names = self.get_body_part_names()
         self.bp_names = [item for sublist in self.bp_names for item in sublist]
         if settings[Unsupervised.DATA_SLICE_SELECTION.value] == Unsupervised.ALL_FEATURES_EX_POSE.value:
             self.data_concatenator(drop_bps=True, user_defined=False)
         elif settings[Unsupervised.DATA_SLICE_SELECTION.value] == Unsupervised.USER_DEFINED_SET.value:
             check_file_exist_and_readable(self.settings[Unsupervised.FEATURE_PATH.value])
             self.feature_lst = list(pd.read_csv(self.settings[Unsupervised.FEATURE_PATH.value], header=None)[0])
             self.data_concatenator(drop_bps=False, user_defined=True)
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/unsupervised/grid_search_visualizers.py` & `Simba-UW-tf-dev-1.57.6/simba/unsupervised/grid_search_visualizers.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,17 +1,16 @@
 import numpy as np
-from simba.train_model_functions import check_if_dir_exists
 import glob, os
 import pandas as pd
-from simba.misc_tools import check_if_filepath_list_is_empty
-from simba.unsupervised.enums import Clustering, Unsupervised
-from simba.mixins.unsupervised_mixin import UnsupervisedMixin
 import seaborn as sns
 import matplotlib.pyplot as plt
+from simba.unsupervised.enums import Clustering, Unsupervised
+from simba.mixins.unsupervised_mixin import UnsupervisedMixin
 from simba.utils.printing import stdout_success
+from simba.utils.checks import check_if_dir_exists, check_if_filepath_list_is_empty
 
 
 class GridSearchVisualizer(UnsupervisedMixin):
     def __init__(self,
                  model_dir: str,
                  save_dir: str,
                  settings: dict):
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/unsupervised/data_extractor.py` & `Simba-UW-tf-dev-1.57.6/simba/unsupervised/data_extractor.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,18 +1,16 @@
 import os
-
+import json
 import pandas as pd
-
 from simba.mixins.unsupervised_mixin import UnsupervisedMixin
 from simba.mixins.config_reader import ConfigReader
 from simba.unsupervised.enums import Unsupervised, Clustering
-from simba.train_model_functions import check_if_dir_exists
+from simba.utils.checks import check_if_dir_exists, check_file_exist_and_readable
 from simba.utils.printing import stdout_success
-from simba.misc_tools import check_file_exist_and_readable
-import json
+
 
 CLUSTERER_PARAMETERS = 'CLUSTERER HYPER-PARAMETERS'
 DIMENSIONALITY_REDUCTION_PARAMETERS = 'DIMENSIONALITY REDUCTION HYPER-PARAMETERS'
 SCALER = 'SCALER'
 SCALED_DATA = 'SCALED DATA'
 LOW_VARIANCE_FIELDS = 'LOW VARIANCE FIELDS'
 FEATURE_NAMES = 'FEATURE_NAMES'
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/unsupervised/umap_embedder.py` & `Simba-UW-tf-dev-1.57.6/simba/unsupervised/umap_embedder.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 import os
 import random
 from copy import deepcopy
-from simba.misc_tools import SimbaTimer
-from simba.read_config_unit_tests import check_file_exist_and_readable
 from simba.mixins.unsupervised_mixin import UnsupervisedMixin
 from simba.unsupervised.enums import Unsupervised
-from simba.utils.printing import stdout_success
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.utils.checks import check_file_exist_and_readable
 
 import itertools
 import pandas as pd
 
 
 try:
     from cuml import UMAP
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/unsupervised/pop_up_classes.py` & `Simba-UW-tf-dev-1.57.6/simba/unsupervised/pop_up_classes.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,22 +1,25 @@
-import os, glob
-from simba.mixins.pop_up_mixin import PopUpMixin
-from simba.mixins.config_reader import ConfigReader
-from simba.mixins.unsupervised_mixin import UnsupervisedMixin
+import glob
 from tkinter import *
-from simba.enums import Formats, Options
-from simba.misc_tools import check_file_exist_and_readable, check_if_filepath_list_is_empty
-from simba.unsupervised.enums import UnsupervisedOptions, Unsupervised, Clustering
 import numpy as np
+
 from simba.tkinter_functions import (FolderSelect,
                                      DropDownMenu,
                                      FileSelect,
                                      Entry_Box)
-from simba.train_model_functions import check_if_dir_exists
-from simba.read_config_unit_tests import check_int
+
+from simba.mixins.pop_up_mixin import PopUpMixin
+from simba.mixins.config_reader import ConfigReader
+from simba.mixins.unsupervised_mixin import UnsupervisedMixin
+
+from simba.enums import Formats, Options
+from simba.unsupervised.enums import UnsupervisedOptions, Unsupervised, Clustering
+from simba.utils.checks import check_file_exist_and_readable, check_if_filepath_list_is_empty, check_if_dir_exists, check_int
+
+
 from simba.unsupervised.grid_search_visualizers import GridSearchVisualizer
 from simba.unsupervised.data_extractor import DataExtractor
 from simba.utils.errors import NoSpecifiedOutputError
 from simba.unsupervised.umap_embedder import UmapEmbedder
 from simba.unsupervised.tsne import TSNEGridSearch
 from simba.unsupervised.hdbscan_clusterer import HDBSCANClusterer
 from simba.unsupervised.cluster_visualizer import ClusterVisualizer
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/unsupervised/bout_aggregator.py` & `Simba-UW-tf-dev-1.57.6/simba/unsupervised/bout_aggregator.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,13 +1,12 @@
 import pandas as pd
 from joblib.externals.loky import get_reusable_executor
 from joblib import Parallel, delayed
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.misc_tools import detect_bouts
-
+from simba.utils.read_write import read_video_info
+from simba.utils.data import detect_bouts
 
 def bout_aggregator(data: pd.DataFrame,
                     clfs: list,
                     feature_names: list,
                     aggregator: str,
                     min_bout_length: int,
                     video_info: pd.DataFrame):
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/unsupervised/cluster_statistics.py` & `Simba-UW-tf-dev-1.57.6/simba/unsupervised/cluster_statistics.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,28 +1,28 @@
-from simba.mixins.config_reader import ConfigReader
-from simba.mixins.unsupervised_mixin import UnsupervisedMixin
 import os
 import numpy as np
 import pandas as pd
 from copy import deepcopy
-from simba.unsupervised.enums import Clustering, Unsupervised
-from simba.enums import Methods
-from simba.utils.printing import stdout_success
-from simba.misc_tools import (check_file_exist_and_readable,
-                              SimbaTimer)
 from scipy.stats import f_oneway
 import shap
 from statsmodels.stats.multicomp import pairwise_tukeyhsd
 from statsmodels.stats.libqsturng import psturng
 from sklearn.ensemble import RandomForestClassifier
 from sklearn.inspection import permutation_importance
 import seaborn as sns
 import matplotlib.pyplot as plt
 import itertools
 
+from simba.unsupervised.enums import Clustering, Unsupervised
+from simba.enums import Methods
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.mixins.config_reader import ConfigReader
+from simba.mixins.unsupervised_mixin import UnsupervisedMixin
+from simba.utils.checks import check_file_exist_and_readable
+
 FEATURE_NAME = 'FEATURE NAME'
 FEATURE_IMPORTANCE = 'IMPORTANCE'
 F_STATISTIC = 'F-STATISTIC'
 MEASURE = 'MEASURE'
 P_VALUE = 'P-VALUE'
 CLUSTER = 'CLUSTER'
 PAIRED = 'cluster_paired'
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/unsupervised/data_map.yaml` & `Simba-UW-tf-dev-1.57.6/simba/unsupervised/data_map.yaml`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/unsupervised/hdbscan_clusterer.py` & `Simba-UW-tf-dev-1.57.6/simba/unsupervised/hdbscan_clusterer.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,26 +1,24 @@
-from simba.read_config_unit_tests import (check_if_filepath_list_is_empty,
-                                          check_file_exist_and_readable)
-from simba.misc_tools import SimbaTimer
-from simba.train_model_functions import check_if_dir_exists
-from simba.unsupervised.enums import Clustering, Unsupervised
-import itertools
-import os, glob
-import random
-import pandas as pd
-from simba.utils.printing import stdout_success
-from simba.mixins.unsupervised_mixin import UnsupervisedMixin
-from simba.unsupervised.umap_embedder import UmapEmbedder
 try:
     from cuml.cluster.hdbscan import HDBSCAN
     from cuml.cluster import hdbscan
     gpu_flag = True
 except ModuleNotFoundError:
     from hdbscan import HDBSCAN
     import hdbscan
+import itertools
+import os, glob
+import random
+import pandas as pd
+from simba.utils.checks import check_if_dir_exists, check_file_exist_and_readable, check_if_filepath_list_is_empty
+from simba.unsupervised.enums import Clustering, Unsupervised
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.mixins.unsupervised_mixin import UnsupervisedMixin
+from simba.unsupervised.umap_embedder import UmapEmbedder
+
 
 
 class HDBSCANClusterer(UnsupervisedMixin):
     def __init__(self):
         super().__init__()
 
     def fit(self,
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/unsupervised/tsne.py` & `Simba-UW-tf-dev-1.57.6/simba/unsupervised/tsne.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/unsupervised/cluster_visualizer.py` & `Simba-UW-tf-dev-1.57.6/simba/unsupervised/cluster_visualizer.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,20 +1,21 @@
-from simba.misc_tools import (check_file_exist_and_readable,
-                              find_all_videos_in_directory,
-                              get_video_meta_data)
+import pandas as pd
+import numpy as np
+import os
+import cv2
+
+from simba.utils.checks import check_file_exist_and_readable
+from simba.utils.read_write import find_all_videos_in_directory, get_video_meta_data
 from simba.enums import Paths, Formats
 from simba.mixins.config_reader import ConfigReader
 from simba.mixins.unsupervised_mixin import UnsupervisedMixin
 from simba.unsupervised.enums import Clustering, Unsupervised
 from simba.utils.printing import stdout_success
-import pandas as pd
-import numpy as np
-import os
 from simba.utils.warnings import NoFileFoundWarning
-import cv2
+
 
 CLUSTER = 'CLUSTER'
 FPS = 'fps'
 VIDEO_SPEED = 'video_speed'
 START_FRAME = 'START_FRAME'
 POSE = 'pose'
 CREATE = 'create'
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/enums.py` & `Simba-UW-tf-dev-1.57.6/simba/enums.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,11 +1,12 @@
 from enum import Enum
 import pkg_resources
 from pathlib import Path
 import cv2
+import numpy as np
 
 class ReadConfig(Enum):
     GENERAL_SETTINGS = 'General settings'
     PROJECT_PATH = 'project_path'
     SML_SETTINGS = 'SML settings'
     VIDEO_INFO_CSV = 'video_info.csv'
     FOLDER_PATH = 'folder_path'
@@ -125,21 +126,22 @@
     MP4_CODEC = 'mp4v'
     AVI_CODEC = 'XVID'
     LABELFRAME_HEADER_FORMAT = ('Helvetica', 12, 'bold')
     LABELFRAME_HEADER_CLICKABLE_FORMAT = ('Helvetica', 12, 'bold', 'underline')
     LABELFRAME_HEADER_CLICKABLE_COLOR = f'#{5:02x}{99:02x}{193:02x}'
     CSV = 'csv'
     PARQUET = 'parquet'
-    PICKLE = 'parquet'
+    PICKLE = 'pickle'
     PERIMETER = 'perimeter'
     AREA = 'area'
     H5 = 'h5'
     ROOT_WINDOW_SIZE = "750x750"
     FONT = cv2.FONT_HERSHEY_TRIPLEX
     TKINTER_FONT = ("Rockwell", 11)
+    DLC_NETWORK_FILE_NAMES = ['dlc_resnet50', 'dlc_resnet_50', 'dlc_dlcrnetms5', 'dlc_effnet_b0', 'dlc_resnet101']
 
 
 class Options(Enum):
     ROLLING_WINDOW_DIVISORS = [2, 5, 6, 7.5, 15]
     CLF_MODELS = ['RF', 'GBC', 'XGBoost']
     CLF_MAX_FEATURES = ['sqrt', 'log', 'None']
     CLF_CRITERION = ['gini', 'entropy']
@@ -147,14 +149,15 @@
     OVERSAMPLE_OPTIONS = ['None', 'SMOTE', 'SMOTEENN']
     CLASS_WEIGHT_OPTIONS = ['None', 'balanced', 'balanced_subsample', 'custom']
     CLF_TEST_SIZE_OPTIONS = ['0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9']
     PALETTE_OPTIONS = ['magma', 'jet', 'inferno', 'plasma', 'viridis', 'gnuplot2']
     PALETTE_OPTIONS_CATEGORICAL = ['Pastel1', 'Paired', 'Accent', 'Dark', 'Set1', 'Set2', 'tab10']
     RESOLUTION_OPTIONS = ['320240', '640480', '720480', '800640', '960800', '1120960', '1280720', '19801080']
     DPI_OPTIONS = [100, 200, 400, 800, 1600, 3200]
+    SPEED_OPTIONS = [round(x, 1) for x in list(np.arange(0.1, 2.1, 0.1))]
     PERFORM_FLAGS = ['yes', True, 'True']
     RUN_OPTIONS_FLAGS = ['yes', True, 'True', 'False', 'no', False]
     SCALER_NAMES = ['MIN-MAX', 'STANDARD', 'QUANTILE']
     HEATMAP_SHADING_OPTIONS = ['gouraud', 'flat']
     HEATMAP_BIN_SIZE_OPTIONS = ['1010', '2020', '4040', '8080', '160160', '320320', '640640', '12801280']
     INTERPOLATION_OPTIONS = ['Animal(s): Nearest', 'Animal(s): Linear', 'Animal(s): Quadratic','Body-parts: Nearest', 'Body-parts: Linear', 'Body-parts: Quadratic']
     INTERPOLATION_OPTIONS_W_NONE = ['None', 'Animal(s): Nearest', 'Animal(s): Linear', 'Animal(s): Quadratic','Body-parts: Nearest', 'Body-parts: Linear', 'Body-parts: Quadratic']
@@ -234,14 +237,15 @@
     DOCUMENTATION = 'documentation'
 
 class Dtypes(Enum):
     NAN = 'NaN'
     STR = 'str'
     INT = 'int'
     FLOAT = 'float'
+    FOLDER = 'folder_path'
     NONE = 'None'
     SQRT = 'sqrt'
     ENTROPY = 'entropy'
 
 class Methods(Enum):
     USER_DEFINED = 'user_defined'
     CLASSIC_TRACKING = 'Classic tracking'
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/bounding_box_tools/.DS_Store` & `Simba-UW-tf-dev-1.57.6/simba/bounding_box_tools/.DS_Store`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/bounding_box_tools/agg_boundary_stats.py` & `Simba-UW-tf-dev-1.57.6/simba/bounding_box_tools/agg_boundary_stats.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,21 +1,17 @@
 import pandas as pd
-from simba.rw_dfs import read_df
-from simba.read_config_unit_tests import (read_config_entry,
-                                          read_config_file)
-from simba.misc_tools import (detect_bouts,
-                              plug_holes_shortest_bout)
-from simba.utils.printing import stdout_success
-from simba.feature_extractors.unit_tests import read_video_info_csv, read_video_info
-from simba.misc_tools import get_fn_ext
-from datetime import datetime
 import os, glob
+from simba.utils.read_write import read_df, get_fn_ext
+from simba.utils.printing import stdout_success
 from simba.utils.errors import NotDirectoryError
+from simba.utils.data import detect_bouts, plug_holes_shortest_bout
+from simba.mixins.config_reader import ConfigReader
+
+class AggBoundaryStatisticsCalculator(ConfigReader):
 
-class AggBoundaryStatisticsCalculator(object):
     """
     Class computing aggregate boundary statistics
 
     Parameters
     ----------
     config_path: str
         Path to SimBA project config file in Configparser format
@@ -37,40 +33,32 @@
 
 
     def __init__(self,
                  config_path: str,
                  measures: list,
                  shortest_allowed_interaction=int):
 
-        self.config_path, self.config, self.measures = config_path, read_config_file(config_path), measures
-        self.shortest_allowed_interaction_ms = shortest_allowed_interaction
-        self.project_path = read_config_entry(self.config, 'General settings', 'project_path', data_type='folder_path')
+        ConfigReader.__init__(self, config_path=config_path)
+        self.measures, self.shortest_allowed_interaction_ms = measures, shortest_allowed_interaction
         self.anchored_roi_path = os.path.join(self.project_path, 'logs', 'anchored_rois.pickle')
         self.data_path = os.path.join(self.project_path, 'csv', 'anchored_roi_data')
-        self.datetime = datetime.now().strftime('%Y%m%d%H%M%S')
-        self.video_info = read_video_info_csv(file_path=os.path.join(self.project_path, 'logs', 'video_info.csv'))
         if not os.path.isdir(self.data_path):
-            raise NotDirectoryError(msg='SIMBA ERROR: No anchored roi statistics found in {}. Create data before analyzing aggregate statistics'.format(self.data_path))
+            raise NotDirectoryError(msg=f'SIMBA ERROR: No anchored roi statistics found in {self.data_path}. Create data before analyzing aggregate statistics')
         self.files_found = glob.glob(self.data_path + '/*.pickle') + glob.glob(self.data_path + '/*.parquet') + glob.glob(self.data_path + '/*.csv')
 
     def run(self):
         self.results = {}
         for file_cnt, file_path in enumerate(self.files_found):
             _, self.file_name, ext = get_fn_ext(file_path)
-            print('Creating aggregate statistics for video {}...'.format(self.file_name))
-            _, _, fps = read_video_info(vid_info_df=self.video_info, video_name=self.file_name)
-
-            if ext.lower() == '.csv': data_df = read_df(file_path=file_path, file_type='csv')
-            elif ext.lower() == '.parquet': data_df = read_df(file_path=file_path, file_type='parquet')
-            elif ext.lower() == '.pickle': data_df = pd.read_pickle(file_path)
-            else:
-                print('Data with extension {} is not supported (OPTIONS: csv, parquet or pickle)')
-                raise ValueError()
+            print(f'Creating aggregate statistics for video {self.file_name}...')
+            _, _, fps = self.read_video_info(video_name=self.file_name)
+            data_df = read_df(file_path=file_path, file_type=ext[1:])
             if (self.shortest_allowed_interaction_ms / fps) > 0:
                 for column in data_df.columns:
+                    print(column)
                     data_df = plug_holes_shortest_bout(data_df=data_df, clf_name=column, fps=int(fps),shortest_bout=self.shortest_allowed_interaction_ms)
             bouts_df = detect_bouts(data_df=data_df, target_lst=list(data_df.columns), fps=int(fps))
             self.video_results, self.detailed_interactions_results = {}, {}
             if 'INTERACTION TIME (s)' in self.measures:
                 self.video_results['INTERACTION TIME (s)'] = bouts_df.groupby(by='Event')['Bout_time'].sum().to_dict()
             if ('INTERACTION BOUT COUNT' in self.measures):
                 self.video_results['INTERACTION BOUT COUNT'] = bouts_df.groupby(by='Event')['Bout_time'].count().to_dict()
@@ -79,42 +67,44 @@
             if ('INTERACTION BOUT TIME MEDIAN (s)' in self.measures):
                 self.video_results['INTERACTION BOUT MEDIAN (s)'] = bouts_df.groupby(by='Event')['Bout_time'].median().to_dict()
             if ('DETAILED INTERACTIONS TABLE' in self.measures):
                 self.create_detailed_interactions_table(df=bouts_df)
             self.results[self.file_name] = self.video_results
 
     def save(self):
+        self.timer.stop_timer()
         save_path = os.path.join(self.project_path, 'logs', 'aggregate_statistics_anchored_rois_{}.csv'.format(self.datetime))
         out_df = pd.DataFrame(columns=['VIDEO', 'ANIMAL 1', 'ANIMAL 2', 'ANIMAL 2 KEYPOINT', 'MEASUREMENT', 'VALUE'])
         if len(self.results.keys()) > 0:
             for video, video_data in self.results.items():
                 for measurement, measurement_data in video_data.items():
                     for animal_interaction, animal_interaction_value in measurement_data.items():
                         animal_names = animal_interaction.split(':')
                         if len(animal_names) == 2:
                             animal_names.append('None')
                         out_df.loc[len(out_df)] = [video, animal_names[0], animal_names[1], animal_names[2], measurement, animal_interaction_value]
             out_df['VALUE'] = out_df['VALUE'].round(4)
             out_df = out_df.sort_values(by=['VIDEO', 'MEASUREMENT']).set_index('VIDEO')
             out_df.to_csv(save_path)
-            stdout_success(msg=f'Aggregate animal-anchored ROI statistics saved at {save_path}')
+            stdout_success(msg=f'Aggregate animal-anchored ROI statistics saved at {save_path}', elapsed_time=self.timer.elapsed_time_str)
         if len(self.detailed_interactions_results.keys()) > 0:
             save_path = os.path.join(self.project_path, 'logs', 'detailed_aggregate_statistics_anchored_rois_{}.csv'.format(self.datetime))
             out_df = pd.concat(self.detailed_interactions_results.values(), ignore_index=True)
             out_df = out_df.sort_values(by=['VIDEO']).set_index('VIDEO')
             out_df.to_csv(save_path)
-            stdout_success(msg=f'Detailed Aggregate animal-anchored ROI statistics saved at {save_path}')
+            stdout_success(msg=f'Detailed Aggregate animal-anchored ROI statistics saved at {save_path}', elapsed_time=self.timer.elapsed_time_str)
 
     def create_detailed_interactions_table(self,
                                            df: pd.DataFrame):
 
         df = df.rename(columns={'Start_time': 'START TIME (s)', 'End Time': 'END TIME (s)', 'Start_frame': 'START FRAME', 'End_frame': 'END FRAME', 'Bout_time': 'BOUT TIME (s)'})
         df['ROI 1'], df['ROI 2'], df['KEY-POINT'] = df['Event'].str.split(':', 2).str
         df = df.drop(['Event'], axis=1)
         df['VIDEO'] = self.file_name
         df['BOUT FRAMES'] = (df['END FRAME'] + 1) - df['START FRAME']
         df = df[['VIDEO', 'ROI 1', 'ROI 2', 'KEY-POINT', 'START TIME (s)', 'END TIME (s)', 'START FRAME', 'END FRAME', 'BOUT FRAMES', 'BOUT TIME (s)']]
         self.detailed_interactions_results[self.file_name] = df
 
-# boundary_stats_calculator = AggBoundaryStatisticsCalculator('/Users/simon/Desktop/troubleshooting/termites/project_folder/project_config.ini', measures=['INTERACTION TIME (s)', 'DETAILED INTERACTIONS TABLE'], shortest_allowed_interaction=200)
+# boundary_stats_calculator = AggBoundaryStatisticsCalculator('/Users/simon/Desktop/envs/troubleshooting/sleap_5_animals/project_folder/project_config.ini',
+#                                                             measures=['INTERACTION TIME (s)', 'DETAILED INTERACTIONS TABLE'], shortest_allowed_interaction=0)
 # boundary_stats_calculator.run()
 # boundary_stats_calculator.save()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/bounding_box_tools/find_bounderies.py` & `Simba-UW-tf-dev-1.57.6/simba/pose_importers/import_mars.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,148 +1,160 @@
-from simba.read_config_unit_tests import (read_config_file,
-                                          read_config_entry,
-                                          check_if_filepath_list_is_empty)
-from simba.rw_dfs import read_df
-from simba.feature_extractors.unit_tests import (read_video_info_csv,
-                                               read_video_info)
-from simba.drop_bp_cords import (create_body_part_dictionary,
-                                 get_fn_ext,
-                                 getBpNames)
-from simba.read_config_unit_tests import read_project_path_and_file_type
+__author__ = "Simon Nilsson"
+
 import os, glob
-import itertools
+import json
 import numpy as np
-from shapely.geometry import (Polygon,
-                              Point,
-                              LineString)
-import shapely.wkt
-from joblib import Parallel, delayed
-import pickle
-import platform
-from simba.enums import ReadConfig, Dtypes, Paths
-from scipy.spatial import ConvexHull
+import pandas as pd
+from copy import deepcopy
+import pyarrow.parquet as pq
+import pyarrow as pa
 from simba.utils.printing import stdout_success
-from simba.misc_tools import (check_multi_animal_status,
-                              find_core_cnt)
+from simba.utils.errors import NoFilesFoundError
+from simba.enums import Paths, Methods, Dtypes
+from simba.interpolate_pose import Interpolate
+from simba.utils.data import smooth_data_gaussian, smooth_data_savitzky_golay
+from simba.utils.read_write import get_fn_ext, write_df, read_config_file, read_project_path_and_file_type
 
+class MarsImporter(object):
 
-class AnimalBoundaryFinder(object):
     """
-    Class finding boundaries (animal-anchored) ROIs for animals in each frame. Result is saved as a pickle in the
-    `project_folder/logs` directory of the SimBA project.
+    Class for importing two animal BENTO pose-estimation data (in JSON format) into a SimBA project in
+    parquet or CSV format.
 
     Parameters
     ----------
     config_path: str
         path to SimBA project config file in Configparser format
-    roi_type: str
-        shape type of ROI. OPTIONS: ENTIRE ANIMAL, SINGLE BODY-PART SQUARE, SINGLE BODY-PART CIRCLE
-    force_rectangle: bool or None
-        If True, forces roi shape into rectangles.
-    body_parts: dict
-        Body-parts to anchor the ROI to with keys as animal names and values as body-parts. E.g., body_parts={'Animal_1': 'Head_1', 'Animal_2': 'Head_2'}.
-    parallel_offset: int
-        Offset of ROI from the animal outer bounds in millimeter.
+    data_folder: str
+        Path to file or folder with data in `.json` format.
+    interpolation_settings: str
+        String defining the pose-estimation interpolation method. OPTIONS: 'None', 'Animal(s): Nearest',
+        'Animal(s): Linear', 'Animal(s): Quadratic','Body-parts: Nearest', 'Body-parts: Linear',
+        'Body-parts: Quadratic'.
+    smoothing_method: dict
+        Dictionary defining the pose estimation smoothing method. EXAMPLE: {'Method': 'Savitzky Golay',
+        'Parameters': {'Time_window': '200'}})
 
     Notes
-    ----------
-    `Bounding boxes tutorial <https://github.com/sgoldenlab/simba/blob/master/docs/anchored_rois.md__.
+    -----
+    `Multi-animal import tutorial <https://github.com/sgoldenlab/simba/blob/master/docs/Multi_animal_pose.md>`__.
 
     Examples
+    -----
+    >>> mars_importer = MarsImporter(config_path=r'MyConfigPath', data_folder=r'MyMarsDataFolder', interpolation_settings='None', smoothing_settings={'Method': 'None', 'Parameters': {'Time_window': '200'}})
+    >>> mars_importer.import_data()
+
+    References
     ----------
-    >>> animal_boundary_finder= AnimalBoundaryFinder(config_path='/Users/simon/Desktop/troubleshooting/termites/project_folder/project_config.ini', roi_type='SINGLE BODY-PART CIRCLE',body_parts={'Animal_1': 'Head_1', 'Animal_2': 'Head_2'}, force_rectangle=False, parallel_offset=15)
-    >>> animal_boundary_finder.find_boundaries()
+    .. [1] Segalin et al., The Mouse Action Recognition System (MARS) software pipeline for automated analysis of social behaviors in mice, `eLife`, 2021.
+
     """
 
 
     def __init__(self,
                  config_path: str,
-                 roi_type: str or None,
-                 force_rectangle: bool,
-                 body_parts: dict or None,
-                 parallel_offset: int or None):
-
-        self.config, self.config_path = read_config_file(ini_path=config_path), config_path
-        self.parallel_offset_mm, self.roi_type, self.force_rectangle = parallel_offset, roi_type, force_rectangle
-        if self.parallel_offset_mm == 0:
-            self.parallel_offset_mm += 1
-        self.body_parts = body_parts
+                 data_path: str,
+                 interpolation_method:  str,
+                 smoothing_method: dict):
+
+        self.config, self._config_path = read_config_file(config_path=config_path), config_path
+        self.data_path = data_path
+        self.interpolation_method, self.smoothing_method = interpolation_method, smoothing_method
         self.project_path, self.file_type = read_project_path_and_file_type(config=self.config)
-        self.input_dir = os.path.join(self.project_path, Paths.OUTLIER_CORRECTED.value)
-        self.files_found = glob.glob(self.input_dir + '/*.' + self.file_type)
-        check_if_filepath_list_is_empty(filepaths=self.files_found,
-                                        error_msg="SIMBA ERROR: ZERO files found in project_folder/outlier_corrected_movement_location directory")
-        self.vid_info_df = read_video_info_csv(os.path.join(self.project_path, Paths.VIDEO_INFO.value))
-        self.save_path = os.path.join(self.project_path, 'logs', 'anchored_rois.pickle')
-        self.no_animals = read_config_entry(self.config, ReadConfig.GENERAL_SETTINGS.value, ReadConfig.ANIMAL_CNT.value, Dtypes.INT.value)
-        self.multi_animal_status, self.multi_animal_id_lst = check_multi_animal_status(self.config, self.no_animals)
-        self.x_cols, self.y_cols, self.pcols = getBpNames(config_path)
-        self.animal_bp_dict = create_body_part_dictionary(self.multi_animal_status, list(self.multi_animal_id_lst),  self.no_animals, list(self.x_cols), list(self.y_cols), [], [])
-        self.cpus, self.cpus_to_use = find_core_cnt()
-        if (self.roi_type == 'SINGLE BODY-PART CIRCLE') or (self.roi_type == 'SINGLE BODY-PART SQUARE'):
-            self.center_bp_names = {}
-            for animal, body_part in self.body_parts.items():
-                self.center_bp_names[animal] = [body_part + '_x', body_part + '_y']
-
-    def _save_results(self):
-        with open(self.save_path, 'wb') as path:
-            pickle.dump(self.polygons, path, pickle.HIGHEST_PROTOCOL)
-        stdout_success(msg='Animal shapes for {str(len(self.files_found))} videos saved at {self.save_path}')
-
-    def minimum_bounding_rectangle(self, points):
-        pi2 = np.pi / 2.
-        hull_points = points[ConvexHull(points).vertices]
-        edges = hull_points[1:] - hull_points[:-1]
-        angles = np.arctan2(edges[:, 1], edges[:, 0])
-        angles = np.abs(np.mod(angles, pi2))
-        angles = np.unique(angles)
-        rotations = np.vstack([np.cos(angles), np.cos(angles - pi2), np.cos(angles + pi2), np.cos(angles)]).T
-        rotations = rotations.reshape((-1, 2, 2))
-        rot_points = np.dot(rotations, hull_points.T)
-        min_x, max_x = np.nanmin(rot_points[:, 0], axis=1), np.nanmax(rot_points[:, 0], axis=1)
-        min_y, max_y = np.nanmin(rot_points[:, 1], axis=1), np.nanmax(rot_points[:, 1], axis=1)
-        areas = (max_x - min_x) * (max_y - min_y)
-        best_idx = np.argmin(areas)
-        x1, x2 = max_x[best_idx], min_x[best_idx]
-        y1, y2 = max_y[best_idx], min_y[best_idx]
-        r = rotations[best_idx]
-        rval = np.zeros((4, 2))
-        rval[0], rval[1] = np.dot([x1, y2], r), np.dot([x2, y2], r)
-        rval[2], rval[3] = np.dot([x2, y1], r), np.dot([x1, y1], r)
-        return rval
-
-    def _find_polygons(self, point_array: np.array):
-        if self.roi_type == 'ENTIRE ANIMAL':
-            animal_shape = LineString(point_array.tolist()).buffer(self.offset_px)
-        elif self.roi_type == 'SINGLE BODY-PART CIRCLE':
-            animal_shape = Point(point_array).buffer(self.offset_px)
-        elif self.roi_type == 'SINGLE BODY-PART SQUARE':
-            top_left = Point(int(point_array[0] - self.offset_px), int(point_array[1] - self.offset_px))
-            top_right = Point(int(point_array[0] + self.offset_px), int(point_array[1] - self.offset_px))
-            bottom_left = Point(int(point_array[0] - self.offset_px), int(point_array[1] + self.offset_px))
-            bottom_right = Point(int(point_array[0] + self.offset_px), int(point_array[1] + self.offset_px))
-            animal_shape = Polygon([top_left, top_right, bottom_left, bottom_right])
-        if self.force_rectangle:
-            animal_shape = Polygon(self.minimum_bounding_rectangle(points=np.array(animal_shape.exterior.coords)))
-        animal_shape = shapely.wkt.loads(shapely.wkt.dumps(animal_shape, rounding_precision=1)).simplify(0)
-        return animal_shape
+        self.save_dir = os.path.join(self.project_path, Paths.INPUT_CSV.value)
+        if os.path.isdir(data_path):
+            self.files_found = glob.glob(data_path + '/*.json')
+        else:
+            self.files_found = [data_path]
+        if len(self.files_found) == 0:
+            raise NoFilesFoundError(msg=f'Zero .json files found in {data_path} directory')
+        body_part_names = ['Nose', 'Ear_left', 'Ear_right', 'Neck', 'Hip_left', 'Hip_right', 'Tail']
+        self.keypoint_headers, self.scores_headers = [], []
+        for animal in ['1', '2']:
+            for body_part in body_part_names:
+                for coordinate in ['x', 'y']:
+                    self.keypoint_headers.append(body_part + '_' + animal + '_' + coordinate)
+        for animal in ['1', '2']:
+            for body_part in body_part_names:
+                self.scores_headers.append(body_part + '_' + animal + '_p')
+        self.headers = deepcopy(self.keypoint_headers)
+        index = 3 - 1
+        for elem in self.scores_headers:
+            self.headers.insert(index, elem)
+            index += 3
+
+    def __merge_dfs(self, df_1: pd.DataFrame, df_2: pd.DataFrame):
+        df = pd.DataFrame()
+        for cnt, c in enumerate(df_1.columns):
+            df[len(df.columns)] = df_1[c]
+            df[len(df.columns)] = df_2[c]
+        return df
+
+    def __create_multi_index_headers(self, df: pd.DataFrame):
+        multi_index_tuples = []
+        for column in range(len(df.columns)):
+            multi_index_tuples.append(tuple(('MARS', 'MARS', df.columns[column])))
+        df.columns = pd.MultiIndex.from_tuples(multi_index_tuples, names=['scorer', 'bodypart', 'coords'])
+        return df
+
+    def __perform_interpolation(self,
+                                file_path: str,
+                                workflow_file_type: str,
+                                config_path: str,
+                                interpolation_method: str):
+        if workflow_file_type == 'parquet':
+            df = pd.read_parquet(file_path)
+        else:
+            df = pd.read_csv(file_path, index_col=0)
+        interpolate_body_parts = Interpolate(config_path, df)
+        interpolate_body_parts.detect_headers()
+        interpolate_body_parts.fix_missing_values(interpolation_method)
+        interpolate_body_parts.reorganize_headers()
+        if workflow_file_type == 'parquet':
+            table = pa.Table.from_pandas(interpolate_body_parts.new_df)
+            pq.write_table(table, file_path)
+        if workflow_file_type == 'csv':
+            interpolate_body_parts.new_df.to_csv(file_path)
+
+    def __run_smoothing(self):
+        if self.smoothing_method['Method'] == Methods.GAUSSIAN.value:
+            print('Performing Gaussian smoothing on video {}...'.format(self.file_name))
+            time_window = self.smoothing_method['Parameters']['Time_window']
+            smooth_data_gaussian(config=self.config, file_path=self.save_path, time_window_parameter=time_window)
+
+        if self.smoothing_method['Method'] == Methods.SAVITZKY_GOLAY.value:
+            print('Performing Savitzky Golay smoothing on video {}...'.format(self.file_name))
+            time_window = self.smoothing_method['Parameters']['Time_window']
+            smooth_data_savitzky_golay(config=self.config, file_path=self.save_path, time_window_parameter=time_window)
 
-    def find_boundaries(self):
-        self.polygons = {}
+    def import_data(self):
         for file_cnt, file_path in enumerate(self.files_found):
-            _, self.video_name, _ = get_fn_ext(file_path)
-            _, px_per_mm, _ = read_video_info(self.vid_info_df, self.video_name)
-            self.offset_px = px_per_mm * self.parallel_offset_mm
-            self.polygons[self.video_name] = {}
-            self.data_df = read_df(file_path=file_path,file_type=self.file_type).astype(int)
-            for animal_cnt, animal in enumerate(self.animal_bp_dict.keys()):
-                print('Analyzing shapes in video {} ({}/{}), animal {} ({}/{})...'.format(self.video_name, str(file_cnt+1), str(len(self.files_found)), animal, str(animal_cnt+1), len(list(self.animal_bp_dict.keys()))))
-                if self.roi_type == 'ENTIRE ANIMAL':
-                    animal_x_cols, animal_y_cols = self.animal_bp_dict[animal]['X_bps'], self.animal_bp_dict[animal]['Y_bps']
-                    animal_df = self.data_df[[x for x in itertools.chain.from_iterable(itertools.zip_longest(animal_x_cols,animal_y_cols)) if x]]
-                    animal_arr = np.reshape(animal_df.values, (-1, len(animal_x_cols), 2))
-                if (self.roi_type == 'SINGLE BODY-PART SQUARE') or (self.roi_type == 'SINGLE BODY-PART CIRCLE'):
-                    animal_arr = self.data_df[self.center_bp_names[animal]].values
-
-                self.polygons[self.video_name][animal] = Parallel(n_jobs=self.cpus_to_use, verbose=1, backend="threading")(delayed(self._find_polygons)(x) for x in animal_arr)
-        self._save_results()
+            _, self.file_name, _ = get_fn_ext(file_path)
+            print('Importing data for video {}...'.format(self.file_name))
+            self.save_path = os.path.join(self.save_dir, self.file_name + '.' + self.file_type)
+            with open(file_path, 'r') as j:
+                data = json.loads(j.read())
+            key_points, scores = np.array(data['keypoints']).astype(int), np.array(data['scores'])
+            animal_1_scores, animal_2_scores = pd.DataFrame(scores[:, 0]), pd.DataFrame(scores[:, 1])
+            data_df = []
+            for a in [key_points[:, 0], key_points[:, 1]]:
+                m, n, r = a.shape
+                arr = np.column_stack((np.repeat(np.arange(m),n),a.reshape(m*n,-1)))
+                df = pd.DataFrame(arr)
+                df_x, df_y = df[df.index % 2 != 0].set_index(0), df[df.index % 2 != 1].set_index(0)
+                data_df.append(self.__merge_dfs(df_x, df_y))
+            data_df = pd.concat(data_df, axis=1)
+            data_df.columns = self.keypoint_headers
+            scores_df = pd.concat([animal_1_scores, animal_2_scores], axis=1)
+            scores_df.columns = self.scores_headers
+            data_df = pd.concat([data_df, scores_df], axis=1)[self.headers]
+            data_df = self.__create_multi_index_headers(df=data_df)
+            write_df(data_df, self.file_type, self.save_path)
+
+            if self.interpolation_method != Dtypes.NONE.value:
+                print('Performing interpolation...')
+                self.__perform_interpolation(self.save_path, self.file_type, self._config_path, self.interpolation_method)
+            if self.smoothing_method['Method'] != Dtypes.NONE.value:
+                self.__run_smoothing()
+            print('Video imported {}.'.format(self.file_name))
+        stdout_success(msg=f'{str(len(self.files_found))} data files imported to SimBA project')
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/bounding_box_tools/boundary_menus.py` & `Simba-UW-tf-dev-1.57.6/simba/bounding_box_tools/boundary_menus.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,32 +1,27 @@
-from simba.read_config_unit_tests import (read_config_entry,
-                                          read_config_file,
-                                          check_int,
-                                          read_project_path_and_file_type)
-from simba.tkinter_functions import (DropDownMenu,
-                                     Entry_Box,
-                                     CreateLabelFrameWithIcon)
-from simba.drop_bp_cords import (create_body_part_dictionary,
-                                 getBpNames)
-from simba.misc_tools import (check_multi_animal_status,
-                              get_fn_ext,
-                              get_named_colors)
-from simba.enums import ReadConfig, Dtypes, Formats
-
 import os, glob
 import pickle
 from tkinter import *
-from simba.bounding_box_tools.find_bounderies import AnimalBoundaryFinder
+from simba.bounding_box_tools.find_boundaries import AnimalBoundaryFinder
 from simba.bounding_box_tools.visualize_boundaries import BoundaryVisualizer
 from simba.bounding_box_tools.boundary_statistics import BoundaryStatisticsCalculator
 from simba.bounding_box_tools.agg_boundary_stats import AggBoundaryStatisticsCalculator
 from simba.utils.errors import NoFilesFoundError, NoChoosenMeasurementError
 from simba.enums import Keys, Links
+from simba.mixins.config_reader import ConfigReader
+from simba.mixins.pop_up_mixin import PopUpMixin
+from simba.tkinter_functions import (DropDownMenu,
+                                     Entry_Box,
+                                     CreateLabelFrameWithIcon)
+from simba.utils.read_write import get_fn_ext
+from simba.utils.checks import check_int
+from simba.enums import Formats
+from simba.utils.lookups import get_named_colors
 
-class BoundaryMenus(object):
+class BoundaryMenus(ConfigReader, PopUpMixin):
     """
     Class creating GUI interface for extrapolating bounding boxes from pose-estimation data, and calculating
     statstics on bounding boxes and pose-estmated key-point intersections.
 
     Parameters
     ----------
     config_path: str
@@ -40,28 +35,18 @@
     ----------
     >>> _ = BoundaryMenus(config_path='/Users/simon/Desktop/troubleshooting/train_model_project/project_folder/project_config.ini')
     """
 
     def __init__(self,
                  config_path: str):
 
-        self.config_path = config_path
-        self.config = read_config_file(self.config_path)
-        self.project_path, _ = read_project_path_and_file_type(config=self.config)
-        self.video_dir = os.path.join(self.project_path, 'videos')
-        self.no_animals = read_config_entry(self.config, ReadConfig.GENERAL_SETTINGS.value, ReadConfig.ANIMAL_CNT.value, Dtypes.INT.value)
-        self.boundary_main_frm = Toplevel()
-        self.boundary_main_frm.minsize(750, 300)
-        self.boundary_main_frm.wm_title("SIMBA ANCHORED ROI (BOUNDARY BOXES ANALYSIS)")
+        ConfigReader.__init__(self, config_path=config_path)
+        PopUpMixin.__init__(self, title="SIMBA ANCHORED ROI (BOUNDARY BOXES ANALYSIS)", size=(750, 300))
         self.named_shape_colors = get_named_colors()
-
-        self.settings_frm = CreateLabelFrameWithIcon(parent=self.boundary_main_frm, header='SETTINGS', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.BBOXES.value)
-        self.multi_animal_status, self.multi_animal_id_lst = check_multi_animal_status(self.config, self.no_animals)
-        self.x_cols, self.y_cols, self.pcols = getBpNames(config_path)
-        self.animal_bp_dict = create_body_part_dictionary(self.multi_animal_status, list(self.multi_animal_id_lst), self.no_animals, list(self.x_cols), list(self.y_cols), [], [])
+        self.settings_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='SETTINGS', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.BBOXES.value)
         self.max_animal_name_char = len(max([x for x in list(self.animal_bp_dict.keys())]))
         self.find_boundaries_btn = Button(self.settings_frm, text='FIND ANIMAL BOUNDARIES', command=lambda: self.__launch_find_boundaries_pop_up())
         self.visualize_boundaries_btn = Button(self.settings_frm, text='VISUALIZE BOUNDARIES', command=lambda: self.__launch_visualize_boundaries())
         self.boundary_statistics_btn = Button(self.settings_frm, text='CALCULATE BOUNDARY STATISTICS', command=lambda: self.__launch_boundary_statistics())
         self.agg_boundary_statistics_btn = Button(self.settings_frm, text='CALCULATE AGGREGATE BOUNDARY STATISTICS', command=lambda: self.__launch_agg_boundary_statistics())
         self.settings_frm.grid(row=0, sticky=W)
         self.find_boundaries_btn.grid(row=0, column=0, sticky=NW)
@@ -109,14 +94,15 @@
         self.parallel_offset_entry = Entry_Box(self.boundary_settings, 'PARALLEL OFFSET (MM):', labelwidth='18', width=10, validation='numeric')
         self.run_find_shapes_btn = Button(self.boundary_settings, text='RUN', command=lambda: self.__run_find_boundaries())
         self.parallel_offset_entry.entry_set('0')
         self.parallel_offset_entry.grid(row=boundary_settings_row_cnt, column=0, sticky=NW)
         self.run_find_shapes_btn.grid(row=boundary_settings_row_cnt+1, column=0, sticky=NW)
 
     def __run_find_boundaries(self):
+        body_parts, force_rectangle = None, False
         if self.selected_shape_type == 'ENTIRE ANIMAL':
             force_rectangle = self.force_rectangle_var.get()
             body_parts = None
         elif (self.selected_shape_type == 'SINGLE BODY-PART SQUARE') | (self.selected_shape_type == 'SINGLE BODY-PART CIRCLE'):
             body_parts = {}
             for animal, animal_data in self.animals.items():
                 body_parts[animal] = self.animals[animal]['body_part_dropdown'].getChoices()
@@ -129,21 +115,20 @@
                                                force_rectangle=force_rectangle,
                                                parallel_offset=int(parallel_offset))
         boundary_finder.find_boundaries()
 
     def __launch_visualize_boundaries(self):
         self.anchored_roi_path = os.path.join(self.project_path, 'logs', 'anchored_rois.pickle')
         if not os.path.isfile(self.anchored_roi_path):
-            raise NoFilesFoundError(msg='SIMBA ERROR: No anchored ROI found in {}.'.format(self.anchored_roi_path))
+            raise NoFilesFoundError(msg='No anchored ROI found in {}.'.format(self.anchored_roi_path))
         with open(self.anchored_roi_path, 'rb') as fp: self.roi_data = pickle.load(fp)
         videos_in_project = glob.glob(self.video_dir + '/*')
         videos_with_data = list(self.roi_data.keys())
         if len(videos_in_project) == 0:
-            print('SIMBA ERROR: Zero video files found in SimBA project')
-            raise ValueError()
+            raise NoFilesFoundError(msg='Zero video files found in SimBA project')
         video_names = []
         for file_path in videos_in_project:
             _, name, _ = get_fn_ext(filepath=file_path)
             video_names.append(name)
         sets_w_data_and_video = list(set(videos_with_data).intersection(video_names))
         if len(sets_w_data_and_video) == 0:
             raise NoFilesFoundError(msg='SIMBA ERROR: Zero video files found with calculated anchored ROIs in SimBA project')
@@ -177,21 +162,21 @@
         Label(self.roi_attr_frm, text='ROI THICKNESS', font=Formats.LABELFRAME_HEADER_FORMAT.value, width=self.max_animal_name_char + 10).grid(row=0, column=2, sticky=N)
         Label(self.roi_attr_frm, text='KEY-POINT SIZE', font=Formats.LABELFRAME_HEADER_FORMAT.value, width=self.max_animal_name_char + 10).grid(row=0, column=3, sticky=N)
         Label(self.roi_attr_frm, text='HIGHLIGHT COLOR', font=Formats.LABELFRAME_HEADER_FORMAT.value, width=self.max_animal_name_char + 10).grid(row=0, column=4, sticky=N)
         Label(self.roi_attr_frm, text='HIGHLIGHT THICKNESS', font=Formats.LABELFRAME_HEADER_FORMAT.value, width=self.max_animal_name_char + 10).grid(row=0, column=5, sticky=N)
         for cnt, animal_name in enumerate(self.animal_bp_dict.keys()):
             self.animal_attr_dict[animal_name] = {}
             self.animal_attr_dict[animal_name]['label'] = Label(self.roi_attr_frm, text=animal_name, width=self.max_animal_name_char)
-            self.animal_attr_dict[animal_name]['clr_dropdown'] = DropDownMenu(self.roi_attr_frm, '', list(self.named_shape_colors.keys()), '10', command=None)
-            self.animal_attr_dict[animal_name]['clr_dropdown'].setChoices(list(self.named_shape_colors.keys())[cnt])
+            self.animal_attr_dict[animal_name]['clr_dropdown'] = DropDownMenu(self.roi_attr_frm, '', self.named_shape_colors, '10', command=None)
+            self.animal_attr_dict[animal_name]['clr_dropdown'].setChoices(self.named_shape_colors[cnt])
             self.animal_attr_dict[animal_name]['thickness_dropdown'] = DropDownMenu(self.roi_attr_frm, '', list(range(1, 10)), '10',command=None)
             self.animal_attr_dict[animal_name]['thickness_dropdown'].setChoices(1)
             self.animal_attr_dict[animal_name]['circle_size_dropdown'] = DropDownMenu(self.roi_attr_frm, '', list(range(1, 10)), '10', command=None)
             self.animal_attr_dict[animal_name]['circle_size_dropdown'].setChoices(1)
-            self.animal_attr_dict[animal_name]['highlight_clr_dropdown'] = DropDownMenu(self.roi_attr_frm, '', list(self.named_shape_colors.keys()), '10',command=None)
+            self.animal_attr_dict[animal_name]['highlight_clr_dropdown'] = DropDownMenu(self.roi_attr_frm, '', self.named_shape_colors, '10',command=None)
             self.animal_attr_dict[animal_name]['highlight_clr_dropdown'].setChoices('Red')
             self.animal_attr_dict[animal_name]['highlight_clr_thickness'] = DropDownMenu(self.roi_attr_frm, '',list(range(1, 10)), '10',command=None)
             self.animal_attr_dict[animal_name]['highlight_clr_thickness'].setChoices(5)
             self.animal_attr_dict[animal_name]['label'].grid(row=cnt+1, column=0, sticky=NW)
             self.animal_attr_dict[animal_name]['clr_dropdown'].grid(row=cnt+1, column=1, sticky=NW)
             self.animal_attr_dict[animal_name]['thickness_dropdown'].grid(row=cnt+1, column=2, sticky=NW)
             self.animal_attr_dict[animal_name]['circle_size_dropdown'].grid(row=cnt+1, column=3, sticky=NW)
@@ -324,10 +309,10 @@
 
         agg_stats_calculator = AggBoundaryStatisticsCalculator(config_path=self.config_path,
                                                                measures=measures,
                                                                shortest_allowed_interaction=int(min_bout))
         agg_stats_calculator.run()
         agg_stats_calculator.save()
 
-# test = BoundaryMenus(config_path='/Users/simon/Desktop/troubleshooting/train_model_project/project_folder/project_config.ini')
-# test.boundary_main_frm.mainloop()
+# test = BoundaryMenus(config_path='/Users/simon/Desktop/envs/troubleshooting/sleap_5_animals/project_folder/project_config.ini')
+# test.main_frm.mainloop()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/bounding_box_tools/boundary_statistics.py` & `Simba-UW-tf-dev-1.57.6/simba/bounding_box_tools/boundary_statistics.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,26 +1,21 @@
 import pandas as pd
-from simba.read_config_unit_tests import (read_config_file,
-                                          read_config_entry,
-                                          read_project_path_and_file_type)
-from simba.drop_bp_cords import (create_body_part_dictionary,
-                                 getBpNames)
-from simba.enums import ReadConfig, Paths, Dtypes
-from simba.misc_tools import check_multi_animal_status
-from simba.utils.printing import stdout_success
-from simba.rw_dfs import read_df, save_df
+import os
 from joblib import Parallel, delayed
 from shapely.geometry import Point
 from copy import deepcopy
 from collections import defaultdict
 from simba.utils.errors import NoFilesFoundError
-import os
-import pickle
+from simba.enums import Formats
+from simba.utils.read_write import read_df, write_df
+from simba.mixins.config_reader import ConfigReader
+from simba.utils.printing import stdout_success
+
 
-class BoundaryStatisticsCalculator(object):
+class BoundaryStatisticsCalculator(ConfigReader):
     """
     Class computing boundary intersection statistics.
 
     Parameters
     ----------
     config_path: str
         Path to SimBA project config file in Configparser format
@@ -44,28 +39,21 @@
 
     def __init__(self,
                  config_path: str,
                  roi_intersections: bool,
                  roi_keypoint_intersections: bool,
                  save_format: str):
 
-        self.config, self.config_path = read_config_file(ini_path=config_path), config_path
-        self.save_format = save_format
-        self.roi_intersections, self.roi_keypoint_intersections = roi_intersections, roi_keypoint_intersections
-        self.project_path, self.file_type = read_project_path_and_file_type(config=self.config)
+        ConfigReader.__init__(self, config_path=config_path)
+        self.save_format, self.roi_intersections, self.roi_keypoint_intersections = save_format, roi_intersections, roi_keypoint_intersections
         self.anchored_roi_path = os.path.join(self.project_path, 'logs', 'anchored_rois.pickle')
-        self.input_dir = os.path.join(self.project_path, Paths.OUTLIER_CORRECTED.value)
         self.save_folder = os.path.join(self.project_path, 'csv', 'anchored_roi_data')
         if not os.path.isfile(self.anchored_roi_path):
             raise NoFilesFoundError(msg=f'No anchored ROI data detected. Extract anchored ROIs before computing statistics. File expected at path {self.anchored_roi_path}')
-        with open(self.anchored_roi_path, 'rb') as fp: self.polygons = pickle.load(fp)
-        self.no_animals = read_config_entry(self.config, ReadConfig.GENERAL_SETTINGS.value, ReadConfig.ANIMAL_CNT.value, Dtypes.INT.value)
-        self.multi_animal_status, self.multi_animal_id_lst = check_multi_animal_status(self.config, self.no_animals)
-        self.x_cols, self.y_cols, self.pcols = getBpNames(config_path)
-        self.animal_bp_dict = create_body_part_dictionary(self.multi_animal_status, list(self.multi_animal_id_lst), self.no_animals, list(self.x_cols), list(self.y_cols), [], [])
+        self.polygons = read_df(file_path=self.anchored_roi_path, file_type=Formats.PICKLE.value)
         self.calculate_statistics()
 
     def _find_intersections(self,
                             animal_roi: list,
                             other_animals: dict):
         results = []
         for first_animal, second_animal in zip(animal_roi, other_animals):
@@ -114,15 +102,15 @@
                     for second_animal in {k: v for k, v in video_data.items() if k != first_animal}.keys():
                         second_animal_anchored_rois = [video_data[second_animal][i:i + 100] for i in range(0, len(video_data[second_animal]), 100)]
                         results = Parallel(n_jobs=5, verbose=2, backend="threading")(delayed(self._find_intersections)(i, j) for i,j in zip(first_animal_anchored_rois,second_animal_anchored_rois))
                         self.intersecting_rois[first_animal][second_animal] = [i for s in results for i in s]
                 self.intersection_dfs[video_name] = self._sort_intersection_results()
 
             if self.roi_keypoint_intersections:
-                self.data_df = read_df(os.path.join(self.input_dir, video_name + '.' + self.file_type), self.file_type).astype(int)
+                self.data_df = read_df(os.path.join(self.outlier_corrected_dir, video_name + '.' + self.file_type), self.file_type).astype(int)
                 keypoints_df_lst = []
                 print('Calculate intersecting anchored ROIs and keypoints for video {}...'.format(video_name))
                 for first_animal in self.animal_bp_dict.keys():
                     first_animal_anchored_rois = [video_data[first_animal][i:i + 100] for i in range(0, len(video_data[first_animal]), 100)]
                     for second_animal in {k: v for k, v in self.animal_bp_dict.items() if k != first_animal}.keys():
                         second_animal_name = deepcopy(second_animal)
                         second_animal_df_tuples = pd.DataFrame()
@@ -133,27 +121,26 @@
                         results = Parallel(n_jobs=5, verbose=1, backend="threading")(delayed(self._find_points_in_roi)(i, j) for i, j in zip(first_animal_anchored_rois, second_animal))
                         self.results = [i for s in results for i in s]
                         keypoints_df_lst.append(self._sort_keypoint_results(first_animal_name=first_animal, second_animal_name=second_animal_name))
                 self.keypoint_dfs[video_name] = pd.concat(keypoints_df_lst, axis=1)
 
     def save_results(self):
         if not os.path.exists(self.save_folder): os.makedirs(self.save_folder)
+        out_df = None
         for video_cnt, (video_name, video_data) in enumerate(self.polygons.items()):
-            save_path = os.path.join(self.save_folder, video_name + '.' + self.file_type)
+            save_path = os.path.join(self.save_folder, f'{video_name}.{self.save_format.lower()}')
             if (self.roi_intersections) and (self.roi_keypoint_intersections):
                 out_df = pd.concat([self.intersection_dfs[video_name], self.keypoint_dfs[video_name]], axis=1)
             elif self.roi_intersections:
                 out_df = self.intersection_dfs[video_name]
             elif self.roi_keypoint_intersections:
                 out_df = self.keypoint_dfs[video_name]
-            if self.save_format == 'CSV':
-                save_df(df=out_df,file_type='csv', save_path=save_path)
-            elif self.save_format == 'PARQUET':
-                save_df(df=out_df, file_type='parquet', save_path=save_path)
-            elif self.save_format == 'PICKLE':
-                out_df.to_pickle(save_path)
-            print('Data for video {} saved...'.format(video_name))
+            write_df(df=out_df, file_type=self.save_format.lower(), save_path=save_path)
+            print(f'Data for video {video_name} saved...')
 
         stdout_success(msg=f'Data for {str(len(self.polygons.keys()))} videos saved in {self.save_folder}')
 
-# boundary_stats_calculator = BoundaryStatisticsCalculator(config_path='/Users/simon/Desktop/troubleshooting/termites/project_folder/project_config.ini',roi_intersections=True, roi_keypoint_intersections=True, save_format='CSV')
+# boundary_stats_calculator = BoundaryStatisticsCalculator(config_path='/Users/simon/Desktop/envs/troubleshooting/sleap_5_animals/project_folder/project_config.ini',
+#                                                          roi_intersections=True,
+#                                                          roi_keypoint_intersections=True,
+#                                                          save_format='PICKLE')
 # boundary_stats_calculator.save_results()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/bounding_box_tools/visualize_boundaries.py` & `Simba-UW-tf-dev-1.57.6/simba/bounding_box_tools/visualize_boundaries.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,47 +1,36 @@
 import pandas as pd
-
-from simba.read_config_unit_tests import (read_config_file,
-                                          read_config_entry,
-                                          read_project_path_and_file_type)
-from simba.read_config_unit_tests import check_file_exist_and_readable
-from simba.misc_tools import (check_multi_animal_status,
-                              find_video_of_file,
-                              get_video_meta_data,
-                              find_core_cnt,
-                              remove_a_folder)
-from simba.utils.printing import stdout_success
-from simba.drop_bp_cords import (create_body_part_dictionary,
-                                 getBpNames,
-                                 createColorListofList)
-from simba.enums import Paths, ReadConfig, Dtypes
-from simba.rw_dfs import read_df
 import numpy as np
 import pickle
 import functools
 import cv2
-import pathlib, re
 import multiprocessing
 from multiprocessing import pool
 import platform
-import os, glob
+import os
 from simba.utils.errors import NoFilesFoundError
+from simba.mixins.config_reader import ConfigReader
+from simba.utils.read_write import (read_df,
+                                    get_fn_ext,
+                                    get_video_meta_data,
+                                    concatenate_videos_in_folder)
+from simba.utils.checks import check_file_exist_and_readable
+from simba.utils.printing import stdout_success
 
 def _image_creator(frm_range: list,
                    polygon_data: dict,
                    animal_bp_dict: dict,
                    data_df: pd.DataFrame or None,
                    intersection_data_df: pd.DataFrame or None,
                    roi_attributes: dict,
                    video_path: str,
                    key_points: bool,
                    greyscale: bool):
 
     cap, current_frame = cv2.VideoCapture(video_path), frm_range[0]
-
     cap.set(1, frm_range[0])
     img_lst = []
     while current_frame < frm_range[-1]:
         ret, frame = cap.read()
         if ret:
             if key_points:
                 frm_data = data_df.iloc[current_frame]
@@ -60,15 +49,15 @@
                 cv2.polylines(frame, [animal_polygon], 1, roi_attributes[animal]['bbox_clr'], roi_attributes[animal]['bbox_thickness'])
             img_lst.append(frame)
             current_frame += 1
         else:
             print('SIMBA WARNING: SimBA tried to grab frame number {} from video {}, but could not find it. The video has {} frames.'.format(str(current_frame), video_path, str(cap.get(cv2.CAP_PROP_FRAME_COUNT))))
     return img_lst
 
-class BoundaryVisualizer(object):
+class BoundaryVisualizer(ConfigReader):
     """
     Class visualizing user-specified animal-anchored ROI boundaries. Results are stored in the
     `project_folder/frames/output/anchored_rois` directory of teh SimBA project
 
     Parameters
     ----------
     config_path: str
@@ -96,67 +85,52 @@
                  config_path: str,
                  video_name: str,
                  include_key_points: bool,
                  greyscale: bool,
                  show_intersections: bool or None,
                  roi_attributes: dict or None):
 
+        ConfigReader.__init__(self, config_path=config_path)
         if platform.system() == "Darwin":
             multiprocessing.set_start_method('spawn', force=True)
-
-        self.config, self.config_path = read_config_file(ini_path=config_path), config_path
-        self.project_path, self.file_type = read_project_path_and_file_type(config=self.config)
         self.polygon_path = os.path.join(self.project_path, 'logs', 'anchored_rois.pickle')
+        check_file_exist_and_readable(file_path=self.polygon_path)
         self.video_name, self.include_key_points, self.greyscale, self.roi_attributes = video_name, include_key_points, greyscale, roi_attributes
         self.show_intersections, self.intersection_data_folder = show_intersections, os.path.join(self.project_path, 'csv', 'anchored_roi_data')
-        check_file_exist_and_readable(file_path=self.polygon_path)
         self.intersections_df = None
         if self.show_intersections: self._find_intersection_data()
         with open(self.polygon_path, 'rb') as fp: self.polygons = pickle.load(fp)
-        self.input_dir = os.path.join(self.project_path, Paths.OUTLIER_CORRECTED.value)
-        self.video_dir = os.path.join(self.project_path, 'videos')
-        self.video_path = find_video_of_file(video_dir=self.video_dir, filename=video_name)
+        self.video_path = self.find_video_of_file(video_dir=self.video_dir, filename=video_name)
         self.save_parent_dir = os.path.join(self.project_path, 'frames', 'output', 'anchored_rois')
         self.save_video_path = os.path.join(self.save_parent_dir, video_name + '.mp4')
         if not os.path.exists(self.save_parent_dir): os.makedirs(self.save_parent_dir)
-        self.no_animals = read_config_entry(self.config, ReadConfig.GENERAL_SETTINGS.value, ReadConfig.ANIMAL_CNT.value, Dtypes.INT.value)
-        self.multi_animal_status, self.multi_animal_id_lst = check_multi_animal_status(self.config, self.no_animals)
-        self.x_cols, self.y_cols, self.pcols = getBpNames(config_path)
-        self.color_lst_of_lst = createColorListofList(self.no_animals, int(len(list(self.x_cols)) + 1))
-        self.cpu_cnt, self.cpu_to_use = find_core_cnt()
-        self.maxtasksperchild, self.chunksize = 10, 1
-        self.animal_bp_dict = create_body_part_dictionary(self.multi_animal_status, list(self.multi_animal_id_lst), self.no_animals, list(self.x_cols), list(self.y_cols), [], self.color_lst_of_lst)
 
     def _find_intersection_data(self):
         self.intersection_path = None
         for p in [os.path.join(self.intersection_data_folder, self.video_name + x) for x in ['.pickle', '.csv', '.parquet']]:
             if os.path.isfile(p):
                 self.intersection_path = p
         if self.intersection_path is None:
             print('SIMBA WARNING: No ROI intersection data found for video {} in directory {}. Skipping intersection visualizations'.format(self.video_name, self.intersection_data_folder))
             self.show_intersections = False
             self.intersections_df = None
         else:
-            if self.intersection_path.endswith('pickle'):
-                self.intersections_df = pd.read_pickle(self.intersection_path)
-            elif self.intersection_path.endswith('parquet'):
-                self.intersections_df = pd.read_parquet(self.intersection_path)
-            elif self.intersection_path.endswith('csv'):
-                self.intersections_df = pd.read_csv(self.intersection_path)
+            _, _, ext = get_fn_ext(filepath=self.intersection_path)
+            self.intersections_df = read_df(file_path=self.intersection_path, file_type=ext[1:])
 
     def run_visualization(self, chunk_size=50):
         if self.include_key_points:
-            self.data_df_path = os.path.join(self.input_dir, self.video_name + '.' + self.file_type)
+            self.data_df_path = os.path.join(self.outlier_corrected_dir, self.video_name + '.' + self.file_type)
             if not os.path.isfile(self.data_df_path):
                 raise NoFilesFoundError(msg=f'SIMBA ERROR: No keypoint data found in {self.data_df_path}. Untick key-point checkbox or import pose-estimation data.')
             self.data_df = read_df(file_path=self.data_df_path, file_type=self.file_type).astype(int).reset_index(drop=True)
         else:
             self.data_df = None
         print('Creating visualization for video {}...'.format(self.video_name))
-        video_path = find_video_of_file(video_dir=self.video_dir, filename=self.video_name)
+        video_path = self.find_video_of_file(video_dir=self.video_dir, filename=self.video_name)
         video_meta_data = get_video_meta_data(video_path=video_path)
         self.max_dim = max(video_meta_data['width'], video_meta_data['height'])
         self.space_scale, self.radius_scale, self.res_scale, self.font_scale = 60, 12, 1500, 1.1
         if self.roi_attributes is None:
             self.roi_attributes = {}
             for animal_name, animal_data in self.animal_bp_dict.items():
                 self.roi_attributes[animal_name] = {}
@@ -178,40 +152,28 @@
                                           polygon_data=self.polygons[self.video_name],
                                           animal_bp_dict=self.animal_bp_dict,
                                           roi_attributes=self.roi_attributes,
                                           video_path=video_path,
                                           key_points=self.include_key_points,
                                           greyscale=self.greyscale,
                                           intersection_data_df=self.intersections_df)
-            for cnt, result in enumerate(p.imap(constants, frame_chunks, chunksize=self.chunksize)):
+            for cnt, result in enumerate(p.imap(constants, frame_chunks, chunksize=self.multiprocess_chunksize)):
                 save_path = os.path.join(self.temp_folder, str(cnt) + '.mp4')
                 writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), video_meta_data['fps'], (video_meta_data['width'], video_meta_data['height']))
                 for img in result:
                     writer.write(img)
                 writer.release()
                 if int(chunk_size * cnt) < video_meta_data['frame_count']:
                     print('Image {}/{}...'.format(str(int(chunk_size * cnt)), str(video_meta_data['frame_count'])))
             p.terminate()
             p.join()
 
-        files = glob.glob(self.temp_folder + '/*.mp4')
-        files.sort(key=lambda f: int(re.sub('\D', '', f)))
-        temp_txt_path = pathlib.Path(self.temp_folder, 'files.txt')
-        with open(temp_txt_path, 'w') as f:
-            for file in files:
-                f.write("file '" + str(pathlib.Path(file)) + "'\n")
-        if os.path.exists(self.save_video_path): os.remove(self.save_video_path)
-        returned = os.system('ffmpeg -f concat -safe 0 -i "{}" "{}" -hide_banner -loglevel error'.format(temp_txt_path, self.save_video_path))
-        while True:
-            if returned != 0:
-                pass
-            else:
-                remove_a_folder(folder_dir=self.temp_folder)
-                break
+        concatenate_videos_in_folder(in_folder=self.temp_folder, save_path=self.save_video_path, video_format='mp4', remove_splits=True)
         stdout_success(msg=f'Anchored ROI video created at {self.save_video_path}')
 
-# boundary_visualizer = BoundaryVisualizer(config_path='/Users/simon/Desktop/troubleshooting/termites/project_folder/project_config.ini',
-#                                          video_name='termites_test',
+# boundary_visualizer = BoundaryVisualizer(config_path='/Users/simon/Desktop/envs/troubleshooting/sleap_5_animals/project_folder/project_config.ini',
+#                                          video_name='Testing_Video_3',
 #                                          include_key_points=True,
 #                                          greyscale=True,
-#                                          show_intersections=True)
+#                                          show_intersections=True,
+#                                          roi_attributes=None)
 # boundary_visualizer.run_visualization()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/.DS_Store` & `Simba-UW-tf-dev-1.57.6/simba/.DS_Store`

 * *Files 3% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 00000000: 0000 0001 4275 6431 0000 7800 0000 0800  ....Bud1..x.....
 00000010: 0000 7800 0000 100c 0000 700b 0000 200c  ..x.......p... .
 00000020: 0000 300c 0000 0000 0000 0000 0000 0800  ..0.............
 00000030: 0000 0800 0000 0000 0000 0000 0000 0000  ................
-00000040: 0000 0000 0000 0003 0000 0001 0000 007b  ...............{
+00000040: 0000 0000 0000 0003 0000 0001 0000 007c  ...............|
 00000050: 0000 0007 0000 1000 0074 0063 0068 005f  .........t.c.h._
 00000060: 0070 0072 0000 0000 0000 0000 0000 0000  .p.r............
 00000070: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00000080: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00000090: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 000000a0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 000000b0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
@@ -253,15 +253,15 @@
 00000fc0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00000fd0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00000fe0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00000ff0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00001000: 0000 0000 0000 0000 0000 0010 0000 000c  ................
 00001010: 0075 006e 0073 0075 0070 0065 0072 0076  .u.n.s.u.p.e.r.v
 00001020: 0069 0073 0065 0064 6c67 3153 636f 6d70  .i.s.e.dlg1Scomp
-00001030: 0000 0000 0005 d88e 0000 000c 0075 006e  .............u.n
+00001030: 0000 0000 0005 ab85 0000 000c 0075 006e  .............u.n
 00001040: 0073 0075 0070 0065 0072 0076 0069 0073  .s.u.p.e.r.v.i.s
 00001050: 0065 0064 6c73 7643 626c 6f62 0000 0297  .e.dlsvCblob....
 00001060: 6270 6c69 7374 3030 d801 0203 0405 0607  bplist00........
 00001070: 0809 0a0b 1949 4a0a 4c5f 1012 7669 6577  .....IJ.L_..view
 00001080: 4f70 7469 6f6e 7356 6572 7369 6f6e 5f10  OptionsVersion_.
 00001090: 0f73 686f 7749 636f 6e50 7265 7669 6577  .showIconPreview
 000010a0: 5763 6f6c 756d 6e73 5f10 1163 616c 6375  Wcolumns_..calcu
@@ -340,21 +340,21 @@
 00001530: 5a01 6301 6501 6601 6801 6901 7201 7401  Z.c.e.f.h.i.r.t.
 00001540: 7501 7701 7801 8101 8301 8401 8701 8801  u.w.x...........
 00001550: 9101 9201 9301 9401 9d01 a201 a300 0000  ................
 00001560: 0000 0002 0100 0000 0000 0000 4900 0000  ............I...
 00001570: 0000 0000 0000 0000 0000 0001 ac00 0000  ................
 00001580: 0c00 7500 6e00 7300 7500 7000 6500 7200  ..u.n.s.u.p.e.r.
 00001590: 7600 6900 7300 6500 646d 6f44 4462 6c6f  v.i.s.e.dmoDDblo
-000015a0: 6200 0000 08f8 5284 dfc7 f8c4 4100 0000  b.....R.....A...
+000015a0: 6200 0000 0883 abcd ff10 fcc4 4100 0000  b...........A...
 000015b0: 0c00 7500 6e00 7300 7500 7000 6500 7200  ..u.n.s.u.p.e.r.
 000015c0: 7600 6900 7300 6500 646d 6f64 4462 6c6f  v.i.s.e.dmodDblo
-000015d0: 6200 0000 08f8 5284 dfc7 f8c4 4100 0000  b.....R.....A...
+000015d0: 6200 0000 0883 abcd ff10 fcc4 4100 0000  b...........A...
 000015e0: 0c00 7500 6e00 7300 7500 7000 6500 7200  ..u.n.s.u.p.e.r.
 000015f0: 7600 6900 7300 6500 6470 6831 5363 6f6d  v.i.s.e.dph1Scom
-00001600: 7000 0000 0000 0760 0000 0000 0c00 7500  p......`......u.
+00001600: 7000 0000 0000 0730 0000 0000 0c00 7500  p......0......u.
 00001610: 6e00 7300 7500 7000 6500 7200 7600 6900  n.s.u.p.e.r.v.i.
 00001620: 7300 6500 6476 5372 6e6c 6f6e 6700 0000  s.e.dvSrnlong...
 00001630: 0100 0000 0500 7500 7400 6900 6c00 7362  ......u.t.i.l.sb
 00001640: 7773 7062 6c6f 6200 0000 c962 706c 6973  wspblob....bplis
 00001650: 7430 30d7 0102 0304 0506 0708 080a 080a  t00.............
 00001660: 0d0a 5d53 686f 7753 7461 7475 7342 6172  ..]ShowStatusBar
 00001670: 5b53 686f 7750 6174 6862 6172 5b53 686f  [ShowPathbar[Sho
@@ -366,15 +366,15 @@
 000016d0: 362c 2033 3230 7d2c 207b 3737 302c 2034  6, 320}, {770, 4
 000016e0: 3336 7d7d 0908 1725 313d 4960 6d79 7a7b  36}}...%1=I`myz{
 000016f0: 7c7d 7e99 0000 0000 0000 0101 0000 0000  |}~.............
 00001700: 0000 000f 0000 0000 0000 0000 0000 0000  ................
 00001710: 0000 009a 0000 0005 0075 0074 0069 006c  .........u.t.i.l
 00001720: 0073 6473 636c 626f 6f6c 0000 0000 0500  .sdsclbool......
 00001730: 7500 7400 6900 6c00 736c 6731 5363 6f6d  u.t.i.l.slg1Scom
-00001740: 7000 0000 0000 011e f300 0000 0500 7500  p.............u.
+00001740: 7000 0000 0000 02b6 8600 0000 0500 7500  p.............u.
 00001750: 7400 6900 6c00 736c 7376 4362 6c6f 6200  t.i.l.slsvCblob.
 00001760: 0002 9762 706c 6973 7430 30d8 0102 0304  ...bplist00.....
 00001770: 0506 0708 090a 0b19 494a 0a4c 5f10 1276  ........IJ.L_..v
 00001780: 6965 774f 7074 696f 6e73 5665 7273 696f  iewOptionsVersio
 00001790: 6e5f 100f 7368 6f77 4963 6f6e 5072 6576  n_..showIconPrev
 000017a0: 6965 7757 636f 6c75 6d6e 735f 1011 6361  iewWcolumns_..ca
 000017b0: 6c63 756c 6174 6541 6c6c 5369 7a65 7358  lculateAllSizesX
@@ -450,20 +450,20 @@
 00001c10: 013c 0145 0147 0148 014a 014b 0154 0156  .<.E.G.H.J.K.T.V
 00001c20: 0157 0159 015a 0163 0165 0166 0168 0169  .W.Y.Z.c.e.f.h.i
 00001c30: 0172 0174 0175 0177 0178 0181 0183 0184  .r.t.u.w.x......
 00001c40: 0187 0188 0191 0192 0193 0194 019d 01a2  ................
 00001c50: 01a3 0000 0000 0000 0201 0000 0000 0000  ................
 00001c60: 0049 0000 0000 0000 0000 0000 0000 0000  .I..............
 00001c70: 01ac 0000 0005 0075 0074 0069 006c 0073  .......u.t.i.l.s
-00001c80: 6d6f 4444 626c 6f62 0000 0008 54f1 87c2  moDDblob....T...
-00001c90: 44f6 c441 0000 0005 0075 0074 0069 006c  D..A.....u.t.i.l
-00001ca0: 0073 6d6f 6444 626c 6f62 0000 0008 b191  .smodDblob......
-00001cb0: 97e3 46f2 c441 0000 0005 0075 0074 0069  ..F..A.....u.t.i
+00001c80: 6d6f 4444 626c 6f62 0000 0008 4ce8 3936  moDDblob....L.96
+00001c90: d0fc c441 0000 0005 0075 0074 0069 006c  ...A.....u.t.i.l
+00001ca0: 0073 6d6f 6444 626c 6f62 0000 0008 d948  .smodDblob.....H
+00001cb0: 036a b6fc c441 0000 0005 0075 0074 0069  .j...A.....u.t.i
 00001cc0: 006c 0073 7068 3153 636f 6d70 0000 0000  .l.sph1Scomp....
-00001cd0: 0001 6000 0000 0005 0075 0074 0069 006c  ..`......u.t.i.l
+00001cd0: 0003 3000 0000 0005 0075 0074 0069 006c  ..0......u.t.i.l
 00001ce0: 0073 7653 726e 6c6f 6e67 0000 0001 0000  .svSrnlong......
 00001cf0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00001d00: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00001d10: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00001d20: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00001d30: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00001d40: 0000 0000 0000 0000 0000 0000 0000 0000  ................
@@ -509,268 +509,268 @@
 00001fc0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00001fd0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00001fe0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00001ff0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00002000: 0000 0000 0000 0000 0000 0013 0000 000b  ................
 00002010: 005f 005f 0070 0079 0063 0061 0063 0068  ._._.p.y.c.a.c.h
 00002020: 0065 005f 005f 6c67 3153 636f 6d70 0000  .e._._lg1Scomp..
-00002030: 0000 0042 1d4f 0000 000b 005f 005f 0070  ...B.O....._._.p
+00002030: 0000 0041 d4e3 0000 000b 005f 005f 0070  ...A......._._.p
 00002040: 0079 0063 0061 0063 0068 0065 005f 005f  .y.c.a.c.h.e._._
-00002050: 6d6f 4444 626c 6f62 0000 0008 3293 8634  moDDblob....2..4
-00002060: 16fa c441 0000 000b 005f 005f 0070 0079  ...A....._._.p.y
+00002050: 6d6f 4444 626c 6f62 0000 0008 788a 0547  moDDblob....x..G
+00002060: 63fc c441 0000 000b 005f 005f 0070 0079  c..A....._._.p.y
 00002070: 0063 0061 0063 0068 0065 005f 005f 6d6f  .c.a.c.h.e._._mo
-00002080: 6444 626c 6f62 0000 0008 6a13 8953 eaf6  dDblob....j..S..
+00002080: 6444 626c 6f62 0000 0008 788a 0547 63fc  dDblob....x..Gc.
 00002090: c441 0000 000b 005f 005f 0070 0079 0063  .A....._._.p.y.c
 000020a0: 0061 0063 0068 0065 005f 005f 7068 3153  .a.c.h.e._._ph1S
-000020b0: 636f 6d70 0000 0000 0050 0000 0000 0006  comp.....P......
+000020b0: 636f 6d70 0000 0000 004f a000 0000 0006  comp.....O......
 000020c0: 0061 0073 0073 0065 0074 0073 6277 7370  .a.s.s.e.t.sbwsp
-000020d0: 626c 6f62 0000 00ca 6270 6c69 7374 3030  blob....bplist00
+000020d0: 626c 6f62 0000 00c8 6270 6c69 7374 3030  blob....bplist00
 000020e0: d701 0203 0405 0607 0808 0a08 0a0d 0a5d  ...............]
 000020f0: 5368 6f77 5374 6174 7573 4261 725b 5368  ShowStatusBar[Sh
 00002100: 6f77 5061 7468 6261 725b 5368 6f77 546f  owPathbar[ShowTo
 00002110: 6f6c 6261 725b 5368 6f77 5461 6256 6965  olbar[ShowTabVie
 00002120: 775f 1014 436f 6e74 6169 6e65 7253 686f  w_..ContainerSho
 00002130: 7753 6964 6562 6172 5c57 696e 646f 7742  wSidebar\WindowB
 00002140: 6f75 6e64 735b 5368 6f77 5369 6465 6261  ounds[ShowSideba
-00002150: 7208 0809 0809 5f10 197b 7b34 3230 2c20  r....._..{{420, 
-00002160: 3131 337d 2c20 7b31 3031 352c 2037 3637  113}, {1015, 767
-00002170: 7d7d 0908 1725 313d 4960 6d79 7a7b 7c7d  }}...%1=I`myz{|}
-00002180: 7e9a 0000 0000 0000 0101 0000 0000 0000  ~...............
-00002190: 000f 0000 0000 0000 0000 0000 0000 0000  ................
-000021a0: 009b 0000 0006 0061 0073 0073 0065 0074  .......a.s.s.e.t
-000021b0: 0073 6c67 3153 636f 6d70 0000 0000 007d  .slg1Scomp.....}
-000021c0: d138 0000 0006 0061 0073 0073 0065 0074  .8.....a.s.s.e.t
-000021d0: 0073 6c73 7643 626c 6f62 0000 02b0 6270  .slsvCblob....bp
-000021e0: 6c69 7374 3030 da01 0203 0405 0607 0809  list00..........
-000021f0: 0a0b 0c0d 1848 4948 4a4b 0c5f 1012 7669  .....HIHJK._..vi
-00002200: 6577 4f70 7469 6f6e 7356 6572 7369 6f6e  ewOptionsVersion
-00002210: 5f10 0f73 686f 7749 636f 6e50 7265 7669  _..showIconPrevi
-00002220: 6577 5763 6f6c 756d 6e73 5f10 1163 616c  ewWcolumns_..cal
-00002230: 6375 6c61 7465 416c 6c53 697a 6573 5f10  culateAllSizes_.
-00002240: 0f73 6372 6f6c 6c50 6f73 6974 696f 6e59  .scrollPositionY
-00002250: 5874 6578 7453 697a 655f 100f 7363 726f  XtextSize_..scro
-00002260: 6c6c 506f 7369 7469 6f6e 585a 736f 7274  llPositionXZsort
-00002270: 436f 6c75 6d6e 5869 636f 6e53 697a 655f  ColumnXiconSize_
-00002280: 1010 7573 6552 656c 6174 6976 6544 6174  ..useRelativeDat
-00002290: 6573 1001 09ab 0e17 1c21 252a 2f34 393e  es.......!%*/49>
-000022a0: 43d4 0f10 1112 0c14 0c16 5776 6973 6962  C.........Wvisib
-000022b0: 6c65 5577 6964 7468 5961 7363 656e 6469  leUwidthYascendi
-000022c0: 6e67 5a69 6465 6e74 6966 6965 7209 1101  ngZidentifier...
-000022d0: 2709 546e 616d 65d4 0f10 1112 1819 181b  '.Tname.........
-000022e0: 0810 2308 5875 6269 7175 6974 79d4 0f10  ..#.Xubiquity...
-000022f0: 1112 0c1e 1820 0910 b508 5c64 6174 654d  ..... ....\dateM
-00002300: 6f64 6966 6965 64d4 0f10 1112 181e 1824  odified........$
-00002310: 0808 5b64 6174 6543 7265 6174 6564 d40f  ..[dateCreated..
-00002320: 1011 120c 2718 2909 1061 0854 7369 7a65  ....'.)..a.Tsize
-00002330: d40f 1011 120c 2c0c 2e09 1073 0954 6b69  ......,....s.Tki
-00002340: 6e64 d40f 1011 1218 310c 3308 1064 0955  nd......1.3..d.U
-00002350: 6c61 6265 6cd4 0f10 1112 1836 0c38 0810  label......6.8..
-00002360: 4b09 5776 6572 7369 6f6e d40f 1011 1218  K.Wversion......
-00002370: 3b0c 3d08 1101 2c09 5863 6f6d 6d65 6e74  ;.=...,.Xcomment
-00002380: 73d4 0f10 1112 1840 1842 0810 c808 5e64  s......@.B....^d
-00002390: 6174 654c 6173 744f 7065 6e65 64d4 0f10  ateLastOpened...
-000023a0: 1112 181e 1846 0808 5964 6174 6541 6464  .....F..YdateAdd
-000023b0: 6564 0823 0000 0000 0000 0000 2340 2800  ed.#........#@(.
-000023c0: 0000 0000 0054 6e61 6d65 2340 3000 0000  .....Tname#@0...
-000023d0: 0000 0009 0008 001d 0032 0044 004c 0060  .........2.D.L.`
-000023e0: 0072 007b 008d 0098 00a1 00b4 00b6 00b7  .r.{............
-000023f0: 00c3 00cc 00d4 00da 00e4 00ef 00f0 00f3  ................
-00002400: 00f4 00f9 0102 0103 0105 0106 010f 0118  ................
-00002410: 0119 011b 011c 0129 0132 0133 0134 0140  .......).2.3.4.@
-00002420: 0149 014a 014c 014d 0152 015b 015c 015e  .I.J.L.M.R.[.\.^
-00002430: 015f 0164 016d 016e 0170 0171 0177 0180  ._.d.m.n.p.q.w..
-00002440: 0181 0183 0184 018c 0195 0196 0199 019a  ................
-00002450: 01a3 01ac 01ad 01af 01b0 01bf 01c8 01c9  ................
-00002460: 01ca 01d4 01d5 01de 01e7 01ec 01f5 0000  ................
-00002470: 0000 0000 0201 0000 0000 0000 004d 0000  .............M..
-00002480: 0000 0000 0000 0000 0000 0000 01f6 0000  ................
-00002490: 0006 0061 0073 0073 0065 0074 0073 6c73  ...a.s.s.e.t.sls
-000024a0: 7670 626c 6f62 0000 0295 6270 6c69 7374  vpblob....bplist
-000024b0: 3030 da01 0203 0405 0607 0809 0a0b 0c0d  00..............
-000024c0: 1f47 4847 494a 0c5f 1012 7669 6577 4f70  .GHGIJ._..viewOp
-000024d0: 7469 6f6e 7356 6572 7369 6f6e 5f10 0f73  tionsVersion_..s
-000024e0: 686f 7749 636f 6e50 7265 7669 6577 5763  howIconPreviewWc
-000024f0: 6f6c 756d 6e73 5f10 1163 616c 6375 6c61  olumns_..calcula
-00002500: 7465 416c 6c53 697a 6573 5f10 0f73 6372  teAllSizes_..scr
-00002510: 6f6c 6c50 6f73 6974 696f 6e59 5874 6578  ollPositionYXtex
-00002520: 7453 697a 655f 100f 7363 726f 6c6c 506f  tSize_..scrollPo
-00002530: 7369 7469 6f6e 585a 736f 7274 436f 6c75  sitionXZsortColu
-00002540: 6d6e 5869 636f 6e53 697a 655f 1010 7573  mnXiconSize_..us
-00002550: 6552 656c 6174 6976 6544 6174 6573 1001  eRelativeDates..
-00002560: 09d9 0e0f 1011 1213 1415 1617 2025 292d  ............ %)-
-00002570: 3237 3c41 5863 6f6d 6d65 6e74 735e 6461  27<AXcomments^da
-00002580: 7465 4c61 7374 4f70 656e 6564 5c64 6174  teLastOpened\dat
-00002590: 654d 6f64 6966 6965 645b 6461 7465 4372  eModified[dateCr
-000025a0: 6561 7465 6454 7369 7a65 556c 6162 656c  eatedTsizeUlabel
-000025b0: 546b 696e 6457 7665 7273 696f 6e54 6e61  TkindWversionTna
-000025c0: 6d65 d418 191a 1b1c 1d0c 1f55 696e 6465  me.........Uinde
-000025d0: 7855 7769 6474 6859 6173 6365 6e64 696e  xUwidthYascendin
-000025e0: 6757 7669 7369 626c 6510 0711 012c 0908  gWvisible....,..
-000025f0: d418 191a 1b21 221f 1f10 0810 c808 08d4  .....!".........
-00002600: 1819 1a1b 0b26 1f0c 10b5 0809 d418 191a  .....&..........
-00002610: 1b2a 261f 1f10 0208 08d4 1819 1a1b 2e2f  .*&............/
-00002620: 1f0c 1003 1061 0809 d418 191a 1b33 340c  .....a.......34.
-00002630: 1f10 0510 6409 08d4 1819 1a1b 3839 0c0c  ....d.......89..
-00002640: 1004 1073 0909 d418 191a 1b3d 3e0c 1f10  ...s.......=>...
-00002650: 0610 4b09 08d4 1819 1a1b 4243 0c0c 1000  ..K.......BC....
-00002660: 1101 2709 0908 2300 0000 0000 0000 0023  ..'...#........#
-00002670: 4028 0000 0000 0000 546e 616d 6523 4030  @(......Tname#@0
-00002680: 0000 0000 0000 0900 0800 1d00 3200 4400  ............2.D.
-00002690: 4c00 6000 7200 7b00 8d00 9800 a100 b400  L.`.r.{.........
-000026a0: b600 b700 ca00 d300 e200 ef00 fb01 0001  ................
-000026b0: 0601 0b01 1301 1801 2101 2701 2d01 3701  ........!.'.-.7.
-000026c0: 3f01 4101 4401 4501 4601 4f01 5101 5301  ?.A.D.E.F.O.Q.S.
-000026d0: 5401 5501 5e01 6001 6101 6201 6b01 6d01  T.U.^.`.a.b.k.m.
-000026e0: 6e01 6f01 7801 7a01 7c01 7d01 7e01 8701  n.o.x.z.|.}.~...
-000026f0: 8901 8b01 8c01 8d01 9601 9801 9a01 9b01  ................
-00002700: 9c01 a501 a701 a901 aa01 ab01 b401 b601  ................
-00002710: b901 ba01 bb01 bc01 c501 ce01 d301 dc00  ................
-00002720: 0000 0000 0002 0100 0000 0000 0000 4c00  ..............L.
-00002730: 0000 0000 0000 0000 0000 0000 0001 dd00  ................
-00002740: 0000 0600 6100 7300 7300 6500 7400 736d  ....a.s.s.e.t.sm
-00002750: 6f44 4462 6c6f 6200 0000 08cf 958c e8d0  oDDblob.........
-00002760: e1c4 4100 0000 0600 6100 7300 7300 6500  ..A.....a.s.s.e.
-00002770: 7400 736d 6f64 4462 6c6f 6200 0000 08cf  t.smodDblob.....
-00002780: 958c e8d0 e1c4 4100 0000 0600 6100 7300  ......A.....a.s.
-00002790: 7300 6500 7400 7370 6831 5363 6f6d 7000  s.e.t.sph1Scomp.
-000027a0: 0000 0000 8190 0000 0000 0600 6100 7300  ............a.s.
-000027b0: 7300 6500 7400 7376 5372 6e6c 6f6e 6700  s.e.t.svSrnlong.
-000027c0: 0000 0100 0000 1400 6200 6100 7400 6300  ........b.a.t.c.
-000027d0: 6800 5f00 7000 7200 6f00 6300 6500 7300  h._.p.r.o.c.e.s.
-000027e0: 7300 5f00 7600 6900 6400 6500 6f00 7362  s._.v.i.d.e.o.sb
-000027f0: 7773 7062 6c6f 6200 0000 ca62 706c 6973  wspblob....bplis
-00002800: 7430 30d7 0102 0304 0506 0708 080a 080a  t00.............
-00002810: 0d0a 5d53 686f 7753 7461 7475 7342 6172  ..]ShowStatusBar
-00002820: 5b53 686f 7750 6174 6862 6172 5b53 686f  [ShowPathbar[Sho
-00002830: 7754 6f6f 6c62 6172 5b53 686f 7754 6162  wToolbar[ShowTab
-00002840: 5669 6577 5f10 1443 6f6e 7461 696e 6572  View_..Container
-00002850: 5368 6f77 5369 6465 6261 725c 5769 6e64  ShowSidebar\Wind
-00002860: 6f77 426f 756e 6473 5b53 686f 7753 6964  owBounds[ShowSid
-00002870: 6562 6172 0808 0908 095f 1019 7b7b 3130  ebar....._..{{10
-00002880: 3632 2c20 3337 337d 2c20 7b37 3730 2c20  62, 373}, {770, 
-00002890: 3433 367d 7d09 0817 2531 3d49 606d 797a  436}}...%1=I`myz
-000028a0: 7b7c 7d7e 9a00 0000 0000 0001 0100 0000  {|}~............
-000028b0: 0000 0000 0f00 0000 0000 0000 0000 0000  ................
-000028c0: 0000 0000 9b00 0000 1400 6200 6100 7400  ..........b.a.t.
-000028d0: 6300 6800 5f00 7000 7200 6f00 6300 6500  c.h._.p.r.o.c.e.
-000028e0: 7300 7300 5f00 7600 6900 6400 6500 6f00  s.s._.v.i.d.e.o.
-000028f0: 736c 6731 5363 6f6d 7000 0000 0000 017e  slg1Scomp......~
-00002900: 5700 0000 1400 6200 6100 7400 6300 6800  W.....b.a.t.c.h.
-00002910: 5f00 7000 7200 6f00 6300 6500 7300 7300  _.p.r.o.c.e.s.s.
-00002920: 5f00 7600 6900 6400 6500 6f00 736c 7376  _.v.i.d.e.o.slsv
-00002930: 4362 6c6f 6200 0003 0762 706c 6973 7430  Cblob....bplist0
-00002940: 30d8 0102 0304 0506 0708 090a 0b19 5657  0.............VW
-00002950: 0a59 5869 636f 6e53 697a 655f 100f 7368  .YXiconSize_..sh
-00002960: 6f77 4963 6f6e 5072 6576 6965 7757 636f  owIconPreviewWco
-00002970: 6c75 6d6e 735f 1011 6361 6c63 756c 6174  lumns_..calculat
-00002980: 6541 6c6c 5369 7a65 7358 7465 7874 5369  eAllSizesXtextSi
-00002990: 7a65 5a73 6f72 7443 6f6c 756d 6e5f 1010  zeZsortColumn_..
-000029a0: 7573 6552 656c 6174 6976 6544 6174 6573  useRelativeDates
-000029b0: 5f10 1276 6965 774f 7074 696f 6e73 5665  _..viewOptionsVe
-000029c0: 7273 696f 6e23 4030 0000 0000 0000 09ae  rsion#@0........
-000029d0: 0c15 1d22 262b 3035 3a3f 4448 4d51 d40d  ..."&+05:?DHMQ..
-000029e0: 0e0f 1011 120a 0a5a 6964 656e 7469 6669  .......Zidentifi
-000029f0: 6572 5577 6964 7468 5961 7363 656e 6469  erUwidthYascendi
-00002a00: 6e67 5776 6973 6962 6c65 546e 616d 6511  ngWvisibleTname.
-00002a10: 032a 0909 d416 1718 0d19 1a19 1c57 7669  .*...........Wvi
-00002a20: 7369 626c 6555 7769 6474 6859 6173 6365  sibleUwidthYasce
-00002a30: 6e64 696e 6708 1023 0858 7562 6971 7569  nding..#.Xubiqui
-00002a40: 7479 d40d 0e0f 101e 1f19 0a5c 6461 7465  ty.........\date
-00002a50: 4d6f 6469 6669 6564 10b5 0809 d40d 0e0f  Modified........
-00002a60: 1023 1f19 195b 6461 7465 4372 6561 7465  .#...[dateCreate
-00002a70: 6408 08d4 0d0e 0f10 2728 190a 5473 697a  d.......'(..Tsiz
-00002a80: 6510 6108 09d4 0d0e 0f10 2c2d 0a0a 546b  e.a.......,-..Tk
-00002a90: 696e 6410 7309 09d4 0d0e 0f10 3132 0a19  ind.s.......12..
-00002aa0: 556c 6162 656c 1064 0908 d40d 0e0f 1036  Ulabel.d.......6
-00002ab0: 370a 1957 7665 7273 696f 6e10 4b09 08d4  7..Wversion.K...
-00002ac0: 0d0e 0f10 3b3c 0a19 5863 6f6d 6d65 6e74  ....;<..Xcomment
-00002ad0: 7311 012c 0908 d40d 0e0f 1040 4119 195e  s..,.......@A..^
-00002ae0: 6461 7465 4c61 7374 4f70 656e 6564 10c8  dateLastOpened..
-00002af0: 0808 d416 1718 0d19 1f19 4708 0859 6461  ..........G..Yda
-00002b00: 7465 4164 6465 64d4 0d17 1816 494a 1919  teAdded.....IJ..
-00002b10: 5a73 6861 7265 4f77 6e65 7210 d208 08d4  ZshareOwner.....
-00002b20: 0d17 1816 4e4a 1919 5f10 0f73 6861 7265  ....NJ.._..share
-00002b30: 4c61 7374 4564 6974 6f72 0808 d40d 1718  LastEditor......
-00002b40: 1652 4a19 195f 1010 696e 7669 7461 7469  .RJ.._..invitati
-00002b50: 6f6e 5374 6174 7573 0808 0823 4028 0000  onStatus...#@(..
-00002b60: 0000 0000 546e 616d 6509 1001 0008 0019  ....Tname.......
-00002b70: 0022 0034 003c 0050 0059 0064 0077 008c  .".4.<.P.Y.d.w..
-00002b80: 0095 0096 00a5 00ae 00b9 00bf 00c9 00d1  ................
-00002b90: 00d6 00d9 00da 00db 00e4 00ec 00f2 00fc  ................
-00002ba0: 00fd 00ff 0100 0109 0112 011f 0121 0122  .............!."
-00002bb0: 0123 012c 0138 0139 013a 0143 0148 014a  .#.,.8.9.:.C.H.J
-00002bc0: 014b 014c 0155 015a 015c 015d 015e 0167  .K.L.U.Z.\.].^.g
-00002bd0: 016d 016f 0170 0171 017a 0182 0184 0185  .m.o.p.q.z......
-00002be0: 0186 018f 0198 019b 019c 019d 01a6 01b5  ................
-00002bf0: 01b7 01b8 01b9 01c2 01c3 01c4 01ce 01d7  ................
-00002c00: 01e2 01e4 01e5 01e6 01ef 0201 0202 0203  ................
-00002c10: 020c 021f 0220 0221 0222 022b 0230 0231  ..... .!.".+.0.1
-00002c20: 0000 0000 0000 0201 0000 0000 0000 005a  ...............Z
-00002c30: 0000 0000 0000 0000 0000 0000 0000 0233  ...............3
-00002c40: 0000 0014 0062 0061 0074 0063 0068 005f  .....b.a.t.c.h._
-00002c50: 0070 0072 006f 0063 0065 0073 0073 005f  .p.r.o.c.e.s.s._
-00002c60: 0076 0069 0064 0065 006f 0073 6c73 7670  .v.i.d.e.o.slsvp
-00002c70: 626c 6f62 0000 025e 6270 6c69 7374 3030  blob...^bplist00
-00002c80: d801 0203 0405 0607 0809 0a0b 1a46 470a  .............FG.
-00002c90: 3558 6963 6f6e 5369 7a65 5f10 0f73 686f  5XiconSize_..sho
-00002ca0: 7749 636f 6e50 7265 7669 6577 5763 6f6c  wIconPreviewWcol
-00002cb0: 756d 6e73 5f10 1163 616c 6375 6c61 7465  umns_..calculate
-00002cc0: 416c 6c53 697a 6573 5874 6578 7453 697a  AllSizesXtextSiz
-00002cd0: 655a 736f 7274 436f 6c75 6d6e 5f10 1075  eZsortColumn_..u
-00002ce0: 7365 5265 6c61 7469 7665 4461 7465 735f  seRelativeDates_
-00002cf0: 1012 7669 6577 4f70 7469 6f6e 7356 6572  ..viewOptionsVer
-00002d00: 7369 6f6e 2340 3000 0000 0000 0009 d90c  sion#@0.........
-00002d10: 0d0e 0f10 1112 1314 151e 2328 2d32 363b  ..........#(-26;
-00002d20: 4058 636f 6d6d 656e 7473 556c 6162 656c  @XcommentsUlabel
-00002d30: 5776 6572 7369 6f6e 5b64 6174 6543 7265  Wversion[dateCre
-00002d40: 6174 6564 5473 697a 655c 6461 7465 4d6f  atedTsize\dateMo
-00002d50: 6469 6669 6564 546b 696e 6454 6e61 6d65  difiedTkindTname
-00002d60: 5e64 6174 654c 6173 744f 7065 6e65 64d4  ^dateLastOpened.
-00002d70: 1617 1819 1a1b 0a1d 5776 6973 6962 6c65  ........Wvisible
-00002d80: 5577 6964 7468 5961 7363 656e 6469 6e67  UwidthYascending
-00002d90: 5569 6e64 6578 0811 012c 0910 07d4 1617  Uindex...,......
-00002da0: 1819 1a20 0a22 0810 6409 1005 d416 1718  ... ."..d.......
-00002db0: 191a 250a 2708 104b 0910 06d4 1617 1819  ..%.'..K........
-00002dc0: 1a2a 1a2c 0810 b508 1002 d416 1718 190a  .*.,............
-00002dd0: 2f1a 3109 1061 0810 03d4 1617 1819 0a2a  /.1..a.........*
-00002de0: 1a35 0908 1001 d416 1718 190a 380a 3a09  .5..........8.:.
-00002df0: 1073 0910 04d4 1617 1819 0a3d 0a3f 0911  .s.........=.?..
-00002e00: 032a 0910 00d4 1617 1819 1a42 1a44 0810  .*.........B.D..
-00002e10: c808 1008 0823 4028 0000 0000 0000 546e  .....#@(......Tn
-00002e20: 616d 6509 0008 0019 0022 0034 003c 0050  ame......".4.<.P
-00002e30: 0059 0064 0077 008c 0095 0096 00a9 00b2  .Y.d.w..........
-00002e40: 00b8 00c0 00cc 00d1 00de 00e3 00e8 00f7  ................
-00002e50: 0100 0108 010e 0118 011e 011f 0122 0123  .............".#
-00002e60: 0125 012e 012f 0131 0132 0134 013d 013e  .%.../.1.2.4.=.>
-00002e70: 0140 0141 0143 014c 014d 014f 0150 0152  .@.A.C.L.M.O.P.R
-00002e80: 015b 015c 015e 015f 0161 016a 016b 016c  .[.\.^._.a.j.k.l
-00002e90: 016e 0177 0178 017a 017b 017d 0186 0187  .n.w.x.z.{.}....
-00002ea0: 018a 018b 018d 0196 0197 0199 019a 019c  ................
-00002eb0: 019d 01a6 01ab 0000 0000 0000 0201 0000  ................
-00002ec0: 0000 0000 0049 0000 0000 0000 0000 0000  .....I..........
-00002ed0: 0000 0000 01ac 0000 0014 0062 0061 0074  ...........b.a.t
-00002ee0: 0063 0068 005f 0070 0072 006f 0063 0065  .c.h._.p.r.o.c.e
-00002ef0: 0073 0073 005f 0076 0069 0064 0065 006f  .s.s._.v.i.d.e.o
-00002f00: 0073 6d6f 4444 626c 6f62 0000 0008 f203  .smoDDblob......
-00002f10: dcf3 ebf6 c441 0000 0014 0062 0061 0074  .....A.....b.a.t
-00002f20: 0063 0068 005f 0070 0072 006f 0063 0065  .c.h._.p.r.o.c.e
-00002f30: 0073 0073 005f 0076 0069 0064 0065 006f  .s.s._.v.i.d.e.o
-00002f40: 0073 6d6f 6444 626c 6f62 0000 0008 4b60  .smodDblob....K`
-00002f50: d4fa 99f1 c441 0000 0014 0062 0061 0074  .....A.....b.a.t
-00002f60: 0063 0068 005f 0070 0072 006f 0063 0065  .c.h._.p.r.o.c.e
-00002f70: 0073 0073 005f 0076 0069 0064 0065 006f  .s.s._.v.i.d.e.o
-00002f80: 0073 7068 3153 636f 6d70 0000 0000 0001  .sph1Scomp......
-00002f90: f000 0000 0000 0000 0000 0000 0000 0000  ................
+00002150: 7208 0809 0809 5f10 177b 7b32 302c 2039  r....._..{{20, 9
+00002160: 307d 2c20 7b31 3031 352c 2037 3637 7d7d  0}, {1015, 767}}
+00002170: 0908 1725 313d 4960 6d79 7a7b 7c7d 7e98  ...%1=I`myz{|}~.
+00002180: 0000 0000 0000 0101 0000 0000 0000 000f  ................
+00002190: 0000 0000 0000 0000 0000 0000 0000 0099  ................
+000021a0: 0000 0006 0061 0073 0073 0065 0074 0073  .....a.s.s.e.t.s
+000021b0: 6c67 3153 636f 6d70 0000 0000 007d db93  lg1Scomp.....}..
+000021c0: 0000 0006 0061 0073 0073 0065 0074 0073  .....a.s.s.e.t.s
+000021d0: 6c73 7643 626c 6f62 0000 02b0 6270 6c69  lsvCblob....bpli
+000021e0: 7374 3030 da01 0203 0405 0607 0809 0a0b  st00............
+000021f0: 0c0d 1848 4948 4a4b 0c5f 1012 7669 6577  ...HIHJK._..view
+00002200: 4f70 7469 6f6e 7356 6572 7369 6f6e 5f10  OptionsVersion_.
+00002210: 0f73 686f 7749 636f 6e50 7265 7669 6577  .showIconPreview
+00002220: 5763 6f6c 756d 6e73 5f10 1163 616c 6375  Wcolumns_..calcu
+00002230: 6c61 7465 416c 6c53 697a 6573 5f10 0f73  lateAllSizes_..s
+00002240: 6372 6f6c 6c50 6f73 6974 696f 6e59 5874  crollPositionYXt
+00002250: 6578 7453 697a 655f 100f 7363 726f 6c6c  extSize_..scroll
+00002260: 506f 7369 7469 6f6e 585a 736f 7274 436f  PositionXZsortCo
+00002270: 6c75 6d6e 5869 636f 6e53 697a 655f 1010  lumnXiconSize_..
+00002280: 7573 6552 656c 6174 6976 6544 6174 6573  useRelativeDates
+00002290: 1001 09ab 0e17 1c21 252a 2f34 393e 43d4  .......!%*/49>C.
+000022a0: 0f10 1112 0c14 0c16 5776 6973 6962 6c65  ........Wvisible
+000022b0: 5577 6964 7468 5961 7363 656e 6469 6e67  UwidthYascending
+000022c0: 5a69 6465 6e74 6966 6965 7209 1101 2709  Zidentifier...'.
+000022d0: 546e 616d 65d4 0f10 1112 1819 181b 0810  Tname...........
+000022e0: 2308 5875 6269 7175 6974 79d4 0f10 1112  #.Xubiquity.....
+000022f0: 0c1e 1820 0910 b508 5c64 6174 654d 6f64  ... ....\dateMod
+00002300: 6966 6965 64d4 0f10 1112 181e 1824 0808  ified........$..
+00002310: 5b64 6174 6543 7265 6174 6564 d40f 1011  [dateCreated....
+00002320: 120c 2718 2909 1061 0854 7369 7a65 d40f  ..'.)..a.Tsize..
+00002330: 1011 120c 2c0c 2e09 1073 0954 6b69 6e64  ....,....s.Tkind
+00002340: d40f 1011 1218 310c 3308 1064 0955 6c61  ......1.3..d.Ula
+00002350: 6265 6cd4 0f10 1112 1836 0c38 0810 4b09  bel......6.8..K.
+00002360: 5776 6572 7369 6f6e d40f 1011 1218 3b0c  Wversion......;.
+00002370: 3d08 1101 2c09 5863 6f6d 6d65 6e74 73d4  =...,.Xcomments.
+00002380: 0f10 1112 1840 1842 0810 c808 5e64 6174  .....@.B....^dat
+00002390: 654c 6173 744f 7065 6e65 64d4 0f10 1112  eLastOpened.....
+000023a0: 181e 1846 0808 5964 6174 6541 6464 6564  ...F..YdateAdded
+000023b0: 0823 0000 0000 0000 0000 2340 2800 0000  .#........#@(...
+000023c0: 0000 0054 6e61 6d65 2340 3000 0000 0000  ...Tname#@0.....
+000023d0: 0009 0008 001d 0032 0044 004c 0060 0072  .......2.D.L.`.r
+000023e0: 007b 008d 0098 00a1 00b4 00b6 00b7 00c3  .{..............
+000023f0: 00cc 00d4 00da 00e4 00ef 00f0 00f3 00f4  ................
+00002400: 00f9 0102 0103 0105 0106 010f 0118 0119  ................
+00002410: 011b 011c 0129 0132 0133 0134 0140 0149  .....).2.3.4.@.I
+00002420: 014a 014c 014d 0152 015b 015c 015e 015f  .J.L.M.R.[.\.^._
+00002430: 0164 016d 016e 0170 0171 0177 0180 0181  .d.m.n.p.q.w....
+00002440: 0183 0184 018c 0195 0196 0199 019a 01a3  ................
+00002450: 01ac 01ad 01af 01b0 01bf 01c8 01c9 01ca  ................
+00002460: 01d4 01d5 01de 01e7 01ec 01f5 0000 0000  ................
+00002470: 0000 0201 0000 0000 0000 004d 0000 0000  ...........M....
+00002480: 0000 0000 0000 0000 0000 01f6 0000 0006  ................
+00002490: 0061 0073 0073 0065 0074 0073 6c73 7670  .a.s.s.e.t.slsvp
+000024a0: 626c 6f62 0000 0295 6270 6c69 7374 3030  blob....bplist00
+000024b0: da01 0203 0405 0607 0809 0a0b 0c0d 1f47  ...............G
+000024c0: 4847 494a 0c5f 1012 7669 6577 4f70 7469  HGIJ._..viewOpti
+000024d0: 6f6e 7356 6572 7369 6f6e 5f10 0f73 686f  onsVersion_..sho
+000024e0: 7749 636f 6e50 7265 7669 6577 5763 6f6c  wIconPreviewWcol
+000024f0: 756d 6e73 5f10 1163 616c 6375 6c61 7465  umns_..calculate
+00002500: 416c 6c53 697a 6573 5f10 0f73 6372 6f6c  AllSizes_..scrol
+00002510: 6c50 6f73 6974 696f 6e59 5874 6578 7453  lPositionYXtextS
+00002520: 697a 655f 100f 7363 726f 6c6c 506f 7369  ize_..scrollPosi
+00002530: 7469 6f6e 585a 736f 7274 436f 6c75 6d6e  tionXZsortColumn
+00002540: 5869 636f 6e53 697a 655f 1010 7573 6552  XiconSize_..useR
+00002550: 656c 6174 6976 6544 6174 6573 1001 09d9  elativeDates....
+00002560: 0e0f 1011 1213 1415 1617 2025 292d 3237  .......... %)-27
+00002570: 3c41 5863 6f6d 6d65 6e74 735e 6461 7465  <AXcomments^date
+00002580: 4c61 7374 4f70 656e 6564 5c64 6174 654d  LastOpened\dateM
+00002590: 6f64 6966 6965 645b 6461 7465 4372 6561  odified[dateCrea
+000025a0: 7465 6454 7369 7a65 556c 6162 656c 546b  tedTsizeUlabelTk
+000025b0: 696e 6457 7665 7273 696f 6e54 6e61 6d65  indWversionTname
+000025c0: d418 191a 1b1c 1d0c 1f55 696e 6465 7855  .........UindexU
+000025d0: 7769 6474 6859 6173 6365 6e64 696e 6757  widthYascendingW
+000025e0: 7669 7369 626c 6510 0711 012c 0908 d418  visible....,....
+000025f0: 191a 1b21 221f 1f10 0810 c808 08d4 1819  ...!"...........
+00002600: 1a1b 0b26 1f0c 10b5 0809 d418 191a 1b2a  ...&...........*
+00002610: 261f 1f10 0208 08d4 1819 1a1b 2e2f 1f0c  &............/..
+00002620: 1003 1061 0809 d418 191a 1b33 340c 1f10  ...a.......34...
+00002630: 0510 6409 08d4 1819 1a1b 3839 0c0c 1004  ..d.......89....
+00002640: 1073 0909 d418 191a 1b3d 3e0c 1f10 0610  .s.......=>.....
+00002650: 4b09 08d4 1819 1a1b 4243 0c0c 1000 1101  K.......BC......
+00002660: 2709 0908 2300 0000 0000 0000 0023 4028  '...#........#@(
+00002670: 0000 0000 0000 546e 616d 6523 4030 0000  ......Tname#@0..
+00002680: 0000 0000 0900 0800 1d00 3200 4400 4c00  ..........2.D.L.
+00002690: 6000 7200 7b00 8d00 9800 a100 b400 b600  `.r.{...........
+000026a0: b700 ca00 d300 e200 ef00 fb01 0001 0601  ................
+000026b0: 0b01 1301 1801 2101 2701 2d01 3701 3f01  ......!.'.-.7.?.
+000026c0: 4101 4401 4501 4601 4f01 5101 5301 5401  A.D.E.F.O.Q.S.T.
+000026d0: 5501 5e01 6001 6101 6201 6b01 6d01 6e01  U.^.`.a.b.k.m.n.
+000026e0: 6f01 7801 7a01 7c01 7d01 7e01 8701 8901  o.x.z.|.}.~.....
+000026f0: 8b01 8c01 8d01 9601 9801 9a01 9b01 9c01  ................
+00002700: a501 a701 a901 aa01 ab01 b401 b601 b901  ................
+00002710: ba01 bb01 bc01 c501 ce01 d301 dc00 0000  ................
+00002720: 0000 0002 0100 0000 0000 0000 4c00 0000  ............L...
+00002730: 0000 0000 0000 0000 0000 0001 dd00 0000  ................
+00002740: 0600 6100 7300 7300 6500 7400 736d 6f44  ..a.s.s.e.t.smoD
+00002750: 4462 6c6f 6200 0000 08cf 958c e8d0 e1c4  Dblob...........
+00002760: 4100 0000 0600 6100 7300 7300 6500 7400  A.....a.s.s.e.t.
+00002770: 736d 6f64 4462 6c6f 6200 0000 08cf 958c  smodDblob.......
+00002780: e8d0 e1c4 4100 0000 0600 6100 7300 7300  ....A.....a.s.s.
+00002790: 6500 7400 7370 6831 5363 6f6d 7000 0000  e.t.sph1Scomp...
+000027a0: 0000 81a0 0000 0000 0600 6100 7300 7300  ..........a.s.s.
+000027b0: 6500 7400 7376 5372 6e6c 6f6e 6700 0000  e.t.svSrnlong...
+000027c0: 0100 0000 1400 6200 6100 7400 6300 6800  ......b.a.t.c.h.
+000027d0: 5f00 7000 7200 6f00 6300 6500 7300 7300  _.p.r.o.c.e.s.s.
+000027e0: 5f00 7600 6900 6400 6500 6f00 7362 7773  _.v.i.d.e.o.sbws
+000027f0: 7062 6c6f 6200 0000 ca62 706c 6973 7430  pblob....bplist0
+00002800: 30d7 0102 0304 0506 0708 080a 080a 0d0a  0...............
+00002810: 5d53 686f 7753 7461 7475 7342 6172 5b53  ]ShowStatusBar[S
+00002820: 686f 7750 6174 6862 6172 5b53 686f 7754  howPathbar[ShowT
+00002830: 6f6f 6c62 6172 5b53 686f 7754 6162 5669  oolbar[ShowTabVi
+00002840: 6577 5f10 1443 6f6e 7461 696e 6572 5368  ew_..ContainerSh
+00002850: 6f77 5369 6465 6261 725c 5769 6e64 6f77  owSidebar\Window
+00002860: 426f 756e 6473 5b53 686f 7753 6964 6562  Bounds[ShowSideb
+00002870: 6172 0808 0908 095f 1019 7b7b 3130 3632  ar....._..{{1062
+00002880: 2c20 3337 337d 2c20 7b37 3730 2c20 3433  , 373}, {770, 43
+00002890: 367d 7d09 0817 2531 3d49 606d 797a 7b7c  6}}...%1=I`myz{|
+000028a0: 7d7e 9a00 0000 0000 0001 0100 0000 0000  }~..............
+000028b0: 0000 0f00 0000 0000 0000 0000 0000 0000  ................
+000028c0: 0000 9b00 0000 1400 6200 6100 7400 6300  ........b.a.t.c.
+000028d0: 6800 5f00 7000 7200 6f00 6300 6500 7300  h._.p.r.o.c.e.s.
+000028e0: 7300 5f00 7600 6900 6400 6500 6f00 736c  s._.v.i.d.e.o.sl
+000028f0: 6731 5363 6f6d 7000 0000 0000 017e 8a00  g1Scomp......~..
+00002900: 0000 1400 6200 6100 7400 6300 6800 5f00  ....b.a.t.c.h._.
+00002910: 7000 7200 6f00 6300 6500 7300 7300 5f00  p.r.o.c.e.s.s._.
+00002920: 7600 6900 6400 6500 6f00 736c 7376 4362  v.i.d.e.o.slsvCb
+00002930: 6c6f 6200 0003 0762 706c 6973 7430 30d8  lob....bplist00.
+00002940: 0102 0304 0506 0708 090a 0b19 5657 0a59  ............VW.Y
+00002950: 5869 636f 6e53 697a 655f 100f 7368 6f77  XiconSize_..show
+00002960: 4963 6f6e 5072 6576 6965 7757 636f 6c75  IconPreviewWcolu
+00002970: 6d6e 735f 1011 6361 6c63 756c 6174 6541  mns_..calculateA
+00002980: 6c6c 5369 7a65 7358 7465 7874 5369 7a65  llSizesXtextSize
+00002990: 5a73 6f72 7443 6f6c 756d 6e5f 1010 7573  ZsortColumn_..us
+000029a0: 6552 656c 6174 6976 6544 6174 6573 5f10  eRelativeDates_.
+000029b0: 1276 6965 774f 7074 696f 6e73 5665 7273  .viewOptionsVers
+000029c0: 696f 6e23 4030 0000 0000 0000 09ae 0c15  ion#@0..........
+000029d0: 1d22 262b 3035 3a3f 4448 4d51 d40d 0e0f  ."&+05:?DHMQ....
+000029e0: 1011 120a 0a5a 6964 656e 7469 6669 6572  .....Zidentifier
+000029f0: 5577 6964 7468 5961 7363 656e 6469 6e67  UwidthYascending
+00002a00: 5776 6973 6962 6c65 546e 616d 6511 032a  WvisibleTname..*
+00002a10: 0909 d416 1718 0d19 1a19 1c57 7669 7369  ...........Wvisi
+00002a20: 626c 6555 7769 6474 6859 6173 6365 6e64  bleUwidthYascend
+00002a30: 696e 6708 1023 0858 7562 6971 7569 7479  ing..#.Xubiquity
+00002a40: d40d 0e0f 101e 1f19 0a5c 6461 7465 4d6f  .........\dateMo
+00002a50: 6469 6669 6564 10b5 0809 d40d 0e0f 1023  dified.........#
+00002a60: 1f19 195b 6461 7465 4372 6561 7465 6408  ...[dateCreated.
+00002a70: 08d4 0d0e 0f10 2728 190a 5473 697a 6510  ......'(..Tsize.
+00002a80: 6108 09d4 0d0e 0f10 2c2d 0a0a 546b 696e  a.......,-..Tkin
+00002a90: 6410 7309 09d4 0d0e 0f10 3132 0a19 556c  d.s.......12..Ul
+00002aa0: 6162 656c 1064 0908 d40d 0e0f 1036 370a  abel.d.......67.
+00002ab0: 1957 7665 7273 696f 6e10 4b09 08d4 0d0e  .Wversion.K.....
+00002ac0: 0f10 3b3c 0a19 5863 6f6d 6d65 6e74 7311  ..;<..Xcomments.
+00002ad0: 012c 0908 d40d 0e0f 1040 4119 195e 6461  .,.......@A..^da
+00002ae0: 7465 4c61 7374 4f70 656e 6564 10c8 0808  teLastOpened....
+00002af0: d416 1718 0d19 1f19 4708 0859 6461 7465  ........G..Ydate
+00002b00: 4164 6465 64d4 0d17 1816 494a 1919 5a73  Added.....IJ..Zs
+00002b10: 6861 7265 4f77 6e65 7210 d208 08d4 0d17  hareOwner.......
+00002b20: 1816 4e4a 1919 5f10 0f73 6861 7265 4c61  ..NJ.._..shareLa
+00002b30: 7374 4564 6974 6f72 0808 d40d 1718 1652  stEditor.......R
+00002b40: 4a19 195f 1010 696e 7669 7461 7469 6f6e  J.._..invitation
+00002b50: 5374 6174 7573 0808 0823 4028 0000 0000  Status...#@(....
+00002b60: 0000 546e 616d 6509 1001 0008 0019 0022  ..Tname........"
+00002b70: 0034 003c 0050 0059 0064 0077 008c 0095  .4.<.P.Y.d.w....
+00002b80: 0096 00a5 00ae 00b9 00bf 00c9 00d1 00d6  ................
+00002b90: 00d9 00da 00db 00e4 00ec 00f2 00fc 00fd  ................
+00002ba0: 00ff 0100 0109 0112 011f 0121 0122 0123  ...........!.".#
+00002bb0: 012c 0138 0139 013a 0143 0148 014a 014b  .,.8.9.:.C.H.J.K
+00002bc0: 014c 0155 015a 015c 015d 015e 0167 016d  .L.U.Z.\.].^.g.m
+00002bd0: 016f 0170 0171 017a 0182 0184 0185 0186  .o.p.q.z........
+00002be0: 018f 0198 019b 019c 019d 01a6 01b5 01b7  ................
+00002bf0: 01b8 01b9 01c2 01c3 01c4 01ce 01d7 01e2  ................
+00002c00: 01e4 01e5 01e6 01ef 0201 0202 0203 020c  ................
+00002c10: 021f 0220 0221 0222 022b 0230 0231 0000  ... .!.".+.0.1..
+00002c20: 0000 0000 0201 0000 0000 0000 005a 0000  .............Z..
+00002c30: 0000 0000 0000 0000 0000 0000 0233 0000  .............3..
+00002c40: 0014 0062 0061 0074 0063 0068 005f 0070  ...b.a.t.c.h._.p
+00002c50: 0072 006f 0063 0065 0073 0073 005f 0076  .r.o.c.e.s.s._.v
+00002c60: 0069 0064 0065 006f 0073 6c73 7670 626c  .i.d.e.o.slsvpbl
+00002c70: 6f62 0000 025e 6270 6c69 7374 3030 d801  ob...^bplist00..
+00002c80: 0203 0405 0607 0809 0a0b 1a46 470a 3558  ...........FG.5X
+00002c90: 6963 6f6e 5369 7a65 5f10 0f73 686f 7749  iconSize_..showI
+00002ca0: 636f 6e50 7265 7669 6577 5763 6f6c 756d  conPreviewWcolum
+00002cb0: 6e73 5f10 1163 616c 6375 6c61 7465 416c  ns_..calculateAl
+00002cc0: 6c53 697a 6573 5874 6578 7453 697a 655a  lSizesXtextSizeZ
+00002cd0: 736f 7274 436f 6c75 6d6e 5f10 1075 7365  sortColumn_..use
+00002ce0: 5265 6c61 7469 7665 4461 7465 735f 1012  RelativeDates_..
+00002cf0: 7669 6577 4f70 7469 6f6e 7356 6572 7369  viewOptionsVersi
+00002d00: 6f6e 2340 3000 0000 0000 0009 d90c 0d0e  on#@0...........
+00002d10: 0f10 1112 1314 151e 2328 2d32 363b 4058  ........#(-26;@X
+00002d20: 636f 6d6d 656e 7473 556c 6162 656c 5776  commentsUlabelWv
+00002d30: 6572 7369 6f6e 5b64 6174 6543 7265 6174  ersion[dateCreat
+00002d40: 6564 5473 697a 655c 6461 7465 4d6f 6469  edTsize\dateModi
+00002d50: 6669 6564 546b 696e 6454 6e61 6d65 5e64  fiedTkindTname^d
+00002d60: 6174 654c 6173 744f 7065 6e65 64d4 1617  ateLastOpened...
+00002d70: 1819 1a1b 0a1d 5776 6973 6962 6c65 5577  ......WvisibleUw
+00002d80: 6964 7468 5961 7363 656e 6469 6e67 5569  idthYascendingUi
+00002d90: 6e64 6578 0811 012c 0910 07d4 1617 1819  ndex...,........
+00002da0: 1a20 0a22 0810 6409 1005 d416 1718 191a  . ."..d.........
+00002db0: 250a 2708 104b 0910 06d4 1617 1819 1a2a  %.'..K.........*
+00002dc0: 1a2c 0810 b508 1002 d416 1718 190a 2f1a  .,............/.
+00002dd0: 3109 1061 0810 03d4 1617 1819 0a2a 1a35  1..a.........*.5
+00002de0: 0908 1001 d416 1718 190a 380a 3a09 1073  ..........8.:..s
+00002df0: 0910 04d4 1617 1819 0a3d 0a3f 0911 032a  .........=.?...*
+00002e00: 0910 00d4 1617 1819 1a42 1a44 0810 c808  .........B.D....
+00002e10: 1008 0823 4028 0000 0000 0000 546e 616d  ...#@(......Tnam
+00002e20: 6509 0008 0019 0022 0034 003c 0050 0059  e......".4.<.P.Y
+00002e30: 0064 0077 008c 0095 0096 00a9 00b2 00b8  .d.w............
+00002e40: 00c0 00cc 00d1 00de 00e3 00e8 00f7 0100  ................
+00002e50: 0108 010e 0118 011e 011f 0122 0123 0125  ...........".#.%
+00002e60: 012e 012f 0131 0132 0134 013d 013e 0140  .../.1.2.4.=.>.@
+00002e70: 0141 0143 014c 014d 014f 0150 0152 015b  .A.C.L.M.O.P.R.[
+00002e80: 015c 015e 015f 0161 016a 016b 016c 016e  .\.^._.a.j.k.l.n
+00002e90: 0177 0178 017a 017b 017d 0186 0187 018a  .w.x.z.{.}......
+00002ea0: 018b 018d 0196 0197 0199 019a 019c 019d  ................
+00002eb0: 01a6 01ab 0000 0000 0000 0201 0000 0000  ................
+00002ec0: 0000 0049 0000 0000 0000 0000 0000 0000  ...I............
+00002ed0: 0000 01ac 0000 0014 0062 0061 0074 0063  .........b.a.t.c
+00002ee0: 0068 005f 0070 0072 006f 0063 0065 0073  .h._.p.r.o.c.e.s
+00002ef0: 0073 005f 0076 0069 0064 0065 006f 0073  .s._.v.i.d.e.o.s
+00002f00: 6d6f 4444 626c 6f62 0000 0008 a501 0052  moDDblob.......R
+00002f10: 06fc c441 0000 0014 0062 0061 0074 0063  ...A.....b.a.t.c
+00002f20: 0068 005f 0070 0072 006f 0063 0065 0073  .h._.p.r.o.c.e.s
+00002f30: 0073 005f 0076 0069 0064 0065 006f 0073  .s._.v.i.d.e.o.s
+00002f40: 6d6f 6444 626c 6f62 0000 0008 a501 0052  modDblob.......R
+00002f50: 06fc c441 0000 0014 0062 0061 0074 0063  ...A.....b.a.t.c
+00002f60: 0068 005f 0070 0072 006f 0063 0065 0073  .h._.p.r.o.c.e.s
+00002f70: 0073 005f 0076 0069 0064 0065 006f 0073  .s._.v.i.d.e.o.s
+00002f80: 7068 3153 636f 6d70 0000 0000 0001 f000  ph1Scomp........
+00002f90: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00002fa0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00002fb0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00002fc0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00002fd0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00002fe0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00002ff0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
-00003000: 0000 0000 0000 0000 0000 0019 0000 000c  ................
+00003000: 0000 0000 0000 0000 0000 001a 0000 000c  ................
 00003010: 0062 006c 006f 0062 005f 0073 0074 006f  .b.l.o.b._.s.t.o
 00003020: 0072 0061 0067 0065 6277 7370 626c 6f62  .r.a.g.ebwspblob
 00003030: 0000 00c9 6270 6c69 7374 3030 d701 0203  ....bplist00....
 00003040: 0405 0607 0808 0a08 0a0d 0a5d 5368 6f77  ...........]Show
 00003050: 5374 6174 7573 4261 725b 5368 6f77 5061  StatusBar[ShowPa
 00003060: 7468 6261 725b 5368 6f77 546f 6f6c 6261  thbar[ShowToolba
 00003070: 725b 5368 6f77 5461 6256 6965 775f 1014  r[ShowTabView_..
@@ -810,234 +810,234 @@
 00003290: 1018 7b7b 3339 342c 2031 3831 7d2c 207b  ..{{394, 181}, {
 000032a0: 3737 302c 2034 3336 7d7d 0908 1725 313d  770, 436}}...%1=
 000032b0: 4960 6d79 7a7b 7c7d 7e99 0000 0000 0000  I`myz{|}~.......
 000032c0: 0101 0000 0000 0000 000f 0000 0000 0000  ................
 000032d0: 0000 0000 0000 0000 009a 0000 0012 0062  ...............b
 000032e0: 006f 0075 006e 0064 0069 006e 0067 005f  .o.u.n.d.i.n.g._
 000032f0: 0062 006f 0078 005f 0074 006f 006f 006c  .b.o.x._.t.o.o.l
-00003300: 0073 6c67 3153 636f 6d70 0000 0000 0002  .slg1Scomp......
-00003310: 831e 0000 0012 0062 006f 0075 006e 0064  .......b.o.u.n.d
-00003320: 0069 006e 0067 005f 0062 006f 0078 005f  .i.n.g._.b.o.x._
-00003330: 0074 006f 006f 006c 0073 6c73 7643 626c  .t.o.o.l.slsvCbl
-00003340: 6f62 0000 0278 6270 6c69 7374 3030 d801  ob...xbplist00..
-00003350: 0203 0405 0607 0809 0a0b 1846 470a 4958  ...........FG.IX
-00003360: 6963 6f6e 5369 7a65 5f10 0f73 686f 7749  iconSize_..showI
-00003370: 636f 6e50 7265 7669 6577 5763 6f6c 756d  conPreviewWcolum
-00003380: 6e73 5f10 1163 616c 6375 6c61 7465 416c  ns_..calculateAl
-00003390: 6c53 697a 6573 5874 6578 7453 697a 655a  lSizesXtextSizeZ
-000033a0: 736f 7274 436f 6c75 6d6e 5f10 1075 7365  sortColumn_..use
-000033b0: 5265 6c61 7469 7665 4461 7465 735f 1012  RelativeDates_..
-000033c0: 7669 6577 4f70 7469 6f6e 7356 6572 7369  viewOptionsVersi
-000033d0: 6f6e 2340 3000 0000 0000 0009 ab0c 151a  on#@0...........
-000033e0: 1f23 282d 3237 3c41 d40d 0e0f 1011 120a  .#(-27<A........
-000033f0: 0a5a 6964 656e 7469 6669 6572 5577 6964  .ZidentifierUwid
-00003400: 7468 5961 7363 656e 6469 6e67 5776 6973  thYascendingWvis
-00003410: 6962 6c65 546e 616d 6510 f009 09d4 0d0e  ibleTname.......
-00003420: 0f10 1617 1818 5875 6269 7175 6974 7910  ......Xubiquity.
-00003430: 2308 08d4 0d0e 0f10 1b1c 180a 5c64 6174  #...........\dat
-00003440: 654d 6f64 6966 6965 6410 b508 09d4 0d0e  eModified.......
-00003450: 0f10 201c 1818 5b64 6174 6543 7265 6174  .. ...[dateCreat
-00003460: 6564 0808 d40d 0e0f 1024 2518 0a54 7369  ed.......$%..Tsi
-00003470: 7a65 1061 0809 d40d 0e0f 1029 2a0a 0a54  ze.a.......)*..T
-00003480: 6b69 6e64 1073 0909 d40d 0e0f 102e 2f0a  kind.s......../.
-00003490: 1855 6c61 6265 6c10 6409 08d4 0d0e 0f10  .Ulabel.d.......
-000034a0: 3334 0a18 5776 6572 7369 6f6e 104b 0908  34..Wversion.K..
-000034b0: d40d 0e0f 1038 390a 1858 636f 6d6d 656e  .....89..Xcommen
-000034c0: 7473 1101 2c09 08d4 0d0e 0f10 3d3e 1818  ts..,.......=>..
-000034d0: 5e64 6174 654c 6173 744f 7065 6e65 6410  ^dateLastOpened.
-000034e0: c808 08d4 0d0e 0f10 421c 1818 5964 6174  ........B...Ydat
-000034f0: 6541 6464 6564 0808 0823 4028 0000 0000  eAdded...#@(....
-00003500: 0000 546e 616d 6509 1001 0008 0019 0022  ..Tname........"
-00003510: 0034 003c 0050 0059 0064 0077 008c 0095  .4.<.P.Y.d.w....
-00003520: 0096 00a2 00ab 00b6 00bc 00c6 00ce 00d3  ................
-00003530: 00d5 00d6 00d7 00e0 00e9 00eb 00ec 00ed  ................
-00003540: 00f6 0103 0105 0106 0107 0110 011c 011d  ................
-00003550: 011e 0127 012c 012e 012f 0130 0139 013e  ...'.,.../.0.9.>
-00003560: 0140 0141 0142 014b 0151 0153 0154 0155  .@.A.B.K.Q.S.T.U
-00003570: 015e 0166 0168 0169 016a 0173 017c 017f  .^.f.h.i.j.s.|..
-00003580: 0180 0181 018a 0199 019b 019c 019d 01a6  ................
-00003590: 01b0 01b1 01b2 01b3 01bc 01c1 01c2 0000  ................
-000035a0: 0000 0000 0201 0000 0000 0000 004a 0000  .............J..
-000035b0: 0000 0000 0000 0000 0000 0000 01c4 0000  ................
-000035c0: 0012 0062 006f 0075 006e 0064 0069 006e  ...b.o.u.n.d.i.n
-000035d0: 0067 005f 0062 006f 0078 005f 0074 006f  .g._.b.o.x._.t.o
-000035e0: 006f 006c 0073 6c73 7670 626c 6f62 0000  .o.l.slsvpblob..
-000035f0: 025d 6270 6c69 7374 3030 d801 0203 0405  .]bplist00......
-00003600: 0607 0809 0a0b 1a46 470a 2758 6963 6f6e  .......FG.'Xicon
-00003610: 5369 7a65 5f10 0f73 686f 7749 636f 6e50  Size_..showIconP
-00003620: 7265 7669 6577 5763 6f6c 756d 6e73 5f10  reviewWcolumns_.
-00003630: 1163 616c 6375 6c61 7465 416c 6c53 697a  .calculateAllSiz
-00003640: 6573 5874 6578 7453 697a 655a 736f 7274  esXtextSizeZsort
-00003650: 436f 6c75 6d6e 5f10 1075 7365 5265 6c61  Column_..useRela
-00003660: 7469 7665 4461 7465 735f 1012 7669 6577  tiveDates_..view
-00003670: 4f70 7469 6f6e 7356 6572 7369 6f6e 2340  OptionsVersion#@
-00003680: 3000 0000 0000 0009 d90c 0d0e 0f10 1112  0...............
-00003690: 1314 151e 2328 2c31 363b 4058 636f 6d6d  ....#(,16;@Xcomm
-000036a0: 656e 7473 5e64 6174 654c 6173 744f 7065  ents^dateLastOpe
-000036b0: 6e65 645c 6461 7465 4d6f 6469 6669 6564  ned\dateModified
-000036c0: 5b64 6174 6543 7265 6174 6564 5473 697a  [dateCreatedTsiz
-000036d0: 6555 6c61 6265 6c54 6b69 6e64 5776 6572  eUlabelTkindWver
-000036e0: 7369 6f6e 546e 616d 65d4 1617 1819 1a1b  sionTname.......
-000036f0: 0a1d 5776 6973 6962 6c65 5577 6964 7468  ..WvisibleUwidth
-00003700: 5961 7363 656e 6469 6e67 5569 6e64 6578  YascendingUindex
-00003710: 0811 012c 0910 07d4 1617 1819 1a20 1a22  ...,......... ."
-00003720: 0810 c808 1008 d416 1718 190a 251a 2709  ............%.'.
-00003730: 10b5 0810 01d4 1617 1819 1a25 1a2b 0808  ...........%.+..
-00003740: 1002 d416 1718 190a 2e1a 3009 1061 0810  ..........0..a..
-00003750: 03d4 1617 1819 1a33 0a35 0810 6409 1005  .......3.5..d...
-00003760: d416 1718 190a 380a 3a09 1073 0910 04d4  ......8.:..s....
-00003770: 1617 1819 1a3d 0a3f 0810 4b09 1006 d416  .....=.?..K.....
-00003780: 1718 190a 420a 4409 10f0 0910 0008 2340  ....B.D.......#@
-00003790: 2800 0000 0000 0054 6e61 6d65 0900 0800  (......Tname....
-000037a0: 1900 2200 3400 3c00 5000 5900 6400 7700  ..".4.<.P.Y.d.w.
-000037b0: 8c00 9500 9600 a900 b200 c100 ce00 da00  ................
-000037c0: df00 e500 ea00 f200 f701 0001 0801 0e01  ................
-000037d0: 1801 1e01 1f01 2201 2301 2501 2e01 2f01  ......".#.%.../.
-000037e0: 3101 3201 3401 3d01 3e01 4001 4101 4301  1.2.4.=.>.@.A.C.
-000037f0: 4c01 4d01 4e01 5001 5901 5a01 5c01 5d01  L.M.N.P.Y.Z.\.].
-00003800: 5f01 6801 6901 6b01 6c01 6e01 7701 7801  _.h.i.k.l.n.w.x.
-00003810: 7a01 7b01 7d01 8601 8701 8901 8a01 8c01  z.{.}...........
-00003820: 9501 9601 9801 9901 9b01 9c01 a501 aa00  ................
-00003830: 0000 0000 0002 0100 0000 0000 0000 4900  ..............I.
-00003840: 0000 0000 0000 0000 0000 0000 0001 ab00  ................
-00003850: 0000 1200 6200 6f00 7500 6e00 6400 6900  ....b.o.u.n.d.i.
-00003860: 6e00 6700 5f00 6200 6f00 7800 5f00 7400  n.g._.b.o.x._.t.
-00003870: 6f00 6f00 6c00 736d 6f44 4462 6c6f 6200  o.o.l.smoDDblob.
-00003880: 0000 08fc f5a0 5623 f2c4 4100 0000 1200  ......V#..A.....
-00003890: 6200 6f00 7500 6e00 6400 6900 6e00 6700  b.o.u.n.d.i.n.g.
-000038a0: 5f00 6200 6f00 7800 5f00 7400 6f00 6f00  _.b.o.x._.t.o.o.
-000038b0: 6c00 736d 6f64 4462 6c6f 6200 0000 08fc  l.smodDblob.....
-000038c0: f5a0 5623 f2c4 4100 0000 1200 6200 6f00  ..V#..A.....b.o.
-000038d0: 7500 6e00 6400 6900 6e00 6700 5f00 6200  u.n.d.i.n.g._.b.
-000038e0: 6f00 7800 5f00 7400 6f00 6f00 6c00 7370  o.x._.t.o.o.l.sp
-000038f0: 6831 5363 6f6d 7000 0000 0000 0310 0000  h1Scomp.........
-00003900: 0000 1200 6200 6f00 7500 6e00 6400 6900  ....b.o.u.n.d.i.
-00003910: 6e00 6700 5f00 6200 6f00 7800 5f00 7400  n.g._.b.o.x._.t.
-00003920: 6f00 6f00 6c00 7376 5372 6e6c 6f6e 6700  o.o.l.svSrnlong.
-00003930: 0000 0100 0000 0f00 6300 7500 6500 5f00  ........c.u.e._.
-00003940: 6c00 6900 6700 6800 7400 5f00 7400 6f00  l.i.g.h.t._.t.o.
-00003950: 6f00 6c00 7362 7773 7062 6c6f 6200 0000  o.l.sbwspblob...
-00003960: c962 706c 6973 7430 30d7 0102 0304 0506  .bplist00.......
-00003970: 0708 080a 080a 0d0a 5d53 686f 7753 7461  ........]ShowSta
-00003980: 7475 7342 6172 5b53 686f 7750 6174 6862  tusBar[ShowPathb
-00003990: 6172 5b53 686f 7754 6f6f 6c62 6172 5b53  ar[ShowToolbar[S
-000039a0: 686f 7754 6162 5669 6577 5f10 1443 6f6e  howTabView_..Con
-000039b0: 7461 696e 6572 5368 6f77 5369 6465 6261  tainerShowSideba
-000039c0: 725c 5769 6e64 6f77 426f 756e 6473 5b53  r\WindowBounds[S
-000039d0: 686f 7753 6964 6562 6172 0808 0908 095f  howSidebar....._
-000039e0: 1018 7b7b 3339 342c 2031 3831 7d2c 207b  ..{{394, 181}, {
-000039f0: 3737 302c 2034 3336 7d7d 0908 1725 313d  770, 436}}...%1=
-00003a00: 4960 6d79 7a7b 7c7d 7e99 0000 0000 0000  I`myz{|}~.......
-00003a10: 0101 0000 0000 0000 000f 0000 0000 0000  ................
-00003a20: 0000 0000 0000 0000 009a 0000 000f 0063  ...............c
-00003a30: 0075 0065 005f 006c 0069 0067 0068 0074  .u.e._.l.i.g.h.t
-00003a40: 005f 0074 006f 006f 006c 0073 6473 636c  ._.t.o.o.l.sdscl
-00003a50: 626f 6f6c 0000 0000 0f00 6300 7500 6500  bool......c.u.e.
-00003a60: 5f00 6c00 6900 6700 6800 7400 5f00 7400  _.l.i.g.h.t._.t.
-00003a70: 6f00 6f00 6c00 736c 6731 5363 6f6d 7000  o.o.l.slg1Scomp.
-00003a80: 0000 0000 01fe 0500 0000 0f00 6300 7500  ............c.u.
-00003a90: 6500 5f00 6c00 6900 6700 6800 7400 5f00  e._.l.i.g.h.t._.
-00003aa0: 7400 6f00 6f00 6c00 736d 6f44 4462 6c6f  t.o.o.l.smoDDblo
-00003ab0: 6200 0000 08a6 e198 5623 f2c4 4100 0000  b.......V#..A...
-00003ac0: 0f00 6300 7500 6500 5f00 6c00 6900 6700  ..c.u.e._.l.i.g.
-00003ad0: 6800 7400 5f00 7400 6f00 6f00 6c00 736d  h.t._.t.o.o.l.sm
-00003ae0: 6f64 4462 6c6f 6200 0000 08a6 e198 5623  odDblob.......V#
-00003af0: f2c4 4100 0000 0f00 6300 7500 6500 5f00  ..A.....c.u.e._.
-00003b00: 6c00 6900 6700 6800 7400 5f00 7400 6f00  l.i.g.h.t._.t.o.
-00003b10: 6f00 6c00 7370 6831 5363 6f6d 7000 0000  o.l.sph1Scomp...
-00003b20: 0000 0290 0000 0000 0f00 6300 7500 6500  ..........c.u.e.
-00003b30: 5f00 6c00 6900 6700 6800 7400 5f00 7400  _.l.i.g.h.t._.t.
-00003b40: 6f00 6f00 6c00 7376 5372 6e6c 6f6e 6700  o.o.l.svSrnlong.
-00003b50: 0000 0100 0000 1200 6600 6500 6100 7400  ........f.e.a.t.
-00003b60: 7500 7200 6500 5f00 6500 7800 7400 7200  u.r.e._.e.x.t.r.
-00003b70: 6100 6300 7400 6f00 7200 7362 7773 7062  a.c.t.o.r.sbwspb
-00003b80: 6c6f 6200 0000 c862 706c 6973 7430 30d7  lob....bplist00.
-00003b90: 0102 0304 0506 0708 080a 080a 0d0a 5d53  ..............]S
-00003ba0: 686f 7753 7461 7475 7342 6172 5b53 686f  howStatusBar[Sho
-00003bb0: 7750 6174 6862 6172 5b53 686f 7754 6f6f  wPathbar[ShowToo
-00003bc0: 6c62 6172 5b53 686f 7754 6162 5669 6577  lbar[ShowTabView
-00003bd0: 5f10 1443 6f6e 7461 696e 6572 5368 6f77  _..ContainerShow
-00003be0: 5369 6465 6261 725c 5769 6e64 6f77 426f  Sidebar\WindowBo
-00003bf0: 756e 6473 5b53 686f 7753 6964 6562 6172  unds[ShowSidebar
-00003c00: 0808 0908 095f 1017 7b7b 3334 2c20 3930  ....._..{{34, 90
-00003c10: 7d2c 207b 3130 3135 2c20 3736 377d 7d09  }, {1015, 767}}.
-00003c20: 0817 2531 3d49 606d 797a 7b7c 7d7e 9800  ..%1=I`myz{|}~..
-00003c30: 0000 0000 0001 0100 0000 0000 0000 0f00  ................
-00003c40: 0000 0000 0000 0000 0000 0000 0000 9900  ................
-00003c50: 0000 1200 6600 6500 6100 7400 7500 7200  ....f.e.a.t.u.r.
-00003c60: 6500 5f00 6500 7800 7400 7200 6100 6300  e._.e.x.t.r.a.c.
-00003c70: 7400 6f00 7200 7364 7363 6c62 6f6f 6c00  t.o.r.sdsclbool.
+00003300: 0073 6473 636c 626f 6f6c 0000 0000 1200  .sdsclbool......
+00003310: 6200 6f00 7500 6e00 6400 6900 6e00 6700  b.o.u.n.d.i.n.g.
+00003320: 5f00 6200 6f00 7800 5f00 7400 6f00 6f00  _.b.o.x._.t.o.o.
+00003330: 6c00 736c 6731 5363 6f6d 7000 0000 0000  l.slg1Scomp.....
+00003340: 026c 3200 0000 1200 6200 6f00 7500 6e00  .l2.....b.o.u.n.
+00003350: 6400 6900 6e00 6700 5f00 6200 6f00 7800  d.i.n.g._.b.o.x.
+00003360: 5f00 7400 6f00 6f00 6c00 736c 7376 4362  _.t.o.o.l.slsvCb
+00003370: 6c6f 6200 0002 7862 706c 6973 7430 30d8  lob...xbplist00.
+00003380: 0102 0304 0506 0708 090a 0b18 4647 0a49  ............FG.I
+00003390: 5869 636f 6e53 697a 655f 100f 7368 6f77  XiconSize_..show
+000033a0: 4963 6f6e 5072 6576 6965 7757 636f 6c75  IconPreviewWcolu
+000033b0: 6d6e 735f 1011 6361 6c63 756c 6174 6541  mns_..calculateA
+000033c0: 6c6c 5369 7a65 7358 7465 7874 5369 7a65  llSizesXtextSize
+000033d0: 5a73 6f72 7443 6f6c 756d 6e5f 1010 7573  ZsortColumn_..us
+000033e0: 6552 656c 6174 6976 6544 6174 6573 5f10  eRelativeDates_.
+000033f0: 1276 6965 774f 7074 696f 6e73 5665 7273  .viewOptionsVers
+00003400: 696f 6e23 4030 0000 0000 0000 09ab 0c15  ion#@0..........
+00003410: 1a1f 2328 2d32 373c 41d4 0d0e 0f10 1112  ..#(-27<A.......
+00003420: 0a0a 5a69 6465 6e74 6966 6965 7255 7769  ..ZidentifierUwi
+00003430: 6474 6859 6173 6365 6e64 696e 6757 7669  dthYascendingWvi
+00003440: 7369 626c 6554 6e61 6d65 10f0 0909 d40d  sibleTname......
+00003450: 0e0f 1016 1718 1858 7562 6971 7569 7479  .......Xubiquity
+00003460: 1023 0808 d40d 0e0f 101b 1c18 0a5c 6461  .#...........\da
+00003470: 7465 4d6f 6469 6669 6564 10b5 0809 d40d  teModified......
+00003480: 0e0f 1020 1c18 185b 6461 7465 4372 6561  ... ...[dateCrea
+00003490: 7465 6408 08d4 0d0e 0f10 2425 180a 5473  ted.......$%..Ts
+000034a0: 697a 6510 6108 09d4 0d0e 0f10 292a 0a0a  ize.a.......)*..
+000034b0: 546b 696e 6410 7309 09d4 0d0e 0f10 2e2f  Tkind.s......../
+000034c0: 0a18 556c 6162 656c 1064 0908 d40d 0e0f  ..Ulabel.d......
+000034d0: 1033 340a 1857 7665 7273 696f 6e10 4b09  .34..Wversion.K.
+000034e0: 08d4 0d0e 0f10 3839 0a18 5863 6f6d 6d65  ......89..Xcomme
+000034f0: 6e74 7311 012c 0908 d40d 0e0f 103d 3e18  nts..,.......=>.
+00003500: 185e 6461 7465 4c61 7374 4f70 656e 6564  .^dateLastOpened
+00003510: 10c8 0808 d40d 0e0f 1042 1c18 1859 6461  .........B...Yda
+00003520: 7465 4164 6465 6408 0808 2340 2800 0000  teAdded...#@(...
+00003530: 0000 0054 6e61 6d65 0910 0100 0800 1900  ...Tname........
+00003540: 2200 3400 3c00 5000 5900 6400 7700 8c00  ".4.<.P.Y.d.w...
+00003550: 9500 9600 a200 ab00 b600 bc00 c600 ce00  ................
+00003560: d300 d500 d600 d700 e000 e900 eb00 ec00  ................
+00003570: ed00 f601 0301 0501 0601 0701 1001 1c01  ................
+00003580: 1d01 1e01 2701 2c01 2e01 2f01 3001 3901  ....'.,.../.0.9.
+00003590: 3e01 4001 4101 4201 4b01 5101 5301 5401  >.@.A.B.K.Q.S.T.
+000035a0: 5501 5e01 6601 6801 6901 6a01 7301 7c01  U.^.f.h.i.j.s.|.
+000035b0: 7f01 8001 8101 8a01 9901 9b01 9c01 9d01  ................
+000035c0: a601 b001 b101 b201 b301 bc01 c101 c200  ................
+000035d0: 0000 0000 0002 0100 0000 0000 0000 4a00  ..............J.
+000035e0: 0000 0000 0000 0000 0000 0000 0001 c400  ................
+000035f0: 0000 1200 6200 6f00 7500 6e00 6400 6900  ....b.o.u.n.d.i.
+00003600: 6e00 6700 5f00 6200 6f00 7800 5f00 7400  n.g._.b.o.x._.t.
+00003610: 6f00 6f00 6c00 736c 7376 7062 6c6f 6200  o.o.l.slsvpblob.
+00003620: 0002 5d62 706c 6973 7430 30d8 0102 0304  ..]bplist00.....
+00003630: 0506 0708 090a 0b1a 4647 0a27 5869 636f  ........FG.'Xico
+00003640: 6e53 697a 655f 100f 7368 6f77 4963 6f6e  nSize_..showIcon
+00003650: 5072 6576 6965 7757 636f 6c75 6d6e 735f  PreviewWcolumns_
+00003660: 1011 6361 6c63 756c 6174 6541 6c6c 5369  ..calculateAllSi
+00003670: 7a65 7358 7465 7874 5369 7a65 5a73 6f72  zesXtextSizeZsor
+00003680: 7443 6f6c 756d 6e5f 1010 7573 6552 656c  tColumn_..useRel
+00003690: 6174 6976 6544 6174 6573 5f10 1276 6965  ativeDates_..vie
+000036a0: 774f 7074 696f 6e73 5665 7273 696f 6e23  wOptionsVersion#
+000036b0: 4030 0000 0000 0000 09d9 0c0d 0e0f 1011  @0..............
+000036c0: 1213 1415 1e23 282c 3136 3b40 5863 6f6d  .....#(,16;@Xcom
+000036d0: 6d65 6e74 735e 6461 7465 4c61 7374 4f70  ments^dateLastOp
+000036e0: 656e 6564 5c64 6174 654d 6f64 6966 6965  ened\dateModifie
+000036f0: 645b 6461 7465 4372 6561 7465 6454 7369  d[dateCreatedTsi
+00003700: 7a65 556c 6162 656c 546b 696e 6457 7665  zeUlabelTkindWve
+00003710: 7273 696f 6e54 6e61 6d65 d416 1718 191a  rsionTname......
+00003720: 1b0a 1d57 7669 7369 626c 6555 7769 6474  ...WvisibleUwidt
+00003730: 6859 6173 6365 6e64 696e 6755 696e 6465  hYascendingUinde
+00003740: 7808 1101 2c09 1007 d416 1718 191a 201a  x...,......... .
+00003750: 2208 10c8 0810 08d4 1617 1819 0a25 1a27  "............%.'
+00003760: 0910 b508 1001 d416 1718 191a 251a 2b08  ............%.+.
+00003770: 0810 02d4 1617 1819 0a2e 1a30 0910 6108  ...........0..a.
+00003780: 1003 d416 1718 191a 330a 3508 1064 0910  ........3.5..d..
+00003790: 05d4 1617 1819 0a38 0a3a 0910 7309 1004  .......8.:..s...
+000037a0: d416 1718 191a 3d0a 3f08 104b 0910 06d4  ......=.?..K....
+000037b0: 1617 1819 0a42 0a44 0910 f009 1000 0823  .....B.D.......#
+000037c0: 4028 0000 0000 0000 546e 616d 6509 0008  @(......Tname...
+000037d0: 0019 0022 0034 003c 0050 0059 0064 0077  ...".4.<.P.Y.d.w
+000037e0: 008c 0095 0096 00a9 00b2 00c1 00ce 00da  ................
+000037f0: 00df 00e5 00ea 00f2 00f7 0100 0108 010e  ................
+00003800: 0118 011e 011f 0122 0123 0125 012e 012f  .......".#.%.../
+00003810: 0131 0132 0134 013d 013e 0140 0141 0143  .1.2.4.=.>.@.A.C
+00003820: 014c 014d 014e 0150 0159 015a 015c 015d  .L.M.N.P.Y.Z.\.]
+00003830: 015f 0168 0169 016b 016c 016e 0177 0178  ._.h.i.k.l.n.w.x
+00003840: 017a 017b 017d 0186 0187 0189 018a 018c  .z.{.}..........
+00003850: 0195 0196 0198 0199 019b 019c 01a5 01aa  ................
+00003860: 0000 0000 0000 0201 0000 0000 0000 0049  ...............I
+00003870: 0000 0000 0000 0000 0000 0000 0000 01ab  ................
+00003880: 0000 0012 0062 006f 0075 006e 0064 0069  .....b.o.u.n.d.i
+00003890: 006e 0067 005f 0062 006f 0078 005f 0074  .n.g._.b.o.x._.t
+000038a0: 006f 006f 006c 0073 6d6f 4444 626c 6f62  .o.o.l.smoDDblob
+000038b0: 0000 0008 180d d46b 2dfc c441 0000 0012  .......k-..A....
+000038c0: 0062 006f 0075 006e 0064 0069 006e 0067  .b.o.u.n.d.i.n.g
+000038d0: 005f 0062 006f 0078 005f 0074 006f 006f  ._.b.o.x._.t.o.o
+000038e0: 006c 0073 6d6f 6444 626c 6f62 0000 0008  .l.smodDblob....
+000038f0: 180d d46b 2dfc c441 0000 0012 0062 006f  ...k-..A.....b.o
+00003900: 0075 006e 0064 0069 006e 0067 005f 0062  .u.n.d.i.n.g._.b
+00003910: 006f 0078 005f 0074 006f 006f 006c 0073  .o.x._.t.o.o.l.s
+00003920: 7068 3153 636f 6d70 0000 0000 0002 e000  ph1Scomp........
+00003930: 0000 0012 0062 006f 0075 006e 0064 0069  .....b.o.u.n.d.i
+00003940: 006e 0067 005f 0062 006f 0078 005f 0074  .n.g._.b.o.x._.t
+00003950: 006f 006f 006c 0073 7653 726e 6c6f 6e67  .o.o.l.svSrnlong
+00003960: 0000 0001 0000 000f 0063 0075 0065 005f  .........c.u.e._
+00003970: 006c 0069 0067 0068 0074 005f 0074 006f  .l.i.g.h.t._.t.o
+00003980: 006f 006c 0073 6277 7370 626c 6f62 0000  .o.l.sbwspblob..
+00003990: 00c9 6270 6c69 7374 3030 d701 0203 0405  ..bplist00......
+000039a0: 0607 0808 0a08 0a0d 0a5d 5368 6f77 5374  .........]ShowSt
+000039b0: 6174 7573 4261 725b 5368 6f77 5061 7468  atusBar[ShowPath
+000039c0: 6261 725b 5368 6f77 546f 6f6c 6261 725b  bar[ShowToolbar[
+000039d0: 5368 6f77 5461 6256 6965 775f 1014 436f  ShowTabView_..Co
+000039e0: 6e74 6169 6e65 7253 686f 7753 6964 6562  ntainerShowSideb
+000039f0: 6172 5c57 696e 646f 7742 6f75 6e64 735b  ar\WindowBounds[
+00003a00: 5368 6f77 5369 6465 6261 7208 0809 0809  ShowSidebar.....
+00003a10: 5f10 187b 7b33 3934 2c20 3138 317d 2c20  _..{{394, 181}, 
+00003a20: 7b37 3730 2c20 3433 367d 7d09 0817 2531  {770, 436}}...%1
+00003a30: 3d49 606d 797a 7b7c 7d7e 9900 0000 0000  =I`myz{|}~......
+00003a40: 0001 0100 0000 0000 0000 0f00 0000 0000  ................
+00003a50: 0000 0000 0000 0000 0000 9a00 0000 0f00  ................
+00003a60: 6300 7500 6500 5f00 6c00 6900 6700 6800  c.u.e._.l.i.g.h.
+00003a70: 7400 5f00 7400 6f00 6f00 6c00 7364 7363  t._.t.o.o.l.sdsc
+00003a80: 6c62 6f6f 6c00 0000 000f 0063 0075 0065  lbool......c.u.e
+00003a90: 005f 006c 0069 0067 0068 0074 005f 0074  ._.l.i.g.h.t._.t
+00003aa0: 006f 006f 006c 0073 6c67 3153 636f 6d70  .o.o.l.slg1Scomp
+00003ab0: 0000 0000 0001 da48 0000 000f 0063 0075  .......H.....c.u
+00003ac0: 0065 005f 006c 0069 0067 0068 0074 005f  .e._.l.i.g.h.t._
+00003ad0: 0074 006f 006f 006c 0073 6d6f 4444 626c  .t.o.o.l.smoDDbl
+00003ae0: 6f62 0000 0008 95af cbc6 2afc c441 0000  ob........*..A..
+00003af0: 000f 0063 0075 0065 005f 006c 0069 0067  ...c.u.e._.l.i.g
+00003b00: 0068 0074 005f 0074 006f 006f 006c 0073  .h.t._.t.o.o.l.s
+00003b10: 6d6f 6444 626c 6f62 0000 0008 95af cbc6  modDblob........
+00003b20: 2afc c441 0000 000f 0063 0075 0065 005f  *..A.....c.u.e._
+00003b30: 006c 0069 0067 0068 0074 005f 0074 006f  .l.i.g.h.t._.t.o
+00003b40: 006f 006c 0073 7068 3153 636f 6d70 0000  .o.l.sph1Scomp..
+00003b50: 0000 0002 5000 0000 000f 0063 0075 0065  ....P......c.u.e
+00003b60: 005f 006c 0069 0067 0068 0074 005f 0074  ._.l.i.g.h.t._.t
+00003b70: 006f 006f 006c 0073 7653 726e 6c6f 6e67  .o.o.l.svSrnlong
+00003b80: 0000 0001 0000 0012 0066 0065 0061 0074  .........f.e.a.t
+00003b90: 0075 0072 0065 005f 0065 0078 0074 0072  .u.r.e._.e.x.t.r
+00003ba0: 0061 0063 0074 006f 0072 0073 6277 7370  .a.c.t.o.r.sbwsp
+00003bb0: 626c 6f62 0000 00c8 6270 6c69 7374 3030  blob....bplist00
+00003bc0: d701 0203 0405 0607 0808 0a08 0a0d 0a5d  ...............]
+00003bd0: 5368 6f77 5374 6174 7573 4261 725b 5368  ShowStatusBar[Sh
+00003be0: 6f77 5061 7468 6261 725b 5368 6f77 546f  owPathbar[ShowTo
+00003bf0: 6f6c 6261 725b 5368 6f77 5461 6256 6965  olbar[ShowTabVie
+00003c00: 775f 1014 436f 6e74 6169 6e65 7253 686f  w_..ContainerSho
+00003c10: 7753 6964 6562 6172 5c57 696e 646f 7742  wSidebar\WindowB
+00003c20: 6f75 6e64 735b 5368 6f77 5369 6465 6261  ounds[ShowSideba
+00003c30: 7208 0809 0809 5f10 177b 7b32 302c 2039  r....._..{{20, 9
+00003c40: 307d 2c20 7b31 3031 352c 2037 3637 7d7d  0}, {1015, 767}}
+00003c50: 0908 1725 313d 4960 6d79 7a7b 7c7d 7e98  ...%1=I`myz{|}~.
+00003c60: 0000 0000 0000 0101 0000 0000 0000 000f  ................
+00003c70: 0000 0000 0000 0000 0000 0000 0000 0099  ................
 00003c80: 0000 0012 0066 0065 0061 0074 0075 0072  .....f.e.a.t.u.r
 00003c90: 0065 005f 0065 0078 0074 0072 0061 0063  .e._.e.x.t.r.a.c
-00003ca0: 0074 006f 0072 0073 6c67 3153 636f 6d70  .t.o.r.slg1Scomp
-00003cb0: 0000 0000 0012 d944 0000 0012 0066 0065  .......D.....f.e
-00003cc0: 0061 0074 0075 0072 0065 005f 0065 0078  .a.t.u.r.e._.e.x
-00003cd0: 0074 0072 0061 0063 0074 006f 0072 0073  .t.r.a.c.t.o.r.s
-00003ce0: 6c73 7643 626c 6f62 0000 02b8 6270 6c69  lsvCblob....bpli
-00003cf0: 7374 3030 da01 0203 0405 0607 0809 0a0b  st00............
-00003d00: 0c0d 1a48 4948 4a4b 0c5f 1012 7669 6577  ...HIHJK._..view
-00003d10: 4f70 7469 6f6e 7356 6572 7369 6f6e 5f10  OptionsVersion_.
-00003d20: 0f73 686f 7749 636f 6e50 7265 7669 6577  .showIconPreview
-00003d30: 5763 6f6c 756d 6e73 5f10 1163 616c 6375  Wcolumns_..calcu
-00003d40: 6c61 7465 416c 6c53 697a 6573 5f10 0f73  lateAllSizes_..s
-00003d50: 6372 6f6c 6c50 6f73 6974 696f 6e59 5874  crollPositionYXt
-00003d60: 6578 7453 697a 655f 100f 7363 726f 6c6c  extSize_..scroll
-00003d70: 506f 7369 7469 6f6e 585a 736f 7274 436f  PositionXZsortCo
-00003d80: 6c75 6d6e 5869 636f 6e53 697a 655f 1010  lumnXiconSize_..
-00003d90: 7573 6552 656c 6174 6976 6544 6174 6573  useRelativeDates
-00003da0: 1001 09ab 0e17 1c21 252a 2f34 393e 43d4  .......!%*/49>C.
-00003db0: 0f10 1112 1314 0c0c 5a69 6465 6e74 6966  ........Zidentif
-00003dc0: 6965 7255 7769 6474 6859 6173 6365 6e64  ierUwidthYascend
-00003dd0: 696e 6757 7669 7369 626c 6554 6e61 6d65  ingWvisibleTname
-00003de0: 1101 a609 09d4 0f10 1112 1819 1a1a 5875  ..............Xu
-00003df0: 6269 7175 6974 7910 2308 08d4 0f10 1112  biquity.#.......
-00003e00: 1d1e 1a0c 5c64 6174 654d 6f64 6966 6965  ....\dateModifie
-00003e10: 6410 b508 09d4 0f10 1112 221e 1a1a 5b64  d........."...[d
-00003e20: 6174 6543 7265 6174 6564 0808 d40f 1011  ateCreated......
-00003e30: 1226 271a 0c54 7369 7a65 1061 0809 d40f  .&'..Tsize.a....
-00003e40: 1011 122b 2c0c 0c54 6b69 6e64 1073 0909  ...+,..Tkind.s..
-00003e50: d40f 1011 1230 310c 1a55 6c61 6265 6c10  .....01..Ulabel.
-00003e60: 6409 08d4 0f10 1112 3536 0c1a 5776 6572  d.......56..Wver
-00003e70: 7369 6f6e 104b 0908 d40f 1011 123a 3b0c  sion.K.......:;.
-00003e80: 1a58 636f 6d6d 656e 7473 1101 2c09 08d4  .Xcomments..,...
-00003e90: 0f10 1112 3f40 1a1a 5e64 6174 654c 6173  ....?@..^dateLas
-00003ea0: 744f 7065 6e65 6410 c808 08d4 0f10 1112  tOpened.........
-00003eb0: 441e 1a1a 5964 6174 6541 6464 6564 0808  D...YdateAdded..
-00003ec0: 0823 0000 0000 0000 0000 2340 2800 0000  .#........#@(...
-00003ed0: 0000 005c 6461 7465 4d6f 6469 6669 6564  ...\dateModified
-00003ee0: 2340 3000 0000 0000 0009 0008 001d 0032  #@0............2
-00003ef0: 0044 004c 0060 0072 007b 008d 0098 00a1  .D.L.`.r.{......
-00003f00: 00b4 00b6 00b7 00c3 00cc 00d7 00dd 00e7  ................
-00003f10: 00ef 00f4 00f7 00f8 00f9 0102 010b 010d  ................
-00003f20: 010e 010f 0118 0125 0127 0128 0129 0132  .......%.'.(.).2
-00003f30: 013e 013f 0140 0149 014e 0150 0151 0152  .>.?.@.I.N.P.Q.R
-00003f40: 015b 0160 0162 0163 0164 016d 0173 0175  .[.`.b.c.d.m.s.u
-00003f50: 0176 0177 0180 0188 018a 018b 018c 0195  .v.w............
-00003f60: 019e 01a1 01a2 01a3 01ac 01bb 01bd 01be  ................
-00003f70: 01bf 01c8 01d2 01d3 01d4 01d5 01de 01e7  ................
-00003f80: 01f4 01fd 0000 0000 0000 0201 0000 0000  ................
-00003f90: 0000 004d 0000 0000 0000 0000 0000 0000  ...M............
-00003fa0: 0000 01fe 0000 0000 0000 0000 0000 0000  ................
-00003fb0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
-00003fc0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
-00003fd0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
+00003ca0: 0074 006f 0072 0073 6473 636c 626f 6f6c  .t.o.r.sdsclbool
+00003cb0: 0000 0000 1200 6600 6500 6100 7400 7500  ......f.e.a.t.u.
+00003cc0: 7200 6500 5f00 6500 7800 7400 7200 6100  r.e._.e.x.t.r.a.
+00003cd0: 6300 7400 6f00 7200 736c 6731 5363 6f6d  c.t.o.r.slg1Scom
+00003ce0: 7000 0000 0000 12a9 d700 0000 1200 6600  p.............f.
+00003cf0: 6500 6100 7400 7500 7200 6500 5f00 6500  e.a.t.u.r.e._.e.
+00003d00: 7800 7400 7200 6100 6300 7400 6f00 7200  x.t.r.a.c.t.o.r.
+00003d10: 736c 7376 4362 6c6f 6200 0002 b862 706c  slsvCblob....bpl
+00003d20: 6973 7430 30da 0102 0304 0506 0708 090a  ist00...........
+00003d30: 0b0c 0d1a 4849 484a 4b0c 5f10 1276 6965  ....HIHJK._..vie
+00003d40: 774f 7074 696f 6e73 5665 7273 696f 6e5f  wOptionsVersion_
+00003d50: 100f 7368 6f77 4963 6f6e 5072 6576 6965  ..showIconPrevie
+00003d60: 7757 636f 6c75 6d6e 735f 1011 6361 6c63  wWcolumns_..calc
+00003d70: 756c 6174 6541 6c6c 5369 7a65 735f 100f  ulateAllSizes_..
+00003d80: 7363 726f 6c6c 506f 7369 7469 6f6e 5958  scrollPositionYX
+00003d90: 7465 7874 5369 7a65 5f10 0f73 6372 6f6c  textSize_..scrol
+00003da0: 6c50 6f73 6974 696f 6e58 5a73 6f72 7443  lPositionXZsortC
+00003db0: 6f6c 756d 6e58 6963 6f6e 5369 7a65 5f10  olumnXiconSize_.
+00003dc0: 1075 7365 5265 6c61 7469 7665 4461 7465  .useRelativeDate
+00003dd0: 7310 0109 ab0e 171c 2125 2a2f 3439 3e43  s.......!%*/49>C
+00003de0: d40f 1011 1213 140c 0c5a 6964 656e 7469  .........Zidenti
+00003df0: 6669 6572 5577 6964 7468 5961 7363 656e  fierUwidthYascen
+00003e00: 6469 6e67 5776 6973 6962 6c65 546e 616d  dingWvisibleTnam
+00003e10: 6511 01a6 0909 d40f 1011 1218 191a 1a58  e..............X
+00003e20: 7562 6971 7569 7479 1023 0808 d40f 1011  ubiquity.#......
+00003e30: 121d 1e1a 0c5c 6461 7465 4d6f 6469 6669  .....\dateModifi
+00003e40: 6564 10b5 0809 d40f 1011 1222 1e1a 1a5b  ed........."...[
+00003e50: 6461 7465 4372 6561 7465 6408 08d4 0f10  dateCreated.....
+00003e60: 1112 2627 1a0c 5473 697a 6510 6108 09d4  ..&'..Tsize.a...
+00003e70: 0f10 1112 2b2c 0c0c 546b 696e 6410 7309  ....+,..Tkind.s.
+00003e80: 09d4 0f10 1112 3031 0c1a 556c 6162 656c  ......01..Ulabel
+00003e90: 1064 0908 d40f 1011 1235 360c 1a57 7665  .d.......56..Wve
+00003ea0: 7273 696f 6e10 4b09 08d4 0f10 1112 3a3b  rsion.K.......:;
+00003eb0: 0c1a 5863 6f6d 6d65 6e74 7311 012c 0908  ..Xcomments..,..
+00003ec0: d40f 1011 123f 401a 1a5e 6461 7465 4c61  .....?@..^dateLa
+00003ed0: 7374 4f70 656e 6564 10c8 0808 d40f 1011  stOpened........
+00003ee0: 1244 1e1a 1a59 6461 7465 4164 6465 6408  .D...YdateAdded.
+00003ef0: 0808 2300 0000 0000 0000 0023 4028 0000  ..#........#@(..
+00003f00: 0000 0000 5c64 6174 654d 6f64 6966 6965  ....\dateModifie
+00003f10: 6423 4030 0000 0000 0000 0900 0800 1d00  d#@0............
+00003f20: 3200 4400 4c00 6000 7200 7b00 8d00 9800  2.D.L.`.r.{.....
+00003f30: a100 b400 b600 b700 c300 cc00 d700 dd00  ................
+00003f40: e700 ef00 f400 f700 f800 f901 0201 0b01  ................
+00003f50: 0d01 0e01 0f01 1801 2501 2701 2801 2901  ........%.'.(.).
+00003f60: 3201 3e01 3f01 4001 4901 4e01 5001 5101  2.>.?.@.I.N.P.Q.
+00003f70: 5201 5b01 6001 6201 6301 6401 6d01 7301  R.[.`.b.c.d.m.s.
+00003f80: 7501 7601 7701 8001 8801 8a01 8b01 8c01  u.v.w...........
+00003f90: 9501 9e01 a101 a201 a301 ac01 bb01 bd01  ................
+00003fa0: be01 bf01 c801 d201 d301 d401 d501 de01  ................
+00003fb0: e701 f401 fd00 0000 0000 0002 0100 0000  ................
+00003fc0: 0000 0000 4d00 0000 0000 0000 0000 0000  ....M...........
+00003fd0: 0000 0001 fe00 0000 0000 0000 0000 0000  ................
 00003fe0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00003ff0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00004000: 0000 0000 0000 0000 0000 0015 0000 0012  ................
 00004010: 0066 0065 0061 0074 0075 0072 0065 005f  .f.e.a.t.u.r.e._
 00004020: 0065 0078 0074 0072 0061 0063 0074 006f  .e.x.t.r.a.c.t.o
 00004030: 0072 0073 6d6f 4444 626c 6f62 0000 0008  .r.smoDDblob....
-00004040: e84a b14c eaf6 c441 0000 0012 0066 0065  .J.L...A.....f.e
+00004040: 8438 0737 5bfc c441 0000 0012 0066 0065  .8.7[..A.....f.e
 00004050: 0061 0074 0075 0072 0065 005f 0065 0078  .a.t.u.r.e._.e.x
 00004060: 0074 0072 0061 0063 0074 006f 0072 0073  .t.r.a.c.t.o.r.s
-00004070: 6d6f 6444 626c 6f62 0000 0008 e84a b14c  modDblob.....J.L
-00004080: eaf6 c441 0000 0012 0066 0065 0061 0074  ...A.....f.e.a.t
+00004070: 6d6f 6444 626c 6f62 0000 0008 8438 0737  modDblob.....8.7
+00004080: 5bfc c441 0000 0012 0066 0065 0061 0074  [..A.....f.e.a.t
 00004090: 0075 0072 0065 005f 0065 0078 0074 0072  .u.r.e._.e.x.t.r
 000040a0: 0061 0063 0074 006f 0072 0073 7068 3153  .a.c.t.o.r.sph1S
-000040b0: 636f 6d70 0000 0000 0015 5000 0000 0012  comp......P.....
+000040b0: 636f 6d70 0000 0000 0015 2000 0000 0012  comp...... .....
 000040c0: 0066 0065 0061 0074 0075 0072 0065 005f  .f.e.a.t.u.r.e._
 000040d0: 0065 0078 0074 0072 0061 0063 0074 006f  .e.x.t.r.a.c.t.o
 000040e0: 0072 0073 7653 726e 6c6f 6e67 0000 0001  .r.svSrnlong....
 000040f0: 0000 0006 006d 0069 0078 0069 006e 0073  .....m.i.x.i.n.s
 00004100: 6277 7370 626c 6f62 0000 00c9 6270 6c69  bwspblob....bpli
 00004110: 7374 3030 d701 0203 0405 0607 0808 0a08  st00............
 00004120: 0a0d 0a5d 5368 6f77 5374 6174 7573 4261  ...]ShowStatusBa
@@ -1049,21 +1049,21 @@
 00004180: 6465 6261 7208 0809 0809 5f10 187b 7b33  debar....._..{{3
 00004190: 3934 2c20 3138 317d 2c20 7b37 3730 2c20  94, 181}, {770, 
 000041a0: 3433 367d 7d09 0817 2531 3d49 606d 797a  436}}...%1=I`myz
 000041b0: 7b7c 7d7e 9900 0000 0000 0001 0100 0000  {|}~............
 000041c0: 0000 0000 0f00 0000 0000 0000 0000 0000  ................
 000041d0: 0000 0000 9a00 0000 0600 6d00 6900 7800  ..........m.i.x.
 000041e0: 6900 6e00 736c 6731 5363 6f6d 7000 0000  i.n.slg1Scomp...
-000041f0: 0000 01b9 c300 0000 0600 6d00 6900 7800  ..........m.i.x.
+000041f0: 0000 07b4 8400 0000 0600 6d00 6900 7800  ..........m.i.x.
 00004200: 6900 6e00 736d 6f44 4462 6c6f 6200 0000  i.n.smoDDblob...
-00004210: 08a5 671d 440a fac4 4100 0000 0600 6d00  ..g.D...A.....m.
+00004210: 083a 8ccc d7cf fcc4 4100 0000 0600 6d00  .:......A.....m.
 00004220: 6900 7800 6900 6e00 736d 6f64 4462 6c6f  i.x.i.n.smodDblo
-00004230: 6200 0000 0821 b3af 405b f8c4 4100 0000  b....!..@[..A...
+00004230: 6200 0000 08dc b424 e5b4 fcc4 4100 0000  b......$....A...
 00004240: 0600 6d00 6900 7800 6900 6e00 7370 6831  ..m.i.x.i.n.sph1
-00004250: 5363 6f6d 7000 0000 0000 0210 0000 0000  Scomp...........
+00004250: 5363 6f6d 7000 0000 0000 0860 0000 0000  Scomp......`....
 00004260: 0600 6d00 6900 7800 6900 6e00 7376 5372  ..m.i.x.i.n.svSr
 00004270: 6e6c 6f6e 6700 0000 0100 0000 0d00 6f00  nlong.........o.
 00004280: 7500 7400 6c00 6900 6500 7200 5f00 7400  u.t.l.i.e.r._.t.
 00004290: 6f00 6f00 6c00 7362 7773 7062 6c6f 6200  o.o.l.sbwspblob.
 000042a0: 0000 c962 706c 6973 7430 30d7 0102 0304  ...bplist00.....
 000042b0: 0506 0708 080a 080a 0d0a 5d53 686f 7753  ..........]ShowS
 000042c0: 7461 7475 7342 6172 5b53 686f 7750 6174  tatusBar[ShowPat
@@ -1075,15 +1075,15 @@
 00004320: 095f 1018 7b7b 3339 342c 2031 3831 7d2c  ._..{{394, 181},
 00004330: 207b 3737 302c 2034 3336 7d7d 0908 1725   {770, 436}}...%
 00004340: 313d 4960 6d79 7a7b 7c7d 7e99 0000 0000  1=I`myz{|}~.....
 00004350: 0000 0101 0000 0000 0000 000f 0000 0000  ................
 00004360: 0000 0000 0000 0000 0000 009a 0000 000d  ................
 00004370: 006f 0075 0074 006c 0069 0065 0072 005f  .o.u.t.l.i.e.r._
 00004380: 0074 006f 006f 006c 0073 6c67 3153 636f  .t.o.o.l.slg1Sco
-00004390: 6d70 0000 0000 0001 3c67 0000 000d 006f  mp......<g.....o
+00004390: 6d70 0000 0000 0001 383b 0000 000d 006f  mp......8;.....o
 000043a0: 0075 0074 006c 0069 0065 0072 005f 0074  .u.t.l.i.e.r._.t
 000043b0: 006f 006f 006c 0073 6c73 7643 626c 6f62  .o.o.l.slsvCblob
 000043c0: 0000 02af 6270 6c69 7374 3030 da01 0203  ....bplist00....
 000043d0: 0405 0607 0809 0a0b 0c0d 1a48 4948 4a0c  ...........HIHJ.
 000043e0: 4c58 6963 6f6e 5369 7a65 5f10 0f73 686f  LXiconSize_..sho
 000043f0: 7749 636f 6e50 7265 7669 6577 5763 6f6c  wIconPreviewWcol
 00004400: 756d 6e73 5f10 1163 616c 6375 6c61 7465  umns_..calculate
@@ -1167,129 +1167,129 @@
 000048e0: 8701 9001 9101 9301 9401 9601 9f01 a001  ................
 000048f0: a201 a301 a501 ae01 af01 b101 b201 b401  ................
 00004900: bd01 bf01 c101 c201 c301 c401 cd01 d601  ................
 00004910: db00 0000 0000 0002 0100 0000 0000 0000  ................
 00004920: 4c00 0000 0000 0000 0000 0000 0000 0001  L...............
 00004930: dc00 0000 0d00 6f00 7500 7400 6c00 6900  ......o.u.t.l.i.
 00004940: 6500 7200 5f00 7400 6f00 6f00 6c00 736d  e.r._.t.o.o.l.sm
-00004950: 6f44 4462 6c6f 6200 0000 08dc ce8d ed38  oDDblob........8
-00004960: f2c4 4100 0000 0d00 6f00 7500 7400 6c00  ..A.....o.u.t.l.
+00004950: 6f44 4462 6c6f 6200 0000 0898 fdc3 c754  oDDblob........T
+00004960: fcc4 4100 0000 0d00 6f00 7500 7400 6c00  ..A.....o.u.t.l.
 00004970: 6900 6500 7200 5f00 7400 6f00 6f00 6c00  i.e.r._.t.o.o.l.
-00004980: 736d 6f64 4462 6c6f 6200 0000 08dc ce8d  smodDblob.......
-00004990: ed38 f2c4 4100 0000 0d00 6f00 7500 7400  .8..A.....o.u.t.
+00004980: 736d 6f64 4462 6c6f 6200 0000 0898 fdc3  smodDblob.......
+00004990: c754 fcc4 4100 0000 0d00 6f00 7500 7400  .T..A.....o.u.t.
 000049a0: 6c00 6900 6500 7200 5f00 7400 6f00 6f00  l.i.e.r._.t.o.o.
 000049b0: 6c00 7370 6831 5363 6f6d 7000 0000 0000  l.sph1Scomp.....
-000049c0: 0230 0000 0000 0d00 6f00 7500 7400 6c00  .0......o.u.t.l.
+000049c0: 0220 0000 0000 0d00 6f00 7500 7400 6c00  . ......o.u.t.l.
 000049d0: 6900 6500 7200 5f00 7400 6f00 6f00 6c00  i.e.r._.t.o.o.l.
 000049e0: 7376 5372 6e6c 6f6e 6700 0000 0100 0000  svSrnlong.......
 000049f0: 0800 7000 6c00 6f00 7400 7400 6900 6e00  ..p.l.o.t.t.i.n.
-00004a00: 6762 7773 7062 6c6f 6200 0000 ca62 706c  gbwspblob....bpl
+00004a00: 6762 7773 7062 6c6f 6200 0000 c862 706c  gbwspblob....bpl
 00004a10: 6973 7430 30d7 0102 0304 0506 0708 080a  ist00...........
 00004a20: 080a 0d0a 5d53 686f 7753 7461 7475 7342  ....]ShowStatusB
 00004a30: 6172 5b53 686f 7750 6174 6862 6172 5b53  ar[ShowPathbar[S
 00004a40: 686f 7754 6f6f 6c62 6172 5b53 686f 7754  howToolbar[ShowT
 00004a50: 6162 5669 6577 5f10 1443 6f6e 7461 696e  abView_..Contain
 00004a60: 6572 5368 6f77 5369 6465 6261 725c 5769  erShowSidebar\Wi
 00004a70: 6e64 6f77 426f 756e 6473 5b53 686f 7753  ndowBounds[ShowS
-00004a80: 6964 6562 6172 0808 0908 095f 1019 7b7b  idebar....._..{{
-00004a90: 3135 392c 2031 3233 7d2c 207b 3130 3736  159, 123}, {1076
-00004aa0: 2c20 3632 317d 7d09 0817 2531 3d49 606d  , 621}}...%1=I`m
-00004ab0: 797a 7b7c 7d7e 9a00 0000 0000 0001 0100  yz{|}~..........
-00004ac0: 0000 0000 0000 0f00 0000 0000 0000 0000  ................
-00004ad0: 0000 0000 0000 9b00 0000 0800 7000 6c00  ............p.l.
-00004ae0: 6f00 7400 7400 6900 6e00 676c 6731 5363  o.t.t.i.n.glg1Sc
-00004af0: 6f6d 7000 0000 0000 0a1f d300 0000 0800  omp.............
-00004b00: 7000 6c00 6f00 7400 7400 6900 6e00 676c  p.l.o.t.t.i.n.gl
-00004b10: 7376 4362 6c6f 6200 0002 bb62 706c 6973  svCblob....bplis
-00004b20: 7430 30da 0102 0304 0506 0708 090a 0b0c  t00.............
-00004b30: 0d1a 4849 4a4b 4c0c 5f10 1276 6965 774f  ..HIJKL._..viewO
-00004b40: 7074 696f 6e73 5665 7273 696f 6e5f 100f  ptionsVersion_..
-00004b50: 7368 6f77 4963 6f6e 5072 6576 6965 7757  showIconPreviewW
-00004b60: 636f 6c75 6d6e 735f 1011 6361 6c63 756c  columns_..calcul
-00004b70: 6174 6541 6c6c 5369 7a65 735f 100f 7363  ateAllSizes_..sc
-00004b80: 726f 6c6c 506f 7369 7469 6f6e 5958 7465  rollPositionYXte
-00004b90: 7874 5369 7a65 5f10 0f73 6372 6f6c 6c50  xtSize_..scrollP
-00004ba0: 6f73 6974 696f 6e58 5a73 6f72 7443 6f6c  ositionXZsortCol
-00004bb0: 756d 6e58 6963 6f6e 5369 7a65 5f10 1075  umnXiconSize_..u
-00004bc0: 7365 5265 6c61 7469 7665 4461 7465 7310  seRelativeDates.
-00004bd0: 0109 ab0e 171c 2125 2a2f 3439 3e43 d40f  ......!%*/49>C..
-00004be0: 1011 1213 140c 0c5a 6964 656e 7469 6669  .......Zidentifi
-00004bf0: 6572 5577 6964 7468 5961 7363 656e 6469  erUwidthYascendi
-00004c00: 6e67 5776 6973 6962 6c65 546e 616d 6511  ngWvisibleTname.
-00004c10: 0127 0909 d40f 1011 1218 191a 1a58 7562  .'...........Xub
-00004c20: 6971 7569 7479 1023 0808 d40f 1011 121d  iquity.#........
-00004c30: 1e1a 0c5c 6461 7465 4d6f 6469 6669 6564  ...\dateModified
-00004c40: 10b5 0809 d40f 1011 1222 1e1a 1a5b 6461  ........."...[da
-00004c50: 7465 4372 6561 7465 6408 08d4 0f10 1112  teCreated.......
-00004c60: 2627 1a0c 5473 697a 6510 6108 09d4 0f10  &'..Tsize.a.....
-00004c70: 1112 2b2c 0c0c 546b 696e 6410 7309 09d4  ..+,..Tkind.s...
-00004c80: 0f10 1112 3031 0c1a 556c 6162 656c 1064  ....01..Ulabel.d
-00004c90: 0908 d40f 1011 1235 360c 1a57 7665 7273  .......56..Wvers
-00004ca0: 696f 6e10 4b09 08d4 0f10 1112 3a3b 0c1a  ion.K.......:;..
-00004cb0: 5863 6f6d 6d65 6e74 7311 012c 0908 d40f  Xcomments..,....
-00004cc0: 1011 123f 401a 1a5e 6461 7465 4c61 7374  ...?@..^dateLast
-00004cd0: 4f70 656e 6564 10c8 0808 d40f 1011 1244  Opened.........D
-00004ce0: 1e1a 1a59 6461 7465 4164 6465 6408 0808  ...YdateAdded...
-00004cf0: 2340 4800 0000 0000 0023 4028 0000 0000  #@H......#@(....
-00004d00: 0000 2300 0000 0000 0000 0054 6e61 6d65  ..#........Tname
-00004d10: 2340 3000 0000 0000 0009 0008 001d 0032  #@0............2
-00004d20: 0044 004c 0060 0072 007b 008d 0098 00a1  .D.L.`.r.{......
-00004d30: 00b4 00b6 00b7 00c3 00cc 00d7 00dd 00e7  ................
-00004d40: 00ef 00f4 00f7 00f8 00f9 0102 010b 010d  ................
-00004d50: 010e 010f 0118 0125 0127 0128 0129 0132  .......%.'.(.).2
-00004d60: 013e 013f 0140 0149 014e 0150 0151 0152  .>.?.@.I.N.P.Q.R
-00004d70: 015b 0160 0162 0163 0164 016d 0173 0175  .[.`.b.c.d.m.s.u
-00004d80: 0176 0177 0180 0188 018a 018b 018c 0195  .v.w............
-00004d90: 019e 01a1 01a2 01a3 01ac 01bb 01bd 01be  ................
-00004da0: 01bf 01c8 01d2 01d3 01d4 01d5 01de 01e7  ................
-00004db0: 01f0 01f5 01fe 0000 0000 0000 0201 0000  ................
-00004dc0: 0000 0000 004e 0000 0000 0000 0000 0000  .....N..........
-00004dd0: 0000 0000 01ff 7369 626c 6554 6e61 6d65  ......sibleTname
-00004de0: 1101 a609 09d4 0f10 1112 1819 1a1a 5875  ..............Xu
-00004df0: 6269 7175 6974 7910 2308 08d4 0f10 1112  biquity.#.......
-00004e00: 1d1e 1a0c 5c64 6174 654d 6f64 6966 6965  ....\dateModifie
-00004e10: 6410 b508 09d4 0f10 1112 221e 1a1a 5b64  d........."...[d
-00004e20: 6174 6543 7265 6174 6564 0808 d40f 1011  ateCreated......
-00004e30: 1226 271a 0c54 7369 7a65 1061 0809 d40f  .&'..Tsize.a....
-00004e40: 1011 122b 2c0c 0c54 6b69 6e64 1073 0909  ...+,..Tkind.s..
-00004e50: d40f 1011 1230 310c 1a55 6c61 6265 6c10  .....01..Ulabel.
-00004e60: 6409 08d4 0f10 1112 3536 0c1a 5776 6572  d.......56..Wver
-00004e70: 7369 6f6e 104b 0908 d40f 1011 123a 3b0c  sion.K.......:;.
-00004e80: 1a58 636f 6d6d 656e 7473 1101 2c09 08d4  .Xcomments..,...
-00004e90: 0f10 1112 3f40 1a1a 5e64 6174 654c 6173  ....?@..^dateLas
-00004ea0: 744f 7065 6e65 6410 c808 08d4 0f10 1112  tOpened.........
-00004eb0: 441e 1a1a 5964 6174 6541 6464 6564 0808  D...YdateAdded..
-00004ec0: 0823 0000 0000 0000 0000 2340 2800 0000  .#........#@(...
-00004ed0: 0000 005c 6461 7465 4d6f 6469 6669 6564  ...\dateModified
-00004ee0: 2340 3000 0000 0000 0009 0008 001d 0032  #@0............2
-00004ef0: 0044 004c 0060 0072 007b 008d 0098 00a1  .D.L.`.r.{......
-00004f00: 00b4 00b6 00b7 00c3 00cc 00d7 00dd 00e7  ................
-00004f10: 00ef 00f4 00f7 00f8 00f9 0102 010b 010d  ................
-00004f20: 010e 010f 0118 0125 0127 0128 0129 0132  .......%.'.(.).2
-00004f30: 013e 013f 0140 0149 014e 0150 0151 0152  .>.?.@.I.N.P.Q.R
-00004f40: 015b 0160 0162 0163 0164 016d 0173 0175  .[.`.b.c.d.m.s.u
-00004f50: 0176 0177 0180 0188 018a 018b 018c 0195  .v.w............
-00004f60: 019e 01a1 01a2 01a3 01ac 01bb 01bd 01be  ................
-00004f70: 01bf 01c8 01d2 01d3 01d4 01d5 01de 01e7  ................
-00004f80: 01f4 01fd 0000 0000 0000 0201 0000 0000  ................
-00004f90: 0000 004d 0000 0000 0000 0000 0000 0000  ...M............
-00004fa0: 0000 01fe 0000 0000 0000 0000 0000 0000  ................
-00004fb0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
-00004fc0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
-00004fd0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
+00004a80: 6964 6562 6172 0808 0908 095f 1017 7b7b  idebar....._..{{
+00004a90: 3230 2c20 3930 7d2c 207b 3130 3135 2c20  20, 90}, {1015, 
+00004aa0: 3736 377d 7d09 0817 2531 3d49 606d 797a  767}}...%1=I`myz
+00004ab0: 7b7c 7d7e 9800 0000 0000 0001 0100 0000  {|}~............
+00004ac0: 0000 0000 0f00 0000 0000 0000 0000 0000  ................
+00004ad0: 0000 0000 9900 0000 0800 7000 6c00 6f00  ..........p.l.o.
+00004ae0: 7400 7400 6900 6e00 676c 6731 5363 6f6d  t.t.i.n.glg1Scom
+00004af0: 7000 0000 0000 095c f100 0000 0800 7000  p......\......p.
+00004b00: 6c00 6f00 7400 7400 6900 6e00 676c 7376  l.o.t.t.i.n.glsv
+00004b10: 4362 6c6f 6200 0002 b062 706c 6973 7430  Cblob....bplist0
+00004b20: 30da 0102 0304 0506 0708 090a 0b0c 0d1a  0...............
+00004b30: 4849 484a 0c4c 5869 636f 6e53 697a 655f  HIHJ.LXiconSize_
+00004b40: 100f 7368 6f77 4963 6f6e 5072 6576 6965  ..showIconPrevie
+00004b50: 7757 636f 6c75 6d6e 735f 1011 6361 6c63  wWcolumns_..calc
+00004b60: 756c 6174 6541 6c6c 5369 7a65 735f 100f  ulateAllSizes_..
+00004b70: 7363 726f 6c6c 506f 7369 7469 6f6e 5958  scrollPositionYX
+00004b80: 7465 7874 5369 7a65 5f10 0f73 6372 6f6c  textSize_..scrol
+00004b90: 6c50 6f73 6974 696f 6e58 5a73 6f72 7443  lPositionXZsortC
+00004ba0: 6f6c 756d 6e5f 1010 7573 6552 656c 6174  olumn_..useRelat
+00004bb0: 6976 6544 6174 6573 5f10 1276 6965 774f  iveDates_..viewO
+00004bc0: 7074 696f 6e73 5665 7273 696f 6e23 4030  ptionsVersion#@0
+00004bd0: 0000 0000 0000 09ab 0e17 1c21 252a 2f34  ...........!%*/4
+00004be0: 393e 43d4 0f10 1112 1314 0c0c 5a69 6465  9>C.........Zide
+00004bf0: 6e74 6966 6965 7255 7769 6474 6859 6173  ntifierUwidthYas
+00004c00: 6365 6e64 696e 6757 7669 7369 626c 6554  cendingWvisibleT
+00004c10: 6e61 6d65 1101 2709 09d4 0f10 1112 1819  name..'.........
+00004c20: 1a1a 5875 6269 7175 6974 7910 2308 08d4  ..Xubiquity.#...
+00004c30: 0f10 1112 1d1e 1a0c 5c64 6174 654d 6f64  ........\dateMod
+00004c40: 6966 6965 6410 b508 09d4 0f10 1112 221e  ified.........".
+00004c50: 1a1a 5b64 6174 6543 7265 6174 6564 0808  ..[dateCreated..
+00004c60: d40f 1011 1226 271a 0c54 7369 7a65 1061  .....&'..Tsize.a
+00004c70: 0809 d40f 1011 122b 2c0c 0c54 6b69 6e64  .......+,..Tkind
+00004c80: 1073 0909 d40f 1011 1230 310c 1a55 6c61  .s.......01..Ula
+00004c90: 6265 6c10 6409 08d4 0f10 1112 3536 0c1a  bel.d.......56..
+00004ca0: 5776 6572 7369 6f6e 104b 0908 d40f 1011  Wversion.K......
+00004cb0: 123a 3b0c 1a58 636f 6d6d 656e 7473 1101  .:;..Xcomments..
+00004cc0: 2c09 08d4 0f10 1112 3f40 1a1a 5e64 6174  ,.......?@..^dat
+00004cd0: 654c 6173 744f 7065 6e65 6410 c808 08d4  eLastOpened.....
+00004ce0: 0f10 1112 441e 1a1a 5964 6174 6541 6464  ....D...YdateAdd
+00004cf0: 6564 0808 0823 0000 0000 0000 0000 2340  ed...#........#@
+00004d00: 2800 0000 0000 0054 6e61 6d65 0910 0100  (......Tname....
+00004d10: 0800 1d00 2600 3800 4000 5400 6600 6f00  ....&.8.@.T.f.o.
+00004d20: 8100 8c00 9f00 b400 bd00 be00 ca00 d300  ................
+00004d30: de00 e400 ee00 f600 fb00 fe00 ff01 0001  ................
+00004d40: 0901 1201 1401 1501 1601 1f01 2c01 2e01  ............,...
+00004d50: 2f01 3001 3901 4501 4601 4701 5001 5501  /.0.9.E.F.G.P.U.
+00004d60: 5701 5801 5901 6201 6701 6901 6a01 6b01  W.X.Y.b.g.i.j.k.
+00004d70: 7401 7a01 7c01 7d01 7e01 8701 8f01 9101  t.z.|.}.~.......
+00004d80: 9201 9301 9c01 a501 a801 a901 aa01 b301  ................
+00004d90: c201 c401 c501 c601 cf01 d901 da01 db01  ................
+00004da0: dc01 e501 ee01 f301 f400 0000 0000 0002  ................
+00004db0: 0100 0000 0000 0000 4d00 0000 0000 0000  ........M.......
+00004dc0: 0000 0000 0000 0001 f669 7665 4461 7465  .........iveDate
+00004dd0: 7310 0109 ab0e 171c 2125 2a2f 3439 3e43  s.......!%*/49>C
+00004de0: d40f 1011 1213 140c 0c5a 6964 656e 7469  .........Zidenti
+00004df0: 6669 6572 5577 6964 7468 5961 7363 656e  fierUwidthYascen
+00004e00: 6469 6e67 5776 6973 6962 6c65 546e 616d  dingWvisibleTnam
+00004e10: 6511 01a6 0909 d40f 1011 1218 191a 1a58  e..............X
+00004e20: 7562 6971 7569 7479 1023 0808 d40f 1011  ubiquity.#......
+00004e30: 121d 1e1a 0c5c 6461 7465 4d6f 6469 6669  .....\dateModifi
+00004e40: 6564 10b5 0809 d40f 1011 1222 1e1a 1a5b  ed........."...[
+00004e50: 6461 7465 4372 6561 7465 6408 08d4 0f10  dateCreated.....
+00004e60: 1112 2627 1a0c 5473 697a 6510 6108 09d4  ..&'..Tsize.a...
+00004e70: 0f10 1112 2b2c 0c0c 546b 696e 6410 7309  ....+,..Tkind.s.
+00004e80: 09d4 0f10 1112 3031 0c1a 556c 6162 656c  ......01..Ulabel
+00004e90: 1064 0908 d40f 1011 1235 360c 1a57 7665  .d.......56..Wve
+00004ea0: 7273 696f 6e10 4b09 08d4 0f10 1112 3a3b  rsion.K.......:;
+00004eb0: 0c1a 5863 6f6d 6d65 6e74 7311 012c 0908  ..Xcomments..,..
+00004ec0: d40f 1011 123f 401a 1a5e 6461 7465 4c61  .....?@..^dateLa
+00004ed0: 7374 4f70 656e 6564 10c8 0808 d40f 1011  stOpened........
+00004ee0: 1244 1e1a 1a59 6461 7465 4164 6465 6408  .D...YdateAdded.
+00004ef0: 0808 2300 0000 0000 0000 0023 4028 0000  ..#........#@(..
+00004f00: 0000 0000 5c64 6174 654d 6f64 6966 6965  ....\dateModifie
+00004f10: 6423 4030 0000 0000 0000 0900 0800 1d00  d#@0............
+00004f20: 3200 4400 4c00 6000 7200 7b00 8d00 9800  2.D.L.`.r.{.....
+00004f30: a100 b400 b600 b700 c300 cc00 d700 dd00  ................
+00004f40: e700 ef00 f400 f700 f800 f901 0201 0b01  ................
+00004f50: 0d01 0e01 0f01 1801 2501 2701 2801 2901  ........%.'.(.).
+00004f60: 3201 3e01 3f01 4001 4901 4e01 5001 5101  2.>.?.@.I.N.P.Q.
+00004f70: 5201 5b01 6001 6201 6301 6401 6d01 7301  R.[.`.b.c.d.m.s.
+00004f80: 7501 7601 7701 8001 8801 8a01 8b01 8c01  u.v.w...........
+00004f90: 9501 9e01 a101 a201 a301 ac01 bb01 bd01  ................
+00004fa0: be01 bf01 c801 d201 d301 d401 d501 de01  ................
+00004fb0: e701 f401 fd00 0000 0000 0002 0100 0000  ................
+00004fc0: 0000 0000 4d00 0000 0000 0000 0000 0000  ....M...........
+00004fd0: 0000 0001 fe00 0000 0000 0000 0000 0000  ................
 00004fe0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00004ff0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00005000: 0000 0000 0000 0000 0000 0014 0000 0008  ................
 00005010: 0070 006c 006f 0074 0074 0069 006e 0067  .p.l.o.t.t.i.n.g
-00005020: 6d6f 4444 626c 6f62 0000 0008 34e5 9d60  moDDblob....4..`
-00005030: 16fa c441 0000 0008 0070 006c 006f 0074  ...A.....p.l.o.t
+00005020: 6d6f 4444 626c 6f62 0000 0008 98b6 bd19  moDDblob........
+00005030: bbfc c441 0000 0008 0070 006c 006f 0074  ...A.....p.l.o.t
 00005040: 0074 0069 006e 0067 6d6f 6444 626c 6f62  .t.i.n.gmodDblob
-00005050: 0000 0008 65be f96a 3ef2 c441 0000 0008  ....e..j>..A....
+00005050: 0000 0008 98b6 bd19 bbfc c441 0000 0008  ...........A....
 00005060: 0070 006c 006f 0074 0074 0069 006e 0067  .p.l.o.t.t.i.n.g
-00005070: 7068 3153 636f 6d70 0000 0000 000c 4000  ph1Scomp......@.
+00005070: 7068 3153 636f 6d70 0000 0000 000b 6000  ph1Scomp......`.
 00005080: 0000 0008 0070 006c 006f 0074 0074 0069  .....p.l.o.t.t.i
 00005090: 006e 0067 7653 726e 6c6f 6e67 0000 0001  .n.gvSrnlong....
 000050a0: 0000 0013 0070 006f 0073 0065 005f 0063  .....p.o.s.e._.c
 000050b0: 006f 006e 0066 0069 0067 0075 0072 0061  .o.n.f.i.g.u.r.a
 000050c0: 0074 0069 006f 006e 0073 6277 7370 626c  .t.i.o.n.sbwspbl
 000050d0: 6f62 0000 00ca 6270 6c69 7374 3030 d701  ob....bplist00..
 000050e0: 0203 0405 0607 0808 0a08 0a0d 0a5d 5368  .............]Sh
@@ -1415,127 +1415,127 @@
 00005860: 006e 0073 7068 3153 636f 6d70 0000 0000  .n.sph1Scomp....
 00005870: 0007 6000 0000 0013 0070 006f 0073 0065  ..`......p.o.s.e
 00005880: 005f 0063 006f 006e 0066 0069 0067 0075  ._.c.o.n.f.i.g.u
 00005890: 0072 0061 0074 0069 006f 006e 0073 7653  .r.a.t.i.o.n.svS
 000058a0: 726e 6c6f 6e67 0000 0001 0000 000e 0070  rnlong.........p
 000058b0: 006f 0073 0065 005f 0069 006d 0070 006f  .o.s.e._.i.m.p.o
 000058c0: 0072 0074 0065 0072 0073 6277 7370 626c  .r.t.e.r.sbwspbl
-000058d0: 6f62 0000 00c9 6270 6c69 7374 3030 d701  ob....bplist00..
+000058d0: 6f62 0000 00ca 6270 6c69 7374 3030 d701  ob....bplist00..
 000058e0: 0203 0405 0607 0808 0a08 0a0d 0a5d 5368  .............]Sh
 000058f0: 6f77 5374 6174 7573 4261 725b 5368 6f77  owStatusBar[Show
 00005900: 5061 7468 6261 725b 5368 6f77 546f 6f6c  Pathbar[ShowTool
 00005910: 6261 725b 5368 6f77 5461 6256 6965 775f  bar[ShowTabView_
 00005920: 1014 436f 6e74 6169 6e65 7253 686f 7753  ..ContainerShowS
 00005930: 6964 6562 6172 5c57 696e 646f 7742 6f75  idebar\WindowBou
 00005940: 6e64 735b 5368 6f77 5369 6465 6261 7208  nds[ShowSidebar.
-00005950: 0809 0809 5f10 187b 7b31 3930 2c20 3332  ...._..{{190, 32
-00005960: 7d2c 207b 3132 3530 2c20 3736 317d 7d09  }, {1250, 761}}.
-00005970: 0817 2531 3d49 606d 797a 7b7c 7d7e 9900  ..%1=I`myz{|}~..
-00005980: 0000 0000 0001 0100 0000 0000 0000 0f00  ................
-00005990: 0000 0000 0000 0000 0000 0000 0000 9a00  ................
-000059a0: 0000 0e00 7000 6f00 7300 6500 5f00 6900  ....p.o.s.e._.i.
-000059b0: 6d00 7000 6f00 7200 7400 6500 7200 736c  m.p.o.r.t.e.r.sl
-000059c0: 6731 5363 6f6d 7000 0000 0000 03b9 6300  g1Scomp.......c.
-000059d0: 0000 0e00 7000 6f00 7300 6500 5f00 6900  ....p.o.s.e._.i.
-000059e0: 6d00 7000 6f00 7200 7400 6500 7200 736c  m.p.o.r.t.e.r.sl
-000059f0: 7376 4362 6c6f 6200 0002 7962 706c 6973  svCblob...ybplis
-00005a00: 7430 30d8 0102 0304 0506 0708 090a 0b18  t00.............
-00005a10: 4647 0a49 5869 636f 6e53 697a 655f 100f  FG.IXiconSize_..
-00005a20: 7368 6f77 4963 6f6e 5072 6576 6965 7757  showIconPreviewW
-00005a30: 636f 6c75 6d6e 735f 1011 6361 6c63 756c  columns_..calcul
-00005a40: 6174 6541 6c6c 5369 7a65 7358 7465 7874  ateAllSizesXtext
-00005a50: 5369 7a65 5a73 6f72 7443 6f6c 756d 6e5f  SizeZsortColumn_
-00005a60: 1010 7573 6552 656c 6174 6976 6544 6174  ..useRelativeDat
-00005a70: 6573 5f10 1276 6965 774f 7074 696f 6e73  es_..viewOptions
-00005a80: 5665 7273 696f 6e23 4030 0000 0000 0000  Version#@0......
-00005a90: 09ab 0c15 1a1f 2328 2d32 373c 41d4 0d0e  ......#(-27<A...
-00005aa0: 0f10 1112 0a0a 5a69 6465 6e74 6966 6965  ......Zidentifie
-00005ab0: 7255 7769 6474 6859 6173 6365 6e64 696e  rUwidthYascendin
-00005ac0: 6757 7669 7369 626c 6554 6e61 6d65 1102  gWvisibleTname..
-00005ad0: d009 09d4 0d0e 0f10 1617 1818 5875 6269  ............Xubi
-00005ae0: 7175 6974 7910 2308 08d4 0d0e 0f10 1b1c  quity.#.........
-00005af0: 180a 5c64 6174 654d 6f64 6966 6965 6410  ..\dateModified.
-00005b00: b508 09d4 0d0e 0f10 201c 1818 5b64 6174  ........ ...[dat
-00005b10: 6543 7265 6174 6564 0808 d40d 0e0f 1024  eCreated.......$
-00005b20: 2518 0a54 7369 7a65 1061 0809 d40d 0e0f  %..Tsize.a......
-00005b30: 1029 2a0a 0a54 6b69 6e64 1073 0909 d40d  .)*..Tkind.s....
-00005b40: 0e0f 102e 2f0a 1855 6c61 6265 6c10 6409  ..../..Ulabel.d.
-00005b50: 08d4 0d0e 0f10 3334 0a18 5776 6572 7369  ......34..Wversi
-00005b60: 6f6e 104b 0908 d40d 0e0f 1038 390a 1858  on.K.......89..X
-00005b70: 636f 6d6d 656e 7473 1101 2c09 08d4 0d0e  comments..,.....
-00005b80: 0f10 3d3e 1818 5e64 6174 654c 6173 744f  ..=>..^dateLastO
-00005b90: 7065 6e65 6410 c808 08d4 0d0e 0f10 421c  pened.........B.
-00005ba0: 1818 5964 6174 6541 6464 6564 0808 0823  ..YdateAdded...#
-00005bb0: 4028 0000 0000 0000 546e 616d 6509 1001  @(......Tname...
-00005bc0: 0008 0019 0022 0034 003c 0050 0059 0064  .....".4.<.P.Y.d
-00005bd0: 0077 008c 0095 0096 00a2 00ab 00b6 00bc  .w..............
-00005be0: 00c6 00ce 00d3 00d6 00d7 00d8 00e1 00ea  ................
-00005bf0: 00ec 00ed 00ee 00f7 0104 0106 0107 0108  ................
-00005c00: 0111 011d 011e 011f 0128 012d 012f 0130  .........(.-./.0
-00005c10: 0131 013a 013f 0141 0142 0143 014c 0152  .1.:.?.A.B.C.L.R
-00005c20: 0154 0155 0156 015f 0167 0169 016a 016b  .T.U.V._.g.i.j.k
-00005c30: 0174 017d 0180 0181 0182 018b 019a 019c  .t.}............
-00005c40: 019d 019e 01a7 01b1 01b2 01b3 01b4 01bd  ................
-00005c50: 01c2 01c3 0000 0000 0000 0201 0000 0000  ................
+00005950: 0809 0809 5f10 197b 7b36 3432 2c20 3132  ...._..{{642, 12
+00005960: 397d 2c20 7b31 3031 352c 2037 3637 7d7d  9}, {1015, 767}}
+00005970: 0908 1725 313d 4960 6d79 7a7b 7c7d 7e9a  ...%1=I`myz{|}~.
+00005980: 0000 0000 0000 0101 0000 0000 0000 000f  ................
+00005990: 0000 0000 0000 0000 0000 0000 0000 009b  ................
+000059a0: 0000 000e 0070 006f 0073 0065 005f 0069  .....p.o.s.e._.i
+000059b0: 006d 0070 006f 0072 0074 0065 0072 0073  .m.p.o.r.t.e.r.s
+000059c0: 6c67 3153 636f 6d70 0000 0000 0003 83b7  lg1Scomp........
+000059d0: 0000 000e 0070 006f 0073 0065 005f 0069  .....p.o.s.e._.i
+000059e0: 006d 0070 006f 0072 0074 0065 0072 0073  .m.p.o.r.t.e.r.s
+000059f0: 6c73 7643 626c 6f62 0000 0278 6270 6c69  lsvCblob...xbpli
+00005a00: 7374 3030 d801 0203 0405 0607 0809 0a0b  st00............
+00005a10: 1646 4748 0a5f 1012 7669 6577 4f70 7469  .FGH._..viewOpti
+00005a20: 6f6e 7356 6572 7369 6f6e 5f10 0f73 686f  onsVersion_..sho
+00005a30: 7749 636f 6e50 7265 7669 6577 5763 6f6c  wIconPreviewWcol
+00005a40: 756d 6e73 5f10 1163 616c 6375 6c61 7465  umns_..calculate
+00005a50: 416c 6c53 697a 6573 5874 6578 7453 697a  AllSizesXtextSiz
+00005a60: 655a 736f 7274 436f 6c75 6d6e 5869 636f  eZsortColumnXico
+00005a70: 6e53 697a 655f 1010 7573 6552 656c 6174  nSize_..useRelat
+00005a80: 6976 6544 6174 6573 1001 09ab 0c15 1a1f  iveDates........
+00005a90: 2328 2d32 373c 41d4 0d0e 0f10 0a12 0a14  #(-27<A.........
+00005aa0: 5776 6973 6962 6c65 5577 6964 7468 5961  WvisibleUwidthYa
+00005ab0: 7363 656e 6469 6e67 5a69 6465 6e74 6966  scendingZidentif
+00005ac0: 6965 7209 10ea 0954 6e61 6d65 d40d 0e0f  ier....Tname....
+00005ad0: 1016 1716 1908 1023 0858 7562 6971 7569  .......#.Xubiqui
+00005ae0: 7479 d40d 0e0f 100a 1c16 1e09 10b5 085c  ty.............\
+00005af0: 6461 7465 4d6f 6469 6669 6564 d40d 0e0f  dateModified....
+00005b00: 1016 1c16 2208 085b 6461 7465 4372 6561  ...."..[dateCrea
+00005b10: 7465 64d4 0d0e 0f10 0a25 1627 0910 6108  ted......%.'..a.
+00005b20: 5473 697a 65d4 0d0e 0f10 0a2a 0a2c 0910  Tsize......*.,..
+00005b30: 7309 546b 696e 64d4 0d0e 0f10 162f 0a31  s.Tkind....../.1
+00005b40: 0810 6409 556c 6162 656c d40d 0e0f 1016  ..d.Ulabel......
+00005b50: 340a 3608 104b 0957 7665 7273 696f 6ed4  4.6..K.Wversion.
+00005b60: 0d0e 0f10 1639 0a3b 0811 012c 0958 636f  .....9.;...,.Xco
+00005b70: 6d6d 656e 7473 d40d 0e0f 1016 3e16 4008  mments......>.@.
+00005b80: 10c8 085e 6461 7465 4c61 7374 4f70 656e  ...^dateLastOpen
+00005b90: 6564 d40d 0e0f 1016 1c16 4408 0859 6461  ed........D..Yda
+00005ba0: 7465 4164 6465 6408 2340 2800 0000 0000  teAdded.#@(.....
+00005bb0: 0054 6e61 6d65 2340 3000 0000 0000 0009  .Tname#@0.......
+00005bc0: 0008 0019 002e 0040 0048 005c 0065 0070  .......@.H.\.e.p
+00005bd0: 0079 008c 008e 008f 009b 00a4 00ac 00b2  .y..............
+00005be0: 00bc 00c7 00c8 00ca 00cb 00d0 00d9 00da  ................
+00005bf0: 00dc 00dd 00e6 00ef 00f0 00f2 00f3 0100  ................
+00005c00: 0109 010a 010b 0117 0120 0121 0123 0124  ......... .!.#.$
+00005c10: 0129 0132 0133 0135 0136 013b 0144 0145  .).2.3.5.6.;.D.E
+00005c20: 0147 0148 014e 0157 0158 015a 015b 0163  .G.H.N.W.X.Z.[.c
+00005c30: 016c 016d 0170 0171 017a 0183 0184 0186  .l.m.p.q.z......
+00005c40: 0187 0196 019f 01a0 01a1 01ab 01ac 01b5  ................
+00005c50: 01ba 01c3 0000 0000 0000 0201 0000 0000  ................
 00005c60: 0000 004a 0000 0000 0000 0000 0000 0000  ...J............
-00005c70: 0000 01c5 0000 000e 0070 006f 0073 0065  .........p.o.s.e
+00005c70: 0000 01c4 0000 000e 0070 006f 0073 0065  .........p.o.s.e
 00005c80: 005f 0069 006d 0070 006f 0072 0074 0065  ._.i.m.p.o.r.t.e
-00005c90: 0072 0073 6c73 7670 626c 6f62 0000 025e  .r.slsvpblob...^
+00005c90: 0072 0073 6c73 7670 626c 6f62 0000 025d  .r.slsvpblob...]
 00005ca0: 6270 6c69 7374 3030 d801 0203 0405 0607  bplist00........
-00005cb0: 0809 0a0b 1a46 470a 2758 6963 6f6e 5369  .....FG.'XiconSi
-00005cc0: 7a65 5f10 0f73 686f 7749 636f 6e50 7265  ze_..showIconPre
-00005cd0: 7669 6577 5763 6f6c 756d 6e73 5f10 1163  viewWcolumns_..c
-00005ce0: 616c 6375 6c61 7465 416c 6c53 697a 6573  alculateAllSizes
-00005cf0: 5874 6578 7453 697a 655a 736f 7274 436f  XtextSizeZsortCo
-00005d00: 6c75 6d6e 5f10 1075 7365 5265 6c61 7469  lumn_..useRelati
-00005d10: 7665 4461 7465 735f 1012 7669 6577 4f70  veDates_..viewOp
-00005d20: 7469 6f6e 7356 6572 7369 6f6e 2340 3000  tionsVersion#@0.
-00005d30: 0000 0000 0009 d90c 0d0e 0f10 1112 1314  ................
-00005d40: 151e 2328 2c31 363b 4058 636f 6d6d 656e  ..#(,16;@Xcommen
-00005d50: 7473 5e64 6174 654c 6173 744f 7065 6e65  ts^dateLastOpene
-00005d60: 645c 6461 7465 4d6f 6469 6669 6564 5b64  d\dateModified[d
-00005d70: 6174 6543 7265 6174 6564 5473 697a 6555  ateCreatedTsizeU
-00005d80: 6c61 6265 6c54 6b69 6e64 5776 6572 7369  labelTkindWversi
-00005d90: 6f6e 546e 616d 65d4 1617 1819 1a1b 0a1d  onTname.........
-00005da0: 5776 6973 6962 6c65 5577 6964 7468 5961  WvisibleUwidthYa
-00005db0: 7363 656e 6469 6e67 5569 6e64 6578 0811  scendingUindex..
-00005dc0: 012c 0910 07d4 1617 1819 1a20 1a22 0810  .,......... ."..
-00005dd0: c808 1008 d416 1718 190a 251a 2709 10b5  ..........%.'...
-00005de0: 0810 01d4 1617 1819 1a25 1a2b 0808 1002  .........%.+....
-00005df0: d416 1718 190a 2e1a 3009 1061 0810 03d4  ........0..a....
-00005e00: 1617 1819 1a33 0a35 0810 6409 1005 d416  .....3.5..d.....
-00005e10: 1718 190a 380a 3a09 1073 0910 04d4 1617  ....8.:..s......
-00005e20: 1819 1a3d 0a3f 0810 4b09 1006 d416 1718  ...=.?..K.......
-00005e30: 190a 420a 4409 1102 d009 1000 0823 4028  ..B.D........#@(
-00005e40: 0000 0000 0000 546e 616d 6509 0008 0019  ......Tname.....
-00005e50: 0022 0034 003c 0050 0059 0064 0077 008c  .".4.<.P.Y.d.w..
-00005e60: 0095 0096 00a9 00b2 00c1 00ce 00da 00df  ................
-00005e70: 00e5 00ea 00f2 00f7 0100 0108 010e 0118  ................
-00005e80: 011e 011f 0122 0123 0125 012e 012f 0131  .....".#.%.../.1
-00005e90: 0132 0134 013d 013e 0140 0141 0143 014c  .2.4.=.>.@.A.C.L
-00005ea0: 014d 014e 0150 0159 015a 015c 015d 015f  .M.N.P.Y.Z.\.]._
-00005eb0: 0168 0169 016b 016c 016e 0177 0178 017a  .h.i.k.l.n.w.x.z
-00005ec0: 017b 017d 0186 0187 0189 018a 018c 0195  .{.}............
-00005ed0: 0196 0199 019a 019c 019d 01a6 01ab 0000  ................
-00005ee0: 0000 0000 0201 0000 0000 0000 0049 0000  .............I..
-00005ef0: 0000 0000 0000 0000 0000 0000 01ac 0000  ................
-00005f00: 000e 0070 006f 0073 0065 005f 0069 006d  ...p.o.s.e._.i.m
-00005f10: 0070 006f 0072 0074 0065 0072 0073 6d6f  .p.o.r.t.e.r.smo
-00005f20: 4444 626c 6f62 0000 0008 0b30 86dc dcf4  DDblob.....0....
-00005f30: c441 0000 000e 0070 006f 0073 0065 005f  .A.....p.o.s.e._
-00005f40: 0069 006d 0070 006f 0072 0074 0065 0072  .i.m.p.o.r.t.e.r
-00005f50: 0073 6d6f 6444 626c 6f62 0000 0008 be76  .smodDblob.....v
-00005f60: 2985 44f2 c441 0000 000e 0070 006f 0073  ).D..A.....p.o.s
-00005f70: 0065 005f 0069 006d 0070 006f 0072 0074  .e._.i.m.p.o.r.t
-00005f80: 0065 0072 0073 7068 3153 636f 6d70 0000  .e.r.sph1Scomp..
-00005f90: 0000 0004 4000 0000 0000 0000 0000 0000  ....@...........
-00005fa0: 0000 01fe 0000 0000 0000 0000 0000 0000  ................
-00005fb0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
-00005fc0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
-00005fd0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
+00005cb0: 0809 0a0b 1d45 4647 0a5f 1012 7669 6577  .....EFG._..view
+00005cc0: 4f70 7469 6f6e 7356 6572 7369 6f6e 5f10  OptionsVersion_.
+00005cd0: 0f73 686f 7749 636f 6e50 7265 7669 6577  .showIconPreview
+00005ce0: 5763 6f6c 756d 6e73 5f10 1163 616c 6375  Wcolumns_..calcu
+00005cf0: 6c61 7465 416c 6c53 697a 6573 5874 6578  lateAllSizesXtex
+00005d00: 7453 697a 655a 736f 7274 436f 6c75 6d6e  tSizeZsortColumn
+00005d10: 5869 636f 6e53 697a 655f 1010 7573 6552  XiconSize_..useR
+00005d20: 656c 6174 6976 6544 6174 6573 1001 09d9  elativeDates....
+00005d30: 0c0d 0e0f 1011 1213 1415 1e23 272b 3035  ...........#'+05
+00005d40: 3a3f 5863 6f6d 6d65 6e74 735e 6461 7465  :?Xcomments^date
+00005d50: 4c61 7374 4f70 656e 6564 5c64 6174 654d  LastOpened\dateM
+00005d60: 6f64 6966 6965 645b 6461 7465 4372 6561  odified[dateCrea
+00005d70: 7465 6454 7369 7a65 556c 6162 656c 546b  tedTsizeUlabelTk
+00005d80: 696e 6457 7665 7273 696f 6e54 6e61 6d65  indWversionTname
+00005d90: d416 1718 191a 1b0a 1d55 696e 6465 7855  .........UindexU
+00005da0: 7769 6474 6859 6173 6365 6e64 696e 6757  widthYascendingW
+00005db0: 7669 7369 626c 6510 0711 012c 0908 d416  visible....,....
+00005dc0: 1718 191f 201d 1d10 0810 c808 08d4 1617  .... ...........
+00005dd0: 1819 0924 1d0a 10b5 0809 d416 1718 1928  ...$...........(
+00005de0: 241d 1d10 0208 08d4 1617 1819 2c2d 1d0a  $...........,-..
+00005df0: 1003 1061 0809 d416 1718 1931 320a 1d10  ...a.......12...
+00005e00: 0510 6409 08d4 1617 1819 3637 0a0a 1004  ..d.......67....
+00005e10: 1073 0909 d416 1718 193b 3c0a 1d10 0610  .s.......;<.....
+00005e20: 4b09 08d4 1617 1819 4041 0a0a 1000 10ea  K.......@A......
+00005e30: 0909 0823 4028 0000 0000 0000 546e 616d  ...#@(......Tnam
+00005e40: 6523 4030 0000 0000 0000 0900 0800 1900  e#@0............
+00005e50: 2e00 4000 4800 5c00 6500 7000 7900 8c00  ..@.H.\.e.p.y...
+00005e60: 8e00 8f00 a200 ab00 ba00 c700 d300 d800  ................
+00005e70: de00 e300 eb00 f000 f900 ff01 0501 0f01  ................
+00005e80: 1701 1901 1c01 1d01 1e01 2701 2901 2b01  ..........'.).+.
+00005e90: 2c01 2d01 3601 3801 3901 3a01 4301 4501  ,.-.6.8.9.:.C.E.
+00005ea0: 4601 4701 5001 5201 5401 5501 5601 5f01  F.G.P.R.T.U.V._.
+00005eb0: 6101 6301 6401 6501 6e01 7001 7201 7301  a.c.d.e.n.p.r.s.
+00005ec0: 7401 7d01 7f01 8101 8201 8301 8c01 8e01  t.}.............
+00005ed0: 9001 9101 9201 9301 9c01 a101 aa00 0000  ................
+00005ee0: 0000 0002 0100 0000 0000 0000 4900 0000  ............I...
+00005ef0: 0000 0000 0000 0000 0000 0001 ab00 0000  ................
+00005f00: 0e00 7000 6f00 7300 6500 5f00 6900 6d00  ..p.o.s.e._.i.m.
+00005f10: 7000 6f00 7200 7400 6500 7200 736d 6f44  p.o.r.t.e.r.smoD
+00005f20: 4462 6c6f 6200 0000 0854 85ff 04d2 fcc4  Dblob....T......
+00005f30: 4100 0000 0e00 7000 6f00 7300 6500 5f00  A.....p.o.s.e._.
+00005f40: 6900 6d00 7000 6f00 7200 7400 6500 7200  i.m.p.o.r.t.e.r.
+00005f50: 736d 6f64 4462 6c6f 6200 0000 08ac 084a  smodDblob......J
+00005f60: 662c fcc4 4100 0000 0e00 7000 6f00 7300  f,..A.....p.o.s.
+00005f70: 6500 5f00 6900 6d00 7000 6f00 7200 7400  e._.i.m.p.o.r.t.
+00005f80: 6500 7200 7370 6831 5363 6f6d 7000 0000  e.r.sph1Scomp...
+00005f90: 0000 0420 0001 a201 a301 ac01 bb01 bd01  ... ............
+00005fa0: be01 bf01 c801 d201 d301 d401 d501 de01  ................
+00005fb0: e701 f401 fd00 0000 0000 0002 0100 0000  ................
+00005fc0: 0000 0000 4d00 0000 0000 0000 0000 0000  ....M...........
+00005fd0: 0000 0001 fe00 0000 0000 0000 0000 0000  ................
 00005fe0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00005ff0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00006000: 0000 0000 0000 0000 0000 0011 0000 0009  ................
 00006010: 0072 006f 0069 005f 0074 006f 006f 006c  .r.o.i._.t.o.o.l
 00006020: 0073 6277 7370 626c 6f62 0000 00c9 6270  .sbwspblob....bp
 00006030: 6c69 7374 3030 d701 0203 0405 0607 0808  list00..........
 00006040: 0a08 0a0d 0a5d 5368 6f77 5374 6174 7573  .....]ShowStatus
@@ -1547,15 +1547,15 @@
 000060a0: 5369 6465 6261 7208 0809 0809 5f10 187b  Sidebar....._..{
 000060b0: 7b33 3234 2c20 3332 7d2c 207b 3132 3530  {324, 32}, {1250
 000060c0: 2c20 3736 317d 7d09 0817 2531 3d49 606d  , 761}}...%1=I`m
 000060d0: 797a 7b7c 7d7e 9900 0000 0000 0001 0100  yz{|}~..........
 000060e0: 0000 0000 0000 0f00 0000 0000 0000 0000  ................
 000060f0: 0000 0000 0000 9a00 0000 0900 7200 6f00  ............r.o.
 00006100: 6900 5f00 7400 6f00 6f00 6c00 736c 6731  i._.t.o.o.l.slg1
-00006110: 5363 6f6d 7000 0000 0000 0449 7300 0000  Scomp......Is...
+00006110: 5363 6f6d 7000 0000 0000 0423 8a00 0000  Scomp......#....
 00006120: 0900 7200 6f00 6900 5f00 7400 6f00 6f00  ..r.o.i._.t.o.o.
 00006130: 6c00 736c 7376 4362 6c6f 6200 0002 7962  l.slsvCblob...yb
 00006140: 706c 6973 7430 30d8 0102 0304 0506 0708  plist00.........
 00006150: 090a 0b16 4647 480a 5f10 1276 6965 774f  ....FGH._..viewO
 00006160: 7074 696f 6e73 5665 7273 696f 6e5f 100f  ptionsVersion_..
 00006170: 7368 6f77 4963 6f6e 5072 6576 6965 7757  showIconPreviewW
 00006180: 636f 6c75 6d6e 735f 1011 6361 6c63 756c  columns_..calcul
@@ -1631,21 +1631,21 @@
 000065e0: 0152 0154 0155 0156 015f 0161 0163 0164  .R.T.U.V._.a.c.d
 000065f0: 0165 016e 0170 0172 0173 0174 017d 017f  .e.n.p.r.s.t.}..
 00006600: 0181 0182 0183 018c 018e 0191 0192 0193  ................
 00006610: 0194 019d 01a2 01ab 0000 0000 0000 0201  ................
 00006620: 0000 0000 0000 0049 0000 0000 0000 0000  .......I........
 00006630: 0000 0000 0000 01ac 0000 0009 0072 006f  .............r.o
 00006640: 0069 005f 0074 006f 006f 006c 0073 6d6f  .i._.t.o.o.l.smo
-00006650: 4444 626c 6f62 0000 0008 6030 99e3 46f2  DDblob....`0..F.
+00006650: 4444 626c 6f62 0000 0008 a02c 4966 bbfc  DDblob.....,If..
 00006660: c441 0000 0009 0072 006f 0069 005f 0074  .A.....r.o.i._.t
 00006670: 006f 006f 006c 0073 6d6f 6444 626c 6f62  .o.o.l.smodDblob
-00006680: 0000 0008 6030 99e3 46f2 c441 0000 0009  ....`0..F..A....
+00006680: 0000 0008 29c9 1a35 2cfc c441 0000 0009  ....)..5,..A....
 00006690: 0072 006f 0069 005f 0074 006f 006f 006c  .r.o.i._.t.o.o.l
 000066a0: 0073 7068 3153 636f 6d70 0000 0000 0005  .sph1Scomp......
-000066b0: 2000 0000 0009 0072 006f 0069 005f 0074   ......r.o.i._.t
+000066b0: 0000 0000 0009 0072 006f 0069 005f 0074  .......r.o.i._.t
 000066c0: 006f 006f 006c 0073 7653 726e 6c6f 6e67  .o.o.l.svSrnlong
 000066d0: 0000 0001 0000 001b 0074 0068 0069 0072  .........t.h.i.r
 000066e0: 0064 005f 0070 0061 0072 0074 0079 005f  .d._.p.a.r.t.y._
 000066f0: 006c 0061 0062 0065 006c 005f 0061 0070  .l.a.b.e.l._.a.p
 00006700: 0070 0065 006e 0064 0065 0072 0073 6277  .p.e.n.d.e.r.sbw
 00006710: 7370 626c 6f62 0000 00c9 6270 6c69 7374  spblob....bplist
 00006720: 3030 d701 0203 0405 0607 0808 0a08 0a0d  00..............
@@ -1660,15 +1660,15 @@
 000067b0: 347d 7d09 0817 2531 3d49 606d 797a 7b7c  4}}...%1=I`myz{|
 000067c0: 7d7e 9900 0000 0000 0001 0100 0000 0000  }~..............
 000067d0: 0000 0f00 0000 0000 0000 0000 0000 0000  ................
 000067e0: 0000 9a00 0000 1b00 7400 6800 6900 7200  ........t.h.i.r.
 000067f0: 6400 5f00 7000 6100 7200 7400 7900 5f00  d._.p.a.r.t.y._.
 00006800: 6c00 6100 6200 6500 6c00 5f00 6100 7000  l.a.b.e.l._.a.p.
 00006810: 7000 6500 6e00 6400 6500 7200 736c 6731  p.e.n.d.e.r.slg1
-00006820: 5363 6f6d 7000 0000 0000 0221 1f00 0000  Scomp......!....
+00006820: 5363 6f6d 7000 0000 0000 021a c200 0000  Scomp...........
 00006830: 1b00 7400 6800 6900 7200 6400 5f00 7000  ..t.h.i.r.d._.p.
 00006840: 6100 7200 7400 7900 5f00 6c00 6100 6200  a.r.t.y._.l.a.b.
 00006850: 6500 6c00 5f00 6100 7000 7000 6500 6e00  e.l._.a.p.p.e.n.
 00006860: 6400 6500 7200 736c 7376 4362 6c6f 6200  d.e.r.slsvCblob.
 00006870: 0002 7962 706c 6973 7430 30d8 0102 0304  ..ybplist00.....
 00006880: 0506 0708 090a 0b16 4647 480a 5f10 1276  ........FGH._..v
 00006890: 6965 774f 7074 696f 6e73 5665 7273 696f  iewOptionsVersio
@@ -1751,47 +1751,47 @@
 00006d60: 018e 0191 0192 0193 0194 019d 01a2 01ab  ................
 00006d70: 0000 0000 0000 0201 0000 0000 0000 0049  ...............I
 00006d80: 0000 0000 0000 0000 0000 0000 0000 01ac  ................
 00006d90: 0000 001b 0074 0068 0069 0072 0064 005f  .....t.h.i.r.d._
 00006da0: 0070 0061 0072 0074 0079 005f 006c 0061  .p.a.r.t.y._.l.a
 00006db0: 0062 0065 006c 005f 0061 0070 0070 0065  .b.e.l._.a.p.p.e
 00006dc0: 006e 0064 0065 0072 0073 6d6f 4444 626c  .n.d.e.r.smoDDbl
-00006dd0: 6f62 0000 0008 6874 98e3 46f2 c441 0000  ob....ht..F..A..
+00006dd0: 6f62 0000 0008 4c89 caff 10fc c441 0000  ob....L......A..
 00006de0: 001b 0074 0068 0069 0072 0064 005f 0070  ...t.h.i.r.d._.p
 00006df0: 0061 0072 0074 0079 005f 006c 0061 0062  .a.r.t.y._.l.a.b
 00006e00: 0065 006c 005f 0061 0070 0070 0065 006e  .e.l._.a.p.p.e.n
 00006e10: 0064 0065 0072 0073 6d6f 6444 626c 6f62  .d.e.r.smodDblob
-00006e20: 0000 0008 6874 98e3 46f2 c441 0000 001b  ....ht..F..A....
+00006e20: 0000 0008 4c89 caff 10fc c441 0000 001b  ....L......A....
 00006e30: 0074 0068 0069 0072 0064 005f 0070 0061  .t.h.i.r.d._.p.a
 00006e40: 0072 0074 0079 005f 006c 0061 0062 0065  .r.t.y._.l.a.b.e
 00006e50: 006c 005f 0061 0070 0070 0065 006e 0064  .l._.a.p.p.e.n.d
 00006e60: 0065 0072 0073 7068 3153 636f 6d70 0000  .e.r.sph1Scomp..
-00006e70: 0000 0002 c000 0000 001b 0074 0068 0069  ...........t.h.i
+00006e70: 0000 0002 b000 0000 001b 0074 0068 0069  ...........t.h.i
 00006e80: 0072 0064 005f 0070 0061 0072 0074 0079  .r.d._.p.a.r.t.y
 00006e90: 005f 006c 0061 0062 0065 006c 005f 0061  ._.l.a.b.e.l._.a
 00006ea0: 0070 0070 0065 006e 0064 0065 0072 0073  .p.p.e.n.d.e.r.s
 00006eb0: 7653 726e 6c6f 6e67 0000 0001 0000 000c  vSrnlong........
 00006ec0: 0075 006e 0073 0075 0070 0065 0072 0076  .u.n.s.u.p.e.r.v
 00006ed0: 0069 0073 0065 0064 6277 7370 626c 6f62  .i.s.e.dbwspblob
 00006ee0: 0000 00ca 6270 6c69 7374 3030 d701 0203  ....bplist00....
 00006ef0: 0405 0607 0808 0a08 0a0d 0a5d 5368 6f77  ...........]Show
 00006f00: 5374 6174 7573 4261 725b 5368 6f77 5061  StatusBar[ShowPa
 00006f10: 7468 6261 725b 5368 6f77 546f 6f6c 6261  thbar[ShowToolba
 00006f20: 725b 5368 6f77 5461 6256 6965 775f 1014  r[ShowTabView_..
 00006f30: 436f 6e74 6169 6e65 7253 686f 7753 6964  ContainerShowSid
 00006f40: 6562 6172 5c57 696e 646f 7742 6f75 6e64  ebar\WindowBound
 00006f50: 735b 5368 6f77 5369 6465 6261 7208 0809  s[ShowSidebar...
-00006f60: 0809 5f10 197b 7b32 3633 2c20 3239 357d  .._..{{263, 295}
+00006f60: 0809 5f10 197b 7b32 3630 2c20 3136 327d  .._..{{260, 162}
 00006f70: 2c20 7b31 3138 302c 2035 3538 7d7d 0908  , {1180, 558}}..
 00006f80: 1725 313d 4960 6d79 7a7b 7c7d 7e9a 0000  .%1=I`myz{|}~...
 00006f90: 0000 0000 0101 0000 0000 0000 000f 0000  ................
-00006fa0: 0000 0000 0000 0000 0000 0000 009b 0000  ................
-00006fb0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
-00006fc0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
-00006fd0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
+00006fa0: 0000 0000 0000 0000 0000 0000 009b de01  ................
+00006fb0: e701 f401 fd00 0000 0000 0002 0100 0000  ................
+00006fc0: 0000 0000 4d00 0000 0000 0000 0000 0000  ....M...........
+00006fd0: 0000 0001 fe00 0000 0000 0000 0000 0000  ................
 00006fe0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00006ff0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00007000: 0000 0000 0000 0002 0000 0005 0000 0004  ................
 00007010: 0000 0014 0062 0061 0074 0063 0068 005f  .....b.a.t.c.h._
 00007020: 0070 0072 006f 0063 0065 0073 0073 005f  .p.r.o.c.e.s.s._
 00007030: 0076 0069 0064 0065 006f 0073 7653 726e  .v.i.d.e.o.svSrn
 00007040: 6c6f 6e67 0000 0001 0000 0005 0000 0012  long............
@@ -1838,70 +1838,70 @@
 000072d0: 8a01 8b01 8d01 9601 9701 9901 9a01 9c01  ................
 000072e0: a501 a601 a801 a901 ab01 b401 b501 b801  ................
 000072f0: b901 bb01 bc01 c501 ce01 db01 e400 0000  ................
 00007300: 0000 0002 0100 0000 0000 0000 4c00 0000  ............L...
 00007310: 0000 0000 0000 0000 0000 0001 e500 0000  ................
 00007320: 0600 0000 0800 7000 6c00 6f00 7400 7400  ......p.l.o.t.t.
 00007330: 6900 6e00 676c 7376 7062 6c6f 6200 0002  i.n.glsvpblob...
-00007340: a062 706c 6973 7430 30da 0102 0304 0506  .bplist00.......
-00007350: 0708 090a 0b0c 0d1c 4748 494a 4b0c 5f10  ........GHIJK._.
-00007360: 1276 6965 774f 7074 696f 6e73 5665 7273  .viewOptionsVers
-00007370: 696f 6e5f 100f 7368 6f77 4963 6f6e 5072  ion_..showIconPr
-00007380: 6576 6965 7757 636f 6c75 6d6e 735f 1011  eviewWcolumns_..
-00007390: 6361 6c63 756c 6174 6541 6c6c 5369 7a65  calculateAllSize
-000073a0: 735f 100f 7363 726f 6c6c 506f 7369 7469  s_..scrollPositi
-000073b0: 6f6e 5958 7465 7874 5369 7a65 5f10 0f73  onYXtextSize_..s
-000073c0: 6372 6f6c 6c50 6f73 6974 696f 6e58 5a73  crollPositionXZs
-000073d0: 6f72 7443 6f6c 756d 6e58 6963 6f6e 5369  ortColumnXiconSi
-000073e0: 7a65 5f10 1075 7365 5265 6c61 7469 7665  ze_..useRelative
-000073f0: 4461 7465 7310 0109 d90e 0f10 1112 1314  Dates...........
-00007400: 1516 1720 2529 2d32 373c 4158 636f 6d6d  ... %)-27<AXcomm
-00007410: 656e 7473 5e64 6174 654c 6173 744f 7065  ents^dateLastOpe
-00007420: 6e65 645c 6461 7465 4d6f 6469 6669 6564  ned\dateModified
-00007430: 5b64 6174 6543 7265 6174 6564 5473 697a  [dateCreatedTsiz
-00007440: 6555 6c61 6265 6c54 6b69 6e64 5776 6572  eUlabelTkindWver
-00007450: 7369 6f6e 546e 616d 65d4 1819 1a1b 1c1d  sionTname.......
-00007460: 0c1f 5776 6973 6962 6c65 5577 6964 7468  ..WvisibleUwidth
-00007470: 5961 7363 656e 6469 6e67 5569 6e64 6578  YascendingUindex
-00007480: 0811 012c 0910 07d4 1819 1a1b 1c22 1c24  ...,.........".$
-00007490: 0810 c808 1008 d418 191a 1b0c 271c 0b09  ............'...
-000074a0: 10b5 08d4 1819 1a1b 1c27 1c2c 0808 1002  .........'.,....
-000074b0: d418 191a 1b0c 2f1c 3109 1061 0810 03d4  ....../.1..a....
-000074c0: 1819 1a1b 1c34 0c36 0810 6409 1005 d418  .....4.6..d.....
-000074d0: 191a 1b0c 390c 3b09 1073 0910 04d4 1819  ....9.;..s......
-000074e0: 1a1b 1c3e 0c40 0810 4b09 1006 d418 191a  ...>.@..K.......
-000074f0: 1b0c 430c 4509 1101 2709 1000 0823 4048  ..C.E...'....#@H
-00007500: 0000 0000 0000 2340 2800 0000 0000 0023  ......#@(......#
-00007510: 0000 0000 0000 0000 546e 616d 6523 4030  ........Tname#@0
-00007520: 0000 0000 0000 0900 0800 1d00 3200 4400  ............2.D.
-00007530: 4c00 6000 7200 7b00 8d00 9800 a100 b400  L.`.r.{.........
-00007540: b600 b700 ca00 d300 e200 ef00 fb01 0001  ................
-00007550: 0601 0b01 1301 1801 2101 2901 2f01 3901  ........!.)./.9.
-00007560: 3f01 4001 4301 4401 4601 4f01 5001 5201  ?.@.C.D.F.O.P.R.
-00007570: 5301 5501 5e01 5f01 6101 6201 6b01 6c01  S.U.^._.a.b.k.l.
-00007580: 6d01 6f01 7801 7901 7b01 7c01 7e01 8701  m.o.x.y.{.|.~...
-00007590: 8801 8a01 8b01 8d01 9601 9701 9901 9a01  ................
-000075a0: 9c01 a501 a601 a801 a901 ab01 b401 b501  ................
-000075b0: b801 b901 bb01 bc01 c501 ce01 d701 dc01  ................
-000075c0: e500 0000 0000 0002 0100 0000 0000 0000  ................
-000075d0: 4d00 0000 0000 0000 0000 0000 0000 0001  M...............
-000075e0: e600 0000 0700 0000 0e00 7000 6f00 7300  ..........p.o.s.
-000075f0: 6500 5f00 6900 6d00 7000 6f00 7200 7400  e._.i.m.p.o.r.t.
-00007600: 6500 7200 7376 5372 6e6c 6f6e 6700 0000  e.r.svSrnlong...
-00007610: 0100 0000 0800 0000 0c00 7500 6e00 7300  ..........u.n.s.
-00007620: 7500 7000 6500 7200 7600 6900 7300 6500  u.p.e.r.v.i.s.e.
-00007630: 6464 7363 6c62 6f6f 6c00 0009 0072 006f  ddsclbool....r.o
+00007340: 9562 706c 6973 7430 30da 0102 0304 0506  .bplist00.......
+00007350: 0708 090a 0b0c 0d1c 4849 484a 0c29 5869  ........HIHJ.)Xi
+00007360: 636f 6e53 697a 655f 100f 7368 6f77 4963  conSize_..showIc
+00007370: 6f6e 5072 6576 6965 7757 636f 6c75 6d6e  onPreviewWcolumn
+00007380: 735f 1011 6361 6c63 756c 6174 6541 6c6c  s_..calculateAll
+00007390: 5369 7a65 735f 100f 7363 726f 6c6c 506f  Sizes_..scrollPo
+000073a0: 7369 7469 6f6e 5958 7465 7874 5369 7a65  sitionYXtextSize
+000073b0: 5f10 0f73 6372 6f6c 6c50 6f73 6974 696f  _..scrollPositio
+000073c0: 6e58 5a73 6f72 7443 6f6c 756d 6e5f 1010  nXZsortColumn_..
+000073d0: 7573 6552 656c 6174 6976 6544 6174 6573  useRelativeDates
+000073e0: 5f10 1276 6965 774f 7074 696f 6e73 5665  _..viewOptionsVe
+000073f0: 7273 696f 6e23 4030 0000 0000 0000 09d9  rsion#@0........
+00007400: 0e0f 1011 1213 1415 1617 2025 2a2e 3338  .......... %*.38
+00007410: 3d42 5863 6f6d 6d65 6e74 735e 6461 7465  =BXcomments^date
+00007420: 4c61 7374 4f70 656e 6564 5c64 6174 654d  LastOpened\dateM
+00007430: 6f64 6966 6965 645b 6461 7465 4372 6561  odified[dateCrea
+00007440: 7465 6454 7369 7a65 556c 6162 656c 546b  tedTsizeUlabelTk
+00007450: 696e 6457 7665 7273 696f 6e54 6e61 6d65  indWversionTname
+00007460: d418 191a 1b1c 1d0c 1f57 7669 7369 626c  .........Wvisibl
+00007470: 6555 7769 6474 6859 6173 6365 6e64 696e  eUwidthYascendin
+00007480: 6755 696e 6465 7808 1101 2c09 1007 d418  gUindex...,.....
+00007490: 191a 1b1c 221c 2408 10c8 0810 08d4 1819  ....".$.........
+000074a0: 1a1b 0c27 1c29 0910 b508 1001 d418 191a  ...'.)..........
+000074b0: 1b1c 271c 2d08 0810 02d4 1819 1a1b 0c30  ..'.-..........0
+000074c0: 1c32 0910 6108 1003 d418 191a 1b1c 350c  .2..a.........5.
+000074d0: 3708 1064 0910 05d4 1819 1a1b 0c3a 0c3c  7..d.........:.<
+000074e0: 0910 7309 1004 d418 191a 1b1c 3f0c 4108  ..s.........?.A.
+000074f0: 104b 0910 06d4 1819 1a1b 0c44 0c46 0911  .K.........D.F..
+00007500: 0127 0910 0008 2300 0000 0000 0000 0023  .'....#........#
+00007510: 4028 0000 0000 0000 546e 616d 6509 0008  @(......Tname...
+00007520: 001d 0026 0038 0040 0054 0066 006f 0081  ...&.8.@.T.f.o..
+00007530: 008c 009f 00b4 00bd 00be 00d1 00da 00e9  ................
+00007540: 00f6 0102 0107 010d 0112 011a 011f 0128  ...............(
+00007550: 0130 0136 0140 0146 0147 014a 014b 014d  .0.6.@.F.G.J.K.M
+00007560: 0156 0157 0159 015a 015c 0165 0166 0168  .V.W.Y.Z.\.e.f.h
+00007570: 0169 016b 0174 0175 0176 0178 0181 0182  .i.k.t.u.v.x....
+00007580: 0184 0185 0187 0190 0191 0193 0194 0196  ................
+00007590: 019f 01a0 01a2 01a3 01a5 01ae 01af 01b1  ................
+000075a0: 01b2 01b4 01bd 01be 01c1 01c2 01c4 01c5  ................
+000075b0: 01ce 01d7 01dc 0000 0000 0000 0201 0000  ................
+000075c0: 0000 0000 004c 0000 0000 0000 0000 0000  .....L..........
+000075d0: 0000 0000 01dd 0000 0007 0000 000e 0070  ...............p
+000075e0: 006f 0073 0065 005f 0069 006d 0070 006f  .o.s.e._.i.m.p.o
+000075f0: 0072 0074 0065 0072 0073 7653 726e 6c6f  .r.t.e.r.svSrnlo
+00007600: 6e67 0000 0001 0000 0008 0000 000c 0075  ng.............u
+00007610: 006e 0073 0075 0070 0065 0072 0076 0069  .n.s.u.p.e.r.v.i
+00007620: 0073 0065 0064 6473 636c 626f 6f6c 0000  .s.e.ddsclbool..
+00007630: 0000 0000 0000 01ac 0000 0009 0072 006f  .............r.o
 00007640: 0069 005f 0074 006f 006f 006c 0073 6d6f  .i._.t.o.o.l.smo
-00007650: 4444 626c 6f62 0000 0008 6030 99e3 46f2  DDblob....`0..F.
+00007650: 4444 626c 6f62 0000 0008 a02c 4966 bbfc  DDblob.....,If..
 00007660: c441 0000 0009 0072 006f 0069 005f 0074  .A.....r.o.i._.t
 00007670: 006f 006f 006c 0073 6d6f 6444 626c 6f62  .o.o.l.smodDblob
-00007680: 0000 0008 6030 99e3 46f2 c441 0000 0009  ....`0..F..A....
+00007680: 0000 0008 29c9 1a35 2cfc c441 0000 0009  ....)..5,..A....
 00007690: 0072 006f 0069 005f 0074 006f 006f 006c  .r.o.i._.t.o.o.l
 000076a0: 0073 7068 3153 636f 6d70 0000 0000 0005  .sph1Scomp......
-000076b0: 2000 0000 0009 0072 006f 0069 005f 0074   ......r.o.i._.t
+000076b0: 0000 0000 0009 0072 006f 0069 005f 0074  .......r.o.i._.t
 000076c0: 006f 006f 006c 0073 7653 726e 6c6f 6e67  .o.o.l.svSrnlong
 000076d0: 0000 0001 0000 001b 0074 0068 0069 0072  .........t.h.i.r
 000076e0: 0064 005f 0070 0061 0072 0074 0079 005f  .d._.p.a.r.t.y._
 000076f0: 006c 0061 0062 0065 006c 005f 0061 0070  .l.a.b.e.l._.a.p
 00007700: 0070 0065 006e 0064 0065 0072 0073 6277  .p.e.n.d.e.r.sbw
 00007710: 7370 626c 6f62 0000 00c9 6270 6c69 7374  spblob....bplist
 00007720: 3030 d701 0203 0405 0607 0808 0a08 0a0d  00..............
@@ -1993,43 +1993,43 @@
 00007c80: 0000 0000 0100 0200 0000 0000 0100 0400  ................
 00007c90: 0000 0000 0100 0800 0000 0000 0100 1000  ................
 00007ca0: 0000 0000 0100 2000 0000 0000 0100 4000  ...... .......@.
 00007cb0: 0000 0000 0100 8000 0000 0000 0101 0000  ................
 00007cc0: 0000 0000 0102 0000 0000 0000 0104 0000  ................
 00007cd0: 0000 0000 0108 0000 0000 0000 0110 0000  ................
 00007ce0: 0000 0000 0120 0000 0000 0000 0140 0000  ..... .......@..
-00007cf0: 0000 0000 0009 1101 2709 1000 0823 4048  ........'....#@H
-00007d00: 0000 0000 0000 2340 2800 0000 0000 0023  ......#@(......#
-00007d10: 0000 0000 0000 0000 546e 616d 6523 4030  ........Tname#@0
-00007d20: 0000 0000 0000 0900 0800 1d00 3200 4400  ............2.D.
-00007d30: 4c00 6000 7200 7b00 8d00 9800 a100 b400  L.`.r.{.........
-00007d40: b600 b700 ca00 d300 e200 ef00 fb01 0001  ................
-00007d50: 0601 0b01 1301 1801 2101 2901 2f01 3901  ........!.)./.9.
-00007d60: 3f01 4001 4301 4401 4601 4f01 5001 5201  ?.@.C.D.F.O.P.R.
-00007d70: 5301 5501 5e01 5f01 6101 6201 6b01 6c01  S.U.^._.a.b.k.l.
-00007d80: 6d01 6f01 7801 7901 7b01 7c01 7e01 8701  m.o.x.y.{.|.~...
-00007d90: 8801 8a01 8b01 8d01 9601 9701 9901 9a01  ................
-00007da0: 9c01 a501 a601 a801 a901 ab01 b401 b501  ................
-00007db0: b801 b901 bb01 bc01 c501 ce01 d701 dc01  ................
-00007dc0: e500 0000 0000 0002 0100 0000 0000 0000  ................
-00007dd0: 4d00 0000 0000 0000 0000 0000 0000 0001  M...............
-00007de0: e600 0000 0700 0000 0e00 7000 6f00 7300  ..........p.o.s.
-00007df0: 6500 5f00 6900 6d00 7000 6f00 7200 7400  e._.i.m.p.o.r.t.
-00007e00: 6500 7200 7376 5372 6e6c 6f6e 6700 0000  e.r.svSrnlong...
-00007e10: 0100 0000 0800 0000 0c00 7500 6e00 7300  ..........u.n.s.
-00007e20: 7500 7000 6500 7200 7600 6900 7300 6500  u.p.e.r.v.i.s.e.
-00007e30: 6464 7363 6c62 6f6f 6c00 0009 0072 006f  ddsclbool....r.o
+00007cf0: 0000 0000 00d4 1819 1a1b 0c44 0c46 0911  ...........D.F..
+00007d00: 0127 0910 0008 2300 0000 0000 0000 0023  .'....#........#
+00007d10: 4028 0000 0000 0000 546e 616d 6509 0008  @(......Tname...
+00007d20: 001d 0026 0038 0040 0054 0066 006f 0081  ...&.8.@.T.f.o..
+00007d30: 008c 009f 00b4 00bd 00be 00d1 00da 00e9  ................
+00007d40: 00f6 0102 0107 010d 0112 011a 011f 0128  ...............(
+00007d50: 0130 0136 0140 0146 0147 014a 014b 014d  .0.6.@.F.G.J.K.M
+00007d60: 0156 0157 0159 015a 015c 0165 0166 0168  .V.W.Y.Z.\.e.f.h
+00007d70: 0169 016b 0174 0175 0176 0178 0181 0182  .i.k.t.u.v.x....
+00007d80: 0184 0185 0187 0190 0191 0193 0194 0196  ................
+00007d90: 019f 01a0 01a2 01a3 01a5 01ae 01af 01b1  ................
+00007da0: 01b2 01b4 01bd 01be 01c1 01c2 01c4 01c5  ................
+00007db0: 01ce 01d7 01dc 0000 0000 0000 0201 0000  ................
+00007dc0: 0000 0000 004c 0000 0000 0000 0000 0000  .....L..........
+00007dd0: 0000 0000 01dd 0000 0007 0000 000e 0070  ...............p
+00007de0: 006f 0073 0065 005f 0069 006d 0070 006f  .o.s.e._.i.m.p.o
+00007df0: 0072 0074 0065 0072 0073 7653 726e 6c6f  .r.t.e.r.svSrnlo
+00007e00: 6e67 0000 0001 0000 0008 0000 000c 0075  ng.............u
+00007e10: 006e 0073 0075 0070 0065 0072 0076 0069  .n.s.u.p.e.r.v.i
+00007e20: 0073 0065 0064 6473 636c 626f 6f6c 0000  .s.e.ddsclbool..
+00007e30: 0000 0000 0000 01ac 0000 0009 0072 006f  .............r.o
 00007e40: 0069 005f 0074 006f 006f 006c 0073 6d6f  .i._.t.o.o.l.smo
-00007e50: 4444 626c 6f62 0000 0008 6030 99e3 46f2  DDblob....`0..F.
+00007e50: 4444 626c 6f62 0000 0008 a02c 4966 bbfc  DDblob.....,If..
 00007e60: c441 0000 0009 0072 006f 0069 005f 0074  .A.....r.o.i._.t
 00007e70: 006f 006f 006c 0073 6d6f 6444 626c 6f62  .o.o.l.smodDblob
-00007e80: 0000 0008 6030 99e3 46f2 c441 0000 0009  ....`0..F..A....
+00007e80: 0000 0008 29c9 1a35 2cfc c441 0000 0009  ....)..5,..A....
 00007e90: 0072 006f 0069 005f 0074 006f 006f 006c  .r.o.i._.t.o.o.l
 00007ea0: 0073 7068 3153 636f 6d70 0000 0000 0005  .sph1Scomp......
-00007eb0: 2000 0000 0009 0072 006f 0069 005f 0074   ......r.o.i._.t
+00007eb0: 0000 0000 0009 0072 006f 0069 005f 0074  .......r.o.i._.t
 00007ec0: 006f 006f 006c 0073 7653 726e 6c6f 6e67  .o.o.l.svSrnlong
 00007ed0: 0000 0001 0000 001b 0074 0068 0069 0072  .........t.h.i.r
 00007ee0: 0064 005f 0070 0061 0072 0074 0079 005f  .d._.p.a.r.t.y._
 00007ef0: 006c 0061 0062 0065 006c 005f 0061 0070  .l.a.b.e.l._.a.p
 00007f00: 0070 0065 006e 0064 0065 0072 0073 6277  .p.e.n.d.e.r.sbw
 00007f10: 7370 626c 6f62 0000 00c9 6270 6c69 7374  spblob....bplist
 00007f20: 3030 d701 0203 0405 0607 0808 0a08 0a0d  00..............
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/feature_extractor_14bp.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/feature_extractor_14bp.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,28 +1,22 @@
-from simba.read_config_unit_tests import (insert_default_headers_for_feature_extraction)
 import os
-from simba.feature_extractors.unit_tests import (read_video_info)
-from simba.misc_tools import get_feature_extraction_headers
-from simba.utils.printing import stdout_success
-from simba.drop_bp_cords import get_fn_ext
-from simba.rw_dfs import read_df, save_df
 import pandas as pd
 from copy import deepcopy
-from scipy.spatial import ConvexHull
-import scipy
 import numpy as np
 from collections import defaultdict
 import math
 from simba.enums import Formats
-import time
 from simba.mixins.feature_extraction_mixin import FeatureExtractionMixin
+from simba.mixins.config_reader import ConfigReader
 from simba.feature_extractors.perimeter_jit import jitted_hull
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.utils.read_write import get_fn_ext, write_df, read_df
 
 
-class ExtractFeaturesFrom14bps(FeatureExtractionMixin):
+class ExtractFeaturesFrom14bps(ConfigReader, FeatureExtractionMixin):
     """
     Class for creating a hard-coded set of features from two animals with 7 tracked body-parts
     each using pose-estimation. Results are stored in the `project_folder/csv/features_extracted`
     directory of the SimBA project.
 
     Parameters
     ----------
@@ -33,47 +27,50 @@
     ----------
     Feature extraction tutorial <https://github.com/sgoldenlab/simba/blob/master/docs/tutorial.md#step-5-extract-features>`__.
 
 
     Examples
     ----------
     >>> feature_extractor = ExtractFeaturesFrom14bps(config_path='MyProjectConfig')
-    >>> feature_extractor.extract_features()
+    >>> feature_extractor.run()
     """
     
     def __init__(self,
                  config_path: str):
-        super().__init__(config_path=config_path)
-        self.in_headers = get_feature_extraction_headers(pose='2 animals 14 body-parts')
+        FeatureExtractionMixin.__init__(self, config_path=config_path)
+        ConfigReader.__init__(self, config_path=config_path)
+        self.in_headers = self.get_feature_extraction_headers(pose='2 animals 14 body-parts')
         self.mouse_1_headers, self.mouse_2_headers = self.in_headers[0:21], self.in_headers[21:]
         self.mouse_2_p_headers = [x for x in self.mouse_2_headers if x[-2:] == '_p']
         self.mouse_1_p_headers = [x for x in self.mouse_1_headers if x[-2:] == '_p']
         self.mouse_1_headers = [x for x in self.mouse_1_headers if x[-2:] != '_p']
         self.mouse_2_headers = [x for x in self.mouse_2_headers if x[-2:] != '_p']
         print('Extracting features from {} file(s)...'.format(str(len(self.files_found))))
 
-    def extract_features(self):
+    def run(self):
         """
         Method to compute and save features to disk. Results are saved in the `project_folder/csv/features_extracted`
         directory of the SimBA project.
 
         Returns
         -------
         None
         """
-        session_time = 0
+
+
         for file_cnt, file_path in enumerate(self.files_found):
-            roll_windows, file_start_time = [], time.time()
+            video_timer = SimbaTimer(start=True)
+            roll_windows = []
             _, self.video_name, _ = get_fn_ext(file_path)
-            video_settings, self.px_per_mm, fps = read_video_info(self.vid_info_df, self.video_name)
+            video_settings, self.px_per_mm, fps = self.read_video_info(video_name=self.video_name)
             for window in self.roll_windows_values:
                 roll_windows.append(int(fps / window))
             self.in_data = read_df(file_path, self.file_type).fillna(0).apply(pd.to_numeric).reset_index(drop=True)
             print('Processing {} ({} frames)...'.format(self.video_name, str(len(self.in_data))))
-            self.in_data = insert_default_headers_for_feature_extraction(df=self.in_data, headers=self.in_headers, pose_config='14 body-parts', filename=file_path)
+            self.in_data = self.insert_default_headers_for_feature_extraction(df=self.in_data, headers=self.in_headers, pose_config='14 body-parts', filename=file_path)
             self.out_data = deepcopy(self.in_data)
             mouse_1_ar = np.reshape(self.out_data[self.mouse_1_headers].values, (len(self.out_data / 2), -1, 2))
             self.out_data['Mouse_1_poly_area'] = jitted_hull(points=mouse_1_ar, target=Formats.PERIMETER.value) / self.px_per_mm
             mouse_2_ar = np.reshape(self.out_data[self.mouse_2_headers].values, (len(self.out_data / 2), -1, 2))
             self.out_data['Mouse_2_poly_area'] = jitted_hull(points=mouse_2_ar, target=Formats.PERIMETER.value) / self.px_per_mm
             self.in_data_shifted = self.out_data.shift(periods=1).add_suffix('_shifted').fillna(0)
             self.in_data = pd.concat([self.in_data, self.in_data_shifted], axis=1, join='inner').fillna(0).reset_index(drop=True)
@@ -120,16 +117,15 @@
             self.out_data['Mouse_2_polygon_size_change'] = (self.in_data['Mouse_2_poly_area_shifted'] - self.out_data['Mouse_2_poly_area'])
 
             print('Calculating hull variables...')
             mouse_1_array, mouse_2_array = self.in_data[self.mouse_1_headers].to_numpy(), self.in_data[self.mouse_2_headers].to_numpy()
             self.hull_dict = defaultdict(list)
             for cnt, (animal_1, animal_2) in enumerate(zip(mouse_1_array, mouse_2_array)):
                 animal_1, animal_2 = np.reshape(animal_1, (-1, 2)), np.reshape(animal_2, (-1, 2))
-                animal_1_dist = scipy.spatial.distance.cdist(animal_1, animal_1, metric='euclidean')
-                animal_2_dist = scipy.spatial.distance.cdist(animal_2, animal_2, metric='euclidean')
+                animal_1_dist, animal_2_dist = self.cdist(animal_1, animal_1), self.cdist(animal_2, animal_2)
                 animal_1_dist, animal_2_dist = animal_1_dist[animal_1_dist != 0], animal_2_dist[animal_2_dist != 0]
                 for animal, animal_name in zip([animal_1_dist, animal_2_dist], ['M1', 'M2']):
                     self.hull_dict['{}_hull_large_euclidean'.format(animal_name)].append(np.amax(animal, initial=0) / self.px_per_mm)
                     self.hull_dict['{}_hull_small_euclidean'.format(animal_name)].append(np.min(animal, initial=self.hull_dict['{}_hull_large_euclidean'.format(animal_name)][-1]) / self.px_per_mm)
                     self.hull_dict['{}_hull_mean_euclidean'.format(animal_name)].append(np.mean(animal) / self.px_per_mm)
                     self.hull_dict['{}_hull_sum_euclidean'.format(animal_name)].append(np.sum(animal) / self.px_per_mm)
             for k, v in self.hull_dict.items():
@@ -437,25 +433,25 @@
             self.out_data['Sum_probabilities_deviation'] = (self.out_data['Sum_probabilities'].mean() - self.out_data['Sum_probabilities'])
             self.out_data['Sum_probabilities_deviation_percentile_rank'] = self.out_data['Sum_probabilities_deviation'].rank(pct=True)
             self.out_data['Sum_probabilities_percentile_rank'] = self.out_data['Sum_probabilities_deviation_percentile_rank'].rank(pct=True)
             results = pd.DataFrame(self.count_values_in_range(data=self.out_data.filter(all_p_columns).values, ranges=np.array([[0.0, 0.1], [0.0, 0.5], [0.0, 0.75]])), columns=['Low_prob_detections_0.1', 'Low_prob_detections_0.5', 'Low_prob_detections_0.75'])
             self.out_data = pd.concat([self.out_data, results], axis=1)
             self.out_data = self.out_data.reset_index(drop=True).fillna(0)
             save_path = os.path.join(self.save_dir, self.video_name + '.' + self.file_type)
-            save_df(self.out_data, self.file_type, save_path)
-            session_time, file_time = session_time + (time.time() - file_start_time), int(time.time() - file_start_time)
-            print('Feature extraction complete for {} ({}/{} (elapsed time: {}s)...'.format(self.video_name,
-                                                                                             str(file_cnt + 1),
-                                                                                             str(len(self.files_found)),
-                                                                                             str(file_time)))
+            write_df(df=self.out_data, file_type=self.file_type, save_path=save_path)
+
+            video_timer.stop_timer()
+
+            print(f'Feature extraction complete for {self.video_name} ({(file_cnt + 1)}/{len(self.files_found)} (elapsed time: {video_timer.elapsed_time_str}s)...')
 
-        stdout_success(msg='All features extracted. Results stored in project_folder/csv/features_extracted directory', elapsed_time=str(int(session_time)))
+        self.timer.stop_timer()
+        stdout_success(msg='All features extracted. Results stored in project_folder/csv/features_extracted directory', elapsed_time=self.timer.elapsed_time_str)
 
 # test = ExtractFeaturesFrom14bps(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini')
-# test.extract_features()
+# test.run()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/feature_extractor_7bp.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/feature_extractor_7bp.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,24 +1,22 @@
-import os, glob
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.read_config_unit_tests import insert_default_headers_for_feature_extraction
-from simba.misc_tools import get_feature_extraction_headers
-from simba.utils.printing import stdout_success
-from simba.drop_bp_cords import get_fn_ext
-from simba.rw_dfs import read_df, save_df
+import os
 import pandas as pd
 import numpy as np
 from copy import deepcopy
 import math
 from scipy.spatial import ConvexHull
 from collections import defaultdict
 import scipy
 from simba.mixins.feature_extraction_mixin import FeatureExtractionMixin
+from simba.mixins.config_reader import ConfigReader
+from simba.utils.printing import stdout_success
+from simba.utils.read_write import read_df, write_df, get_fn_ext
+from simba.feature_extractors.perimeter_jit import jitted_hull
 
-class ExtractFeaturesFrom7bps(FeatureExtractionMixin):
+class ExtractFeaturesFrom7bps(ConfigReader, FeatureExtractionMixin):
     
     """
     Class for creating a hard-coded set of features from single animals with 7 tracked body-parts
     using pose-estimation. Results are stored in the `project_folder/csv/features_extracted`
     directory of the SimBA project.
 
     Parameters
@@ -29,49 +27,49 @@
     Notes
     ----------
     Feature extraction tutorial <https://github.com/sgoldenlab/simba/blob/master/docs/tutorial.md#step-5-extract-features>`__.
 
     Examples
     ----------
     >>> feature_extractor = ExtractFeaturesFrom7bps(config_path='MyProjectConfig')
-    >>> feature_extractor.extract_features()
+    >>> feature_extractor.run()
 
     """
      
     def __init__(self,
                  config_path: str):
 
-        super().__init__(config_path=config_path)
-        self.in_headers = get_feature_extraction_headers(pose='1 animal 7 body-parts')
+        FeatureExtractionMixin.__init__(self, config_path=config_path)
+        ConfigReader.__init__(self, config_path=config_path)
+        self.in_headers = self.get_feature_extraction_headers(pose='1 animal 7 body-parts')
         self.mouse_p_headers = [x for x in self.in_headers if x[-2:] == '_p']
         self.mouse_headers = [x for x in self.in_headers if x[-2:] != '_p']
         print('Extracting features from {} file(s)...'.format(str(len(self.files_found))))
 
-    def extract_features(self):
+    def run(self):
         """
         Method to compute and save features to disk. Results are saved in the `project_folder/csv/features_extracted`
         directory of the SimBA project.
 
         Returns
         -------
         None
         """
         for file_cnt, file_path in enumerate(self.files_found):
             _, self.video_name, _ = get_fn_ext(file_path)
-            video_settings, self.px_per_mm, fps = read_video_info(self.vid_info_df, self.video_name)
+            video_settings, self.px_per_mm, fps = self.read_video_info(video_name=self.video_name)
             roll_windows = []
             for window in self.roll_windows_values:
                 roll_windows.append(int(fps / window))
             self.in_data = read_df(file_path, self.file_type).fillna(0).apply(pd.to_numeric).reset_index(drop=True)
             print('Processing {} ({} frames)...'.format(self.video_name, str(len(self.in_data))))
-            self.in_data = insert_default_headers_for_feature_extraction(df=self.in_data, headers=self.in_headers, pose_config='7 body-parts', filename=file_path)
+            self.in_data = self.insert_default_headers_for_feature_extraction(df=self.in_data, headers=self.in_headers, pose_config='7 body-parts', filename=file_path)
             self.out_data = deepcopy(self.in_data)
-
-            self.out_data['Mouse_poly_area'] = self.out_data.apply(lambda x: ConvexHull(np.array([[x['Ear_left_x'], x["Ear_left_y"]],[x['Ear_right_x'], x["Ear_right_y"]],[x['Nose_x'], x["Nose_y"]],[x['Lat_left_x'], x["Lat_left_y"]],[x['Lat_right_x'], x["Lat_right_y"]], [x['Tail_base_x'], x["Tail_base_y"]],[x['Center_x'], x["Center_y"]]])).area, axis=1)
-            self.out_data['Mouse_poly_area'] = self.out_data['Mouse_poly_area'] / self.px_per_mm
+            mouse_array = np.reshape(self.out_data[self.mouse_headers].values, (len(self.out_data / 2), -1, 2))
+            self.out_data['Mouse_poly_area'] = jitted_hull(points=mouse_array, target='perimeter') / self.px_per_mm
             self.in_data_shifted = self.out_data.shift(periods=1).add_suffix('_shifted').fillna(0)
             self.in_data = pd.concat([self.out_data, self.in_data_shifted], axis=1, join='inner').fillna(0).reset_index(drop=True)
             self.out_data['Mouse_nose_to_tail'] = self.euclidean_distance(self.in_data['Nose_x'].values, self.in_data['Tail_base_x'].values, self.in_data['Nose_y'].values, self.in_data['Tail_base_y'].values, self.px_per_mm)
             self.out_data['Mouse_width'] = self.euclidean_distance(self.in_data['Lat_left_x'].values, self.in_data['Lat_right_x'].values, self.in_data['Lat_left_y'].values, self.in_data['Lat_right_y'].values, self.px_per_mm)
             self.out_data['Mouse_Ear_distance'] = self.euclidean_distance(self.in_data['Ear_left_x'].values, self.in_data['Ear_right_x'].values, self.in_data['Ear_left_y'].values, self.in_data['Ear_right_y'].values, self.px_per_mm)
             self.out_data['Mouse_Nose_to_centroid'] = self.euclidean_distance(self.in_data['Nose_x'].values, self.in_data['Center_x'].values, self.in_data['Nose_y'].values, self.in_data['Center_y'].values, self.px_per_mm)
             self.out_data['Mouse_Nose_to_lateral_left'] = self.euclidean_distance(self.in_data['Nose_x'].values, self.in_data['Lat_left_x'].values, self.in_data['Nose_y'].values, self.in_data['Lat_left_y'].values, self.px_per_mm)
@@ -246,20 +244,19 @@
             self.out_data['Sum_probabilities_deviation_percentile_rank'] = self.out_data['Sum_probabilities_deviation'].rank(pct=True)
             self.out_data['Sum_probabilities_percentile_rank'] = self.out_data['Sum_probabilities_deviation_percentile_rank'].rank(pct=True)
             results = pd.DataFrame(self.count_values_in_range(data=self.out_data.filter(self.mouse_p_headers).values, ranges=np.array([[0.0, 0.1], [0.0, 0.5], [0.0, 0.75]])), columns=['Low_prob_detections_0.1', 'Low_prob_detections_0.5','Low_prob_detections_0.75'])
             self.out_data = pd.concat([self.out_data, results], axis=1)
 
             self.out_data = self.out_data.reset_index(drop=True).fillna(0)
             save_path = os.path.join(self.save_dir, self.video_name + '.' + self.file_type)
-            save_df(self.out_data, self.file_type, save_path)
-
-            print('Feature extraction complete for {} ({}/{})...'.format(self.video_name, str(file_cnt + 1),str(len(self.files_found))))
-        stdout_success(msg='All features extracted. Results are stored in the project_folder/csv/features_extracted directory')
-
+            write_df(df=self.out_data, file_type=self.file_type, save_path=save_path)
+            print(f'Feature extraction complete for {self.video_name} ({file_cnt + 1}/{len(self.files_found)})...')
 
+        self.timer.stop_timer()
+        stdout_success(msg='All features extracted. Results are stored in the project_folder/csv/features_extracted directory', elapsed_time=self.timer.elapsed_time_str)
 
-# test = ExtractFeaturesFrom7bps(config_path='/Users/simon/Desktop/train_model_project/project_folder/project_config.ini')
-# test.extract_features()
+# test = ExtractFeaturesFrom7bps(config_path='/Users/simon/Desktop/envs/troubleshooting/Emergence/project_folder/project_config.ini')
+# test.run()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/doctests.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/doctests.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/fish_feature_extractor_2023_version_3.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/fish_feature_extractor_2023_version_3.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/read_in_mp.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/read_in_mp.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/peaks.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/peaks.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/fish_feature_extractor_2022.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/fish_feature_extractor_2022.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/convex_hull_3_scratch_3.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/convex_hull_3_scratch_3.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/convex_hull_scratch_1.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/convex_hull_scratch_1.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/.DS_Store` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/.DS_Store`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/fish_feature_extractor_2023_version_2.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/fish_feature_extractor_2023_version_2.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/egocentrical_aligner.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/egocentrical_aligner.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/count_values_in_range.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/count_values_in_range.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/graph_creator.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/graph_creator.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/termite_rois.csv` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/termite_rois.csv`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/mutual_exclusive.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/mutual_exclusive.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/video_color.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/video_color.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/graph_3d_plotter.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/graph_3d_plotter.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/video_rotator.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/video_rotator.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/add_probability_cnt_features.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/add_probability_cnt_features.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/make_splash.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/make_splash.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/time_stamp_calculator.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/time_stamp_calculator.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/video_rotator_mp.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/video_rotator_mp.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/fish_feature_extractor_2023_version_4.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/fish_feature_extractor_2023_version_4.py`

 * *Files 2% similar despite different names*

```diff
@@ -7,57 +7,58 @@
 from scipy import stats
 from statsmodels.stats.diagnostic import lilliefors
 from scipy.signal import find_peaks
 from scipy.spatial import ConvexHull
 from scipy.spatial.qhull import QhullError
 from scipy.stats import zscore
 from numba import jit, prange
-from simba.drop_bp_cords import *
-from simba.feature_extractors.unit_tests import read_video_info, check_minimum_roll_windows
-from simba.drop_bp_cords import get_fn_ext, getBpNames, getBpHeaders
-from simba.misc_tools import SimbaTimer, detect_bouts
+import os, glob
+from simba.enums import Paths
+from simba.utils.read_write import get_fn_ext, read_video_info, read_config_file, write_df, read_df
+from simba.utils.printing import SimbaTimer
 from itertools import combinations
 from joblib import Parallel, delayed
+from simba.mixins.config_reader import ConfigReader
+from simba.mixins.feature_extraction_mixin import FeatureExtractionMixin
 
 TAIL_BP_NAMES = ['objectA', 'peduncle_base']
 CENTER_BP_NAMES = ['midpoint']
 MOUTH = ['mouth']
 
 ANGULAR_DISPERSION_S = [10, 5, 2, 1, 0.5, 0.25]
 
-class FishFeatureExtractor():
-    def __init__(self, config_path: str):
+class FishFeatureExtractor(ConfigReader, FeatureExtractionMixin):
+    def __init__(self,
+                 config_path: str):
+        ConfigReader.__init__(self, config_path=config_path)
+        FeatureExtractionMixin.__init__(self, config_path=config_path)
         self.timer = SimbaTimer()
         self.timer.start_timer()
         self.compass_brackets = ["N", "NE", "E", "SE", "S", "SW", "W", "NW", "N"]
         self.compass_brackets_long = ["Direction_N", "Direction_NE", "Direction_E", "Direction_SE", "Direction_S", "Direction_SW", "Direction_W", "Direction_NW"]
         self.compass_brackets_digits = ["0", "1", "2", "3", "4", "5", "6", "7", "0"]
-        self.config = read_config_file(ini_path=config_path)
+        self.config = read_config_file(config_path=config_path)
         self.project_path, self.file_type = read_project_path_and_file_type(config=self.config)
         self.input_file_dir = os.path.join(self.project_path, Paths.OUTLIER_CORRECTED.value)
         self.save_dir = os.path.join(self.project_path, Paths.FEATURES_EXTRACTED_DIR.value)
         self.video_info_path = os.path.join(self.project_path, Paths.VIDEO_INFO.value)
         self.video_info_df = pd.read_csv(self.video_info_path)
         bp_names_path = os.path.join( self.project_path, Paths.BP_NAMES.value)
         self.bp_names = list(pd.read_csv(bp_names_path, header=None)[0])
-        self.bp_header_list = getBpHeaders(str(config_path))
         self.col_headers_shifted = []
         for bp in self.bp_names:
             self.col_headers_shifted.extend((bp + '_x_shifted', bp + '_y_shifted', bp + '_p_shifted'))
-        self.x_cols, self.y_cols, self.p_cols = getBpNames(str(config_path))
         self.x_y_cols = []
         self.x_cols_shifted, self.y_cols_shifted = [], []
         for (x_name, y_name) in zip(self.x_cols, self.y_cols):
             self.x_y_cols.extend((x_name, y_name))
             self.x_cols_shifted.append(x_name + '_shifted')
             self.y_cols_shifted.append(y_name + '_shifted')
 
-        self.roll_windows_values = check_minimum_roll_windows([25, 20, 15, 10, 4, 2], self.video_info_df['fps'].min())
-        self.roll_windows_values = [x for x in self.roll_windows_values if x >= 2]
-        self.roll_windows_values = self.roll_windows_values + [50, 75]
+        self.roll_windows_values = [75, 50, 25, 20, 15, 10, 4, 2, ]
         self.files_found = glob.glob(self.input_file_dir + '/*.{}'.format(self.file_type))
         check_if_filepath_list_is_empty(filepaths=self.files_found, error_msg='SIMBA ERROR: No file in {} directory'.format(self.input_file_dir))
         print('Extracting features from {} {}...'.format(str(len(self.files_found)), 'file(s)'))
 
         for file_path in self.files_found:
             video_timer = SimbaTimer()
             video_timer.start_timer()
@@ -67,15 +68,15 @@
             self.video_width, self.video_height = video_info['Resolution_width'].values, video_info['Resolution_height'].values
             self.angular_dispersion_windows = []
             for i in range(len(ANGULAR_DISPERSION_S)):
                 self.angular_dispersion_windows.append(int(self.fps * ANGULAR_DISPERSION_S[i]))
 
             self.csv_df = read_df(file_path, self.file_type).fillna(0).apply(pd.to_numeric)
             try:
-                self.csv_df.columns = self.bp_header_list
+                self.csv_df.columns = self.bp_col_names
             except ValueError:
                 msg = f'ERROR: Data contains the following fields: {self.csv_df.columns}. \n SimBA wants to use the following field names {self.bp_header_list}'
                 print(msg)
                 raise ValueError(msg)
 
             csv_df_shifted = self.csv_df.shift(periods=1)
             csv_df_shifted.columns = self.col_headers_shifted
@@ -388,18 +389,19 @@
         for side in ['left', 'right', 'top', 'bottom']:
             side_col_names = [c for c in self.csv_df_combined.columns if f'distance_to_{side}_border' in c]
             self.csv_df_combined[f'Mean_bp_distance_to_{side}_border'] = self.csv_df_combined[side_col_names].mean(axis=1)
             for window in self.roll_windows_values:
                 self.csv_df_combined[f'Mean_bp_distance_to_{side}_border_{window}'] = self.csv_df_combined[f'Mean_bp_distance_to_{side}_border'].rolling(window, min_periods=1).mean()
                 self.csv_df_combined[f'Std_bp_distance_to_{side}_border_{window}'] = self.csv_df_combined[f'Mean_bp_distance_to_{side}_border'].rolling(window, min_periods=1).std()
                 try:
-                    self.csv_df_combined[f'Kurtosis_bp_distance_to_{side}_border_{window}'] = self.csv_df_combined[f'Mean_bp_distance_to_{side}_border'].rolling(window, min_periods=window).kurt()
+                    #self.csv_df_combined[f'Kurtosis_bp_distance_to_{side}_border_{window}'] = self.csv_df_combined[f'Mean_bp_distance_to_{side}_border'].rolling(window, min_periods=window).kurt()
                     self.csv_df_combined[f'Skew_bp_distance_to_{side}_border_{window}'] = self.csv_df_combined[f'Mean_bp_distance_to_{side}_border'].rolling(window, min_periods=window).skew()
                 except:
-                    pass
+                    #self.csv_df_combined[f'Kurtosis_bp_distance_to_{side}_border_{window}'] = -1
+                    self.csv_df_combined[f'Skew_bp_distance_to_{side}_border_{window}'] = -1
 
     def calc_distances_between_body_part(self):
         two_point_combs = np.array(list(combinations(self.bp_names, 2)))
         distance_fields = []
         for bps in two_point_combs:
             self.csv_df_combined[f'Distance_{bps[0]}_{bps[1]}'] = self.euclidian_distance_calc(self.csv_df_combined[bps[0]+'_x'].values, self.csv_df_combined[bps[0]+'_y'].values, self.csv_df_combined[bps[1]+'_x'].values, self.csv_df_combined[bps[1]+'_y'].values) / self.px_per_mm
             distance_fields.append(f'Distance_{bps[0]}_{bps[1]}')
@@ -408,30 +410,32 @@
             for window in self.roll_windows_values:
                 self.csv_df_combined[f'{distance_field}_mean_{window}'] = self.csv_df_combined[distance_field].rolling(window, min_periods=1).mean()
                 self.csv_df_combined[f'{distance_field}_std_{window}'] = self.csv_df_combined[distance_field].rolling(window, min_periods=1).std()
                 try:
                     self.csv_df_combined[f'{distance_field}_skew_{window}'] = self.csv_df_combined[distance_field].rolling(window, min_periods=1).skew()
                     self.csv_df_combined[f'{distance_field}_kurtosis_{window}'] = self.csv_df_combined[distance_field].rolling(window, min_periods=1).kurt()
                 except:
-                    pass
+                    self.csv_df_combined[f'{distance_field}_skew_{window}'] = -1
+                    self.csv_df_combined[f'{distance_field}_kurtosis_{window}'] = -1
 
     def calc_convex_hulls(self):
         fish_array = np.reshape(self.csv_df[self.x_y_cols].values, (len(self.csv_df / 2), -1, 2))
         self.csv_df_combined['Convex_hull'] = Parallel(n_jobs=-1, verbose=0, backend="threading")(delayed(self.convex_hull_calculator_mp)(x, self.px_per_mm) for x in fish_array)
         for window in self.roll_windows_values:
             self.csv_df_combined[f'Convex_hull_mean_{window}_window'] = self.csv_df_combined['Convex_hull'].rolling(window, min_periods=1).mean()
             self.csv_df_combined[f'Convex_hull_std_{window}_window'] = self.csv_df_combined['Convex_hull'].rolling(window, min_periods=1).std()
             self.csv_df_combined[f'Convex_hull_min_{window}_window'] = self.csv_df_combined['Convex_hull'].rolling(window, min_periods=1).min()
             self.csv_df_combined[f'Convex_hull_max_{window}_window'] = self.csv_df_combined['Convex_hull'].rolling(window, min_periods=1).max()
             self.csv_df_combined[f'Absolute_diff_min_max_convex_hull_{window}_window'] = abs(self.csv_df_combined[f'Convex_hull_min_{window}_window'] - self.csv_df_combined[f'Convex_hull_max_{window}_window'])
             try:
                 self.csv_df_combined[f'Convex_hull_skew_{window}'] = self.csv_df_combined['Convex_hull'].rolling(window, min_periods=1).skew()
                 self.csv_df_combined[f'Convex_hull_kurtosis_{window}'] = self.csv_df_combined['Convex_hull'].rolling(window, min_periods=1).kurt()
             except:
-                pass
+                self.csv_df_combined[f'Convex_hull_skew_{window}'] = -1
+                self.csv_df_combined[f'Convex_hull_kurtosis_{window}'] = -1
 
 
     def distribution_tests(self):
         distribution_features = ['Mean_bp_distance_to_left_border',
                                  'Mean_bp_distance_to_right_border',
                                  'Mean_bp_distance_to_top_border',
                                  'Mean_bp_distance_to_bottom_border',
@@ -451,10 +455,10 @@
         self.csv_df_combined['Sum_probabilities_deviation'] = (self.csv_df_combined['Sum_probabilities'].mean() - self.csv_df_combined['Sum_probabilities'])
         p_brackets_results = pd.DataFrame(self.count_values_in_range(data=self.csv_df_combined.filter(self.p_cols).values, ranges=np.array([[0.0, 0.1], [0.000000000, 0.5], [0.000000000, 0.75], [0.000000000, 0.95], [0.000000000, 0.99]])), columns=['Low_prob_detections_0.1', 'Low_prob_detections_0.5', 'Low_prob_detections_0.75', 'Low_prob_detections_0.95', 'Low_prob_detections_0.99'])
         self.csv_df_combined = pd.concat([self.csv_df_combined, p_brackets_results], axis=1).reset_index(drop=True).fillna(0)
 
     def save_file(self):
         self.csv_df_combined = self.csv_df_combined.drop(self.col_headers_shifted, axis=1)
         self.csv_df_combined = self.csv_df_combined.drop(['Compass_digit_shifted', 'Direction_switch', 'Switch_direction_value', 'Compass_digit', 'Compass_direction', 'Angle_sin_cumsum', 'Angle_cos_cumsum'], axis=1).fillna(0)
-        save_df(self.csv_df_combined.astype(np.float32), self.file_type, self.save_path)
+        write_df(self.csv_df_combined.astype(np.float32), self.file_type, self.save_path)
 
-test = FishFeatureExtractor(config_path='/Users/simon/Desktop/envs/troubleshooting/naresh/project_folder/project_config.ini')
+#test = FishFeatureExtractor(config_path='/Users/simon/Desktop/envs/troubleshooting/naresh/project_folder/project_config.ini')
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/misc/convex_hull_scratch_2.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/misc/convex_hull_scratch_2.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/feature_extractor_8bps_2_animals.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/feature_extractor_8bps_2_animals.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,27 +1,21 @@
-from simba.read_config_unit_tests import (insert_default_headers_for_feature_extraction)
-from simba.misc_tools import get_feature_extraction_headers
-from simba.utils.printing import stdout_success
-import os
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.drop_bp_cords import get_fn_ext
-from simba.rw_dfs import read_df, save_df
 import pandas as pd
 import numpy as np
 from copy import deepcopy
-from scipy.spatial import ConvexHull
 from collections import defaultdict
-import scipy
-import time
+import os
 from simba.mixins.feature_extraction_mixin import FeatureExtractionMixin
+from simba.mixins.config_reader import ConfigReader
 from simba.feature_extractors.perimeter_jit import jitted_hull
+from simba.utils.read_write import get_fn_ext, read_df, write_df
+from simba.utils.printing import stdout_success, SimbaTimer
 from simba.enums import Formats
 
 
-class ExtractFeaturesFrom8bps2Animals(FeatureExtractionMixin):
+class ExtractFeaturesFrom8bps2Animals(ConfigReader, FeatureExtractionMixin):
     """
     Class for creating a hard-coded set of features from two animals with 4 pose-estimated body-parts.
     Results are stored in the `project_folder/csv/features_extracted`
     directory of the SimBA project
     Parameters
     ----------
     config_path: str
@@ -30,48 +24,50 @@
     Notes
     ----------
     Feature extraction tutorial <https://github.com/sgoldenlab/simba/blob/master/docs/tutorial.md#step-5-extract-features>`__.
 
     Examples
     ----------
     >>> feature_extractor = ExtractFeaturesFrom8bps2Animals(config_path='MyProjectConfig')
-    >>> feature_extractor.extract_features()
+    >>> feature_extractor.run()
     """
 
     def __init__(self,
                  config_path: str):
 
-        super().__init__(config_path=config_path)
-        self.in_headers = get_feature_extraction_headers(pose='2 animals 8 body-parts')
+        FeatureExtractionMixin.__init__(self, config_path=config_path)
+        ConfigReader.__init__(self, config_path=config_path)
+        self.in_headers = self.get_feature_extraction_headers(pose='2 animals 8 body-parts')
         self.mouse_1_headers, self.mouse_2_headers = self.in_headers[0:12], self.in_headers[12:]
         self.mouse_2_p_headers = [x for x in self.mouse_2_headers if x[-2:] == '_p']
         self.mouse_1_p_headers = [x for x in self.mouse_1_headers if x[-2:] == '_p']
         self.mouse_1_headers = [x for x in self.mouse_1_headers if x[-2:] != '_p']
         self.mouse_2_headers = [x for x in self.mouse_2_headers if x[-2:] != '_p']
         print('Extracting features from {} file(s)...'.format(str(len(self.files_found))))
 
-    def extract_features(self):
+    def run(self):
         """
         Method to compute and save feature battery to disk. Results are saved in the `project_folder/csv/features_extracted`
         directory of the SimBA project.
 
         Returns
         -------
         None
         """
-        session_time = 0
+
         for file_cnt, file_path in enumerate(self.files_found):
-            roll_windows, file_start_time = [], time.time()
+            video_timer = SimbaTimer(start=True)
+            roll_windows = []
             _, self.video_name, _ = get_fn_ext(file_path)
-            video_settings, self.px_per_mm, fps = read_video_info(self.vid_info_df, self.video_name)
+            video_settings, self.px_per_mm, fps = self.read_video_info(video_name=self.video_name)
             for window in self.roll_windows_values:
                 roll_windows.append(int(fps / window))
             self.in_data = read_df(file_path, self.file_type).fillna(0).apply(pd.to_numeric).reset_index(drop=True)
             print('Processing {} ({} frames)...'.format(self.video_name, str(len(self.in_data))))
-            self.in_data = insert_default_headers_for_feature_extraction(df=self.in_data, headers=self.in_headers, pose_config='8 body-parts from 2 animals', filename=file_path)
+            self.in_data = self.insert_default_headers_for_feature_extraction(df=self.in_data, headers=self.in_headers, pose_config='8 body-parts from 2 animals', filename=file_path)
             self.out_data = deepcopy(self.in_data)
             mouse_1_ar = np.reshape(self.out_data[self.mouse_1_headers].values, (len(self.out_data / 2), -1, 2))
             self.out_data['Mouse_1_poly_area'] = jitted_hull(points=mouse_1_ar, target=Formats.PERIMETER.value) / self.px_per_mm
             mouse_2_ar = np.reshape(self.out_data[self.mouse_2_headers].values, (len(self.out_data / 2), -1, 2))
             self.out_data['Mouse_2_poly_area'] = jitted_hull(points=mouse_2_ar, target=Formats.PERIMETER.value) / self.px_per_mm
             self.in_data_shifted = self.out_data.shift(periods=1).add_suffix('_shifted').fillna(0)
             self.in_data = pd.concat([self.in_data, self.in_data_shifted], axis=1, join='inner').fillna(0).reset_index(drop=True)
@@ -88,26 +84,26 @@
             self.out_data['Movement_mouse_2_left_ear'] = self.euclidean_distance(self.in_data['Ear_left_2_x_shifted'].values, self.in_data['Ear_left_2_x'].values, self.in_data['Ear_left_2_y_shifted'].values, self.in_data['Ear_left_2_y'].values, self.px_per_mm)
             self.out_data['Movement_mouse_1_right_ear'] = self.euclidean_distance(self.in_data['Ear_right_1_x_shifted'].values, self.in_data['Ear_right_1_x'].values, self.in_data['Ear_right_1_y_shifted'].values, self.in_data['Ear_right_1_y'].values, self.px_per_mm)
             self.out_data['Movement_mouse_2_right_ear'] = self.euclidean_distance(self.in_data['Ear_right_2_x_shifted'].values, self.in_data['Ear_right_2_x'].values, self.in_data['Ear_right_2_y_shifted'].values, self.in_data['Ear_right_2_y'].values, self.px_per_mm)
             self.out_data['Mouse_1_polygon_size_change'] = (self.in_data['Mouse_1_poly_area_shifted'] - self.out_data['Mouse_1_poly_area'])
             self.out_data['Mouse_2_polygon_size_change'] = (self.in_data['Mouse_2_poly_area_shifted'] - self.out_data['Mouse_2_poly_area'])
 
             print('Calculating hull variables...')
-            mouse_1_array, mouse_2_array = self.in_data[self.mouse_1_headers].to_numpy(), self.in_data[self.mouse_2_headers].to_numpy()
             self.hull_dict = defaultdict(list)
+            mouse_1_array, mouse_2_array = self.in_data[self.mouse_1_headers].to_numpy(), self.in_data[self.mouse_2_headers].to_numpy()
             for cnt, (animal_1, animal_2) in enumerate(zip(mouse_1_array, mouse_2_array)):
                 animal_1, animal_2 = np.reshape(animal_1, (-1, 2)), np.reshape(animal_2, (-1, 2))
-                animal_1_dist = scipy.spatial.distance.cdist(animal_1, animal_1, metric='euclidean')
-                animal_2_dist = scipy.spatial.distance.cdist(animal_2, animal_2, metric='euclidean')
+                animal_1_dist, animal_2_dist = self.cdist(animal_1, animal_1), self.cdist(animal_2, animal_2)
                 animal_1_dist, animal_2_dist = animal_1_dist[animal_1_dist != 0], animal_2_dist[animal_2_dist != 0]
                 for animal, animal_name in zip([animal_1_dist, animal_2_dist], ['M1', 'M2']):
                     self.hull_dict['{}_hull_large_euclidean'.format(animal_name)].append(np.amax(animal, initial=0) / self.px_per_mm)
                     self.hull_dict['{}_hull_small_euclidean'.format(animal_name)].append(np.min(animal, initial=self.hull_dict['{}_hull_large_euclidean'.format(animal_name)][-1]) / self.px_per_mm)
                     self.hull_dict['{}_hull_mean_euclidean'.format(animal_name)].append(np.mean(animal) / self.px_per_mm)
                     self.hull_dict['{}_hull_sum_euclidean'.format(animal_name)].append(np.sum(animal, initial=0) / self.px_per_mm)
+
             for k, v in self.hull_dict.items():
                 self.out_data[k] = v
 
             self.out_data['Sum_euclidean_distance_hull_M1_M2'] = (self.out_data['M1_hull_sum_euclidean'] + self.out_data['M2_hull_sum_euclidean'])
 
             self.out_data['Total_movement_nose'] = self.out_data.eval("Movement_mouse_1_nose + Movement_mouse_2_nose")
             self.out_data['Total_movement_tail_base'] = self.out_data.eval('Movement_mouse_1_tail_base + Movement_mouse_2_tail_base')
@@ -321,15 +317,15 @@
             self.out_data['Sum_probabilities_deviation'] = (self.out_data['Sum_probabilities'].mean() - self.out_data['Sum_probabilities'])
             self.out_data['Sum_probabilities_deviation_percentile_rank'] = self.out_data['Sum_probabilities_deviation'].rank(pct=True)
             self.out_data['Sum_probabilities_percentile_rank'] = self.out_data['Sum_probabilities_deviation_percentile_rank'].rank(pct=True)
             results = pd.DataFrame(self.count_values_in_range(data=self.out_data.filter(all_p_columns).values, ranges=np.array([[0.0, 0.1], [0.0, 0.5], [0.0, 0.75]])), columns=['Low_prob_detections_0.1', 'Low_prob_detections_0.5', 'Low_prob_detections_0.75'])
             self.out_data = pd.concat([self.out_data, results], axis=1)
             self.out_data = self.out_data.reset_index(drop=True).fillna(0)
             save_path = os.path.join(self.save_dir, self.video_name + '.' + self.file_type)
-            save_df(self.out_data, self.file_type, save_path)
-            session_time, file_time = session_time + (time.time()-file_start_time), int(time.time() - file_start_time)
-            print('Feature extraction complete for {} ({}/{} (elapsed time: {}s))...'.format(self.video_name, str(file_cnt + 1), str(len(self.files_found)), str(file_time)))
-
-        stdout_success(msg='All features extracted. Results stored in project_folder/csv/features_extracted directory.', elapsed_time=str(int(session_time)))
+            write_df(df=self.out_data, file_type=self.file_type, save_path=save_path)
+            video_timer.stop_timer()
+            print(f'Feature extraction complete for {self.video_name} ({file_cnt + 1}/{len(self.files_found)} (elapsed time: {video_timer.elapsed_time_str}s))...')
+        self.timer.stop_timer()
+        stdout_success(msg='All features extracted. Results stored in project_folder/csv/features_extracted directory.', elapsed_time=self.timer.elapsed_time_str)
 
 # test = ExtractFeaturesFrom8bps2Animals(config_path='/Users/simon/Desktop/envs/troubleshooting/8Bp_2_animals/project_folder/project_config.ini')
-# test.extract_features()
+# test.run()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/.DS_Store` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/.DS_Store`

 * *Files 5% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 00000000: 0000 0001 4275 6431 0000 2000 0000 0800  ....Bud1.. .....
 00000010: 0000 2000 0000 100c 0000 0000 0000 0000  .. .............
 00000020: 0000 0000 0000 0000 0000 0000 0000 0800  ................
 00000030: 0000 0800 0000 0000 0000 0000 0000 0000  ................
-00000040: 0000 0000 0000 0002 0000 0000 0000 0012  ................
+00000040: 0000 0000 0000 0002 0000 0000 0000 0013  ................
 00000050: 0000 0001 0000 1000 0061 6c67 3153 636f  .........alg1Sco
 00000060: 6d70 0000 0000 0000 0000 0000 0000 0000  mp..............
 00000070: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00000080: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00000090: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 000000a0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 000000b0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
@@ -250,15 +250,15 @@
 00000f90: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00000fa0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00000fb0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00000fc0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00000fd0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00000fe0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00000ff0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
-00001000: 0000 0000 0000 0000 0000 0012 0000 0005  ................
+00001000: 0000 0000 0000 0000 0000 0013 0000 0005  ................
 00001010: 002e 0069 0064 0065 0061 6c67 3153 636f  ...i.d.e.alg1Sco
 00001020: 6d70 0000 0000 0000 29ab 0000 0005 002e  mp......).......
 00001030: 0069 0064 0065 0061 6d6f 4444 626c 6f62  .i.d.e.amoDDblob
 00001040: 0000 0008 de3b 4374 e2dd c441 0000 0005  .....;Ct...A....
 00001050: 002e 0069 0064 0065 0061 6d6f 6444 626c  ...i.d.e.amodDbl
 00001060: 6f62 0000 0008 de3b 4374 e2dd c441 0000  ob.....;Ct...A..
 00001070: 0005 002e 0069 0064 0065 0061 7068 3153  .....i.d.e.aph1S
@@ -276,23 +276,23 @@
 00001130: 5f10 197b 7b34 3732 2c20 3134 327d 2c20  _..{{472, 142}, 
 00001140: 7b31 3037 362c 2036 3231 7d7d 0908 1725  {1076, 621}}...%
 00001150: 313d 4960 6d79 7a7b 7c7d 7e9a 0000 0000  1=I`myz{|}~.....
 00001160: 0000 0101 0000 0000 0000 000f 0000 0000  ................
 00001170: 0000 0000 0000 0000 0000 009b 0000 000b  ................
 00001180: 005f 005f 0070 0079 0063 0061 0063 0068  ._._.p.y.c.a.c.h
 00001190: 0065 005f 005f 6c67 3153 636f 6d70 0000  .e._._lg1Scomp..
-000011a0: 0000 000b e224 0000 000b 005f 005f 0070  .....$....._._.p
+000011a0: 0000 000b dbb7 0000 000b 005f 005f 0070  ..........._._.p
 000011b0: 0079 0063 0061 0063 0068 0065 005f 005f  .y.c.a.c.h.e._._
-000011c0: 6d6f 4444 626c 6f62 0000 0008 00ee c752  moDDblob.......R
-000011d0: eaf6 c441 0000 000b 005f 005f 0070 0079  ...A....._._.p.y
+000011c0: 6d6f 4444 626c 6f62 0000 0008 47b4 5787  moDDblob....G.W.
+000011d0: 2cfc c441 0000 000b 005f 005f 0070 0079  ,..A....._._.p.y
 000011e0: 0063 0061 0063 0068 0065 005f 005f 6d6f  .c.a.c.h.e._._mo
-000011f0: 6444 626c 6f62 0000 0008 0a8c 6973 23f2  dDblob......is#.
+000011f0: 6444 626c 6f62 0000 0008 9edb 857b 6efb  dDblob.......{n.
 00001200: c441 0000 000b 005f 005f 0070 0079 0063  .A....._._.p.y.c
 00001210: 0061 0063 0068 0065 005f 005f 7068 3153  .a.c.h.e._._ph1S
-00001220: 636f 6d70 0000 0000 000c 9000 0000 000b  comp............
+00001220: 636f 6d70 0000 0000 000c 8000 0000 000b  comp............
 00001230: 005f 005f 0070 0079 0063 0061 0063 0068  ._._.p.y.c.a.c.h
 00001240: 0065 005f 005f 7653 726e 6c6f 6e67 0000  .e._._vSrnlong..
 00001250: 0001 0000 0004 006d 0069 0073 0063 6277  .......m.i.s.cbw
 00001260: 7370 626c 6f62 0000 00c8 6270 6c69 7374  spblob....bplist
 00001270: 3030 d701 0203 0405 0607 0808 0a08 0a0d  00..............
 00001280: 0a5d 5368 6f77 5374 6174 7573 4261 725b  .]ShowStatusBar[
 00001290: 5368 6f77 5061 7468 6261 725b 5368 6f77  ShowPathbar[Show
@@ -301,113 +301,113 @@
 000012c0: 686f 7753 6964 6562 6172 5c57 696e 646f  howSidebar\Windo
 000012d0: 7742 6f75 6e64 735b 5368 6f77 5369 6465  wBounds[ShowSide
 000012e0: 6261 7208 0809 0809 5f10 177b 7b33 342c  bar....._..{{34,
 000012f0: 2039 307d 2c20 7b31 3031 352c 2037 3637   90}, {1015, 767
 00001300: 7d7d 0908 1725 313d 4960 6d79 7a7b 7c7d  }}...%1=I`myz{|}
 00001310: 7e98 0000 0000 0000 0101 0000 0000 0000  ~...............
 00001320: 000f 0000 0000 0000 0000 0000 0000 0000  ................
-00001330: 0099 0000 0004 006d 0069 0073 0063 6c67  .......m.i.s.clg
-00001340: 3153 636f 6d70 0000 0000 0003 0365 0000  1Scomp.......e..
-00001350: 0004 006d 0069 0073 0063 6c73 7643 626c  ...m.i.s.clsvCbl
-00001360: 6f62 0000 02b8 6270 6c69 7374 3030 da01  ob....bplist00..
-00001370: 0203 0405 0607 0809 0a0b 0c0d 1848 4948  .............HIH
-00001380: 4a0c 4c58 6963 6f6e 5369 7a65 5f10 0f73  J.LXiconSize_..s
-00001390: 686f 7749 636f 6e50 7265 7669 6577 5763  howIconPreviewWc
-000013a0: 6f6c 756d 6e73 5f10 1163 616c 6375 6c61  olumns_..calcula
-000013b0: 7465 416c 6c53 697a 6573 5f10 0f73 6372  teAllSizes_..scr
-000013c0: 6f6c 6c50 6f73 6974 696f 6e59 5874 6578  ollPositionYXtex
-000013d0: 7453 697a 655f 100f 7363 726f 6c6c 506f  tSize_..scrollPo
-000013e0: 7369 7469 6f6e 585a 736f 7274 436f 6c75  sitionXZsortColu
-000013f0: 6d6e 5f10 1075 7365 5265 6c61 7469 7665  mn_..useRelative
-00001400: 4461 7465 735f 1012 7669 6577 4f70 7469  Dates_..viewOpti
-00001410: 6f6e 7356 6572 7369 6f6e 2340 3000 0000  onsVersion#@0...
-00001420: 0000 0009 ab0e 171c 2125 2a2f 3439 3e43  ........!%*/49>C
-00001430: d40f 1011 1213 140c 0c5a 6964 656e 7469  .........Zidenti
-00001440: 6669 6572 5577 6964 7468 5961 7363 656e  fierUwidthYascen
-00001450: 6469 6e67 5776 6973 6962 6c65 546e 616d  dingWvisibleTnam
-00001460: 6511 01a6 0909 d412 1011 0f18 1918 1b08  e...............
-00001470: 1023 0858 7562 6971 7569 7479 d412 1011  .#.Xubiquity....
-00001480: 0f0c 1e18 2009 10b5 085c 6461 7465 4d6f  .... ....\dateMo
-00001490: 6469 6669 6564 d412 1011 0f18 1e18 2408  dified........$.
-000014a0: 085b 6461 7465 4372 6561 7465 64d4 1210  .[dateCreated...
-000014b0: 110f 0c27 1829 0910 6108 5473 697a 65d4  ...'.)..a.Tsize.
-000014c0: 1210 110f 0c2c 0c2e 0910 7309 546b 696e  .....,....s.Tkin
-000014d0: 64d4 1210 110f 1831 0c33 0810 6409 556c  d......1.3..d.Ul
-000014e0: 6162 656c d412 1011 0f18 360c 3808 104b  abel......6.8..K
-000014f0: 0957 7665 7273 696f 6ed4 1210 110f 183b  .Wversion......;
-00001500: 0c3d 0811 012c 0958 636f 6d6d 656e 7473  .=...,.Xcomments
-00001510: d412 1011 0f18 4018 4208 10c8 085e 6461  ......@.B....^da
-00001520: 7465 4c61 7374 4f70 656e 6564 d412 1011  teLastOpened....
-00001530: 0f18 1e18 4608 0859 6461 7465 4164 6465  ....F..YdateAdde
-00001540: 6408 2300 0000 0000 0000 0023 4028 0000  d.#........#@(..
-00001550: 0000 0000 5c64 6174 654d 6f64 6966 6965  ....\dateModifie
-00001560: 6409 1001 0008 001d 0026 0038 0040 0054  d........&.8.@.T
-00001570: 0066 006f 0081 008c 009f 00b4 00bd 00be  .f.o............
-00001580: 00ca 00d3 00de 00e4 00ee 00f6 00fb 00fe  ................
-00001590: 00ff 0100 0109 010a 010c 010d 0116 011f  ................
-000015a0: 0120 0122 0123 0130 0139 013a 013b 0147  . .".#.0.9.:.;.G
-000015b0: 0150 0151 0153 0154 0159 0162 0163 0165  .P.Q.S.T.Y.b.c.e
-000015c0: 0166 016b 0174 0175 0177 0178 017e 0187  .f.k.t.u.w.x.~..
-000015d0: 0188 018a 018b 0193 019c 019d 01a0 01a1  ................
-000015e0: 01aa 01b3 01b4 01b6 01b7 01c6 01cf 01d0  ................
-000015f0: 01d1 01db 01dc 01e5 01ee 01fb 01fc 0000  ................
-00001600: 0000 0000 0201 0000 0000 0000 004d 0000  .............M..
-00001610: 0000 0000 0000 0000 0000 0000 01fe 0000  ................
-00001620: 0004 006d 0069 0073 0063 6c73 7670 626c  ...m.i.s.clsvpbl
-00001630: 6f62 0000 029d 6270 6c69 7374 3030 da01  ob....bplist00..
-00001640: 0203 0405 0607 0809 0a0b 0c0d 1f48 4948  .............HIH
-00001650: 4a0c 2658 6963 6f6e 5369 7a65 5f10 0f73  J.&XiconSize_..s
-00001660: 686f 7749 636f 6e50 7265 7669 6577 5763  howIconPreviewWc
-00001670: 6f6c 756d 6e73 5f10 1163 616c 6375 6c61  olumns_..calcula
-00001680: 7465 416c 6c53 697a 6573 5f10 0f73 6372  teAllSizes_..scr
-00001690: 6f6c 6c50 6f73 6974 696f 6e59 5874 6578  ollPositionYXtex
-000016a0: 7453 697a 655f 100f 7363 726f 6c6c 506f  tSize_..scrollPo
-000016b0: 7369 7469 6f6e 585a 736f 7274 436f 6c75  sitionXZsortColu
-000016c0: 6d6e 5f10 1075 7365 5265 6c61 7469 7665  mn_..useRelative
-000016d0: 4461 7465 735f 1012 7669 6577 4f70 7469  Dates_..viewOpti
-000016e0: 6f6e 7356 6572 7369 6f6e 2340 3000 0000  onsVersion#@0...
-000016f0: 0000 0009 d90e 0f10 1112 1314 1516 1720  ............... 
-00001700: 252a 2e33 383d 4258 636f 6d6d 656e 7473  %*.38=BXcomments
-00001710: 5e64 6174 654c 6173 744f 7065 6e65 645c  ^dateLastOpened\
-00001720: 6461 7465 4d6f 6469 6669 6564 5b64 6174  dateModified[dat
-00001730: 6543 7265 6174 6564 5473 697a 6555 6c61  eCreatedTsizeUla
-00001740: 6265 6c54 6b69 6e64 5776 6572 7369 6f6e  belTkindWversion
-00001750: 546e 616d 65d4 1819 1a1b 1c1d 0c1f 5569  Tname.........Ui
-00001760: 6e64 6578 5577 6964 7468 5961 7363 656e  ndexUwidthYascen
-00001770: 6469 6e67 5776 6973 6962 6c65 1007 1101  dingWvisible....
-00001780: 2c09 08d4 1819 1a1b 2122 1f1f 1008 10c8  ,.......!"......
-00001790: 0808 d418 191a 1b26 271f 0c10 0110 b508  .......&'.......
-000017a0: 09d4 1819 1a1b 2b27 1f1f 1002 0808 d418  ......+'........
-000017b0: 191a 1b2f 301f 0c10 0310 6108 09d4 1819  .../0.....a.....
-000017c0: 1a1b 3435 0c1f 1005 1064 0908 d418 191a  ..45.....d......
-000017d0: 1b39 3a0c 0c10 0410 7309 09d4 1819 1a1b  .9:.....s.......
-000017e0: 3e3f 0c1f 1006 104b 0908 d41b 191a 180c  >?.....K........
-000017f0: 440c 4609 1101 a609 1000 0823 0000 0000  D.F........#....
-00001800: 0000 0000 2340 2800 0000 0000 005c 6461  ....#@(......\da
-00001810: 7465 4d6f 6469 6669 6564 0900 0800 1d00  teModified......
-00001820: 2600 3800 4000 5400 6600 6f00 8100 8c00  &.8.@.T.f.o.....
-00001830: 9f00 b400 bd00 be00 d100 da00 e900 f601  ................
-00001840: 0201 0701 0d01 1201 1a01 1f01 2801 2e01  ............(...
-00001850: 3401 3e01 4601 4801 4b01 4c01 4d01 5601  4.>.F.H.K.L.M.V.
-00001860: 5801 5a01 5b01 5c01 6501 6701 6901 6a01  X.Z.[.\.e.g.i.j.
-00001870: 6b01 7401 7601 7701 7801 8101 8301 8501  k.t.v.w.x.......
-00001880: 8601 8701 9001 9201 9401 9501 9601 9f01  ................
-00001890: a101 a301 a401 a501 ae01 b001 b201 b301  ................
-000018a0: b401 bd01 be01 c101 c201 c401 c501 ce01  ................
-000018b0: d701 e400 0000 0000 0002 0100 0000 0000  ................
-000018c0: 0000 4c00 0000 0000 0000 0000 0000 0000  ..L.............
-000018d0: 0001 e500 0000 0400 6d00 6900 7300 636d  ........m.i.s.cm
-000018e0: 6f44 4462 6c6f 6200 0000 08e7 9910 0635  oDDblob........5
-000018f0: fac4 4100 0000 0400 6d00 6900 7300 636d  ..A.....m.i.s.cm
-00001900: 6f64 4462 6c6f 6200 0000 08e7 9910 0635  odDblob........5
-00001910: fac4 4100 0000 0400 6d00 6900 7300 6370  ..A.....m.i.s.cp
-00001920: 6831 5363 6f6d 7000 0000 0000 0400 0000  h1Scomp.........
-00001930: 0000 0400 6d00 6900 7300 6376 5372 6e6c  ....m.i.s.cvSrnl
-00001940: 6f6e 6700 0000 0100 0000 0000 0000 0000  ong.............
-00001950: 0000 0000 0000 0000 0000 0000 0000 0000  ................
+00001330: 0099 0000 0004 006d 0069 0073 0063 6473  .......m.i.s.cds
+00001340: 636c 626f 6f6c 0000 0000 0400 6d00 6900  clbool......m.i.
+00001350: 7300 636c 6731 5363 6f6d 7000 0000 0000  s.clg1Scomp.....
+00001360: 0306 2e00 0000 0400 6d00 6900 7300 636c  ........m.i.s.cl
+00001370: 7376 4362 6c6f 6200 0002 b862 706c 6973  svCblob....bplis
+00001380: 7430 30da 0102 0304 0506 0708 090a 0b0c  t00.............
+00001390: 0d18 4849 484a 0c4c 5869 636f 6e53 697a  ..HIHJ.LXiconSiz
+000013a0: 655f 100f 7368 6f77 4963 6f6e 5072 6576  e_..showIconPrev
+000013b0: 6965 7757 636f 6c75 6d6e 735f 1011 6361  iewWcolumns_..ca
+000013c0: 6c63 756c 6174 6541 6c6c 5369 7a65 735f  lculateAllSizes_
+000013d0: 100f 7363 726f 6c6c 506f 7369 7469 6f6e  ..scrollPosition
+000013e0: 5958 7465 7874 5369 7a65 5f10 0f73 6372  YXtextSize_..scr
+000013f0: 6f6c 6c50 6f73 6974 696f 6e58 5a73 6f72  ollPositionXZsor
+00001400: 7443 6f6c 756d 6e5f 1010 7573 6552 656c  tColumn_..useRel
+00001410: 6174 6976 6544 6174 6573 5f10 1276 6965  ativeDates_..vie
+00001420: 774f 7074 696f 6e73 5665 7273 696f 6e23  wOptionsVersion#
+00001430: 4030 0000 0000 0000 09ab 0e17 1c21 252a  @0...........!%*
+00001440: 2f34 393e 43d4 0f10 1112 1314 0c0c 5a69  /49>C.........Zi
+00001450: 6465 6e74 6966 6965 7255 7769 6474 6859  dentifierUwidthY
+00001460: 6173 6365 6e64 696e 6757 7669 7369 626c  ascendingWvisibl
+00001470: 6554 6e61 6d65 1101 a609 09d4 1210 110f  eTname..........
+00001480: 1819 181b 0810 2308 5875 6269 7175 6974  ......#.Xubiquit
+00001490: 79d4 1210 110f 0c1e 1820 0910 b508 5c64  y........ ....\d
+000014a0: 6174 654d 6f64 6966 6965 64d4 1210 110f  ateModified.....
+000014b0: 181e 1824 0808 5b64 6174 6543 7265 6174  ...$..[dateCreat
+000014c0: 6564 d412 1011 0f0c 2718 2909 1061 0854  ed......'.)..a.T
+000014d0: 7369 7a65 d412 1011 0f0c 2c0c 2e09 1073  size......,....s
+000014e0: 0954 6b69 6e64 d412 1011 0f18 310c 3308  .Tkind......1.3.
+000014f0: 1064 0955 6c61 6265 6cd4 1210 110f 1836  .d.Ulabel......6
+00001500: 0c38 0810 4b09 5776 6572 7369 6f6e d412  .8..K.Wversion..
+00001510: 1011 0f18 3b0c 3d08 1101 2c09 5863 6f6d  ....;.=...,.Xcom
+00001520: 6d65 6e74 73d4 1210 110f 1840 1842 0810  ments......@.B..
+00001530: c808 5e64 6174 654c 6173 744f 7065 6e65  ..^dateLastOpene
+00001540: 64d4 1210 110f 181e 1846 0808 5964 6174  d........F..Ydat
+00001550: 6541 6464 6564 0823 0000 0000 0000 0000  eAdded.#........
+00001560: 2340 2800 0000 0000 005c 6461 7465 4d6f  #@(......\dateMo
+00001570: 6469 6669 6564 0910 0100 0800 1d00 2600  dified........&.
+00001580: 3800 4000 5400 6600 6f00 8100 8c00 9f00  8.@.T.f.o.......
+00001590: b400 bd00 be00 ca00 d300 de00 e400 ee00  ................
+000015a0: f600 fb00 fe00 ff01 0001 0901 0a01 0c01  ................
+000015b0: 0d01 1601 1f01 2001 2201 2301 3001 3901  ...... .".#.0.9.
+000015c0: 3a01 3b01 4701 5001 5101 5301 5401 5901  :.;.G.P.Q.S.T.Y.
+000015d0: 6201 6301 6501 6601 6b01 7401 7501 7701  b.c.e.f.k.t.u.w.
+000015e0: 7801 7e01 8701 8801 8a01 8b01 9301 9c01  x.~.............
+000015f0: 9d01 a001 a101 aa01 b301 b401 b601 b701  ................
+00001600: c601 cf01 d001 d101 db01 dc01 e501 ee01  ................
+00001610: fb01 fc00 0000 0000 0002 0100 0000 0000  ................
+00001620: 0000 4d00 0000 0000 0000 0000 0000 0000  ..M.............
+00001630: 0001 fe00 0000 0400 6d00 6900 7300 636c  ........m.i.s.cl
+00001640: 7376 7062 6c6f 6200 0002 9d62 706c 6973  svpblob....bplis
+00001650: 7430 30da 0102 0304 0506 0708 090a 0b0c  t00.............
+00001660: 0d1f 4849 484a 0c26 5869 636f 6e53 697a  ..HIHJ.&XiconSiz
+00001670: 655f 100f 7368 6f77 4963 6f6e 5072 6576  e_..showIconPrev
+00001680: 6965 7757 636f 6c75 6d6e 735f 1011 6361  iewWcolumns_..ca
+00001690: 6c63 756c 6174 6541 6c6c 5369 7a65 735f  lculateAllSizes_
+000016a0: 100f 7363 726f 6c6c 506f 7369 7469 6f6e  ..scrollPosition
+000016b0: 5958 7465 7874 5369 7a65 5f10 0f73 6372  YXtextSize_..scr
+000016c0: 6f6c 6c50 6f73 6974 696f 6e58 5a73 6f72  ollPositionXZsor
+000016d0: 7443 6f6c 756d 6e5f 1010 7573 6552 656c  tColumn_..useRel
+000016e0: 6174 6976 6544 6174 6573 5f10 1276 6965  ativeDates_..vie
+000016f0: 774f 7074 696f 6e73 5665 7273 696f 6e23  wOptionsVersion#
+00001700: 4030 0000 0000 0000 09d9 0e0f 1011 1213  @0..............
+00001710: 1415 1617 2025 2a2e 3338 3d42 5863 6f6d  .... %*.38=BXcom
+00001720: 6d65 6e74 735e 6461 7465 4c61 7374 4f70  ments^dateLastOp
+00001730: 656e 6564 5c64 6174 654d 6f64 6966 6965  ened\dateModifie
+00001740: 645b 6461 7465 4372 6561 7465 6454 7369  d[dateCreatedTsi
+00001750: 7a65 556c 6162 656c 546b 696e 6457 7665  zeUlabelTkindWve
+00001760: 7273 696f 6e54 6e61 6d65 d418 191a 1b1c  rsionTname......
+00001770: 1d0c 1f55 696e 6465 7855 7769 6474 6859  ...UindexUwidthY
+00001780: 6173 6365 6e64 696e 6757 7669 7369 626c  ascendingWvisibl
+00001790: 6510 0711 012c 0908 d418 191a 1b21 221f  e....,.......!".
+000017a0: 1f10 0810 c808 08d4 1819 1a1b 2627 1f0c  ............&'..
+000017b0: 1001 10b5 0809 d418 191a 1b2b 271f 1f10  ...........+'...
+000017c0: 0208 08d4 1819 1a1b 2f30 1f0c 1003 1061  ......../0.....a
+000017d0: 0809 d418 191a 1b34 350c 1f10 0510 6409  .......45.....d.
+000017e0: 08d4 1819 1a1b 393a 0c0c 1004 1073 0909  ......9:.....s..
+000017f0: d418 191a 1b3e 3f0c 1f10 0610 4b09 08d4  .....>?.....K...
+00001800: 1b19 1a18 0c44 0c46 0911 01a6 0910 0008  .....D.F........
+00001810: 2300 0000 0000 0000 0023 4028 0000 0000  #........#@(....
+00001820: 0000 5c64 6174 654d 6f64 6966 6965 6409  ..\dateModified.
+00001830: 0008 001d 0026 0038 0040 0054 0066 006f  .....&.8.@.T.f.o
+00001840: 0081 008c 009f 00b4 00bd 00be 00d1 00da  ................
+00001850: 00e9 00f6 0102 0107 010d 0112 011a 011f  ................
+00001860: 0128 012e 0134 013e 0146 0148 014b 014c  .(...4.>.F.H.K.L
+00001870: 014d 0156 0158 015a 015b 015c 0165 0167  .M.V.X.Z.[.\.e.g
+00001880: 0169 016a 016b 0174 0176 0177 0178 0181  .i.j.k.t.v.w.x..
+00001890: 0183 0185 0186 0187 0190 0192 0194 0195  ................
+000018a0: 0196 019f 01a1 01a3 01a4 01a5 01ae 01b0  ................
+000018b0: 01b2 01b3 01b4 01bd 01be 01c1 01c2 01c4  ................
+000018c0: 01c5 01ce 01d7 01e4 0000 0000 0000 0201  ................
+000018d0: 0000 0000 0000 004c 0000 0000 0000 0000  .......L........
+000018e0: 0000 0000 0000 01e5 0000 0004 006d 0069  .............m.i
+000018f0: 0073 0063 6d6f 4444 626c 6f62 0000 0008  .s.cmoDDblob....
+00001900: 52c2 c56a fdfa c441 0000 0004 006d 0069  R..j...A.....m.i
+00001910: 0073 0063 6d6f 6444 626c 6f62 0000 0008  .s.cmodDblob....
+00001920: e799 1006 35fa c441 0000 0004 006d 0069  ....5..A.....m.i
+00001930: 0073 0063 7068 3153 636f 6d70 0000 0000  .s.cph1Scomp....
+00001940: 0004 0000 0000 0004 006d 0069 0073 0063  .........m.i.s.c
+00001950: 7653 726e 6c6f 6e67 0000 0001 0000 0000  vSrnlong........
 00001960: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00001970: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00001980: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00001990: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 000019a0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 000019b0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 000019c0: 0000 0000 0000 0000 0000 0000 0000 0000  ................
@@ -586,56 +586,56 @@
 00002490: 0100 0200 0000 0000 0100 0400 0000 0000  ................
 000024a0: 0100 0800 0000 0000 0100 1000 0000 0000  ................
 000024b0: 0100 2000 0000 0000 0100 4000 0000 0000  .. .......@.....
 000024c0: 0100 8000 0000 0000 0101 0000 0000 0000  ................
 000024d0: 0102 0000 0000 0000 0104 0000 0000 0000  ................
 000024e0: 0108 0000 0000 0000 0110 0000 0000 0000  ................
 000024f0: 0120 0000 0000 0000 0140 0000 0000 0000  . .......@......
-00002500: 003d 0811 012c 0958 636f 6d6d 656e 7473  .=...,.Xcomments
-00002510: d412 1011 0f18 4018 4208 10c8 085e 6461  ......@.B....^da
-00002520: 7465 4c61 7374 4f70 656e 6564 d412 1011  teLastOpened....
-00002530: 0f18 1e18 4608 0859 6461 7465 4164 6465  ....F..YdateAdde
-00002540: 6408 2300 0000 0000 0000 0023 4028 0000  d.#........#@(..
-00002550: 0000 0000 5c64 6174 654d 6f64 6966 6965  ....\dateModifie
-00002560: 6409 1001 0008 001d 0026 0038 0040 0054  d........&.8.@.T
-00002570: 0066 006f 0081 008c 009f 00b4 00bd 00be  .f.o............
-00002580: 00ca 00d3 00de 00e4 00ee 00f6 00fb 00fe  ................
-00002590: 00ff 0100 0109 010a 010c 010d 0116 011f  ................
-000025a0: 0120 0122 0123 0130 0139 013a 013b 0147  . .".#.0.9.:.;.G
-000025b0: 0150 0151 0153 0154 0159 0162 0163 0165  .P.Q.S.T.Y.b.c.e
-000025c0: 0166 016b 0174 0175 0177 0178 017e 0187  .f.k.t.u.w.x.~..
-000025d0: 0188 018a 018b 0193 019c 019d 01a0 01a1  ................
-000025e0: 01aa 01b3 01b4 01b6 01b7 01c6 01cf 01d0  ................
-000025f0: 01d1 01db 01dc 01e5 01ee 01fb 01fc 0000  ................
-00002600: 0000 0000 0201 0000 0000 0000 004d 0000  .............M..
-00002610: 0000 0000 0000 0000 0000 0000 01fe 0000  ................
-00002620: 0004 006d 0069 0073 0063 6c73 7670 626c  ...m.i.s.clsvpbl
-00002630: 6f62 0000 029d 6270 6c69 7374 3030 da01  ob....bplist00..
-00002640: 0203 0405 0607 0809 0a0b 0c0d 1f48 4948  .............HIH
-00002650: 4a0c 2658 6963 6f6e 5369 7a65 5f10 0f73  J.&XiconSize_..s
-00002660: 686f 7749 636f 6e50 7265 7669 6577 5763  howIconPreviewWc
-00002670: 6f6c 756d 6e73 5f10 1163 616c 6375 6c61  olumns_..calcula
-00002680: 7465 416c 6c53 697a 6573 5f10 0f73 6372  teAllSizes_..scr
-00002690: 6f6c 6c50 6f73 6974 696f 6e59 5874 6578  ollPositionYXtex
-000026a0: 7453 697a 655f 100f 7363 726f 6c6c 506f  tSize_..scrollPo
-000026b0: 7369 7469 6f6e 585a 736f 7274 436f 6c75  sitionXZsortColu
-000026c0: 6d6e 5f10 1075 7365 5265 6c61 7469 7665  mn_..useRelative
-000026d0: 4461 7465 735f 1012 7669 6577 4f70 7469  Dates_..viewOpti
-000026e0: 6f6e 7356 6572 7369 6f6e 2340 3000 0000  onsVersion#@0...
-000026f0: 0000 0009 d90e 0f10 1112 1314 1516 1720  ............... 
-00002700: 252a 2e33 383d 4258 636f 6d6d 656e 7473  %*.38=BXcomments
-00002710: 5e64 6174 654c 6173 744f 7065 6e65 645c  ^dateLastOpened\
-00002720: 6461 7465 4d6f 6469 6669 6564 5b64 6174  dateModified[dat
-00002730: 6543 7265 6174 6564 5473 697a 6555 6c61  eCreatedTsizeUla
-00002740: 6265 6c54 6b69 6e64 5776 6572 7369 6f6e  belTkindWversion
-00002750: 546e 616d 65d4 1819 1a1b 1c1d 0c1f 5569  Tname.........Ui
-00002760: 6e64 6578 5577 6964 7468 5961 7363 656e  ndexUwidthYascen
-00002770: 6469 6e67 5776 6973 6962 6c65 1007 1101  dingWvisible....
-00002780: 2c09 08d4 1819 1a1b 2122 1f1f 1008 10c8  ,.......!"......
-00002790: 0808 d418 191a 1b26 271f 0c10 0110 b508  .......&'.......
-000027a0: 09d4 1819 1a1b 2b27 1f1f 1002 0808 d418  ......+'........
-000027b0: 191a 1b2f 301f 0c10 0310 6108 09d4 1819  .../0.....a.....
-000027c0: 1a1b 3435 0c1f 1005 1064 0908 d418 191a  ..45.....d......
-000027d0: 1b39 3a0c 0c10 0410 7309 09d4 1819 1a1b  .9:.....s.......
-000027e0: 3e3f 0c1f 1006 104b 0908 d41b 191a 180c  >?.....K........
-000027f0: 440c 4609 1101 a609 1000 0823 0000 0000  D.F........#....
-00002800: 0000 0000                                ....
+00002500: 0038 0810 4b09 5776 6572 7369 6f6e d412  .8..K.Wversion..
+00002510: 1011 0f18 3b0c 3d08 1101 2c09 5863 6f6d  ....;.=...,.Xcom
+00002520: 6d65 6e74 73d4 1210 110f 1840 1842 0810  ments......@.B..
+00002530: c808 5e64 6174 654c 6173 744f 7065 6e65  ..^dateLastOpene
+00002540: 64d4 1210 110f 181e 1846 0808 5964 6174  d........F..Ydat
+00002550: 6541 6464 6564 0823 0000 0000 0000 0000  eAdded.#........
+00002560: 2340 2800 0000 0000 005c 6461 7465 4d6f  #@(......\dateMo
+00002570: 6469 6669 6564 0910 0100 0800 1d00 2600  dified........&.
+00002580: 3800 4000 5400 6600 6f00 8100 8c00 9f00  8.@.T.f.o.......
+00002590: b400 bd00 be00 ca00 d300 de00 e400 ee00  ................
+000025a0: f600 fb00 fe00 ff01 0001 0901 0a01 0c01  ................
+000025b0: 0d01 1601 1f01 2001 2201 2301 3001 3901  ...... .".#.0.9.
+000025c0: 3a01 3b01 4701 5001 5101 5301 5401 5901  :.;.G.P.Q.S.T.Y.
+000025d0: 6201 6301 6501 6601 6b01 7401 7501 7701  b.c.e.f.k.t.u.w.
+000025e0: 7801 7e01 8701 8801 8a01 8b01 9301 9c01  x.~.............
+000025f0: 9d01 a001 a101 aa01 b301 b401 b601 b701  ................
+00002600: c601 cf01 d001 d101 db01 dc01 e501 ee01  ................
+00002610: fb01 fc00 0000 0000 0002 0100 0000 0000  ................
+00002620: 0000 4d00 0000 0000 0000 0000 0000 0000  ..M.............
+00002630: 0001 fe00 0000 0400 6d00 6900 7300 636c  ........m.i.s.cl
+00002640: 7376 7062 6c6f 6200 0002 9d62 706c 6973  svpblob....bplis
+00002650: 7430 30da 0102 0304 0506 0708 090a 0b0c  t00.............
+00002660: 0d1f 4849 484a 0c26 5869 636f 6e53 697a  ..HIHJ.&XiconSiz
+00002670: 655f 100f 7368 6f77 4963 6f6e 5072 6576  e_..showIconPrev
+00002680: 6965 7757 636f 6c75 6d6e 735f 1011 6361  iewWcolumns_..ca
+00002690: 6c63 756c 6174 6541 6c6c 5369 7a65 735f  lculateAllSizes_
+000026a0: 100f 7363 726f 6c6c 506f 7369 7469 6f6e  ..scrollPosition
+000026b0: 5958 7465 7874 5369 7a65 5f10 0f73 6372  YXtextSize_..scr
+000026c0: 6f6c 6c50 6f73 6974 696f 6e58 5a73 6f72  ollPositionXZsor
+000026d0: 7443 6f6c 756d 6e5f 1010 7573 6552 656c  tColumn_..useRel
+000026e0: 6174 6976 6544 6174 6573 5f10 1276 6965  ativeDates_..vie
+000026f0: 774f 7074 696f 6e73 5665 7273 696f 6e23  wOptionsVersion#
+00002700: 4030 0000 0000 0000 09d9 0e0f 1011 1213  @0..............
+00002710: 1415 1617 2025 2a2e 3338 3d42 5863 6f6d  .... %*.38=BXcom
+00002720: 6d65 6e74 735e 6461 7465 4c61 7374 4f70  ments^dateLastOp
+00002730: 656e 6564 5c64 6174 654d 6f64 6966 6965  ened\dateModifie
+00002740: 645b 6461 7465 4372 6561 7465 6454 7369  d[dateCreatedTsi
+00002750: 7a65 556c 6162 656c 546b 696e 6457 7665  zeUlabelTkindWve
+00002760: 7273 696f 6e54 6e61 6d65 d418 191a 1b1c  rsionTname......
+00002770: 1d0c 1f55 696e 6465 7855 7769 6474 6859  ...UindexUwidthY
+00002780: 6173 6365 6e64 696e 6757 7669 7369 626c  ascendingWvisibl
+00002790: 6510 0711 012c 0908 d418 191a 1b21 221f  e....,.......!".
+000027a0: 1f10 0810 c808 08d4 1819 1a1b 2627 1f0c  ............&'..
+000027b0: 1001 10b5 0809 d418 191a 1b2b 271f 1f10  ...........+'...
+000027c0: 0208 08d4 1819 1a1b 2f30 1f0c 1003 1061  ......../0.....a
+000027d0: 0809 d418 191a 1b34 350c 1f10 0510 6409  .......45.....d.
+000027e0: 08d4 1819 1a1b 393a 0c0c 1004 1073 0909  ......9:.....s..
+000027f0: d418 191a 1b3e 3f0c 1f10 0610 4b09 08d4  .....>?.....K...
+00002800: 1b19 1a18                                ....
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/perimeter_jit.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/perimeter_jit.py`

 * *Files 9% similar despite different names*

```diff
@@ -16,14 +16,18 @@
 @njit('(float64[:, :,:], types.unicode_type)', fastmath=True)
 def jitted_hull(points: np.ndarray, target: str='perimeter') -> np.ndarray:
 
     """
     :param array points: 3d array FRAMESxBODY-PARTxCOORDINATE
     :param str target: Options [perimeter, area]
     :return: 1d np.array
+
+    :EXAMPLE:
+    >>> points = np.random.randint(1, 50, size=(50, 5, 2)).astype(float)
+    >>> results = jitted_hull(points, target='area')
     """
 
     results = np.full((points.shape[0]), np.nan)
 
     def perimeter(xy):
         perimeter = np.linalg.norm(xy[0] - xy[-1])
         for i in prange(xy.shape[0]-1):
@@ -52,10 +56,8 @@
             xy = np.vstack((x_sorted, y_sorted)).T
             results[i] = perimeter(xy)
         if target == 'area':
             results[i] = area(x_sorted, y_sorted)
 
     return results
 
-# points = np.random.randint(1, 50, size=(50, 5, 2)).astype(float)
-# results = jitted_hull(points, target='area')
-#print(time.time() - start)
+
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/feature_subsets.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/feature_subsets.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,29 +1,28 @@
 import pandas as pd
-from simba.mixins.config_reader import ConfigReader
-from simba.mixins.feature_extraction_mixin import FeatureExtractionMixin
-from simba.misc_tools import check_if_filepath_list_is_empty
-from simba.utils.printing import stdout_success
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.misc_tools import get_fn_ext, SimbaTimer
-from simba.rw_dfs import read_df
 import os
 import numpy as np
 from itertools import combinations
 from simba.feature_extractors.perimeter_jit import jitted_hull
-from simba.enums import Formats, Keys
-
+from simba.enums import Formats
+from simba.mixins.config_reader import ConfigReader
+from simba.mixins.feature_extraction_mixin import FeatureExtractionMixin
+from simba.utils.checks import check_if_filepath_list_is_empty
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.utils.read_write import get_fn_ext, read_df, write_df
 
 
 class FeatureSubsetsCalculator(ConfigReader, FeatureExtractionMixin):
     def __init__(self,
                  config_path: str,
                  save_dir: str,
                  feature_family: str):
-        super().__init__(config_path=config_path)
+
+        FeatureExtractionMixin.__init__(self, config_path=config_path)
+        ConfigReader.__init__(self, config_path=config_path)
         check_if_filepath_list_is_empty(filepaths=self.outlier_corrected_paths, error_msg=f'SIMBA ERROR: Zero data files found in {self.outlier_corrected_paths} directory')
         self.feature_family, self.save_dir = feature_family, save_dir
 
     def __get_bp_combinations(self):
         self.two_point_combs = np.array(list(combinations(self.project_bps, 2)))
         self.within_animal_three_point_combs = {}
         self.within_animal_four_point_combs = {}
@@ -33,20 +32,19 @@
             self.animal_bps[animal] = animal_bps
             self.within_animal_three_point_combs[animal] = np.array(list(combinations(animal_bps, 3)))
             self.within_animal_four_point_combs[animal] = np.array(list(combinations(animal_bps, 4)))
 
     def run(self):
         self.__get_bp_combinations()
         for file_path in self.outlier_corrected_paths:
-            self.video_timer = SimbaTimer()
-            self.video_timer.start_timer()
+            self.video_timer = SimbaTimer(start=True)
             self.results = pd.DataFrame()
             _, self.video_name, _ = get_fn_ext(filepath=file_path)
             print(f'Analyzing {self.video_name} ({self.feature_family})...')
-            _, self.pixel_per_mm, self.fps = read_video_info(vid_info_df=self.video_info_df, video_name=self.video_name)
+            _, self.pixel_per_mm, self.fps = self.read_video_info(video_name=self.video_name)
             self.df = read_df(file_path=file_path, file_type=self.file_type)
             if self.feature_family == 'Two-point body-part distances (mm)':
                 self.calc_distances()
             elif self.feature_family == 'Within-animal three-point body-part angles (degrees)':
                 self.calc_angles()
             elif self.feature_family == 'Within-animal three-point convex hull perimeters (mm)':
                 self.calc_three_point_hulls()
@@ -58,15 +56,14 @@
                 self.calc_animal_convex_hulls_area()
             elif self.feature_family == 'Frame-by-frame body-part movements (mm)':
                 self.calc_movements()
             elif self.feature_family == 'Frame-by-frame body-part distances to ROI centers (mm)':
                 self.calc_roi_center_distances()
             elif self.feature_family == 'Frame-by-frame body-parts inside ROIs (Boolean)':
                 self.calc_inside_roi()
-
             self.__save()
             self.video_timer.stop_timer()
             print(f'Video {self.video_name} complete (elapsed time {self.video_timer.elapsed_time_str}s)...')
         self.timer.stop_timer()
         stdout_success(msg=f'{self.feature_family} for {str(len(self.outlier_corrected_paths))} videos saved in {self.save_dir}', elapsed_time=self.timer.elapsed_time_str)
 
     def calc_distances(self):
@@ -149,17 +146,15 @@
                         if shape_type == 'polygons':
                             shape_data = shape_data.loc[(shape_data['Video'] == self.video_name) & (shape_data['Name'] == shape_name)][['vertices']].values[0][0]
                             self.results[f'{animal} {bp} inside polygon {shape_name} (Boolean)'] = self.framewise_inside_polygon_roi(bp_location=bp_arr, roi_coords=shape_data)
 
 
     def __save(self):
         save_path = os.path.join(self.save_dir, f'{self.video_name}.csv')
-        self.results.round(2).to_csv(save_path)
-
-
+        write_df(df=self.results.round(2), file_type=Formats.CSV.value, save_path=save_path)
 
 
 # test = FeatureSubsetsCalculator(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini',
 #                                 feature_family='Frame-by-frame body-parts inside ROIs (Boolean)',
 #                                 save_dir='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/data')
 # test.run()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/__pycache__/perimeter_jit.quickhull_2d-16.py36m.nbi` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/__pycache__/perimeter_jit.quickhull_2d-16.py36m.nbi`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/__pycache__/perimeter_jit.quickhull_2d-16.py36m.1.nbc` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/__pycache__/perimeter_jit.quickhull_2d-16.py36m.1.nbc`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/__pycache__/perimeter_jit.process-7.py36m.1.nbc` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/__pycache__/perimeter_jit.process-7.py36m.1.nbc`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/__pycache__/perimeter_jit.convex_hull_perimeter_2d-16.py36m.1.nbc` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/__pycache__/perimeter_jit.convex_hull_perimeter_2d-16.py36m.1.nbc`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/__pycache__/perimeter_jit.process-7.py36m.2.nbc` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/__pycache__/perimeter_jit.process-7.py36m.2.nbc`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/__pycache__/perimeter_jit.convex_hull_perimeter_2d-16.py36m.nbi` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/__pycache__/perimeter_jit.convex_hull_perimeter_2d-16.py36m.nbi`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/__pycache__/perimeter_jit.process-7.py36m.nbi` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/__pycache__/perimeter_jit.process-7.py36m.nbi`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/feature_extractor_user_defined.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/feature_extractor_user_defined.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,22 +1,18 @@
-from simba.misc_tools import (get_fn_ext,
-                              SimbaTimer,
-                              )
-from simba.utils.printing import stdout_success
-from simba.read_config_unit_tests import check_str
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.rw_dfs import (read_df,
-                          save_df)
 import os
 import pandas as pd
 import numpy as np
 from itertools import product
 from simba.mixins.feature_extraction_mixin import FeatureExtractionMixin
+from simba.mixins.config_reader import ConfigReader
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.utils.read_write import get_fn_ext, read_df, write_df
+from simba.utils.checks import check_str
 
-class UserDefinedFeatureExtractor(FeatureExtractionMixin):
+class UserDefinedFeatureExtractor(ConfigReader, FeatureExtractionMixin):
     """
     Class for featurizing data within SimBA project using user-defined body-parts in the pose-estimation data.
     Results are stored in the `project_folder/csv/features_extracted` directory of the SimBA project.
 
     Parameters
     ----------
     config_path: str
@@ -25,24 +21,23 @@
     Notes
     ----------
     Feature extraction tutorial <https://github.com/sgoldenlab/simba/blob/master/docs/tutorial.md#step-5-extract-features>`__.
 
     Examples
     ----------
     >>> feature_extractor = UserDefinedFeatureExtractor(config_path='MyProjectConfig')
-    >>> feature_extractor.extract_features()
+    >>> feature_extractor.run()
 
     """
 
     def __init__(self,
                  config_path: str):
 
-        super().__init__(config_path=config_path)
-        self.timer = SimbaTimer()
-        self.timer.start_timer()
+        FeatureExtractionMixin.__init__(self, config_path=config_path)
+        ConfigReader.__init__(self, config_path=config_path)
         print('Extracting features from {} file(s)...'.format(str(len(self.files_found))))
 
     def __euclid_dist_between_bps_of_other_animals(self):
         print('Calculating euclidean distances...')
         self.distance_col_names = []
         for animal_name, animal_data in self.animal_bp_dict.items():
             current_animal_bp_xs, current_animal_bp_ys = animal_data['X_bps'], animal_data['Y_bps']
@@ -85,37 +80,36 @@
     def __rolling_windows_movement(self):
         print('Calculating rolling windows data: animal movements...')
         for i in product(self.roll_windows_values, self.mean_movement_cols):
             self.data_df['Mean_{}_{}'.format(i[1], i[0])] = self.data_df[i[1]].rolling(int(i[0]), min_periods=1).mean()
             self.data_df['Sum_{}_{}'.format(i[1], i[0])] = self.data_df[i[1]].rolling(int(i[0]), min_periods=1).sum()
 
     def __pose_probability_filters(self):
-        p_df = self.data_df.filter(self.pcols, axis=1)
+        p_df = self.data_df.filter(self.p_cols, axis=1)
         self.data_df['Sum_probabilities'] = p_df.sum(axis=1)
         self.data_df['Mean_probabilities'] = p_df.mean(axis=1)
-        results = pd.DataFrame(self.count_values_in_range(data=self.data_df.filter(self.pcols).values, ranges=np.array([[0.0, 0.1], [0.0, 0.5], [0.0, 0.75]])), columns=['Low_prob_detections_0.1', 'Low_prob_detections_0.5','Low_prob_detections_0.75'])
+        results = pd.DataFrame(self.count_values_in_range(data=self.data_df.filter(self.p_cols).values, ranges=np.array([[0.0, 0.1], [0.0, 0.5], [0.0, 0.75]])), columns=['Low_prob_detections_0.1', 'Low_prob_detections_0.5','Low_prob_detections_0.75'])
         self.data_df = pd.concat([self.data_df, results], axis=1)
 
-    def extract_features(self):
+    def run(self):
         """
         Method to compute and save features to disk. Results are saved in the `project_folder/csv/features_extracted`
         directory of the SimBA project.
 
         Returns
         -------
         None
         """
 
         for file_cnt, file_path in enumerate(self.files_found):
-            video_timer = SimbaTimer()
-            video_timer.start_timer()
+            video_timer = SimbaTimer(start=True)
             print('Extracting features for video {}/{}...'.format(str(file_cnt+1), str(len(self.files_found))))
             _, file_name, _ = get_fn_ext(file_path)
             check_str('file name', file_name)
-            video_settings, self.px_per_mm, fps = read_video_info(self.vid_info_df, file_name)
+            video_settings, self.px_per_mm, fps = self.read_video_info(video_name=file_name)
             roll_windows = []
             for i in range(len(self.roll_windows_values)):
                 roll_windows.append(int(fps / self.roll_windows_values[i]))
             self.data_df = read_df(file_path, self.file_type)
             self.data_df.columns = self.col_headers
             self.data_df = self.data_df.fillna(0).apply(pd.to_numeric)
             self.data_df_shifted = self.data_df.shift(periods=1)
@@ -124,17 +118,16 @@
             self.__euclid_dist_between_bps_of_other_animals()
             self.__movement_of_all_bps()
             self.__rolling_windows_bp_distances()
             self.__rolling_windows_movement()
             self.__pose_probability_filters()
             save_path = os.path.join(self.save_dir, file_name + '.' + self.file_type)
             self.data_df = self.data_df.reset_index(drop=True).fillna(0)
-            save_df(self.data_df, self.file_type, save_path)
+            write_df(df=self.data_df, file_type=self.file_type, save_path=save_path)
             video_timer.stop_timer()
-            print('Saving features for video {}...'.format(file_name))
-            print('Feature extraction complete for video {} (elapsed time: {}s)'.format(file_name, video_timer.elapsed_time_str))
+            print(f'Feature extraction complete for video {file_name} (elapsed time: {video_timer.elapsed_time_str}s)')
 
         self.timer.stop_timer()
         stdout_success(f'Feature extraction complete for {str(len(self.files_found))} video(s). Results are saved inside the project_folder/csv/features_extracted directory', elapsed_time=self.timer.elapsed_time_str)
 
-## test = UserDefinedFeatureExtractor(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini')
-## test.extract_features()
+# test = UserDefinedFeatureExtractor(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini')
+# test.run()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/feature_extractor_16bp.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/feature_extractor_16bp.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,27 +1,21 @@
-from simba.read_config_unit_tests import insert_default_headers_for_feature_extraction
 import os
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.misc_tools import get_feature_extraction_headers
-from simba.utils.printing import stdout_success
-from simba.drop_bp_cords import get_fn_ext
-from simba.rw_dfs import read_df, save_df
 import pandas as pd
 import numpy as np
 from copy import deepcopy
 import math
-from scipy.spatial import ConvexHull
 from collections import defaultdict
-import scipy
-import time
 from simba.enums import Formats
 from simba.mixins.feature_extraction_mixin import FeatureExtractionMixin
+from simba.mixins.config_reader import ConfigReader
 from simba.feature_extractors.perimeter_jit import jitted_hull
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.utils.read_write import get_fn_ext, read_df, write_df
 
-class ExtractFeaturesFrom16bps(FeatureExtractionMixin):
+class ExtractFeaturesFrom16bps(ConfigReader, FeatureExtractionMixin):
     """
     Class for creating a hard-coded set of features from two animals with 8 tracked body-parts
     each using pose-estimation. Results are stored in the `project_folder/csv/features_extracted`
     directory of the SimBA project
     Parameters
     ----------
     config_path: str
@@ -30,48 +24,49 @@
     Notes
     ----------
     Feature extraction tutorial <https://github.com/sgoldenlab/simba/blob/master/docs/tutorial.md#step-5-extract-features>`__.
 
     Examples
     ----------
     >>> feature_extractor = ExtractFeaturesFrom16bps(config_path='MyProjectConfig')
-    >>> feature_extractor.extract_features()
+    >>> feature_extractor.run()
     """
 
     def __init__(self,
                  config_path: str):
 
-        super().__init__(config_path=config_path)
-        self.in_headers = get_feature_extraction_headers(pose='2 animals 16 body-parts')
+        FeatureExtractionMixin.__init__(self, config_path=config_path)
+        ConfigReader.__init__(self, config_path=config_path)
+        self.in_headers = self.get_feature_extraction_headers(pose='2 animals 16 body-parts')
         self.mouse_1_headers, self.mouse_2_headers = self.in_headers[0:24], self.in_headers[24:]
         self.mouse_2_p_headers = [x for x in self.mouse_2_headers if x[-2:] == '_p']
         self.mouse_1_p_headers = [x for x in self.mouse_1_headers if x[-2:] == '_p']
         self.mouse_1_headers = [x for x in self.mouse_1_headers if x[-2:] != '_p']
         self.mouse_2_headers = [x for x in self.mouse_2_headers if x[-2:] != '_p']
         print('Extracting features from {} file(s)...'.format(str(len(self.files_found))))
 
-    def extract_features(self):
+    def run(self):
         """
         Method to compute and save feature battery to disk. Results are saved in the `project_folder/csv/features_extracted`
         directory of the SimBA project.
 
         Returns
         -------
         None
         """
-        session_time = 0
         for file_cnt, file_path in enumerate(self.files_found):
-            roll_windows, file_start_time = [], time.time()
+            video_timer = SimbaTimer(start=True)
+            roll_windows = []
             _, self.video_name, _ = get_fn_ext(file_path)
-            video_settings, self.px_per_mm, fps = read_video_info(self.vid_info_df, self.video_name)
+            video_settings, self.px_per_mm, fps = self.read_video_info(video_name=self.video_name)
             for window in self.roll_windows_values:
                 roll_windows.append(int(fps / window))
             self.in_data = read_df(file_path, self.file_type).fillna(0).apply(pd.to_numeric).reset_index(drop=True)
             print('Processing {} ({} frames)...'.format(self.video_name, str(len(self.in_data))))
-            self.in_data = insert_default_headers_for_feature_extraction(df=self.in_data, headers=self.in_headers, pose_config='16 body-parts', filename=file_path)
+            self.in_data = self.insert_default_headers_for_feature_extraction(df=self.in_data, headers=self.in_headers, pose_config='16 body-parts', filename=file_path)
             self.out_data = deepcopy(self.in_data)
             mouse_1_ar = np.reshape(self.out_data[self.mouse_1_headers].values, (len(self.out_data / 2), -1, 2))
             self.out_data['Mouse_1_poly_area'] = jitted_hull(points=mouse_1_ar, target=Formats.PERIMETER.value) / self.px_per_mm
             mouse_2_ar = np.reshape(self.out_data[self.mouse_2_headers].values, (len(self.out_data / 2), -1, 2))
             self.out_data['Mouse_2_poly_area'] = jitted_hull(points=mouse_2_ar, target=Formats.PERIMETER.value) / self.px_per_mm
             self.in_data_shifted = self.out_data.shift(periods=1).add_suffix('_shifted').fillna(0)
             self.in_data = pd.concat([self.in_data, self.in_data_shifted], axis=1, join='inner').fillna(0).reset_index(drop=True)
@@ -119,16 +114,15 @@
             self.out_data['Mouse_2_polygon_size_change'] = (self.in_data['Mouse_2_poly_area_shifted'] - self.out_data['Mouse_2_poly_area'])
 
             print('Calculating hull variables...')
             mouse_1_array, mouse_2_array = self.in_data[self.mouse_1_headers].to_numpy(), self.in_data[self.mouse_2_headers].to_numpy()
             self.hull_dict = defaultdict(list)
             for cnt, (animal_1, animal_2) in enumerate(zip(mouse_1_array, mouse_2_array)):
                 animal_1, animal_2 = np.reshape(animal_1, (-1, 2)), np.reshape(animal_2, (-1, 2))
-                animal_1_dist = scipy.spatial.distance.cdist(animal_1, animal_1, metric='euclidean')
-                animal_2_dist = scipy.spatial.distance.cdist(animal_2, animal_2, metric='euclidean')
+                animal_1_dist, animal_2_dist = self.cdist(animal_1, animal_1), self.cdist(animal_2, animal_2)
                 animal_1_dist, animal_2_dist = animal_1_dist[animal_1_dist != 0], animal_2_dist[animal_2_dist != 0]
                 for animal, animal_name in zip([animal_1_dist, animal_2_dist], ['M1', 'M2']):
                     self.hull_dict['{}_hull_large_euclidean'.format(animal_name)].append(np.amax(animal, initial=0) / self.px_per_mm)
                     self.hull_dict['{}_hull_small_euclidean'.format(animal_name)].append(np.min(animal, initial=self.hull_dict['{}_hull_large_euclidean'.format(animal_name)][-1]) / self.px_per_mm)
                     self.hull_dict['{}_hull_mean_euclidean'.format(animal_name)].append(np.mean(animal) / self.px_per_mm)
                     self.hull_dict['{}_hull_sum_euclidean'.format(animal_name)].append(np.sum(animal, initial=0) / self.px_per_mm)
             for k, v in self.hull_dict.items():
@@ -472,15 +466,16 @@
             self.out_data['Sum_probabilities_deviation'] = (self.out_data['Sum_probabilities'].mean() - self.out_data['Sum_probabilities'])
             self.out_data['Sum_probabilities_deviation_percentile_rank'] = self.out_data['Sum_probabilities_deviation'].rank(pct=True)
             self.out_data['Sum_probabilities_percentile_rank'] = self.out_data['Sum_probabilities_deviation_percentile_rank'].rank(pct=True)
             results = pd.DataFrame(self.count_values_in_range(data=self.out_data.filter(all_p_columns).values, ranges=np.array([[0.0, 0.1], [0.0, 0.5], [0.0, 0.75]])), columns=['Low_prob_detections_0.1', 'Low_prob_detections_0.5', 'Low_prob_detections_0.75'])
             self.out_data = pd.concat([self.out_data, results], axis=1)
             self.out_data = self.out_data.reset_index(drop=True).fillna(0)
             save_path = os.path.join(self.save_dir, self.video_name + '.' + self.file_type)
-            save_df(self.out_data, self.file_type, save_path)
-            session_time, file_time = session_time + (time.time()-file_start_time), int(time.time() - file_start_time)
-            print('Feature extraction complete for {} ({}/{} (elapsed time: {}s)...'.format(self.video_name, str(file_cnt + 1), str(len(self.files_found)), str(file_time)))
+            write_df(df=self.out_data, file_type=self.file_type, save_path=save_path)
+            video_timer.stop_timer()
+            print(f'Feature extraction complete for {self.video_name} ({file_cnt + 1}/{len(self.files_found)} (elapsed time: {video_timer.elapsed_time_str}s)...')
 
-        stdout_success(msg='All features extracted. Results stored in project_folder/csv/features_extracted directory', elapsed_time=str(int(session_time)))
+        self.timer.stop_timer()
+        stdout_success(msg='All features extracted. Results stored in project_folder/csv/features_extracted directory', elapsed_time=self.timer.elapsed_time_str)
 
 # test = ExtractFeaturesFrom16bps(config_path='/Users/simon/Desktop/envs/troubleshooting/two_animals_16bp_032023/project_folder/project_config.ini')
-# test.extract_features()
+# test.run()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/feature_extractor_8bp.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/feature_extractor_8bp.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,27 +1,21 @@
-import os, glob
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.read_config_unit_tests import insert_default_headers_for_feature_extraction
-from simba.misc_tools import get_feature_extraction_headers
-from simba.utils.printing import stdout_success
-from simba.drop_bp_cords import get_fn_ext
-from simba.rw_dfs import read_df, save_df
+import os
 import numpy as np
 import pandas as pd
 from copy import deepcopy
 import math
-from scipy.spatial import ConvexHull
-import scipy
 from collections import defaultdict
-import time
+from simba.enums import Formats
 from simba.mixins.feature_extraction_mixin import FeatureExtractionMixin
+from simba.mixins.config_reader import ConfigReader
 from simba.feature_extractors.perimeter_jit import jitted_hull
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.utils.read_write import get_fn_ext, read_df, write_df
 
-
-class ExtractFeaturesFrom8bps(FeatureExtractionMixin):
+class ExtractFeaturesFrom8bps(ConfigReader, FeatureExtractionMixin):
     """
     Class for creating a hard-coded set of features from single animals with 8 tracked body-parts
     using pose-estimation. Results are stored in the `project_folder/csv/features_extracted`
     directory of the SimBA project.
 
     Parameters
     ----------
@@ -32,48 +26,50 @@
     ----------
     Feature extraction tutorial <https://github.com/sgoldenlab/simba/blob/master/docs/tutorial.md#step-5-extract-features>`__.
     feature_extractor_14bps_new
 
     Examples
     ----------
     >>> feature_extractor = ExtractFeaturesFrom8bps(config_path='MyProjectConfig')
-    >>> feature_extractor.extract_features()
+    >>> feature_extractor.run()
     """
 
     def __init__(self,
                  config_path=None):
 
-        super().__init__(config_path=config_path)
-        self.in_headers = get_feature_extraction_headers(pose='1 animal 8 body-parts')
+        FeatureExtractionMixin.__init__(self, config_path=config_path)
+        ConfigReader.__init__(self, config_path=config_path)
+        self.in_headers = self.get_feature_extraction_headers(pose='1 animal 8 body-parts')
         self.mouse_p_headers = [x for x in self.in_headers if x[-2:] == '_p']
         self.mouse_headers = [x for x in self.in_headers if x[-2:] != '_p']
         print('Extracting features from {} file(s)...'.format(str(len(self.files_found))))
 
-    def extract_features(self):
+    def run(self):
         """
         Method to compute and save features to disk. Results are saved in the `project_folder/csv/features_extracted`
         directory of the SimBA project.
 
         Returns
         -------
         None
         """
-        session_time = 0
+
         for file_cnt, file_path in enumerate(self.files_found):
+            video_timer = SimbaTimer(start=True)
             _, self.video_name, _ = get_fn_ext(file_path)
-            video_settings, self.px_per_mm, fps = read_video_info(self.vid_info_df, self.video_name)
-            roll_windows, file_start_time = [], time.time()
+            video_settings, self.px_per_mm, fps = self.read_video_info(video_name=self.video_name)
+            roll_windows = []
             for window in self.roll_windows_values:
                 roll_windows.append(int(fps / window))
             self.in_data = read_df(file_path, self.file_type).fillna(0).apply(pd.to_numeric).reset_index(drop=True)
             print('Processing {} ({} frames)...'.format(self.video_name, str(len(self.in_data))))
-            self.in_data = insert_default_headers_for_feature_extraction(df=self.in_data, headers=self.in_headers, pose_config='8 body-parts', filename=file_path)
+            self.in_data = self.insert_default_headers_for_feature_extraction(df=self.in_data, headers=self.in_headers, pose_config='8 body-parts', filename=file_path)
             self.out_data = deepcopy(self.in_data)
             mouse_1_ar = np.reshape(self.out_data[self.mouse_headers].values, (len(self.out_data / 2), -1, 2))
-            self.out_data['Mouse_poly_area'] = jitted_hull(points=mouse_1_ar, target=Format.PERIMETER.value) / self.px_per_mm
+            self.out_data['Mouse_poly_area'] = jitted_hull(points=mouse_1_ar, target=Formats.PERIMETER.value) / self.px_per_mm
             self.in_data_shifted = self.out_data.shift(periods=1).add_suffix('_shifted').fillna(0)
             self.in_data = pd.concat([self.in_data, self.in_data_shifted], axis=1, join='inner').fillna(0).reset_index(drop=True)
             self.out_data['Mouse_nose_to_tail'] = self.euclidean_distance(self.in_data['Nose_x'].values, self.in_data['Tail_base_x'].values, self.in_data['Nose_y'].values, self.in_data['Tail_base_y'].values, self.px_per_mm)
             self.out_data['Mouse_width'] = self.euclidean_distance(self.in_data['Lat_left_x'].values, self.in_data['Lat_right_x'].values, self.in_data['Lat_left_y'].values, self.in_data['Lat_right_y'].values, self.px_per_mm)
             self.out_data['Mouse_Ear_distance'] = self.euclidean_distance(self.in_data['Ear_left_x'].values, self.in_data['Ear_right_x'].values, self.in_data['Ear_left_y'].values, self.in_data['Ear_right_y'].values, self.px_per_mm)
             self.out_data['Mouse_Nose_to_centroid'] = self.euclidean_distance(self.in_data['Nose_x'].values, self.in_data['Center_x'].values, self.in_data['Nose_y'].values, self.in_data['Center_y'].values, self.px_per_mm)
             self.out_data['Mouse_Nose_to_lateral_left'] = self.euclidean_distance(self.in_data['Nose_x'].values, self.in_data['Lat_left_x'].values, self.in_data['Nose_y'].values, self.in_data['Lat_left_y'].values, self.px_per_mm)
@@ -91,15 +87,15 @@
             self.out_data['Mouse_polygon_size_change'] = (self.in_data['Mouse_poly_area_shifted'] - self.out_data['Mouse_poly_area'])
 
             print('Calculating hull variables...')
             mouse_array = self.in_data[self.mouse_headers].to_numpy()
             self.hull_dict = defaultdict(list)
             for cnt, animal_frm in enumerate(mouse_array):
                 animal_frm = np.reshape(animal_frm, (-1, 2))
-                animal_dists = scipy.spatial.distance.cdist(animal_frm, animal_frm, metric='euclidean')
+                animal_dists = self.cdist(array_1=animal_frm, array_2=animal_frm)
                 animal_dists = animal_dists[animal_dists != 0]
                 self.hull_dict['M1_largest_euclidean_distance_hull'].append(np.amax(animal_dists, initial=0) / self.px_per_mm)
                 self.hull_dict['M1_smallest_euclidean_distance_hull'].append(np.amin(animal_dists, initial=self.hull_dict['M1_largest_euclidean_distance_hull'][-1]) / self.px_per_mm)
                 self.hull_dict['M1_mean_euclidean_distance_hull'].append(np.mean(animal_dists) / self.px_per_mm)
                 self.hull_dict['M1_sum_euclidean_distance_hull'].append(np.sum(animal_dists, initial=self.hull_dict['M1_largest_euclidean_distance_hull'][-1]) / self.px_per_mm)
             for k, v in self.hull_dict.items():
                 self.out_data[k] = v
@@ -273,15 +269,15 @@
             self.out_data['Sum_probabilities_deviation_percentile_rank'] = self.out_data['Sum_probabilities_deviation'].rank(pct=True)
             self.out_data['Sum_probabilities_percentile_rank'] = self.out_data['Sum_probabilities_deviation_percentile_rank'].rank(pct=True)
             results = pd.DataFrame(self.count_values_in_range(data=self.out_data.filter(self.mouse_p_headers).values, ranges=np.array([[0.0, 0.1], [0.0, 0.5], [0.0, 0.75]])), columns=['Low_prob_detections_0.1', 'Low_prob_detections_0.5','Low_prob_detections_0.75'])
             self.out_data = pd.concat([self.out_data, results], axis=1)
 
             self.out_data = self.out_data.reset_index(drop=True).fillna(0)
             save_path = os.path.join(self.save_dir, self.video_name + '.' + self.file_type)
-            save_df(self.out_data, self.file_type, save_path)
-            session_time, file_time = session_time + (time.time() - file_start_time), int(time.time() - file_start_time)
-            print('Feature extraction complete for {} ({}/{} (elapsed time: {}s)...'.format(self.video_name, str(file_cnt + 1), str(len(self.files_found)), str(file_time)))
-
-        stdout_success(msg='All features extracted. Results stored in project_folder/csv/features_extracted directory', elapsed_time=str(int(session_time)))
+            write_df(df=self.out_data, file_type=self.file_type, save_path=save_path)
+            video_timer.stop_timer()
+            print(f'Feature extraction complete for {self.video_name} ({file_cnt + 1}/{len(self.files_found)} (elapsed time: {video_timer.elapsed_time_str}s)...')
+        self.timer.stop_timer()
+        stdout_success(msg='All features extracted. Results stored in project_folder/csv/features_extracted directory', elapsed_time=self.timer.elapsed_time_str)
 #
 # test = ExtractFeaturesFrom8bps(config_path='/Users/simon/Desktop/envs/troubleshooting/one_black_animal/project_folder/project_config.ini')
-# test.extract_features()
+# test.run()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/feature_extractor_4bp.py` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/feature_extractor_4bp.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,23 +1,20 @@
 import os
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.read_config_unit_tests import insert_default_headers_for_feature_extraction
-from simba.misc_tools import get_feature_extraction_headers
-from simba.utils.printing import stdout_success
-from simba.drop_bp_cords import get_fn_ext
-from simba.rw_dfs import read_df, save_df
 import pandas as pd
 import numpy as np
 from copy import deepcopy
 import math
 from collections import defaultdict
 import scipy
 from simba.mixins.feature_extraction_mixin import FeatureExtractionMixin
+from simba.mixins.config_reader import ConfigReader
+from simba.utils.printing import stdout_success
+from simba.utils.read_write import read_df, write_df, get_fn_ext
 
-class ExtractFeaturesFrom4bps(FeatureExtractionMixin):
+class ExtractFeaturesFrom4bps(ConfigReader, FeatureExtractionMixin):
     """
     Class for creating a hard-coded set of features from single animals with 4 tracked body-parts
     using pose-estimation. Results are stored in the `project_folder/csv/features_extracted`
     directory of the SimBA project.
 
     Parameters
     ----------
@@ -27,45 +24,46 @@
     Notes
     ----------
     Feature extraction tutorial <https://github.com/sgoldenlab/simba/blob/master/docs/tutorial.md#step-5-extract-features>`__.
 
     Examples
     ----------
     >>> feature_extractor = ExtractFeaturesFrom4bps(config_path='MyProjectConfig')
-    >>> feature_extractor.extract_features()
+    >>> feature_extractor.run()
 
     """
     
     def __init__(self,
                  config_path: str):
 
-        super().__init__(config_path=config_path)
-        self.in_headers = get_feature_extraction_headers(pose='1 animal 4 body-parts')
+        FeatureExtractionMixin.__init__(self, config_path=config_path)
+        ConfigReader.__init__(self, config_path=config_path)
+        self.in_headers = self.get_feature_extraction_headers(pose='1 animal 4 body-parts')
         self.mouse_p_headers = [x for x in self.in_headers if x[-2:] == '_p']
         self.mouse_headers = [x for x in self.in_headers if x[-2:] != '_p']
         print('Extracting features from {} file(s)...'.format(str(len(self.files_found))))
 
-    def extract_features(self):
+    def run(self):
         """
         Method to compute and save features to disk. Results are saved in the `project_folder/csv/features_extracted`
         directory of the SimBA project.
 
         Returns
         -------
         None
         """
         for file_cnt, file_path in enumerate(self.files_found):
             _, self.video_name, _ = get_fn_ext(file_path)
-            video_settings, self.px_per_mm, fps = read_video_info(self.vid_info_df, self.video_name)
+            video_settings, self.px_per_mm, fps = self.read_video_info(video_name=self.video_name)
             roll_windows = []
             for window in self.roll_windows_values:
                 roll_windows.append(int(fps / window))
             self.in_data = read_df(file_path, self.file_type).fillna(0).apply(pd.to_numeric).reset_index(drop=True)
             print('Processing {} ({} frames)...'.format(self.video_name, str(len(self.in_data))))
-            self.in_data = insert_default_headers_for_feature_extraction(df=self.in_data, headers=self.in_headers, pose_config='4 body-parts', filename=file_path)
+            self.in_data = self.insert_default_headers_for_feature_extraction(df=self.in_data, headers=self.in_headers, pose_config='4 body-parts', filename=file_path)
             self.out_data = deepcopy(self.in_data)
             self.in_data_shifted = self.out_data.shift(periods=1).add_suffix('_shifted').fillna(0)
             self.in_data = pd.concat([self.in_data, self.in_data_shifted], axis=1, join='inner').fillna(0).reset_index(drop=True)
             print('Calculating euclidean distances...')
             self.out_data['Mouse_nose_to_tail'] = self.euclidean_distance(self.in_data['Nose_x'].values, self.in_data['Tail_base_x'].values, self.in_data['Nose_y'].values, self.in_data['Tail_base_y'].values, self.px_per_mm)
             self.out_data['Mouse_Ear_distance'] = self.euclidean_distance(self.in_data['Ear_left_x'].values, self.in_data['Ear_right_x'].values, self.in_data['Ear_left_y'].values, self.in_data['Ear_right_y'].values, self.px_per_mm)
             self.out_data['Movement_mouse_nose'] = self.euclidean_distance(self.in_data['Nose_x_shifted'].values, self.in_data['Nose_x'].values, self.in_data['Nose_y_shifted'].values, self.in_data['Nose_y'].values, self.px_per_mm)
@@ -209,21 +207,21 @@
             self.out_data['Sum_probabilities_deviation_percentile_rank'] = self.out_data['Sum_probabilities_deviation'].rank(pct=True)
             self.out_data['Sum_probabilities_percentile_rank'] = self.out_data['Sum_probabilities_deviation_percentile_rank'].rank(pct=True)
             results = pd.DataFrame(self.count_values_in_range(data=self.out_data.filter(self.mouse_p_headers).values, ranges=np.array([[0.0, 0.1], [0.0, 0.5], [0.0, 0.75]])), columns=['Low_prob_detections_0.1', 'Low_prob_detections_0.5','Low_prob_detections_0.75'])
             self.out_data = pd.concat([self.out_data, results], axis=1)
 
             self.out_data = self.out_data.reset_index(drop=True).fillna(0)
             save_path = os.path.join(self.save_dir, self.video_name + '.' + self.file_type)
-            save_df(self.out_data, self.file_type, save_path)
-
-            print('Feature extraction complete for {} ({}/{})...'.format(self.video_name, str(file_cnt + 1), str(len(self.files_found))))
+            write_df(df=self.out_data, file_type=self.file_type, save_path=save_path)
+            print(f'Feature extraction complete for {self.video_name} ({file_cnt + 1}/{len(self.files_found)})...')
 
-        stdout_success(msg='All features extracted. Results are stored in the project_folder/csv/features_extracted directory')
+        self.timer.stop_timer()
+        stdout_success(msg='All features extracted. Results are stored in the project_folder/csv/features_extracted directory', elapsed_time=self.timer.elapsed_time_str)
 
-# test = ExtractFeaturesFrom4bps(config_path='/Users/simon/Desktop/train_model_project/project_folder/project_config.ini')
+# test = ExtractFeaturesFrom4bps(config_path='/Users/simon/Desktop/envs/simba_dev/tests/test_data/mouse_open_field/project_folder/project_config.ini')
 # test.extract_features()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/.idea/features_scripts.iml` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/.idea/features_scripts.iml`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/.idea/inspectionProfiles/Project_Default.xml` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/.idea/inspectionProfiles/Project_Default.xml`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/feature_extractors/.idea/workspace.xml` & `Simba-UW-tf-dev-1.57.6/simba/feature_extractors/.idea/workspace.xml`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/requirements.txt` & `Simba-UW-tf-dev-1.57.6/simba/requirements.txt`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/severity_processor.py` & `Simba-UW-tf-dev-1.57.6/simba/severity_processor.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,32 +1,23 @@
 __author__ = "Simon Nilsson", "JJ Choong"
 
 import numpy as np
 import glob, os
-
 import pandas as pd
-
-from simba.rw_dfs import read_df
-from simba.feature_extractors.unit_tests import read_video_info, read_video_info_csv
-from simba.read_config_unit_tests import (read_config_file,
-                                          read_config_entry,
-                                          read_project_path_and_file_type,
-                                          check_if_filepath_list_is_empty)
 from datetime import datetime
 from numba import jit
-from simba.drop_bp_cords import getBpNames, create_body_part_dictionary
-from simba.enums import ReadConfig, Dtypes, Paths
-from simba.misc_tools import (check_multi_animal_status,
-                              get_fn_ext,
-                              SimbaTimer)
+from simba.utils.read_write import read_video_info_csv, get_fn_ext, read_df
+from simba.utils.checks import check_if_filepath_list_is_empty
+from simba.enums import Paths
 from simba.utils.printing import stdout_success
 from simba.utils.warnings import NoDataFoundWarning
+from simba.mixins.config_reader import ConfigReader
 
 
-class SeverityProcessor(object):
+class SeverityProcessor(ConfigReader):
     """
     Class for analyzing the `severity` of classification frame events based on how much
     the animals are moving. Frames are scored as less or more severe at lower and higher movements.
 
     Parameters
     ----------
     config_path: str
@@ -46,47 +37,36 @@
     >>> processor.save()
     """
 
     def __init__(self,
                  config_path: str,
                  settings: dict):
 
-        self.timer = SimbaTimer()
-        self.timer.start_timer()
-        self.config = read_config_file(ini_path=config_path)
-        self.project_path, self.file_type = read_project_path_and_file_type(config=self.config)
-        log_dir = os.path.join(self.project_path, 'logs')
+        ConfigReader.__init__(self, config_path=config_path)
         self.settings = settings
-        self.in_dir = os.path.join(self.project_path, Paths.MACHINE_RESULTS_DIR.value)
-        self.files_found = glob.glob(self.in_dir + '/*.' + self.file_type)
-        check_if_filepath_list_is_empty(filepaths=self.files_found,
-                                        error_msg=f'SIMBA ERROR: Cannot process severity. {self.in_dir} directory is empty')
+        check_if_filepath_list_is_empty(filepaths=self.machine_results_paths,
+                                        error_msg=f'SIMBA ERROR: Cannot process severity. {self.machine_results_dir} directory is empty')
         save_name = os.path.join(f'severity_{datetime.now().strftime("%Y%m%d%H%M%S")}.csv')
-        self.save_path = os.path.join(log_dir, save_name)
+        self.save_path = os.path.join(self.logs_path, save_name)
         self.results = {}
-        self.x_cols, self.y_cols, self.p_cols = getBpNames(config_path)
-        self.video_info_df = read_video_info_csv(file_path=os.path.join(log_dir, 'video_info.csv'))
-        self.no_animals = read_config_entry(self.config, ReadConfig.GENERAL_SETTINGS.value, ReadConfig.ANIMAL_CNT.value, Dtypes.INT.value)
-        self.multi_animal_status, self.multi_animal_id_lst = check_multi_animal_status(self.config, self.no_animals)
-        self.animal_bp_dict = create_body_part_dictionary(self.multi_animal_status, self.multi_animal_id_lst, self.no_animals, self.x_cols, self.y_cols, self.p_cols, [])
 
     @staticmethod
     @jit(nopython=True)
     def __euclidean_distance(bp_1_x_vals, bp_2_x_vals, bp_1_y_vals, bp_2_y_vals):
         return (np.sqrt((bp_1_x_vals - bp_2_x_vals) ** 2 + (bp_1_y_vals - bp_2_y_vals) ** 2))
 
     def run(self):
-        for file_path in self.files_found:
+        for file_path in self.machine_results_paths:
             _, video_name, _ = get_fn_ext(file_path)
             self.results[video_name] = {}
             df = read_df(file_path=file_path, file_type=self.file_type)
             if self.settings['clf'] not in df.columns:
                 NoDataFoundWarning(msg=f'Skipping file {video_name} - {self.settings["clf"]} data not present in file')
                 continue
-            _, _, fps = read_video_info(vid_info_df=self.video_info_df, video_name=video_name)
+            _, _, fps = self.read_video_info(video_name=video_name)
             for animal_name, animal_bodyparts in self.animal_bp_dict.items():
                 animal_df = df[animal_bodyparts['X_bps'] + animal_bodyparts['Y_bps']]
                 shifted = animal_df.shift(periods=1).fillna(0)
                 movement = pd.DataFrame()
                 for (bp_x, bp_y) in zip(animal_bodyparts['X_bps'], animal_bodyparts['Y_bps']):
                     movement[bp_x.rstrip('_x')] = self.__euclidean_distance(animal_df[bp_x].values, shifted[bp_x].values, animal_df[bp_y].values, shifted[bp_y].values)
                 movement['sum'] = movement.sum(axis=1)
@@ -104,8 +84,14 @@
     def save(self):
         out_df = pd.DataFrame(columns=['VIDEO', 'MEASUREMENT', 'VALUE'])
         for video_name, video_data in self.results.items():
             for grade, grade_data in video_data.items():
                 out_df.loc[len(out_df)] = [video_name, grade, grade_data]
         out_df.to_csv(self.save_path)
         self.timer.stop_timer()
-        stdout_success(msg=f'Severity data saved at {self.save_path}', elapsed_time=self.timer.elapsed_time_str)
+        stdout_success(msg=f'Severity data saved at {self.save_path}', elapsed_time=self.timer.elapsed_time_str)
+
+
+# settings = {'brackets': 10, 'clf': 'Attack', 'animals': ['Simon', 'JJ'], 'time': True, 'frames': False}
+# processor = SeverityProcessor(config_path='/Users/simon/Desktop/envs/troubleshooting/naresh/project_folder/project_config.ini', settings=settings)
+# processor.run()
+# processor.save()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/user_pose_config_creator.py` & `Simba-UW-tf-dev-1.57.6/simba/user_pose_config_creator.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 __author__ = "Simon Nilsson"
 
 import cv2
 import numpy as np
 import imutils
-from simba.read_config_unit_tests import check_file_exist_and_readable
-from simba.drop_bp_cords import createColorListofList
-from simba.enums import Paths
-from simba.utils.errors import InvalidFileTypeError
 import simba
 import os, glob
+from simba.enums import Paths
+from simba.utils.errors import InvalidFileTypeError
+from simba.utils.checks import check_file_exist_and_readable
+from simba.mixins.plotting_mixin import PlottingMixin
 
 
 
-class PoseConfigCreator(object):
+class PoseConfigCreator(PlottingMixin):
 
     """
     Class for creating user-defined pose-estimation settings in SimBA through a GUI interface.
 
     Parameters
     ----------
     pose_name: str
@@ -43,14 +43,16 @@
     def __init__(self,
                  pose_name: str,
                  no_animals: int,
                  img_path: str,
                  bp_list: list,
                  animal_id_int_list: list):
 
+        PlottingMixin.__init__(self)
+
         self.pose_name, self.img_path = pose_name, img_path
         self.bp_list, self.animal_id_int_list = bp_list, animal_id_int_list
         check_file_exist_and_readable(img_path)
         self.no_animals, self.font = no_animals, cv2.FONT_HERSHEY_SIMPLEX
         self.img = cv2.imread(img_path)
         if not isinstance(self.img, (list, tuple, np.ndarray)):
             raise InvalidFileTypeError(msg=f'The chosen image file could not be read as an image ({img_path})')
@@ -66,15 +68,15 @@
         self.spacing_scale = int(self.space_scale / (self.res_scale / self.max_dim))
         cv2.namedWindow('Define pose', cv2.WINDOW_NORMAL)
         self.overlay = self.img.copy()
 
         if self.no_animals > 1:
             for cnt, (bp_name, animal_number_id) in enumerate(zip(self.bp_list, self.animal_id_int_list)):
                 self.bp_list[cnt] = '{}_{}'.format(bp_name, animal_number_id)
-        self.color_lst = createColorListofList(1, len(self.bp_list))[0]
+        self.color_lst = self.create_color_lst_of_lst(1, len(self.bp_list))[0]
 
 
     def launch(self):
         def draw_circle(event, x, y, flags, param):
             if (event == cv2.EVENT_LBUTTONDBLCLK):
                 cv2.circle(self.overlay, (x, int(y - self.side_img.shape[0])), self.circle_scale, self.color_lst[self.bp_cnt], -1)
                 cv2.putText(self.overlay, str(self.bp_cnt + 1), (x + 4, int(y - self.side_img.shape[0])), cv2.FONT_HERSHEY_SIMPLEX, self.font_size, self.color_lst[self.bp_cnt], 2)
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/mixins/.DS_Store` & `Simba-UW-tf-dev-1.57.6/simba/mixins/.DS_Store`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/mixins/pop_up_mixin.py` & `Simba-UW-tf-dev-1.57.6/simba/mixins/pop_up_mixin.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,48 +1,44 @@
 from tkinter import *
-from simba.read_config_unit_tests import (check_int,
-                                          check_str,
-                                          check_float,
-                                          check_if_dir_exists,
-                                          read_project_path_and_file_type)
+from PIL import ImageTk
+import PIL.Image
+from tkinter import messagebox
+import os
+from simba.pose_importers import trk_importer
+
+
+from simba.utils.checks import (check_int,
+                                check_str,
+                                check_float,
+                                check_if_dir_exists)
 from simba.pose_importers.read_DANNCE_mat import import_DANNCE_file, import_DANNCE_folder
 from simba.pose_importers.import_mars import MarsImporter
 from simba.pose_importers.dlc_multi_animal_importer import MADLC_Importer
 from simba.pose_importers.sleap_importer_csv import SLEAPImporterCSV
 from simba.pose_importers.sleap_importer_h5 import SLEAPImporterH5
 from simba.pose_importers.sleap_importer_slp import SLEAPImporterSLP
-from simba.pose_importers.import_trk import *
-from tkinter import messagebox
-from simba.drop_bp_cords import (create_body_part_dictionary,
-                                 getBpNames)
-from simba.pose_importers.dlc_importer_csv import (import_multiple_dlc_tracking_csv_file,
-                                                   import_single_dlc_tracking_csv_file)
-from simba.enums import Formats, ReadConfig, Options
-from simba.misc_tools import (check_multi_animal_status,
-                              find_core_cnt,
-                              get_color_dict,
-                              get_named_colors,
-                              copy_single_video_to_project,
-                              copy_multiple_videos_to_project,
-                              )
-from simba.train_model_functions import get_all_clf_names
+
+
+from simba.pose_importers.dlc_importer_csv import (import_multiple_dlc_tracking_csv_file, import_single_dlc_tracking_csv_file)
+from simba.enums import ReadConfig, Options
+from simba.utils.read_write import find_core_cnt, copy_single_video_to_project, copy_multiple_videos_to_project, read_config_file, read_config_entry
 from simba.tkinter_functions import (hxtScrollbar,
                                      DropDownMenu,
                                      Entry_Box,
                                      FileSelect,
                                      FolderSelect)
+from simba.utils.checks import check_file_exist_and_readable
 from simba.utils.errors import CountError
-from simba.utils.lookups import get_icons_paths
-from PIL import ImageTk
-import PIL.Image
-from simba.enums import Formats
-import webbrowser
-import simba
+from simba.utils.lookups import (get_icons_paths,
+                                 get_color_dict,
+                                 get_named_colors)
 
 
+from simba.enums import Formats
+
 class PopUpMixin(object):
     def __init__(self,
                  title: str,
                  config_path: str or None=None,
                  size: tuple=(400,400)):
 
         self.main_frm = Toplevel()
@@ -60,32 +56,14 @@
         self.colors = get_named_colors()
         self.colors_dict = get_color_dict()
         self.cpu_cnt, _ = find_core_cnt()
         self.menu_icons = get_icons_paths()
         for k in self.menu_icons.keys():
             self.menu_icons[k]['img'] = ImageTk.PhotoImage(image=PIL.Image.open(os.path.join(os.path.dirname(__file__), self.menu_icons[k]['icon_path'])))
 
-        if config_path:
-            self.config_path = config_path
-            self.config = read_config_file(ini_path=config_path)
-            self.project_path, self.file_type = read_project_path_and_file_type(config=self.config)
-            self.project_animal_cnt = read_config_entry(config=self.config, section=ReadConfig.GENERAL_SETTINGS.value, option=ReadConfig.ANIMAL_CNT.value, data_type='int')
-            self.multi_animal_status, self.multi_animal_id_lst = check_multi_animal_status(self.config, self.project_animal_cnt)
-            self.x_cols, self.y_cols, self.pcols = getBpNames(config_path)
-            self.animal_bp_dict = create_body_part_dictionary(self.multi_animal_status, list(self.multi_animal_id_lst), self.project_animal_cnt, self.x_cols, self.y_cols, [], [])
-            self.target_cnt = read_config_entry(config=self.config, section=ReadConfig.SML_SETTINGS.value, option=ReadConfig.TARGET_CNT.value, data_type='int')
-            self.clf_names = get_all_clf_names(config=self.config, target_cnt=self.target_cnt)
-            self.videos_dir = os.path.join(self.project_path, 'videos')
-            self.bp_names = []
-            for animal_name, coords in self.animal_bp_dict.items():
-                for bp in coords['X_bps']:
-                    self.bp_names.append(bp.rstrip('_x'))
-
-
-
     def create_clf_checkboxes(self, main_frm: Frame, clfs: list):
         self.choose_clf_frm = LabelFrame(self.main_frm, text='SELECT CLASSIFIER ANNOTATIONS', font=Formats.LABELFRAME_HEADER_FORMAT.value)
         self.clf_selections = {}
         for clf_cnt, clf in enumerate(clfs):
             self.clf_selections[clf] = BooleanVar(value=False)
             self.calculate_distance_moved_cb = Checkbutton(self.choose_clf_frm, text=clf, variable=self.clf_selections[clf])
             self.calculate_distance_moved_cb.grid(row=clf_cnt, column=0, sticky=NW)
@@ -138,17 +116,17 @@
         self.body_part_frm.grid(row=self.children_cnt_main(), sticky=NW)
 
     def update_body_parts(self):
         for child in self.body_part_frm.winfo_children():
             child.destroy()
         for animal_cnt in range(int(self.animal_cnt_dropdown.getChoices())):
             animal_name = list(self.animal_bp_dict.keys())[animal_cnt]
-            self.body_parts_dropdown_dict[animal_name] = DropDownMenu(self.body_part_frm, f'{animal_name} body-part:', self.bp_names, '25')
+            self.body_parts_dropdown_dict[animal_name] = DropDownMenu(self.body_part_frm, f'{animal_name} body-part:', self.body_parts_lst, '25')
             self.body_parts_dropdown_dict[animal_name].grid(row=animal_cnt, column=1, sticky=NW)
-            self.body_parts_dropdown_dict[animal_name].setChoices(self.bp_names[animal_cnt])
+            self.body_parts_dropdown_dict[animal_name].setChoices(self.body_parts_lst[animal_cnt])
 
     def create_time_bin_entry(self):
         if hasattr(self, 'time_bin_frm'):
             self.time_bin_frm.destroy()
         self.time_bin_frm = LabelFrame(self.main_frm, text="TIME BIN", font=Formats.LABELFRAME_HEADER_FORMAT.value)
         self.time_bin_entrybox = Entry_Box(self.time_bin_frm, 'Time-bin size (s): ', '12', validation='numeric')
         self.time_bin_entrybox.grid(row=0, column=0, sticky=NW)
@@ -254,16 +232,16 @@
         check_int(name='NUMBER OF ANIMALS', value=animal_cnt, min_value=0)
         if hasattr(self, 'animal_names_frm'):
             self.animal_names_frm.destroy()
         self.animal_names_frm = Frame(self.animal_settings_frm, pady=5, padx=5)
         self.animal_name_entry_boxes = {}
         for i in range(int(animal_cnt)):
             self.animal_name_entry_boxes[i+1] = Entry_Box(self.animal_names_frm, f'Animal {str(i+1)} name: ', '25')
-            if i <= len(self.multi_animal_id_lst)-1:
-                self.animal_name_entry_boxes[i+1].entry_set(self.multi_animal_id_lst[i])
+            if i <= len(self.multi_animal_id_list)-1:
+                self.animal_name_entry_boxes[i+1].entry_set(self.multi_animal_id_list[i])
             self.animal_name_entry_boxes[i+1].grid(row=i, column=0, sticky=NW)
 
         self.animal_names_frm.grid(row=1, column=0, sticky=NW)
 
     def enable_entrybox_from_checkbox(self,
                                       check_box_var: BooleanVar,
                                       entry_boxes: [Entry_Box],
@@ -309,26 +287,26 @@
 
             animal_ids = []
             for animal_cnt, animal_entry_box in animal_names.items():
                 check_str(name=f'ANIMAL {str(animal_cnt)} NAME', value=animal_entry_box.entry_get, allow_blank=False)
                 animal_ids.append(animal_entry_box.entry_get)
 
 
-            self.config = read_config_file(ini_path=self.config_path)
+            self.config = read_config_file(config_path=self.config_path)
             self.config.set(ReadConfig.MULTI_ANIMAL_ID_SETTING.value, ReadConfig.MULTI_ANIMAL_IDS.value, ",".join(animal_ids))
             self.update_config()
 
             if data_type == 'H5 (multi-animal DLC)':
                 dlc_multi_animal_importer = MADLC_Importer(config_path=self.config_path,
                                                            data_folder=data_path,
                                                            file_type=tracking_data_type,
                                                            id_lst=animal_ids,
                                                            interpolation_settings=interpolation,
                                                            smoothing_settings=smooth_settings)
-                dlc_multi_animal_importer.import_data()
+                dlc_multi_animal_importer.run()
 
             if data_type == 'SLP (SLEAP)':
                 sleap_importer = SLEAPImporterSLP(project_path=self.config_path,
                                                   data_folder=data_path,
                                                   actor_IDs=animal_ids,
                                                   interpolation_settings=interpolation,
                                                   smoothing_settings=smooth_settings)
@@ -338,25 +316,25 @@
                 sleap_importer.save_df()
                 sleap_importer.perform_interpolation()
                 sleap_importer.perform_smothing()
                 print('All SLEAP imports complete.')
 
             if data_type == 'TRK (multi-animal APT)':
                 try:
-                    import_trk(self.config_path, data_path, animal_ids, interpolation, smooth_settings)
+                    trk_importer(self.config_path, data_path, animal_ids, interpolation, smooth_settings)
                 except Exception as e:
                     messagebox.showerror("Error", str(e))
 
             if data_type == 'CSV (SLEAP)':
                 sleap_csv_importer = SLEAPImporterCSV(config_path=self.config_path,
                                                       data_folder=data_path,
                                                       actor_IDs=animal_ids,
                                                       interpolation_settings=interpolation,
                                                       smoothing_settings=smooth_settings)
-                sleap_csv_importer.initate_import_slp()
+                sleap_csv_importer.run()
 
             if data_type == 'H5 (SLEAP)':
                 sleap_h5_importer = SLEAPImporterH5(config_path=self.config_path,
                                                     data_folder=data_path,
                                                     actor_IDs=animal_ids,
                                                     interpolation_settings=interpolation,
                                                     smoothing_settings=smooth_settings)
@@ -515,17 +493,16 @@
 
         self.import_tracking_frm = LabelFrame(parent_frm, text='IMPORT TRACKING DATA', font=Formats.LABELFRAME_HEADER_FORMAT.value, fg='black')
         if not hasattr(self, 'config_path'):
             self.instructions_lbl = Label(self.import_tracking_frm, text='Please CREATE PROJECT CONFIG before importing tracking data \n')
             self.import_tracking_frm.grid(row=0, column=0, sticky=NW)
             self.instructions_lbl.grid(row=0, column=0, sticky=NW)
         else:
-            self.config = read_config_file(ini_path=self.config_path)
+            self.config = read_config_file(config_path=self.config_path)
             self.project_animal_cnt = read_config_entry(config=self.config, section=ReadConfig.GENERAL_SETTINGS.value, option=ReadConfig.ANIMAL_CNT.value, data_type='int')
-            _, self.multi_animal_id_lst = check_multi_animal_status(self.config, self.project_animal_cnt)
             self.data_type_dropdown = DropDownMenu(self.import_tracking_frm,'DATA TYPE:', Options.IMPORT_TYPE_OPTIONS.value, labelwidth=25, com=import_menu)
             self.data_type_dropdown.setChoices(Options.IMPORT_TYPE_OPTIONS.value[0])
             import_menu(data_type_choice=Options.IMPORT_TYPE_OPTIONS.value[0])
             self.import_tracking_frm.grid(row=idx_row, column=idx_column, sticky=NW)
             self.data_type_dropdown.grid(row=0, column=0, sticky=NW)
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/mixins/unsupervised_mixin.py` & `Simba-UW-tf-dev-1.57.6/simba/mixins/unsupervised_mixin.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,9 @@
 import os, glob
 import pickle
-from simba.misc_tools import SimbaTimer
-from simba.read_config_unit_tests import check_float
 import simba
 from simba.enums import Paths
 from sklearn.feature_selection import VarianceThreshold
 from simba.unsupervised.enums import Unsupervised
 import pandas as pd
 from datetime import datetime
 import numpy as np
@@ -15,22 +13,23 @@
 from simba.utils.errors import (InvalidInputError,
                                 NoDataError,
                                 NoFilesFoundError,
                                 InvalidFileTypeError,
                                 MissingColumnsError,
                                 IntegerError,
                                 DirectoryNotEmptyError)
+from simba.utils.checks import check_float
+from simba.utils.printing import SimbaTimer
 
 
 class UnsupervisedMixin(object):
     def __init__(self):
 
         self.datetime = datetime.now().strftime('%Y%m%d%H%M%S')
-        self.timer = SimbaTimer()
-        self.timer.start_timer()
+        self.timer = SimbaTimer(start=True)
         model_names_dir = os.path.join(os.path.dirname(simba.__file__), Paths.UNSUPERVISED_MODEL_NAMES.value)
         self.model_names = list(pd.read_parquet(model_names_dir)[Unsupervised.NAMES.value])
 
     def read_pickle(self,
                     data_path: str) -> dict:
 
         if os.path.isdir(data_path):
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/machine_model_settings_pop_up.py` & `Simba-UW-tf-dev-1.57.6/simba/machine_model_settings_pop_up.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,58 +1,48 @@
 __author__ = "Simon Nilsson"
 
-
-from simba.read_config_unit_tests import (read_config_entry,
-                                          read_config_file,
-                                          check_int,
-                                          check_float,
-                                          check_file_exist_and_readable)
+import pandas as pd
+import os, ast
+import webbrowser
+from tkinter import *
 from simba.tkinter_functions import (hxtScrollbar,
                                      DropDownMenu,
                                      FileSelect,
                                      Entry_Box)
-import pandas as pd
-import os, ast
-from simba.enums import ReadConfig, Options, Formats, Keys, Links
-from simba.train_model_functions import get_all_clf_names
-from simba.misc_tools import (find_files_of_filetypes_in_directory,
-                              get_fn_ext)
+from simba.enums import Options, Formats, Keys, Links
+from simba.utils.read_write import find_files_of_filetypes_in_directory, get_fn_ext
 from simba.utils.printing import stdout_success, stdout_trash, stdout_warning
 from simba.tkinter_functions import CreateLabelFrameWithIcon
 from simba.utils.errors import InvalidHyperparametersFileError
+from simba.utils.checks import (check_int, check_float, check_file_exist_and_readable)
 from simba.mixins.pop_up_mixin import PopUpMixin
-import webbrowser
-from tkinter import *
-from tkinter import ttk
+from simba.mixins.config_reader import ConfigReader
 
-class MachineModelSettingsPopUp(PopUpMixin):
+class MachineModelSettingsPopUp(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str):
 
+        ConfigReader.__init__(self, config_path=config_path)
         main = Toplevel()
         main.minsize(450, 700)
         main.wm_title("MACHINE MODEL SETTINGS")
         main.lift()
         main = Canvas(hxtScrollbar(main))
         main.pack(fill="both", expand=True)
 
-        self.config, self.config_path = read_config_file(ini_path=config_path), config_path
-        self.project_path = read_config_entry(self.config, ReadConfig.GENERAL_SETTINGS.value, ReadConfig.PROJECT_PATH.value, data_type=ReadConfig.FOLDER_PATH.value)
-        self.configs_path = os.path.join(self.project_path, 'configs')
-        if not os.path.exists(self.configs_path): os.makedirs(self.configs_path)
+        if not os.path.exists(self.configs_meta_dir): os.makedirs(self.configs_meta_dir)
         self.clf_options = Options.CLF_MODELS.value
         self.max_features_options = Options.CLF_MAX_FEATURES.value
         self.criterion_options = Options.CLF_CRITERION.value
         self.under_sample_options = Options.UNDERSAMPLE_OPTIONS.value
         self.over_sample_options = Options.OVERSAMPLE_OPTIONS.value
         self.class_weighing_options = Options.CLASS_WEIGHT_OPTIONS.value
         self.train_test_sizes_options = Options.CLF_TEST_SIZE_OPTIONS.value
         self.class_weights_options = list(range(1, 11, 1))
-        self.clf_cnt = read_config_entry(self.config, ReadConfig.SML_SETTINGS.value, ReadConfig.TARGET_CNT.value, 'int')
-        self.clf_names = list(get_all_clf_names(config=self.config, target_cnt=self.clf_cnt))
+        self.clf_names = list(self.get_all_clf_names())
         load_meta_data_frm = CreateLabelFrameWithIcon(parent=main, header='LOAD META-DATA', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.TRAIN_ML_MODEL.value)
         self.select_config_file = FileSelect(load_meta_data_frm, 'CONFIG PATH:')
         load_config_btn = Button(load_meta_data_frm, text='LOAD', fg='blue', command= lambda: self.load_config())
         label_link = Label(load_meta_data_frm,text='[MODEL SETTINGS TUTORIAL]', fg='blue')
         label_link.bind('<Button-1>', lambda e: webbrowser.open_new('https://github.com/sgoldenlab/simba/blob/master/docs/tutorial.md#step-7-train-machine-model'))
 
         machine_model_frm = LabelFrame(main, text='MACHINE MODEL ALGORITHM', font=Formats.LABELFRAME_HEADER_FORMAT.value)
@@ -260,16 +250,16 @@
         self.learning_curve_data_split = 0
         if self.learning_curve:
             self.learning_curve_k_split = self.learning_curve_k_splits_entry_box.entry_get
             self.learning_curve_data_split = self.learning_curve_data_splits_entry_box.entry_get
 
     def find_meta_file_cnt(self):
         self.meta_file_cnt = 0
-        self.total_meta_files = find_files_of_filetypes_in_directory(directory=self.configs_path, extensions=['.csv'], raise_warning=False)
-        for f in os.listdir(self.configs_path):
+        self.total_meta_files = find_files_of_filetypes_in_directory(directory=self.configs_meta_dir, extensions=['.csv'], raise_warning=False)
+        for f in os.listdir(self.configs_meta_dir):
             if f.__contains__('_meta') and f.__contains__(str(self.behavior_name)):
                 self.meta_file_cnt += 1
 
     def save_global(self):
         self.__checks()
         self.__get_variables()
         self.config.set('create ensemble settings', 'model_to_run', self.algorithm)
@@ -342,17 +332,17 @@
                 'class_weights': self.class_weight_method,
                 'class_custom_weights': str(self.class_custom_weights)}
 
         meta_df = pd.DataFrame(meta, index=[0])
         meta_df.insert(0, 'Classifier_name', self.behavior_name)
         self.find_meta_file_cnt()
         file_name = '{}_meta_{}.csv'.format(self.behavior_name, str(self.meta_file_cnt))
-        save_path = os.path.join(self.configs_path, file_name)
+        save_path = os.path.join(self.configs_meta_dir, file_name)
         meta_df.to_csv(save_path, index=FALSE)
-        stdout_success(msg=f'Hyper-parameter config ({str(len(self.total_meta_files)+1)} saved in project_folder/configs folder.')
+        stdout_success(msg=f'Hyper-parameter config saved ({str(len(self.total_meta_files)+1)} saved in project_folder/configs folder).')
 
     def clear_cache(self):
         self.behavior_name = self.behavior_name_dropdown.getChoices()
         self.find_meta_file_cnt()
         for file_path in self.total_meta_files:
             os.remove(os.path.join(file_path))
             print('Deleted hyperparameters config {} ...'.format(file_path))
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/remove_keypoints_in_pose.py` & `Simba-UW-tf-dev-1.57.6/simba/remove_keypoints_in_pose.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 import glob, os
 import pandas as pd
 from datetime import datetime
 import warnings
 from tables import NaturalNameWarning
-from simba.misc_tools import SimbaTimer
-from simba.utils.printing import stdout_success
-from simba.read_config_unit_tests import check_if_filepath_list_is_empty
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.utils.checks import check_if_filepath_list_is_empty
 from simba.utils.errors import NotDirectoryError, BodypartColumnNotFoundError, InvalidFileTypeError
 warnings.filterwarnings('ignore', category=NaturalNameWarning)
 
 class KeypointRemover(object):
     """
     Class for removing pose-estimated keypoints from data in CSV or H5 format.
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/third_party_label_appenders/deepethogram_importer.py` & `Simba-UW-tf-dev-1.57.6/simba/third_party_label_appenders/deepethogram_importer.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,19 +1,16 @@
 __author__ = "Simon Nilsson"
 
-from simba.rw_dfs import read_df, save_df
+
 import os, glob
 from copy import deepcopy
 import pandas as pd
-from simba.misc_tools import (get_fn_ext,
-                              )
+from simba.utils.read_write import read_df, write_df, get_fn_ext
 from simba.utils.printing import stdout_success
-from simba.read_config_unit_tests import (check_if_filepath_list_is_empty,
-                                          check_if_dir_exists)
-from simba.feature_extractors.unit_tests import read_video_info
+from simba.utils.checks import check_if_filepath_list_is_empty,check_if_dir_exists
 from simba.mixins.config_reader import ConfigReader
 
 class DeepEthogramImporter(ConfigReader):
 
     """
     Class for appending DeepEthogram optical flow annotations onto featurized pose-estimation data.
 
@@ -72,15 +69,15 @@
                 raise FileNotFoundError()
 
     def import_deepethogram(self):
         for cnt, (k, v) in enumerate(self.matches_dict.items()):
             _, video_name, _ = get_fn_ext(filepath=v)
             self.annotations_df = read_df(file_path=k, file_type=self.file_type).reset_index(drop=True)
             self.features_df = read_df(file_path=v, file_type=self.file_type).reset_index(drop=True)
-            _, _, self.fps = read_video_info(self.video_info_df, video_name)
+            _, _, self.fps = self.read_video_info(video_name=video_name)
             for clf_name in self.clf_names:
                 if clf_name not in self.annotations_df.columns:
                     print('SIMBA ERROR: No annotations for behavior {} found in DeepEthogram annotation file for video {}'
                           'Exclude {} from your SimBA project or add DeepEthogram annotations for {} for video {}.'.format(clf_name, video_name, clf_name, clf_name, video_name))
                     raise ValueError()
             if len(self.annotations_df) > len(self.features_df):
                 print(f'SIMBA WARNING: The DEEPETHOGRAM annotations for video {video_name} contain data for {str(len(self.annotations_df))} frames. The pose-estimation features for the same video contain data for {str(len(self.features_df))} frames. '
@@ -94,15 +91,15 @@
                 self.annotations_df = self.annotations_df.append(padding, ignore_index=True)
 
             self.out_data = deepcopy(self.features_df)
             for clf_name in self.clf_names:
                 self.out_data[clf_name] = self.annotations_df[clf_name]
 
             save_path = os.path.join(self.targets_folder, video_name + '.' + self.file_type)
-            save_df(df=self.out_data, file_type=self.file_type, save_path=save_path)
+            write_df(df=self.out_data, file_type=self.file_type, save_path=save_path)
             print('DeepEthogram annotation for video {} saved...'.format(video_name))
 
         stdout_success(msg=f'Annotations for {str(len(list(self.clf_names)))} behaviors added to {len(self.matches_dict.keys())} videos and saved in the project_folder/csv/targets_inserted directory.')
 
 # test = DeepEthogramImporter(deep_ethogram_dir='/Users/simon/Desktop/troubleshooting/deepethnogram/deepethnogram',
 #                             config_path='/Users/simon/Desktop/troubleshooting/deepethnogram/project_folder/project_config.ini')
 # test.import_deepethogram()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/third_party_label_appenders/BORIS_appender.py` & `Simba-UW-tf-dev-1.57.6/simba/third_party_label_appenders/BORIS_appender.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,21 +1,20 @@
 __author__ = "Simon Nilsson"
 
-from simba.read_config_unit_tests import (check_if_dir_exists,
-                                          check_if_filepath_list_is_empty)
-from simba.mixins.config_reader import ConfigReader
+import pandas as pd
+from copy import deepcopy
 import os, glob
-from simba.rw_dfs import read_df, save_df
-from simba.misc_tools import (get_fn_ext)
+from simba.mixins.config_reader import ConfigReader
+from simba.utils.read_write import get_fn_ext, read_df, write_df
+from simba.utils.checks import check_if_dir_exists, check_if_filepath_list_is_empty
 from simba.utils.printing import stdout_success
 from simba.utils.errors import (ThirdPartyAnnotationOverlapError,
                                 ThirdPartyAnnotationEventCountError)
-from simba.utils.warnings import (ThirdPartyAnnotationsOutsidePoseEstimationDataWarning, ThirdPartyAnnotationsInvalidFileFormatWarning)
-import pandas as pd
-from copy import deepcopy
+from simba.utils.warnings import (ThirdPartyAnnotationsOutsidePoseEstimationDataWarning,
+                                  ThirdPartyAnnotationsInvalidFileFormatWarning)
 
 class BorisAppender(ConfigReader):
 
     """
     Class for appending BORIS human annotations onto featurized pose-estimation data.
 
     Parameters
@@ -142,15 +141,15 @@
                 self.out_df.loc[annotations_idx, clf] = 1
             self.__save_boris_annotations()
         self.timer.stop_timer()
         stdout_success(msg='BORIS annotations appended to dataset and saved in project_folder/csv/targets_inserted directory', elapsed_time=self.timer.elapsed_time_str)
 
     def __save_boris_annotations(self):
         save_path = os.path.join(self.targets_folder, self.video_name + '.' + self.file_type)
-        save_df(self.out_df, self.file_type, save_path)
+        write_df(self.out_df, self.file_type, save_path)
         print('Saved BORIS annotations for video {}...'.format(self.video_name))
 
 # test = BorisAppender(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini',
 #                      boris_folder='/Users/simon/Downloads/FIXED')
 # test.create_boris_master_file()
 # test.run()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/third_party_label_appenders/observer_importer.py` & `Simba-UW-tf-dev-1.57.6/simba/third_party_label_appenders/observer_importer.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,25 +1,23 @@
-from simba.mixins.config_reader import ConfigReader
-from simba.read_config_unit_tests import check_if_filepath_list_is_empty
 import os, glob
 import numpy as np
-from simba.misc_tools import (get_fn_ext,
-                              SimbaTimer,
-                              )
-from simba.utils.printing import stdout_success
-from simba.rw_dfs import read_df, save_df
+import pandas as pd
+from copy import deepcopy
+
+from simba.mixins.config_reader import ConfigReader
+from simba.utils.checks import check_if_filepath_list_is_empty
+from simba.utils.read_write import get_fn_ext, read_df, write_df
+from simba.utils.printing import stdout_success, SimbaTimer
 from simba.utils.errors import (ColumnNotFoundError,
                                 AnnotationFileNotFoundError,
                                 ThirdPartyAnnotationEventCountError,
                                 ThirdPartyAnnotationOverlapError)
 from simba.utils.warnings import (ThirdPartyAnnotationsClfMissingWarning,
                                   ThirdPartyAnnotationsOutsidePoseEstimationDataWarning)
-from simba.feature_extractors.unit_tests import read_video_info
-import pandas as pd
-from copy import deepcopy
+
 
 TIME_FIELD = 'Time_Relative_hmsf'
 VIDEO_NAME_FIELD = 'Observation'
 BEHAVIOR_FIELD = 'Behavior'
 EVENT_TYPE_FIELD = 'Event_Type'
 POINT_EVENT = 'Point'
 START = 'State start'
@@ -92,15 +90,15 @@
             for video_name in df[VIDEO_NAME_FIELD].unique():
                 video_df = df[df[VIDEO_NAME_FIELD] == video_name].reset_index(drop=True)
                 self.__check_column_names(df=video_df, file_path=file_path)
                 video_df = video_df[video_df[EVENT_TYPE_FIELD] != POINT_EVENT]
                 video_df[TIME_FIELD] = self.check_timestamps(timestamps=list(video_df[TIME_FIELD].astype(str)))
                 video_df[TIME_FIELD] = pd.to_timedelta(video_df[TIME_FIELD])
                 video_df[EVENT_TYPE_FIELD] = video_df[EVENT_TYPE_FIELD].replace({START: 'START', STOP: 'STOP'})
-                _, _, fps = read_video_info(vid_info_df=self.video_info_df, video_name=video_name)
+                _, _, fps = self.read_video_info(video_name=video_name)
                 video_df['FRAME'] = video_df[TIME_FIELD].dt.total_seconds() * fps
                 video_df['FRAME'] = video_df['FRAME'].apply(np.floor)
                 video_df = video_df.drop([TIME_FIELD, VIDEO_NAME_FIELD], axis=1)
                 if video_name in list(self.annotation.keys()):
                     self.annotation[video_name] = pd.concat([self.annotation[video_name], video_df], axis=0).reset_index(drop=True)
                 else:
                     self.annotation[video_name] = video_df
@@ -147,15 +145,15 @@
             self.__save(df=output_df, path= os.path.join(self.targets_folder, file_name + '.' + self.file_type))
             video_timer.stop_timer()
             print(f'Imported Noldus Observer annotations for video {file_name} (elapsed time {video_timer.elapsed_time_str}s)...')
         self.timer.stop_timer()
         stdout_success(msg=f'Imported annotations saved in project/folder/csv/targets_inserted directory', elapsed_time=self.timer.elapsed_time_str)
 
     def __save(self, df: pd.DataFrame, path: str):
-        save_df(df=df, file_type=self.file_type, save_path=path)
+        write_df(df=df, file_type=self.file_type, save_path=path)
 
 # test = NoldusObserverImporter(config_path='/Users/simon/Desktop/envs/troubleshooting/Gosia/project_folder/project_config.ini',
 #                               data_dir='/Users/simon/Desktop/envs/troubleshooting/Gosia/source/behaviours/Exp_38')
 # test.run()
 
 
 # for k, v in test.annotation.items():
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/third_party_label_appenders/tools.py` & `Simba-UW-tf-dev-1.57.6/simba/third_party_label_appenders/tools.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 import pandas as pd
 import numpy as np
-from simba.misc_tools import get_fn_ext, detect_bouts
-from simba.feature_extractors.unit_tests import read_video_info, read_video_info_csv
+from simba.utils.data import detect_bouts
+from simba.utils.read_write import get_fn_ext, read_video_info
 from simba.enums import Methods
 from simba.utils.warnings import ThirdPartyAnnotationsInvalidFileFormatWarning
 from simba.utils.errors import (InvalidFileTypeError, ColumnNotFoundError)
 
 def observer_timestamp_corrector(timestamps=list):
     corrected_ts = []
     for timestamp in timestamps:
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/third_party_label_appenders/third_party_appender.py` & `Simba-UW-tf-dev-1.57.6/simba/third_party_label_appenders/third_party_appender.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,16 @@
 import pandas as pd
 
+
+from simba.enums import Methods
+import os, glob
+from copy import deepcopy
 from simba.mixins.config_reader import ConfigReader
-from simba.read_config_unit_tests import (check_if_dir_exists,
-                                          check_if_filepath_list_is_empty)
-from simba.rw_dfs import read_df, save_df
-from simba.misc_tools import (get_fn_ext, create_logger)
+from simba.utils.read_write import read_df, write_df, get_fn_ext
+from simba.utils.checks import check_if_filepath_list_is_empty, check_if_dir_exists
 from simba.utils.printing import stdout_success
 from simba.third_party_label_appenders.tools import (read_boris_annotation_files,
                                                      read_deepethogram_files,
                                                      read_ethovision_files,
                                                      read_observer_files,
                                                      read_solomon_files,
                                                      read_bento_files,
@@ -23,17 +25,15 @@
 from simba.utils.errors import (ThirdPartyAnnotationFileNotFoundError,
                                 ThirdPartyAnnotationsAdditionalClfError,
                                 ThirdPartyAnnotationsMissingAnnotationsError,
                                 ThirdPartyAnnotationEventCountError,
                                 ThirdPartyAnnotationOverlapError,
                                 ThirdPartyAnnotationsOutsidePoseEstimationDataError)
 
-from simba.enums import Methods
-import os, glob
-from copy import deepcopy
+
 
 BORIS = 'BORIS'
 DEEPETHOGRAM = 'DEEPETHOGRAM'
 ETHOVISION = 'ETHOVISION'
 OBSERVER = 'OBSERVER'
 SOLOMON = 'SOLOMON'
 BENTO = 'BENTO'
@@ -98,15 +98,15 @@
                  settings: dict):
 
         super().__init__(config_path=config_path)
         check_if_dir_exists(in_dir=data_dir)
         self.data_dir, self.app, self.settings = data_dir, app, settings
         self.err_settings = self.settings['errors']
         if self.settings['log']:
-            create_logger(path=os.path.join(self.logs_path, f'BORIS_append_{self.datetime}.log'))
+            self.create_logger(path=os.path.join(self.logs_path, f'BORIS_append_{self.datetime}.log'))
         self.data_file_paths = glob.glob(self.data_dir + f'/*.{self.settings["file_format"]}')
         self.data_file_paths = [x for x in self.data_file_paths if '~$' not in x]
         check_if_filepath_list_is_empty(filepaths=self.data_file_paths,
                                         error_msg=f'SIMBA ERROR: ZERO {app} {self.settings["file_format"]} files found in {data_dir} directory')
         check_if_filepath_list_is_empty(filepaths=self.feature_file_paths,
                                         error_msg='SIMBA ERROR: ZERO files found in the project_folder/csv/features_extracted directory')
         print(f'Processing {str(len(self.feature_file_paths))} {app} file(s)...')
@@ -226,15 +226,15 @@
                                                                                   first_error_frm=idx_diff[0],
                                                                                   ambiguous_cnt=len(idx_diff))
 
                 annot_idx = [x for x in annot_idx if x not in idx_diff]
                 out_df[clf] = 0
                 out_df.loc[annot_idx, clf] = 1
             save_path = os.path.join(self.targets_folder, self.video_name + '.' + self.file_type)
-            save_df(out_df, self.file_type, save_path)
+            write_df(out_df, self.file_type, save_path)
             print(f'Saved {self.app} annotations for video {self.video_name}...')
         self.timer.stop_timer()
         stdout_success(msg=f'{self.app} annotations appended to dataset and saved in project_folder/csv/targets_inserted directory', elapsed_time=self.timer.elapsed_time_str)
 
 # settings = {'log': True,  'file_format': 'xlsx', 'errors': {'INVALID annotations file data format': 'WARNING',
 #                                                            'ADDITIONAL third-party behavior detected': 'NONE',
 #                                                            'Annotations EVENT COUNT conflict': 'WARNING',
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/third_party_label_appenders/ethovision_import.py` & `Simba-UW-tf-dev-1.57.6/simba/third_party_label_appenders/ethovision_import.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,22 +1,17 @@
 __author__ = "Simon Nilsson", "JJ Choong"
 
 import os, glob
 import numpy as np
 import pandas as pd
-from simba.rw_dfs import read_df, save_df
-from simba.read_config_unit_tests import (read_config_file,
-                                          check_if_filepath_list_is_empty,
-                                          check_that_column_exist)
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.misc_tools import get_fn_ext
+from simba.utils.read_write import get_fn_ext, read_df, write_df, read_config_file
+from simba.utils.checks import check_if_filepath_list_is_empty, check_that_column_exist
 from simba.utils.printing import stdout_success
 from simba.mixins.config_reader import ConfigReader
 
-
 class ImportEthovision(ConfigReader):
     """
     Class for appending ETHOVISION human annotations onto featurized pose-estimation data.
     Results are saved within the project_folder/csv/targets_inserted directory of
     the SimBA project (as parquets' or CSVs).
 
     Parameters
@@ -69,15 +64,15 @@
                     raise ValueError(f'SIMBA ERROR: "Video file" row does not have a value in the sheet named {manual_scoring_sheet_name} in file {file_path}')
             except:
                 pass
             dir_name, self.video_name, ext = get_fn_ext(video_path)
             self.processed_videos.append(video_path)
             self.features_file_path = os.path.join(self.features_dir, self.video_name + '.' + self.file_type)
             print('Processing annotations for video ' + str(self.video_name) + '...')
-            _, _, fps = read_video_info(self.video_info_df, str(self.video_name))
+            _, _, fps = self.read_video_info(video_name=str(self.video_name))
             header_lines_n = int(ethovision_df.loc['Number of header lines:'].values[0]) - 2
             ethovision_df = ethovision_df.iloc[header_lines_n:].reset_index(drop=True)
             ethovision_df.columns = list(ethovision_df.iloc[0])
             ethovision_df = ethovision_df.iloc[2:].reset_index(drop=True)
             self.clf_dict = {}
             check_that_column_exist(df=ethovision_df,column_name='Behavior',file_name=file_path)
             check_that_column_exist(df=ethovision_df, column_name='Recording time', file_name=file_path)
@@ -116,12 +111,12 @@
                       f'Please make sure you imported the same video as you annotated in ETHOVISION into SimBA and the video is registered with the correct frame rate.')
             self.features_df[clf] = 0
             self.features_df[clf] = np.where(self.features_df.index.isin(self.clf_dict[clf]['frames']), 1, 0)
         self.__save_data()
 
     def __save_data(self):
         save_file_name = os.path.join(self.targets_folder, self.video_name + '.' + self.file_type)
-        save_df(self.features_df, self.file_type, save_file_name)
+        write_df(self.features_df, self.file_type, save_file_name)
         print('Added Ethovision annotations for video {} ... '.format(self.video_name))
 
 #test = ImportEthovision(config_path= r"/Users/simon/Desktop/envs/simba_dev/tests/test_data/import_tests/project_folder/project_config.ini", folder_path=r'/Users/simon/Desktop/envs/simba_dev/tests/test_data/import_tests/ethovision_data')
 # test = ImportEthovision(config_path= r"/Users/simon/Desktop/simbapypi_dev/tests/test_data/multi_animal_dlc_two_c57/project_folder/project_config.ini", folder_path=r'/Users/simon/Desktop/simbapypi_dev/tests/test_data/multi_animal_dlc_two_c57/ethovision_import')
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/third_party_label_appenders/BENTO_appender.py` & `Simba-UW-tf-dev-1.57.6/simba/third_party_label_appenders/BENTO_appender.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,23 +1,22 @@
 __author__ = "Simon Nilsson"
 
 
 import os, glob
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.read_config_unit_tests import check_if_filepath_list_is_empty
+import pandas as pd
+from copy import deepcopy
 from simba.mixins.config_reader import ConfigReader
-from simba.misc_tools import get_fn_ext
+from simba.utils.checks import check_if_filepath_list_is_empty
+from simba.utils.read_write import get_fn_ext, read_df, write_df
 from simba.utils.printing import stdout_success
-from simba.rw_dfs import read_df, save_df
 from simba.utils.warnings import (ThirdPartyAnnotationsOutsidePoseEstimationDataWarning,
                                   ThirdPartyAnnotationsClfMissingWarning,
                                   ThirdPartyAnnotationsAdditionalClfWarning)
 from simba.utils.errors import AnnotationFileNotFoundError
-import pandas as pd
-from copy import deepcopy
+
 
 class BentoAppender(ConfigReader):
     """
     Class for appending BENTO annotation to SimBA featurized datasets.
 
     Notes
     ----------
@@ -38,27 +37,27 @@
 
     """
 
     def __init__(self,
                  config_path: str,
                  bento_dir: str):
 
-        super().__init__(config_path=config_path)
+        ConfigReader.__init__(self, config_path=config_path)
         self.bento_dir = bento_dir
         self.feature_files = glob.glob(self.features_dir + '/*.' + self.file_type)
         self.bento_files = glob.glob(self.bento_dir + '/*.' + 'annot')
         check_if_filepath_list_is_empty(filepaths=self.feature_files, error_msg='SIMBA ERROR: No feature files found in project_folder/csv/features_extracted. Extract Features BEFORE appending BENTO annotations')
         check_if_filepath_list_is_empty(filepaths=self.bento_files, error_msg=f'SIMBA ERROR: No BENTO files with .annot extension found in {self.bento_dir}.')
         self.saved_files = []
 
     def run(self):
         for file_cnt, file_path in enumerate(self.feature_files):
             _, self.video_name, ext = get_fn_ext(filepath=file_path)
             print(f'Appending BENTO annotation to video {self.video_name}...')
-            _, _, fps = read_video_info(vid_info_df=self.video_info_df, video_name=self.video_name)
+            _, _, fps = self.read_video_info(video_name=self.video_name)
             bento_path = os.path.join(self.bento_dir, self.video_name + '.annot')
             if bento_path not in self.bento_files:
                 raise AnnotationFileNotFoundError(video_name=self.video_name)
             self.save_path = os.path.join(self.targets_folder, self.video_name + '.' + self.file_type)
             feature_df = read_df(file_path=file_path, file_type=self.file_type)
             video_frm_length = len(feature_df)
             self.results_df = deepcopy(feature_df)
@@ -104,15 +103,15 @@
                 if len(valid_annotation_ids) > 0:
                     print(f'Appending {str(len(valid_annotation_ids))} {clf_name} frame annotations to video {self.video_name}...')
                     self.results_df.loc[valid_annotation_ids, clf_name] = 1
             self.__save()
         stdout_success(msg=f'Annotations for {str(len(self.saved_files))} video(s) and saved in project_folder/csv/targets_inserted directory.')
 
     def __save(self):
-        save_df(df=self.results_df, file_type=self.file_type, save_path=self.save_path)
+        write_df(df=self.results_df, file_type=self.file_type, save_path=self.save_path)
         self.saved_files.append(self.save_path)
         print(f'BENTO annotations appended to video {self.video_name} and saved in {self.save_path}')
 
 
 # test = BentoAppender(config_path='/Users/simon/Desktop/envs/simba_dev/tests/test_data/import_tests/project_folder/project_config.ini',
 #                      bento_dir='/Users/simon/Desktop/envs/simba_dev/tests/test_data/bento_example')
 # test.run()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/third_party_label_appenders/solomon_importer.py` & `Simba-UW-tf-dev-1.57.6/simba/third_party_label_appenders/solomon_importer.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,17 +1,15 @@
 __author__ = "Simon Nilsson"
 
 import os, glob
-from simba.drop_bp_cords import get_fn_ext
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.utils.printing import stdout_success
-from simba.read_config_unit_tests import (check_if_filepath_list_is_empty,
-                                          check_that_column_exist)
-from simba.rw_dfs import read_df, save_df
 from copy import deepcopy
+
+from simba.utils.printing import stdout_success
+from simba.utils.checks import check_that_column_exist, check_if_filepath_list_is_empty
+from simba.utils.read_write import read_df, write_df, get_fn_ext
 from simba.mixins.config_reader import ConfigReader
 
 class SolomonImporter(ConfigReader):
     """
     Class for appending SOLOMON human annotations onto featurized pose-estimation data.
 
     Parameters
@@ -48,15 +46,15 @@
                                         error_msg=f'SIMBA ERROR: No CSV files detected in feature directory {self.features_dir}')
         if not os.path.exists(self.targets_folder): os.mkdir(self.targets_folder)
 
     def import_solomon(self):
         for file_cnt, file_path in enumerate(self.solomon_paths):
             _, file_name, _ = get_fn_ext(file_path)
             feature_file_path = os.path.join(self.features_dir, file_name + '.' + self.file_type)
-            _, _, fps = read_video_info(self.video_info_df, file_name)
+            _, _, fps = self.read_video_info(video_name=file_name)
             if not os.path.isfile(feature_file_path):
                 print('SIMBA WARNING: Data for video {} does not exist in the features directory. SimBA will SKIP appending annotations for video {}'.format(file_name, file_name))
                 continue
             save_path = os.path.join(self.targets_folder, file_name + '.' + self.file_type)
             solomon_df = read_df(file_path, self.file_type).reset_index()
             check_that_column_exist(df=solomon_df, column_name='Behaviour', file_name=file_path)
             features_df = read_df(feature_file_path, self.file_type)
@@ -78,15 +76,15 @@
                               f'However, in SOLOMON, you have annotated {clf_name} to happen at frame number {str(idx_difference[0])}. '
                               f'These ambiguous annotations occur in {str(len(idx_difference))} different frames for video {file_name} that SimBA will **remove** by default. '
                               f'Please make sure you imported the same video as you annotated in SOLOMON into SimBA and the video is registered with the correct frame rate.')
                     target_frm_list = [x for x in target_frm_list if x not in idx_difference]
                 out_df[clf_name] = 0
                 out_df.loc[target_frm_list, clf_name] = 1
 
-            save_df(out_df, self.file_type, save_path)
+            write_df(out_df, self.file_type, save_path)
             print('Solomon annotations appended for video {}...'.format(file_name))
         stdout_success(msg='All SOLOMON annotations imported. Data saved in the project_folder/csv/targets_inserted directory of the SimBA project')
 
 # test = SolomonImporter(config_path='/Users/simon/Desktop/envs/simba_dev/tests/test_data/import_tests/project_folder/project_config.ini',
 #                        solomon_dir='/Users/simon/Desktop/envs/simba_dev/tests/test_data/import_tests/solomon_data')
 #
 # test.import_solomon()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/multi_cropper.py` & `Simba-UW-tf-dev-1.57.6/simba/multi_cropper.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,20 +1,18 @@
 __author__ = "Simon Nilsson"
 
 import pandas as pd
-from simba.read_config_unit_tests import (check_int,
-                                          check_str,
-                                          check_if_filepath_list_is_empty)
+
 import os, glob
 import cv2
-from copy import deepcopy
-from simba.misc_tools import (get_fn_ext,
-                              SimbaTimer)
-from simba.utils.printing import stdout_success
 import subprocess
+from copy import deepcopy
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.utils.checks import  (check_int, check_str, check_if_filepath_list_is_empty)
+from simba.utils.read_write import get_fn_ext
 from simba.enums import Formats
 from simba.utils.errors import CountError, InvalidVideoFileError
 
 class MultiCropper(object):
     """
     Class for cropping single video into multiple videos
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/FSTTC_calculator.py` & `Simba-UW-tf-dev-1.57.6/simba/FSTTC_calculator.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,21 +1,18 @@
 __author__ = "Simon Nilsson"
 
-from simba.read_config_unit_tests import check_if_filepath_list_is_empty
 import os
 import pandas as pd
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.drop_bp_cords import get_fn_ext
-from simba.rw_dfs import read_df
-from simba.misc_tools import (detect_bouts)
-from simba.utils.printing import stdout_success
-from simba.enums import Defaults, TagNames
-from simba.mixins.config_reader import ConfigReader
 import itertools
 import seaborn as sns
+from simba.utils.data import detect_bouts
+from simba.utils.printing import stdout_success
+from simba.utils.read_write import get_fn_ext, read_df
+from simba.utils.checks import check_if_filepath_list_is_empty
+from simba.mixins.config_reader import ConfigReader
 
 class FSTTCPerformer(ConfigReader):
     """
     Class for calculating forward spike-time tiling coefficients between pairs of
     classified behaviors.
 
     Parameters
@@ -88,15 +85,15 @@
                          'Difference: first behavior start to second behavior start',
                          'Time 2nd behaviour start to time window end']
 
         for file_cnt, file_path in enumerate(self.machine_results_paths):
             _, self.video_name, _ = get_fn_ext(file_path)
             self.video_sequence_dict[self.video_name] = {}
             print('Analyzing behavioral sequences: {}. Video {}/{}'.format(self.video_name, str(file_cnt + 1), str(len(self.machine_results_paths))))
-            _, _, self.fps = read_video_info(self.video_info_df, self.video_name)
+            _, _, self.fps = self.read_video_info(video_name=self.video_name)
             self.video_sequence_dict[self.video_name]['fps'] = self.fps
             self.frames_in_window = int((self.fps / 1000) * self.time_delta)
             self.data_df = read_df(file_path, self.file_type)[self.behavior_lst]
             self.video_sequence_dict[self.video_name]['session_length_frames'] = len(self.data_df)
             bouts_df = detect_bouts(data_df=self.data_df, target_lst=self.behavior_lst, fps=self.fps)
             bouts_df['Start_frame'] = (bouts_df['Start_time'] * self.fps).astype(int) - 1
             bouts_df = bouts_df[['Event', 'Start_frame', 'End_frame']]
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/create_project_pop_up.py` & `Simba-UW-tf-dev-1.57.6/simba/create_project_pop_up.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,32 +1,33 @@
 __author__ = "Simon Nilsson"
 
 import tkinter.ttk as ttk
 from tkinter import *
 import os
 from copy import deepcopy
 import pandas as pd
+from PIL import ImageTk
+import PIL.Image
+
 from simba.tkinter_functions import (hxtScrollbar,
                                      FolderSelect,
                                      Entry_Box,
                                      DropDownMenu)
-from PIL import ImageTk
-import PIL.Image
 from simba.mixins.pop_up_mixin import PopUpMixin
 from simba.enums import Formats, Options, Methods, Paths, Keys, Links
 from simba.tkinter_functions import CreateLabelFrameWithIcon
 from simba.utils.errors import DuplicationError, MissingProjectConfigEntryError
 from simba.utils.lookups import (get_body_part_configurations,
                                  get_bp_config_codes,
                                  get_icons_paths)
 from simba.pop_up_classes import (PoseResetterPopUp,
                                   CreateUserDefinedPoseConfigurationPopUp)
-from simba.read_config_unit_tests import (check_if_dir_exists, check_str)
 from simba.project_config_creator import ProjectConfigCreator
-from simba.misc_tools import extract_frames_from_all_videos_in_directory
+from simba.video_processing import extract_frames_from_all_videos_in_directory
+from simba.utils.checks import check_if_dir_exists, check_str
 
 
 class ProjectCreatorPopUp(PopUpMixin):
     """
     Creates tkinter GUI pop-up window accepting user-input for generating SimBA project.
     """
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/video_info_table.py` & `Simba-UW-tf-dev-1.57.6/simba/video_info_table.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,28 +1,25 @@
 __author__ = "Simon Nilsson"
 
 from tkinter import *
 import os, glob
 import pandas as pd
-from simba.misc_tools import (get_fn_ext,
-                              get_video_meta_data)
-from simba.read_config_unit_tests import (read_config_file,
-                                          read_config_entry,
-                                          read_project_path_and_file_type)
-from simba.feature_extractors.unit_tests import (read_video_info_csv,
-                                               read_video_info)
+import collections
+
+from simba.utils.read_write import get_fn_ext, get_video_meta_data, read_config_entry
 from simba.enums import Paths, ReadConfig, Dtypes, Keys, Links, Formats
 from simba.get_coordinates_tools_v2 import get_coordinates_nilsson
 from simba.tkinter_functions import hxtScrollbar, CreateLabelFrameWithIcon
-import collections
 from simba.utils.printing import stdout_success
 from simba.utils.errors import NoFilesFoundError, ParametersFileError, InvalidInputError, PermissionError
 from simba.utils.warnings import DuplicateNamesWarning, InvalidValueWarning
+from simba.mixins.config_reader import ConfigReader
+from simba.utils.read_write import read_video_info_csv
 
-class VideoInfoTable(object):
+class VideoInfoTable(ConfigReader):
     """
     Class for creating Tkinter GUI video meta data table. Allows users to modify resolutions, fps, and pixels-per-mm
     interactively of videos within the SimBA project. Data is stored within the project_folder/logs/video_info.csv
     file in the SimBA project.
 
     Parameters
     ----------
@@ -39,32 +36,27 @@
     >>> video_info_gui.create_window()
     >>> video_info_gui.main_frm.mainloop()
     """
 
     def __init__(self,
                  config_path: str):
 
-        self.config = read_config_file(config_path)
-        self.project_path, _ = read_project_path_and_file_type(config=self.config)
-        self.logs_path = os.path.join(self.project_path, 'logs')
-        self.video_folder = os.path.join(self.project_path, 'videos')
-        self.vid_info_path = os.path.join(self.project_path, Paths.VIDEO_INFO.value)
-
-        if os.path.isfile(self.vid_info_path):
-            self.vid_info_df = read_video_info_csv(self.vid_info_path).reset_index(drop=True)
+        ConfigReader.__init__(self, config_path=config_path, read_video_info=False)
+        if os.path.isfile(self.video_info_path):
+            self.video_info_df = read_video_info_csv(self.video_info_path).reset_index(drop=True)
         else:
-            self.vid_info_df = None
+            self.video_info_df = None
         self.distance_mm = read_config_entry(self.config, ReadConfig.FRAME_SETTINGS.value, ReadConfig.DISTANCE_MM.value, Dtypes.FLOAT.value, 0.00)
         self.find_video_files()
         self.video_basename_lst = []
         self.max_char_vid_name = len(max(self.video_paths))
 
     def find_video_files(self):
         self.video_paths = []
-        file_paths_in_folder = [f for f in glob.glob(self.video_folder + '/*') if os.path.isfile(f)]
+        file_paths_in_folder = [f for f in glob.glob(self.video_dir + '/*') if os.path.isfile(f)]
         for file_cnt, file_path in enumerate(file_paths_in_folder):
             _, file_name, file_ext = get_fn_ext(file_path)
             if (file_ext.lower() == '.mp4') or (file_ext.lower() == '.avi'):
                 self.video_paths.append(file_name + file_ext)
         if len(self.video_paths) == 0:
             raise NoFilesFoundError(msg='No videos in mp4 or avi format was found to be imported to SimBA project')
 
@@ -80,15 +72,15 @@
         for cnt, name in enumerate(self.video_paths):
             _, video_basename, _ = get_fn_ext(name)
             self.video_basename_lst.append(video_basename)
             self.videos[name] = {}
             self.videos[name]['video_idx_lbl'] = Label(self.video_frm, text=str(cnt), width = 6)
             self.videos[name]['video_name_lbl'] = Label(self.video_frm, text=video_basename, width=self.max_char_vid_name)
             self.videos[name]['video_name_w_ext'] = name
-            video_meta = get_video_meta_data(os.path.join(self.video_folder, name))
+            video_meta = get_video_meta_data(os.path.join(self.video_dir, name))
             self.videos[name]['fps_var'] = IntVar()
             self.videos[name]['fps_var'].set(video_meta['fps'])
             self.videos[name]['fps_entry'] = Entry(self.video_frm, width=20, textvariable=self.videos[name]['fps_var'])
             self.videos[name]['width_var'] = IntVar()
             self.videos[name]['width_var'].set(video_meta['width'])
             self.videos[name]['width_entry'] = Entry(self.video_frm, width=20, textvariable=self.videos[name]['width_var'])
             self.videos[name]['height_var'] = IntVar()
@@ -97,18 +89,18 @@
             self.videos[name]['distance'] = StringVar()
             self.videos[name]['distance'].set(self.distance_mm)
             self.videos[name]['distance_entry'] = Entry(self.video_frm, width=20, textvariable=self.videos[name]['distance'])
             self.videos[name]['find_dist_btn'] = Button(self.video_frm, text='Calculate distance', fg='black', command=lambda k= (self.videos[name]['video_name_w_ext'], self.videos[name]['distance']): self.__initiate_find_distance(k))
             self.videos[name]['px_mm'] = StringVar()
             self.videos[name]['px_mm'].set(0)
             self.videos[name]['px_mm_entry'] = Entry(self.video_frm, width=20, textvariable=self.videos[name]['px_mm'])
-            if isinstance(self.vid_info_df, pd.DataFrame):
+            if isinstance(self.video_info_df, pd.DataFrame):
                 prior_data = None
                 try:
-                    prior_data = read_video_info(self.vid_info_df, video_basename)[0]
+                    prior_data = self.read_video_info(video_name=video_basename)[0]
                 except ParametersFileError:
                     pass
                 if prior_data is not None:
                     for value_name, set_name in zip(['fps', 'Resolution_width', 'Resolution_height', 'Distance_in_mm', 'pixels/mm'], ['fps_var', 'width_var', 'height_var', 'distance', 'px_mm']):
                         float_val = self.__check_that_value_is_numeric(value=prior_data[value_name].values[0], value_name=value_name, video_name=prior_data['Video'].values[0])
                         self.videos[name][set_name].set(float_val)
 
@@ -175,15 +167,15 @@
         video_name, distance = k[0], k[1].get()
         try:
             distance = float(distance)
         except:
             raise InvalidInputError(msg=f'The *DISTANCE IN MM* for video {video_name} is not an integer or float value. The *DISTANCE IN MM* has to be a numerical value.')
         if distance <= 0:
             raise InvalidInputError(msg=f'The *DISTANCE IN MM* for video {video_name} is <=0. The *DISTANCE IN MM* has to be a value above 0.')
-        video_pixels_per_mm = get_coordinates_nilsson(os.path.join(self.video_folder, video_name), distance)
+        video_pixels_per_mm = get_coordinates_nilsson(os.path.join(self.video_dir, video_name), distance)
         self.videos[video_name]['px_mm'].set(str(round(video_pixels_per_mm, 5)))
 
     def __duplicate_idx_1_px_mm(self):
         px_value = self.videos[list(self.videos.keys())[0]]['px_mm_entry'].get()
         for cnt, name in enumerate(self.video_paths):
             self.videos[name]['px_mm'].set(px_value)
 
@@ -198,14 +190,21 @@
         self.video_df = self.video_df.set_index('Video')
         try:
             self.video_df.to_csv(os.path.join(self.project_path, Paths.VIDEO_INFO.value))
         except PermissionError:
             raise PermissionError(msg='SimBA tried to write to project_folder/logs/video_info.csv, but was not allowed. If this file is open in another program, tru closing it.')
         stdout_success(msg='Video info saved at project_folder/logs/video_info.csv')
 
+# test = VideoInfoTable(config_path='/Users/simon/Desktop/envs/troubleshooting/Lucas/project_folder/project_config.ini')
+# test.create_window()
+# test.main_frm.mainloop()
+
+
+
+
 # test = VideoInfoTable(config_path='/Users/simon/Desktop/troubleshooting/train_model_project/project_folder/project_config.ini')
 # test.create_window()
 # test.main_frm.mainloop()
 
 
 # test = VideoInfoTable(config_path='/Users/simon/Desktop/envs/troubleshooting/sleap_5_animals_2/project_folder/project_config.ini')
 # test.create_window()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/cue_light_tools/.DS_Store` & `Simba-UW-tf-dev-1.57.6/simba/cue_light_tools/.DS_Store`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/cue_light_tools/cue_light_clf_statistics.py` & `Simba-UW-tf-dev-1.57.6/simba/cue_light_tools/cue_light_clf_statistics.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,23 +1,17 @@
 import pandas as pd
-from simba.read_config_unit_tests import (read_config_entry, read_config_file, check_file_exist_and_readable)
-from simba.feature_extractors.unit_tests import read_video_info_csv, read_video_info
 import os, glob
-from simba.drop_bp_cords import getBpNames, create_body_part_dictionary
-from simba.misc_tools import (check_multi_animal_status,
-                              get_fn_ext,
-                              )
+from simba.utils.read_write import read_df, get_fn_ext, read_config_entry
 from simba.utils.printing import stdout_success
-from simba.rw_dfs import read_df
-from simba.read_config_unit_tests import check_that_column_exist
-from datetime import datetime
+from simba.utils.checks import check_that_column_exist
 from simba.cue_light_tools.cue_light_tools import find_frames_when_cue_light_on
 from simba.utils.errors import NoFilesFoundError
+from simba.mixins.config_reader import ConfigReader
 
-class CueLightClfAnalyzer(object):
+class CueLightClfAnalyzer(ConfigReader):
     """
     Class for computing aggregate statistics when classified behaviors are occurring in relation to the cue light
     ON and OFF states.
 
     Parameters
     ----------
     config_path: str
@@ -48,34 +42,25 @@
     def __init__(self,
                  config_path: str,
                  pre_window: int,
                  post_window: int,
                  cue_light_names: list,
                  clf_list: list):
 
-
-
+        ConfigReader.__init__(config_path=config_path)
         self.pre_window, self.post_window = pre_window, post_window
-        self.config_path, self.cue_light_names = config_path, cue_light_names
-        self.config = read_config_file(config_path)
+        self.cue_light_names = cue_light_names
         self.clf_list = clf_list
         self.project_path = read_config_entry(self.config, 'General settings', 'project_path', data_type='folder_path')
         self.cue_light_data_dir = os.path.join(self.project_path, 'csv', 'cue_lights')
         self.machine_results_dir = os.path.join(self.project_path, 'csv', 'machine_results')
-        self.logs_path = os.path.join(self.project_path, 'logs')
-        self.datetime = datetime.now().strftime('%Y%m%d%H%M%S')
-        self.file_type = read_config_entry(self.config, 'General settings', 'workflow_file_type', 'str', 'csv')
-        self.vid_info_df = read_video_info_csv(os.path.join(self.project_path, 'logs', 'video_info.csv'))
         self.no_animals = read_config_entry(self.config, 'General settings', 'animal_no', 'int')
-        self.x_cols, self.y_cols, self.pcols = getBpNames(config_path)
-        self.multi_animal_status, self.multi_animal_id_lst = check_multi_animal_status(self.config, self.no_animals)
         self.files_found_cue_light = glob.glob(self.cue_light_data_dir + '/*.' + self.file_type)
         if len(self.files_found_cue_light) == 0:
             raise NoFilesFoundError(msg='SIMBA ERROR: No cue light data found. Please analyze cue light data before analyzing classifications based on cue light data')
-        self.animal_bp_dict = create_body_part_dictionary(self.multi_animal_status, self.multi_animal_id_lst, self.no_animals, self.x_cols, self.y_cols, self.pcols,[])
 
     def analyze_clf(self):
         """
         Method to calculate classifier data during cue lights periods
 
         Returns
         -------
@@ -91,15 +76,15 @@
             if not os.path.isfile(machine_results_path):
                 print('SIMBA ERROR: No machine classifications exist for {}.'
                       ' Skipping cue light classifier analysis for video {}'.format(self.video_name, self.video_name))
                 continue
             else:
                 self.results[self.video_name] = {}
                 cue_light_df = read_df(file_path, self.file_type)
-                self.video_info_settings, self.px_per_mm, self.fps = read_video_info(self.vid_info_df, self.video_name)
+                self.video_info_settings, self.px_per_mm, self.fps = self.read_video_info(video_name=self.video_name)
                 self.prior_window_frames_cnt = int(self.pre_window / (1000 / self.fps))
                 self.post_window_frames_cnt = int(self.post_window / (1000 / self.fps))
                 machine_results_df = read_df(machine_results_path, self.file_type)
                 data_df = pd.concat([machine_results_df, cue_light_df[self.cue_light_names]], axis=1)
                 del cue_light_df, machine_results_df
                 cue_light_frames_dict = find_frames_when_cue_light_on(data_df=data_df,
                                               cue_light_names=self.cue_light_names,
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/cue_light_tools/cue_light_analyzer.py` & `Simba-UW-tf-dev-1.57.6/simba/cue_light_tools/cue_light_analyzer.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,34 +1,23 @@
-from simba.read_config_unit_tests import (read_config_entry,
-                                          read_config_file)
 from sklearn.cluster import KMeans
 import os, glob
 import itertools
 import pandas as pd
-from simba.rw_dfs import read_df, save_df
-from simba.drop_bp_cords import (get_fn_ext,
-                                 create_body_part_dictionary)
-from simba.misc_tools import (find_video_of_file,
-                              get_video_meta_data,
-                              detect_bouts,
-                              find_core_cnt,
-                              check_multi_animal_status,
-                              )
-from simba.utils.printing import stdout_success
-from simba.drop_bp_cords import getBpNames
 import cv2
 import numpy as np
 import multiprocessing
-from simba.feature_extractors.unit_tests import read_video_info_csv, read_video_info
 import functools
 import time
 import platform
-from shapely.geometry import Polygon
-from joblib import Parallel, delayed
+from simba.utils.read_write import read_df, write_df, get_fn_ext, find_video_of_file, get_video_meta_data, find_core_cnt
+from simba.utils.data import detect_bouts
+from simba.utils.printing import stdout_success
 from simba.utils.errors import NoFilesFoundError, CountError, NoROIDataError
+from simba.mixins.config_reader import ConfigReader
+
 
 
 
 def get_intensity_scores_in_rois(frm_list: list=None,
                                  video_path: str = None,
                                  rectangles_df: pd.DataFrame = None,
                                  polygon_df: pd.DataFrame = None,
@@ -63,15 +52,15 @@
             bg = np.ones_like(roi_img, np.uint8)
             cv2.bitwise_not(bg, bg, mask=mask)
             roi_image = bg + dst
             results_dict[frm_cnt][circle['Name']] = int(np.average(np.linalg.norm(roi_image, axis=2)) / np.sqrt(3))
         frm_cnt+=1
     return results_dict
 
-class CueLightAnalyzer(object):
+class CueLightAnalyzer(ConfigReader):
     """
     Class for analyzing when cue lights are in ON and OFF states. Results are stored in the
     `project_folder/csv/cue_lights` cue lights directory.
 
     Parameters
     ----------
     config_path: str
@@ -93,35 +82,25 @@
 
     def __init__(self,
                  config_path: str,
                  in_dir: str,
                  cue_light_names: list):
 
 
-
+        ConfigReader.__init__(config_path=config_path)
 
         if len(cue_light_names) == 0:
             raise CountError(msg='SIMBA ERROR: Please select one or more cue lights')
         if platform.system() == "Darwin":
             multiprocessing.set_start_method('spawn', force=True)
 
-        self.config = read_config_file(config_path)
-        self.project_path = read_config_entry(self.config, 'General settings', 'project_path', data_type='folder_path')
-        self.logs_path, self.video_dir = os.path.join(self.project_path, 'logs'), os.path.join(self.project_path, 'videos')
         self.out_dir = os.path.join(self.project_path, 'csv', 'cue_lights')
         if not os.path.exists(self.out_dir): os.makedirs(self.out_dir)
         self.cue_light_names, self.in_dir = cue_light_names, in_dir
-        self.file_type = read_config_entry(self.config, 'General settings', 'workflow_file_type', 'str', 'csv')
-        self.vid_info_df = read_video_info_csv(os.path.join(self.logs_path, 'video_info.csv'))
         self.files_found = glob.glob(self.in_dir + '/*' + self.file_type)
-        self.x_cols, self.y_cols, self.p_cols = getBpNames(config_path)
-        self.no_animals = read_config_entry(self.config, 'General settings', 'animal_no', 'int')
-        self.file_type = read_config_entry(self.config, 'General settings', 'workflow_file_type', 'str', 'csv')
-        self.multi_animal_status, self.multi_animal_id_lst = check_multi_animal_status(self.config, self.no_animals)
-        self.animal_bp_dict = create_body_part_dictionary(self.multi_animal_status, self.multi_animal_id_lst, self.no_animals, self.x_cols, self.y_cols, self.p_cols, [])
         if len(self.files_found) == 0:
             raise NoFilesFoundError(msg='SIMBA ERROR: Zero tracking files detected in the "project_folder/csv/outlier_corrected_movement_location" directory')
         _, self.cpu_cnt_to_use = find_core_cnt()
         self.maxtasksperchild = 10
         self.chunksize = 1
         self.read_roi_dfs()
         print('Processing {} cue light(s) in {} data file(s)...'.format(str(len(cue_light_names)), str(len(self.files_found))))
@@ -169,15 +148,15 @@
 
     def analyze_files(self):
         start_time = time.time()
         for file_cnt, file_path in enumerate(self.files_found):
             self.data_df = read_df(file_path, self.file_type)
             _, self.video_name, _ = get_fn_ext(file_path)
             self.save_path = os.path.join(self.out_dir, self.video_name + '.' + self.file_type)
-            video_settings, pix_per_mm, self.fps = read_video_info(self.vid_info_df, self.video_name)
+            video_settings, pix_per_mm, self.fps = self.read_video_info(video_name=self.video_name)
             self.video_recs = self.rectangles_df.loc[(self.rectangles_df['Video'] == self.video_name) & (self.rectangles_df['Name'].isin(self.cue_light_names))]
             self.video_circs = self.circles_df.loc[(self.circles_df['Video'] == self.video_name)  & (self.circles_df['Name'].isin(self.cue_light_names))]
             self.video_polys = self.polygon_df.loc[(self.polygon_df['Video'] == self.video_name) & (self.polygon_df['Name'].isin(self.cue_light_names))]
             self.shape_names = list(itertools.chain(self.rectangles_df['Name'].unique(), self.circles_df['Name'].unique(),self.polygon_df['Name'].unique()))
             self.video_path = find_video_of_file(self.video_dir, self.video_name)
             self.video_meta_data = get_video_meta_data(self.video_path)
 
@@ -200,15 +179,15 @@
                     self.intensity_results.update(result)
                     print('Image {}/{}, Video {}/{}...'.format(str(int(imgs_peer_loop*cnt)), str(len(self.data_df)), str(file_cnt+1), str(len(self.files_found))))
             pool.terminate()
             pool.join()
             self.calculate_descriptive_statistics()
             self.insert_light_data()
             self.remove_outlier_events()
-            save_df(self.data_df, self.file_type, self.save_path)
+            write_df(self.data_df, self.file_type, self.save_path)
         elapsed_time = str(round(time.time() - start_time, 2)) + 's'
         stdout_success(msg=f'Analysed {str(len(self.files_found))} files. Data stored in project_folder/csv/cue_lights', elapsed_time=elapsed_time)
 
 # test = CueLightAnalyzer(config_path='/Users/simon/Desktop/troubleshooting/light_analyzer/project_folder/project_config.ini',
 #                         in_dir='/Users/simon/Desktop/troubleshooting/light_analyzer/project_folder/csv/outlier_corrected_movement_location',
 #                         cue_light_names=['Cue_light'])
 # test.analyze_files()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/cue_light_tools/cue_light_menues.py` & `Simba-UW-tf-dev-1.57.6/simba/cue_light_tools/cue_light_menues.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,28 +1,26 @@
 from tkinter import *
 import glob, os
 import itertools
-import platform
-from simba.read_config_unit_tests import read_config_entry, read_config_file, check_float, check_int
-from simba.drop_bp_cords import getBpNames
-from simba.misc_tools import get_fn_ext, find_video_of_file
 import pandas as pd
+
+from simba.utils.checks import check_float, check_int
+from simba.utils.read_write import get_fn_ext, find_video_of_file, get_all_clf_names, read_config_entry
 from simba.cue_light_tools.cue_light_analyzer import CueLightAnalyzer
 from simba.cue_light_tools.cue_light_visualizer import CueLightVisualizer
-from simba.train_model_functions import get_all_clf_names
 from simba.cue_light_tools.cue_light_clf_statistics import CueLightClfAnalyzer
 from simba.cue_light_tools.cue_light_movement_statistics import CueLightMovementAnalyzer
 from simba.utils.errors import NoFilesFoundError, CountError, NoROIDataError, NoChoosenClassifierError
 from simba.tkinter_functions import hxtScrollbar, CreateLabelFrameWithIcon
 from simba.enums import Keys, Links
-
+from simba.mixins.config_reader import ConfigReader
 import webbrowser
 
 
-class CueLightAnalyzerMenu(object):
+class CueLightAnalyzerMenu(ConfigReader):
     """
     Class for lunching cue light analysis GUI in SimBA.
 
     Parameters
     ----------
     config_path: str
         path to SimBA project config file in Configparser format
@@ -39,22 +37,17 @@
     """
 
 
 
     def __init__(self,
                  config_path: str):
 
-        self.config_path = config_path
-        self.config = read_config_file(self.config_path)
-        self.project_path = read_config_entry(self.config, 'General settings', 'project_path', data_type='folder_path')
-        self.logs_path, self.video_dir = os.path.join(self.project_path, 'logs'), os.path.join(self.project_path, 'videos')
+        ConfigReader.__init__(config_path=config_path)
         self.data_dir = os.path.join(self.project_path, 'csv', 'outlier_corrected_movement_location')
         self.cue_light_data_folder = os.path.join(self.project_path, 'csv', 'cue_lights')
-        self.animal_cnt = read_config_entry(self.config, 'General settings', 'animal_no', 'int')
-        self.file_type = read_config_entry(self.config, 'General settings', 'workflow_file_type', 'str', 'csv')
         self.__read_roi_dfs()
         if len(self.shape_names) == 0:
             raise CountError(msg='SIMBA ERROR: Cue light analysis require ROI definitions. Please define ROIs before doing cue light analysis')
         self.cue_light_main_frame = Toplevel()
         self.cue_light_main_frame.minsize(750, 300)
         self.cue_light_main_frame.wm_title("SIMBA CUE LIGHT ANALYZER")
         self.cue_light_main_frame.lift()
@@ -158,15 +151,15 @@
                                                      command=self.__create_animal_bp_menues)
         self.animal_cnt_frm.grid(row=0, column=0, sticky=W)
         self.choose_animal_cnt_lbl.grid(row=0, column=0, sticky=W)
         self.choose_animal_cnt_dropdown.grid(row=0, column=1)
 
     def __create_animal_bp_menues(self, no_animals):
         self.animal_dict = {}
-        self.bp_names = getBpNames(self.config_path)[0]
+        self.bp_names = self.get_body_part_names()[0]
         self.bp_names = [x[0:-2] for x in self.bp_names]
         current_row = 0
         for animal_cnt in range(no_animals):
             self.animal_dict[animal_cnt] = {}
             current_row = 1 + animal_cnt
             self.animal_dict[animal_cnt]['label'] = Label(self.animal_cnt_frm, text='Animal {} body-part:'.format(str(animal_cnt+1)), width=17, anchor=W)
             self.animal_dict[animal_cnt]['bp_chosen'] = StringVar()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/cue_light_tools/cue_light_tools.py` & `Simba-UW-tf-dev-1.57.6/simba/cue_light_tools/cue_light_tools.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 import pandas as pd
-from simba.misc_tools import detect_bouts
+from simba.utils.data import detect_bouts
 
 def find_frames_when_cue_light_on(data_df: pd.DataFrame,
                                   cue_light_names: list,
                                   fps: int,
                                   prior_window_frames_cnt: int,
                                   post_window_frames_cnt: int):
     light_on_dict = {}
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/cue_light_tools/cue_light_visualizer.py` & `Simba-UW-tf-dev-1.57.6/simba/cue_light_tools/cue_light_visualizer.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,21 +1,17 @@
-from simba.read_config_unit_tests import (read_config_entry, read_config_file, check_file_exist_and_readable)
-from simba.feature_extractors.unit_tests import read_video_info_csv, read_video_info
-from simba.misc_tools import get_video_meta_data
-from simba.utils.printing import stdout_success
 import itertools, os
-from simba.drop_bp_cords import get_fn_ext
-from simba.rw_dfs import read_df
 import pandas as pd
 import cv2
-from simba.drop_bp_cords import getBpNames, create_body_part_dictionary, createColorListofList
-from simba.misc_tools import check_multi_animal_status
 from simba.utils.errors import NoSpecifiedOutputError, NoROIDataError
+from simba.mixins.config_reader import ConfigReader
+from simba.utils.read_write import read_df, get_fn_ext, get_video_meta_data
+from simba.utils.printing import stdout_success
+from simba.utils.checks import check_file_exist_and_readable
 
-class CueLightVisualizer(object):
+class CueLightVisualizer(ConfigReader):
     """
     Class for visualizing SimBA computed cue-light ON and OFF states and the aggregate statistics of ON and OFF
     states.
 
     Parameters
     ----------
     config_path: str
@@ -43,40 +39,33 @@
     def __init__(self,
                  config_path: str,
                  cue_light_names: list,
                  video_path: str,
                  frame_setting: bool,
                  video_setting: bool):
 
+        ConfigReader.__init__(config_path=config_path)
+
         if (not frame_setting) and (not video_setting):
             raise NoSpecifiedOutputError(msg='SIMBA ERROR: Please choose to select either videos, frames, or both frames and videos.')
         self.video_setting, self.frame_setting = video_setting, frame_setting
-        self.config = read_config_file(config_path)
-        self.project_path = read_config_entry(self.config, 'General settings', 'project_path', data_type='folder_path')
         self.in_dir = os.path.join(self.project_path, 'csv', 'cue_lights')
-        self.file_type = read_config_entry(self.config, 'General settings', 'workflow_file_type', 'str', 'csv')
         self.cue_light_names, self.video_path = cue_light_names, video_path
         _, self.video_name, _ = get_fn_ext(video_path)
         self.video_meta_data = get_video_meta_data(self.video_path)
         self.logs_path, self.video_dir = os.path.join(self.project_path, 'logs'), os.path.join(self.project_path, 'videos')
         self.data_file_path = os.path.join(self.in_dir, self.video_name + '.' + self.file_type)
         check_file_exist_and_readable(self.data_file_path)
         self.data_df = read_df(self.data_file_path, self.file_type)
         self.output_folder = os.path.join(self.project_path, 'frames', 'output', 'cue_lights')
         if not os.path.exists(self.output_folder): os.makedirs(self.output_folder)
-        self.vid_info_df = read_video_info_csv(os.path.join(self.project_path, 'logs', 'video_info.csv'))
-        self.video_settings, pix_per_mm, self.fps = read_video_info(self.vid_info_df, self.video_name)
+        self.video_settings, pix_per_mm, self.fps = self.read_video_info(video_name=self.video_name)
         self.space_scale, radius_scale, res_scale, font_scale = 25, 10, 1500, 0.8
         max_dim = max(self.video_meta_data['width'], self.video_meta_data['height'])
         self.draw_scale, self.font_size = int(radius_scale / (res_scale / max_dim)), float(font_scale / (res_scale / max_dim))
-        self.no_animals = read_config_entry(self.config, 'General settings', 'animal_no', 'int')
-        self.x_cols, self.y_cols, self.pcols = getBpNames(config_path)
-        self.multi_animal_status, self.multi_animal_id_lst = check_multi_animal_status(self.config, self.no_animals)
-        self.color_lst_of_lst = createColorListofList(self.no_animals, int(len(self.x_cols) + 1))
-        self.animal_bp_dict = create_body_part_dictionary(self.multi_animal_status, self.multi_animal_id_lst, self.no_animals, self.x_cols, self.y_cols, [], self.color_lst_of_lst)
         self.spacing_scaler = int(self.space_scale / (res_scale / max_dim))
         self.font = cv2.FONT_HERSHEY_TRIPLEX
         self.__read_roi_dfs()
 
     def __update_video_meta_data(self):
         new_cap = cv2.VideoCapture(self.video_path)
         new_cap.set(1, 1)
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/cue_light_tools/cue_light_movement_statistics.py` & `Simba-UW-tf-dev-1.57.6/simba/cue_light_tools/cue_light_movement_statistics.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,26 +1,20 @@
 import os, glob
-from simba.read_config_unit_tests import (read_config_entry, read_config_file, check_file_exist_and_readable)
-from simba.feature_extractors.unit_tests import read_video_info_csv, read_video_info
-from simba.rw_dfs import read_df
-from simba.misc_tools import (get_fn_ext,
-                              check_multi_animal_status,
-                              )
-from simba.utils.printing import stdout_success
-from simba.drop_bp_cords import getBpNames, create_body_part_dictionary
 from collections import defaultdict
 import pandas as pd
 import numpy as np
 from statistics import mean
 from simba.roi_tools.ROI_analyzer import ROIAnalyzer
-from datetime import datetime
 from simba.cue_light_tools.cue_light_tools import find_frames_when_cue_light_on
+from simba.mixins.config_reader import ConfigReader
+from simba.utils.read_write import get_fn_ext, read_df
+from simba.utils.printing import stdout_success
 
 
-class CueLightMovementAnalyzer(object):
+class CueLightMovementAnalyzer(ConfigReader):
     """
     Class for computing aggregate statistics of animal movement in relation to the cue light
     ON and OFF states.
 
     Parameters
     ----------
     config_path: str
@@ -56,46 +50,37 @@
                  config_path: str,
                  pre_window: int,
                  post_window: int,
                  cue_light_names: list,
                  threshold: float,
                  roi_setting: bool):
 
-        self.config_path, self.cue_light_names = config_path, cue_light_names
-        self.config, self.roi_setting = read_config_file(config_path), roi_setting
+        ConfigReader.__init__(config_path=config_path)
+        self.cue_light_names = cue_light_names
+        self.roi_setting = roi_setting
         self.p_threshold = threshold
         self.pre_window, self.post_window = pre_window, post_window
-        self.project_path = read_config_entry(self.config, 'General settings', 'project_path', data_type='folder_path')
         self.in_dir = os.path.join(self.project_path, 'csv', 'cue_lights')
-        self.datetime = datetime.now().strftime('%Y%m%d%H%M%S')
-        self.logs_path = os.path.join(self.project_path, 'logs')
-        self.file_type = read_config_entry(self.config, 'General settings', 'workflow_file_type', 'str', 'csv')
-        self.vid_info_df = read_video_info_csv(os.path.join(self.project_path, 'logs', 'video_info.csv'))
-        self.no_animals = read_config_entry(self.config, 'General settings', 'animal_no', 'int')
-        self.x_cols, self.y_cols, self.pcols = getBpNames(config_path)
-        self.multi_animal_status, self.multi_animal_id_lst = check_multi_animal_status(self.config, self.no_animals)
         self.files_found = glob.glob(self.in_dir + '/*.' + self.file_type)
-        self.animal_bp_dict = create_body_part_dictionary(self.multi_animal_status, self.multi_animal_id_lst, self.no_animals, self.x_cols, self.y_cols, self.pcols,[])
         self.bp_dict, self.bp_columns = defaultdict(list), []
-        for cnt, animal in enumerate(self.multi_animal_id_lst):
+        for cnt, animal in enumerate(self.multi_animal_id_list):
             bp_name = self.config.get('ROI settings', 'animal_' + str(cnt + 1) + '_bp')
             if bp_name == 'None':
                 print('SIMBA ERROR: Please analyze ROI data and set body-parts first.')
                 raise ValueError
             for c in ['_x', '_y', '_p']:
                 self.bp_dict[animal].append(bp_name + c)
                 self.bp_columns.append(bp_name + c)
         print('Analyzing {} files...'.format(str(len(self.files_found))))
 
         if roi_setting:
             self.roi_analyzer = ROIAnalyzer(ini_path=self.config_path,
                                             data_path=os.path.join(self.project_path, 'csv', 'outlier_corrected_movement_location'),
                                             calculate_distances=False)
-            self.roi_analyzer.read_roi_dfs()
-            self.roi_analyzer.analyze_ROIs()
+            self.roi_analyzer.run()
             self.entries_exits_df = pd.concat(self.roi_analyzer.entry_exit_df_lst, axis=0)
             self.entries_exits_df = self.entries_exits_df[~self.entries_exits_df['Shape'].isin(self.cue_light_names)]
             self.entries_exits_df['inside_lst'] = self.entries_exits_df.apply(lambda x: list(range(int(x['Entry_times']), int(x['Exit_times'] + 1))), axis=1)
 
     def __euclidean_distance(self, bp_1_x_vals, bp_2_x_vals, bp_1_y_vals, bp_2_y_vals, px_per_mm):
         series = (np.sqrt((bp_1_x_vals - bp_2_x_vals) ** 2 + (bp_1_y_vals - bp_2_y_vals) ** 2)) / px_per_mm
         return series
@@ -113,15 +98,15 @@
         self.results = {}
         if self.roi_setting:
             self.roi_results = {}
         for file_cnt, file_path in enumerate(self.files_found):
             _, self.video_name, _ = get_fn_ext(file_path)
             self.results[self.video_name] = {}
             self.data_df = read_df(file_path, self.file_type).reset_index(drop=True)
-            self.video_info_settings, self.px_per_mm, self.fps = read_video_info(self.vid_info_df, self.video_name)
+            self.video_info_settings, self.px_per_mm, self.fps = self.read_video_info(video_name=self.video_name)
             self.prior_window_frames_cnt = int(self.pre_window / (1000 / self.fps))
             self.post_window_frames_cnt = int(self.post_window / (1000 / self.fps))
             self.light_on_dict = find_frames_when_cue_light_on(data_df=self.data_df,
                                           cue_light_names=self.cue_light_names,
                                           fps=self.fps,
                                           prior_window_frames_cnt=self.prior_window_frames_cnt,
                                           post_window_frames_cnt=self.post_window_frames_cnt)
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/extract_frames_fast.py` & `Simba-UW-tf-dev-1.57.6/simba/extract_frames_fast.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 # MODIFIED FROM https://gist.github.com/HaydenFaulkner/54318fd3e9b9bdb66c5440c44e4e08b8
 # Medium article https://medium.com/@haydenfaulkner/extracting-frames-fast-from-a-video-using-opencv-and-python-73b9b7dc9661
 # All cred to Hayden Faulkner, ta!
 
-from concurrent.futures import ProcessPoolExecutor, as_completed
+from concurrent.futures import ProcessPoolExecutor
 import cv2
 import multiprocessing
 import os
 
 def extract_frames(video_filename, frames_dir, overwrite=True, start=-1, end=-1, every=1):
     capture = cv2.VideoCapture(video_filename)
     if start < 0:
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/utils/.DS_Store` & `Simba-UW-tf-dev-1.57.6/simba/utils/.DS_Store`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/utils/warnings.py` & `Simba-UW-tf-dev-1.57.6/simba/utils/warnings.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/utils/lookups.py` & `Simba-UW-tf-dev-1.57.6/simba/utils/lookups.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,23 +1,15 @@
 import os, glob
 import pandas as pd
 import re
-from simba.enums import Paths, Methods
-from simba.read_config_unit_tests import check_file_exist_and_readable, check_if_dir_exists
-from simba.feature_extractors.feature_extractor_16bp import ExtractFeaturesFrom16bps
-from simba.feature_extractors.feature_extractor_14bp import ExtractFeaturesFrom14bps
-from simba.feature_extractors.extract_features_9bp import extract_features_wotarget_9
-from simba.feature_extractors.feature_extractor_8bp import ExtractFeaturesFrom8bps
-from simba.feature_extractors.feature_extractor_8bps_2_animals import ExtractFeaturesFrom8bps2Animals
-from simba.feature_extractors.feature_extractor_7bp import ExtractFeaturesFrom7bps
-from simba.feature_extractors.feature_extractor_4bp import ExtractFeaturesFrom4bps
-from simba.feature_extractors.feature_extractor_user_defined import UserDefinedFeatureExtractor
-from simba.misc_tools import get_fn_ext
 import struct
 import simba
+from simba.enums import Paths, Methods
+from simba.utils.checks import check_file_exist_and_readable, check_if_dir_exists
+from simba.utils.read_write import get_fn_ext
 
 
 def get_body_part_configurations() -> dict:
 
     """Helper to return dict with named body-part schematics of pose-estimation schemas in SimBA installation as keys,
     and paths to the images representing those body-part schematics as values.
     """
@@ -49,17 +41,25 @@
             'Multi-animals; 4 body-parts': '8',
             'Multi-animals; 7 body-parts': '14',
             'Multi-animals; 8 body-parts': '16',
             '3D tracking': '3D_user_defined'}
 
 
 def get_bp_config_code_class_pairs() -> dict:
+    from simba.feature_extractors.feature_extractor_16bp import ExtractFeaturesFrom16bps
+    from simba.feature_extractors.feature_extractor_14bp import ExtractFeaturesFrom14bps
+    from simba.feature_extractors.feature_extractor_9bp import ExtractFeaturesFrom9bps
+    from simba.feature_extractors.feature_extractor_8bp import ExtractFeaturesFrom8bps
+    from simba.feature_extractors.feature_extractor_8bps_2_animals import ExtractFeaturesFrom8bps2Animals
+    from simba.feature_extractors.feature_extractor_7bp import ExtractFeaturesFrom7bps
+    from simba.feature_extractors.feature_extractor_4bp import ExtractFeaturesFrom4bps
+    from simba.feature_extractors.feature_extractor_user_defined import UserDefinedFeatureExtractor
     return {'16': ExtractFeaturesFrom16bps,
             '14': ExtractFeaturesFrom14bps,
-            '9': extract_features_wotarget_9,
+            '9': ExtractFeaturesFrom9bps,
             '8': {1: ExtractFeaturesFrom8bps, 2: ExtractFeaturesFrom8bps2Animals},
             '7': ExtractFeaturesFrom7bps,
             '4': ExtractFeaturesFrom4bps,
             'user_defined': UserDefinedFeatureExtractor}
 
 
 def get_icons_paths() -> dict:
@@ -113,21 +113,76 @@
             "over_sample_setting",
             "train_test_size",
             "train_test_split_type",
             "under_sample_ratio",
             "under_sample_setting",
             "class_weight"]
 
-
 def get_cmaps() -> list:
     return ['spring',
             'summer',
             'autumn',
             'cool',
             'Wistia',
             'Pastel1',
             'Set1',
             'winter',
             'afmhot',
             'gist_heat',
             'copper']
 
+def get_color_dict() -> dict:
+    return {'Grey': (220, 200, 200),
+            'Red': (0, 0, 255),
+            'Dark-red': (0, 0, 139),
+            'Maroon': (0, 0, 128),
+            'Orange': (0, 165, 255),
+            'Dark-orange': (0, 140, 255),
+            'Coral': (80, 127, 255),
+            'Chocolate': (30, 105, 210),
+            'Yellow': (0, 255, 255),
+            'Green': (0, 128, 0),
+            'Dark-grey': (105, 105, 105),
+            'Light-grey': (192, 192, 192),
+            'Pink': (178, 102, 255),
+            'Lime': (204, 255, 229),
+            'Purple': (255, 51, 153),
+            'Cyan': (255, 255, 102),
+            'White': (255, 255, 255),
+            'Black': (0, 0, 0),
+            'Darkgoldenrod': (184, 134, 11),
+            'Olive': (109,113,46),
+            'Seagreen': (46, 139, 87),
+            'Dodgerblue': (30, 144, 255),
+            'Springgreen': (0, 255, 127),
+            'Firebrick': (178, 34, 34),
+            'Indigo': (63, 15, 183)}
+
+def get_named_colors() -> list:
+    return ['red',
+            'black',
+            'green',
+            'pink',
+            'orange',
+            'blue',
+            'purple',
+            'lavender',
+            'grey',
+            'sienna',
+            'tomato',
+            'azure',
+            'crimson',
+            'aqua',
+            'plum',
+            'teal',
+            'maroon',
+            'lime',
+            'coral',
+            'deeppink',
+            'darkgoldenrod',
+            'olive',
+            'seagreen',
+            'dodgerblue',
+            'springgreen',
+            'firebrick',
+            'indigo'
+            'white']
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/utils/errors.py` & `Simba-UW-tf-dev-1.57.6/simba/utils/errors.py`

 * *Files 1% similar despite different names*

```diff
@@ -15,15 +15,15 @@
         return self.msg
 
     def print_msg(self, msg):
         print(f'{msg}{Defaults.STR_SPLIT_DELIMITER.value}{TagNames.ERROR.value}')
 
 
 class NoSpecifiedOutputError(SimbaError):
-    def __init__(self, msg: str, show_window: bool = False):
+    def __init__(self, msg: str, show_window: bool = True):
         super().__init__(msg=msg, show_window=show_window)
         self.print_msg(msg=f'SIMBA NO SPECIFIED OUTPUT ERROR: {msg}')
 
 class ROICoordinatesNotFoundError(SimbaError):
     def __init__(self, expected_file_path: str, show_window: bool = False):
         msg = f'No ROI coordinates found. Please use the [ROI] tab to define ROIs. Expected at location {expected_file_path}'
         super().__init__(msg=msg, show_window=show_window)
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/labelling_interface.py` & `Simba-UW-tf-dev-1.57.6/simba/labelling_interface.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,34 +1,25 @@
 __author__ = "Simon Nilsson"
 
-import time
-
 import cv2
 import pandas as pd
-from simba.rw_dfs import read_df, save_df
-from simba.read_config_unit_tests import (read_config_entry,
-                                          read_config_file,
-                                          check_file_exist_and_readable,
-                                          check_int,
-                                          check_float,
-                                          read_project_path_and_file_type)
-from simba.misc_tools import get_video_meta_data, get_fn_ext
-from simba.utils.printing import stdout_success
-from simba.enums import ReadConfig, Paths, Dtypes
-import simba
 from tkinter import *
 from tkinter import filedialog
 from PIL import Image, ImageTk
 from subprocess import Popen, PIPE
 import os
-from simba.train_model_functions import get_all_clf_names
 from tabulate import tabulate
 from simba.utils.errors import FrameRangeError
+from simba.mixins.config_reader import ConfigReader
+from simba.utils.read_write import read_config_entry, read_df, write_df, get_fn_ext, get_video_meta_data
+from simba.utils.checks import check_file_exist_and_readable, check_int, check_float
+from simba.utils.printing import stdout_success
+import simba
 
-class LabellingInterface(object):
+class LabellingInterface(ConfigReader):
     """
     Class for launching ``standard`` and ``pseudo``-labelling (annotation) GUI interface in SimBA.
 
     Parameters
     ----------
     config_path: str
         path to SimBA project config file in Configparser format
@@ -55,35 +46,29 @@
     def __init__(self,
                  config_path: str=None,
                  file_path: str=None,
                  setting: str = 'pseudo',  # from_scratch, #pseudo
                  threshold_dict: dict=None,
                  continuing: bool=False):
 
+        ConfigReader.__init__(self, config_path=config_path)
         self.padding, self.file_path = 5, file_path
         self.frm_no, self.threshold_dict = 0, threshold_dict
-        self.config_path, self.setting = config_path, setting
-        self.config = read_config_file(config_path)
+        self.setting = setting
         self.play_video_script_path = os.path.join(os.path.dirname(simba.__file__), 'play_annotation_video.py')
-        self.project_path, self.file_type = read_project_path_and_file_type(config=self.config)
-        self.target_cnt = read_config_entry(self.config, ReadConfig.SML_SETTINGS.value, ReadConfig.TARGET_CNT.value, Dtypes.INT.value)
-        self.videos_dir_path = os.path.join(self.project_path, 'videos')
         _, self.video_name, _ = get_fn_ext(filepath=file_path)
-        self.features_extracted_folder = os.path.join(self.project_path, Paths.FEATURES_EXTRACTED_DIR.value)
-        self.targets_inserted_folder = os.path.join(self.project_path, Paths.TARGETS_INSERTED_DIR.value)
-        self.machine_results_folder = os.path.join(self.project_path, Paths.MACHINE_RESULTS_DIR.value)
-        self.features_extracted_file_path = os.path.join(self.features_extracted_folder, self.video_name + '.' + self.file_type)
-        self.targets_inserted_file_path = os.path.join(self.targets_inserted_folder, self.video_name + '.' + self.file_type)
-        self.machine_results_file_path = os.path.join(self.machine_results_folder, self.video_name + '.' + self.file_type)
+        self.features_extracted_file_path = os.path.join(self.features_dir, self.video_name + '.' + self.file_type)
+        self.targets_inserted_file_path = os.path.join(self.targets_folder, self.video_name + '.' + self.file_type)
+        self.machine_results_file_path = os.path.join(self.machine_results_dir, self.video_name + '.' + self.file_type)
         self.video_path = file_path
         self.cap = cv2.VideoCapture(self.video_path)
         self.video_meta_data = get_video_meta_data(video_path=self.video_path)
         self.frame_lst = list(range(0, self.video_meta_data['frame_count']))
         self.max_frm_no = max(self.frame_lst)
-        self.target_lst = get_all_clf_names(config=self.config, target_cnt=self.target_cnt)
+        self.target_lst = self.get_all_clf_names()
         self.max_frm_size = 1080, 650
         self.main_window = Toplevel()
         if continuing:
             check_file_exist_and_readable(file_path=self.targets_inserted_file_path)
             check_file_exist_and_readable(file_path=self.features_extracted_file_path)
             self.data_df = read_df(self.targets_inserted_file_path, self.file_type)
             self.data_df_features = read_df(self.features_extracted_file_path, self.file_type)
@@ -293,15 +278,15 @@
     def save_behavior_in_frm(self, frame_number=None, target=None):
         self.data_df_targets[target].loc[int(self.current_frm_n.get())] = self.checkboxes[target]['var'].get()
 
     def __save_results(self):
         self.save_df = read_df(self.features_extracted_file_path, self.file_type)
         self.save_df = pd.concat([self.save_df, self.data_df_targets], axis=1)
         try:
-            save_df(self.save_df, self.file_type, self.targets_inserted_file_path)
+            write_df(self.save_df, self.file_type, self.targets_inserted_file_path)
         except Exception as e:
             print(e, 'SIMBA ERROR: File for video {} could not be saved.')
             raise FileExistsError
         stdout_success(msg=f'SAVED: Annotation file for video {self.video_name} saved within the project_folder/csv/targets_inserted directory.')
         if not self.config.has_section('Last saved frames'):
             self.config.add_section('Last saved frames')
         self.config.set('Last saved frames', str(self.video_name), str(self.current_frm_n.get()))
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/timebins_movement_analyzer.py` & `Simba-UW-tf-dev-1.57.6/simba/timebins_movement_analyzer.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,29 +1,22 @@
 __author__ = "Simon Nilsson"
 
 import pandas as pd
-from simba.read_config_unit_tests import (read_config_entry,
-                                          check_that_column_exist,
-                                          check_if_filepath_list_is_empty)
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.misc_tools import (SimbaTimer,
-                              framewise_euclidean_distance)
-from simba.utils.printing import stdout_success
-from simba.enums import (ReadConfig,
-                         Dtypes)
-from simba.drop_bp_cords import create_body_part_dictionary, getBpNames
-import os, glob
-from simba.rw_dfs import read_df
-from simba.drop_bp_cords import get_fn_ext
 import seaborn as sns
 import matplotlib.pyplot as plt
 import itertools
+import os, glob
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.enums import ReadConfig, Dtypes
+from simba.utils.checks import check_that_column_exist, check_if_filepath_list_is_empty, check_int
+from simba.utils.read_write import get_fn_ext, read_df, read_config_entry
 from simba.mixins.config_reader import ConfigReader
+from simba.mixins.feature_extraction_mixin import FeatureExtractionMixin
 
-class TimeBinsMovementAnalyzer(ConfigReader):
+class TimeBinsMovementAnalyzer(ConfigReader, FeatureExtractionMixin):
     """
     Class for calculating and aggregating movement statistics into user-defined time-bins.
 
     Parameters
     ----------
     config_path: str
         path to SimBA project config file in Configparser format
@@ -39,33 +32,30 @@
     """
 
     def __init__(self,
                  config_path: str,
                  bin_length: int,
                  plots: bool):
 
-        super().__init__(config_path=config_path)
+        ConfigReader.__init__(self, config_path=config_path)
         self.bin_length, self.plots = bin_length, plots
+        check_int(name='TIME BIN', value=bin_length, min_value=1)
         self.col_headers = []
         for animal_no in range(self.animal_cnt):
             animal_bp = read_config_entry(self.config, ReadConfig.PROCESS_MOVEMENT_SETTINGS.value, 'animal_{}_bp'.format(str(animal_no + 1)), Dtypes.STR.value)
             self.col_headers.extend((animal_bp + '_x', animal_bp + '_y'))
 
-        self.x_cols, self.y_cols, self.p_cols = getBpNames(config_path)
-        self.x_cols = [x for x in self.x_cols if x in self.col_headers]
-        self.y_cols = [x for x in self.y_cols if x in self.col_headers]
-        self.files_found = glob.glob(self.outlier_corrected_dir + '/*.' + self.file_type)
-        check_if_filepath_list_is_empty(filepaths=self.files_found,
+        check_if_filepath_list_is_empty(filepaths=self.outlier_corrected_paths,
                                         error_msg=f'SIMBA ERROR: Cannot analyze movement in time-bins, data directory {self.outlier_corrected_dir} is empty.')
-        self.animal_bp_dict = create_body_part_dictionary(self.multi_animal_status, self.multi_animal_id_list, self.animal_cnt, self.x_cols, self.y_cols, [], [])
         self.animal_combinations = list(itertools.combinations(self.animal_bp_dict, 2))
-        print('Processing {} video(s)...'.format(str(len(self.files_found))))
+        print('Processing {} video(s)...'.format(str(len(self.outlier_corrected_paths))))
 
     def __create_plots(self):
         print('Creating time-bin movement plots...')
+        sns.set_style("whitegrid", {'grid.linestyle': '--'})
         self.video_df['Time bin #'] = self.video_df['Time bin #'].astype(str)
         plots_dir = os.path.join(self.project_path, 'logs', f'time_bin_movement_plots_{self.datetime}')
         if not os.path.exists(plots_dir): os.makedirs(plots_dir)
         for video_name in self.video_df.index.unique():
             video_df = self.video_df[self.video_df.index == video_name].reset_index(drop=True)
             video_movement_df = video_df[video_df['Measurement'].isin(list(self.movement_cols))]
             line_plot = sns.lineplot(data=video_movement_df, x="Time bin #", y="Value", hue='Measurement')
@@ -79,22 +69,21 @@
         of the SimBA project.
 
         Returns
         ----------
         None
         """
         video_dict, self.out_df_lst = {}, []
-        for file_cnt, file_path in enumerate(self.files_found):
-            video_timer = SimbaTimer()
-            video_timer.start_timer()
+        for file_cnt, file_path in enumerate(self.outlier_corrected_paths):
+            video_timer = SimbaTimer(start=True)
             _, video_name, _ = get_fn_ext(file_path)
-            print(f'Processing time-bin movements for video {video_name} ({str(file_cnt+1)}/{str(len(self.files_found))})...')
+            print(f'Processing time-bin movements for video {video_name} ({str(file_cnt+1)}/{str(len(self.outlier_corrected_paths))})...')
             result_df = pd.DataFrame()
             video_dict[video_name] = {}
-            video_settings, px_per_mm, fps = read_video_info(vid_info_df=self.video_info_df, video_name=video_name)
+            video_settings, px_per_mm, fps = self.read_video_info(video_name=video_name)
             fps, self.movement_cols, self.velocity_cols = int(fps), set(), set()
             bin_length_frames = int(fps * self.bin_length)
             data_df = read_df(file_path, self.file_type)
             data_df_sliced = pd.DataFrame()
             for animal, data in self.animal_bp_dict.items():
                 check_that_column_exist(df=data_df, column_name=data['X_bps'][0], file_name=file_path)
                 check_that_column_exist(df=data_df, column_name=data['Y_bps'][0], file_name=file_path)
@@ -103,23 +92,23 @@
             data_df_shifted = data_df.shift(periods=1).add_suffix('_shifted').fillna(0)
             data_df = pd.concat([data_df_sliced, data_df_shifted], axis=1, join='inner').fillna(0).reset_index(drop=True)
             for animal, data in self.animal_bp_dict.items():
                 movement_col_name = 'Movement {}'.format(animal)
                 x_col, y_col = data['X_bps'][0], data['Y_bps'][0]
                 bp_time_1 = data_df[[x_col, y_col]].values
                 bp_time_2 = data_df[[x_col + '_shifted', y_col + '_shifted']].values
-                result_df[movement_col_name] = pd.Series(framewise_euclidean_distance(location_1=bp_time_1, location_2=bp_time_2, px_per_mm=px_per_mm, centimeter=True))
+                result_df[movement_col_name] = pd.Series(self.framewise_euclidean_distance(location_1=bp_time_1, location_2=bp_time_2, px_per_mm=px_per_mm, centimeter=True))
                 result_df.loc[0, movement_col_name] = 0
             for animal_c in self.animal_combinations:
                 distance_col_name = 'Distance {} {}'.format(animal_c[0], animal_c[1])
                 bp_1_x, bp_1_y = self.animal_bp_dict[animal_c[0]]['X_bps'][0], self.animal_bp_dict[animal_c[0]]['Y_bps'][0]
                 bp_2_x, bp_2_y = self.animal_bp_dict[animal_c[0]]['X_bps'][0], self.animal_bp_dict[animal_c[1]]['Y_bps'][0]
                 bp_1 = data_df[[bp_1_x, bp_1_y]].values.astype(float)
                 bp_2 = data_df[[bp_2_x, bp_2_y]].values.astype(float)
-                result_df[distance_col_name] = pd.Series(framewise_euclidean_distance(location_1=bp_1, location_2=bp_2, px_per_mm=px_per_mm))
+                result_df[distance_col_name] = pd.Series(self.framewise_euclidean_distance(location_1=bp_1, location_2=bp_2, px_per_mm=px_per_mm))
             results_df_lists = [result_df[i:i + bin_length_frames] for i in range(0, result_df.shape[0], bin_length_frames)]
             indexed_df_lst = []
             for bin, results in enumerate(results_df_lists):
                 time_bin_per_s = [results[i:i + fps] for i in range(0, results.shape[0], fps)]
                 for second, df in enumerate(time_bin_per_s):
                     df['Time bin #'], df['Second'] = bin, second
                     indexed_df_lst.append(df)
@@ -152,14 +141,14 @@
             self.__create_plots()
 
         save_path = os.path.join(self.project_path, 'logs', 'Time_bins_movement_results_' + self.datetime + '.csv')
         self.video_df.to_csv(save_path)
         self.timer.stop_timer()
         stdout_success(msg=f'Movement time-bins results saved at {save_path}', elapsed_time=self.timer.elapsed_time_str)
 
-# test = TimeBinsMovementAnalyzer(config_path='/Users/simon/Desktop/envs/troubleshooting/Vince_time_bins/project_folder/project_config.ini',
+# test = TimeBinsMovementAnalyzer(config_path='/Users/simon/Desktop/envs/troubleshooting/naresh/project_folder/project_config.ini',
 #                                 bin_length=60, plots=True)
 # test.analyze_movement()
 
 # test = TimeBinsMovementAnalyzer(config_path='/Users/simon/Desktop/envs/troubleshooting/Two_animals_16bps/project_folder/project_config.ini',
 #                                 bin_length=1, plots=True)
 # test.analyze_movement()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/train_model_functions.py` & `Simba-UW-tf-dev-1.57.6/simba/mixins/train_model_mixin.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,1099 +1,1205 @@
-__author__ = "Simon Nilsson"
-
-import os
-import numpy as np
-import pandas as pd
-from sklearn.inspection import partial_dependence
-from simba.rw_dfs import read_df
-from simba.misc_tools import get_fn_ext
-from imblearn.combine import SMOTEENN
-from imblearn.over_sampling import SMOTE
-from sklearn.inspection import permutation_importance
-from sklearn.model_selection import learning_curve
-from sklearn.model_selection import ShuffleSplit
-from sklearn.metrics import precision_recall_curve
-from sklearn.ensemble import RandomForestClassifier
-from copy import deepcopy
-from sklearn.tree import export_graphviz
-from subprocess import call
-from yellowbrick.classifier import ClassificationReport
-import shap
-from tabulate import tabulate
-from simba.plotting.shap_agg_stats_visualizer import ShapAggregateStatisticsVisualizer
-from simba.read_config_unit_tests import (check_int, check_str, check_if_dir_exists,
-                                          check_float,
-                                          read_config_entry)
-from concurrent.futures import ProcessPoolExecutor
-from concurrent.futures.process import BrokenProcessPool
-from itertools import repeat
-from simba.misc_tools import (create_single_color_lst,
-                              SimbaTimer,
-                              detect_bouts,
-                              find_core_cnt)
-from simba.utils.errors import (ColumnNotFoundError,
-                                FaultyTrainingSetError,
-                                MissingColumnsError,
-                                NoDataError,
-                                SamplingError,
-                                CorruptedFileError,
-                                FeatureNumberMismatchError,
-                                ClassifierInferenceError,
-                                CountError)
-from simba.utils.warnings import (NotEnoughDataWarning,
-                                  NoModuleWarning,
-                                  MissingUserInputWarning)
-from simba.utils.printing import stdout_success
-from simba.utils.lookups import get_meta_data_file_headers
-import configparser
-import platform
-from sklearn.utils import parallel_backend
-import pickle
-from dtreeviz.trees import tree, dtreeviz
-import matplotlib.pyplot as plt
-from simba.enums import ReadConfig, Dtypes, MetaKeys
-import multiprocessing
-plt.switch_backend('agg')
-
-def read_all_files_in_folder(file_paths: list,
-                             file_type: str,
-                             classifier_names=None):
-    """
-
-    Helper function to read in all data files in a folder to a single pd.DataFrame for downstream ML algorithm.
-    Asserts that all classifiers have annotation fields present in concatenated dataframes.
-
-    Parameters
-    ----------
-    file_paths: list
-        List of file paths representing files to be read in.
-    file_type: str
-        Type of files in ``file_paths``. OPTIONS: csv or parquet.
-    classifier_names: list or None
-        List of classifier names representing fields of human annotations. If not None, then assert that classifier names
-        are present in each data file.
-
-    Returns
-    -------
-    df_concat: pd.DataFrame
-
-    """
-
-    timer = SimbaTimer()
-    timer.start_timer()
-    df_concat = pd.DataFrame()
-    for file_cnt, file in enumerate(file_paths):
-        print(f'Reading in file {str(file_cnt+1)}/{str(len(file_paths))}...')
-        _, vid_name, _ = get_fn_ext(file)
-        df = read_df(file, file_type).dropna(axis=0, how='all').fillna(0).astype(np.float16)
-        if classifier_names != None:
-            for clf_name in classifier_names:
-                if not clf_name in df.columns:
-                    raise MissingColumnsError(msg=f'Data for video {vid_name} does not contain any annotations for behavior {clf_name}. Delete classifier {clf_name} from the SimBA project, or add annotations for behavior {clf_name} to the video {vid_name}')
-                else:
-                    df_concat = pd.concat([df_concat, df], axis=0).astype(np.float16)
-        else:
-            df_concat = pd.concat([df_concat, df], axis=0).astype(np.float16)
-    try:
-        df_concat = df_concat.set_index('scorer').astype(np.float16)
-    except KeyError:
-        pass
-    if len(df_concat) == 0:
-        raise NoDataError(msg='SimBA found 0 annotated frames in the project_folder/csv/targets_inserted directory')
-    df_concat = df_concat.loc[:, ~df_concat.columns.str.contains('^Unnamed')].astype(np.float16)
-    timer.stop_timer()
-    data_size = df_concat.memory_usage(index=True).sum()
-    print(f'Dataset size: {round(data_size / 1000000, 6)}MB / {round(data_size / 1000000000, 6)}GB')
-    print('{} file(s) read (elapsed time: {}s) ...'.format(str(len(file_paths)), timer.elapsed_time_str))
-    return df_concat.reset_index(drop=True).astype(np.float16)
-
-
-def read_in_all_model_names_to_remove(config, model_cnt, clf_name):
-    """
-    Helper to find all field names that contain annotations but are not the target.
-
-    Parameters
-    ----------
-    config: Configparser,
-        Configparser object holding data from the project_config.ini
-    model_cnt: int,
-        Number of classifiers in the SimBA project.
-    clf_name
-        Name of the classifier.
-
-    Returns
-    -------
-    annotation_cols_to_remove: list
-    """
-
-    annotation_cols_to_remove = []
-    for model_no in range(model_cnt):
-        model_name = config.get(ReadConfig.SML_SETTINGS.value, 'target_name_' + str(model_no+1))
-        if model_name != clf_name:
-            annotation_cols_to_remove.append(model_name)
-    return annotation_cols_to_remove
-
-def delete_other_annotation_columns(df: pd.DataFrame,
-                                    annotations_lst: list):
-    """
-    Helper to delete fields that contain annotations which are not the target.
-
-    Parameters
-    ----------
-    df: pd.DataFrame
-        pandas Dataframe holding features and annotations.
-    annotations_lst: list
-        Column fields to be removed from df
-
-    Returns
-    -------
-    df: pd.DataFrame
-    """
-
-    for a_col in annotations_lst:
-        df = df.drop([a_col], axis=1)
-    return df
-
-def split_df_to_x_y(df: pd.DataFrame,
-                    clf_name: str):
-    """
-    Helper to split dataframe into features and target.
-
-    Parameters
-    ----------
-    df: pd.DataFrame
-        pandas Dataframe holding features and annotations.
-    clf_name: str
-        Name of target.
-
-    Returns
-    -------
-    df: pd.DataFrame
-    y: pd.DataFrame
-    """
-
-    df = deepcopy(df)
-    y = df.pop(clf_name)
-    return df, y
-
-def random_undersampler(x_train: np.array,
-                        y_train: np.array,
-                        sample_ratio: float):
-    """
-    Helper to perform random undersampling of behavior-absent frames in a dataframe.
-
-    Parameters
-    ----------
-    x_train: pd.DataFrame
-        Features in train set
-    y_train: pd.DataFrame
-        Target in train set
-    sample_ratio: float,
-        Ratio of behavior-absent frames to keep relative to the behavior-present frames. E.g., ``1.0`` returns an equal
-        count of behavior-absent and behavior-present frames. ``2.0`` returns twice as many behavior-absent frames as
-        and behavior-present frames.
-
-    Returns
-    -------
-    df: pd.DataFrame
-    """
-
-    print(f'Performing under-sampling at sample ratio {str(sample_ratio)}...')
-    data_df = pd.concat([x_train, y_train], axis=1)
-    present_df, absent_df = data_df[data_df[y_train.name] == 1], data_df[data_df[y_train.name] == 0]
-    ratio_n = int(len(present_df) * sample_ratio)
-    if len(absent_df) < ratio_n:
-        raise SamplingError(msg=f'SIMBA UNDER SAMPLING ERROR: The under-sample ratio of {str(sample_ratio)} in classifier {y_train.name} demands {str(ratio_n)} behavior-absent annotations. This is more than the number of behavior-absent annotations in the entire dataset {str(len(absent_df))}. Please annotate more images or decrease the under-sample ratio.')
-    data_df = pd.concat([present_df, absent_df.sample(n=ratio_n, replace=False)], axis=0)
-    return split_df_to_x_y(data_df, y_train.name)
-
-def smoteen_oversampler(x_train: pd.DataFrame,
-                        y_train: pd.DataFrame,
-                        sample_ratio: float):
-
-    """
-    Helper to perform smoteen oversampling of behavior-present frames in a dataframe
-
-    Parameters
-    ----------
-    x_train: pd.DataFrame or array
-        pandas Dataframe holding features and annotations.
-    y_train: pd.DataFrame or array
-        List of column fields to be removed from df
-    sample_ratio:
-        New behavior-present frames.
-
-    Returns
-    -------
-    x_train: array
-    y_train: array
-
-    """
-
-    print('Performing SMOTEEN oversampling...')
-    smt = SMOTEENN(sampling_strategy=sample_ratio)
-    return smt.fit_sample(x_train, y_train)
-
-def smote_oversampler(x_train, y_train, sample_ratio):
-    """
-    Helper to perform smote oversampling of behavior-present frames in a dataframe
-
-    Parameters
-    ----------
-    x_train: pd.DataFrame or np.array
-        pandas Dataframe holding features and annotations.
-    y_train: pd.DataFrame or np.array
-        List of column fields to be removed from df
-    sample_ratio:
-        New behavior-present frames.
-
-    Returns
-    -------
-    x_train: np.array
-    y_train: np.array
-
-    """
-    print('Performing SMOTE oversampling...')
-    smt = SMOTE(sampling_strategy=sample_ratio)
-    return smt.fit_sample(x_train, y_train)
-
-def calc_permutation_importance(x_test: np.array,
-                                y_test: np.array,
-                                clf: RandomForestClassifier,
-                                feature_names: list,
-                                clf_name: str,
-                                save_dir: str,
-                                save_file_no=None):
-    """
-    Helper to calculate feature permutation importance scores.
-
-    Parameters
-    ----------
-    x_test: np.array,
-        Array holding feature test data
-    y_test: np.array
-        Array holding target test data
-    clf: object
-        sklearn RandomForestClassifier object
-    feature_names: list,
-        list of feature names
-    clf_name: str,
-        Name of classifier
-    save_dir: str,
-        Directory where to save output in csv file format.
-    save_file_no: int or None.
-        If integer, represents the count of the classifier within a grid search. If none, the classifier is not
-        part of a grid search.
-
-    Returns
-    -------
-    None
-
-    """
-    print('Calculating feature permutation importances...')
-    timer = SimbaTimer()
-    timer.start_timer()
-    p_importances = permutation_importance(clf, x_test, y_test, n_repeats=10, random_state=0)
-    df = pd.DataFrame(np.column_stack([feature_names, p_importances.importances_mean, p_importances.importances_std]), columns=['FEATURE_NAME', 'FEATURE_IMPORTANCE_MEAN', 'FEATURE_IMPORTANCE_STDEV'])
-    df = df.sort_values(by=['FEATURE_IMPORTANCE_MEAN'], ascending=False)
-    if save_file_no != None:
-        save_file_path = os.path.join(save_dir, clf_name + '_' + str(save_file_no+1) +'_permutations_importances.csv')
-    else:
-        save_file_path = os.path.join(save_dir, clf_name + '_permutations_importances.csv')
-    df.to_csv(save_file_path, index=False)
-    timer.stop_timer()
-    print('Permutation importance calculation complete (elapsed time: {}s) ...'.format(timer.elapsed_time_str))
-
-def calc_learning_curve(x_y_df: pd.DataFrame,
-                  clf_name: str,
-                  shuffle_splits: int,
-                  dataset_splits: int,
-                  tt_size: float,
-                  rf_clf: RandomForestClassifier,
-                  save_dir: str,
-                  save_file_no=None):
-    """
-    Helper to compute random forest learning curves with cross-validation.
-
-    Parameters
-    ----------
-    x_y_df: pd.DataFrame
-        Pandas dataframe holding features and targets.
-    clf_name: str,
-        Name of the classifier
-    shuffle_splits: int
-        Number of cross-validation datasets at each data split.
-    dataset_splits: int
-        Number of data splits.
-    tt_size: float
-        dataset test size.
-    rf_clf: RandomForestClassifier
-        sklearn RandomForestClassifier object.
-    save_dir: str,
-        Directory where to save output in csv file format.
-    save_file_no: int or None.
-        If integer, represents the count of the classifier within a grid search. If none, the classifier is not
-        part of a grid search.
-
-    Returns
-    -------
-    None
-
-    """
-
-    print('Calculating learning curves...')
-    timer = SimbaTimer()
-    timer.start_timer()
-    x_df, y_df = split_df_to_x_y(x_y_df, clf_name)
-    cv = ShuffleSplit(n_splits=shuffle_splits, test_size=tt_size)
-    if platform.system() == "Darwin":
-        with parallel_backend("threading", n_jobs=-2):
-            train_sizes, train_scores, test_scores = learning_curve(estimator=rf_clf, X=x_df, y=y_df, cv=cv,scoring='f1', shuffle=False, verbose=0, train_sizes=np.linspace(0.01, 1.0, dataset_splits), error_score='raise')
-    else:
-        train_sizes, train_scores, test_scores = learning_curve(estimator=rf_clf, X=x_df, y=y_df, cv=cv, scoring='f1', shuffle=False, n_jobs=-1, verbose=0, train_sizes=np.linspace(0.01, 1.0, dataset_splits), error_score='raise')
-    results_df = pd.DataFrame()
-    results_df['FRACTION TRAIN SIZE'] = np.linspace(0.01, 1.0, dataset_splits)
-    results_df['TRAIN_MEAN_F1'] = np.mean(train_scores, axis=1)
-    results_df['TEST_MEAN_F1'] = np.mean(test_scores, axis=1)
-    results_df['TRAIN_STDEV_F1'] = np.std(train_scores, axis=1)
-    results_df['TEST_STDEV_F1'] = np.std(test_scores, axis=1)
-    if save_file_no != None:
-        save_file_path = os.path.join(save_dir, clf_name + '_' + str(save_file_no+1) +'_learning_curve.csv')
-    else:
-        save_file_path = os.path.join(save_dir, clf_name + '_learning_curve.csv')
-    results_df.to_csv(save_file_path, index=False)
-    timer.stop_timer()
-    print('Learning curve calculation complete (elapsed time: {}s) ...'.format(timer.elapsed_time_str))
-
-
-def calc_pr_curve(rf_clf,
-                  x_df,
-                  y_df,
-                  clf_name,
-                  save_dir,
-                  save_file_no=None):
-    """
-    Helper to compute random forest precision-recall curve.
-
-    Parameters
-    ----------
-    rf_clf: RandomForestClassifier
-        sklearn RandomForestClassifier object.
-    x_df: pd.DataFrame
-        Pandas dataframe holding test features.
-    y_df: pd.DataFrame
-        Pandas dataframe holding test target.
-    clf_name: str
-        Classifier name.
-    save_dir: str,
-        Directory where to save output in csv file format.
-    save_file_no: int or None.
-        If integer, represents the count of the classifier within a grid search. If none, the classifier is not
-        part of a grid search.
-
-    Returns
-    -------
-    None
-
-    """
-
-    print('Calculating PR curves...')
-    timer = SimbaTimer()
-    timer.start_timer()
-    p = rf_clf.predict_proba(x_df)[:, 1]
-    precision, recall, thresholds = precision_recall_curve(y_df, p, pos_label=1)
-    pr_df = pd.DataFrame()
-    pr_df['PRECISION'] = precision
-    pr_df['RECALL'] = recall
-    pr_df['F1'] = 2 * pr_df['RECALL'] * pr_df['PRECISION'] / (pr_df['RECALL'] + pr_df['PRECISION'])
-    thresholds = list(thresholds)
-    thresholds.insert(0, 0.00)
-    pr_df['DISCRIMINATION THRESHOLDS'] = thresholds
-    if save_file_no != None:
-        save_file_path = os.path.join(save_dir, clf_name + '_' + str(save_file_no+1) +'_pr_curve.csv')
-    else:
-        save_file_path = os.path.join(save_dir, clf_name + '_pr_curve.csv')
-    pr_df.to_csv(save_file_path, index=False)
-    timer.stop_timer()
-    print('Precision-recall curve calculation complete (elapsed time: {}s) ...'.format(timer.elapsed_time_str))
-
-
-def create_example_dt(rf_clf: RandomForestClassifier,
-                      clf_name: str,
-                      feature_names: list,
-                      class_names: list,
-                      save_dir: str,
-                      save_file_no=None):
-    """
-    Helper to produce visualization of random forest decision tree.
-
-    Parameters
-    ----------
-    rf_clf: RandomForestClassifier
-        sklearn RandomForestClassifier object.
-    clf_name: str
-        Classifier name.
-    feature_names: list
-        List of feature names.
-    class_names
-        List of classes. E.g., ['Attack absent', 'Attack present']
-    save_dir: str,
-        Directory where to save output in csv file format.
-    save_file_no: int or None.
-        If integer, represents the count of the classifier within a grid search. If none, the classifier is not
-        part of a grid search.
-
-    Returns
-    -------
-    None
-    """
-
-    print('Visualizing example decision tree using graphviz...')
-    estimator = rf_clf.estimators_[3]
-    if save_file_no != None:
-        dot_name = os.path.join(save_dir, str(clf_name) + '_' + str(save_file_no) + '_tree.dot')
-        file_name = os.path.join(save_dir, str(clf_name) + '_' + str(save_file_no) +'_tree.pdf')
-    else:
-        dot_name = os.path.join(save_dir, str(clf_name) + '_tree.dot')
-        file_name = os.path.join(save_dir, str(clf_name) + '_tree.pdf')
-    export_graphviz(estimator, out_file=dot_name, filled=True, rounded=True, special_characters=False, impurity=False, class_names=class_names, feature_names=feature_names)
-    command = ('dot ' + str(dot_name) + ' -T pdf -o ' + str(file_name) + ' -Gdpi=600')
-    call(command, shell=True)
-
-
-def create_clf_report(rf_clf,
-                      x_df,
-                      y_df,
-                      class_names,
-                      save_dir,
-                      save_file_no=None):
-    """
-    Helper to create classifier truth table report.
-
-    Parameters
-    ----------
-    rf_clf: RandomForestClassifier
-        sklearn RandomForestClassifier object.
-    x_df: pd.DataFrame
-        Pandas dataframe holding test features.
-    y_df: pd.DataFrame
-        Pandas dataframe holding test target.
-    class_names: list
-        List of classes. E.g., ['Attack absent', 'Attack present']
-    save_dir: str,
-        Directory where to save output in csv file format.
-    save_file_no: int or None.
-        If integer, represents the count of the classifier within a grid search. If none, the classifier is not
-        part of a grid search.
-
-    Returns
-    -------
-    None
-    """
-
-    print('Creating classification report visualization...')
-    try:
-        visualizer = ClassificationReport(rf_clf, classes=class_names, support=True)
-        visualizer.score(x_df, y_df)
-        if save_file_no != None:
-            save_path = os.path.join(save_dir, class_names[1] + '_' + str(save_file_no) + '_classification_report.png')
-        else:
-            save_path = os.path.join(save_dir, class_names[1] + '_classification_report.png')
-        visualizer.poof(outpath=save_path, clear_figure=True)
-    except KeyError as e:
-        NotEnoughDataWarning(msg=f'Not enough data to create classification report: {class_names[1]}')
-
-def create_x_importance_log(rf_clf: RandomForestClassifier,
-                            x_names: list,
-                            clf_name: str,
-                            save_dir: str,
-                            save_file_no=None):
-    """
-    Helper to save gini or entropy based feature importance scores.
-
-    Parameters
-    ----------
-    rf_clf: RandomForestClassifier
-        sklearn RandomForestClassifier object.
-    x_names: list
-        Names of features.
-    clf_name: str
-        Name of classifier.
-    save_dir: str,
-        Directory where to save output in csv file format.
-    save_file_no: int or None.
-        If integer, represents the count of the classifier within a grid search. If none, the classifier is not
-        part of a grid search.
-
-    Returns
-    -------
-    None
-
-    """
-
-    print('Creating feature importance log...')
-    importances = list(rf_clf.feature_importances_)
-    feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(x_names, importances)]
-    df = pd.DataFrame(feature_importances, columns=['FEATURE', 'FEATURE_IMPORTANCE']).sort_values(by=['FEATURE_IMPORTANCE'], ascending=False)
-    if save_file_no != None:
-        save_file_path = os.path.join(save_dir, clf_name + '_' + str(save_file_no) + '_feature_importance_log.csv')
-    else:
-        save_file_path = os.path.join(save_dir, clf_name + '_feature_importance_log.csv')
-    df.to_csv(save_file_path, index=False)
-
-def create_x_importance_bar_chart(rf_clf: RandomForestClassifier,
-                                  x_names: list,
-                                  clf_name: str,
-                                  save_dir: str,
-                                  n_bars: int,
-                                  save_file_no=None):
-    """
-    Helper to create a bar chart displaying the top N gini or entropy feature importance scores.
-
-    Parameters
-    ----------
-    rf_clf: RandomForestClassifier
-        sklearn RandomForestClassifier object.
-    x_names: list
-        Names of features.
-    clf_name: str
-        Name of classifier.
-    save_dir: str
-        Directory where to save output in csv file format.
-    n_bars: int
-        Number of bars in the plot.
-    save_file_no: str or None
-        If integer, represents the count of the classifier within a grid search. If none, the classifier is not
-        part of a grid search.
-
-    Returns
-    -------
-    None
-    """
-
-    print('Creating feature importance bar chart...')
-    create_x_importance_log(rf_clf, x_names, clf_name, save_dir)
-    importances_df = pd.read_csv(os.path.join(save_dir, clf_name + '_feature_importance_log.csv'))
-    importances_head = importances_df.head(n_bars)
-    colors = create_single_color_lst(pallete_name='hot',increments=n_bars, as_rgb_ratio=True)
-    colors = [x[::-1] for x in colors]
-    ax = importances_head.plot.bar(x='FEATURE', y='FEATURE_IMPORTANCE', legend=False, rot=90, fontsize=6, color=colors)
-    plt.ylabel("Feature importances' (mean decrease impurity)", fontsize=6)
-    plt.tight_layout()
-    if save_file_no != None:
-        save_file_path = os.path.join(save_dir, clf_name + '_' + str(save_file_no) + '_feature_importance_bar_graph.png')
-    else:
-        save_file_path = os.path.join(save_dir, clf_name + '_feature_importance_bar_graph.png')
-    plt.savefig(save_file_path, dpi=600)
-    plt.close('all')
-
-def dviz_classification_visualization(x_train: np.array,
-                                      y_train: np.array,
-                                      clf_name: str,
-                                      class_names: list,
-                                      save_dir: str):
-    """
-    Helper to create visualization of example decision tree.
-
-    Parameters
-    ----------
-    x_train: np.array
-        Array with training features
-    y_train: np.array
-        Array with training targets
-    clf_name: str
-        Name of classifier
-    class_names:
-        List of class names. E.g., ['Attack absent', 'Attack present']
-    save_dir: str
-        Directory where to save output in svg file format.
-
-    Returns
-    -------
-    None
-    """
-
-    clf = tree.DecisionTreeClassifier(max_depth=5, random_state=666)
-    clf.fit(x_train, y_train)
-    try:
-        svg_tree = dtreeviz(clf, x_train, y_train, target_name=clf_name, feature_names=x_train.columns, orientation="TD", class_names=class_names, fancy=True, histtype='strip', X=None, label_fontsize=12, ticks_fontsize=8, fontname="Arial")
-        save_path = os.path.join(save_dir, clf_name + '_fancy_decision_tree_example.svg')
-        svg_tree.save(save_path)
-    except:
-        NoModuleWarning(msg='Skipping dtreeviz example decision tree visualization. Make sure "graphviz" is installed.')
-
-
-def create_shap_log(ini_file_path: str,
-                    rf_clf: RandomForestClassifier,
-                    x_df: pd.DataFrame,
-                    y_df: pd.DataFrame,
-                    x_names: list,
-                    clf_name: str,
-                    cnt_present: int,
-                    cnt_absent: int,
-                    save_path: str,
-                    save_it: int=100,
-                    save_file_no=None):
-
-    """
-    Helper to compute SHAP values.
-
-    Parameters
-    ----------
-    ini_file_path: str
-        Path to the SimBA project_config.ini
-    rf_clf: RandomForestClassifier
-        sklearn random forest classifier
-    x_df: pd.DataFrame
-        Pandas dataframe holding test features.
-    y_df: pd.DataFrame
-        Pandas dataframe holding test target.
-    x_names: list
-        Feature names.
-    clf_name:
-        Classifier name.
-    cnt_present: int
-        Number of behavior-present frames to calculate SHAP values for.
-    cnt_absent: int
-        Number of behavior-absent frames to calculate SHAP values for.
-    save_dir: str,
-        Directory where to save output in csv file format.
-    save_file_no: int or None.
-        If integer, represents the count of the classifier within a grid search. If none, the classifier is not
-        part of a grid search.
-
-    Returns
-    -------
-
-    """
-
-    print('Calculating SHAP values...')
-    shap_timer = SimbaTimer(start=True)
-    data_df = pd.concat([x_df, y_df], axis=1)
-    if save_file_no == None:
-        out_df_shap_path = os.path.join(save_path, f'SHAP_values_{clf_name}.csv')
-        out_df_raw_path = os.path.join(save_path, f'RAW_SHAP_feature_values_{clf_name}.csv')
-    else:
-        out_df_shap_path = os.path.join(save_path, f'SHAP_values_{str(save_file_no)}_{clf_name}.csv')
-        out_df_raw_path = os.path.join(save_path, f'RAW_SHAP_feature_values_{str(save_file_no)}_{clf_name}.csv')
-
-    target_df, nontarget_df = data_df[data_df[y_df.name] == 1], data_df[data_df[y_df.name] == 0]
-    if len(target_df) < cnt_present:
-        NotEnoughDataWarning(msg=f'Train data contains {str(len(target_df))} behavior-present annotations. This is less the number of frames you specified to calculate shap values for {str(cnt_present)}. SimBA will calculate shap scores for the {str(len(target_df))} behavior-present frames available')
-        cnt_present = len(target_df)
-    if len(nontarget_df) < cnt_absent:
-        NotEnoughDataWarning(msg=f'Train data contains {str(len(nontarget_df))} behavior-absent annotations. This is less the number of frames you specified to calculate shap values for {str(cnt_absent)}. SimBA will calculate shap scores for the {str(len(target_df))} behavior-absent frames available')
-        cnt_absent = len(nontarget_df)
-    non_target_for_shap = nontarget_df.sample(cnt_absent, replace=False)
-    targets_for_shap = target_df.sample(cnt_present, replace=False)
-    shap_df = pd.concat([targets_for_shap, non_target_for_shap], axis=0)
-    y_df = shap_df.pop(clf_name).values
-    explainer = shap.TreeExplainer(rf_clf, data=None, model_output='raw', feature_perturbation='tree_path_dependent')
-    expected_value = explainer.expected_value[1]
-    out_df_raw = pd.DataFrame(columns=x_names)
-    shap_headers = list(x_names)
-    shap_headers.extend(('Expected_value', 'Sum', 'Prediction_probability', clf_name))
-    out_df_shap = pd.DataFrame(columns=shap_headers)
-    for cnt, frame in enumerate(range(len(shap_df))):
-        shap_frm_timer = SimbaTimer(start=True)
-        frame_data = shap_df.iloc[[frame]]
-        frame_shap = explainer.shap_values(frame_data, check_additivity=False)[1][0].tolist()
-        frame_shap.extend((expected_value, sum(frame_shap), rf_clf.predict_proba(frame_data)[0][1], y_df[cnt]))
-        out_df_raw.loc[len(out_df_raw)] = list(shap_df.iloc[frame])
-        out_df_shap.loc[len(out_df_shap)] = frame_shap
-        if (cnt % save_it == 0) or (cnt == len(shap_df)-1) and (cnt != 0):
-            print(f'Saving SHAP data after {cnt} iterations...')
-            out_df_shap.to_csv(out_df_shap_path)
-            out_df_raw.to_csv(out_df_raw_path)
-        shap_frm_timer.stop_timer()
-        print(f'SHAP frame: {cnt+1} / {len(shap_df)}, elapsed time: {shap_frm_timer.elapsed_time_str}...')
-
-    shap_timer.stop_timer()
-    stdout_success(msg='SHAP calculations complete', elapsed_time=shap_timer.elapsed_time_str)
-    _ = ShapAggregateStatisticsVisualizer(config_path=ini_file_path,
-                                          classifier_name=clf_name,
-                                          shap_df=out_df_shap,
-                                          shap_baseline_value=int(expected_value * 100),
-                                          save_path=save_path)
-
-
-
-def print_machine_model_information(model_dict: dict):
-    """
-    Helper to print model information in tabular form.
-
-    Parameters
-    ----------
-    model_dict: dict
-        Python dictionary holding model meta data in SimBA meta-config format.
-
-    Returns
-    -------
-    None
-    """
-
-    table_view = [["Model name", model_dict[MetaKeys.CLF_NAME.value]], ["Ensemble method", 'RF'],
-                 ["Estimators (trees)", model_dict[MetaKeys.RF_ESTIMATORS.value]], ["Max features", model_dict[MetaKeys.RF_MAX_FEATURES.value]],
-                 ["Under sampling setting", model_dict[ReadConfig.UNDERSAMPLE_SETTING.value]], ["Under sampling ratio", model_dict[ReadConfig.UNDERSAMPLE_RATIO.value]],
-                 ["Over sampling setting", model_dict[ReadConfig.OVERSAMPLE_SETTING.value]], ["Over sampling ratio", model_dict[ReadConfig.OVERSAMPLE_RATIO.value]],
-                 ["criterion", model_dict[MetaKeys.CRITERION.value]], ["Min sample leaf", model_dict[MetaKeys.MIN_LEAF.value]]]
-    headers = ["Setting", "value"]
-    print(tabulate(table_view, headers, tablefmt="grid"))
-
-def create_meta_data_csv_training_one_model(meta_data_lst: list,
-                                            clf_name: str,
-                                            save_dir: str):
-    """
-    Helper to save single model meta data (hyperparameters, sampling settings etc.) into SimBA
-    compatible CSV config file.
-
-    Parameters
-    ----------
-    meta_data_lst: list
-        list of meta data
-    clf_name: str
-        name of classifier
-    save_dir: str,
-        Directory where to save output in csv file format.
-
-    Returns
-    -------
-    None
-    """
-    print('Saving model meta data file...')
-    save_path = os.path.join(save_dir, clf_name + '_meta.csv')
-    out_df = pd.DataFrame(columns=get_meta_data_file_headers())
-    out_df.loc[len(out_df)] = meta_data_lst
-    out_df.to_csv(save_path)
-
-
-def create_meta_data_csv_training_multiple_models(meta_data,
-                                                  clf_name,
-                                                  save_dir,
-                                                  save_file_no=None):
-    print('Saving model meta data file...')
-    save_path = os.path.join(save_dir,  f'{clf_name}_{str(save_file_no)}_meta.csv')
-    out_df = pd.DataFrame.from_dict(meta_data, orient='index').T
-    out_df.to_csv(save_path)
-
-def save_rf_model(rf_clf: RandomForestClassifier,
-                  clf_name: str,
-                  save_dir: str,
-                  save_file_no=None):
-    """
-    Helper to save pickled classifier object to disk.
-
-    Parameters
-    ----------
-    rf_clf: RandomForestClassifier
-        sklearn random forest classifier
-    clf_name: str
-        Classifier name
-    save_dir: str,
-        Directory where to save output in csv file format.
-    save_file_no: int or None.
-        If integer, represents the count of the classifier within a grid search. If none, the classifier is not
-        part of a grid search.
-
-    Returns
-    -------
-    None
-    """
-
-    if save_file_no != None:
-        save_path = os.path.join(save_dir, clf_name + '_' + str(save_file_no) + '.sav')
-    else:
-        save_path = os.path.join(save_dir, clf_name + '.sav')
-    pickle.dump(rf_clf, open(save_path, 'wb'))
-
-def get_model_info(config: configparser.ConfigParser,
-                   model_cnt: int):
-    """
-    Helper to read in N SimBA random forest config meta files to python dict memory.
-
-    Parameters
-    ----------
-    config:  configparser.ConfigParser
-        Parsed SimBA project_config.ini
-    model_cnt
-        Count of models
-
-    Returns
-    -------
-    model_dict: dict
-    """
-
-    model_dict = {}
-    for n in range(model_cnt):
-        try:
-            model_dict[n] = {}
-            if config.get('SML settings', 'model_path_' + str(n+1)) == '':
-                MissingUserInputWarning(msg=f'Skipping {str(config.get("SML settings", "target_name_" + str(n + 1)))} classifier analysis: no path set to model file')
-                continue
-            if config.get('SML settings', 'model_path_' + str(n+1)) == 'No file selected':
-                MissingUserInputWarning(msg=f'Skipping {str(config.get("SML settings", "target_name_" + str(n + 1)))} classifier analysis: The classifier path is set to "No file selected')
-                continue
-            model_dict[n]['model_path'] = config.get(ReadConfig.SML_SETTINGS.value, 'model_path_' + str(n+1))
-            model_dict[n]['model_name'] = config.get(ReadConfig.SML_SETTINGS.value, 'target_name_' + str(n+1))
-            check_str('model_name', model_dict[n]['model_name'])
-            model_dict[n]['threshold'] = config.getfloat(ReadConfig.THRESHOLD_SETTINGS.value, 'threshold_' + str(n+1))
-            check_float('threshold', model_dict[n]['threshold'], min_value=0.0, max_value=1.0)
-            model_dict[n]['minimum_bout_length'] = config.getfloat(ReadConfig.MIN_BOUT_LENGTH.value, 'min_bout_' + str(n+1))
-            check_int('minimum_bout_length', model_dict[n]['minimum_bout_length'])
-        except ValueError:
-            MissingUserInputWarning(msg=f'Skipping {str(config.get("SML settings", "target_name_" + str(n+1)))} classifier analysis: missing information (e.g., no discrimination threshold and/or minimum bout set in the project_config.ini')
-
-    if len(model_dict.keys()) == 0:
-        raise NoDataError(msg=f'There are no models with accurate data specified in the RUN MODELS menu. Speficy the model information to SimBA RUN MODELS menu to use them to analyze videos')
-    else:
-        return model_dict
-
-def get_all_clf_names(config: configparser.ConfigParser,
-                      target_cnt: int):
-    """
-    Helper to get all classifier names in a SimBA project.
-
-    Parameters
-    ----------
-    config:  configparser.ConfigParser
-        Parsed SimBA project_config.ini
-    target_cnt
-        Count of models
-
-    Returns
-    -------
-    model_names: list
-    """
-
-    model_names = []
-    for i in range(target_cnt):
-        entry_name = 'target_name_{}'.format(str(i+1))
-        model_names.append(read_config_entry(config, ReadConfig.SML_SETTINGS.value, entry_name, data_type=Dtypes.STR.value))
-    return model_names
-
-
-def insert_column_headers_for_outlier_correction(data_df: pd.DataFrame,
-                                                 new_headers:list,
-                                                 filepath: str):
-    """
-    Helper to insert new column headers onto a dataframe.
-
-    Parameters
-    ----------
-    data_df:  pd.DataFrame
-        Dataframe where headers to to-bo replaced.
-    new_headers: list
-        Names of new headers.
-    filepath: str
-        Path to where ``data_df`` is stored on disk
-
-    Returns
-    -------
-    data_df: pd.DataFrame
-        Dataframe with new headers
-    """
-
-    if len(new_headers) != len(data_df.columns):
-        difference = int(len(data_df.columns) - len(new_headers))
-        bp_missing = int(abs(difference) / 3)
-        if difference < 0:
-
-            print('SIMBA ERROR: SimBA expects {} columns of data inside the files within project_folder/csv/input_csv directory. However, '
-                  'within file {} file, SimBA found {} columns. Thus, there is {} missing data columns in the imported data, which may represent {} '
-                  'bodyparts if each body-part has an x, y and p value. Either revise the SimBA project pose-configuration with {} less body-part, or '
-                  'include {} more body-part in the imported data'.format(str(len(new_headers)), filepath, str(len(data_df.columns)), str(abs(difference)),
-                                                                      str(int(bp_missing)), str(bp_missing), str(bp_missing)))
-        else:
-            print('SIMBA ERROR: SimBA expects {} columns of data inside the files within project_folder/csv/input_csv directory. However, '
-                'within file {} file, SimBA found {} columns. Thus, there is {} more data columns in the imported data than anticipated, which may represent {} '
-                'bodyparts if each body-part has an x, y and p value. Either revise the SimBA project pose-configuration with {} more body-part, or '
-                'include {} less body-part in the imported data'.format(str(len(new_headers)), filepath,
-                                                                        str(len(data_df.columns)), str(abs(difference)),
-                                                                        str(int(bp_missing)), str(bp_missing),
-                                                                        str(bp_missing)))
-        raise ValueError()
-    else:
-        data_df.columns = new_headers
-        return data_df
-
-def read_pickle(file_path: str) -> object:
-    try:
-        clf = pickle.load(open(file_path, 'rb'))
-    except pickle.UnpicklingError:
-        raise CorruptedFileError(msg=f'Can not read {file_path} as a classifier file (pickle).')
-    return clf
-
-
-def bout_train_test_splitter(x_df: pd.DataFrame,
-                             y_df: pd.Series,
-                             test_size: float):
-    """
-    Helper to split train and test based on annotated `bouts`.
-
-    Parameters
-    ----------
-    x_df:  pd.DataFrame
-        Features
-    y_df: pd.Series
-        Target
-    test_size: float
-        Size of test as ratio of all annotated bouts.
-
-    Returns
-    -------
-    x_train, x_test, y_train, y_test
-    """
-
-    print('Using bout sampling...')
-    def find_bouts(s: pd.Series, type: str):
-        test_bouts_frames, train_bouts_frames = [], []
-        bouts = detect_bouts(pd.DataFrame(s), target_lst=pd.DataFrame(s).columns, fps=-1)
-        print(f'{str(len(bouts))} {type} bouts found...')
-        bouts = list(bouts.apply(lambda x: list(range(int(x['Start_frame']), int(x['End_frame']) + 1)), 1).values)
-        test_bouts_idx = np.random.choice(np.arange(0, len(bouts)), int(len(bouts) * test_size))
-        train_bouts_idx = np.array([x for x in list(range(len(bouts))) if x not in test_bouts_idx])
-        for i in range(0, len(bouts)):
-            if i in test_bouts_idx:
-                test_bouts_frames.append(bouts[i])
-            if i in train_bouts_idx:
-                train_bouts_frames.append(bouts[i])
-        return [i for s in test_bouts_frames for i in s], [i for s in train_bouts_frames for i in s]
-
-    test_bouts_frames, train_bouts_frames = find_bouts(s=y_df, type='behavior present')
-    test_nonbouts_frames, train_nonbouts_frames = find_bouts(s=np.logical_xor(y_df, 1).astype(int), type='behavior absent')
-    x_train = x_df[x_df.index.isin(train_bouts_frames + train_nonbouts_frames)]
-    x_test = x_df[x_df.index.isin(test_bouts_frames + test_nonbouts_frames)]
-    y_train = y_df[y_df.index.isin(train_bouts_frames + train_nonbouts_frames)]
-    y_test = y_df[y_df.index.isin(test_bouts_frames + test_nonbouts_frames)]
-
-    return x_train, x_test, y_train, y_test
-
-def check_dataset_integrity(x_df: pd.DataFrame, y_df: pd.DataFrame):
-    x_df = x_df.replace([np.inf, -np.inf, None], np.nan)
-    x_nan_cnt = x_df.isna().sum()
-    x_nan_cnt = x_nan_cnt[x_nan_cnt > 0]
-
-    if len(x_nan_cnt) > 0:
-        if len(x_nan_cnt) < 10:
-            raise FaultyTrainingSetError(msg=f'{str(len(x_nan_cnt))} feature column(s) exist in some files within the project_folder/csv/targets_inserted directory, but missing in others. ' \
-                  f'SimBA expects all files within the project_folder/csv/targets_inserted directory to have the same number of features: the ' \
-                  f'column names with mismatches are: {list(x_nan_cnt.index)}')
-        else:
-            raise FaultyTrainingSetError(
-                msg=f'{str(len(x_nan_cnt))} feature columns exist in some files, but missing in others. The feature files are found in the project_folder/csv/targets_inserted directory. ' \
-                    f'SimBA expects all files within the project_folder/csv/targets_inserted directory to have the same number of features: the first 10 ' \
-                    f'column names with mismatches are: {list(x_nan_cnt.index)[0:9]}')
-
-    if len(y_df.unique()) == 1:
-        if y_df.unique()[0] == 0:
-            raise FaultyTrainingSetError(msg=f'All training annotations for classifier {str(y_df.name)} is labelled as ABSENT. A classifier has be be trained with both behavior PRESENT and ABSENT ANNOTATIONS.')
-        if y_df.unique()[0] == 1:
-            raise FaultyTrainingSetError(msg=f'All training annotations for classifier {str(y_df.name)} is labelled as PRESENT. A classifier has be be trained with both behavior PRESENT and ABSENT ANNOTATIONS.')
-
-
-def partial_dependence_calculator(clf: RandomForestClassifier,
-                                  x_df: pd.DataFrame,
-                                  clf_name: str,
-                                  save_dir: str,
-                                  clf_cnt: int or None=None):
-
-    print(f'Calculating partial dependencies for {len(x_df.columns)} features...')
-    clf.verbose = 0
-    check_if_dir_exists(save_dir)
-    if clf_cnt:
-        save_dir = os.path.join(save_dir, f'partial_dependencies_{clf_name}_{clf_cnt}')
-    else:
-        save_dir = os.path.join(save_dir, f'partial_dependencies_{clf_name}')
-    if not os.path.exists(save_dir): os.makedirs(save_dir)
-    for feature_cnt, feature_name in enumerate(x_df.columns):
-        save_path = os.path.join(save_dir, f'{feature_name}.csv')
-        pdp, axes = partial_dependence(clf, features=[feature_name], X=x_df, percentiles=(0, 1), grid_resolution=30)
-        df = pd.DataFrame({'partial dependence': pdp[0], 'feature value': axes[0]})
-        df.to_csv(save_path)
-        print(f'Partial dependencies for {feature_name} complete...')
-
-
-def _read_data_file_helper(file_path, file_type, clf_names):
-    """ Private function called by ``simba.train_model_functions.read_all_files_in_folder_mp`` """
-
-    timer = SimbaTimer()
-    timer.start_timer()
-    _, vid_name, _ = get_fn_ext(file_path)
-    df = read_df(file_path, file_type).dropna(axis=0, how='all').fillna(0).astype(np.float16)
-    if clf_names != None:
-        for clf_name in clf_names:
-            if not clf_name in df.columns:
-                raise ColumnNotFoundError(column_name=clf_name, file_name=file_path)
-    timer.stop_timer()
-    print(f'Reading complete {vid_name} (elapsed time: {timer.elapsed_time_str}s)...')
-    return df
-
-
-def clf_predict_proba(clf: RandomForestClassifier,
-                      x_df: pd.DataFrame, model_name: str or None=None,
-                      data_path: str or None=None):
-    if len(x_df.columns) != clf.n_features_:
-        raise FeatureNumberMismatchError(f'Mismatch in the number of features in input file {data_path}, and what is expected by the model {model_name}. The model expects {str(clf.n_features_)} features. The data contains {len(x_df.columns)} features.')
-    p_vals = clf.predict_proba(x_df)
-    if p_vals.shape[1] != 2:
-        raise ClassifierInferenceError(msg='The classifier {model_name} has not been created properly. See The SimBA GitHub FAQ page or Gitter for more information and suggested fixes.')
-    return p_vals[:, 1]
-
-
-def clf_fit(clf: RandomForestClassifier, x_df: pd.DataFrame, y_df: pd.DataFrame):
-    nan_features = x_df[~x_df.applymap(np.isreal).all(1)]
-    nan_target = y_df.loc[pd.to_numeric(y_df).isna()]
-    if len(nan_features) > 0:
-        raise FaultyTrainingSetError(msg=f'{len(nan_features)} frame(s) in your project_folder/csv/targets_inserted directory contains FEATURES with non-numerical values')
-    if len(nan_target) > 0:
-        raise FaultyTrainingSetError(msg=f'{len(nan_target)} frame(s) in your project_folder/csv/targets_inserted directory contains ANNOTATIONS with non-numerical values')
-    return clf.fit(x_df, y_df)
-
-
-
-
-def read_all_files_in_folder_mp(file_paths: list,
-                                file_type: str,
-                                classifier_names: list or None = None):
-    """
-
-    Multiprocessing helper function to read in all data files in a folder to a single
-    pd.DataFrame for downstream ML. Defaults to ceil(CPU COUNT / 2) cores. Asserts that all classifiers
-    have annotation fields present in each dataframe.
-
-    Parameters
-    ----------
-    file_paths: list
-        List of file paths representing files to be read in.
-    file_type: str
-        Type of files in ``file_paths``. OPTIONS: csv or parquet.
-    classifier_names: list or None
-        List of classifier names representing fields of human annotations. If not None, then assert that classifier names
-        are present in each data file.
-
-    Returns
-    -------
-    pd.DataFrame
-
-    """
-    if platform.system() == "Darwin":
-        multiprocessing.set_start_method('spawn', force=True)
-    cpu_cnt, _ = find_core_cnt()
-    df_lst = []
-    try:
-        with ProcessPoolExecutor(int(np.ceil(cpu_cnt/2))) as pool:
-            for res in pool.map(_read_data_file_helper, file_paths, repeat(file_type), repeat(classifier_names)):
-                df_lst.append(res)
-        df_concat = pd.concat(df_lst, axis=0).astype(np.float16)
-        if 'scorer' in df_concat.columns:
-            df_concat = df_concat.set_index('scorer')
-        if len(df_concat) == 0:
-            raise ValueError('ANNOTATION ERROR: SimBA found 0 observations (frames) in the project_folder/csv/targets_inserted directory')
-        df_concat = df_concat.loc[:, ~df_concat.columns.str.contains('^Unnamed')].astype(np.float16)
-        data_size = df_concat.memory_usage(index=True).sum()
-        print(f'Dataset size: {round(data_size/1000000, 6)}MB / {round(data_size/1000000000, 6)}GB')
-        return df_concat.reset_index(drop=True)
-
-    except BrokenProcessPool:
-        return read_all_files_in_folder(file_paths=file_paths,
-                                        file_type=file_type,
-                                        classifier_names=classifier_names)
+__author__ = "Simon Nilsson"
+
+import os
+import numpy as np
+import pandas as pd
+from sklearn.inspection import partial_dependence
+from imblearn.combine import SMOTEENN
+from imblearn.over_sampling import SMOTE
+from sklearn.inspection import permutation_importance
+from sklearn.model_selection import learning_curve
+from sklearn.model_selection import ShuffleSplit
+from sklearn.metrics import precision_recall_curve
+from sklearn.ensemble import RandomForestClassifier
+from copy import deepcopy
+from sklearn.tree import export_graphviz
+from subprocess import call
+from yellowbrick.classifier import ClassificationReport
+from datetime import datetime
+import shap
+from tabulate import tabulate
+from concurrent.futures import ProcessPoolExecutor
+from concurrent.futures.process import BrokenProcessPool
+from itertools import repeat
+import configparser
+import platform
+from sklearn.utils import parallel_backend
+import pickle
+from dtreeviz.trees import tree, dtreeviz
+import matplotlib.pyplot as plt
+import multiprocessing
+
+from simba.enums import ReadConfig, Dtypes, MetaKeys
+from simba.plotting.shap_agg_stats_visualizer import ShapAggregateStatisticsVisualizer
+from simba.utils.data import detect_bouts, create_color_palette
+from simba.utils.read_write import find_core_cnt, get_memory_usage_of_df, read_config_entry, read_df, get_fn_ext
+from simba.utils.checks import (check_int,
+                                check_str,
+                                check_if_dir_exists,
+                                check_float)
+from simba.utils.errors import (ColumnNotFoundError,
+                                FaultyTrainingSetError,
+                                MissingColumnsError,
+                                NoDataError,
+                                SamplingError,
+                                CorruptedFileError,
+                                FeatureNumberMismatchError,
+                                ClassifierInferenceError)
+from simba.utils.warnings import (NotEnoughDataWarning,
+                                  NoModuleWarning,
+                                  MissingUserInputWarning)
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.utils.lookups import get_meta_data_file_headers
+
+
+plt.switch_backend('agg')
+
+class TrainModelMixin(object):
+    def __init__(self):
+        pass
+
+    def read_all_files_in_folder(self,
+                                 file_paths: list,
+                                 file_type: str,
+                                 classifier_names=None):
+        """
+        Helper function to read in all data files in a folder to a single pd.DataFrame for downstream ML algorithm.
+        Asserts that all classifiers have annotation fields present in concatenated dataframes.
+
+        Parameters
+        ----------
+        file_paths: list
+            List of file paths representing files to be read in.
+        file_type: str
+            Type of files in ``file_paths``. OPTIONS: csv or parquet.
+        classifier_names: list or None
+            List of classifier names representing fields of human annotations. If not None, then assert that classifier names
+            are present in each data file.
+
+        Returns
+        -------
+        df_concat: pd.DataFrame
+
+        """
+
+        timer = SimbaTimer()
+        timer.start_timer()
+        df_concat = pd.DataFrame()
+        for file_cnt, file in enumerate(file_paths):
+            print(f'Reading in file {str(file_cnt + 1)}/{str(len(file_paths))}...')
+            _, vid_name, _ = get_fn_ext(file)
+            df = read_df(file, file_type).dropna(axis=0, how='all').fillna(0).astype(np.float32)
+            df.index = [vid_name] * len(df)
+            if classifier_names != None:
+                for clf_name in classifier_names:
+                    if not clf_name in df.columns:
+                        raise MissingColumnsError(
+                            msg=f'Data for video {vid_name} does not contain any annotations for behavior {clf_name}. Delete classifier {clf_name} from the SimBA project, or add annotations for behavior {clf_name} to the video {vid_name}')
+                    else:
+                        df_concat = pd.concat([df_concat, df], axis=0)
+            else:
+                df_concat = pd.concat([df_concat, df], axis=0)
+        try:
+            df_concat = df_concat.set_index('scorer')
+        except KeyError:
+            pass
+        if len(df_concat) == 0:
+            raise NoDataError(msg='SimBA found 0 annotated frames in the project_folder/csv/targets_inserted directory')
+        df_concat = df_concat.loc[:, ~df_concat.columns.str.contains('^Unnamed')].fillna(0)
+        timer.stop_timer()
+        memory_size = get_memory_usage_of_df(df=df_concat)
+        print(f'Dataset size: {memory_size["megabytes"]}MB / {memory_size["gigabytes"]}GB')
+        print('{} file(s) read (elapsed time: {}s) ...'.format(str(len(file_paths)), timer.elapsed_time_str))
+        return df_concat.astype(np.float32)
+
+    def read_in_all_model_names_to_remove(self,
+                                          config: configparser,
+                                          model_cnt: int,
+                                          clf_name: str):
+        """
+        Helper to find all field names that contain annotations but are not the target.
+
+        Parameters
+        ----------
+        config: Configparser,
+            Configparser object holding data from the project_config.ini
+        model_cnt: int,
+            Number of classifiers in the SimBA project.
+        clf_name
+            Name of the classifier.
+
+        Returns
+        -------
+        annotation_cols_to_remove: list
+        """
+
+        annotation_cols_to_remove = []
+        for model_no in range(model_cnt):
+            model_name = config.get(ReadConfig.SML_SETTINGS.value, 'target_name_' + str(model_no + 1))
+            if model_name != clf_name:
+                annotation_cols_to_remove.append(model_name)
+        return annotation_cols_to_remove
+
+    def delete_other_annotation_columns(self,
+                                        df: pd.DataFrame,
+                                        annotations_lst: list):
+        """
+        Helper to delete fields that contain annotations which are not the target.
+
+        Parameters
+        ----------
+        df: pd.DataFrame
+            pandas Dataframe holding features and annotations.
+        annotations_lst: list
+            Column fields to be removed from df
+
+        Returns
+        -------
+        df: pd.DataFrame
+        """
+
+        for a_col in annotations_lst:
+            df = df.drop([a_col], axis=1)
+        return df
+
+    def split_df_to_x_y(self,
+                        df: pd.DataFrame,
+                        clf_name: str):
+        """
+        Helper to split dataframe into features and target.
+
+        Parameters
+        ----------
+        df: pd.DataFrame
+            pandas Dataframe holding features and annotations.
+        clf_name: str
+            Name of target.
+
+        Returns
+        -------
+        df: pd.DataFrame
+        y: pd.DataFrame
+        """
+
+        df = deepcopy(df)
+        y = df.pop(clf_name)
+        return df, y
+
+    def random_undersampler(self,
+                            x_train: np.array,
+                            y_train: np.array,
+                            sample_ratio: float):
+        """
+        Helper to perform random undersampling of behavior-absent frames in a dataframe.
+
+        Parameters
+        ----------
+        x_train: pd.DataFrame
+            Features in train set
+        y_train: pd.DataFrame
+            Target in train set
+        sample_ratio: float,
+            Ratio of behavior-absent frames to keep relative to the behavior-present frames. E.g., ``1.0`` returns an equal
+            count of behavior-absent and behavior-present frames. ``2.0`` returns twice as many behavior-absent frames as
+            and behavior-present frames.
+
+        Returns
+        -------
+        df: pd.DataFrame
+        """
+
+        print(f'Performing under-sampling at sample ratio {str(sample_ratio)}...')
+        data_df = pd.concat([x_train, y_train], axis=1)
+        present_df, absent_df = data_df[data_df[y_train.name] == 1], data_df[data_df[y_train.name] == 0]
+        ratio_n = int(len(present_df) * sample_ratio)
+        if len(absent_df) < ratio_n:
+            raise SamplingError(
+                msg=f'SIMBA UNDER SAMPLING ERROR: The under-sample ratio of {str(sample_ratio)} in classifier {y_train.name} demands {str(ratio_n)} behavior-absent annotations. This is more than the number of behavior-absent annotations in the entire dataset {str(len(absent_df))}. Please annotate more images or decrease the under-sample ratio.')
+        data_df = pd.concat([present_df, absent_df.sample(n=ratio_n, replace=False)], axis=0)
+        return self.split_df_to_x_y(data_df, y_train.name)
+
+    def smoteen_oversampler(self,
+                            x_train: pd.DataFrame,
+                            y_train: pd.DataFrame,
+                            sample_ratio: float):
+
+        """
+        Helper to perform smoteen oversampling of behavior-present frames in a dataframe
+
+        Parameters
+        ----------
+        x_train: pd.DataFrame or array
+            pandas Dataframe holding features and annotations.
+        y_train: pd.DataFrame or array
+            List of column fields to be removed from df
+        sample_ratio:
+            New behavior-present frames.
+
+        Returns
+        -------
+        x_train: array
+        y_train: array
+
+        """
+
+        print('Performing SMOTEEN oversampling...')
+        smt = SMOTEENN(sampling_strategy=sample_ratio)
+        return smt.fit_sample(x_train, y_train)
+
+    def smote_oversampler(self,
+                          x_train: pd.DataFrame or np.array,
+                          y_train: pd.DataFrame or np.array,
+                          sample_ratio: float):
+        """
+        Helper to perform smote oversampling of behavior-present frames in a dataframe
+
+        Parameters
+        ----------
+        x_train: pd.DataFrame or array
+            pandas Dataframe holding features and annotations.
+        y_train: pd.DataFrame or array
+            List of column fields to be removed from df
+        sample_ratio:
+            New behavior-present frames.
+
+        Returns
+        -------
+        x_train: array
+        y_train: array
+
+        """
+        print('Performing SMOTE oversampling...')
+        smt = SMOTE(sampling_strategy=sample_ratio)
+        return smt.fit_sample(x_train, y_train)
+
+    def calc_permutation_importance(self,
+                                    x_test: np.array,
+                                    y_test: np.array,
+                                    clf: RandomForestClassifier,
+                                    feature_names: list,
+                                    clf_name: str,
+                                    save_dir: str,
+                                    save_file_no=None):
+        """
+        Helper to calculate feature permutation importance scores.
+
+        Parameters
+        ----------
+        x_test: np.array,
+            Array holding feature test data
+        y_test: np.array
+            Array holding target test data
+        clf: object
+            sklearn RandomForestClassifier object
+        feature_names: list,
+            list of feature names
+        clf_name: str,
+            Name of classifier
+        save_dir: str,
+            Directory where to save output in csv file format.
+        save_file_no: int or None.
+            If integer, represents the count of the classifier within a grid search. If none, the classifier is not
+            part of a grid search.
+
+        Returns
+        -------
+        None
+
+        """
+        print('Calculating feature permutation importances...')
+        timer = SimbaTimer()
+        timer.start_timer()
+        p_importances = permutation_importance(clf, x_test, y_test, n_repeats=10, random_state=0)
+        df = pd.DataFrame(
+            np.column_stack([feature_names, p_importances.importances_mean, p_importances.importances_std]),
+            columns=['FEATURE_NAME', 'FEATURE_IMPORTANCE_MEAN', 'FEATURE_IMPORTANCE_STDEV'])
+        df = df.sort_values(by=['FEATURE_IMPORTANCE_MEAN'], ascending=False)
+        if save_file_no != None:
+            save_file_path = os.path.join(save_dir,
+                                          clf_name + '_' + str(save_file_no + 1) + '_permutations_importances.csv')
+        else:
+            save_file_path = os.path.join(save_dir, clf_name + '_permutations_importances.csv')
+        df.to_csv(save_file_path, index=False)
+        timer.stop_timer()
+        print('Permutation importance calculation complete (elapsed time: {}s) ...'.format(timer.elapsed_time_str))
+
+    def calc_learning_curve(self,
+                            x_y_df: pd.DataFrame,
+                            clf_name: str,
+                            shuffle_splits: int,
+                            dataset_splits: int,
+                            tt_size: float,
+                            rf_clf: RandomForestClassifier,
+                            save_dir: str,
+                            save_file_no=None):
+        """
+        Helper to compute random forest learning curves with cross-validation.
+
+        Parameters
+        ----------
+        x_y_df: pd.DataFrame
+            Pandas dataframe holding features and targets.
+        clf_name: str,
+            Name of the classifier
+        shuffle_splits: int
+            Number of cross-validation datasets at each data split.
+        dataset_splits: int
+            Number of data splits.
+        tt_size: float
+            dataset test size.
+        rf_clf: RandomForestClassifier
+            sklearn RandomForestClassifier object.
+        save_dir: str,
+            Directory where to save output in csv file format.
+        save_file_no: int or None.
+            If integer, represents the count of the classifier within a grid search. If none, the classifier is not
+            part of a grid search.
+
+        Returns
+        -------
+        None
+
+        """
+
+        print('Calculating learning curves...')
+        timer = SimbaTimer()
+        timer.start_timer()
+        x_df, y_df = self.split_df_to_x_y(x_y_df, clf_name)
+        cv = ShuffleSplit(n_splits=shuffle_splits, test_size=tt_size)
+        if platform.system() == "Darwin":
+            with parallel_backend("threading", n_jobs=-2):
+                train_sizes, train_scores, test_scores = learning_curve(estimator=rf_clf, X=x_df, y=y_df, cv=cv,
+                                                                        scoring='f1', shuffle=False, verbose=0,
+                                                                        train_sizes=np.linspace(0.01, 1.0,
+                                                                                                dataset_splits),
+                                                                        error_score='raise')
+        else:
+            train_sizes, train_scores, test_scores = learning_curve(estimator=rf_clf, X=x_df, y=y_df, cv=cv,
+                                                                    scoring='f1', shuffle=False, n_jobs=-1, verbose=0,
+                                                                    train_sizes=np.linspace(0.01, 1.0, dataset_splits),
+                                                                    error_score='raise')
+        results_df = pd.DataFrame()
+        results_df['FRACTION TRAIN SIZE'] = np.linspace(0.01, 1.0, dataset_splits)
+        results_df['TRAIN_MEAN_F1'] = np.mean(train_scores, axis=1)
+        results_df['TEST_MEAN_F1'] = np.mean(test_scores, axis=1)
+        results_df['TRAIN_STDEV_F1'] = np.std(train_scores, axis=1)
+        results_df['TEST_STDEV_F1'] = np.std(test_scores, axis=1)
+        if save_file_no != None:
+            save_file_path = os.path.join(save_dir, clf_name + '_' + str(save_file_no + 1) + '_learning_curve.csv')
+        else:
+            save_file_path = os.path.join(save_dir, clf_name + '_learning_curve.csv')
+        results_df.to_csv(save_file_path, index=False)
+        timer.stop_timer()
+        print('Learning curve calculation complete (elapsed time: {}s) ...'.format(timer.elapsed_time_str))
+
+    def calc_pr_curve(self,
+                      rf_clf: RandomForestClassifier,
+                      x_df: pd.DataFrame,
+                      y_df: pd.DataFrame,
+                      clf_name: str,
+                      save_dir: str,
+                      save_file_no=None):
+        """
+        Helper to compute random forest precision-recall curve.
+
+        Parameters
+        ----------
+        rf_clf: RandomForestClassifier
+            sklearn RandomForestClassifier object.
+        x_df: pd.DataFrame
+            Pandas dataframe holding test features.
+        y_df: pd.DataFrame
+            Pandas dataframe holding test target.
+        clf_name: str
+            Classifier name.
+        save_dir: str,
+            Directory where to save output in csv file format.
+        save_file_no: int or None.
+            If integer, represents the count of the classifier within a grid search. If none, the classifier is not
+            part of a grid search.
+
+        Returns
+        -------
+        None
+
+        """
+
+        print('Calculating PR curves...')
+        timer = SimbaTimer()
+        timer.start_timer()
+        p = rf_clf.predict_proba(x_df)[:, 1]
+        precision, recall, thresholds = precision_recall_curve(y_df, p, pos_label=1)
+        pr_df = pd.DataFrame()
+        pr_df['PRECISION'] = precision
+        pr_df['RECALL'] = recall
+        pr_df['F1'] = 2 * pr_df['RECALL'] * pr_df['PRECISION'] / (pr_df['RECALL'] + pr_df['PRECISION'])
+        thresholds = list(thresholds)
+        thresholds.insert(0, 0.00)
+        pr_df['DISCRIMINATION THRESHOLDS'] = thresholds
+        if save_file_no != None:
+            save_file_path = os.path.join(save_dir, clf_name + '_' + str(save_file_no + 1) + '_pr_curve.csv')
+        else:
+            save_file_path = os.path.join(save_dir, clf_name + '_pr_curve.csv')
+        pr_df.to_csv(save_file_path, index=False)
+        timer.stop_timer()
+        print('Precision-recall curve calculation complete (elapsed time: {}s) ...'.format(timer.elapsed_time_str))
+
+    def create_example_dt(self,
+                          rf_clf: RandomForestClassifier,
+                          clf_name: str,
+                          feature_names: list,
+                          class_names: list,
+                          save_dir: str,
+                          save_file_no=None):
+        """
+        Helper to produce visualization of random forest decision tree.
+
+        Parameters
+        ----------
+        rf_clf: RandomForestClassifier
+            sklearn RandomForestClassifier object.
+        clf_name: str
+            Classifier name.
+        feature_names: list
+            List of feature names.
+        class_names
+            List of classes. E.g., ['Attack absent', 'Attack present']
+        save_dir: str,
+            Directory where to save output in csv file format.
+        save_file_no: int or None.
+            If integer, represents the count of the classifier within a grid search. If none, the classifier is not
+            part of a grid search.
+
+        Returns
+        -------
+        None
+        """
+
+        print('Visualizing example decision tree using graphviz...')
+        estimator = rf_clf.estimators_[3]
+        if save_file_no != None:
+            dot_name = os.path.join(save_dir, str(clf_name) + '_' + str(save_file_no) + '_tree.dot')
+            file_name = os.path.join(save_dir, str(clf_name) + '_' + str(save_file_no) + '_tree.pdf')
+        else:
+            dot_name = os.path.join(save_dir, str(clf_name) + '_tree.dot')
+            file_name = os.path.join(save_dir, str(clf_name) + '_tree.pdf')
+        export_graphviz(estimator, out_file=dot_name, filled=True, rounded=True, special_characters=False,
+                        impurity=False, class_names=class_names, feature_names=feature_names)
+        command = ('dot ' + str(dot_name) + ' -T pdf -o ' + str(file_name) + ' -Gdpi=600')
+        call(command, shell=True)
+
+    def create_clf_report(self,
+                          rf_clf: RandomForestClassifier,
+                          x_df: pd.DataFrame,
+                          y_df: pd.DataFrame,
+                          class_names: list,
+                          save_dir: str,
+                          save_file_no=None):
+        """
+        Helper to create classifier truth table report.
+
+        Parameters
+        ----------
+        rf_clf: RandomForestClassifier
+            sklearn RandomForestClassifier object.
+        x_df: pd.DataFrame
+            Pandas dataframe holding test features.
+        y_df: pd.DataFrame
+            Pandas dataframe holding test target.
+        class_names: list
+            List of classes. E.g., ['Attack absent', 'Attack present']
+        save_dir: str,
+            Directory where to save output in csv file format.
+        save_file_no: int or None.
+            If integer, represents the count of the classifier within a grid search. If none, the classifier is not
+            part of a grid search.
+
+        Returns
+        -------
+        None
+        """
+
+        print('Creating classification report visualization...')
+        try:
+            visualizer = ClassificationReport(rf_clf, classes=class_names, support=True)
+            visualizer.score(x_df, y_df)
+            if save_file_no != None:
+                save_path = os.path.join(save_dir,
+                                         class_names[1] + '_' + str(save_file_no) + '_classification_report.png')
+            else:
+                save_path = os.path.join(save_dir, class_names[1] + '_classification_report.png')
+            visualizer.poof(outpath=save_path, clear_figure=True)
+        except KeyError as e:
+            NotEnoughDataWarning(msg=f'Not enough data to create classification report: {class_names[1]}')
+
+    def create_x_importance_log(self,
+                                rf_clf: RandomForestClassifier,
+                                x_names: list,
+                                clf_name: str,
+                                save_dir: str,
+                                save_file_no=None):
+        """
+        Helper to save gini or entropy based feature importance scores.
+
+        Parameters
+        ----------
+        rf_clf: RandomForestClassifier
+            sklearn RandomForestClassifier object.
+        x_names: list
+            Names of features.
+        clf_name: str
+            Name of classifier.
+        save_dir: str,
+            Directory where to save output in csv file format.
+        save_file_no: int or None.
+            If integer, represents the count of the classifier within a grid search. If none, the classifier is not
+            part of a grid search.
+
+        Returns
+        -------
+        None
+
+        """
+
+        print('Creating feature importance log...')
+        importances = list(rf_clf.feature_importances_)
+        feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(x_names, importances)]
+        df = pd.DataFrame(feature_importances, columns=['FEATURE', 'FEATURE_IMPORTANCE']).sort_values(
+            by=['FEATURE_IMPORTANCE'], ascending=False)
+        if save_file_no != None:
+            save_file_path = os.path.join(save_dir, clf_name + '_' + str(save_file_no) + '_feature_importance_log.csv')
+        else:
+            save_file_path = os.path.join(save_dir, clf_name + '_feature_importance_log.csv')
+        df.to_csv(save_file_path, index=False)
+
+    def create_x_importance_bar_chart(self,
+                                      rf_clf: RandomForestClassifier,
+                                      x_names: list,
+                                      clf_name: str,
+                                      save_dir: str,
+                                      n_bars: int,
+                                      save_file_no=None):
+        """
+        Helper to create a bar chart displaying the top N gini or entropy feature importance scores.
+
+        Parameters
+        ----------
+        rf_clf: RandomForestClassifier
+            sklearn RandomForestClassifier object.
+        x_names: list
+            Names of features.
+        clf_name: str
+            Name of classifier.
+        save_dir: str
+            Directory where to save output in csv file format.
+        n_bars: int
+            Number of bars in the plot.
+        save_file_no: str or None
+            If integer, represents the count of the classifier within a grid search. If none, the classifier is not
+            part of a grid search.
+
+        Returns
+        -------
+        None
+        """
+
+        print('Creating feature importance bar chart...')
+        self.create_x_importance_log(rf_clf, x_names, clf_name, save_dir)
+        importances_df = pd.read_csv(os.path.join(save_dir, clf_name + '_feature_importance_log.csv'))
+        importances_head = importances_df.head(n_bars)
+        colors = create_color_palette(pallete_name='hot', increments=n_bars, as_rgb_ratio=True)
+        colors = [x[::-1] for x in colors]
+        ax = importances_head.plot.bar(x='FEATURE', y='FEATURE_IMPORTANCE', legend=False, rot=90, fontsize=6,
+                                       color=colors)
+        plt.ylabel("Feature importances' (mean decrease impurity)", fontsize=6)
+        plt.tight_layout()
+        if save_file_no != None:
+            save_file_path = os.path.join(save_dir,
+                                          clf_name + '_' + str(save_file_no) + '_feature_importance_bar_graph.png')
+        else:
+            save_file_path = os.path.join(save_dir, clf_name + '_feature_importance_bar_graph.png')
+        plt.savefig(save_file_path, dpi=600)
+        plt.close('all')
+
+    def dviz_classification_visualization(self,
+                                          x_train: np.array,
+                                          y_train: np.array,
+                                          clf_name: str,
+                                          class_names: list,
+                                          save_dir: str):
+        """
+        Helper to create visualization of example decision tree.
+
+        Parameters
+        ----------
+        x_train: np.array
+            Array with training features
+        y_train: np.array
+            Array with training targets
+        clf_name: str
+            Name of classifier
+        class_names:
+            List of class names. E.g., ['Attack absent', 'Attack present']
+        save_dir: str
+            Directory where to save output in svg file format.
+
+        Returns
+        -------
+        None
+        """
+
+        clf = tree.DecisionTreeClassifier(max_depth=5, random_state=666)
+        clf.fit(x_train, y_train)
+        try:
+            svg_tree = dtreeviz(clf, x_train, y_train, target_name=clf_name, feature_names=x_train.columns,
+                                orientation="TD", class_names=class_names, fancy=True, histtype='strip', X=None,
+                                label_fontsize=12, ticks_fontsize=8, fontname="Arial")
+            save_path = os.path.join(save_dir, clf_name + '_fancy_decision_tree_example.svg')
+            svg_tree.save(save_path)
+        except:
+            NoModuleWarning(
+                msg='Skipping dtreeviz example decision tree visualization. Make sure "graphviz" is installed.')
+
+    def create_shap_log(self,
+                        ini_file_path: str,
+                        rf_clf: RandomForestClassifier,
+                        x_df: pd.DataFrame,
+                        y_df: pd.DataFrame,
+                        x_names: list,
+                        clf_name: str,
+                        cnt_present: int,
+                        cnt_absent: int,
+                        save_path: str,
+                        save_it: int = 100,
+                        save_file_no=None):
+
+        """
+        Helper to compute SHAP values.
+
+        Parameters
+        ----------
+        ini_file_path: str
+            Path to the SimBA project_config.ini
+        rf_clf: RandomForestClassifier
+            sklearn random forest classifier
+        x_df: pd.DataFrame
+            Pandas dataframe holding test features.
+        y_df: pd.DataFrame
+            Pandas dataframe holding test target.
+        x_names: list
+            Feature names.
+        clf_name:
+            Classifier name.
+        cnt_present: int
+            Number of behavior-present frames to calculate SHAP values for.
+        cnt_absent: int
+            Number of behavior-absent frames to calculate SHAP values for.
+        save_dir: str,
+            Directory where to save output in csv file format.
+        save_file_no: int or None.
+            If integer, represents the count of the classifier within a grid search. If none, the classifier is not
+            part of a grid search.
+
+        Returns
+        -------
+
+        """
+
+        print('Calculating SHAP values...')
+        shap_timer = SimbaTimer(start=True)
+        data_df = pd.concat([x_df, y_df], axis=1)
+        if save_file_no == None:
+            out_df_shap_path = os.path.join(save_path, f'SHAP_values_{clf_name}.csv')
+            out_df_raw_path = os.path.join(save_path, f'RAW_SHAP_feature_values_{clf_name}.csv')
+        else:
+            out_df_shap_path = os.path.join(save_path, f'SHAP_values_{str(save_file_no)}_{clf_name}.csv')
+            out_df_raw_path = os.path.join(save_path, f'RAW_SHAP_feature_values_{str(save_file_no)}_{clf_name}.csv')
+
+        target_df, nontarget_df = data_df[data_df[y_df.name] == 1], data_df[data_df[y_df.name] == 0]
+        if len(target_df) < cnt_present:
+            NotEnoughDataWarning(
+                msg=f'Train data contains {str(len(target_df))} behavior-present annotations. This is less the number of frames you specified to calculate shap values for {str(cnt_present)}. SimBA will calculate shap scores for the {str(len(target_df))} behavior-present frames available')
+            cnt_present = len(target_df)
+        if len(nontarget_df) < cnt_absent:
+            NotEnoughDataWarning(
+                msg=f'Train data contains {str(len(nontarget_df))} behavior-absent annotations. This is less the number of frames you specified to calculate shap values for {str(cnt_absent)}. SimBA will calculate shap scores for the {str(len(target_df))} behavior-absent frames available')
+            cnt_absent = len(nontarget_df)
+        non_target_for_shap = nontarget_df.sample(cnt_absent, replace=False)
+        targets_for_shap = target_df.sample(cnt_present, replace=False)
+        shap_df = pd.concat([targets_for_shap, non_target_for_shap], axis=0)
+        y_df = shap_df.pop(clf_name).values
+        explainer = shap.TreeExplainer(rf_clf, data=None, model_output='raw',
+                                       feature_perturbation='tree_path_dependent')
+        expected_value = explainer.expected_value[1]
+        out_df_raw = pd.DataFrame(columns=x_names)
+        shap_headers = list(x_names)
+        shap_headers.extend(('Expected_value', 'Sum', 'Prediction_probability', clf_name))
+        out_df_shap = pd.DataFrame(columns=shap_headers)
+        for cnt, frame in enumerate(range(len(shap_df))):
+            shap_frm_timer = SimbaTimer(start=True)
+            frame_data = shap_df.iloc[[frame]]
+            frame_shap = explainer.shap_values(frame_data, check_additivity=False)[1][0].tolist()
+            frame_shap.extend((expected_value, sum(frame_shap), rf_clf.predict_proba(frame_data)[0][1], y_df[cnt]))
+            out_df_raw.loc[len(out_df_raw)] = list(shap_df.iloc[frame])
+            out_df_shap.loc[len(out_df_shap)] = frame_shap
+            if (cnt % save_it == 0) or (cnt == len(shap_df) - 1) and (cnt != 0):
+                print(f'Saving SHAP data after {cnt} iterations...')
+                out_df_shap.to_csv(out_df_shap_path)
+                out_df_raw.to_csv(out_df_raw_path)
+            shap_frm_timer.stop_timer()
+            print(f'SHAP frame: {cnt + 1} / {len(shap_df)}, elapsed time: {shap_frm_timer.elapsed_time_str}...')
+
+        shap_timer.stop_timer()
+        stdout_success(msg='SHAP calculations complete', elapsed_time=shap_timer.elapsed_time_str)
+        _ = ShapAggregateStatisticsVisualizer(config_path=ini_file_path,
+                                              classifier_name=clf_name,
+                                              shap_df=out_df_shap,
+                                              shap_baseline_value=int(expected_value * 100),
+                                              save_path=save_path)
+
+    def print_machine_model_information(self,
+                                        model_dict: dict):
+        """
+        Helper to print model information in tabular form.
+
+        Parameters
+        ----------
+        model_dict: dict
+            Python dictionary holding model meta data in SimBA meta-config format.
+
+        Returns
+        -------
+        None
+        """
+
+        table_view = [["Model name", model_dict[MetaKeys.CLF_NAME.value]], ["Ensemble method", 'RF'],
+                      ["Estimators (trees)", model_dict[MetaKeys.RF_ESTIMATORS.value]],
+                      ["Max features", model_dict[MetaKeys.RF_MAX_FEATURES.value]],
+                      ["Under sampling setting", model_dict[ReadConfig.UNDERSAMPLE_SETTING.value]],
+                      ["Under sampling ratio", model_dict[ReadConfig.UNDERSAMPLE_RATIO.value]],
+                      ["Over sampling setting", model_dict[ReadConfig.OVERSAMPLE_SETTING.value]],
+                      ["Over sampling ratio", model_dict[ReadConfig.OVERSAMPLE_RATIO.value]],
+                      ["criterion", model_dict[MetaKeys.CRITERION.value]],
+                      ["Min sample leaf", model_dict[MetaKeys.MIN_LEAF.value]]]
+        headers = ["Setting", "value"]
+        print(tabulate(table_view, headers, tablefmt="grid"))
+
+    def create_meta_data_csv_training_one_model(self,
+                                                meta_data_lst: list,
+                                                clf_name: str,
+                                                save_dir: str):
+        """
+        Helper to save single model meta data (hyperparameters, sampling settings etc.) into SimBA
+        compatible CSV config file.
+
+        Parameters
+        ----------
+        meta_data_lst: list
+            list of meta data
+        clf_name: str
+            name of classifier
+        save_dir: str,
+            Directory where to save output in csv file format.
+
+        Returns
+        -------
+        None
+        """
+        print('Saving model meta data file...')
+        save_path = os.path.join(save_dir, clf_name + '_meta.csv')
+        out_df = pd.DataFrame(columns=get_meta_data_file_headers())
+        out_df.loc[len(out_df)] = meta_data_lst
+        out_df.to_csv(save_path)
+
+    def create_meta_data_csv_training_multiple_models(self,
+                                                      meta_data,
+                                                      clf_name,
+                                                      save_dir,
+                                                      save_file_no=None):
+        print('Saving model meta data file...')
+        save_path = os.path.join(save_dir, f'{clf_name}_{str(save_file_no)}_meta.csv')
+        out_df = pd.DataFrame.from_dict(meta_data, orient='index').T
+        out_df.to_csv(save_path)
+
+    def save_rf_model(self,
+                      rf_clf: RandomForestClassifier,
+                      clf_name: str,
+                      save_dir: str,
+                      save_file_no=None):
+        """
+        Helper to save pickled classifier object to disk.
+
+        Parameters
+        ----------
+        rf_clf: RandomForestClassifier
+            sklearn random forest classifier
+        clf_name: str
+            Classifier name
+        save_dir: str,
+            Directory where to save output in csv file format.
+        save_file_no: int or None.
+            If integer, represents the count of the classifier within a grid search. If none, the classifier is not
+            part of a grid search.
+
+        Returns
+        -------
+        None
+        """
+
+        if save_file_no != None:
+            save_path = os.path.join(save_dir, clf_name + '_' + str(save_file_no) + '.sav')
+        else:
+            save_path = os.path.join(save_dir, clf_name + '.sav')
+        pickle.dump(rf_clf, open(save_path, 'wb'))
+
+    def get_model_info(self,
+                       config: configparser.ConfigParser,
+                       model_cnt: int):
+        """
+        Helper to read in N SimBA random forest config meta files to python dict memory.
+
+        Parameters
+        ----------
+        config:  configparser.ConfigParser
+            Parsed SimBA project_config.ini
+        model_cnt
+            Count of models
+
+        Returns
+        -------
+        model_dict: dict
+        """
+
+        model_dict = {}
+        for n in range(model_cnt):
+            try:
+                model_dict[n] = {}
+                if config.get('SML settings', 'model_path_' + str(n + 1)) == '':
+                    MissingUserInputWarning(
+                        msg=f'Skipping {str(config.get("SML settings", "target_name_" + str(n + 1)))} classifier analysis: no path set to model file')
+                    continue
+                if config.get('SML settings', 'model_path_' + str(n + 1)) == 'No file selected':
+                    MissingUserInputWarning(
+                        msg=f'Skipping {str(config.get("SML settings", "target_name_" + str(n + 1)))} classifier analysis: The classifier path is set to "No file selected')
+                    continue
+                model_dict[n]['model_path'] = config.get(ReadConfig.SML_SETTINGS.value, 'model_path_' + str(n + 1))
+                model_dict[n]['model_name'] = config.get(ReadConfig.SML_SETTINGS.value, 'target_name_' + str(n + 1))
+                check_str('model_name', model_dict[n]['model_name'])
+                model_dict[n]['threshold'] = config.getfloat(ReadConfig.THRESHOLD_SETTINGS.value,
+                                                             'threshold_' + str(n + 1))
+                check_float('threshold', model_dict[n]['threshold'], min_value=0.0, max_value=1.0)
+                model_dict[n]['minimum_bout_length'] = config.getfloat(ReadConfig.MIN_BOUT_LENGTH.value,
+                                                                       'min_bout_' + str(n + 1))
+                check_int('minimum_bout_length', model_dict[n]['minimum_bout_length'])
+            except ValueError:
+                MissingUserInputWarning(
+                    msg=f'Skipping {str(config.get("SML settings", "target_name_" + str(n + 1)))} classifier analysis: missing information (e.g., no discrimination threshold and/or minimum bout set in the project_config.ini')
+
+        if len(model_dict.keys()) == 0:
+            raise NoDataError(
+                msg=f'There are no models with accurate data specified in the RUN MODELS menu. Speficy the model information to SimBA RUN MODELS menu to use them to analyze videos')
+        else:
+            return model_dict
+
+    def get_all_clf_names(self,
+                          config: configparser.ConfigParser,
+                          target_cnt: int):
+        """
+        Helper to get all classifier names in a SimBA project.
+
+        Parameters
+        ----------
+        config:  configparser.ConfigParser
+            Parsed SimBA project_config.ini
+        target_cnt
+            Count of models
+
+        Returns
+        -------
+        model_names: list
+        """
+
+        model_names = []
+        for i in range(target_cnt):
+            entry_name = 'target_name_{}'.format(str(i + 1))
+            model_names.append(
+                read_config_entry(config, ReadConfig.SML_SETTINGS.value, entry_name, data_type=Dtypes.STR.value))
+        return model_names
+
+    def insert_column_headers_for_outlier_correction(self,
+                                                     data_df: pd.DataFrame,
+                                                     new_headers: list,
+                                                     filepath: str):
+        """
+        Helper to insert new column headers onto a dataframe.
+
+        Parameters
+        ----------
+        data_df:  pd.DataFrame
+            Dataframe where headers to to-bo replaced.
+        new_headers: list
+            Names of new headers.
+        filepath: str
+            Path to where ``data_df`` is stored on disk
+
+        Returns
+        -------
+        data_df: pd.DataFrame
+            Dataframe with new headers
+        """
+
+        if len(new_headers) != len(data_df.columns):
+            difference = int(len(data_df.columns) - len(new_headers))
+            bp_missing = int(abs(difference) / 3)
+            if difference < 0:
+
+                print(
+                    'SIMBA ERROR: SimBA expects {} columns of data inside the files within project_folder/csv/input_csv directory. However, '
+                    'within file {} file, SimBA found {} columns. Thus, there is {} missing data columns in the imported data, which may represent {} '
+                    'bodyparts if each body-part has an x, y and p value. Either revise the SimBA project pose-configuration with {} less body-part, or '
+                    'include {} more body-part in the imported data'.format(str(len(new_headers)), filepath,
+                                                                            str(len(data_df.columns)),
+                                                                            str(abs(difference)),
+                                                                            str(int(bp_missing)), str(bp_missing),
+                                                                            str(bp_missing)))
+            else:
+                print(
+                    'SIMBA ERROR: SimBA expects {} columns of data inside the files within project_folder/csv/input_csv directory. However, '
+                    'within file {} file, SimBA found {} columns. Thus, there is {} more data columns in the imported data than anticipated, which may represent {} '
+                    'bodyparts if each body-part has an x, y and p value. Either revise the SimBA project pose-configuration with {} more body-part, or '
+                    'include {} less body-part in the imported data'.format(str(len(new_headers)), filepath,
+                                                                            str(len(data_df.columns)),
+                                                                            str(abs(difference)),
+                                                                            str(int(bp_missing)), str(bp_missing),
+                                                                            str(bp_missing)))
+            raise ValueError()
+        else:
+            data_df.columns = new_headers
+            return data_df
+
+    def read_pickle(self,
+                    file_path: str) -> object:
+        try:
+            clf = pickle.load(open(file_path, 'rb'))
+        except pickle.UnpicklingError:
+            raise CorruptedFileError(msg=f'Can not read {file_path} as a classifier file (pickle).')
+        return clf
+
+    def bout_train_test_splitter(self,
+                                 x_df: pd.DataFrame,
+                                 y_df: pd.Series,
+                                 test_size: float):
+        """
+        Helper to split train and test based on annotated `bouts`.
+
+        Parameters
+        ----------
+        x_df:  pd.DataFrame
+            Features
+        y_df: pd.Series
+            Target
+        test_size: float
+            Size of test as ratio of all annotated bouts.
+
+        Returns
+        -------
+        x_train, x_test, y_train, y_test
+        """
+
+        print('Using bout sampling...')
+
+        def find_bouts(s: pd.Series, type: str):
+            test_bouts_frames, train_bouts_frames = [], []
+            bouts = detect_bouts(pd.DataFrame(s), target_lst=pd.DataFrame(s).columns, fps=-1)
+            print(f'{str(len(bouts))} {type} bouts found...')
+            bouts = list(bouts.apply(lambda x: list(range(int(x['Start_frame']), int(x['End_frame']) + 1)), 1).values)
+            test_bouts_idx = np.random.choice(np.arange(0, len(bouts)), int(len(bouts) * test_size))
+            train_bouts_idx = np.array([x for x in list(range(len(bouts))) if x not in test_bouts_idx])
+            for i in range(0, len(bouts)):
+                if i in test_bouts_idx:
+                    test_bouts_frames.append(bouts[i])
+                if i in train_bouts_idx:
+                    train_bouts_frames.append(bouts[i])
+            return [i for s in test_bouts_frames for i in s], [i for s in train_bouts_frames for i in s]
+
+        test_bouts_frames, train_bouts_frames = find_bouts(s=y_df, type='behavior present')
+        test_nonbouts_frames, train_nonbouts_frames = find_bouts(s=np.logical_xor(y_df, 1).astype(int),
+                                                                 type='behavior absent')
+        x_train = x_df[x_df.index.isin(train_bouts_frames + train_nonbouts_frames)]
+        x_test = x_df[x_df.index.isin(test_bouts_frames + test_nonbouts_frames)]
+        y_train = y_df[y_df.index.isin(train_bouts_frames + train_nonbouts_frames)]
+        y_test = y_df[y_df.index.isin(test_bouts_frames + test_nonbouts_frames)]
+
+        return x_train, x_test, y_train, y_test
+
+    def check_sampled_dataset_integrity(self,
+                                        x_df: pd.DataFrame,
+                                        y_df: pd.DataFrame):
+
+        x_df = x_df.replace([np.inf, -np.inf, None], np.nan)
+        x_nan_cnt = x_df.isna().sum()
+        x_nan_cnt = x_nan_cnt[x_nan_cnt > 0]
+
+        if len(x_nan_cnt) > 0:
+            if len(x_nan_cnt) < 10:
+                raise FaultyTrainingSetError(
+                    msg=f'{str(len(x_nan_cnt))} feature column(s) exist in some files within the project_folder/csv/targets_inserted directory, but missing in others. ' \
+                        f'SimBA expects all files within the project_folder/csv/targets_inserted directory to have the same number of features: the ' \
+                        f'column names with mismatches are: {list(x_nan_cnt.index)}')
+            else:
+                raise FaultyTrainingSetError(
+                    msg=f'{str(len(x_nan_cnt))} feature columns exist in some files, but missing in others. The feature files are found in the project_folder/csv/targets_inserted directory. ' \
+                        f'SimBA expects all files within the project_folder/csv/targets_inserted directory to have the same number of features: the first 10 ' \
+                        f'column names with mismatches are: {list(x_nan_cnt.index)[0:9]}')
+
+        if len(y_df.unique()) == 1:
+            if y_df.unique()[0] == 0:
+                raise FaultyTrainingSetError(
+                    msg=f'All training annotations for classifier {str(y_df.name)} is labelled as ABSENT. A classifier has be be trained with both behavior PRESENT and ABSENT ANNOTATIONS.')
+            if y_df.unique()[0] == 1:
+                raise FaultyTrainingSetError(
+                    msg=f'All training annotations for classifier {str(y_df.name)} is labelled as PRESENT. A classifier has be be trained with both behavior PRESENT and ABSENT ANNOTATIONS.')
+
+    def partial_dependence_calculator(self,
+                                      clf: RandomForestClassifier,
+                                      x_df: pd.DataFrame,
+                                      clf_name: str,
+                                      save_dir: str,
+                                      clf_cnt: int or None = None):
+
+        print(f'Calculating partial dependencies for {len(x_df.columns)} features...')
+        clf.verbose = 0
+        check_if_dir_exists(save_dir)
+        if clf_cnt:
+            save_dir = os.path.join(save_dir, f'partial_dependencies_{clf_name}_{clf_cnt}')
+        else:
+            save_dir = os.path.join(save_dir, f'partial_dependencies_{clf_name}')
+        if not os.path.exists(save_dir): os.makedirs(save_dir)
+        for feature_cnt, feature_name in enumerate(x_df.columns):
+            save_path = os.path.join(save_dir, f'{feature_name}.csv')
+            pdp, axes = partial_dependence(clf, features=[feature_name], X=x_df, percentiles=(0, 1), grid_resolution=30)
+            df = pd.DataFrame({'partial dependence': pdp[0], 'feature value': axes[0]})
+            df.to_csv(save_path)
+            print(f'Partial dependencies for {feature_name} complete...')
+
+    def clf_predict_proba(self,
+                          clf: RandomForestClassifier,
+                          x_df: pd.DataFrame,
+                          model_name: str or None = None,
+                          data_path: str or None = None):
+        if len(x_df.columns) != clf.n_features_:
+            if model_name and data_path:
+                raise FeatureNumberMismatchError(f'Mismatch in the number of features in input file {data_path}, and what is expected by the model {model_name}. The model expects {str(clf.n_features_)} features. The data contains {len(x_df.columns)} features.')
+            else:
+                raise FeatureNumberMismatchError(f'The model expects {str(clf.n_features_)} features. The data contains {len(x_df.columns)} features.')
+        p_vals = clf.predict_proba(x_df)
+        if p_vals.shape[1] != 2:
+            raise ClassifierInferenceError(
+                msg='The classifier {model_name} has not been created properly. See The SimBA GitHub FAQ page or Gitter for more information and suggested fixes.')
+        return p_vals[:, 1]
+
+    def clf_fit(self,
+                clf: RandomForestClassifier,
+                x_df: pd.DataFrame,
+                y_df: pd.DataFrame):
+        nan_features = x_df[~x_df.applymap(np.isreal).all(1)]
+        nan_target = y_df.loc[pd.to_numeric(y_df).isna()]
+        if len(nan_features) > 0:
+            raise FaultyTrainingSetError(
+                msg=f'{len(nan_features)} frame(s) in your project_folder/csv/targets_inserted directory contains FEATURES with non-numerical values')
+        if len(nan_target) > 0:
+            raise FaultyTrainingSetError(
+                msg=f'{len(nan_target)} frame(s) in your project_folder/csv/targets_inserted directory contains ANNOTATIONS with non-numerical values')
+        return clf.fit(x_df, y_df)
+
+    def _read_data_file_helper(self,
+                               file_path: str,
+                               file_type: str,
+                               clf_names: list or None=None):
+        """ Private function called by ``simba.train_model_functions.read_all_files_in_folder_mp`` """
+
+        timer = SimbaTimer(start=True)
+        _, vid_name, _ = get_fn_ext(file_path)
+        df = read_df(file_path, file_type).dropna(axis=0, how='all').fillna(0)
+        df.index = [vid_name] * len(df)
+        if clf_names != None:
+            for clf_name in clf_names:
+                if not clf_name in df.columns:
+                    raise ColumnNotFoundError(column_name=clf_name, file_name=file_path)
+        timer.stop_timer()
+        print(f'Reading complete {vid_name} (elapsed time: {timer.elapsed_time_str}s)...')
+        return df
+
+    def read_all_files_in_folder_mp(self,
+                                    file_paths: list,
+                                    file_type: str,
+                                    classifier_names: list or None = None):
+        """
+
+        Multiprocessing helper function to read in all data files in a folder to a single
+        pd.DataFrame for downstream ML. Defaults to ceil(CPU COUNT / 2) cores. Asserts that all classifiers
+        have annotation fields present in each dataframe.
+
+        Parameters
+        ----------
+        file_paths: list
+            List of file paths representing files to be read in.
+        file_type: str
+            Type of files in ``file_paths``. OPTIONS: csv or parquet.
+        classifier_names: list or None
+            List of classifier names representing fields of human annotations. If not None, then assert that classifier names
+            are present in each data file.
+
+        Returns
+        -------
+        pd.DataFrame
+
+        """
+        if platform.system() == "Darwin":
+            multiprocessing.set_start_method('spawn', force=True)
+        cpu_cnt, _ = find_core_cnt()
+        df_lst = []
+        try:
+            with ProcessPoolExecutor(int(np.ceil(cpu_cnt / 2))) as pool:
+                for res in pool.map(self._read_data_file_helper, file_paths, repeat(file_type), repeat(classifier_names)):
+                    df_lst.append(res)
+            df_concat = pd.concat(df_lst, axis=0).round(4)
+            if 'scorer' in df_concat.columns:
+                df_concat = df_concat.drop(['scorer'], axis=1)
+            if len(df_concat) == 0:
+                raise NoDataError(msg='SimBA found 0 observations (frames) in the project_folder/csv/targets_inserted directory')
+            df_concat = df_concat.loc[:, ~df_concat.columns.str.contains('^Unnamed')].astype(np.float32)
+            memory_size = get_memory_usage_of_df(df=df_concat)
+            print(f'Dataset size: {memory_size["megabytes"]}MB / {memory_size["gigabytes"]}GB')
+            return df_concat
+
+        except BrokenProcessPool or AttributeError:
+            return self.read_all_files_in_folder(file_paths=file_paths,
+                                            file_type=file_type,
+                                            classifier_names=classifier_names)
+
+    def check_raw_dataset_integrity(self,
+                                    df: pd.DataFrame,
+                                    logs_path: str) -> pd.DataFrame:
+
+        nan_cols = df.reset_index(drop=True).replace([np.inf, -np.inf, None], np.nan).columns[df.isna().any()].tolist()
+        if len(nan_cols) == 0:
+            return df.reset_index(drop=True)
+        else:
+            save_log_path = os.path.join(logs_path, f'missing_columns_{datetime.now().strftime("%Y%m%d%H%M%S")}.csv')
+            results = {}
+            for video in list(df.index.unique()):
+                results[video] = {}
+            for nan_col in nan_cols:
+                nan_videos = list(df[df[nan_col].isna()].index.unique())
+                non_nan_video = [x for x in list(results.keys()) if x not in nan_videos]
+                for video in nan_videos: results[video][nan_col] = False
+                for video in non_nan_video: results[video][nan_col] = True
+            results = pd.DataFrame.from_dict(data=results, orient='index')
+            results.to_csv(save_log_path)
+            raise FaultyTrainingSetError(
+                msg=f'{len(nan_cols)} feature columns exist in some files, but missing in others. The feature files are found in the project_folder/csv/targets_inserted directory. ' \
+                    f'SimBA expects all files within the project_folder/csv/targets_inserted directory to have the same number of features: the first 10 ' \
+                    f'column names with mismatches are: {nan_cols[0:9]}. For a log of the files that contain, and not contain, the mis-matched columns, see {save_log_path}')
+
+
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/SimBA_dash_app.py` & `Simba-UW-tf-dev-1.57.6/simba/SimBA_dash_app.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/timebins_clf_analyzer.py` & `Simba-UW-tf-dev-1.57.6/simba/timebins_clf_analyzer.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,19 +1,16 @@
 __author__ = "Simon Nilsson"
 
 import pandas as pd
-from simba.read_config_unit_tests import (check_int,
-                                          check_if_filepath_list_is_empty)
-from simba.misc_tools import (detect_bouts)
-from simba.utils.printing import stdout_success
-from simba.feature_extractors.unit_tests import read_video_info
 import os, glob
-from simba.rw_dfs import read_df
-from simba.drop_bp_cords import get_fn_ext
 from collections import defaultdict
+from simba.utils.checks import check_int, check_if_filepath_list_is_empty
+from simba.utils.data import detect_bouts
+from simba.utils.printing import stdout_success
+from simba.utils.read_write import get_fn_ext, read_df
 from simba.mixins.config_reader import ConfigReader
 from simba.utils.errors import NoChoosenMeasurementError
 
 class TimeBinsClf(ConfigReader):
 
     """
     Class for aggregating classification results into user-defined time-bins. Results are stored in
@@ -45,15 +42,15 @@
                  bin_length: int,
                  measurements: list,
                  classifiers: list):
 
         super().__init__(config_path=config_path)
         if len(measurements) == 0:
             raise NoChoosenMeasurementError()
-        check_int(name='Bin length', value=bin_length)
+        check_int(name='Bin length', value=bin_length, min_value=1)
         self.bin_length, self.measurements, self.classifiers = int(bin_length), measurements, classifiers
         self.files_found = glob.glob(self.machine_results_dir + '/*.' + self.file_type)
         check_if_filepath_list_is_empty(filepaths=self.files_found,
                                         error_msg=f'SIMBA ERROR: Cannot perform time-bin classification analysis, no data in {self.machine_results_dir} directory')
         print('Processing {} video(s)...'.format(str(len(self.files_found))))
         self.out_df_lst = []
 
@@ -67,15 +64,15 @@
         None
         """
 
         video_dict = {}
         for file_cnt, file_path in enumerate(self.files_found):
             dir_name, file_name, extension = get_fn_ext(file_path)
             data_df = read_df(file_path, self.file_type)
-            video_settings, px_per_mm, fps = read_video_info(self.video_info_df, file_name)
+            video_settings, px_per_mm, fps = self.read_video_info(video_name=file_name)
             fps = int(fps)
             bin_frame_length = self.bin_length * fps
             data_df_lst = [data_df[i:i + bin_frame_length] for i in range(0, data_df.shape[0], bin_frame_length)]
             video_dict[file_name] = {}
             for bin_cnt, df in enumerate(data_df_lst):
                 video_dict[file_name][bin_cnt] = {}
                 bouts_df = detect_bouts(data_df=df, target_lst=list(self.clf_names), fps=fps)
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/calculate_px_dist.py` & `Simba-UW-tf-dev-1.57.6/simba/calculate_px_dist.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 __author__ = "Simon Nilsson"
 
 import cv2
 import os
-from simba.misc_tools import (get_video_meta_data,
-                              get_fn_ext)
 from copy import deepcopy
 import numpy as np
+from simba.utils.read_write import get_fn_ext, get_video_meta_data
+
 
 class CalculatePixelDistanceTool(object):
 
     def __init__(self,
                  video_path: str,
                  known_mm_distance: float):
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/movement_processor.py` & `Simba-UW-tf-dev-1.57.6/simba/movement_processor.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,27 +1,23 @@
 __author__ = "Simon Nilsson"
 
 import pandas as pd
-from simba.misc_tools import (get_fn_ext,
-                              framewise_euclidean_distance,
-                              )
-from simba.utils.printing import stdout_success
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.read_config_unit_tests import (read_config_entry,
-                                          check_if_filepath_list_is_empty)
-from simba.utils.errors import NoSpecifiedOutputError
-from simba.enums import ReadConfig
 import os
-from simba.mixins.config_reader import ConfigReader
 from collections import defaultdict
-from simba.rw_dfs import read_df
 import numpy as np
 from statistics import mean
+from simba.utils.printing import stdout_success
+from simba.utils.read_write import read_config_entry, read_df, get_fn_ext
+from simba.utils.checks import check_if_filepath_list_is_empty
+from simba.utils.errors import NoSpecifiedOutputError
+from simba.enums import ReadConfig
+from simba.mixins.config_reader import ConfigReader
+from simba.mixins.feature_extraction_mixin import FeatureExtractionMixin
 
-class MovementProcessor(ConfigReader):
+class MovementProcessor(ConfigReader, FeatureExtractionMixin):
     """
     Class for computing aggregate movement statistics.
 
     Parameters
     ----------
     config_path: str
         path to SimBA project config file in Configparser format
@@ -85,29 +81,29 @@
         """
         self.results = {}
         self.movement_dict = {}
         for file_path in self.files_found:
             _, video_name, _ = get_fn_ext(file_path)
             print('Analysing {}...'.format(video_name))
             self.data_df = read_df(file_path, self.file_type)[self.bp_columns]
-            self.video_info, self.px_per_mm, self.fps = read_video_info(vid_info_df=self.video_info_df, video_name=video_name)
+            self.video_info, self.px_per_mm, self.fps = self.read_video_info(video_name=video_name)
             self.results[video_name] = {}
             self.movement_dict[video_name] = {}
             for animal_name, animal_bps in self.bp_dict.items():
                 self.results[video_name][animal_name] = {}
                 animal_df = self.data_df[animal_bps]
                 if self.p_threshold > 0.00:
                     animal_df = animal_df[animal_df[animal_bps[2]] >= self.p_threshold]
                 animal_df = animal_df.iloc[:, 0:2].reset_index(drop=True)
                 df_shifted = animal_df.shift(1)
                 df_shifted = df_shifted.combine_first(animal_df).add_suffix('_shifted')
                 animal_df = pd.concat([animal_df, df_shifted], axis=1)
                 bp_time_1 = animal_df[[animal_bps[0], animal_bps[1]]].values.astype(float)
                 bp_time_2 = animal_df[[animal_bps[0] + '_shifted', animal_bps[1] + '_shifted']].values.astype(float)
-                self.movement = pd.Series(framewise_euclidean_distance(location_1=bp_time_1, location_2=bp_time_2, px_per_mm=self.px_per_mm))
+                self.movement = pd.Series(self.framewise_euclidean_distance(location_1=bp_time_1, location_2=bp_time_2, px_per_mm=self.px_per_mm))
                 self.movement.loc[0] = 0
                 self.movement_dict[video_name][animal_name] = self.movement
                 self.results[video_name][animal_name]['Distance (cm)'] = round((self.movement.sum() / 10), 4)
                 velocity_lst = []
                 for df in np.array_split(self.movement, int(len(self.movement) / self.fps)):
                     velocity_lst.append(df.sum())
                 self.results[video_name][animal_name]['Velocity (cm/s)'] = round((mean(velocity_lst) / 10), 4)
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pybursts.py` & `Simba-UW-tf-dev-1.57.6/simba/pybursts.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/rw_dfs.py` & `Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_multiply.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,117 +1,75 @@
+import os, glob
 import pandas as pd
-from simba.utils.errors import InvalidFileTypeError
-from simba.enums import Formats
-from simba.read_config_unit_tests import check_file_exist_and_readable
-import pyarrow as pa
-import numpy as np
-import pickle
-from pyarrow import csv
-
-
-PARSE_OPTIONS = csv.ParseOptions(delimiter=',')
-READ_OPTIONS = csv.ReadOptions(encoding='utf8')
-
-def read_df(file_path: str,
-            file_type: str,
-            idx=0,
-            remove_columns: list or None=None,
-            usecols: list or None=None):
-    """
-    Helper function to read single data file into memory.
-
-    Parameters
-    ----------
-    file_path: str
-        Path to data file.
-    file_type: str
-        Type of data. OPTIONS: 'parquet' or 'csv'.
-    idx: int,
-        Index column location. Default: 0.
-    remove_columns: list or None,
-        If list, then remove columns
-    usecols: list or None,
-        If list, keep columns
-
-    Returns
-    -------
-    df: pd.DataFrame
-
-    """
-    check_file_exist_and_readable(file_path=file_path)
-    if file_type == Formats.CSV.value:
-        try:
-            df = csv.read_csv(file_path, parse_options=PARSE_OPTIONS, read_options=READ_OPTIONS)
-            duplicate_headers = list(set([x for x in df.column_names if df.column_names.count(x) > 1]))
-            if len(duplicate_headers) == 1:
-                new_headers = [duplicate_headers[0] + f'_{x}' for x in range(len(df.column_names))]
-                df = df.rename_columns(new_headers)
-            df = df.to_pandas().iloc[:, 1:]
-        except Exception as e:
-            print(e, e.args)
-            raise InvalidFileTypeError(msg=f'{file_path} is not a valid CSV file')
-        if remove_columns:
-            df = df[df.columns[~df.columns.isin(remove_columns)]]
-        if usecols:
-            df = df[df.columns[df.columns.isin(usecols)]]
-    elif file_type == Formats.PARQUET.value:
-        df = pd.read_parquet(file_path)
-    else:
-        raise InvalidFileTypeError(msg=f'{file_type} is not a valid filetype OPTIONS: [csv, parquet]')
+from simba.utils.errors import NoROIDataError
+from simba.utils.read_write import get_fn_ext, read_config_file
+from simba.enums import Paths, ReadConfig, Keys
+from simba.utils.printing import stdout_success
+
+
+def create_emty_df(shape_type):
+    col_list = None
+    if shape_type == Keys.ROI_RECTANGLES.value:
+        col_list = ['Video', 'Shape_type', 'Name', 'Color name', 'Color BGR', 'Thickness', 'topLeftX',
+         'topLeftY', 'Bottom_right_X', 'Bottom_right_Y', 'width', 'height', 'Tags', 'Ear_tag_size']
+    if shape_type == Keys.ROI_CIRCLES.value:
+        col_list = ['Video', 'Shape_type', 'Name', 'Color name', 'Color BGR', 'Thickness', 'centerX', 'centerY',
+         'radius', 'Tags', 'Ear_tag_size']
+    if shape_type == Keys.ROI_POLYGONS.value:
+        col_list = ['Video', 'Shape_type', 'Name', 'Color name', 'Color BGR', 'Thickness', 'Center_X', 'Center_Y', 'vertices', 'Tags', 'Ear_tag_size']
+    return pd.DataFrame(columns=col_list)
+
+def multiply_ROIs(config_path, filename):
+    _, CurrVidName, ext = get_fn_ext(filename)
+    config = read_config_file(config_path=config_path)
+    projectPath = config.get(ReadConfig.GENERAL_SETTINGS.value, ReadConfig.PROJECT_PATH.value)
+    videoPath = os.path.join(projectPath, 'videos')
+    ROIcoordinatesPath = os.path.join(projectPath, 'logs', Paths.ROI_DEFINITIONS.value)
+
+    if not os.path.isfile(ROIcoordinatesPath):
+        raise NoROIDataError(msg='Cannot multiply ROI definitions: no ROI definitions exist in SimBA project')
+    rectanglesInfo = pd.read_hdf(ROIcoordinatesPath, key=Keys.ROI_RECTANGLES.value)
+    circleInfo = pd.read_hdf(ROIcoordinatesPath, key=Keys.ROI_CIRCLES.value)
+    polygonInfo = pd.read_hdf(ROIcoordinatesPath, key=Keys.ROI_POLYGONS.value)
+
+    try:
+        r_df = rectanglesInfo[rectanglesInfo['Video'] == CurrVidName]
+    except KeyError:
+        r_df = create_emty_df('rectangle')
+
+    try:
+        c_df = circleInfo.loc[circleInfo['Video'] == str(CurrVidName)]
+    except KeyError:
+        c_df = create_emty_df('circle')
+
+    try:
+        p_df = polygonInfo.loc[polygonInfo['Video'] == str(CurrVidName)]
+    except KeyError:
+        p_df = create_emty_df('polygon')
 
-    return df
+    if (len(r_df) == 0 and len(c_df) == 0 and len(p_df) == 0):
+        print('Cannot replicate ROIs to all videos: no ROI records exist for ' + str(CurrVidName))
 
-def save_df(df: pd.DataFrame,
-            file_type: str,
-            save_path: str):
-    """
-    Helper function to save single data file from memory.
-
-    Parameters
-    ----------
-    df: pd.DataFrame
-        Pandas dataframe to save to disk.
-    file_type: str
-        Type of data. OPTIONS: 'parquet' or 'csv'.
-    save_path: str,
-        Location where to store the data.
-
-    Returns
-    -------
-    None
-    """
-
-    if file_type == Formats.CSV.value:
-        df = df.drop('scorer', axis=1, errors='ignore')
-        idx = np.arange(len(df)).astype(str)
-        df.insert(0, '', idx)
-        df = pa.Table.from_pandas(df=df)
-        try:
-            df = df.drop(['__index_level_0__'])
-        except KeyError:
-            pass
-        csv.write_csv(df, save_path)
-    elif file_type == Formats.PARQUET.value:
-        df.to_parquet(save_path)
-    elif file_type == Formats.PICKLE.value:
-        try:
-            with open(save_path, 'wb') as f:
-                pickle.dump(df, f, protocol=pickle.HIGHEST_PROTOCOL)
-        except Exception as e:
-            print(e.args[0])
-            raise InvalidFileTypeError(msg='Data could not be saved as a pickle.')
     else:
-        raise InvalidFileTypeError(msg=f'{file_type} is not a valid filetype OPTIONS: [csv, pickle, parquet]')
+        videofilesFound = glob.glob(videoPath + '/*.mp4') + glob.glob(videoPath + '/*.avi')
+        duplicatedRec, duplicatedCirc, duplicatedPoly = (r_df.copy(), c_df.copy(), p_df.copy())
+        for vids in videofilesFound:
+            _, vid_name, ext = get_fn_ext(vids)
+            duplicatedRec['Video'], duplicatedCirc['Video'], duplicatedPoly['Video'] = (vid_name, vid_name, vid_name)
+            r_df = r_df.append(duplicatedRec, ignore_index=True)
+            c_df = c_df.append(duplicatedCirc, ignore_index=True)
+            p_df = p_df.append(duplicatedPoly, ignore_index=True)
+        r_df = r_df.drop_duplicates(subset=['Video', 'Name'], keep="first")
+        c_df = c_df.drop_duplicates(subset=['Video', 'Name'], keep="first")
+        p_df = p_df.drop_duplicates(subset=['Video', 'Name'], keep="first")
+
+        store = pd.HDFStore(ROIcoordinatesPath, mode='w')
+        store['rectangles'] = r_df
+        store['circleDf'] = c_df
+        store['polygons'] = p_df
+        store.close()
+        stdout_success(msg=f'ROI(s) for {CurrVidName} applied to all videos')
+        print()
+        print('Next, click on "draw" to modify ROI location(s) or click on "reset" to remove ROI drawing(s)')
+
+
 
-# df = read_df(file_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/csv/input_csv/Together_1.csv', file_type='csv')
-# df = df.loc[2:]
-# df = pd.concat([df, df, df,df, df, df,df, df, df]).reset_index(drop=True)
-# df = pd.concat([df, df, df]).reset_index(drop=True)
-# df = pd.concat([df, df,df, df, df]).reset_index(drop=True)
-# df = pd.concat([df, df, df, df], axis=1).reset_index(drop=True)
-# df.columns = [str(x) for x in range(len(df.columns))]
-# print(len(df))
-#
-#
-# start = time.time()
-# save_df(df=df, file_type='csv', save_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/csv/validation/test.csv')
-# print(time.time() - start)
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/reverse_2_animal_tracking.py` & `Simba-UW-tf-dev-1.57.6/simba/reverse_2_animal_tracking.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,48 +1,40 @@
 __author__ = "Simon Nilsson", "JJ Choong"
 
 import pandas as pd
 import shutil
-from simba.read_config_unit_tests import read_config_entry, check_that_column_exist, read_config_file, check_file_exist_and_readable
-from datetime import datetime
-from simba.misc_tools import check_multi_animal_status, get_fn_ext
 import os, glob
-from simba.rw_dfs import read_df, save_df
-from simba.drop_bp_cords import getBpNames, create_body_part_dictionary
+from datetime import datetime
+
 from simba.feature_extractors.feature_extractor_16bp import ExtractFeaturesFrom16bps
 from simba.feature_extractors.feature_extractor_14bp import ExtractFeaturesFrom14bps
 from simba.feature_extractors.extract_features_9bp import extract_features_wotarget_9
 from simba.feature_extractors.feature_extractor_8bp import ExtractFeaturesFrom8bps
 from simba.feature_extractors.feature_extractor_7bp import ExtractFeaturesFrom7bps
 from simba.feature_extractors.feature_extractor_4bp import ExtractFeaturesFrom4bps
 from simba.feature_extractors.feature_extractor_user_defined import UserDefinedFeatureExtractor
-from simba.train_model_functions import get_all_clf_names
+from simba.mixins.config_reader import ConfigReader
+from simba.utils.read_write import read_config_entry, read_df, write_df, get_fn_ext, get_all_clf_names
+from simba.utils.checks import check_that_column_exist, check_file_exist_and_readable
 
-class Reverse2AnimalTracking(object):
+class Reverse2AnimalTracking(ConfigReader):
     def __init__(self,
                  config_path: str):
 
-        self.datetime = datetime.now().strftime('%Y%m%d%H%M%S')
-        self.config, self.config_path = read_config_file(config_path), config_path
-        self.project_path = read_config_entry(self.config, 'General settings', 'project_path', data_type='folder_path')
-        self.file_type = read_config_entry(self.config, 'General settings', 'workflow_file_type', 'str', 'csv')
+        ConfigReader.__init__(self, config_path=config_path)
         self.in_dir = os.path.join(self.project_path, 'csv', 'outlier_corrected_movement_location')
         self.features_path = os.path.join(self.project_path, 'csv', 'features_extracted')
         self.targets_path = os.path.join(self.project_path, 'csv', 'targets_inserted')
         self.model_cnt = read_config_entry(self.config, 'SML settings', 'No_targets', data_type='int')
         self.store_path_features = os.path.join(self.features_path, 'Non_reversed_files_at_' + str(self.datetime))
         self.store_path_targets = os.path.join(self.targets_path, 'Non_reversed_files_at_' + str(datetime))
         self.store_path_outliers = os.path.join(self.in_dir, 'Non_reversed_files_at_' + str(datetime))
         if not os.path.exists(self.store_path_features): os.makedirs(self.store_path_features)
         if not os.path.exists(self.store_path_targets): os.makedirs(self.store_path_targets)
         if not os.path.exists(self.store_path_outliers): os.makedirs(self.store_path_outliers)
-        self.animal_cnt = read_config_entry(self.config, 'General settings', 'animal_no', 'int')
-        self.multi_animal_status, self.multi_animal_id_lst = check_multi_animal_status(self.config, self.animal_cnt)
-        self.x_cols, self.y_cols, self.p_cols = getBpNames(config_path)
-        self.animal_bp_dict = create_body_part_dictionary(self.multi_animal_status, list(self.multi_animal_id_lst), self.animal_cnt, list(self.x_cols), list(self.y_cols), [], [])
         self.pose_estimation_setting = read_config_entry(self.config, 'create ensemble settings', 'pose_estimation_body_parts', 'str')
 
         self.files_found = glob.glob(self.in_dir + '/*.' + self.file_type)
         print('Processing {} video(s)...'.format(str(len(self.files_found))))
 
     def reverse_tracking(self):
         for file_cnt, file_path in enumerate(self.files_found):
@@ -52,15 +44,15 @@
             animal_dict, col_counter = {}, 0
             for animal_cnt, (animal_name, animal_bps) in enumerate(self.animal_bp_dict.items()):
                 animal_dict[animal_cnt] = self.data_df.iloc[:, col_counter:col_counter + len(animal_bps['X_bps'] * 3)]
                 col_counter += len(animal_bps['X_bps'] * 3)
             for k in reversed(list(animal_dict.keys())):
                 self.reversed_df = pd.concat([self.reversed_df, animal_dict[k]], axis=1)
             shutil.move(file_path, os.path.join(self.store_path_outliers, os.path.basename(file_path)))
-            save_df(self.reversed_df, self.file_type, file_path)
+            write_df(self.reversed_df, self.file_type, file_path)
 
     def create_features(self):
         old_feature_files = glob.glob(self.features_path + '/*.' + self.file_type)
         for file_path in old_feature_files:
             shutil.move(file_path, os.path.join(self.store_path_features, os.path.basename(file_path)))
         if self.pose_estimation_setting == '16':
             ExtractFeaturesFrom16bps(self.config_path)
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/Directing_animals_analyzer.py` & `Simba-UW-tf-dev-1.57.6/simba/Directing_animals_analyzer.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,24 +1,21 @@
 __author__ = "Simon Nilsson"
 
-from simba.read_config_unit_tests import check_if_filepath_list_is_empty
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.misc_tools import line_length_numba, SimbaTimer
-from simba.utils.printing import stdout_success
-from simba.drop_bp_cords import (get_fn_ext,
-                                 checkDirectionalityCords)
-from simba.rw_dfs import read_df
 import pandas as pd
-from simba.mixins.config_reader import ConfigReader
-from simba.utils.errors import AnimalNumberError
 import itertools
 import numpy as np
 import os
+from simba.read_config_unit_tests import check_if_filepath_list_is_empty
+from simba.mixins.feature_extraction_mixin import FeatureExtractionMixin
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.utils.read_write import read_df, get_fn_ext
+from simba.mixins.config_reader import ConfigReader
+from simba.utils.errors import AnimalNumberError
 
-class DirectingOtherAnimalsAnalyzer(ConfigReader):
+class DirectingOtherAnimalsAnalyzer(ConfigReader, FeatureExtractionMixin):
     """
     Class for calculating when animals are directing towards body-parts of other animals. Results are stored in
     the `project_folder/logs/directionality_dataframes` directory of the SimBA project
 
     Parameters
     ----------
     config_path: str
@@ -60,30 +57,29 @@
         -------
         Attribute: dict
             results_dict
         """
 
         self.results_dict = {}
         for file_cnt, file_path in enumerate(self.outlier_corrected_paths):
-            video_timer = SimbaTimer()
-            video_timer.start_timer()
+            video_timer = SimbaTimer(start=True)
             _, video_name, _ = get_fn_ext(file_path)
             self.results_dict[video_name] = {}
             data_df = read_df(file_path, self.file_type)
-            direct_bp_dict = checkDirectionalityCords(self.animal_bp_dict)
+            direct_bp_dict = self.check_directionality_cords()
             for animal_permutation in self.animal_permutations:
                 self.results_dict[video_name]['{} {} {}'.format(animal_permutation[0], 'directing towards',animal_permutation[1])] = {}
                 first_animal_bps, second_animal_bps = direct_bp_dict[animal_permutation[0]], self.animal_bp_dict[animal_permutation[1]]
                 first_ear_left_arr = data_df[[first_animal_bps['Ear_left']['X_bps'], first_animal_bps['Ear_left']['Y_bps']]].to_numpy()
                 first_ear_right_arr = data_df[[first_animal_bps['Ear_right']['X_bps'], first_animal_bps['Ear_right']['Y_bps']]].to_numpy()
                 first_nose_arr = data_df[[first_animal_bps['Nose']['X_bps'], first_animal_bps['Nose']['Y_bps']]].to_numpy()
                 other_animal_x_bps, other_animal_y_bps = second_animal_bps['X_bps'], second_animal_bps['Y_bps']
                 for x_bp, y_bp in zip(other_animal_x_bps, other_animal_y_bps):
                     target_cord_arr = data_df[[x_bp, y_bp]].to_numpy()
-                    direction_data = line_length_numba(left_ear_array=first_ear_left_arr, right_ear_array=first_ear_right_arr, nose_array=first_nose_arr, target_array=target_cord_arr)
+                    direction_data = self.jitted_line_crosses_to_nonstatic_targets(left_ear_array=first_ear_left_arr, right_ear_array=first_ear_right_arr, nose_array=first_nose_arr, target_array=target_cord_arr)
                     x_min = np.minimum(direction_data[:, 1], first_nose_arr[:, 0])
                     y_min = np.minimum(direction_data[:, 2], first_nose_arr[:, 1])
                     delta_x = abs((direction_data[:, 1] - first_nose_arr[:, 0]) / 2)
                     delta_y = abs((direction_data[:, 2] - first_nose_arr[:, 1]) / 2)
                     x_middle, y_middle = np.add(x_min, delta_x), np.add(y_min, delta_y)
                     direction_data = np.concatenate((y_middle.reshape(-1, 1), direction_data), axis=1)
                     direction_data = np.concatenate((x_middle.reshape(-1, 1), direction_data), axis=1)
@@ -149,15 +145,15 @@
         -------
         None
         """
 
         print('Computing summary statistics...')
         out_df_lst = []
         for video_name, video_data in self.results_dict.items():
-            _, _, fps = read_video_info(self.video_info_df, video_name)
+            _, _, fps = self.read_video_info(video_name=video_name)
             for animal_permutation, permutation_data in video_data.items():
                 idx_directing = set()
                 for bp_name, bp_data in permutation_data.items():
                     idx_directing.update(list(bp_data.index[bp_data['Directing_BOOL'] == 1]))
                 value = round(len(idx_directing) / fps, 3)
                 out_df_lst.append(pd.DataFrame([[video_name, animal_permutation, value]], columns=['Video', 'Animal permutation', 'Value (s)']))
         self.summary_df = pd.concat(out_df_lst, axis=0).sort_values(by=['Video', 'Animal permutation']).set_index('Video')
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/Validate_model_one_video_run_clf.py` & `Simba-UW-tf-dev-1.57.6/simba/Validate_model_one_video_run_clf.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,29 +1,23 @@
 __author__ = "Simon Nilsson"
 
-from simba.read_config_unit_tests import (read_config_file,
-                                          check_file_exist_and_readable,
-                                          read_project_path_and_file_type)
-
-from simba.rw_dfs import (read_df,
-                          save_df)
-from simba.train_model_functions import (read_pickle,
-                                         clf_predict_proba)
-from simba.drop_bp_cords import (get_fn_ext,
-                                 drop_bp_cords)
 from copy import deepcopy
-from simba.utils.printing import stdout_success
-from simba.utils.errors import FeatureNumberMismatchError
+
 import warnings
-import time
 import os
 warnings.filterwarnings('ignore',category=FutureWarning)
 warnings.filterwarnings('ignore',category=DeprecationWarning)
 
-class ValidateModelRunClf(object):
+from simba.utils.printing import stdout_success
+from simba.utils.read_write import read_df, write_df, get_fn_ext
+from simba.utils.checks import check_file_exist_and_readable
+from simba.mixins.config_reader import ConfigReader
+from simba.mixins.train_model_mixin import TrainModelMixin
+
+class ValidateModelRunClf(ConfigReader, TrainModelMixin):
     """
     Class for running a single classifier on a single featurized input file. Results are saved within the
     project_folder/csv/validation directory of the SimBA project.
 
     Parameters
     ----------
     config_file_path: str
@@ -43,33 +37,33 @@
 
     """
 
     def __init__(self,
                  config_path: str,
                  input_file_path: str,
                  clf_path: str):
-        self.start_time = time.time()
-        self.config = read_config_file(config_path)
-        self.project_path, self.file_type = read_project_path_and_file_type(config=self.config)
+
+        ConfigReader.__init__(self, config_path=config_path)
+        TrainModelMixin.__init__(self)
         self.save_path = os.path.join(self.project_path, 'csv', 'validation')
         if not os.path.exists(self.save_path): os.makedirs(self.save_path)
 
         check_file_exist_and_readable(input_file_path)
         check_file_exist_and_readable(clf_path)
         _, file_name, _ = get_fn_ext(str(input_file_path))
         _, classifier_name, _ = get_fn_ext(clf_path)
         data_df = read_df(input_file_path, self.file_type)
         output_df = deepcopy(data_df)
-        data_df = drop_bp_cords(data_df, config_path)
-        clf = read_pickle(file_path=clf_path)
+        data_df = self.drop_bp_cords(df=data_df)
+        clf = self.read_pickle(file_path=clf_path)
         probability_col_name = f'Probability_{classifier_name}'
-        output_df[probability_col_name] = clf_predict_proba(clf=clf, x_df=data_df)
+        output_df[probability_col_name] = self.clf_predict_proba(clf=clf, x_df=data_df)
         save_filename = os.path.join(self.save_path, file_name + '.' + self.file_type)
-        save_df(output_df, self.file_type, save_filename)
-        elapsed_time = str(round(time.time() - self.start_time, 2))
+        write_df(output_df, self.file_type, save_filename)
 
-        stdout_success(msg=f'Validation predictions generated for "{file_name}" within the project_folder/csv/validation directory', elapsed_time=elapsed_time)
+        self.timer.stop_timer()
+        stdout_success(msg=f'Validation predictions generated for "{file_name}" within the project_folder/csv/validation directory', elapsed_time=self.timer.elapsed_time_str)
         print('Click on "Interactive probability plot" to inspect classifier probability thresholds. If satisfactory proceed to specify threshold and minimum bout length and click on "Validate" to create video.')
 #
 # ValidateModelRunClf(config_path=r"Z:\DeepLabCut\DLC_extract\Troubleshooting\DLC_two_mice\project_folder\project_config.ini",
 #                                input_file_path=r"Z:\DeepLabCut\DLC_extract\Troubleshooting\DLC_2_black_060320\project_folder\csv\features_extracted\Together_1.csv",
 #                                clf_path=r"Z:\DeepLabCut\DLC_extract\Troubleshooting\DLC_2_black_060320\models\Approach.sav")
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/tkinter_functions.py` & `Simba-UW-tf-dev-1.57.6/simba/tkinter_functions.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,17 +1,18 @@
 __author__ = "Simon Nilsson", "JJ Choong"
 
 from tkinter import *
 import platform
-from simba.enums import Defaults, Formats
-from tkinter.filedialog import askopenfilename, askdirectory
-from simba.utils.lookups import get_icons_paths
 from PIL import ImageTk
 import PIL.Image
 import webbrowser
+from tkinter.filedialog import askopenfilename, askdirectory
+from simba.utils.lookups import get_icons_paths
+from simba.enums import Defaults, Formats
+
 
 MENU_ICONS = get_icons_paths()
 
 def onMousewheel(event, canvas):
     try:
         scrollSpeed = event.delta
         if platform.system() == 'Darwin':
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/setting_menu.py` & `Simba-UW-tf-dev-1.57.6/simba/setting_menu.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,43 +1,41 @@
 from tkinter import *
-from simba.read_config_unit_tests import read_config_file, read_config_entry, check_float, check_int, read_project_path_and_file_type
 import os
-from simba.misc_tools import check_multi_animal_status
-from simba.drop_bp_cords import getBpNames, create_body_part_dictionary
+
 from simba.roi_tools.ROI_analyzer import ROIAnalyzer
 from simba.roi_tools.ROI_feature_analyzer import ROIFeatureCreator
 from simba.timebins_movement_analyzer import TimeBinsMovementAnalyzer
 from simba.movement_processor import MovementProcessor
 from simba.roi_tools.ROI_time_bin_calculator import ROITimebinCalculator
 from simba.enums import ReadConfig, Formats, Dtypes, Paths
 from simba.utils.errors import NoROIDataError
+from simba.mixins.config_reader import ConfigReader
+from simba.utils.checks import check_float, check_int
+from simba.utils.read_write import read_config_entry
 
-class SettingsMenu(object):
+class SettingsMenu(ConfigReader):
 
     def __init__(self,
                  config_path: str,
                  title: str):
 
-        self.title, self.config_path = title, config_path
-        self.config = read_config_file(ini_path=config_path)
+        ConfigReader.__init__(self, config_path=config_path)
+
+        self.title = title
         self.setting_main = Toplevel()
         self.setting_main.minsize(400, 400)
         self.setting_main.wm_title(self.title)
-        self.project_path, _ = read_project_path_and_file_type(config=self.config)
         self.project_animal_cnt = read_config_entry(config=self.config, section=ReadConfig.GENERAL_SETTINGS.value, option=ReadConfig.ANIMAL_CNT.value, data_type=Dtypes.INT.value)
         self.animal_cnt_frm = LabelFrame(self.setting_main, text='SELECT NUMBER OF ANIMALS', font=Formats.LABELFRAME_HEADER_FORMAT.value)
         self.animal_cnt = IntVar(value=1)
         self.animal_option = set(range(1, self.project_animal_cnt + 1))
         self.animal_cnt_dropdown = OptionMenu(self.animal_cnt_frm, self.animal_cnt, *self.animal_option)
         self.animal_cnt_dropdown_lbl = Label(self.animal_cnt_frm, text="# of animals")
         self.animal_cnt_confirm_btn = Button(self.animal_cnt_frm, text="Confirm", command=lambda: self.display_second_choice_frm())
-        self.multi_animal_status, self.multi_animal_id_lst = check_multi_animal_status(self.config, self.project_animal_cnt)
-        self.x_cols, self.y_cols, self.pcols = getBpNames(config_path)
         self.roi_definitions_path = os.path.join(self.project_path, 'logs', Paths.ROI_DEFINITIONS.value)
-        self.animal_bp_dict = create_body_part_dictionary(self.multi_animal_status, self.multi_animal_id_lst, self.project_animal_cnt, self.x_cols, self.y_cols, [], [])
         self.all_body_parts = []
         for animal, bp_cords in self.animal_bp_dict.items():
             for bp_dim, bp_data in bp_cords.items():
                 self.animal_bp_dict[animal][bp_dim] = [x[:-2] for x in bp_data]
                 self.all_body_parts.extend(([x[:-2] for x in bp_data]))
 
         self.animal_cnt_frm.grid(row=0, sticky=NW)
@@ -167,22 +165,21 @@
             self.config.set(ReadConfig.ROI_SETTINGS.value, ReadConfig.ROI_ANIMAL_CNT.value, str(self.animal_cnt.get()))
             self.config.set(ReadConfig.ROI_SETTINGS.value, ReadConfig.PROBABILITY_THRESHOLD.value, str(self.probability_bp_entry_box.get()))
             self.update_config()
             roi_analyzer = ROIAnalyzer(ini_path=self.config_path,
                                        data_path='outlier_corrected_movement_location',
                                        calculate_distances=self.calculate_distance_moved_var.get(),
                                        settings=settings)
-            roi_analyzer.read_roi_dfs()
-            roi_analyzer.analyze_ROIs()
+            roi_analyzer.run()
             roi_analyzer.save_data()
 
         if self.title == 'APPEND ROI FEATURES':
             roi_feature_creator = ROIFeatureCreator(config_path=self.config_path)
-            roi_feature_creator.analyze_ROI_data()
-            roi_feature_creator.save_new_features_files()
+            roi_feature_creator.run()
+            roi_feature_creator.save()
 
         if self.title == 'ANALYZE MOVEMENT':
             self.config.set(ReadConfig.PROCESS_MOVEMENT_SETTINGS.value, ReadConfig.ROI_ANIMAL_CNT.value, str(self.animal_cnt.get()))
             check_float(name='Probability threshold', value=self.probability_bp_entry_box.get())
             self.config.set(ReadConfig.PROCESS_MOVEMENT_SETTINGS.value, ReadConfig.PROBABILITY_THRESHOLD.value, str(self.probability_bp_entry_box.get()))
             for cnt, (name, data) in enumerate(self.animals_dict.items()):
                 self.config.set(ReadConfig.PROCESS_MOVEMENT_SETTINGS.value, 'animal_{}_bp'.format(str(cnt + 1)), str(self.animals_dict[name]['var'].get()))
@@ -197,21 +194,21 @@
             for cnt, (name, data) in enumerate(self.animals_dict.items()):
                 self.config.set(ReadConfig.PROCESS_MOVEMENT_SETTINGS.value, 'animal_{}_bp'.format(str(cnt + 1)), str(self.animals_dict[name]['var'].get()))
             self.update_config()
             time_bin_movement_analyzer = TimeBinsMovementAnalyzer(config_path=self.config_path, bin_length=int(self.time_bin_val.get()), plots=self.plots_var.get())
             time_bin_movement_analyzer.analyze_movement()
 
         if self.title == 'TIME BINS: ANALYZE ROI':
-            check_int(name='Time bin', value=self.time_bin_val.get())
+            check_int(name='Time bin', value=self.time_bin_val.get(), min_value=1)
             self.config.set(ReadConfig.ROI_SETTINGS.value, ReadConfig.ROI_ANIMAL_CNT.value, str(self.animal_cnt.get()))
             for cnt, (name, data) in enumerate(self.animals_dict.items()):
                 self.config.set(ReadConfig.ROI_SETTINGS.value, f'{name}', str(self.animals_dict[name]['var'].get()))
             self.update_config()
             roi_time_bin_calculator = ROITimebinCalculator(config_path=self.config_path, bin_length=self.time_bin_val.get())
-            roi_time_bin_calculator.analyze_time_bins()
+            roi_time_bin_calculator.run()
             roi_time_bin_calculator.save_results()
 
 
 
 
 # test = SettingsMenu(config_path='/Users/simon/Desktop/envs/troubleshooting/two_animals_16bp_032023/project_folder/project_config.ini', title='ROI ANALYSIS')
 # test.setting_main.mainloop()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/interpolate_pose.py` & `Simba-UW-tf-dev-1.57.6/simba/interpolate_pose.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,13 +1,11 @@
 __author__ = "Simon Nilsson"
 
 import pandas as pd
-from simba.drop_bp_cords import *
 import numpy as np
-from simba.misc_tools import get_number_of_header_columns_in_df
 from simba.mixins.config_reader import ConfigReader
 
 class Interpolate(ConfigReader):
 
     '''
     Class for interpolating missing body-parts in pose-estimation data
 
@@ -31,27 +29,24 @@
 
     '''
 
     def __init__(self,
                  config_file_path: str,
                  in_file: pd.DataFrame):
 
-        super().__init__(config_path=config_file_path)
+        super().__init__(config_path=config_file_path, read_video_info=False)
         self.in_df = in_file
-        self.multi_animal_id_list = [x for x in self.multi_animal_id_list if x]
-        self.animalBpDict = create_body_part_dictionary(True, self.multi_animal_id_list, self.animal_cnt, self.x_cols, self.y_cols, self.p_cols, [])
-
 
     def detect_headers(self):
         """
         Method to detect multi-index headers and set values to numeric in input dataframe
         """
         self.multi_index_headers_list = []
-        self.in_df.columns = self.column_headers
-        self.header_col_cnt = get_number_of_header_columns_in_df(df=self.in_df)
+        self.in_df.columns = self.bp_headers
+        self.header_col_cnt = self.get_number_of_header_columns_in_df(df=self.in_df)
         self.current_df = self.in_df.iloc[self.header_col_cnt:].apply(pd.to_numeric).reset_index(drop=True)
         self.multi_index_headers = self.in_df.iloc[:self.header_col_cnt]
         if self.header_col_cnt == 2:
             self.idx_names = ['scorer', 'bodyparts', 'coords']
             for column in self.multi_index_headers:
                 self.multi_index_headers_list.append((column,
                                                       self.multi_index_headers[column][0],
@@ -77,15 +72,15 @@
 
         """
 
         interpolation_type, interpolation_method = method_str.split(':')[0], method_str.split(':')[1].replace(" ", "").lower()
         self.animal_df_list, self.header_list_p = [], []
         if interpolation_type == 'Animal(s)':
             for animal in self.multi_animal_id_list:
-                currentAnimalX, currentAnimalY, currentAnimalP = self.animalBpDict[animal]['X_bps'], self.animalBpDict[animal]['Y_bps'], self.animalBpDict[animal]['P_bps']
+                currentAnimalX, currentAnimalY, currentAnimalP = self.animal_bp_dict[animal]['X_bps'], self.animal_bp_dict[animal]['Y_bps'], self.animal_bp_dict[animal]['P_bps']
                 header_list_xy = []
                 for col1, col2, col3, in zip(currentAnimalX, currentAnimalY, currentAnimalP):
                     header_list_xy.extend((col1, col2))
                     self.header_list_p.append(col3)
                 self.animal_df_list.append(self.current_df[header_list_xy])
             for loop_val, animal_df in enumerate(self.animal_df_list):
                 repeat_bol = animal_df.eq(animal_df.iloc[:, 0], axis=0).all(axis='columns')
@@ -93,16 +88,16 @@
                 print(f'Detected {str(len(indices_to_replace_animal))} missing pose-estimation frames for {str(self.multi_animal_id_list[loop_val])}...')
                 animal_df.loc[indices_to_replace_animal] = np.nan
                 self.animal_df_list[loop_val] = animal_df.interpolate(method=interpolation_method, axis=0).ffill().bfill()
             self.new_df = pd.concat(self.animal_df_list, axis=1).fillna(0)
 
 
         if interpolation_type == 'Body-parts':
-            for animal in self.animalBpDict:
-                for x_bps_name, y_bps_name in zip(self.animalBpDict[animal]['X_bps'], self.animalBpDict[animal]['Y_bps']):
+            for animal in self.animal_bp_dict:
+                for x_bps_name, y_bps_name in zip(self.animal_bp_dict[animal]['X_bps'], self.animal_bp_dict[animal]['Y_bps']):
                     zero_indices = (self.current_df[(self.current_df[x_bps_name] == 0) & (self.current_df[y_bps_name] == 0)].index.tolist())
                     self.current_df.loc[zero_indices, [x_bps_name, y_bps_name]] = np.nan
                     self.current_df[x_bps_name] = self.current_df[x_bps_name].interpolate(method=interpolation_method, axis=0).ffill().bfill()
                     self.current_df[y_bps_name] = self.current_df[y_bps_name].interpolate(method=interpolation_method, axis=0).ffill().bfill()
             self.new_df = self.current_df.fillna(0)
 
     def reorganize_headers(self):
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/run_inference.py` & `Simba-UW-tf-dev-1.57.6/simba/run_inference.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,31 +1,21 @@
 __author__ = "Simon Nilsson", "JJ Choong"
-from simba.feature_extractors.unit_tests import (read_video_info_csv,
-                                               read_video_info)
-from simba.read_config_unit_tests import (read_config_entry,
-                                          read_config_file,
-                                          read_project_path_and_file_type)
-from simba.train_model_functions import (get_model_info,
-                                         read_pickle,
-                                         clf_predict_proba)
-from simba.misc_tools import (get_fn_ext,
-                              plug_holes_shortest_bout,
-                              SimbaTimer)
-from simba.utils.printing import stdout_success
-from simba.enums import (ReadConfig,
-                         Paths,
-                         Dtypes)
-from simba.drop_bp_cords import drop_bp_cords
-from simba.rw_dfs import read_df, save_df
-import os, glob
+
+import os
 from copy import deepcopy
 import numpy as np
-from simba.utils.errors import NoFilesFoundError, FeatureNumberMismatchError
+from simba.mixins.train_model_mixin import TrainModelMixin
+from simba.mixins.config_reader import ConfigReader
+from simba.utils.data import plug_holes_shortest_bout
+from simba.utils.read_write import get_fn_ext, read_df, write_df
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.utils.errors import NoFilesFoundError
 
-class RunModel(object):
+class RunModel(TrainModelMixin,
+               ConfigReader):
 
     """
     Class for running classifier inference. Results are stored in the `project_folder/csv/machine_results`
     directory of the SimBA project.
 
     Parameters
     ----------
@@ -43,50 +33,42 @@
         """
         Method to run classifier inference. Results are stored in the ``project_folder/csv/machine_results`` directory
         of the SimBA project.
 
         Returns
         ----------
         None
-
         """
 
-        self.config = read_config_file(config_path)
-        self.config_path = config_path
-        self.project_path, self.file_type = read_project_path_and_file_type(config=self.config)
-        self.model_cnt = read_config_entry(self.config, ReadConfig.SML_SETTINGS.value, ReadConfig.TARGET_CNT.value, data_type=Dtypes.INT.value)
-        self.files_in_dir = os.path.join(self.project_path, Paths.FEATURES_EXTRACTED_DIR.value)
-        self.files_out_dir = os.path.join(self.project_path, Paths.MACHINE_RESULTS_DIR.value)
-        self.vid_info_df = read_video_info_csv(os.path.join(self.project_path, Paths.VIDEO_INFO.value))
-        self.model_dict = get_model_info(self.config, self.model_cnt)
-        self.files_found = glob.glob(self.files_in_dir + '/*.' + self.file_type)
-        if len(self.files_found) == 0:
+        ConfigReader.__init__(self, config_path=config_path)
+        TrainModelMixin.__init__(self)
+        if len(self.feature_file_paths) == 0:
             raise NoFilesFoundError('Zero files found in the project_folder/csv/features_extracted directory. Create features before running classifier.')
-        print('Analyzing {} file(s) with {} classifier(s)'.format(str(len(self.files_found)), str(len(self.model_dict))))
-        self.timer = SimbaTimer()
-        self.timer.start_timer()
+        print(f'Analyzing {len(self.feature_file_paths)} file(s) with {self.clf_cnt} classifier(s)')
+        self.timer = SimbaTimer(start=True)
+        self.model_dict = self.get_model_info(config=self.config, model_cnt=self.clf_cnt)
 
     def run_models(self):
-        for file_cnt, file_path in enumerate(self.files_found):
+        for file_cnt, file_path in enumerate(self.feature_file_paths):
             _, file_name, _ = get_fn_ext(file_path)
             print('Analyzing video {}...'.format(file_name))
-            file_save_path = os.path.join(self.files_out_dir, file_name + '.' + self.file_type)
+            file_save_path = os.path.join(self.machine_results_dir, file_name + '.' + self.file_type)
             in_df = read_df(file_path, self.file_type)
-            x_df = drop_bp_cords(in_df, self.config_path)
-            _, px_per_mm, fps = read_video_info(self.vid_info_df, file_name)
+            x_df = self.drop_bp_cords(df=in_df)
+            _, px_per_mm, fps = self.read_video_info(video_name=file_name)
             out_df = deepcopy(in_df)
             for m, m_hyp in self.model_dict.items():
                 if not os.path.isfile(m_hyp['model_path']):
                     raise NoFilesFoundError(msg=f"{m_hyp['model_path']} is not a VALID model file path")
                 probability_column = 'Probability_' + m_hyp['model_name']
-                clf = read_pickle(file_path=m_hyp['model_path'])
-                out_df[probability_column] = clf_predict_proba(clf=clf, x_df=x_df, data_path=file_path, model_name=m_hyp['model_name'])
+                clf = self.read_pickle(file_path=m_hyp['model_path'])
+                out_df[probability_column] = self.clf_predict_proba(clf=clf, x_df=x_df, data_path=file_path, model_name=m_hyp['model_name'])
                 out_df[m_hyp['model_name']] = np.where(out_df[probability_column] > m_hyp['threshold'], 1, 0)
                 out_df = plug_holes_shortest_bout(data_df=out_df, clf_name=m_hyp['model_name'], fps=fps, shortest_bout=m_hyp['minimum_bout_length'])
-            save_df(out_df, self.file_type, file_save_path)
+            write_df(out_df, self.file_type, file_save_path)
             print('Predictions created for {} ...'.format(file_name))
         self.timer.stop_timer()
         stdout_success(msg='Machine predictions complete. Files saved in project_folder/csv/machine_results directory', elapsed_time=self.timer.elapsed_time_str)
 
 # test = RunModel(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini')
 # test.run_models()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/gantt_creator.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/gantt_creator.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,31 +1,26 @@
 __author__ = "Simon Nilsson"
 
-from simba.misc_tools import (detect_bouts,
-                              get_named_colors,
-                              )
-from simba.utils.printing import stdout_success
-from simba.read_config_unit_tests import check_if_filepath_list_is_empty
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.enums import Formats
-from simba.plotting.misc_visualizations import make_gantt_plot
-from simba.train_model_functions import get_all_clf_names
-from simba.drop_bp_cords import get_fn_ext
-from simba.mixins.config_reader import ConfigReader
-from simba.rw_dfs import read_df
 import os
 import numpy as np
 import matplotlib.pyplot as plt
 import io
 import cv2
 import PIL
 from simba.utils.errors import NoSpecifiedOutputError
+from simba.utils.printing import stdout_success
+from simba.utils.lookups import get_named_colors
+from simba.utils.data import detect_bouts
+from simba.enums import Formats
+from simba.mixins.config_reader import ConfigReader
+from simba.mixins.plotting_mixin import PlottingMixin
+from simba.utils.read_write import read_df, get_fn_ext
+from simba.utils.checks import check_if_filepath_list_is_empty
 
-
-class GanttCreatorSingleProcess(ConfigReader):
+class GanttCreatorSingleProcess(ConfigReader, PlottingMixin):
     """
     Class for creating gantt chart videos and/or images using a single core.
 
     Parameters
     ----------
     config_path: str
         path to SimBA project config file in Configparser format
@@ -45,62 +40,62 @@
     `GitHub gantt tutorial <https://github.com/sgoldenlab/simba/blob/master/docs/tutorial.md#gantt-plot>`__.
     See ``simba.gantt_creator_mp.GanttCreatorMultiprocess`` for multiprocess class.
 
     Examples
     ----------
     >>> style_attr = {'width': 640, 'height': 480, 'font size': 12, 'font rotation': 45}
     >>> gantt_creator = GanttCreatorSingleProcess(config_path='tests/test_data/multi_animal_dlc_two_c57/project_folder/project_config.ini', frame_setting=False, video_setting=True, files_found=['tests/test_data/multi_animal_dlc_two_c57/project_folder/csv/machine_results/Together_1.csv'])
-    >>> gantt_creator.create_gannt()
+    >>> gantt_creator.run()
 
     """
 
     def __init__(self,
                  config_path: str,
                  frame_setting: bool,
                  video_setting: bool,
                  last_frm_setting: bool,
                  files_found: list,
                  style_attr: dict):
 
-        super().__init__(config_path=config_path)
-
+        ConfigReader.__init__(self, config_path=config_path)
+        PlottingMixin.__init__(self)
         self.frame_setting, self.video_setting, self.style_attr, self.last_frm_setting = frame_setting, video_setting, style_attr, last_frm_setting
         self.files_found = files_found
         if (self.frame_setting != True) and (self.video_setting != True) and (self.last_frm_setting != True):
             raise NoSpecifiedOutputError(msg='SIMBA ERROR: Please select gantt videos, frames, and/or last frame.')
         check_if_filepath_list_is_empty(filepaths=self.files_found,
                                         error_msg='SIMBA ERROR: Zero files found in the project_folder/csv/machine_results directory. Create classification results before visualizing gantt charts')
         self.colours = get_named_colors()
         self.colour_tuple_x = list(np.arange(3.5, 203.5, 5))
-        self.clf_names = get_all_clf_names(config=self.config, target_cnt=self.clf_cnt)
+        self.clf_names = self.get_all_clf_names()
         if not os.path.exists(self.gantt_plot_dir): os.makedirs(self.gantt_plot_dir)
         self.fourcc = cv2.VideoWriter_fourcc(*Formats.MP4_CODEC.value)
         print('Processing {} video(s)...'.format(str(len(self.files_found))))
 
-    def create_gannt(self):
+    def run(self):
         for file_cnt, file_path in enumerate(self.files_found):
             _, self.video_name, _ = get_fn_ext(file_path)
             self.data_df = read_df(file_path, self.file_type).reset_index(drop=True)
-            self.video_info_settings, _, self.fps = read_video_info(self.video_info_df, self.video_name)
+            self.video_info_settings, _, self.fps = self.read_video_info(video_name=self.video_name)
             self.bouts_df = detect_bouts(data_df=self.data_df, target_lst=self.clf_names, fps=self.fps)
             if self.frame_setting:
                 self.save_frame_folder_dir = os.path.join(self.gantt_plot_dir, self.video_name)
                 if not os.path.exists(self.save_frame_folder_dir): os.makedirs(self.save_frame_folder_dir)
             if self.video_setting:
                 self.save_video_path = os.path.join(self.gantt_plot_dir, self.video_name + '.mp4')
                 self.writer = cv2.VideoWriter(self.save_video_path, self.fourcc, self.fps, (self.style_attr['width'], self.style_attr['height']))
 
             if self.last_frm_setting:
-                _ = make_gantt_plot(data_df=self.data_df,
-                                    bouts_df=self.bouts_df,
-                                    clf_names=self.clf_names,
-                                    fps=self.fps,
-                                    style_attr=self.style_attr,
-                                    video_name=self.video_name,
-                                    save_path=os.path.join(self.gantt_plot_dir, self.video_name + '_final_image.png'))
+                _ = self.make_gantt_plot(data_df=self.data_df,
+                                         bouts_df=self.bouts_df,
+                                         clf_names=self.clf_names,
+                                         fps=self.fps,
+                                         style_attr=self.style_attr,
+                                         video_name=self.video_name,
+                                         save_path=os.path.join(self.gantt_plot_dir, self.video_name + '_final_image.png'))
 
             if self.frame_setting or self.video_setting:
                 for image_cnt, k in enumerate(range(len(self.data_df))):
                     fig, ax = plt.subplots()
                     relevant_rows = self.bouts_df.loc[self.bouts_df['End_frame'] <= k]
                     for i, event in enumerate(relevant_rows.groupby("Event")):
                         for x in self.clf_names:
@@ -138,17 +133,24 @@
                 if self.video_setting:
                     self.writer.release()
                 print('Gantt for video {} saved...'.format(self.video_name))
         self.timer.stop_timer()
         stdout_success(msg='All gantt visualizations created in project_folder/frames/output/gantt_plots directory', elapsed_time=self.timer.elapsed_time_str)
 
 # style_attr = {'width': 640, 'height': 480, 'font size': 12, 'font rotation': 45}
-# test = GanttCreatorSingleProcess(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals/project_folder/project_config.ini',
+# test = GanttCreatorSingleProcess(config_path='/Users/simon/Desktop/envs/troubleshooting/sleap_5_animals/project_folder/project_config.ini',
 #                                  frame_setting=False,
 #                                  video_setting=True,
 #                                  last_frm_setting=True,
 #                                  style_attr=style_attr,
-#                                  files_found=['/Users/simon/Desktop/envs/troubleshooting/two_black_animals/project_folder/csv/machine_results/Together_1.csv'])
+#                                  files_found=['/Users/simon/Desktop/envs/troubleshooting/sleap_5_animals/project_folder/csv/outlier_corrected_movement_location/Testing_Video_3.csv'])
 # test.create_gannt()
 
 
-
+# style_attr = {'width': 640, 'height': 480, 'font size': 12, 'font rotation': 45}
+# test = GanttCreatorSingleProcess(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini',
+#                                  frame_setting=False,
+#                                  video_setting=True,
+#                                  last_frm_setting=True,
+#                                  style_attr=style_attr,
+#                                  files_found=['/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/csv/targets_inserted/Together_1.csv'])
+# test.run()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/tools/tkinter_tools.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/tools/tkinter_tools.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,14 @@
 from tkinter import *
 import cv2
 import numpy as np
-
 from PIL import Image as Img
 from PIL import ImageTk
-from simba.misc_tools import get_video_meta_data
 from simba.utils.errors import FrameRangeError
+from simba.utils.read_write import get_video_meta_data
 
 PADDING = 5
 MAX_SIZE = (1080, 650)
 
 class InteractiveVideoPlotterWindow(object):
     def __init__(self,
                  video_path: str,
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/ROI_plotter_mp.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/ROI_plotter_mp.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,115 +1,31 @@
 __author__ = "Simon Nilsson", "JJ Choong"
 
-from simba.roi_tools.ROI_analyzer import ROIAnalyzer
-from simba.drop_bp_cords import get_fn_ext, createColorListofList
-from simba.feature_extractors.unit_tests import read_video_info
+
 import pandas as pd
 import os
 import itertools
 import cv2
 import platform
 import multiprocessing
 import functools
+import numpy as np
 from simba.enums import Formats, Paths
-from simba.misc_tools import (get_video_meta_data,
-                              add_missing_ROI_cols,
-                              SimbaTimer,
-                              detect_bouts,
-                              concatenate_videos_in_folder,
-                              )
-from simba.utils.printing import stdout_success
-from simba.utils.errors import DuplicationError
+from simba.utils.data import detect_bouts
+from simba.utils.printing import stdout_success, SimbaTimer
 from simba.utils.warnings import DuplicateNamesWarning
-import numpy as np
+from simba.utils.data import create_color_palettes
+from simba.roi_tools.ROI_analyzer import ROIAnalyzer
 from simba.mixins.config_reader import ConfigReader
-from simba.utils.errors import NoFilesFoundError
-
+from simba.mixins.plotting_mixin import PlottingMixin
+from simba.utils.errors import NoFilesFoundError, DuplicationError
+from simba.utils.read_write import get_video_meta_data, concatenate_videos_in_folder, get_fn_ext
 pd.options.mode.chained_assignment = None
-def _img_creator(data: pd.DataFrame,
-                 loc_dict: dict,
-                 scalers: dict,
-                 video_meta_data: dict,
-                 save_temp_directory: str,
-                 shape_meta_data: dict,
-                 video_shape_names: list,
-                 input_video_path: str,
-                 body_part_dict: dict,
-                 roi_analyzer_data: object,
-                 colors: list,
-                 style_attr: dict):
-
-    def __insert_texts(shape_df):
-        for animal_name in roi_analyzer_data.multi_animal_id_list:
-            for _, shape in shape_df.iterrows():
-                shape_name, shape_color = shape['Name'], shape['Color BGR']
-                cv2.putText(border_img, loc_dict[animal_name][shape_name]['timer_text'], loc_dict[animal_name][shape_name]['timer_text_loc'], font, scalers['font_size'], shape_color, 1)
-                cv2.putText(border_img, loc_dict[animal_name][shape_name]['entries_text'], loc_dict[animal_name][shape_name]['entries_text_loc'], font, scalers['font_size'], shape_color, 1)
-
-        return border_img
-
-    font = cv2.FONT_HERSHEY_TRIPLEX
-    fourcc = cv2.VideoWriter_fourcc(*Formats.MP4_CODEC.value)
-    group_cnt = int(data['group'].values[0])
-    start_frm, current_frm, end_frm = data.index[0], data.index[0], data.index[-1]
-    save_path = os.path.join(save_temp_directory, '{}.mp4'.format(str(group_cnt)))
-    writer = cv2.VideoWriter(save_path, fourcc, video_meta_data['fps'], (video_meta_data['width'] * 2, video_meta_data['height']))
-    cap = cv2.VideoCapture(input_video_path)
-    cap.set(1, start_frm)
-
-    while current_frm < end_frm:
-        ret, img = cap.read()
-        border_img = cv2.copyMakeBorder(img, 0, 0, 0, int(video_meta_data['width']), borderType=cv2.BORDER_CONSTANT, value=[0, 0, 0])
-        border_img = __insert_texts(roi_analyzer_data.video_recs)
-        border_img = __insert_texts(roi_analyzer_data.video_circs)
-        border_img = __insert_texts(roi_analyzer_data.video_polys)
-
-        for _, row in roi_analyzer_data.video_recs.iterrows():
-            top_left_x, top_left_y, shape_name = row['topLeftX'], row['topLeftY'], row['Name']
-            bottom_right_x, bottom_right_y = row['Bottom_right_X'], row['Bottom_right_Y']
-            thickness, color = row['Thickness'], row['Color BGR']
-            cv2.rectangle(border_img, (top_left_x, top_left_y), (bottom_right_x, bottom_right_y), color, thickness)
-
-        for _, row in roi_analyzer_data.video_circs.iterrows():
-            center_x, center_y, radius, shape_name = row['centerX'], row['centerY'], row['radius'], row['Name']
-            thickness, color = row['Thickness'], row['Color BGR']
-            cv2.circle(border_img, (center_x, center_y), radius, color, thickness)
-
-        for _, row in roi_analyzer_data.video_polys.iterrows():
-            vertices, shape_name = row['vertices'], row['Name']
-            thickness, color = row['Thickness'], row['Color BGR']
-            cv2.polylines(border_img, [vertices], True, color, thickness=thickness)
-
-        for animal_cnt, animal_name in enumerate(roi_analyzer_data.multi_animal_id_list):
-            if style_attr['Show_body_part'] or style_attr['Show_animal_name']:
-                bp_data = data.loc[current_frm, body_part_dict[animal_name]].values
-                if roi_analyzer_data.settings['threshold'] < bp_data[2]:
-                    if style_attr['Show_body_part']:
-                        cv2.circle(border_img, (int(bp_data[0]), int(bp_data[1])), scalers['circle_size'], colors[animal_cnt], -1)
-                    if style_attr['Show_animal_name']:
-                        cv2.putText(border_img, animal_name, (int(bp_data[0]), int(bp_data[1])), font, scalers['font_size'], colors[animal_cnt], 1)
-
-            for shape_name in video_shape_names:
-                timer = round(data.loc[current_frm, '{}_{}_cum_sum_time'.format(animal_name, shape_name)], 2)
-                entries = data.loc[current_frm, '{}_{}_cum_sum_entries'.format(animal_name, shape_name)]
-                cv2.putText(border_img, str(timer), loc_dict[animal_name][shape_name]['timer_data_loc'], font, scalers['font_size'], shape_meta_data[shape_name]['Color BGR'], 1)
-                cv2.putText(border_img, str(entries), loc_dict[animal_name][shape_name]['entries_data_loc'], font, scalers['font_size'], shape_meta_data[shape_name]['Color BGR'], 1)
-
-        writer.write(border_img)
-        current_frm += 1
-        print('Multi-processing video frame {} on core {}...'.format(str(current_frm), str(group_cnt)))
-
-    cap.release()
-    writer.release()
-
-    return group_cnt
-
-
 
-class ROIPlotMultiprocess(ConfigReader):
+class ROIPlotMultiprocess(ConfigReader, PlottingMixin):
     """
     Class for visualizing the ROI data (number of entries/exits, time-spent-in etc)
 
     Parameters
     ----------
     config_path: str
         Path to SimBA project config file in Configparser format
@@ -130,38 +46,37 @@
     def __init__(
             self,
             ini_path: str,
             video_path: str,
             core_cnt: int,
             style_attr: dict):
 
-        super().__init__(config_path=ini_path)
+        ConfigReader.__init__(self, config_path=ini_path)
+        PlottingMixin.__init__(self)
         if platform.system() == "Darwin":
             multiprocessing.set_start_method('spawn', force=True)
         self.roi_analyzer = ROIAnalyzer(ini_path=ini_path, data_path='outlier_corrected_movement_location')
-        self.video_dir_path = os.path.join(self.roi_analyzer.project_path, 'videos')
-        self.roi_analyzer.read_roi_dfs()
-        self.video_path = os.path.join(self.video_dir_path, video_path)
+        self.video_path = os.path.join(self.video_dir, video_path)
         _, self.video_name, _ = get_fn_ext(video_path)
         self.core_cnt = core_cnt
         self.roi_analyzer.files_found = [os.path.join(self.roi_analyzer.input_folder, self.video_name + '.' + self.roi_analyzer.file_type)]
         if not os.path.isfile(self.roi_analyzer.files_found[0]):
             raise NoFilesFoundError(msg=f'SIMBA ERROR: Could not find the file at path {self.roi_analyzer.files_found[0]}. Please make sure you have corrected body-part outliers or indicated that you want to skip outlier correction')
-        self.roi_analyzer.analyze_ROIs()
+        self.roi_analyzer.run()
         self.roi_entries_df = self.roi_analyzer.detailed_df
         self.data_df, self.style_attr = self.roi_analyzer.data_df, style_attr
         self.out_parent_dir = os.path.join(self.roi_analyzer.project_path, Paths.ROI_ANALYSIS.value)
         if not os.path.exists(self.out_parent_dir): os.makedirs(self.out_parent_dir)
         self.video_save_path = os.path.join(self.out_parent_dir, self.video_name + '.mp4')
         self.video_shapes = list(itertools.chain(self.roi_analyzer.video_recs['Name'].unique(), self.roi_analyzer.video_circs['Name'].unique(),self.roi_analyzer.video_polys['Name'].unique()))
         if len(list(set(self.video_shapes))) != len(self.video_shapes):
             raise DuplicationError(msg='Some SIMBA ROI shapes have identical names. Please use unique names to visualize ROI data.')
-        self.roi_analyzer.video_recs = add_missing_ROI_cols(self.roi_analyzer.video_recs)
-        self.roi_analyzer.video_circs = add_missing_ROI_cols(self.roi_analyzer.video_circs)
-        self.roi_analyzer.video_polys = add_missing_ROI_cols(self.roi_analyzer.video_polys)
+        self.roi_analyzer.video_recs = self.add_missing_ROI_cols(self.roi_analyzer.video_recs)
+        self.roi_analyzer.video_circs = self.add_missing_ROI_cols(self.roi_analyzer.video_circs)
+        self.roi_analyzer.video_polys = self.add_missing_ROI_cols(self.roi_analyzer.video_polys)
 
         self.shape_dicts = {}
         for df in [self.roi_analyzer.video_recs, self.roi_analyzer.video_circs, self.roi_analyzer.video_polys]:
             if not df['Name'].is_unique:
                 df = df.drop_duplicates(subset=['Name'], keep='first')
                 DuplicateNamesWarning('Some of your ROIs with the same shape has the same names. E.g., you have two rectangles named "My rectangle". SimBA prefers ROI shapes with unique names. SimBA will keep one of the unique shape names and drop the rest.')
             d = df.set_index('Name').to_dict(orient='index')
@@ -252,36 +167,36 @@
         None
         """
 
         video_timer = SimbaTimer()
         video_timer.start_timer()
         self.cap = cv2.VideoCapture(self.video_path)
         self.video_meta_data = get_video_meta_data(self.video_path)
-        video_settings, pix_per_mm, self.fps = read_video_info(self.roi_analyzer.video_info_df, self.video_name)
+        video_settings, pix_per_mm, self.fps = self.read_video_info(video_name=self.video_name)
         self.space_scale, radius_scale, res_scale, font_scale = 25, 10, 1500, 0.8
         max_dim = max(self.video_meta_data['width'], self.video_meta_data['height'])
         self.scalers = {}
         self.scalers['circle_size'], self.scalers['font_size'] = int(radius_scale / (res_scale / max_dim)), float(font_scale / (res_scale / max_dim))
         self.scalers['space_size'] = int(self.space_scale / (res_scale / max_dim))
-        color_lst = createColorListofList(self.roi_analyzer.animal_cnt, int((len(self.roi_analyzer.bp_names) / 3)))[0]
+        color_lst = create_color_palettes(self.roi_analyzer.animal_cnt, int((len(self.roi_analyzer.bp_names) / 3)))[0]
         self.temp_folder = os.path.join(self.out_parent_dir, self.video_name, 'temp')
         if not os.path.exists(self.temp_folder): os.makedirs(self.temp_folder)
         self.__update_video_meta_data()
         self.__calc_text_locs()
         self.__create_counters()
         self.__calculate_cumulative()
 
         data_arr = np.array_split(self.data_df, self.core_cnt)
         for df_cnt in range(len(data_arr)):
             data_arr[df_cnt]['group'] = df_cnt
         frm_per_core = len(data_arr[0])
 
         print('Creating ROI images, multiprocessing (determined chunksize: {}, cores: {})...'.format(str(self.multiprocess_chunksize), str(self.core_cnt)))
         with multiprocessing.Pool(self.core_cnt, maxtasksperchild=self.maxtasksperchild) as pool:
-            constants = functools.partial(_img_creator,
+            constants = functools.partial(self.roi_plotter_mp,
                                           loc_dict=self.loc_dict,
                                           scalers=self.scalers,
                                           video_meta_data=self.video_meta_data,
                                           save_temp_directory= self.temp_folder,
                                           body_part_dict=self.bp_dict,
                                           input_video_path=self.video_path,
                                           roi_analyzer_data=self.roi_analyzer,
@@ -311,13 +226,13 @@
 # test.insert_data()
 # test.visualize_ROI_data()
 
 # test = ROIPlot(ini_path=r"Z:\DeepLabCut\DLC_extract\Troubleshooting\ROI_2_animals\project_folder\project_config.ini", video_path=r"Z:\DeepLabCut\DLC_extract\Troubleshooting\ROI_2_animals\project_folder\videos\Video7.mp4")
 # test.insert_data()
 # test.visualize_ROI_data()
 
-# test = ROIPlotMultiprocess(ini_path=r'/Users/simon/Desktop/envs/troubleshooting/two_animals_16bp_032023/project_folder/project_config.ini',
-#                video_path="Together_1.avi",
+# test = ROIPlotMultiprocess(ini_path=r'/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini',
+#                video_path="Together_2.avi",
 #                style_attr={'Show_body_part': True, 'Show_animal_name': False},
 #                            core_cnt=5)
 # test.insert_data()
 # test.visualize_ROI_data()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/shap_agg_stats_visualizer.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/shap_agg_stats_visualizer.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,24 +1,20 @@
 import pandas as pd
-from datetime import datetime
 import numpy as np
 import itertools
 import os
 import cv2
 import simba
-from simba.read_config_unit_tests import (read_config_entry,
-                                          read_config_file,
-                                          check_file_exist_and_readable,
-                                          read_project_path_and_file_type)
-from simba.enums import ReadConfig, Dtypes, Paths
-from simba.misc_tools import SimbaTimer
-from simba.utils.printing import stdout_success
+from simba.enums import Paths
+from simba.utils.printing import stdout_success, SimbaTimer
 from simba.utils.warnings import ShapWarning
+from simba.mixins.config_reader import ConfigReader
+from simba.utils.checks import check_file_exist_and_readable
 
-class ShapAggregateStatisticsVisualizer(object):
+class ShapAggregateStatisticsVisualizer(ConfigReader):
 
     """
     Class for calculating aggregate, binned, SHAP value statistics where individual bins represent reaulated features.
     Also creates line chart visualizations reprsenting aggregations of behavior-present SHAP values.
 
     Parameters
     ----------
@@ -46,26 +42,22 @@
     def __init__(self,
                 config_path: str,
                 classifier_name: str,
                 shap_df: pd.DataFrame,
                 shap_baseline_value: int,
                 save_path: str):
 
-        self.agg_stats_timer = SimbaTimer(start=True)
-        self.config = read_config_file(ini_path=config_path)
-        bp_setting = read_config_entry(config=self.config, section=ReadConfig.CREATE_ENSEMBLE_SETTINGS.value, option=ReadConfig.POSE_SETTING.value, data_type=Dtypes.STR.value)
-        if (bp_setting != '14') and (bp_setting != '16'):
+        ConfigReader.__init__(self, config_path=config_path)
+        if (self.pose_setting != '14') and (self.pose_setting != '16'):
             ShapWarning('SHAP visualizations/aggregate stats skipped (only viable for projects with two animals and default 7 or 8 body-parts per animal) ...')
         else:
-            self.date_time, self.save_path = datetime.now().strftime('%Y%m%d%H%M%S'), save_path
+            self.save_path = save_path
             self.classifier_name, self.shap_df, self.shap_baseline_value = classifier_name, shap_df, shap_baseline_value
-            self.project_path, _ = read_project_path_and_file_type(config=self.config)
-            self.shap_logs_path = os.path.join(self.project_path, Paths.SHAP_LOGS.value)
             if not os.path.exists(self.shap_logs_path): os.makedirs(self.shap_logs_path)
-            self.img_save_path = os.path.join(self.shap_logs_path, 'SHAP_summary_line_graph_{}_{}.png'.format(self.classifier_name, self.date_time))
+            self.img_save_path = os.path.join(self.shap_logs_path, 'SHAP_summary_line_graph_{}_{}.png'.format(self.classifier_name, self.datetime))
             simba_dir = os.path.dirname(simba.__file__)
             feature_categories_csv_path = os.path.join(simba_dir, Paths.SIMBA_SHAP_CATEGORIES_PATH.value)
             shap_img_path = os.path.join(simba_dir, Paths.SIMBA_SHAP_IMG_PATH.value)
             check_file_exist_and_readable(file_path=feature_categories_csv_path)
             self.scale_img_dict = {'baseline_scale': os.path.join(shap_img_path, 'baseline_scale.jpg'),
                                    'small_arrow': os.path.join(shap_img_path, 'down_arrow.jpg'),
                                    'side_scale': os.path.join(shap_img_path, 'side_scale.jpg'),
@@ -98,28 +90,29 @@
                 results.loc[row_name, column_name] = value
         results.reindex(sorted(results.columns, reverse=True), axis=1).to_csv(self.df_save_path)
 
     def __calculate_agg_shap_scores(self):
         """
         Private helper to aggregate SHAP values into bins of related features.
         """
+        self.agg_stats_timer = SimbaTimer(start=True)
         for clf_state, clf_state_name in zip(range(2), ['ABSENT', 'PRESENT']):
             self.results = {}
-            self.df_save_path = os.path.join(self.shap_logs_path, 'SHAP_summary_{}_{}_{}.csv'.format(self.classifier_name, clf_state_name, self.date_time))
+            self.df_save_path = os.path.join(self.shap_logs_path, 'SHAP_summary_{}_{}_{}.csv'.format(self.classifier_name, clf_state_name, self.datetime))
             shap_clf_sliced = self.shap_df[self.shap_df[self.classifier_name] == clf_state]
             for feature_category, feature_time_bin in itertools.product(self.unique_feature_category_names, self.unique_time_bin_names):
                 if feature_category not in self.results.keys():
                     self.results[feature_category] = {}
                 feature_names_sliced = list(self.feature_categories_df.loc[:, (feature_category, feature_time_bin)])
                 feature_names_sliced = [x for x in feature_names_sliced if str(x) != 'nan' and x in shap_clf_sliced]
                 self.results[feature_category][feature_time_bin] = round(shap_clf_sliced[feature_names_sliced].sum(axis=1).mean() * 100, 6)
             self.__save_aggregate_scores()
         self.agg_stats_timer.stop_timer()
-        self.visualization_timer = SimbaTimer()
-        self.visualization_timer.start_timer()
+        self.visualization_timer = SimbaTimer(start=True)
+
         stdout_success(msg=f'Aggregate SHAP statistics saved in {self.shap_logs_path} directory', elapsed_time=self.agg_stats_timer.elapsed_time_str)
 
     def __create_base_shap_img(self):
         """
         Private helper to create the base (axes, icons ticks etc) of the aggregate shap value visualization.
         """
 
@@ -156,15 +149,15 @@
             self.img[icon_top_left[0]:icon_bottom_right[0], icon_top_left[1]:icon_bottom_right[1]] = icon_img
 
     def __insert_data_in_img(self):
         """
         Private helper to insert the data (i.e., colored arrows, text etc.) into the aggregate shap value visualization
         and save the results.
         """
-        data_df = pd.read_csv(os.path.join(self.shap_logs_path, 'SHAP_summary_{}_{}_{}.csv'.format(self.classifier_name, 'PRESENT', self.date_time)), index_col=0)
+        data_df = pd.read_csv(os.path.join(self.shap_logs_path, 'SHAP_summary_{}_{}_{}.csv'.format(self.classifier_name, 'PRESENT', self.datetime)), index_col=0)
         for feature_category in self.unique_feature_category_names:
             self.category_img_dict[feature_category]['value'] = int(data_df.loc[feature_category, :].sum())
 
         for row_cnt, (feature_category_name, feature_data) in enumerate(self.category_img_dict.items()):
             arrow_width = int((self.baseline_scale_img.shape[1] / 100) * abs(feature_data['value']))
             if feature_data['value'] > 0:
                 arrow_end = (self.arrow_start[0] + arrow_width, self.arrow_start[1])
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/gantt_creator_mp.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/probability_plot_creator_mp.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,250 +1,235 @@
 __author__ = "Simon Nilsson"
 
-import warnings
-warnings.simplefilter(action='ignore', category=FutureWarning)
+import functools
 import pandas as pd
-from simba.misc_tools import (detect_bouts,
-                              concatenate_videos_in_folder,
-                              SimbaTimer,
-                              get_named_colors,
-                              )
-from simba.utils.printing import stdout_success
-from simba.read_config_unit_tests import (check_if_filepath_list_is_empty)
-from simba.feature_extractors.unit_tests import (read_video_info)
-from simba.enums import Formats
-from simba.plotting.misc_visualizations import make_gantt_plot
-from simba.drop_bp_cords import get_fn_ext
-from simba.rw_dfs import read_df
-from simba.mixins.config_reader import ConfigReader
 import os
-import numpy as np
 import matplotlib.pyplot as plt
 import cv2
-import multiprocessing
-from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas
-import functools
+import numpy as np
 import shutil
+import multiprocessing
 import platform
+from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas
+
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.utils.read_write import concatenate_videos_in_folder, read_df, get_fn_ext
 from simba.utils.errors import NoSpecifiedOutputError
+from simba.utils.checks import check_that_column_exist
+from simba.enums import Formats
+from simba.mixins.config_reader import ConfigReader
+from simba.mixins.plotting_mixin import PlottingMixin
+
 
-def _image_creator(data: np.array,
-                   frame_setting: bool,
-                   video_setting: bool,
-                   video_save_dir: str,
-                   frame_folder_dir: str,
-                   bouts_df: pd.DataFrame,
-                   clf_names: list,
-                   colors: list,
-                   color_tuple: tuple,
-                   fps: int,
-                   rotation: int,
-                   font_size: int,
-                   width: int,
-                   height: int,
-                   video_name: str):
+def _create_probability_plots(data: list,
+                              probability_lst: list,
+                              clf_name: str,
+                              video_setting: bool,
+                              frame_setting: bool,
+                              video_dir: str,
+                              frame_dir: str,
+                              highest_p: float,
+                              fps: int,
+                              style_attr: dict,
+                              video_name: str):
 
-    group, frame_rng = data[0], data[1:]
-    start_frm, end_frm, current_frm = frame_rng[0], frame_rng[-1], frame_rng[0]
+    group, data = data[0], data[1:]
+    start_frm, end_frm, current_frm = data[0], data[-1], data[0]
 
     if video_setting:
         fourcc = cv2.VideoWriter_fourcc(*Formats.MP4_CODEC.value)
-        video_save_path = os.path.join(video_save_dir, '{}.mp4'.format(str(group)))
-        video_writer = cv2.VideoWriter(video_save_path, fourcc, fps, (width, height))
+        video_save_path = os.path.join(video_dir, '{}.mp4'.format(str(group)))
+        video_writer = cv2.VideoWriter(video_save_path, fourcc, fps, (style_attr['width'], style_attr['height']))
 
     while current_frm < end_frm:
         fig, ax = plt.subplots()
-        bout_rows = bouts_df.loc[bouts_df['End_frame'] <= current_frm]
-        for i, event in enumerate(bout_rows.groupby("Event")):
-            for x in clf_names:
-                if event[0] == x:
-                    ix = clf_names.index(x)
-                    data_event = event[1][["Start_time", "Bout_time"]]
-                    ax.broken_barh(data_event.values, (color_tuple[ix], 3), facecolors=colors[ix])
-
-
-        x_ticks_locs = x_lbls = np.round(np.linspace(0, round((current_frm / fps), 3), 6))
-        ax.set_xticks(x_ticks_locs)
-        ax.set_xticklabels(x_lbls)
-        ax.set_ylim(0, color_tuple[len(clf_names)])
-        ax.set_yticks(np.arange(5, 5 * len(clf_names) + 1, 5))
-        ax.tick_params(axis='both', labelsize=font_size)
-        ax.set_yticklabels(clf_names, rotation=rotation)
-        ax.set_xlabel('Session (s)', fontsize=font_size)
-        ax.yaxis.grid(True)
+        current_lst = probability_lst[0:current_frm+1]
+        ax.plot(current_lst, color=style_attr['color'], linewidth=style_attr['line width'])
+        ax.plot(current_frm, current_lst[-1], "o", markersize=style_attr['circle size'], color=style_attr['color'])
+        ax.set_ylim([0, highest_p])
+        x_ticks_locs = x_lbls = np.linspace(0, current_frm, 5)
+        x_lbls = np.round((x_lbls / fps), 1)
+        ax.xaxis.set_ticks(x_ticks_locs)
+        ax.set_xticklabels(x_lbls, fontsize=style_attr['font size'])
+        ax.set_xlabel('Time (s)', fontsize=style_attr['font size'])
+        ax.set_ylabel('{} {}'.format(clf_name, 'probability'), fontsize=style_attr['font size'])
+        plt.suptitle(clf_name, x=0.5, y=0.92, fontsize=style_attr['font size'] + 4)
         canvas = FigureCanvas(fig)
         canvas.draw()
         mat = np.array(canvas.renderer._renderer)
-        img = cv2.cvtColor(mat, cv2.COLOR_RGB2BGR)
-        img = np.uint8(cv2.resize(img, (width, height)))
+        image = cv2.cvtColor(mat, cv2.COLOR_RGB2BGR)
+        image = np.uint8(cv2.resize(image, (style_attr['width'], style_attr['height'])))
         if video_setting:
-            video_writer.write(img)
+            video_writer.write(image)
         if frame_setting:
-            frame_save_name = os.path.join(frame_folder_dir, '{}.png'.format(str(current_frm)))
-            cv2.imwrite(frame_save_name, img)
-        plt.close(fig)
+            frame_save_name = os.path.join(frame_dir, '{}.png'.format(str(current_frm)))
+            cv2.imwrite(frame_save_name, image)
+        plt.close()
         current_frm += 1
 
-        print('Gantt frame created: {}, Video: {}, Processing core: {}'.format(str(current_frm+1), video_name, str(group+1)))
+        print('Probability frame created: {}, Video: {}, Processing core: {}'.format(str(current_frm+1), video_name, str(group+1)))
 
-    if video_setting:
-        video_writer.release()
 
     return group
 
-class GanttCreatorMultiprocess(ConfigReader):
-
+class TresholdPlotCreatorMultiprocess(ConfigReader, PlottingMixin):
     """
-    Class for multiprocess creation of classifier gantt charts in video and/or image format.
+    Class for line chart visualizations displaying the classification probabilities of a single classifier.
+    Uses multiprocessing.
 
     Parameters
     ----------
     config_path: str
         path to SimBA project config file in Configparser format
+    clf_name: str
+        Name of the classifier to create visualizations for
     frame_setting: bool
-        If True, creates individual frames
+       When True, SimBA creates individual frames in png format
     video_setting: bool
-        If True, creates videos
+       When True, SimBA creates compressed video in mp4 format
     files_found: list
-        File paths representing files with machine predictions e.g., ['project_folder/csv/machine_results/My_results.csv']
+        File paths to create probability plots for, e.g., ['project_folder/csv/machine_results/MyVideo.csv]
+    style_attr: dict
+        Output image style attributes, e.g., {'width': 640, 'height': 480, 'font size': 10, 'line width': 6, 'color': 'magneta', 'circle size': 20}
     cores: int
         Number of cores to use
-    style_attr: dict
-        Output image style attributes, e.g., {'width': 640, 'height': 480, 'font size': 8, 'font rotation': 45}
-
 
     Notes
     ----------
-    `GitHub gantt tutorial <https://github.com/sgoldenlab/simba/blob/master/docs/tutorial.md#gantt-plot>`__.
-    See ``simba.gantt_creator.GanttCreatorSingleProcess`` for single-process class.
+    `Visualization tutorials <https://github.com/sgoldenlab/simba/blob/master/docs/tutorial.md#step-11-visualizations>`__.
+
 
     Examples
     ----------
-    >>> gantt_creator = GanttCreatorMultiprocess(config_path='tests/test_data/multi_animal_dlc_two_c57/project_folder/project_config.ini', frame_setting=False, video_setting=True, files_found=['tests/test_data/multi_animal_dlc_two_c57/project_folder/csv/machine_results/Together_1.csv'], cores=5, style_attr={'width': 640, 'height': 480, 'font size': 8, 'font rotation': 45})
-    >>> gantt_creator.create_gannt()
-
+    >>> plot_creator = TresholdPlotCreatorMultiprocess(config_path='/Users/simon/Desktop/troubleshooting/train_model_project/project_folder/project_config.ini', frame_setting=True, video_setting=True, clf_name='Attack', style_attr={'width': 640, 'height': 480, 'font size': 10, 'line width': 6, 'color': 'magneta', 'circle size': 20}, cores=5)
+    >>> plot_creator.create_plot()
     """
 
+
     def __init__(self,
                  config_path: str,
+                 clf_name: str,
                  frame_setting: bool,
                  video_setting: bool,
-                 files_found: list,
+                 last_frame: bool,
                  cores: int,
                  style_attr: dict,
-                 last_frm_setting: bool):
-
-        super().__init__(config_path=config_path)
-
-        if platform.system() == "Darwin":
-            multiprocessing.set_start_method('spawn', force=True)
+                 files_found: list):
 
-        self.frame_setting, self.video_setting, self.files_found, self.style_attr, self.cores, self.last_frm_setting = frame_setting, video_setting, files_found, style_attr, cores, last_frm_setting
-        if (not self.frame_setting) and (not self.video_setting) and (not self.last_frm_setting):
-            raise NoSpecifiedOutputError(msg='SIMBA ERROR: Please select gantt videos, frames, and/or last frame.')
-        check_if_filepath_list_is_empty(filepaths=self.files_found,
-                                        error_msg='SIMBA ERROR: Zero files found in the project_folder/csv/machine_results directory. Create classification results before visualizing gantt charts')
-        self.colours = get_named_colors()[:-1]
-        self.colour_tuple_x = list(np.arange(3.5, 203.5, 5))
-        if not os.path.exists(self.gantt_plot_dir): os.makedirs(self.gantt_plot_dir)
-        self.y_rotation, self.y_fontsize = self.style_attr['font rotation'], self.style_attr['font size']
-        self.fourcc = cv2.VideoWriter_fourcc(*Formats.MP4_CODEC.value)
+        ConfigReader.__init__(self,config_path=config_path)
+        PlottingMixin.__init__(self)
+        # if platform.system() == "Darwin":
+        #     multiprocessing.set_start_method('spawn', force=True)
+        self.frame_setting, self.video_setting, self.cores, self.style_attr, self.last_frame = frame_setting, video_setting, cores, style_attr, last_frame
+        if (not self.frame_setting) and (not self.video_setting) and (not self.last_frame):
+            raise NoSpecifiedOutputError('SIMBA ERROR: Please choose to create either probability videos, frames, and/or last frame.', show_window=True)
+        self.clf_name, self.files_found = clf_name, files_found
+        self.probability_col = 'Probability_' + self.clf_name
+        self.fontsize = self.style_attr['font size']
         self.out_width, self.out_height = self.style_attr['width'], self.style_attr['height']
-        print('Processing {} video(s)...'.format(str(len(self.files_found))))
-
-    def create_gannt(self):
-        '''
-        Creates gantt charts. Results are stored in the `project_folder/frames/gantt_plots` directory of SimBA project.
-
-        Returns
-        ----------
-        None
-        '''
+        self.fourcc = cv2.VideoWriter_fourcc(*Formats.MP4_CODEC.value)
+        if not os.path.exists(self.probability_plot_dir): os.makedirs(self.probability_plot_dir)
+        print(f'Processing {str(len(self.files_found))} video(s)...')
 
+    def create_plots(self):
         for file_cnt, file_path in enumerate(self.files_found):
             video_timer = SimbaTimer()
             video_timer.start_timer()
             _, self.video_name, _ = get_fn_ext(file_path)
-            self.data_df = read_df(file_path, self.file_type).reset_index(drop=True)
-            print('Processing video {}, Frame count: {} (Video {}/{})...'.format(self.video_name, str(len(self.data_df)), str(file_cnt+1), str(len(self.files_found))))
-            self.video_info_settings, _, self.fps = read_video_info(self.video_info_df, self.video_name)
-            self.bouts_df = detect_bouts(data_df=self.data_df, target_lst=list(self.clf_names), fps=int(self.fps))
-            self.temp_folder = os.path.join(self.gantt_plot_dir, self.video_name, 'temp')
-            self.save_frame_folder_dir = os.path.join(self.gantt_plot_dir, self.video_name)
+            video_info, self.px_per_mm, self.fps = self.read_video_info(video_name=self.video_name)
+            data_df = read_df(file_path, self.file_type)
+            check_that_column_exist(df=data_df, column_name=self.clf_name, file_name=self.video_name)
+            self.save_frame_folder_dir = os.path.join(self.probability_plot_dir, self.video_name + '_' + self.clf_name)
+            self.video_folder = os.path.join(self.probability_plot_dir, self.video_name + '_' + self.clf_name)
+            self.temp_folder = os.path.join(self.probability_plot_dir, self.video_name + '_' + self.clf_name, 'temp')
             if self.frame_setting:
                 if os.path.exists(self.save_frame_folder_dir): shutil.rmtree(self.save_frame_folder_dir)
                 if not os.path.exists(self.save_frame_folder_dir): os.makedirs(self.save_frame_folder_dir)
             if self.video_setting:
-                self.video_folder = os.path.join(self.gantt_plot_dir, self.video_name)
                 if os.path.exists(self.temp_folder):
                     shutil.rmtree(self.temp_folder)
                     shutil.rmtree(self.video_folder)
                 os.makedirs(self.temp_folder)
-                self.save_video_path = os.path.join(self.gantt_plot_dir, self.video_name + '.mp4')
+                self.save_video_path = os.path.join(self.probability_plot_dir, '{}_{}.mp4'.format(self.video_name, self.clf_name))
+
+            probability_lst = list(data_df[self.probability_col])
+
+            if self.last_frame:
+                _ = self.make_probability_plot(data=pd.Series(probability_lst),
+                                               style_attr=self.style_attr,
+                                               clf_name=self.clf_name,
+                                               fps=self.fps,
+                                               save_path=os.path.join(self.probability_plot_dir, self.video_name + '_{}_{}.png'.format(self.clf_name, 'final_image')))
 
-            if self.last_frm_setting:
-                _ = make_gantt_plot(data_df=self.data_df,
-                                    bouts_df=self.bouts_df,
-                                    clf_names=self.clf_names,
-                                    fps=self.fps,
-                                    style_attr=self.style_attr,
-                                    video_name=self.video_name,
-                                    save_path=os.path.join(self.gantt_plot_dir, self.video_name + '_final_image.png'))
 
             if self.video_setting or self.frame_setting:
-                frame_array = np.array_split(list(range(0, len(self.data_df))), self.cores)
-                frm_per_core = len(frame_array[0])
-                for group_cnt, rng in enumerate(frame_array):
-                    frame_array[group_cnt] = np.insert(rng, 0, group_cnt)
-
-                print('Creating gantt, multiprocessing (chunksize: {}, cores: {})...'.format(str(self.multiprocess_chunksize), str(self.cores)))
-                with multiprocessing.pool.Pool(self.cores, maxtasksperchild=self.maxtasksperchild) as pool:
-                    constants = functools.partial(_image_creator,
+                if self.style_attr['y_max'] == 'auto':
+                    highest_p = data_df[self.probability_col].max()
+                else:
+                    highest_p = float(self.style_attr['y_max'])
+                data_split = np.array_split(list(data_df.index), self.cores)
+                frm_per_core = len(data_split[0])
+                for group_cnt, rng in enumerate(data_split):
+                    data_split[group_cnt] = np.insert(rng, 0, group_cnt)
+
+
+                print('Creating probability images, multiprocessing (determined chunksize: {}, cores: {})...'.format(str(self.multiprocess_chunksize), str(self.cores)))
+                with multiprocessing.Pool(self.cores, maxtasksperchild=self.maxtasksperchild) as pool:
+                    constants = functools.partial(_create_probability_plots,
+                                                  clf_name=self.clf_name,
+                                                  probability_lst=probability_lst,
+                                                  highest_p= highest_p,
                                                   video_setting=self.video_setting,
                                                   frame_setting=self.frame_setting,
-                                                  video_save_dir=self.temp_folder,
-                                                  frame_folder_dir=self.save_frame_folder_dir,
-                                                  bouts_df=self.bouts_df,
-                                                  rotation=self.y_rotation,
-                                                  clf_names=self.clf_names,
-                                                  colors=self.colours,
-                                                  color_tuple=self.colour_tuple_x,
                                                   fps=self.fps,
-                                                  font_size=self.y_fontsize,
-                                                  width=self.out_width,
-                                                  height=self.out_height,
+                                                  video_dir=self.temp_folder,
+                                                  frame_dir=self.save_frame_folder_dir,
+                                                  style_attr=self.style_attr,
                                                   video_name=self.video_name)
+                    for cnt, result in enumerate(pool.imap(constants, data_split, chunksize=self.multiprocess_chunksize)):
+                        print('Image {}/{}, Video {}/{}...'.format(str(int(frm_per_core*(result+1))), str(len(data_df)), str(file_cnt+1), str(len(self.files_found))))
 
-                    for cnt, result in enumerate(pool.imap(constants, frame_array, chunksize=self.multiprocess_chunksize)):
-                        print('Image {}/{}, Video {}/{}...'.format(str(int(frm_per_core * (result+1))), str(len(self.data_df)), str(file_cnt + 1), str(len(self.files_found))))
-                    pool.terminate()
-                    pool.join()
-
+                pool.join()
+                pool.terminate()
                 if self.video_setting:
                     print('Joining {} multiprocessed video...'.format(self.video_name))
                     concatenate_videos_in_folder(in_folder=self.temp_folder, save_path=self.save_video_path)
+
                 video_timer.stop_timer()
-                print('Gantt video {} complete (elapsed time: {}s) ...'.format(self.video_name, video_timer.elapsed_time_str))
+                print('Probability video {} complete (elapsed time: {}s) ...'.format(self.video_name, video_timer.elapsed_time_str))
 
         self.timer.stop_timer()
-        stdout_success(msg=f'Gantt visualizations for {len(self.files_found)} videos created in project_folder/frames/output/gantt_plots directory', elapsed_time=self.timer.elapsed_time_str)
+        stdout_success(msg=f'Probability visualizations for {str(len(self.files_found))} videos created in project_folder/frames/output/gantt_plots directory', elapsed_time=self.timer.elapsed_time_str)
+
+
+# test = TresholdPlotCreatorMultiprocess(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals/project_folder/project_config.ini',
+#                                         frame_setting=False,
+#                                         video_setting=True,
+#                                         last_frame=False,
+#                                         clf_name='Attack',
+#                                         cores=5,
+#                                         files_found=['/Users/simon/Desktop/envs/troubleshooting/two_black_animals/project_folder/csv/machine_results/Together_1.csv'],
+#                                         style_attr={'width': 640, 'height': 480, 'font size': 10, 'line width': 6, 'color': 'blue', 'circle size': 20, 'y_max': 'auto'})
+# #test = TresholdPlotCreatorSingleProcess(config_path='/Users/simon/Desktop/troubleshooting/train_model_project/project_folder/project_config.ini', frame_setting=False, video_setting=True, clf_name='Attack')
+# test.create_plots()
+
+
+# test = TresholdPlotCreatorMultiprocess(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini',
+#                                         frame_setting=False,
+#                                         video_setting=True,
+#                                         last_frame=True,
+#                                         clf_name='Attack',
+#                                         cores=5,
+#                                         files_found=['/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/csv/machine_results/Together_1.csv'],
+#                                         style_attr={'width': 640, 'height': 480, 'font size': 10, 'line width': 3, 'color': 'blue', 'circle size': 20, 'y_max': 'auto'})
+# test.create_plots()
+
+
+
+
+
+
+
+
+
 
-# test = GanttCreatorMultiprocess(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini',
-#                                 frame_setting=False,
-#                                 video_setting=True,
-#                                 files_found=['/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/csv/machine_results/Together_1.csv'],
-#                                 cores=5,
-#                                 last_frm_setting=False,
-#                                 style_attr={'width': 640, 'height': 480, 'font size': 12, 'font rotation': 45})
-# test.create_gannt()
-
-
-# style_attr = {'width': 640, 'height': 480, 'font size': 12, 'font rotation': 45}
-# test = GanttCreatorMultiprocess(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals/project_folder/project_config.ini',
-#                                  frame_setting=False,
-#                                  video_setting=True,
-#                                  last_frm_setting=False,
-#                                  style_attr=style_attr,
-# cores=5,
-#                                  files_found=['/Users/simon/Desktop/envs/troubleshooting/two_black_animals/project_folder/csv/machine_results/Together_1.csv'])
-# test.create_gannt()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/heat_mapper_clf_mp.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/heat_mapper_clf_mp.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,74 +1,71 @@
 __author__ = "Simon Nilsson"
 
 import pandas as pd
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.misc_tools import (get_fn_ext,
-                              SimbaTimer,
-                              remove_a_folder,
-                              concatenate_videos_in_folder,
-                              )
-from simba.utils.printing import stdout_success
-from simba.plotting.misc_visualizations import make_clf_heatmap_plot
-from simba.rw_dfs import read_df
 import numpy as np
 import os
 import cv2
 from numba import jit, prange
-from simba.enums import Formats
-from simba.mixins.config_reader import ConfigReader
 import multiprocessing
 import functools
 import platform
+
+import simba.mixins.plotting_mixin
+from simba.enums import Formats
+from simba.mixins.config_reader import ConfigReader
+from simba.mixins.plotting_mixin import PlottingMixin
 from simba.utils.errors import NoSpecifiedOutputError
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.utils.read_write import get_fn_ext, remove_a_folder, concatenate_videos_in_folder, read_df
 
 def _heatmap_multiprocessor(data: np.array,
                             video_setting: bool,
                             frame_setting: bool,
                             video_temp_dir: str,
                             video_name: str,
                             frame_dir: str,
                             fps: int,
                             style_attr: dict,
                             max_scale: float,
                             clf_name:str,
                             aspect_ratio: float,
-                            size: tuple):
+                            size: tuple,
+                            make_clf_heatmap_plot: simba.mixins.plotting_mixin.PlottingMixin.make_clf_heatmap_plot):
 
     group = int(data[0][0][1])
     if video_setting:
         fourcc = cv2.VideoWriter_fourcc(*Formats.MP4_CODEC.value)
         video_save_path = os.path.join(video_temp_dir, '{}.mp4'.format(str(group)))
         video_writer = cv2.VideoWriter(video_save_path, fourcc, fps, size)
 
     for i in range(data.shape[0]):
         frame_id = int(data[i, 0, 0])
         frm_data = data[i, :, 2:]
         img = make_clf_heatmap_plot(frm_data=frm_data,
-                              max_scale=max_scale,
-                              palette=style_attr['palette'],
-                              aspect_ratio=aspect_ratio,
-                              shading=style_attr['shading'],
-                              clf_name=clf_name,
-                              img_size=size,
-                              final_img=False)
+                                    max_scale=max_scale,
+                                    palette=style_attr['palette'],
+                                    aspect_ratio=aspect_ratio,
+                                    shading=style_attr['shading'],
+                                    clf_name=clf_name,
+                                    img_size=size,
+                                    final_img=False)
         print('Heatmap frame created: {}, Video: {}, Processing core: {}'.format(str(frame_id+1), video_name, str(group+1)))
         if video_setting:
             video_writer.write(img)
 
         if frame_setting:
             file_path = os.path.join(frame_dir, '{}.png'.format(frame_id))
             cv2.imwrite(file_path, img)
 
     if video_setting:
         video_writer.release()
 
     return group
 
-class HeatMapperClfMultiprocess(ConfigReader):
+class HeatMapperClfMultiprocess(ConfigReader, PlottingMixin):
 
     """
     Class for creating heatmaps representing the locations of the classified behavior
 
     Parameters
     ----------
     config_path: str
@@ -111,15 +108,16 @@
                  bodypart: str,
                  clf_name: str,
                  files_found: list,
                  style_attr: dict,
                  core_cnt: int
                  ):
 
-        super().__init__(config_path=config_path)
+        ConfigReader.__init__(self, config_path=config_path)
+        PlottingMixin.__init__(self)
 
         if platform.system() == "Darwin":
             multiprocessing.set_start_method('spawn', force=True)
         if (not frame_setting) and (not video_setting) and (not final_img_setting):
             raise NoSpecifiedOutputError(msg='Please choose to select either heatmap videos, frames, and/or final image.')
         self.frame_setting, self.video_setting = frame_setting, video_setting
         self.final_img_setting, self.bp = final_img_setting, bodypart
@@ -221,15 +219,15 @@
         None
         '''
 
         for file_cnt, file_path in enumerate(self.files_found):
             video_timer = SimbaTimer()
             video_timer.start_timer()
             _, self.video_name, _ = get_fn_ext(file_path)
-            self.video_info, self.px_per_mm, self.fps = read_video_info(vid_info_df=self.video_info_df, video_name=self.video_name)
+            self.video_info, self.px_per_mm, self.fps = self.read_video_info(video_name=self.video_name)
             self.width, self.height = int(self.video_info['Resolution_width'].values[0]), int(self.video_info['Resolution_height'].values[0])
             self.save_frame_folder_dir = os.path.join(self.heatmap_clf_location_dir, self.video_name + '_' + self.clf_name)
             self.video_folder = os.path.join(self.heatmap_clf_location_dir, self.video_name + '_' + self.clf_name)
             self.temp_folder = os.path.join(self.heatmap_clf_location_dir, self.video_name + '_' + self.clf_name, 'temp')
             if self.frame_setting:
                 if os.path.exists(self.save_frame_folder_dir):
                     remove_a_folder(folder_dir=self.save_frame_folder_dir)
@@ -251,23 +249,23 @@
                                                                 bin_size=self.bin_size,
                                                                 fps=self.fps)
 
             if self.max_scale == 'auto':
                 self.max_scale = self.__calculate_max_scale(clf_array=clf_array)
 
             if self.final_img_setting:
-                make_clf_heatmap_plot(frm_data=clf_array[-1, :, :],
-                                      max_scale=self.max_scale,
-                                      palette=self.palette,
-                                      aspect_ratio=aspect_ratio,
-                                      file_name=os.path.join(self.heatmap_clf_location_dir, self.video_name + '_final_frm.png'),
-                                      shading=self.shading,
-                                      clf_name=self.clf_name,
-                                      img_size=(self.height, self.width),
-                                      final_img=True)
+                self.make_clf_heatmap_plot(frm_data=clf_array[-1, :, :],
+                                           max_scale=self.max_scale,
+                                           palette=self.palette,
+                                           aspect_ratio=aspect_ratio,
+                                           file_name=os.path.join(self.heatmap_clf_location_dir, self.video_name + '_final_frm.png'),
+                                           shading=self.shading,
+                                           clf_name=self.clf_name,
+                                           img_size=(self.height, self.width),
+                                           final_img=True)
 
             if self.video_setting or self.frame_setting:
                 frame_arrays = np.array_split(clf_array, self.core_cnt)
                 last_frm_idx = 0
                 for frm_group in range(len(frame_arrays)):
                     split_arr = frame_arrays[frm_group]
                     frame_arrays[frm_group] = self.__insert_group_idx_column(data=split_arr, group=frm_group, last_frm_idx=last_frm_idx)
@@ -283,15 +281,16 @@
                                                   fps=self.fps,
                                                   video_temp_dir=self.temp_folder,
                                                   frame_dir=self.save_frame_folder_dir,
                                                   max_scale=self.max_scale,
                                                   aspect_ratio=aspect_ratio,
                                                   clf_name=self.clf_name,
                                                   size=(self.width, self.height),
-                                                  video_name=self.video_name)
+                                                  video_name=self.video_name,
+                                                  make_clf_heatmap_plot=self.make_clf_heatmap_plot)
 
                     for cnt, result in enumerate(pool.imap(constants, frame_arrays, chunksize=self.multiprocess_chunksize)):
                         print('Image {}/{}, Video {}/{}...'.format(str(int(frm_per_core * (result+1))), str(len(self.data_df)), str(file_cnt + 1), str(len(self.files_found))))
                     pool.terminate()
                     pool.join()
 
                 if self.video_setting:
@@ -301,18 +300,18 @@
                 video_timer.stop_timer()
                 print('Heatmap video {} complete (elapsed time: {}s) ...'.format(self.video_name, video_timer.elapsed_time_str))
 
         self.timer.stop_timer()
         stdout_success(msg='heatmap visualizations for {} videos created in project_folder/frames/output/heatmap_classifier locations directory', elapsed_time=self.timer.elapsed_time_str)
 
 
-# test = HeatMapperClfMultiprocess(config_path='/Users/simon/Desktop/envs/troubleshooting/Two_animals_16bps/project_folder/project_config.ini',
+# test = HeatMapperClfMultiprocess(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini',
 #                      style_attr = {'palette': 'jet', 'shading': 'gouraud', 'bin_size': 100, 'max_scale': 'auto'},
 #                      final_img_setting=False,
 #                      video_setting=True,
 #                      frame_setting=False,
 #                      bodypart='Nose_1',
 #                      clf_name='Attack',
 #                                core_cnt=5,
-#                      files_found=['/Users/simon/Desktop/envs/troubleshooting/Two_animals_16bps/project_folder/csv/machine_results/Together_3.csv'])
+#                      files_found=['/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/csv/machine_results/Together_1.csv'])
 # test.create_heatmaps()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/probability_plot_creator.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/probability_plot_creator.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,27 +1,25 @@
 __author__ = "Simon Nilsson"
 
-from simba.read_config_unit_tests import check_that_column_exist
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.misc_tools import SimbaTimer
-from simba.utils.printing import stdout_success
-from simba.plotting.misc_visualizations import make_probability_plot
-import os
-from simba.drop_bp_cords import get_fn_ext
-from simba.rw_dfs import read_df
-from simba.enums import Formats
-from simba.mixins.config_reader import ConfigReader
-from simba.utils.errors import NoSpecifiedOutputError
 import matplotlib.pyplot as plt
 import cv2
 import PIL
 import io
 import numpy as np
+import os
+
+from simba.enums import Formats
+from simba.mixins.config_reader import ConfigReader
+from simba.mixins.plotting_mixin import PlottingMixin
+from simba.utils.errors import NoSpecifiedOutputError
+from simba.utils.read_write import read_df, get_fn_ext
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.utils.checks import check_that_column_exist
 
-class TresholdPlotCreatorSingleProcess(ConfigReader):
+class TresholdPlotCreatorSingleProcess(ConfigReader, PlottingMixin):
     '''
     Class for creating line chart visualizations displaying the classification probabilities of a single classifier.
 
     Parameters
     ----------
     config_path: str
         path to SimBA project config file in Configparser format
@@ -52,15 +50,16 @@
                  clf_name: str,
                  frame_setting: bool,
                  video_setting: bool,
                  last_image: bool,
                  style_attr: dict,
                  files_found: list):
 
-        super().__init__(config_path=config_path)
+        ConfigReader.__init__(self, config_path=config_path)
+        PlottingMixin.__init__(self)
         self.frame_setting, self.video_setting, self.style_attr, self.last_image = frame_setting, video_setting, style_attr, last_image
         if (not self.frame_setting) and (not self.video_setting) and (not self.last_image):
             raise NoSpecifiedOutputError(msg='Please choose to either probability videos, probability frames, or both probability frames and videos.')
 
         self.files_found = files_found
         self.orginal_clf_name = clf_name
         self.clf_name = 'Probability_' + self.orginal_clf_name
@@ -74,33 +73,33 @@
 
 
     def create_plots(self):
         for file_cnt, file_path in enumerate(self.files_found):
             video_timer = SimbaTimer()
             video_timer.start_timer()
             _, self.video_name, _ = get_fn_ext(file_path)
-            video_info, self.px_per_mm, fps = read_video_info(vid_info_df=self.video_info_df, video_name=self.video_name)
+            video_info, self.px_per_mm, fps = self.read_video_info(video_name=self.video_name)
             data_df = read_df(file_path, self.file_type)
             check_that_column_exist(df=data_df, column_name=self.clf_name, file_name=self.video_name)
             if self.frame_setting:
                 self.save_frame_folder_dir = os.path.join(self.probability_plot_dir, self.video_name + '_' + self.orginal_clf_name)
                 if not os.path.exists(self.save_frame_folder_dir): os.makedirs(self.save_frame_folder_dir)
             if self.video_setting:
                 self.save_video_path = os.path.join(self.probability_plot_dir, '{}_{}.mp4'.format(self.video_name, self.orginal_clf_name))
                 self.writer = cv2.VideoWriter(self.save_video_path, self.fourcc, fps, (self.out_width, self.out_height))
 
             data_df = data_df[self.clf_name]
 
 
             if self.last_image:
-                make_probability_plot(data=data_df,
-                                      style_attr=self.style_attr,
-                                      clf_name=self.clf_name,
-                                      fps=fps,
-                                      save_path=os.path.join(self.probability_plot_dir, self.video_name + '_{}_{}.png'.format(self.orginal_clf_name, 'final_image')))
+                self.make_probability_plot(data=data_df,
+                                           style_attr=self.style_attr,
+                                           clf_name=self.clf_name,
+                                           fps=fps,
+                                           save_path=os.path.join(self.probability_plot_dir, self.video_name + '_{}_{}.png'.format(self.orginal_clf_name, 'final_image')))
 
             if self.video_setting or self.frame_setting:
                 if self.style_attr['y_max'] == 'auto':
                     max_y = np.amax(data_df)
                 else:
                     max_y = float(self.style_attr['y_max'])
 
@@ -138,26 +137,24 @@
                     self.writer.release()
                 video_timer.stop_timer()
                 print('Probability plot for video {} saved (elapsed time: {}s)...'.format(self.video_name, video_timer.elapsed_time_str))
         self.timer.stop_timer()
         stdout_success(msg=f'All probability visualizations created in project_folder/frames/output/probability_plots directory', elapsed_time=self.timer.elapsed_time_str)
 
 
-#
-# test = TresholdPlotCreatorSingleProcess(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals/project_folder/project_config.ini',
+# test = TresholdPlotCreatorSingleProcess(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini',
 #                                         frame_setting=False,
 #                                         video_setting=True,
 #                                         last_image=True,
 #                                         clf_name='Attack',
-#                                         files_found=['/Users/simon/Desktop/envs/troubleshooting/two_black_animals/project_folder/csv/machine_results/Together_1.csv'],
+#                                         files_found=['/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/csv/machine_results/Together_1.csv'],
 #                                         style_attr={'width': 640, 'height': 480, 'font size': 10, 'line width': 6, 'color': 'blue', 'circle size': 20, 'y_max': 'auto'})
-# #test = TresholdPlotCreatorSingleProcess(config_path='/Users/simon/Desktop/troubleshooting/train_model_project/project_folder/project_config.ini', frame_setting=False, video_setting=True, clf_name='Attack')
 # test.create_plots()
-#
-#
+
+
 #
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/plot_clf_results.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/plot_clf_results.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,32 +1,23 @@
-from simba.read_config_unit_tests import (read_config_entry,
-                                          check_file_exist_and_readable,
-                                          check_float,
-                                          check_int)
-from simba.misc_tools import (find_video_of_file,
-                              get_video_meta_data)
-from simba.rw_dfs import read_df
-from simba.misc_tools import create_single_color_lst
-from simba.utils.printing import stdout_success
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.drop_bp_cords import (createColorListofList,
-                                 create_body_part_dictionary,
-                                 get_fn_ext)
-from simba.enums import ReadConfig, Formats, Dtypes
 import os, glob
 from copy import deepcopy
-from simba.train_model_functions import get_model_info
-from simba.mixins.config_reader import ConfigReader
-from simba.utils.errors import NoSpecifiedOutputError
 import cv2
 import numpy as np
 from PIL import Image
+from simba.mixins.config_reader import ConfigReader
+from simba.mixins.train_model_mixin import TrainModelMixin
+from simba.mixins.plotting_mixin import PlottingMixin
+from simba.utils.errors import NoSpecifiedOutputError
+from simba.utils.printing import stdout_success
+from simba.enums import ReadConfig, Formats, Dtypes
+from simba.utils.read_write import get_fn_ext, read_df, get_video_meta_data, read_config_entry
+from simba.utils.checks import check_file_exist_and_readable, check_float, check_int
+from simba.utils.data import create_color_palette
 
-
-class PlotSklearnResultsSingleCore(ConfigReader):
+class PlotSklearnResultsSingleCore(ConfigReader, TrainModelMixin, PlottingMixin):
     """
     Class for plotting classification results on videos. Results are stored in the
     `project_folder/frames/output/sklearn_results` directory of the SimBA project.
 
     Parameters
     ----------
     config_path: str
@@ -55,29 +46,29 @@
                  video_setting: bool,
                  frame_setting: bool,
                  text_settings: dict or bool,
                  rotate: False,
                  video_file_path=None,
                  print_timers=True):
 
-        super().__init__(config_path=config_path)
+        ConfigReader.__init__(self, config_path=config_path)
+        TrainModelMixin.__init__(self)
+        PlottingMixin.__init__(self)
 
         if (not video_setting) and (not frame_setting):
             raise NoSpecifiedOutputError(msg='Please choose to create a video and/or frames. SimBA found that you ticked neither video and/or frames')
         self.video_file_path, self.print_timers, self.text_settings = video_file_path, print_timers, text_settings
         self.video_setting, self.frame_setting = video_setting, frame_setting
         if video_file_path is not None:
             check_file_exist_and_readable(os.path.join(self.video_dir, video_file_path))
         if not os.path.exists(self.sklearn_plot_dir): os.makedirs(self.sklearn_plot_dir)
         self.pose_threshold = read_config_entry(self.config, ReadConfig.THRESHOLD_SETTINGS.value, ReadConfig.SKLEARN_BP_PROB_THRESH.value, Dtypes.FLOAT.value, 0.00)
-        self.color_lst_of_lst = createColorListofList(self.animal_cnt, int(len(self.x_cols) + 1))
+        self.clr_lst = create_color_palette(pallete_name='Set1', increments=self.clf_cnt)
         self.files_found = glob.glob(self.machine_results_dir + '/*.' + self.file_type)
-        self.model_dict = get_model_info(self.config, self.clf_cnt)
-        self.clf_colors = create_single_color_lst(pallete_name ='Set1', increments=self.clf_cnt+3)
-        self.animal_bp_dict = create_body_part_dictionary(self.multi_animal_status, self.multi_animal_id_list, self.animal_cnt, self.x_cols, self.y_cols, [], self.color_lst_of_lst)
+        self.model_dict = self.get_model_info(self.config, self.clf_cnt)
         self.fourcc = cv2.VideoWriter_fourcc(*Formats.MP4_CODEC.value)
         self.rotate = rotate
         self.a = np.deg2rad(90)
         print(f'Processing {str(len(self.files_found))} videos...')
 
     def __get_print_settings(self):
         if self.text_settings is False:
@@ -96,16 +87,16 @@
             self.spacing_scale = int(self.text_settings['space_size'])
             self.text_thickness = int(self.text_settings['text_thickness'])
             self.circle_scale = int(self.text_settings['circle_size'])
 
     def create_visualizations(self):
         _, self.video_name, _ = get_fn_ext(self.file_path)
         self.data_df = read_df(self.file_path, self.file_type).reset_index(drop=True)
-        self.video_settings, _, self.fps = read_video_info(self.video_info_df, self.video_name)
-        self.video_path = find_video_of_file(self.video_dir, self.video_name)
+        self.video_settings, _, self.fps = self.read_video_info(video_name=self.video_name)
+        self.video_path = self.find_video_of_file(self.video_dir, self.video_name)
         self.cap = cv2.VideoCapture(self.video_path)
         self.save_path = os.path.join(self.sklearn_plot_dir, self.video_name + '.mp4')
         self.video_meta_data = get_video_meta_data(self.video_path)
         height, width = deepcopy(self.video_meta_data['height']), deepcopy(self.video_meta_data['width'])
         if self.frame_setting:
             self.video_frame_dir = os.path.join(self.sklearn_plot_dir, self.video_name)
             if not os.path.exists(self.video_frame_dir): os.makedirs(self.video_frame_dir)
@@ -157,26 +148,22 @@
                             cv2.putText(self.frame, model_info['model_name'] + ' ' + str(round(self.video_model_dict[model_no]['time'], 2)) + str('s'), (10, (self.video_meta_data['height'] - self.video_meta_data['height']) + self.spacing_scale * self.add_spacer), self.font, self.font_size, (255, 0, 0), self.text_thickness)
                             self.add_spacer += 1
                     cv2.putText(self.frame, str('Ensemble prediction'), (10, (self.video_meta_data['height'] - self.video_meta_data['height']) + self.spacing_scale * self.add_spacer), self.font, self.font_size, (0, 255, 0), self.text_thickness)
                     self.add_spacer += 1
 
                     for model_cnt, model_info in self.video_model_dict.items():
                         if self.video_model_dict[model_cnt]['frame_results'] == 1:
-                            cv2.putText(self.frame, model_info['model_name'], (10, ( self.video_meta_data['height'] - self.video_meta_data['height']) + self.spacing_scale * self.add_spacer), self.font, self.font_size, self.clf_colors[model_cnt], self.text_thickness)
+                            cv2.putText(self.frame, model_info['model_name'], (10, ( self.video_meta_data['height'] - self.video_meta_data['height']) + self.spacing_scale * self.add_spacer), self.font, self.font_size, self.clr_lst[model_cnt], self.text_thickness)
                             self.add_spacer += 1
                     if self.video_setting:
                         self.writer.write(self.frame)
                     if self.frame_setting:
                         frame_save_name = os.path.join(self.video_frame_dir, str(row_n) + '.png')
                         cv2.imwrite(frame_save_name, self.frame)
-                    # cv2.imshow('window', self.frame)
-                    # cv2.waitKey(50000)
-                    print('Frame: {} / {}. Video: {} ({}/{})'.format(str(row_n), str(self.video_meta_data['frame_count']),
-                                                                     self.video_name, str(self.file_cnt + 1),
-                                                                     len(self.files_found)))
+                    print(f'Frame: {row_n} / {self.video_meta_data["frame_count"]}. Video: {self.video_name} ({self.file_cnt + 1}/{len(self.files_found)})')
                     row_n += 1
 
                 else:
                     print('Video {} saved...'.format(self.video_name))
                     self.cap.release()
                     self.writer.release()
 
@@ -199,25 +186,18 @@
             self.files_found = [self.file_path]
             check_file_exist_and_readable(self.file_path)
             self.create_visualizations()
 
         self.timer.stop_timer()
         stdout_success(msg='All visualizations created in project_folder/frames/output/sklearn_results directory', elapsed_time=self.timer.elapsed_time_str)
 
-# test = PlotSklearnResults(config_path='/Users/simon/Desktop/troubleshooting/train_model_project/project_folder/project_config.ini',
-#                           video_setting=True,
-#                           frame_setting=False,
-#                           video_file_path='/Users/simon/Desktop/troubleshooting/train_model_project/project_folder/videos/Together_1.avi',
-#                           print_timers=False)
-# test.initialize_visualizations()
-
-# test = PlotSklearnResultsSingleCore(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals/project_folder/project_config.ini',
+# test = PlotSklearnResultsSingleCore(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini',
 #                                       video_setting=True,
 #                                       frame_setting=False,
-#                                       video_file_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals/project_folder/videos/Together_1.avi',
+#                                       video_file_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/videos/Together_1.avi',
 #                                       print_timers=True,
 #                                       text_settings=False,
 #                                       rotate=False)
 # test.initialize_visualizations()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/plot_clf_results_mp.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/plot_clf_results_mp.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,38 +1,23 @@
-from simba.read_config_unit_tests import (read_config_entry,
-                                          check_file_exist_and_readable,
-                                          check_float,
-                                          check_int)
-from simba.misc_tools import (find_video_of_file,
-                              get_video_meta_data,
-                              concatenate_videos_in_folder)
-from simba.rw_dfs import read_df
-from simba.misc_tools import (create_single_color_lst,
-                              SimbaTimer,
-                              )
-from simba.utils.printing import stdout_success
-from simba.feature_extractors.unit_tests import (read_video_info_csv,
-                                               read_video_info)
-from simba.drop_bp_cords import (getBpNames,
-                                 createColorListofList,
-                                 create_body_part_dictionary,
-                                 get_fn_ext)
-
-from simba.enums import ReadConfig, Formats, Paths, Dtypes
-from simba.mixins.config_reader import ConfigReader
-from simba.train_model_functions import get_model_info
-import os, glob
+import os
 from copy import deepcopy
 import multiprocessing
 import cv2
 import numpy as np
 import functools
 import platform
 from simba.utils.errors import NoSpecifiedOutputError
-
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.enums import ReadConfig, Formats, Dtypes
+from simba.utils.read_write import read_df, get_video_meta_data, concatenate_videos_in_folder, get_fn_ext, read_config_entry
+from simba.utils.checks import check_file_exist_and_readable, check_float, check_int
+from simba.utils.data import create_color_palette
+from simba.mixins.config_reader import ConfigReader
+from simba.mixins.train_model_mixin import TrainModelMixin
+from simba.mixins.plotting_mixin import PlottingMixin
 
 def _multiprocess_sklearn_video(data: np.array,
                                 video_path: str,
                                 video_save_dir: str,
                                 frame_save_dir: str,
                                 clf_colors: list,
                                 models_info: dict,
@@ -49,15 +34,14 @@
     cap = cv2.VideoCapture(video_path)
     group = data['group'].iloc[0]
     start_frm, current_frm, end_frm = data['index'].iloc[0], data['index'].iloc[0], data['index'].iloc[-1]
 
     if video_setting:
         video_save_path = os.path.join(video_save_dir, '{}.mp4'.format(str(group)))
         video_writer = cv2.VideoWriter(video_save_path, fourcc, video_meta_data['fps'], (video_meta_data['width'], video_meta_data['height']))
-
     cap.set(1, start_frm)
     while current_frm < end_frm:
         ret, img = cap.read()
         add_spacer = 2
         for animal_name, animal_data in bp_dict.items():
             animal_clr = animal_data['colors']
             id_flag_cords = None
@@ -102,15 +86,15 @@
     cap.release()
     if video_setting:
         video_writer.release()
 
     return group
 
 
-class PlotSklearnResultsMultiProcess(ConfigReader):
+class PlotSklearnResultsMultiProcess(ConfigReader, TrainModelMixin, PlottingMixin):
     """
     Class for plotting classification results on videos. Results are stored in the
     `project_folder/frames/output/sklearn_results` directory of the SimBA project.
 
     Parameters
     ----------
     config_path: str
@@ -142,36 +126,31 @@
                  frame_setting: bool,
                  text_settings: dict or bool,
                  cores: int,
                  rotate: False,
                  video_file_path=None,
                  print_timers=True):
 
-        super().__init__(config_path=config_path)
+        ConfigReader.__init__(self, config_path=config_path)
+        TrainModelMixin.__init__(self)
+        PlottingMixin.__init__(self)
         if platform.system() == "Darwin":
             multiprocessing.set_start_method('spawn', force=True)
 
         if (not video_setting) and (not frame_setting):
             raise NoSpecifiedOutputError(msg='SIMBA ERROR: Please choose to create a video and/or frames. SimBA found that you ticked neither video and/or frames')
         self.video_file_path, self.print_timers, self.text_settings = video_file_path, print_timers, text_settings
-        self.video_setting, self.frame_setting, self.cores = video_setting, frame_setting, cores
+        self.video_setting, self.frame_setting, self.cores, self.rotate = video_setting, frame_setting, cores, rotate
         if video_file_path is not None:
             check_file_exist_and_readable(os.path.join(self.video_dir, video_file_path))
         if not os.path.exists(self.sklearn_plot_dir): os.makedirs(self.sklearn_plot_dir)
         self.pose_threshold = read_config_entry(self.config, ReadConfig.THRESHOLD_SETTINGS.value, ReadConfig.SKLEARN_BP_PROB_THRESH.value, Dtypes.FLOAT.value, 0.00)
-        self.vid_info_df = read_video_info_csv(os.path.join(self.project_path, Paths.VIDEO_INFO.value))
-        self.model_cnt = read_config_entry(self.config, ReadConfig.SML_SETTINGS.value, ReadConfig.TARGET_CNT.value, data_type=Dtypes.INT.value)
-        self.x_cols, self.y_cols, self.pcols = getBpNames(config_path)
-        self.color_lst_of_lst = createColorListofList(self.animal_cnt, int(len(self.x_cols) + 1))
-        self.files_found = glob.glob(self.machine_results_dir + '/*.' + self.file_type)
-        self.model_dict = get_model_info(self.config, self.model_cnt)
-        self.clf_colors = create_single_color_lst(pallete_name ='Set1', increments=self.model_cnt+3)
-        self.animal_bp_dict = create_body_part_dictionary(self.multi_animal_status, self.multi_animal_id_list, self.animal_cnt, self.x_cols, self.y_cols, self.pcols, self.color_lst_of_lst)
+        self.model_dict = self.get_model_info(self.config, self.clf_cnt)
+        self.clf_colors = create_color_palette(pallete_name='Set1', increments=self.clf_cnt)
         self.fourcc = cv2.VideoWriter_fourcc(*Formats.MP4_CODEC.value)
-        self.rotate = rotate
 
     def __get_print_settings(self):
         self.text_attr = {}
         if self.text_settings is False:
             self.space_scale, self.radius_scale, self.res_scale, self.font_scale = 60, 12, 1500, 1.1
             self.max_dim = max(self.video_meta_data['width'], self.video_meta_data['height'])
             self.text_attr['circle_scale'] = int(self.radius_scale / (self.res_scale / self.max_dim))
@@ -194,16 +173,16 @@
         return data
 
     def create_visualizations(self):
         video_timer = SimbaTimer()
         video_timer.start_timer()
         _, self.video_name, _ = get_fn_ext(self.file_path)
         self.data_df = read_df(self.file_path, self.file_type).reset_index(drop=True)
-        self.video_settings, _, self.fps = read_video_info(self.vid_info_df, self.video_name)
-        self.video_path = find_video_of_file(self.video_dir, self.video_name)
+        self.video_settings, _, self.fps = self.read_video_info(video_name=self.video_name)
+        self.video_path = self.find_video_of_file(self.video_dir, self.video_name)
         self.video_meta_data = get_video_meta_data(self.video_path)
         height, width = deepcopy(self.video_meta_data['height']), deepcopy(self.video_meta_data['width'])
         self.video_frame_dir, self.video_temp_dir = None, None
         if self.frame_setting:
             self.video_frame_dir = os.path.join(self.sklearn_plot_dir, self.video_name)
             if not os.path.exists(self.video_frame_dir): os.makedirs(self.video_frame_dir)
         if self.video_setting:
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/ROI_feature_visualizer.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/ROI_feature_visualizer.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,23 +1,19 @@
 __author__ = "Simon Nilsson"
 
-from simba.read_config_unit_tests import check_file_exist_and_readable
 import os
-from simba.misc_tools import get_video_meta_data
-from simba.utils.printing import stdout_success
-from simba.drop_bp_cords import (createColorListofList,
-                                 create_body_part_dictionary,
-                                 get_fn_ext)
-from simba.enums import Formats
-from simba.roi_tools.ROI_feature_analyzer import ROIFeatureCreator
 import cv2
-from simba.rw_dfs import read_df
 import itertools
 import numpy as np
 from simba.mixins.config_reader import ConfigReader
+from simba.utils.printing import stdout_success
+from simba.enums import Formats
+from simba.utils.read_write import get_video_meta_data, get_fn_ext, read_df
+from simba.roi_tools.ROI_feature_analyzer import ROIFeatureCreator
+from simba.utils.checks import check_file_exist_and_readable
 
 class ROIfeatureVisualizer(ConfigReader):
     """
     Class for visualizing features that depend on the relationships between the location of the animals and user-defined
     ROIs. E.g., distances to centroids of ROIs, cumulative time spent in ROIs, if animals are directing towards ROIs
     etc.
 
@@ -46,23 +42,21 @@
                  ):
 
         super().__init__(config_path=config_path)
         _, self.video_name, _ = get_fn_ext(video_name)
         self.save_path = os.path.join(self.roi_features_save_dir, self.video_name + '.mp4')
         if not os.path.exists(self.roi_features_save_dir): os.makedirs(self.roi_features_save_dir)
         c_map_size, self.style_attr = int(len(self.x_cols) + 1), style_attr
-        color_lst_lst = createColorListofList(self.animal_cnt, c_map_size)
-        self.animal_bp_dict = create_body_part_dictionary(self.multi_animal_status, self.multi_animal_id_list, self.animal_cnt, self.x_cols, self.y_cols, self.p_cols, color_lst_lst)
         self.roi_feature_creator = ROIFeatureCreator(config_path=config_path)
         self.file_in_path = os.path.join(self.outlier_corrected_dir, self.video_name + '.' + self.file_type)
         self.video_path = os.path.join(self.project_path, 'videos', video_name)
         check_file_exist_and_readable(file_path=self.file_in_path)
         self.roi_feature_creator.features_files = [self.file_in_path]
         self.roi_feature_creator.files_found = [self.file_in_path]
-        self.roi_feature_creator.analyze_ROI_data()
+        self.roi_feature_creator.run()
         self.video_meta_data = get_video_meta_data(self.video_path)
         self.fourcc = cv2.VideoWriter_fourcc(*Formats.MP4_CODEC.value)
         self.font = cv2.FONT_HERSHEY_COMPLEX
         self.cap = cv2.VideoCapture(self.video_path)
         self.space_scale, self.radius_scale, self.res_scale, self.font_scale = 25, 10, 1500, 0.8
         self.max_dim = max(self.video_meta_data['width'], self.video_meta_data['height'])
         self.circle_scale = int(self.radius_scale / (self.res_scale / self.max_dim))
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/heat_mapper_location.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/heat_mapper_location.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,26 +1,22 @@
 __author__ = "Simon Nilsson", "JJ Choong"
 
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.misc_tools import (get_fn_ext,
-                              SimbaTimer,
-                              )
-from simba.utils.printing import stdout_success
 import os
 import cv2
-from simba.rw_dfs import read_df
 import numpy as np
 from numba import jit, prange
 import pandas as pd
 from simba.enums import Formats
 from simba.mixins.config_reader import ConfigReader
-from simba.plotting.misc_visualizations import make_location_heatmap_plot
+from simba.mixins.plotting_mixin import PlottingMixin
 from simba.utils.errors import NoSpecifiedOutputError
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.utils.read_write import get_fn_ext, read_df
 
-class HeatmapperLocationSingleCore(ConfigReader):
+class HeatmapperLocationSingleCore(ConfigReader, PlottingMixin):
     """
     Class for creating heatmaps representing the location where animals spend time.
 
     Parameters
     ----------
     config_path: str
         path to SimBA project config file in Configparser format
@@ -56,15 +52,16 @@
                  bodypart: str,
                  style_attr: dict,
                  final_img_setting: bool,
                  video_setting: bool,
                  frame_setting: bool,
                  files_found: list):
 
-        super().__init__(config_path=config_path)
+        ConfigReader.__init__(self, config_path=config_path)
+        PlottingMixin.__init__(self)
 
         if (not frame_setting) and (not video_setting) and (not final_img_setting):
             raise NoSpecifiedOutputError(msg='Please choose to select either heatmap videos, frames, and/or final image.')
 
         self.frame_setting, self.video_setting = frame_setting, video_setting
         self.final_img_setting, self.bp = final_img_setting, bodypart
         self.style_attr = style_attr
@@ -145,15 +142,15 @@
         return cum_sum_arr / fps
 
     def create_heatmaps(self):
         for file_cnt, file_path in enumerate(self.files_found):
             video_timer = SimbaTimer()
             video_timer.start_timer()
             _, self.video_name, _ = get_fn_ext(file_path)
-            self.video_info, self.px_per_mm, self.fps = read_video_info(vid_info_df=self.video_info_df, video_name=self.video_name)
+            self.video_info, self.px_per_mm, self.fps = self.read_video_info(video_name=self.video_name)
             self.width, self.height = int(self.video_info['Resolution_width'].values[0]), int(self.video_info['Resolution_height'].values[0])
             if self.video_setting:
                 self.video_save_path = os.path.join(self.heatmap_location_dir, self.video_name + '.mp4')
                 self.writer = cv2.VideoWriter(self.video_save_path, self.fourcc, self.fps, (self.width, self.height))
             if self.frame_setting | self.final_img_setting:
                 self.save_video_folder = os.path.join(self.heatmap_location_dir, self.video_name)
                 if not os.path.exists(self.save_video_folder): os.makedirs(self.save_video_folder)
@@ -164,37 +161,40 @@
                                                                      img_width=self.width,
                                                                      img_height=self.height,
                                                                      bin_size=self.style_attr['bin_size'],
                                                                      fps=self.fps)
 
             if self.style_attr['max_scale'] == 'auto':
                 self.max_scale = np.round(np.max(np.max(location_array[-1], axis=0)), 3)
-                if self.max_scale == 0: self.max_scale = 1
+                if self.max_scale == 0:
+                    self.max_scale = 1
+            else:
+                self.max_scale = self.style_attr['max_scale']
 
             if self.final_img_setting:
-                make_location_heatmap_plot(frm_data=location_array[-1:, :, :],
-                                           max_scale=self.max_scale,
-                                           palette=self.style_attr['palette'],
-                                           aspect_ratio=aspect_ratio,
-                                           file_name=os.path.join(self.heatmap_location_dir, self.video_name + '_final_frm.png'),
-                                           shading=self.style_attr['shading'],
-                                           img_size=(self.width, self.height),
-                                           final_img=True)
+                self.make_location_heatmap_plot(frm_data=location_array[-1:, :, :][0],
+                                                max_scale=self.max_scale,
+                                                palette=self.style_attr['palette'],
+                                                aspect_ratio=aspect_ratio,
+                                                file_name=os.path.join(self.heatmap_location_dir, self.video_name + '_final_frm.png'),
+                                                shading=self.style_attr['shading'],
+                                                img_size=(self.width, self.height),
+                                                final_img=True)
                 print('Final heatmap image saved at {}'.format(os.path.join(self.save_video_folder, '_final_img.png')))
 
             if (self.frame_setting) or (self.video_setting):
                 for frm_cnt, cumulative_frm in enumerate(range(location_array.shape[0])):
-                    img = make_location_heatmap_plot(frm_data=location_array[cumulative_frm,:,:],
-                                                     max_scale=self.max_scale,
-                                                     palette=self.style_attr['palette'],
-                                                     aspect_ratio=aspect_ratio,
-                                                     file_name=None,
-                                                     shading=self.style_attr['shading'],
-                                                     img_size=(self.width, self.height),
-                                                     final_img=False)
+                    img = self.make_location_heatmap_plot(frm_data=location_array[cumulative_frm,:,:],
+                                                          max_scale=self.max_scale,
+                                                          palette=self.style_attr['palette'],
+                                                          aspect_ratio=aspect_ratio,
+                                                          file_name=None,
+                                                          shading=self.style_attr['shading'],
+                                                          img_size=(self.width, self.height),
+                                                          final_img=False)
                     if self.video_setting:
                         self.writer.write(img)
                     if self.frame_setting:
                         frame_save_path = os.path.join(self.save_video_folder, str(frm_cnt) + '.png')
                         cv2.imwrite(frame_save_path, img)
 
                     print('Heatmap frame: {} / {}. Video: {} ({}/{})'.format(str(frm_cnt + 1), str(len(self.data_df)), self.video_name, str(file_cnt + 1), len(self.files_found)))
@@ -205,16 +205,16 @@
             print(f'Heatmap plot for video {self.video_name} saved (elapsed time: {video_timer.elapsed_time_str}s')
         self.timer.stop_timer()
 
         stdout_success(msg=f'Created heatmaps for {str(len(self.files_found))} videos', elapsed_time=self.timer.elapsed_time_str)
 #
 # test = HeatmapperLocationSingleCore(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini',
 #                                       style_attr = {'palette': 'jet', 'shading': 'gouraud', 'bin_size': 100, 'max_scale': 'auto'},
-#                                       final_img_setting=False,
-#                                       video_setting=True,
+#                                       final_img_setting=True,
+#                                       video_setting=False,
 #                                       frame_setting=False,
 #                                       bodypart='Nose_1',
 #                                       files_found=['/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/csv/machine_results/Together_1.csv'])
 # test.create_heatmaps()
 
 
 
@@ -234,8 +234,9 @@
 #                           bodypart='Nose_1',
 #                           bin_size=50,
 #                           palette='jet',
 #                           max_scale='auto',
 #                           final_img_setting=True,
 #                           video_setting=False,
 #                           frame_setting=False)
-# test.create_heatmaps()
+# test.create_heatmaps()
+
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/probability_plot_creator_mp.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/gantt_creator_mp.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,238 +1,180 @@
 __author__ = "Simon Nilsson"
 
-
-from simba.read_config_unit_tests import check_that_column_exist
-from simba.feature_extractors.unit_tests import read_video_info
-import functools
+import warnings
+warnings.simplefilter(action='ignore', category=FutureWarning)
 import pandas as pd
-from simba.misc_tools import (SimbaTimer,
-                              concatenate_videos_in_folder,
-                              )
-from simba.utils.printing import stdout_success
-from simba.utils.errors import NoSpecifiedOutputError
-from simba.plotting.misc_visualizations import make_probability_plot
-from simba.enums import Formats
-from simba.mixins.config_reader import ConfigReader
 import os
-from simba.drop_bp_cords import get_fn_ext
-from simba.rw_dfs import read_df
-import matplotlib.pyplot as plt
-import cv2
 import numpy as np
-import shutil
+import cv2
 import multiprocessing
+import functools
+import shutil
 import platform
-from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas
-
-def _create_probability_plots(data: list,
-                              probability_lst: list,
-                              clf_name: str,
-                              video_setting: bool,
-                              frame_setting: bool,
-                              video_dir: str,
-                              frame_dir: str,
-                              highest_p: float,
-                              fps: int,
-                              style_attr: dict,
-                              video_name: str):
-
-    group, data = data[0], data[1:]
-    start_frm, end_frm, current_frm = data[0], data[-1], data[0]
-
-    if video_setting:
-        fourcc = cv2.VideoWriter_fourcc(*Formats.MP4_CODEC.value)
-        video_save_path = os.path.join(video_dir, '{}.mp4'.format(str(group)))
-        video_writer = cv2.VideoWriter(video_save_path, fourcc, fps, (style_attr['width'], style_attr['height']))
-
-    while current_frm < end_frm:
-        fig, ax = plt.subplots()
-        current_lst = probability_lst[0:current_frm+1]
-        ax.plot(current_lst, color=style_attr['color'], linewidth=style_attr['line width'])
-        ax.plot(current_frm, current_lst[-1], "o", markersize=style_attr['circle size'], color=style_attr['color'])
-        ax.set_ylim([0, highest_p])
-        x_ticks_locs = x_lbls = np.linspace(0, current_frm, 5)
-        x_lbls = np.round((x_lbls / fps), 1)
-        ax.xaxis.set_ticks(x_ticks_locs)
-        ax.set_xticklabels(x_lbls, fontsize=style_attr['font size'])
-        ax.set_xlabel('Time (s)', fontsize=style_attr['font size'])
-        ax.set_ylabel('{} {}'.format(clf_name, 'probability'), fontsize=style_attr['font size'])
-        plt.suptitle(clf_name, x=0.5, y=0.92, fontsize=style_attr['font size'] + 4)
-        canvas = FigureCanvas(fig)
-        canvas.draw()
-        mat = np.array(canvas.renderer._renderer)
-        image = cv2.cvtColor(mat, cv2.COLOR_RGB2BGR)
-        image = np.uint8(cv2.resize(image, (style_attr['width'], style_attr['height'])))
-        if video_setting:
-            video_writer.write(image)
-        if frame_setting:
-            frame_save_name = os.path.join(frame_dir, '{}.png'.format(str(current_frm)))
-            cv2.imwrite(frame_save_name, image)
-        plt.close()
-        current_frm += 1
-
-        print('Probability frame created: {}, Video: {}, Processing core: {}'.format(str(current_frm+1), video_name, str(group+1)))
-
+from simba.utils.errors import NoSpecifiedOutputError
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.utils.lookups import get_named_colors
+from simba.utils.read_write import concatenate_videos_in_folder, get_fn_ext, read_df
+from simba.utils.checks import check_if_filepath_list_is_empty
+from simba.utils.data import detect_bouts
+from simba.enums import Formats
+from simba.mixins.config_reader import ConfigReader
+from simba.mixins.plotting_mixin import PlottingMixin
 
-    return group
+class GanttCreatorMultiprocess(ConfigReader, PlottingMixin):
 
-class TresholdPlotCreatorMultiprocess(ConfigReader):
     """
-    Class for line chart visualizations displaying the classification probabilities of a single classifier.
-    Uses multiprocessing.
+    Class for multiprocess creation of classifier gantt charts in video and/or image format.
 
     Parameters
     ----------
     config_path: str
         path to SimBA project config file in Configparser format
-    clf_name: str
-        Name of the classifier to create visualizations for
     frame_setting: bool
-       When True, SimBA creates individual frames in png format
+        If True, creates individual frames
     video_setting: bool
-       When True, SimBA creates compressed video in mp4 format
+        If True, creates videos
     files_found: list
-        File paths to create probability plots for, e.g., ['project_folder/csv/machine_results/MyVideo.csv]
-    style_attr: dict
-        Output image style attributes, e.g., {'width': 640, 'height': 480, 'font size': 10, 'line width': 6, 'color': 'magneta', 'circle size': 20}
+        File paths representing files with machine predictions e.g., ['project_folder/csv/machine_results/My_results.csv']
     cores: int
         Number of cores to use
+    style_attr: dict
+        Output image style attributes, e.g., {'width': 640, 'height': 480, 'font size': 8, 'font rotation': 45}
+
 
     Notes
     ----------
-    `Visualization tutorials <https://github.com/sgoldenlab/simba/blob/master/docs/tutorial.md#step-11-visualizations>`__.
-
+    `GitHub gantt tutorial <https://github.com/sgoldenlab/simba/blob/master/docs/tutorial.md#gantt-plot>`__.
+    See ``simba.gantt_creator.GanttCreatorSingleProcess`` for single-process class.
 
     Examples
     ----------
-    >>> plot_creator = TresholdPlotCreatorMultiprocess(config_path='/Users/simon/Desktop/troubleshooting/train_model_project/project_folder/project_config.ini', frame_setting=True, video_setting=True, clf_name='Attack', style_attr={'width': 640, 'height': 480, 'font size': 10, 'line width': 6, 'color': 'magneta', 'circle size': 20}, cores=5)
-    >>> plot_creator.create_plot()
-    """
+    >>> gantt_creator = GanttCreatorMultiprocess(config_path='tests/test_data/multi_animal_dlc_two_c57/project_folder/project_config.ini', frame_setting=False, video_setting=True, files_found=['tests/test_data/multi_animal_dlc_two_c57/project_folder/csv/machine_results/Together_1.csv'], cores=5, style_attr={'width': 640, 'height': 480, 'font size': 8, 'font rotation': 45})
+    >>> gantt_creator.run()
 
+    """
 
     def __init__(self,
                  config_path: str,
-                 clf_name: str,
                  frame_setting: bool,
                  video_setting: bool,
-                 last_frame: bool,
+                 files_found: list,
                  cores: int,
                  style_attr: dict,
-                 files_found: list):
+                 last_frm_setting: bool):
 
-        super().__init__(config_path=config_path)
         if platform.system() == "Darwin":
             multiprocessing.set_start_method('spawn', force=True)
-        self.frame_setting, self.video_setting, self.cores, self.style_attr, self.last_frame = frame_setting, video_setting, cores, style_attr, last_frame
-        if (not self.frame_setting) and (not self.video_setting) and (not self.last_frame):
-            raise NoSpecifiedOutputError('SIMBA ERROR: Please choose to create either probability videos, frames, and/or last frame.', show_window=True)
-        self.clf_name, self.files_found = clf_name, files_found
-        self.probability_col = 'Probability_' + self.clf_name
-        self.fontsize = self.style_attr['font size']
-        self.out_width, self.out_height = self.style_attr['width'], self.style_attr['height']
+
+        ConfigReader.__init__(self, config_path=config_path)
+        PlottingMixin.__init__(self)
+
+        self.frame_setting, self.video_setting, self.files_found, self.style_attr, self.cores, self.last_frm_setting = frame_setting, video_setting, files_found, style_attr, cores, last_frm_setting
+        if (not self.frame_setting) and (not self.video_setting) and (not self.last_frm_setting):
+            raise NoSpecifiedOutputError(msg='SIMBA ERROR: Please select gantt videos, frames, and/or last frame.')
+        check_if_filepath_list_is_empty(filepaths=self.files_found,
+                                        error_msg='SIMBA ERROR: Zero files found in the project_folder/csv/machine_results directory. Create classification results before visualizing gantt charts')
+        self.colours = get_named_colors()[:-1]
+        self.colour_tuple_x = list(np.arange(3.5, 203.5, 5))
+        if not os.path.exists(self.gantt_plot_dir): os.makedirs(self.gantt_plot_dir)
+        self.y_rotation, self.y_fontsize = self.style_attr['font rotation'], self.style_attr['font size']
         self.fourcc = cv2.VideoWriter_fourcc(*Formats.MP4_CODEC.value)
-        if not os.path.exists(self.probability_plot_dir): os.makedirs(self.probability_plot_dir)
-        print(f'Processing {str(len(self.files_found))} video(s)...')
+        self.out_width, self.out_height = self.style_attr['width'], self.style_attr['height']
+        print('Processing {} video(s)...'.format(str(len(self.files_found))))
+
+    def run(self):
+        '''
+        Creates gantt charts. Results are stored in the `project_folder/frames/gantt_plots` directory of SimBA project.
+
+        Returns
+        ----------
+        None
+        '''
 
-    def create_plots(self):
         for file_cnt, file_path in enumerate(self.files_found):
             video_timer = SimbaTimer()
             video_timer.start_timer()
             _, self.video_name, _ = get_fn_ext(file_path)
-            video_info, self.px_per_mm, self.fps = read_video_info(vid_info_df=self.video_info_df, video_name=self.video_name)
-            data_df = read_df(file_path, self.file_type)
-            check_that_column_exist(df=data_df, column_name=self.clf_name, file_name=self.video_name)
-            self.save_frame_folder_dir = os.path.join(self.probability_plot_dir, self.video_name + '_' + self.clf_name)
-            self.video_folder = os.path.join(self.probability_plot_dir, self.video_name + '_' + self.clf_name)
-            self.temp_folder = os.path.join(self.probability_plot_dir, self.video_name + '_' + self.clf_name, 'temp')
+            self.data_df = read_df(file_path, self.file_type).reset_index(drop=True)
+            print('Processing video {}, Frame count: {} (Video {}/{})...'.format(self.video_name, str(len(self.data_df)), str(file_cnt+1), str(len(self.files_found))))
+            self.video_info_settings, _, self.fps = self.read_video_info(video_name=self.video_name)
+            self.bouts_df = detect_bouts(data_df=self.data_df, target_lst=list(self.clf_names), fps=int(self.fps))
+            self.temp_folder = os.path.join(self.gantt_plot_dir, self.video_name, 'temp')
+            self.save_frame_folder_dir = os.path.join(self.gantt_plot_dir, self.video_name)
             if self.frame_setting:
                 if os.path.exists(self.save_frame_folder_dir): shutil.rmtree(self.save_frame_folder_dir)
                 if not os.path.exists(self.save_frame_folder_dir): os.makedirs(self.save_frame_folder_dir)
             if self.video_setting:
+                self.video_folder = os.path.join(self.gantt_plot_dir, self.video_name)
                 if os.path.exists(self.temp_folder):
                     shutil.rmtree(self.temp_folder)
                     shutil.rmtree(self.video_folder)
                 os.makedirs(self.temp_folder)
-                self.save_video_path = os.path.join(self.probability_plot_dir, '{}_{}.mp4'.format(self.video_name, self.clf_name))
-
-            probability_lst = list(data_df[self.probability_col])
-
-            if self.last_frame:
-                _ = make_probability_plot(data=pd.Series(probability_lst),
-                                          style_attr=self.style_attr,
-                                          clf_name=self.clf_name,
-                                          fps=self.fps,
-                                          save_path=os.path.join(self.probability_plot_dir, self.video_name + '_{}_{}.png'.format(self.clf_name, 'final_image')))
+                self.save_video_path = os.path.join(self.gantt_plot_dir, self.video_name + '.mp4')
 
+            if self.last_frm_setting:
+                _ = self.make_gantt_plot(data_df=self.data_df,
+                                         bouts_df=self.bouts_df,
+                                         clf_names=self.clf_names,
+                                         fps=self.fps,
+                                         style_attr=self.style_attr,
+                                         video_name=self.video_name,
+                                         save_path=os.path.join(self.gantt_plot_dir, self.video_name + '_final_image.png'))
 
             if self.video_setting or self.frame_setting:
-                if self.style_attr['y_max'] == 'auto':
-                    highest_p = data_df[self.probability_col].max()
-                else:
-                    highest_p = float(self.style_attr['y_max'])
-                data_split = np.array_split(list(data_df.index), self.cores)
-                frm_per_core = len(data_split[0])
-                for group_cnt, rng in enumerate(data_split):
-                    data_split[group_cnt] = np.insert(rng, 0, group_cnt)
-
+                frame_array = np.array_split(list(range(0, len(self.data_df))), self.cores)
+                frm_per_core = len(frame_array[0])
+                for group_cnt, rng in enumerate(frame_array):
+                    frame_array[group_cnt] = np.insert(rng, 0, group_cnt)
 
-                print('Creating probability images, multiprocessing (determined chunksize: {}, cores: {})...'.format(str(self.multiprocess_chunksize), str(self.cores)))
+                print('Creating gantt, multiprocessing (chunksize: {}, cores: {})...'.format(str(self.multiprocess_chunksize), str(self.cores)))
                 with multiprocessing.Pool(self.cores, maxtasksperchild=self.maxtasksperchild) as pool:
-                    constants = functools.partial(_create_probability_plots,
-                                                  clf_name=self.clf_name,
-                                                  probability_lst=probability_lst,
-                                                  highest_p= highest_p,
+                    constants = functools.partial(self.gantt_creator_mp,
                                                   video_setting=self.video_setting,
                                                   frame_setting=self.frame_setting,
+                                                  video_save_dir=self.temp_folder,
+                                                  frame_folder_dir=self.save_frame_folder_dir,
+                                                  bouts_df=self.bouts_df,
+                                                  rotation=self.y_rotation,
+                                                  clf_names=self.clf_names,
+                                                  colors=self.colours,
+                                                  color_tuple=self.colour_tuple_x,
                                                   fps=self.fps,
-                                                  video_dir=self.temp_folder,
-                                                  frame_dir=self.save_frame_folder_dir,
-                                                  style_attr=self.style_attr,
+                                                  font_size=self.y_fontsize,
+                                                  width=self.out_width,
+                                                  height=self.out_height,
                                                   video_name=self.video_name)
-                    for cnt, result in enumerate(pool.imap(constants, data_split, chunksize=self.multiprocess_chunksize)):
-                        print('Image {}/{}, Video {}/{}...'.format(str(int(frm_per_core*(result+1))), str(len(data_df)), str(file_cnt+1), str(len(self.files_found))))
 
-                pool.join()
-                pool.terminate()
+                    for cnt, result in enumerate(pool.imap(constants, frame_array, chunksize=self.multiprocess_chunksize)):
+                        print('Image {}/{}, Video {}/{}...'.format(str(int(frm_per_core * (result+1))), str(len(self.data_df)), str(file_cnt + 1), str(len(self.files_found))))
+                    pool.terminate()
+                    pool.join()
+
                 if self.video_setting:
                     print('Joining {} multiprocessed video...'.format(self.video_name))
                     concatenate_videos_in_folder(in_folder=self.temp_folder, save_path=self.save_video_path)
-
                 video_timer.stop_timer()
-                print('Probability video {} complete (elapsed time: {}s) ...'.format(self.video_name, video_timer.elapsed_time_str))
+                print('Gantt video {} complete (elapsed time: {}s) ...'.format(self.video_name, video_timer.elapsed_time_str))
 
         self.timer.stop_timer()
-        stdout_success(msg=f'Probability visualizations for {str(len(self.files_found))} videos created in project_folder/frames/output/gantt_plots directory', elapsed_time=self.timer.elapsed_time_str)
-
-
-# test = TresholdPlotCreatorMultiprocess(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals/project_folder/project_config.ini',
-#                                         frame_setting=False,
-#                                         video_setting=True,
-#                                         last_frame=False,
-#                                         clf_name='Attack',
-#                                         cores=5,
-#                                         files_found=['/Users/simon/Desktop/envs/troubleshooting/two_black_animals/project_folder/csv/machine_results/Together_1.csv'],
-#                                         style_attr={'width': 640, 'height': 480, 'font size': 10, 'line width': 6, 'color': 'blue', 'circle size': 20, 'y_max': 'auto'})
-# #test = TresholdPlotCreatorSingleProcess(config_path='/Users/simon/Desktop/troubleshooting/train_model_project/project_folder/project_config.ini', frame_setting=False, video_setting=True, clf_name='Attack')
-# test.create_plots()
-
-
-# test = TresholdPlotCreatorMultiprocess(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini',
-#                                         frame_setting=False,
-#                                         video_setting=False,
-#                                         last_frame=False,
-#                                         clf_name='Attack',
-#                                         cores=5,
-#                                         files_found=['/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/csv/machine_results/Together_1.csv'],
-#                                         style_attr={'width': 640, 'height': 480, 'font size': 10, 'line width': 6, 'color': 'blue', 'circle size': 20, 'y_max': 'auto'})
-# test.create_plots()
-
-
-
-
-
-
-
-
-
+        stdout_success(msg=f'Gantt visualizations for {len(self.files_found)} videos created in project_folder/frames/output/gantt_plots directory', elapsed_time=self.timer.elapsed_time_str)
 
+# test = GanttCreatorMultiprocess(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini',
+#                                 frame_setting=False,
+#                                 video_setting=True,
+#                                 files_found=['/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/csv/targets_inserted/Together_1.csv'],
+#                                 cores=5,
+#                                 last_frm_setting=False,
+#                                 style_attr={'width': 640, 'height': 480, 'font size': 12, 'font rotation': 45})
+# test.run()
+
+
+# style_attr = {'width': 640, 'height': 480, 'font size': 12, 'font rotation': 45}
+# test = GanttCreatorMultiprocess(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals/project_folder/project_config.ini',
+#                                  frame_setting=False,
+#                                  video_setting=True,
+#                                  last_frm_setting=False,
+#                                  style_attr=style_attr,
+# cores=5,
+#                                  files_found=['/Users/simon/Desktop/envs/troubleshooting/two_black_animals/project_folder/csv/machine_results/Together_1.csv'])
+# test.create_gannt()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/interactive_probability_grapher.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/interactive_probability_grapher.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,24 +1,19 @@
 __author__ = "Simon Nilsson", "JJ Choong"
 
 import matplotlib.pyplot as plt
-import numpy as np
-
-from simba.read_config_unit_tests import check_file_exist_and_readable
-from matplotlib.widgets import Button
-from simba.plotting.tools.tkinter_tools import InteractiveVideoPlotterWindow
-from simba.misc_tools import get_fn_ext, find_video_of_file
-from simba.rw_dfs import read_df
 import os
 import threading
 from simba.enums import Paths
-from simba.utils.errors import InvalidInputError, ColumnNotFoundError
 from copy import copy
 from simba.mixins.config_reader import ConfigReader
-
+from simba.utils.errors import InvalidInputError, ColumnNotFoundError
+from simba.utils.checks import check_file_exist_and_readable
+from simba.plotting.tools.tkinter_tools import InteractiveVideoPlotterWindow
+from simba.utils.read_write import read_df, get_fn_ext
 
 class InteractiveProbabilityGrapher(ConfigReader):
     """
     Class for launching and creating interactive GUI for classifier probability inspection.
 
     Parameters
     ----------
@@ -58,15 +53,15 @@
         self.data_path = os.path.join(self.project_path, Paths.CLF_DATA_VALIDATION_DIR.value, os.path.basename(self.file_path))
         check_file_exist_and_readable(self.data_path)
         _, video_name, _ = get_fn_ext(filepath=file_path)
         self.data_df = read_df(self.data_path, self.file_type)
         if f'Probability_{self.clf_name}' not in self.data_df.columns:
             raise ColumnNotFoundError(column_name=f'Probability_{self.clf_name}', file_name=self.data_path)
         self.p_arr = self.data_df[['Probability_{}'.format(self.clf_name)]].to_numpy()
-        current_video_file_path = find_video_of_file(video_dir=self.video_dir, filename=video_name)
+        current_video_file_path = self.find_video_of_file(video_dir=self.video_dir, filename=video_name)
         self.video_frm = InteractiveVideoPlotterWindow(video_path=current_video_file_path, p_arr=self.p_arr)
 
 
     @staticmethod
     def __click_event(event):
         global current_x_cord
         if (event.dblclick) and (event.button == 1) and (type(event.xdata) != None):
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/plot_pose_in_dir.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/plot_pose_in_dir.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,25 +1,20 @@
 __author__ = "Simon Nilsson"
 
 import pandas as pd
 import cv2
 import os, glob
-from simba.drop_bp_cords import get_fn_ext
 from pathlib import Path
-from simba.misc_tools import (find_video_of_file,
-                              get_video_meta_data,
-                              create_single_color_lst,
-                              get_color_dict,
-                              SimbaTimer,
-                              )
-from simba.utils.printing import stdout_success
+from simba.utils.lookups import get_color_dict
+from simba.utils.printing import stdout_success, SimbaTimer
 from simba.enums import Formats
-from simba.read_config_unit_tests import check_if_filepath_list_is_empty
-from simba.rw_dfs import read_df
 from simba.utils.errors import InvalidInputError
+from simba.utils.read_write import read_df, get_video_meta_data, get_fn_ext, find_video_of_file
+from simba.utils.checks import check_if_filepath_list_is_empty
+from simba.utils.data import create_color_palette
 
 
 ACCEPTED_DIRECTORIES = ['input_csv', 'outlier_corrected_movement', 'outlier_corrected_movement_location']
 
 def create_video_from_dir(in_directory: str,
                           out_directory: str,
                           circle_size: int,
@@ -65,15 +60,15 @@
         pose_df = read_df(file_path, ext[1:].lower())
         if os.path.basename(in_directory) == 'input_csv':
             pose_df.columns = list(pose_df.loc['coords'])
 
         pose_df = pose_df.apply(pd.to_numeric, errors='coerce')
         pose_df = pose_df.fillna(0).reset_index(drop=True)
         bp_lst_of_lst = [list(pose_df.columns)[i:i + 3] for i in range(0, len(pose_df.columns), 3)]
-        color_list = create_single_color_lst(increments=len(bp_lst_of_lst), pallete_name='Set1')
+        color_list = create_color_palette(increments=len(bp_lst_of_lst), pallete_name='Set1')
         animal_bp_dict = {}
         if clr_attr:
             clrs = get_color_dict()
             animal_bp_dict = {}
             for animal in range(1, len(clr_attr.keys()) + 1):
                 animal_bp_dict['Animal_{}'.format(str(animal))] = {}
                 animal_bp_dict['Animal_{}'.format(str(animal))]['bps'] = []
@@ -110,12 +105,12 @@
                 break
         print('{} complete...'.format(file_name))
         cap.release()
         writer.release()
     timer.stop_timer()
     stdout_success(msg=f'All pose videos complete. Results located in {str(out_directory)} directory', elapsed_time=timer.elapsed_time_str)
 
-# create_video_from_dir(in_directory=r'/Users/simon/Desktop/envs/troubleshooting/naresh/project_folder/csv/features_extracted',
+# create_video_from_dir(in_directory=r'/Users/simon/Desktop/envs/troubleshooting/naresh/project_folder/csv/outlier_corrected_movement_location',
 #                       out_directory=r'/Users/simon/Desktop/envs/troubleshooting/naresh/project_folder/csv/features_extracted/test',
 #                       circle_size=5,
 #                       clr_attr=None)
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/single_run_model_validation_video.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/single_run_model_validation_video.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,35 +1,28 @@
 __author__ = "Simon Nilsson"
 
 import warnings
 warnings.filterwarnings('ignore',category=FutureWarning)
 warnings.filterwarnings('ignore',category=DeprecationWarning)
-import pickle
-from simba.mixins.config_reader import ConfigReader
 import cv2
+import os
+import numpy as np
 import warnings
-from simba.drop_bp_cords import createColorListofList, getBpNames, create_body_part_dictionary, drop_bp_cords
 import matplotlib.pyplot as plt
-import numpy as np
-from simba.rw_dfs import *
-from simba.misc_tools import (find_video_of_file,
-                              get_fn_ext,
-                              get_video_meta_data,
-                              plug_holes_shortest_bout,
-                              get_bouts_for_gantt,
-                              create_gantt_img,
-                              resize_gantt,
-                              )
+from simba.utils.data import plug_holes_shortest_bout
 from simba.utils.printing import stdout_success
-from simba.feature_extractors.unit_tests import read_video_info
+from simba.utils.read_write import read_df, write_df, get_fn_ext, get_video_meta_data
+from simba.mixins.config_reader import ConfigReader
+from simba.mixins.plotting_mixin import PlottingMixin
+
 plt.interactive(True)
 plt.ioff()
 warnings.simplefilter(action='ignore', category=FutureWarning)
 
-class ValidateModelOneVideo(ConfigReader):
+class ValidateModelOneVideo(ConfigReader, PlottingMixin):
     """
     Class for creating classifier validation video for a single input video. Results are stored in the
     `project_folder/frames/output/validation directory`.
 
     Parameters
     ----------
     config_path: str
@@ -56,49 +49,50 @@
                  feature_file_path: str,
                  model_path: str,
                  discrimination_threshold: float,
                  shortest_bout: int,
                  create_gantt: str,
                  settings: None=None):
 
-        super().__init__(config_path=config_path)
+        ConfigReader.__init__(self, config_path=config_path)
+        PlottingMixin.__init__(self)
         _, self.feature_filename, ext = get_fn_ext(feature_file_path)
         self.discrimination_threshold, self.shortest_bout, self.create_gantt, self.settings = float(discrimination_threshold), shortest_bout, create_gantt, settings
         if not os.path.exists(self.single_validation_video_save_dir): os.makedirs(self.single_validation_video_save_dir)
-        _, _, self.fps = read_video_info(self.video_info_df, self.feature_filename)
+        _, _, self.fps = self.read_video_info(video_name=self.feature_filename)
         self.clf_name = os.path.basename(model_path).replace('.sav', '')
-        self.video_path = find_video_of_file(self.video_dir, self.feature_filename)
+        self.video_path = self.find_video_of_file(self.video_dir, self.feature_filename)
         self.video_meta_data = get_video_meta_data(video_path=self.video_path)
         self.vid_output_path = os.path.join(self.single_validation_video_save_dir, f'{self.feature_filename} {self.clf_name}.avi')
         self.clf_data_save_path = os.path.join(self.clf_data_validation_dir, self.feature_filename + '.csv')
-        self.clf = pickle.load(open(model_path, 'rb'))
+        self.clf = read_df(file_path=model_path, file_type='pickle')
         self.in_df = read_df(feature_file_path, self.file_type)
 
     def __run_clf(self):
-        self.data_df = drop_bp_cords(self.in_df, self.config_path)
+        self.data_df = self.drop_bp_cords(df=self.in_df)
         self.prob_col_name = f'Probability_{self.clf_name}'
         self.data_df[self.prob_col_name] = self.clf.predict_proba(self.data_df)[:, 1]
         self.data_df[self.clf_name] = np.where(self.data_df[self.prob_col_name] > self.discrimination_threshold, 1, 0)
 
     def __plug_bouts(self):
         self.data_df = plug_holes_shortest_bout(data_df=self.data_df, clf_name=self.clf_name, fps=self.fps, shortest_bout=self.shortest_bout)
 
     def __save(self):
-        save_df(self.data_df, self.file_type, self.clf_data_save_path)
+        write_df(df=self.data_df, file_type=self.file_type, save_path=self.clf_data_save_path)
         print(f'Predictions created for video {self.feature_filename}...')
 
     def __create_video(self):
         cap = cv2.VideoCapture(self.video_path)
         fourcc = cv2.VideoWriter_fourcc(*'mp4v')
         if self.create_gantt == 'None':
             writer = cv2.VideoWriter(self.vid_output_path, fourcc, self.fps, (self.video_meta_data['width'], self.video_meta_data['height']))
         else:
-            self.bouts_df = get_bouts_for_gantt(data_df=self.data_df, clf_name=self.clf_name, fps=self.fps)
-            self.gantt_img = create_gantt_img(self.bouts_df, self.clf_name, len(self.data_df), self.fps, 'Behavior gantt chart (entire session)')
-            self.gantt_img = resize_gantt(self.gantt_img, self.video_meta_data['height'])
+            self.bouts_df = self.get_bouts_for_gantt(data_df=self.data_df, clf_name=self.clf_name, fps=self.fps)
+            self.gantt_img = self.create_gantt_img(self.bouts_df, self.clf_name, len(self.data_df), self.fps, 'Behavior gantt chart (entire session)')
+            self.gantt_img = self.resize_gantt(self.gantt_img, self.video_meta_data['height'])
             writer = cv2.VideoWriter(self.vid_output_path, fourcc, self.fps, (int(self.video_meta_data['width'] + self.gantt_img.shape[1]), int(self.video_meta_data['height'])))
 
         if self.settings['styles'] is None:
             self.settings['styles'] = {}
             space_scaler, radius_scaler, resolution_scaler, font_scaler = 60, 20, 1500, 1.5
             max_dim = max(self.video_meta_data['width'], self.video_meta_data['height'])
             self.settings['styles']['circle size'] = int(radius_scaler / (resolution_scaler / max_dim))
@@ -131,16 +125,16 @@
                 addSpacer += 2
                 if clf_val == 1:
                     cv2.putText(frame, self.clf_name, (10, + self.settings['styles']['space_scale'] * addSpacer), self.font, self.settings['styles']['font size'], (2, 166, 249), 2)
                     addSpacer += 1
                 if self.create_gantt == 'Gantt chart: final frame only (slightly faster)':
                     frame = np.concatenate((frame, self.gantt_img), axis=1)
                 elif self.create_gantt == 'Gantt chart: video':
-                    gantt_img = create_gantt_img(self.bouts_df, self.clf_name, frm_cnt, self.fps, 'Behavior gantt chart')
-                    gantt_img = resize_gantt(gantt_img, self.video_meta_data['video_height'])
+                    gantt_img = self.create_gantt_img(self.bouts_df, self.clf_name, frm_cnt, self.fps, 'Behavior gantt chart')
+                    gantt_img = self.resize_gantt(gantt_img, self.video_meta_data['video_height'])
                     frame = np.concatenate((frame, gantt_img), axis=1)
                 elif self.create_gantt != 'None':
                     frame = cv2.resize(frame, (int(self.video_meta_data['width'] + self.gantt_img.shape[1]), self.video_meta_data['height']))
                 writer.write(np.uint8(frame))
                 print('Frame created: {} / {}'.format(str(frm_cnt+1), str(len(self.data_df))))
                 frm_cnt += 1
                 if frame is None:
@@ -169,14 +163,29 @@
 #                              feature_file_path=r'/Users/simon/Desktop/envs/troubleshooting/naresh/project_folder/csv/features_extracted/SF2.csv',
 #                              model_path='/Users/simon/Desktop/envs/troubleshooting/naresh/models/generated_models/Top.sav',
 #                              discrimination_threshold=0.6,
 #                              shortest_bout=50,
 #                              settings={'pose': True, 'animal_names': True, 'styles': None},
 #                              create_gantt='Gantt chart: final frame only (slightly faster)')
 # test.run()
+#
+
+# test = ValidateModelOneVideo(config_path=r'/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini',
+#                              feature_file_path=r'/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/csv/features_extracted/Together_2.csv',
+#                              model_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/models/generated_models/Attack.sav',
+#                              discrimination_threshold=0.6,
+#                              shortest_bout=50,
+#                              settings={'pose': True, 'animal_names': True, 'styles': None},
+#                              create_gantt='Gantt chart: final frame only (slightly faster)')
+# test.run()
+
+
+
+
+
 
 
 # test.perform_clf()
 # test.plug_small_bouts()
 # test.save_classification_data()
 # test.create_video()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/frame_mergerer_ffmpeg.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/frame_mergerer_ffmpeg.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,24 +1,19 @@
 __author__ = "Simon Nilsson"
 
-from simba.read_config_unit_tests import (read_config_file,
-                                          read_config_entry)
 import os
 import subprocess, shutil
-from simba.misc_tools import (get_video_meta_data,
-                              remove_a_folder,
-                              get_fn_ext,
-                              SimbaTimer,
-                              )
-from simba.utils.printing import stdout_success
 from datetime import datetime
-from simba.enums import Paths, ReadConfig
+from simba.utils.read_write import get_fn_ext, remove_a_folder, get_video_meta_data, read_config_file, read_config_entry
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.enums import Paths
+from simba.mixins.config_reader import ConfigReader
 
 
-class FrameMergererFFmpeg(object):
+class FrameMergererFFmpeg(ConfigReader):
     """
     Class for merging separate visualizations of classifications, descriptive statistics etc., into  single
     video mosaic.
 
     Parameters
     ----------
     config_path: str
@@ -40,28 +35,26 @@
     def __init__(self,
                  config_path: str or None,
                  concat_type: str,
                  frame_types: dict,
                  video_height: int or None,
                  video_width: int or None):
 
-        self.timer = SimbaTimer()
-        self.timer.start_timer()
+        self.timer = SimbaTimer(start=True)
         self.datetime = datetime.now().strftime('%Y%m%d%H%M%S')
         if config_path is not None:
-            self.config_path, self.config = config_path, read_config_file(ini_path=config_path)
-            self.project_path = read_config_entry(self.config, ReadConfig.GENERAL_SETTINGS.value, ReadConfig.PROJECT_PATH.value, data_type=ReadConfig.FOLDER_PATH.value)
+            ConfigReader.__init__(self, config_path=config_path)
             self.output_dir = os.path.join(self.project_path, Paths.CONCAT_VIDEOS_DIR.value)
             self.temp_dir = os.path.join(self.project_path, Paths.CONCAT_VIDEOS_DIR.value, 'temp')
-            self.output_path = os.path.join(self.project_path, Paths.CONCAT_VIDEOS_DIR.value, 'merged_video_{}.mp4'.format(str(self.datetime)))
+            self.output_path = os.path.join(self.project_path, Paths.CONCAT_VIDEOS_DIR.value, f'merged_video_{self.datetime}.mp4')
         else:
             self.file_path = list(frame_types.values())[0]
             self.output_dir, ss, df = get_fn_ext(filepath=self.file_path)
             self.temp_dir = os.path.join(self.output_dir, 'temp')
-            self.output_path = os.path.join(self.output_dir, 'merged_video_{}.mp4'.format(str(self.datetime)))
+            self.output_path = os.path.join(self.output_dir, f'merged_video_{self.datetime}.mp4')
 
         self.video_height, self.video_width = video_height, video_width
         self.frame_types, self.concat_type = frame_types, concat_type
         self.video_cnt = len(self.frame_types.keys())
         self.even_bool = (len(self.frame_types.keys()) % 2) == 0
         self.blank_path = os.path.join(self.temp_dir, 'blank.mp4')
         if not os.path.exists(self.output_dir): os.makedirs(self.output_dir)
@@ -184,16 +177,35 @@
         self.frame_types = large_mosaic_dict
         self.__resize_height(new_height=get_video_meta_data(video_path=output_path)['height'])
         self.frame_types = {str(list(large_mosaic_dict.keys())[0]): os.path.join(self.temp_dir, str(list(large_mosaic_dict.keys())[0]) + '.mp4'), 'mosaic': os.path.join(self.temp_dir, 'mosaic.mp4')}
         self.__horizontal_concatenator(frames_dict=self.frame_types, out_path=self.output_path, include_resize=False, final_img=True)
 
 
 
-# FrameMergererFFmpeg(config_path='/Users/simon/Desktop/troubleshooting/train_model_project/project_folder/project_config.ini',
-#                     frame_types={'Video 1': '/Users/simon/Desktop/troubleshooting/train_model_project/project_folder/videos/Together_1.mp4', 'Video 2': '/Users/simon/Desktop/troubleshooting/train_model_project/project_folder/videos/Together_2.avi'},
+# FrameMergererFFmpeg(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini',
+#                     frame_types={'Video 1': '/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/videos/Together_1.avi',
+#                                  'Video 2': '/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/videos/Together_1.avi'},
 #                     video_height=640,
 #                     video_width=480,
 #                     concat_type='vertical') #horizontal, vertical, mosaic, mixed_mosaic
 #
 #
+# FrameMergererFFmpeg(config_path=None,
+#                     frame_types={'Video 1': '/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/videos/Together_1.avi',
+#                                  'Video 2': '/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/videos/Together_1.avi'},
+#                     video_height=640,
+#                     video_width=480,
+#                     concat_type='vertical') #horizontal, vertical, mosaic, mixed_mosaic
+#
+#
+
+
+# FrameMergererFFmpeg(config_path=None,
+#                     frame_types={'Video 1': '/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/videos/Together_1.avi',
+#                                  'Video 2': '/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/videos/Together_2.avi',
+#                                  'Video 3': '/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/videos/Together_3.avi',
+#                                  'Video 4': '/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/videos/Together_3.avi'},
+#                     video_height=640,
+#                     video_width=480,
+#                     concat_type='mixed_mosaic') #horizontal, vertical, mosaic, mixed_mosaic
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/clf_validator.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/clf_validator.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,26 +1,21 @@
 __author__ = "Simon Nilsson"
 
-from simba.read_config_unit_tests import (check_int,
-                                          check_that_column_exist,
-                                          check_if_filepath_list_is_empty)
-from simba.misc_tools import (find_video_of_file,
-                              get_file_path_parts,
-                              detect_bouts,
-                              get_video_meta_data,
-                              )
-from simba.utils.printing import stdout_success
-from simba.enums import Formats
-from simba.mixins.config_reader import ConfigReader
-from simba.utils.errors import NoSpecifiedOutputError
-from simba.utils.warnings import NoDataFoundWarning
-from simba.rw_dfs import read_df
 import numpy as np
+from copy import deepcopy
 import os
 import cv2
+from simba.enums import Formats
+from simba.mixins.config_reader import ConfigReader
+from simba.utils.errors import NoSpecifiedOutputError, NoFilesFoundError
+from simba.utils.warnings import NoDataFoundWarning
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.utils.checks import check_int, check_that_column_exist , check_if_filepath_list_is_empty
+from simba.utils.read_write import get_video_meta_data, get_fn_ext, read_df
+from simba.utils.data import detect_bouts
 
 class ClassifierValidationClips(ConfigReader):
     """
     Class for creating video clips of classified events. Helpful for faster detection of false positive event bouts.
 
     Parameters
     ----------
@@ -30,139 +25,158 @@
         Number of seconds before and after the event bout that should be included in the output video.
     clf_name: str
         Name of the classifier to create validation videos for.
     clips: bool
         If True, creates individual video file clips for each validation bout.
     text_clr: tuple
         Color of text overlay in BGR
+    highlight_clr: None or tuple,
+        Color of text when probability values are above threshold. If None, same as text_clr.
+    video_speed: float,
+        FPS rate in relation to original video. E.g., the same as original video if 1.0.
     concat_video: bool
         If True, creates a single video including all events bouts for each video.
 
     Notes
     ----------
     `GitHub tutorial/documentation <https://github.com/sgoldenlab/simba/blob/master/docs/classifier_validation.md#classifier-validation>`__.
 
     Examples
     ----------
     >>> clf_validator = ClassifierValidationClips(config_path='MyProjectConfigPath', window=5, clf_name='Attack', text_clr=(255,255,0), clips=False, concat_video=True)
-    >>> clf_validator.create_clips()
+    >>> clf_validator.run()
     """
 
     def __init__(self,
                  config_path: str,
                  window: int,
                  clf_name: str,
                  clips: bool,
                  text_clr: tuple,
-                 concat_video: bool):
+                 concat_video: bool,
+                 video_speed: float,
+                 data_paths: list,
+                 highlight_clr: None or tuple = None):
 
         super().__init__(config_path=config_path)
+        if (not clips) and (not concat_video):
+            raise NoSpecifiedOutputError(msg='Please select to create clips and/or a concatenated video')
 
         check_int(name='Time window', value=window)
         self.window, self.clf_name = int(window), clf_name
-        self.clips, self.concat_video = clips, concat_video
-        if (not self.clips) and (not self.concat_video):
-            raise NoSpecifiedOutputError(msg='SIMBA ERROR: Please select to create clips and/or a concatenated video')
-        self.p_col = 'Probability_' + self.clf_name
-        self.text_clr = text_clr
+        self.clips, self.concat_video, self.video_speed, self.highlight_clr = clips, concat_video, video_speed, highlight_clr
+        self.p_col = f'Probability_{self.clf_name}'
+        self.text_clr, self.data_paths = text_clr, data_paths
         self.fourcc = cv2.VideoWriter_fourcc(*Formats.MP4_CODEC.value)
         self.font = cv2.FONT_HERSHEY_SIMPLEX
         if not os.path.exists(self.clf_validation_dir): os.makedirs(self.clf_validation_dir)
-        check_if_filepath_list_is_empty(filepaths=self.machine_results_paths,
-                                        error_msg='SIMBA ERROR: No data found in the project_folder/csv/machine_results directory')
-        print(f'Processing {str(len(self.machine_results_paths))} files...')
+        check_if_filepath_list_is_empty(filepaths=self.data_paths,
+                                        error_msg='No data found in the project_folder/csv/machine_results directory')
+        print(f'Processing {str(len(self.data_paths))} files...')
 
     def __insert_inter_frms(self):
         """
         Helper to create N blank frames separating the classified event bouts.
         """
 
         for i in range(int(self.fps)):
             inter_frm = np.full((int(self.video_info['height']), int(self.video_info['width']), 3), (49, 32, 189)).astype(np.uint8)
             cv2.putText(inter_frm, 'Bout #{}'.format(str(self.bout_cnt + 1)), (10, (self.video_info['height'] - self.video_info['height']) + self.spacing_scale), self.font, self.font_size, (0, 0, 0), 2)
             self.concat_writer.write(inter_frm)
 
-    def create_clips(self):
+    def run(self):
         """
         Method to generate clips. Results are saved in the ``project_folder/frames/output/classifier_validation directory``
         directory of the SimBA project.
 
         Returns
         -------
         None
         """
-
-        for file_cnt, file_path in enumerate(self.machine_results_paths):
+        for file_cnt, file_path in enumerate(self.data_paths):
             self.data_df = read_df(file_path, self.file_type)
             check_that_column_exist(df=self.data_df, column_name=self.p_col, file_name=file_path)
-            _, file_name, _ = get_file_path_parts(file_path)
-            self.video_path = find_video_of_file(video_dir=self.video_dir,filename=file_name)
+            _, file_name, _ = get_fn_ext(file_path)
+            self.video_path = self.find_video_of_file(video_dir=self.video_dir, filename=file_name)
+            if not self.video_path:
+                raise NoFilesFoundError(msg=f'Could not find a video file representing {file_name} in the project_folder/videos directory')
             self.video_info = get_video_meta_data(video_path=self.video_path)
             self.fps = int(self.video_info['fps'])
+            self.video_fps = int(self.fps * self.video_speed)
+            if self.video_fps < 1: self.video_fps = 1
             self.space_scale, self.radius_scale, self.res_scale, self.font_scale = 60, 12, 1500, 1.5
             self.max_dim = max(self.video_info['width'], self.video_info['height'])
             self.circle_scale = int(self.radius_scale / (self.res_scale / self.max_dim))
             self.font_size = float(self.font_scale / (self.res_scale / self.max_dim))
             self.spacing_scale = int(self.space_scale / (self.res_scale / self.max_dim))
+            cap = cv2.VideoCapture(self.video_path)
             clf_bouts = detect_bouts(data_df=self.data_df, target_lst=[self.clf_name], fps=self.fps).reset_index(drop=True)
             if self.concat_video:
                 self.concat_video_save_path = os.path.join(self.clf_validation_dir, self.clf_name + '_' + file_name + '_all_events.mp4')
-                self.concat_writer = cv2.VideoWriter(self.concat_video_save_path, self.fourcc, self.fps, (int(self.video_info['width']), int(self.video_info['height'])))
+                self.concat_writer = cv2.VideoWriter(self.concat_video_save_path, self.fourcc, self.video_fps, (int(self.video_info['width']), int(self.video_info['height'])))
                 self.bout_cnt = 0
                 self.__insert_inter_frms()
             if len(clf_bouts) == 0:
                 NoDataFoundWarning(msg=f'Skipping video {file_name}: No classified behavior detected...')
                 continue
             for bout_cnt, bout in clf_bouts.iterrows():
+                clip_timer = SimbaTimer(start=True)
                 self.bout_cnt = bout_cnt
                 event_start_frm, event_end_frm = bout['Start_frame'], bout['End_frame']
                 start_window = int(event_start_frm - (int(self.video_info['fps']) * self.window))
                 end_window =  int(event_end_frm + (int(self.video_info['fps']) * self.window))
                 self.save_path = os.path.join(self.clf_validation_dir, self.clf_name + '_' + str(bout_cnt) + '_' + file_name + '.mp4')
-                if start_window < 0:
-                    start_window = 0
-                if end_window > len(self.data_df):
-                    end_window = len(self.data_df)
+                if start_window < 0: start_window = 0
+                current_frm = deepcopy(start_window)
+                if end_window > len(self.data_df): end_window = len(self.data_df)
                 if self.clips:
-                    bout_writer = cv2.VideoWriter(self.save_path, self.fourcc, self.fps, (int(self.video_info['width']), int(self.video_info['height'])))
-                cap = cv2.VideoCapture(self.video_path)
+                    bout_writer = cv2.VideoWriter(self.save_path, self.fourcc, self.video_fps, (int(self.video_info['width']), int(self.video_info['height'])))
                 event_frm_count = end_window - start_window
-                for frm_cnt, frame_no in enumerate(list(range(start_window, end_window))):
-                    p = self.data_df.loc[frame_no, self.p_col]
-                    self.add_spacer = 2
-                    cap.set(1, frame_no)
+                print(start_window, end_window, current_frm)
+                frm_cnt = 0
+                cap.set(1, current_frm)
+                while current_frm < end_window:
                     ret, img = cap.read()
+                    p, clf_val = round(float(self.data_df.loc[current_frm, self.p_col]), 3), int(self.data_df.loc[current_frm, self.clf_name])
+                    self.add_spacer = 2
                     cv2.putText(img, '{} event # {}'.format(self.clf_name, str(bout_cnt + 1)), (10, (self.video_info['height'] - self.video_info['height']) + self.spacing_scale * self.add_spacer), self.font, self.font_size, self.text_clr, 2)
                     self.add_spacer += 1
                     cv2.putText(img, 'Total frames of event: {}'.format(str(event_frm_count)), (10, (self.video_info['height'] - self.video_info['height']) + self.spacing_scale * self.add_spacer), self.font, self.font_size, self.text_clr, 2)
                     self.add_spacer += 1
                     cv2.putText(img, 'Frames of event {} to {}'.format(str(start_window), str(end_window)), (10, (self.video_info['height'] - self.video_info['height']) + self.spacing_scale * self.add_spacer), self.font, self.font_size, self.text_clr, 2)
                     self.add_spacer += 1
-                    cv2.putText(img, 'Frame number: {}'.format(str(frame_no)), (10, (self.video_info['height'] - self.video_info['height']) + self.spacing_scale * self.add_spacer), self.font, self.font_size, self.text_clr, 2)
+                    cv2.putText(img, 'Frame number: {}'.format(str(current_frm)), (10, (self.video_info['height'] - self.video_info['height']) + self.spacing_scale * self.add_spacer), self.font, self.font_size, self.text_clr, 2)
                     self.add_spacer += 1
-                    cv2.putText(img, 'Frame {} probability: {}'.format(self.clf_name, str(p)), (10, (self.video_info['height'] - self.video_info['height']) + self.spacing_scale * self.add_spacer), self.font, self.font_size, self.text_clr, 2)
-                    print(f'Frame {str(frm_cnt)} / {str(event_frm_count)}, Bout {str(bout_cnt+1)}/{str(len(clf_bouts))}, Video {str(file_cnt+1)}/{str(len(self.machine_results_paths))}...')
+                    if (self.highlight_clr != None) and (clf_val == 1):
+                        cv2.putText(img, f'Frame {self.clf_name} probability: {p}', (10, (self.video_info['height'] - self.video_info['height']) + self.spacing_scale * self.add_spacer), self.font, self.font_size, self.highlight_clr, 2)
+                    else:
+                        cv2.putText(img, f'Frame {self.clf_name} probability: {p}', (10, (self.video_info['height'] - self.video_info['height']) + self.spacing_scale * self.add_spacer), self.font, self.font_size, self.text_clr, 2)
+                    print(f'Frame {str(frm_cnt)} / {str(event_frm_count)}, Event {str(bout_cnt+1)}/{str(len(clf_bouts))}, Video {str(file_cnt+1)}/{str(len(self.machine_results_paths))}...')
                     if self.clips:
                         bout_writer.write(img)
                     if self.concat_video:
                         self.concat_writer.write(img)
+                    current_frm += 1
+                    frm_cnt += 1
                 if self.clips:
                     bout_writer.release()
-                if self.concat_video:
+                if self.concat_video and bout_cnt != len(clf_bouts)-1:
                     self.__insert_inter_frms()
             if self.concat_video:
                 self.concat_writer.release()
         self.timer.stop_timer()
         stdout_success(msg='All validation clips complete. Files are saved in the project_folder/frames/output/classifier_validation directory of the SimBA project', elapsed_time=self.timer.elapsed_time_str)
 
 # test = ClassifierValidationClips(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini',
-#                                  window=1,
+#                                  window=10,
 #                                  clf_name='Attack',
 #                                  clips=False,
 #                                  concat_video=True,
+#                                  highlight_clr=(255, 0, 0),
+#                                  video_speed=0.5,
 #                                  text_clr=(0, 0, 255))
 # test.create_clips()
 
 # test = ClassifierValidationClips(config_path='/Users/simon/Desktop/envs/troubleshooting/Two_animals_16bps/project_folder/project_config.ini',
 #                                  window=1,
 #                                  clf_name='Attack',
 #                                  clips=False,
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/path_plotter_mp.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/path_plotter_mp.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,35 +1,28 @@
 __author__ = "Simon Nilsson"
 
 import cv2
 import pandas as pd
-
-from simba.read_config_unit_tests import check_if_filepath_list_is_empty
 from copy import deepcopy
 from collections import deque
-from simba.misc_tools import (get_fn_ext,
-                              SimbaTimer,
-                              get_color_dict,
-                              remove_a_folder,
-                              concatenate_videos_in_folder,
-                              find_animal_name_from_body_part_name,
-                              )
-from simba.utils.printing import stdout_success
-from simba.enums import Formats
 from numba import jit, prange
-from simba.plotting.misc_visualizations import make_path_plot
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.rw_dfs import read_df
-from simba.mixins.config_reader import ConfigReader
-from simba.utils.errors import NoSpecifiedOutputError
 import numpy as np
 import os
 import functools
 import multiprocessing
 import platform
+from simba.mixins.config_reader import ConfigReader
+from simba.mixins.plotting_mixin import PlottingMixin
+from simba.utils.errors import NoSpecifiedOutputError
+from simba.utils.lookups import get_color_dict
+from simba.utils.read_write import get_fn_ext, remove_a_folder, concatenate_videos_in_folder, read_df
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.enums import Formats
+from simba.utils.checks import check_if_filepath_list_is_empty
+
 
 def _image_creator(data: np.array,
                    video_setting: bool,
                    frame_setting: bool,
                    video_save_dir: str,
                    video_name: str,
                    frame_folder_dir: str,
@@ -77,15 +70,15 @@
             frm_name = os.path.join(frame_folder_dir, str(frame_id) + '.png')
             cv2.imwrite(frm_name, np.uint8(img))
 
         print('Path frame created: {}, Video: {}, Processing core: {}'.format(str(frame_id + 1), video_name, str(group + 1)))
 
     return group
 
-class PathPlotterMulticore(ConfigReader):
+class PathPlotterMulticore(ConfigReader, PlottingMixin):
     """
     Class for creating "path plots" videos and/or images detailing the movement paths of
     individual animals in SimBA.
 
     Parameters
     ----------
     config_path: str
@@ -123,18 +116,19 @@
                  last_frame: bool,
                  files_found: list,
                  input_style_attr: dict or None,
                  animal_attr: dict,
                  input_clf_attr: dict or None,
                  cores: int):
 
-        if platform.system() == "Darwin":
-            multiprocessing.set_start_method('spawn', force=True)
+        # if platform.system() == "Darwin":
+        #     multiprocessing.set_start_method('spawn', force=True)
 
-        super().__init__(config_path=config_path)
+        ConfigReader.__init__(self, config_path=config_path)
+        PlottingMixin.__init__(self)
         self.video_setting, self.frame_setting, self.input_style_attr, self.files_found, self.animal_attr, self.input_clf_attr, self.last_frame, self.cores = video_setting, frame_setting, input_style_attr, files_found, animal_attr, input_clf_attr, last_frame, cores
         if (not frame_setting) and (not video_setting) and (not last_frame):
             raise NoSpecifiedOutputError(msg='SIMBA ERROR: Please choice to create path frames and/or video path plots')
         self.no_animals_path_plot = len(animal_attr.keys())
         if not os.path.exists(self.path_plot_dir): os.makedirs(self.path_plot_dir)
         check_if_filepath_list_is_empty(filepaths=self.files_found, error_msg='SIMBA ERROR: Zero files found in the project_folder/csv/machine_results directory. To plot paths without performing machine classifications, use path plotter functions in [ROI] tab.')
         print(f'Processing {str(len(self.files_found))} videos...')
@@ -145,15 +139,15 @@
         'project_folder/frames/path_plots' directory of the SimBA project.
         """
 
         for file_cnt, file_path in enumerate(self.files_found):
             video_timer = SimbaTimer()
             video_timer.start_timer()
             _, self.video_name, _ = get_fn_ext(file_path)
-            self.video_info, _, self.fps = read_video_info(self.video_info_df, self.video_name)
+            self.video_info, _, self.fps = self.read_video_info(video_name=self.video_name)
             self.__get_styles()
             self.data_df = read_df(file_path, self.file_type)
             self.temp_folder = os.path.join(self.path_plot_dir, self.video_name, 'temp')
             self.save_frame_folder_dir = os.path.join(self.path_plot_dir, self.video_name)
             if self.frame_setting:
                 if os.path.exists(self.save_frame_folder_dir): remove_a_folder(self.save_frame_folder_dir)
                 if not os.path.exists(self.save_frame_folder_dir): os.makedirs(self.save_frame_folder_dir)
@@ -163,32 +157,29 @@
                     remove_a_folder(self.temp_folder)
                     remove_a_folder(self.video_folder)
                 os.makedirs(self.temp_folder)
                 self.save_video_path = os.path.join(self.path_plot_dir, self.video_name + '.mp4')
 
             if self.input_clf_attr:
                 clf_names = []
-                self.clf_attr = {}
+                self.clf_attr = deepcopy(self.input_clf_attr)
                 for v in self.clf_attr.values():
                     clf_names.append(v[0])
+                self.clf_attr['data'] = self.data_df[clf_names]
 
             if self.last_frame:
                 self.__get_deque_lookups()
-                _ = make_path_plot(data_df=self.data_df,
-                                   video_info=self.video_info,
-                                   style_attr=self.style_attr,
-                                   deque_dict=self.deque_dict,
-                                   clf_attr=self.clf_attr,
-                                   save_path=os.path.join(self.path_plot_dir, self.video_name + '_final_frame.png'))
+                _ = self.make_path_plot(data_df=self.data_df,
+                                        video_info=self.video_info,
+                                        style_attr=self.style_attr,
+                                        deque_dict=self.deque_dict,
+                                        clf_attr=self.clf_attr,
+                                        save_path=os.path.join(self.path_plot_dir, self.video_name + '_final_frame.png'))
 
             if self.video_setting or self.frame_setting:
-
-                if self.clf_attr:
-                    self.clf_attr['data'] = self.data_df[clf_names]
-
                 data_arr = np.array(list(self.data_df.index)).reshape(-1, 1)
                 for animal_cnt, animal_data in self.animal_attr.items():
                     bp_x_name = '{}_{}'.format(animal_data[0], 'x')
                     bp_y_name = '{}_{}'.format(animal_data[0], 'y')
                     data_arr = np.hstack((data_arr, self.data_df[[bp_x_name, bp_y_name]].astype(int).values))
                     if animal_cnt == 0 and self.clf_attr:
                         self.clf_attr['positions'] = deepcopy(data_arr[:, 1:3])
@@ -283,51 +274,39 @@
             self.style_attr['max lines'] = int(self.video_info['fps'].values[0] * 2)
             self.style_attr['font thickness'] = 2
             self.style_attr['line width'] = 2
 
         self.style_attr['animal names'] = []
         self.style_attr['animal clrs'] = []
         for animal_cnt, animal_data in self.animal_attr.items():
-            self.style_attr['animal names'].append(find_animal_name_from_body_part_name(bp_name=animal_data[0], bp_dict=self.animal_bp_dict))
+            self.style_attr['animal names'].append(self.find_animal_name_from_body_part_name(bp_name=animal_data[0], bp_dict=self.animal_bp_dict))
 
         for animal_cnt, animal_data in self.animal_attr.items():
             self.style_attr['animal clrs'].append(self.color_dict[self.animal_attr[animal_cnt][1]])
 
     def __get_deque_lookups(self):
         self.deque_dict = {}
         for animal_cnt, animal in enumerate(self.style_attr['animal names']):
             self.deque_dict[animal] = {}
             self.deque_dict[animal]['deque'] = deque(maxlen=self.style_attr['max lines'])
             self.deque_dict[animal]['bp'] = self.animal_attr[animal_cnt][0]
             self.deque_dict[animal]['clr'] = self.color_dict[self.animal_attr[animal_cnt][1]]
 
 
-# style_attr = {'width': 'As input', 'height': 'As input', 'line width': 5, 'font size': 5, 'font thickness': 2, 'circle size': 5, 'bg color': 'White', 'max lines': 1000}
-# animal_attr = {0: ['Ear_right_1', 'Red'], 1: ['Ear_right_2', 'Lime']}
-# clf_attr = {0: ['Attack', 'Black', 'Size: 30'], 1: ['Sniffing', 'Red', 'Size: 30']}
-
-# clf_attr = None
-# style_attr = None
-
+# style_attr = {'width': 'As input', 'height': 'As input', 'line width': 5, 'font size': 5, 'font thickness': 2, 'circle size': 5, 'bg color': 'White', 'max lines': 10000}
+# animal_attr = {0: ['Ear_right_1', 'Red'], 1: ['Ear_right_2', 'Green']}
+# clf_attr = {0: ['Attack', 'Black', 'Size: 30']}
+# #
+# # clf_attr = None
+# # style_attr = None
+#
 # path_plotter = PathPlotterMulticore(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini',
 #                                     frame_setting=False,
 #                                     video_setting=True,
 #                                     last_frame=False,
 #                                     input_clf_attr=clf_attr,
 #                                     input_style_attr=style_attr,
 #                                     animal_attr=animal_attr,
-#                                     files_found=['/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/csv/targets_inserted/Together_1.csv',
-#                                                  '/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/csv/targets_inserted/Together_2.csv'],
+#                                     files_found=['/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/csv/machine_results/Together_1.csv'],
 #                                     cores=5)
 # path_plotter.create_path_plots()
 
-# path_plotter = PathPlotterMulticore(config_path='/Users/simon/Desktop/envs/simba_dev/tests/test_data/two_C57_madlc/project_folder/project_config.ini',
-#                                     frame_setting=False,
-#                                     video_setting=True,
-#                                     last_frame=True,
-#                                     clf_attr=clf_attr,
-#                                     style_attr=style_attr,
-#                                     animal_attr=animal_attr,
-#                                     files_found=['/Users/simon/Desktop/envs/simba_dev/tests/test_data/two_C57_madlc/project_folder/csv/outlier_corrected_movement_location/Together_1.csv'],
-#                                     cores=5)
-#
-# path_plotter.create_path_plots()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/data_plotter.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/data_plotter.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,26 +1,21 @@
 __author__ = "Simon Nilsson"
 
 import pandas as pd
 from joblib import Parallel, delayed
 import os
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.movement_processor import MovementProcessor
-from simba.misc_tools import (check_multi_animal_status,
-                              get_fn_ext,
-                              SimbaTimer,
-                              get_color_dict,
-                              )
-from simba.utils.printing import stdout_success
 import numpy as np
 import cv2
 from simba.enums import Formats
+from simba.movement_processor import MovementProcessor
 from simba.mixins.config_reader import ConfigReader
 from simba.utils.errors import NoSpecifiedOutputError
-
+from simba.utils.lookups import get_color_dict
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.utils.read_write import get_fn_ext
 
 class DataPlotter(ConfigReader):
     """
     Class for tabular data visualizations of animal movement and distances in the current frame and their aggregate
     statistics.
 
     Parameters
@@ -45,21 +40,20 @@
                  body_part_attr: list,
                  data_paths: list,
                  video_setting: bool,
                  frame_setting: bool,
                  ):
 
         super().__init__(config_path=config_path)
-        self.video_setting, self.frame_setting = video_setting, frame_setting
-        if (not self.video_setting) and (not self.frame_setting):
+        if (not video_setting) and (not frame_setting):
             raise NoSpecifiedOutputError(msg='SIMBA ERROR: Please choose to create video and/or frames data plots. SimBA found that you ticked neither video and/or frames')
+        self.video_setting, self.frame_setting = video_setting, frame_setting
         self.files_found, self.style_attr, self.body_part_attr = data_paths, style_attr, body_part_attr
         if not os.path.exists(self.data_table_path):
             os.makedirs(self.data_table_path)
-        self.multi_animal_status, self.multi_animal_id_list = check_multi_animal_status(self.config, len(self.body_part_attr))
         self.__compute_spacings()
         self.process_movement()
         print('Processing {} video(s)...'.format(str(len(self.files_found))))
 
     def __compute_spacings(self):
         """
         Private helper to compute appropriate spacing between printed text.
@@ -129,15 +123,15 @@
             return img
 
         for file_cnt, file_path in enumerate(self.files_found):
             video_timer = SimbaTimer()
             video_timer.start_timer()
             _, video_name, _ = get_fn_ext(file_path)
             video_data = pd.DataFrame(self.movement[video_name])
-            _, _, self.fps = read_video_info(vid_info_df=self.video_info_df, video_name=video_name)
+            _, _, self.fps = self.read_video_info(video_name=video_name)
             if self.video_setting:
                 self.fourcc = cv2.VideoWriter_fourcc(*Formats.MP4_CODEC.value)
                 self.video_save_path = os.path.join(self.data_table_path, video_name + '.mp4')
                 self.writer = cv2.VideoWriter(self.video_save_path, self.fourcc, self.fps, self.style_attr['size'])
             if self.frame_setting:
                 self.frame_save_path = os.path.join(self.data_table_path, video_name)
                 if not os.path.exists(self.frame_save_path): os.makedirs(self.frame_save_path)
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/path_plotter.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/path_plotter.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,31 +1,23 @@
 __author__ = "Simon Nilsson"
 
 import cv2
-
-from simba.read_config_unit_tests import check_if_filepath_list_is_empty
 from collections import deque
-from simba.misc_tools import (get_fn_ext,
-                              SimbaTimer,
-                              get_color_dict,
-                              )
-from simba.utils.printing import stdout_success
+from copy import deepcopy
+import numpy as np
+import os
 from simba.enums import Formats
 from simba.mixins.config_reader import ConfigReader
-from simba.plotting.misc_visualizations import make_path_plot
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.misc_tools import find_animal_name_from_body_part_name
+from simba.mixins.plotting_mixin import PlottingMixin
+from simba.utils.read_write import get_fn_ext, read_df
 from simba.utils.errors import NoSpecifiedOutputError
-from simba.rw_dfs import read_df
-import numpy as np
-import os
-
-
+from simba.utils.checks import check_if_filepath_list_is_empty
+from simba.utils.printing import stdout_success, SimbaTimer
 
-class PathPlotterSingleCore(ConfigReader):
+class PathPlotterSingleCore(ConfigReader, PlottingMixin):
     """
     Class for creating "path plots" videos and/or images detailing the movement paths of
     individual animals in SimBA.
 
     Parameters
     ----------
     config_path: str
@@ -60,37 +52,38 @@
                  video_setting: bool,
                  last_frame: bool,
                  files_found: list,
                  input_style_attr: dict,
                  animal_attr: dict,
                  input_clf_attr: dict):
 
-        super().__init__(config_path=config_path)
+        ConfigReader.__init__(self, config_path=config_path)
+        PlottingMixin.__init__(self)
         self.video_setting, self.frame_setting, self.input_style_attr, self.files_found, self.animal_attr, self.input_clf_attr, self.last_frame = video_setting, frame_setting, input_style_attr, files_found, animal_attr, input_clf_attr, last_frame
         if (not frame_setting) and (not video_setting) and (not last_frame):
             raise NoSpecifiedOutputError(msg='SIMBA ERROR: Please choice to create path frames and/or video path plots')
 
         self.no_animals_path_plot = len(animal_attr.keys())
-        if not os.path.exists(self.path_plot_dir): os.makedirs(self.path_plot_dir)
-        self.font = Formats.FONT.value
+        if not os.path.exists(self.path_plot_dir):
+            os.makedirs(self.path_plot_dir)
         check_if_filepath_list_is_empty(filepaths=self.files_found,
-                                        error_msg='SIMBA ERROR: Zero files found in the project_folder/csv/machine_results directory. To plot paths without performing machine classifications, use path plotter functions in [ROI] tab.')
+                                        error_msg='Zero files found in the project_folder/csv/machine_results directory. To plot paths without performing machine classifications, use path plotter functions in [ROI] tab.')
         print(f'Processing {str(len(self.files_found))} videos...')
 
     def create_path_plots(self):
         """
         Method to create path plot videos and/or frames.Results are store in the
         'project_folder/frames/path_plots' directory of the SimBA project.
         """
 
         for file_cnt, file_path in enumerate(self.files_found):
             video_timer = SimbaTimer()
             video_timer.start_timer()
             _, self.video_name, _ = get_fn_ext(file_path)
-            self.video_info, _, self.fps = read_video_info(self.video_info_df, self.video_name)
+            self.video_info, _, self.fps = self.read_video_info(video_name=self.video_name)
             self.__get_styles()
             self.__get_deque_lookups()
             self.data_df = read_df(file_path, self.file_type)
             if self.video_setting:
                 self.video_save_path = os.path.join(self.path_plot_dir, self.video_name + '.mp4')
                 self.fourcc = cv2.VideoWriter_fourcc(*Formats.MP4_CODEC.value)
                 self.writer = cv2.VideoWriter(self.video_save_path, self.fourcc, self.fps, (self.style_attr['width'], self.style_attr['height']))
@@ -98,38 +91,38 @@
             if self.frame_setting:
                 self.save_video_folder = os.path.join(self.path_plot_dir, self.video_name)
                 if not os.path.exists(self.save_video_folder):
                     os.makedirs(self.save_video_folder)
 
             if self.input_clf_attr:
                 clf_names = []
-                self.clf_attr = {}
+                self.clf_attr = deepcopy(self.input_clf_attr)
                 for v in self.clf_attr.values():
                     clf_names.append(v[0])
                 clf_df = self.data_df[clf_names]
 
             if self.last_frame:
-                _ = make_path_plot(data_df=self.data_df,
-                                   video_info=self.video_info,
-                                   style_attr=self.style_attr,
-                                   deque_dict=self.deque_dict,
-                                   clf_attr=self.clf_attr,
-                                   save_path=os.path.join(self.path_plot_dir, self.video_name + '_final_frame.png'))
+                _ = self.make_path_plot(data_df=self.data_df,
+                                        video_info=self.video_info,
+                                        style_attr=self.style_attr,
+                                        deque_dict=self.deque_dict,
+                                        clf_attr=self.clf_attr,
+                                        save_path=os.path.join(self.path_plot_dir, self.video_name + '_final_frame.png'))
 
             if self.video_setting or self.frame_setting:
                 for frm_cnt in range(len(self.data_df)):
                     img = np.zeros((int(self.video_info['Resolution_height'].values[0]), int(self.video_info['Resolution_width'].values[0]), 3))
                     img[:] = self.style_attr['bg color']
                     for animal_cnt, (animal_name, animal_data) in enumerate(self.deque_dict.items()):
                         bp_x = int(self.data_df.loc[frm_cnt, '{}_{}'.format(animal_data['bp'], 'x')])
                         bp_y = int(self.data_df.loc[frm_cnt, '{}_{}'.format(animal_data['bp'], 'y')])
                         self.deque_dict[animal_name]['deque'].appendleft((bp_x, bp_y))
                     for animal_name, animal_data in self.deque_dict.items():
                         cv2.circle(img, (self.deque_dict[animal_name]['deque'][0]), 0, self.deque_dict[animal_name]['clr'], self.style_attr['circle size'])
-                        cv2.putText(img, animal_name, (self.deque_dict[animal_name]['deque'][0]), self.font, self.style_attr['font size'], self.deque_dict[animal_name]['clr'], self.style_attr['font thickness'])
+                        cv2.putText(img, animal_name, (self.deque_dict[animal_name]['deque'][0]), Formats.FONT.value, self.style_attr['font size'], self.deque_dict[animal_name]['clr'], self.style_attr['font thickness'])
 
                     for animal_name, animal_data in self.deque_dict.items():
                         for i in range(len(self.deque_dict[animal_name]['deque'])-1):
                             line_clr = self.deque_dict[animal_name]['clr']
                             position_1 = self.deque_dict[animal_name]['deque'][i]
                             position_2 = self.deque_dict[animal_name]['deque'][i+1]
                             cv2.line(img, position_1, position_2, line_clr, self.style_attr['line width'])
@@ -186,42 +179,42 @@
             self.style_attr['max lines'] = int(self.video_info['fps'].values[0] * 2)
             self.style_attr['font thickness'] = 2
             self.style_attr['line width'] = 2
 
     def __get_deque_lookups(self):
         self.deque_dict = {}
         for animal_cnt, animal_data in self.animal_attr.items():
-            animal_name = find_animal_name_from_body_part_name(bp_name=animal_data[0], bp_dict=self.animal_bp_dict)
+            animal_name = self.find_animal_name_from_body_part_name(bp_name=animal_data[0], bp_dict=self.animal_bp_dict)
             self.deque_dict[animal_name] = {}
             self.deque_dict[animal_name]['deque'] = deque(maxlen=self.style_attr['max lines'])
             self.deque_dict[animal_name]['bp'] = self.animal_attr[animal_cnt][0]
             self.deque_dict[animal_name]['clr'] = self.color_dict[self.animal_attr[animal_cnt][1]]
 
-
+#
 # style_attr = {'width': 'As input',
 #               'height': 'As input',
 #               'line width': 5,
 #               'font size': 5,
 #               'font thickness': 2,
 #               'circle size': 5,
 #               'bg color': 'White',
-#               'max lines': 2000}
+#               'max lines': 10000}
 #
-# animal_attr = {0: ['Ear_right_1', 'Red']}
-# clf_attr = {0: ['Attack', 'Black', 'Size: 30'], 1: ['Sniffing', 'Red', 'Size: 30']}
+# animal_attr = {0: ['Ear_right_1', 'Red'], 1: ['Ear_right_2', 'Green']}
+# clf_attr = {0: ['Attack', 'Black', 'Size: 30']}
 #
-#
-# test = PathPlotterSingleCore(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals/project_folder/project_config.ini',
-#                    frame_setting=False,
-#                    video_setting=False,
+# test = PathPlotterSingleCore(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini',
+#                             frame_setting=False,
+#                             video_setting=True,
 #                              last_frame=True,
-#                    style_attr=style_attr,
+#                             input_style_attr=style_attr,
 #                    animal_attr=animal_attr,
-#                              clf_attr=clf_attr,
-#                     files_found=['/Users/simon/Desktop/envs/troubleshooting/two_black_animals/project_folder/csv/machine_results/Together_1.csv'])
+#                              input_clf_attr=clf_attr,
+#                     files_found=['/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/csv/machine_results/Together_1.csv',
+#                                  '/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/csv/machine_results/Together_1.csv'])
 # test.create_path_plots()
 
 # test = PathPlotterSingleCore(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini',
 #                    frame_setting=False,
 #                    video_setting=False,
 #                              last_frame=True,
 #                    style_attr=style_attr,
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/ez_lineplot.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/ez_lineplot.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,36 +1,31 @@
 __author__ = "Simon Nilsson", "JJ Choong"
 
 import os
 import cv2
 import numpy as np
-from simba.drop_bp_cords import get_fn_ext
 import pandas as pd
-from simba.misc_tools import (get_video_meta_data,
-                              get_color_dict,
-                              SimbaTimer,
-                              )
-from simba.utils.printing import stdout_success
+from simba.utils.printing import stdout_success, SimbaTimer
 from simba.utils.errors import DuplicationError, InvalidFileTypeError, DataHeaderError
-from simba.read_config_unit_tests import read_config_file
-from simba.rw_dfs import read_df
+from simba.utils.lookups import get_color_dict
+from simba.utils.read_write import read_config_file, get_video_meta_data, get_fn_ext, read_df
+
 from copy import deepcopy
 
 class DrawPathPlot(object):
     def __init__(self,
                  data_path: str,
                  video_path: str,
                  body_part: str,
                  bg_color: str,
                  line_color: str,
                  line_thinkness: int,
                  circle_size: int):
 
-        self.timer = SimbaTimer()
-        self.timer.start_timer()
+        self.timer = SimbaTimer(start=True)
         self.named_shape_colors = get_color_dict()
         self.line_clr_bgr = self.named_shape_colors[line_color]
         self.bg_clr_bgr = self.named_shape_colors[bg_color]
         self.line_thinkness, self.circle_size = int(line_thinkness), int(circle_size)
         if self.line_clr_bgr == self.bg_clr_bgr:
             raise DuplicationError(msg='The line color and background color are identical')
         directory, file_name, ext = get_fn_ext(filepath=data_path)
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/distance_plotter_mp.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/distance_plotter_mp.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,88 +1,22 @@
 __author__ = "Simon Nilsson", "JJ Choong"
-
-from simba.read_config_unit_tests import check_if_filepath_list_is_empty
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.misc_tools import (get_fn_ext,
-                              SimbaTimer,
-                              get_color_dict,
-                              remove_a_folder,
-                              concatenate_videos_in_folder,
-                              )
-from simba.utils.printing import stdout_success
-from simba.plotting.misc_visualizations import make_distance_plot
-from simba.enums import Formats
-from simba.mixins.config_reader import ConfigReader
-from simba.rw_dfs import read_df
 import numpy as np
-import matplotlib.pyplot as plt
-import PIL
-import io
 import multiprocessing
 import functools
 from numba import jit
-import cv2
 import os
 import platform
 from simba.utils.errors import NoSpecifiedOutputError
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.mixins.config_reader import ConfigReader
+from simba.mixins.plotting_mixin import PlottingMixin
+from simba.utils.checks import check_if_filepath_list_is_empty
+from simba.utils.read_write import read_df, get_fn_ext, concatenate_videos_in_folder
 
-
-def _image_creator(data: np.array,
-                   video_setting: bool,
-                   frame_setting: bool,
-                   video_name: str,
-                   video_save_dir: str,
-                   frame_folder_dir: str,
-                   style_attr: dict,
-                   line_attr: dict,
-                   fps: int):
-    group = int(data[0][0])
-    line_data = data[:, 2:]
-    color_dict = get_color_dict()
-    if video_setting:
-        fourcc = cv2.VideoWriter_fourcc(*Formats.MP4_CODEC.value)
-        video_save_path = os.path.join(video_save_dir, '{}.mp4'.format(str(group)))
-        video_writer = cv2.VideoWriter(video_save_path, fourcc, fps, (style_attr['width'], style_attr['height']))
-
-    for i in range(line_data.shape[0]):
-        frame_id = int(data[i][1])
-        for j in range(line_data.shape[1]):
-            color = (color_dict[line_attr[j][-1]][::-1])
-            color = tuple(x / 255 for x in color)
-            plt.plot(line_data[0:i, j], color=color, linewidth=style_attr['line width'], alpha=style_attr['opacity'])
-
-        x_ticks_locs = x_lbls = np.round(np.linspace(0, i, 5))
-        x_lbls = np.round((x_lbls / fps), 1)
-        plt.ylim(0, style_attr['max_y'])
-        plt.xlabel('time (s)')
-        plt.ylabel('distance (cm)')
-        plt.xticks(x_ticks_locs, x_lbls, rotation='horizontal', fontsize=style_attr['font size'])
-        plt.yticks(style_attr['y_ticks_locs'], style_attr['y_ticks_lbls'], fontsize=style_attr['font size'])
-        plt.suptitle('Animal distances', x=0.5, y=0.92, fontsize=style_attr['font size'] + 4)
-
-        buffer_ = io.BytesIO()
-        plt.savefig(buffer_, format="png")
-        buffer_.seek(0)
-        img = PIL.Image.open(buffer_)
-        img = np.uint8(cv2.cvtColor(np.asarray(img), cv2.COLOR_RGB2BGR))
-        buffer_.close()
-        plt.close()
-
-        img = cv2.resize(img, (style_attr['width'], style_attr['height']))
-        if video_setting:
-            video_writer.write(np.uint8(img))
-        if frame_setting:
-            frm_name = os.path.join(frame_folder_dir, str(frame_id) + '.png')
-            cv2.imwrite(frm_name, np.uint8(img))
-
-        print('Distance frame created: {}, Video: {}, Processing core: {}'.format(str(frame_id + 1), video_name, str(group + 1)))
-
-    return group
-
-class DistancePlotterMultiCore(ConfigReader):
+class DistancePlotterMultiCore(ConfigReader, PlottingMixin):
     """
      Class for visualizing the distances between pose-estimated body-parts (e.g., two animals) through line
      charts. Results are saved as individual line charts, and/or a video of line charts.
 
      Parameters
      ----------
      config_path: str
@@ -118,70 +52,78 @@
                  video_setting: bool,
                  final_img: bool,
                  files_found: list,
                  style_attr: dict,
                  line_attr: dict,
                  core_cnt: int):
 
-        super().__init__(config_path=config_path)
+        ConfigReader.__init__(self, config_path=config_path)
+        PlottingMixin.__init__(self)
 
         if platform.system() == "Darwin":
             multiprocessing.set_start_method('spawn', force=True)
 
         self.video_setting, self.frame_setting, self.files_found, self.style_attr, self.line_attr, self.final_img = video_setting, frame_setting, files_found, style_attr, line_attr, final_img
         if (not frame_setting) and (not video_setting) and (not self.final_img):
             raise NoSpecifiedOutputError(msg='Please choice to create frames and/or video distance plots')
         self.core_cnt = core_cnt
         if not os.path.exists(self.line_plot_dir): os.makedirs(self.line_plot_dir)
         check_if_filepath_list_is_empty(filepaths=self.outlier_corrected_dir,
                                         error_msg='SIMBA ERROR: Zero files found in the project_folder/csv/machine_results directory. Create classification results before visualizing distances.')
         print(f'Processing {str(len(self.files_found))} videos...')
 
+    @staticmethod
+    @jit(nopython=True)
+    def __insert_group_idx_column(data: np.array,
+                                  group: int):
+        group_col = np.full((data.shape[0], 1), group)
+        return np.hstack((group_col, data))
+
+
     def create_distance_plot(self):
         '''
         Creates line charts. Results are stored in the `project_folder/frames/line_plot` directory
 
         Returns
         ----------
         None
         '''
 
         for file_cnt, file_path in enumerate(self.files_found):
 
-            video_timer = SimbaTimer()
-            video_timer.start_timer()
-
+            video_timer = SimbaTimer(start=True)
             self.data_df = read_df(file_path, self.file_type)
             distance_arr = np.full((len(self.data_df), len(self.line_attr.keys())), np.nan)
             _, self.video_name, _ = get_fn_ext(file_path)
-            self.video_info, self.px_per_mm, self.fps = read_video_info(self.video_info_df, self.video_name)
+            self.video_info, self.px_per_mm, self.fps = self.read_video_info(video_name=self.video_name)
             self.save_video_folder = os.path.join(self.line_plot_dir, self.video_name)
             self.temp_folder = os.path.join(self.line_plot_dir, self.video_name, 'temp')
             self.save_frame_folder_dir = os.path.join(self.line_plot_dir, self.video_name)
             for distance_cnt, data in enumerate(self.line_attr.values()):
                 distance_arr[:, distance_cnt] = (np.sqrt((self.data_df[data[0] + '_x'] - self.data_df[data[1] + '_x']) ** 2 + (self.data_df[data[0] + '_y'] - self.data_df[data[1] + '_y']) ** 2) / self.px_per_mm) / 10
             if self.frame_setting:
-                if os.path.exists(self.save_frame_folder_dir): remove_a_folder(self.save_frame_folder_dir)
+                if os.path.exists(self.save_frame_folder_dir):
+                    self.remove_a_folder(self.save_frame_folder_dir)
                 if not os.path.exists(self.save_frame_folder_dir): os.makedirs(self.save_frame_folder_dir)
             if self.video_setting:
                 self.video_folder = os.path.join(self.line_plot_dir, self.video_name)
                 if os.path.exists(self.temp_folder):
-                    remove_a_folder(self.temp_folder)
-                    remove_a_folder(self.video_folder)
+                    self.remove_a_folder(self.temp_folder)
+                    self.remove_a_folder(self.video_folder)
                 os.makedirs(self.temp_folder)
                 self.save_video_path = os.path.join(self.line_plot_dir, self.video_name + '.mp4')
 
             distance_arr = np.nan_to_num(distance_arr, nan=0.0)
 
             if self.final_img:
-                make_distance_plot(data=distance_arr,
-                                   line_attr=self.line_attr,
-                                   style_attr=self.style_attr,
-                                   fps=self.fps,
-                                   save_path=os.path.join(self.line_plot_dir, self.video_name + '_final_img.png'))
+                self.make_distance_plot(data=distance_arr,
+                                        line_attr=self.line_attr,
+                                        style_attr=self.style_attr,
+                                        fps=self.fps,
+                                        save_path=os.path.join(self.line_plot_dir, self.video_name + '_final_img.png'))
 
             if self.video_setting or self.frame_setting:
                 if self.style_attr['y_max'] == 'auto':
                     self.style_attr['max_y'] = np.amax(distance_arr)
                 else:
                     self.style_attr['max_y'] = float(self.style_attr['max_y'])
                 self.style_attr['y_ticks_locs'] = np.round(np.linspace(0, self.style_attr['max_y'], 10), 2)
@@ -194,15 +136,15 @@
                 data = []
                 for cnt, i in enumerate(distance_arr):
                     data.append(self.__insert_group_idx_column(data=i, group=cnt))
                 frm_per_core = data[0].shape[0]
 
                 print('Creating distance plots, multiprocessing (chunksize: {}, cores: {})...'.format(str(self.multiprocess_chunksize), str(self.core_cnt)))
                 with multiprocessing.Pool(self.core_cnt, maxtasksperchild=self.maxtasksperchild) as pool:
-                    constants = functools.partial(_image_creator,
+                    constants = functools.partial(self.distance_plotter_mp,
                                                   video_setting=self.video_setting,
                                                   video_name=self.video_name,
                                                   frame_setting=self.frame_setting,
                                                   video_save_dir=self.temp_folder,
                                                   frame_folder_dir=self.save_frame_folder_dir,
                                                   style_attr=self.style_attr,
                                                   line_attr=self.line_attr,
@@ -217,22 +159,38 @@
                     print('Joining {} multiprocessed video...'.format(self.video_name))
                     concatenate_videos_in_folder(in_folder=self.temp_folder, save_path=self.save_video_path)
 
                 video_timer.stop_timer()
                 print('Distance line chart video {} complete (elapsed time: {}s) ...'.format(self.video_name,video_timer.elapsed_time_str))
 
         self.timer.stop_timer()
-        stdout_success(f'Distance plot visualizations for {str(len(self.files_found))} videos created in project_folder/frames/output/line_plot directory', elapsed_time=self.timer.elapsed_time_str)
+        stdout_success(f'Distance plot visualizations for {str(len(self.files_found))} video(s) created in project_folder/frames/output/line_plot directory', elapsed_time=self.timer.elapsed_time_str)
+
+
+# style_attr = {'width': 640, 'height': 480, 'line width': 6, 'font size': 8, 'y_max': 'auto', 'opacity': 0.9}
+# line_attr = {0: ['Center_1', 'Center_2', 'Green'], 1: ['Ear_left_2', 'Ear_left_1', 'Red']}
+#
+# test = DistancePlotterMultiCore(config_path=r'/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini',
+#                                 frame_setting=False,
+#                                 video_setting=True,
+#                                 style_attr=style_attr,
+#                                 final_img=True,
+#                                 files_found=['/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/csv/machine_results/Together_1.csv'],
+#                                 line_attr=line_attr,
+#                                 core_cnt=3)
+# test.create_distance_plot()
+# #
+# style_attr = {'width': 640, 'height': 480, 'line width': 6, 'font size': 8}
+# line_attr = {0: ['Termite_1_Head_1', 'Termite_1_Thorax_1', 'Dark-red']}
+#
+
+
+
+
 
-    @staticmethod
-    @jit(nopython=True)
-    def __insert_group_idx_column(data: np.array,
-                                  group: int):
-        group_col = np.full((data.shape[0], 1), group)
-        return np.hstack((group_col, data))
 
 # style_attr = {'width': 640, 'height': 480, 'line width': 6, 'font size': 8, 'opacity': 0.5, 'y_max': 'auto'}
 # line_attr = {0: ['Center_1', 'Center_2', 'Green'], 1: ['Ear_left_2', 'Ear_left_1', 'Red']}
 #
 # test = DistancePlotterMultiCore(config_path=r'/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini',
 #                        frame_setting=False,
 #                        video_setting=True,
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/ROI_plotter.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/ROI_plotter.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,28 +1,26 @@
 __author__ = "Simon Nilsson"
 
-from simba.roi_tools.ROI_analyzer import ROIAnalyzer
-from simba.drop_bp_cords import get_fn_ext, createColorListofList
-from simba.feature_extractors.unit_tests import read_video_info
 import os
 import itertools
 import cv2
+import numpy as np
 from simba.enums import Paths, Formats
-from simba.misc_tools import (get_video_meta_data,
-                              add_missing_ROI_cols,
-                              SimbaTimer,
-                              )
-from simba.utils.printing import stdout_success
+from simba.roi_tools.ROI_analyzer import ROIAnalyzer
+from simba.mixins.config_reader import ConfigReader
+from simba.mixins.plotting_mixin import PlottingMixin
 from simba.utils.errors import DuplicationError
 from simba.utils.warnings import DuplicateNamesWarning
-import numpy as np
 from simba.utils.errors import NoFilesFoundError
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.utils.read_write import get_fn_ext, get_video_meta_data
+from simba.utils.data import create_color_palettes
 
 
-class ROIPlot(object):
+class ROIPlot(ConfigReader, PlottingMixin):
     """
     Class for visualizing the ROI data (number of entries/exits, time-spent-in etc)
 
     Parameters
     ----------
     config_path: str
         Path to SimBA project config file in Configparser format
@@ -42,31 +40,32 @@
 
     def __init__(
             self,
             ini_path: str,
             video_path: str,
             style_attr: dict):
 
+        ConfigReader.__init__(self, config_path=ini_path)
+        PlottingMixin.__init__(self)
         self.roi_analyzer = ROIAnalyzer(ini_path=ini_path, data_path='outlier_corrected_movement_location')
         self.video_dir_path = os.path.join(self.roi_analyzer.project_path, 'videos')
-        self.roi_analyzer.read_roi_dfs()
         self.video_path = os.path.join(self.video_dir_path, video_path)
         _, self.video_name, _ = get_fn_ext(video_path)
         self.roi_analyzer.files_found = [os.path.join(self.roi_analyzer.input_folder, self.video_name + '.' + self.roi_analyzer.file_type)]
         if not os.path.isfile(self.roi_analyzer.files_found[0]):
             raise NoFilesFoundError(msg='SIMBA ERROR: Could not find the file at path {}. Please make sure you have corrected body-part outliers or indicated that you want to skip outlier correction'.format(self.roi_analyzer.files_found[0]))
-        self.roi_analyzer.analyze_ROIs()
+        self.roi_analyzer.run()
         self.roi_entries_df = self.roi_analyzer.detailed_df
         self.data_df, self.style_attr = self.roi_analyzer.data_df, style_attr
         self.video_shapes = list(itertools.chain(self.roi_analyzer.video_recs['Name'].unique(), self.roi_analyzer.video_circs['Name'].unique(),self.roi_analyzer.video_polys['Name'].unique()))
         if len(list(set(self.video_shapes))) != len(self.video_shapes):
             raise DuplicationError(msg='Some SIMBA ROI shapes have identical names. Please use unique names to visualize ROI data.')
-        self.roi_analyzer.video_recs = add_missing_ROI_cols(self.roi_analyzer.video_recs)
-        self.roi_analyzer.video_circs = add_missing_ROI_cols(self.roi_analyzer.video_circs)
-        self.roi_analyzer.video_polys = add_missing_ROI_cols(self.roi_analyzer.video_polys)
+        self.roi_analyzer.video_recs = self.add_missing_ROI_cols(self.roi_analyzer.video_recs)
+        self.roi_analyzer.video_circs = self.add_missing_ROI_cols(self.roi_analyzer.video_circs)
+        self.roi_analyzer.video_polys = self.add_missing_ROI_cols(self.roi_analyzer.video_polys)
 
         self.shape_dicts = {}
         for df in [self.roi_analyzer.video_recs, self.roi_analyzer.video_circs, self.roi_analyzer.video_polys]:
             if not df['Name'].is_unique:
                 df = df.drop_duplicates(subset=['Name'], keep='first')
                 DuplicateNamesWarning(msg='Some of your ROIs with the same shape has the same names. E.g., you have two rectangles named "My rectangle". SimBA prefers ROI shapes with unique names. SimBA will keep one of the unique shape names and drop the rest.')
             d = df.set_index('Name').to_dict(orient='index')
@@ -151,23 +150,23 @@
         -------
         None
         """
 
         save_path = os.path.join(self.output_folder, self.video_name + '.avi')
         self.cap = cv2.VideoCapture(self.video_path)
         self.video_meta_data = get_video_meta_data(self.video_path)
-        video_settings, pix_per_mm, fps = read_video_info(self.roi_analyzer.video_info_df, self.video_name)
+        video_settings, pix_per_mm, fps = self.read_video_info(video_name=self.video_name)
         self.space_scale, radius_scale, res_scale, font_scale = 25, 10, 1500, 0.8
         max_dim = max(self.video_meta_data['width'], self.video_meta_data['height'])
         self.font = cv2.FONT_HERSHEY_TRIPLEX
         draw_scale, self.font_size = int(radius_scale / (res_scale / max_dim)), float(font_scale / (res_scale / max_dim))
         fourcc = cv2.VideoWriter_fourcc(*Formats.AVI_CODEC.value)
         self.spacing_scaler = int(self.space_scale / (res_scale / max_dim))
         writer = cv2.VideoWriter(save_path, fourcc, fps, (self.video_meta_data['width'] * 2, self.video_meta_data['height']))
-        color_lst = createColorListofList(self.roi_analyzer.animal_cnt, int((len(self.roi_analyzer.bp_names) / 3)))[0]
+        color_lst = create_color_palettes(self.roi_analyzer.animal_cnt, int((len(self.roi_analyzer.bp_names) / 3)))[0]
         self.__update_video_meta_data()
         self.__calc_text_locs()
         self.__create_counters()
 
         frame_cnt = 0
         while (self.cap.isOpened()):
             ret, img = self.cap.read()
@@ -231,15 +230,15 @@
             except Exception as e:
                 writer.release()
                 print(e.args)
                 print('NOTE: index error / keyerror. Some frames of the video may be missing. Make sure you are running latest version of SimBA with pip install simba-uw-tf-dev')
                 break
 
         writer.release()
-        #stdout_success(msg=f'Video {self.video_name} created. Video saved in project_folder/frames/output/ROI_analysis')
+        stdout_success(msg=f'Video {self.video_name} created. Video saved in project_folder/frames/output/ROI_analysis')
 
 # test = ROIPlot(ini_path=r'/Users/simon/Desktop/envs/troubleshooting/Termites_5/project_folder/project_config.ini',
 #                video_path="termite_test.mp4",
 #                style_attr={'Show_body_part': True, 'Show_animal_name': True})
 # test.insert_data()
 # test.visualize_ROI_data()
 
@@ -248,16 +247,13 @@
 # test.insert_data()
 # test.visualize_ROI_data()
 
 # test = ROIPlot(ini_path=r'/Users/simon/Desktop/troubleshooting/train_model_project/project_folder/project_config.ini', video_path=r"Together_1.avi")
 # test.insert_data()
 # test.visualize_ROI_data()
 
-# test = ROIPlot(ini_path=r"Z:\DeepLabCut\DLC_extract\Troubleshooting\ROI_2_animals\project_folder\project_config.ini", video_path=r"Z:\DeepLabCut\DLC_extract\Troubleshooting\ROI_2_animals\project_folder\videos\Video7.mp4")
-# test.insert_data()
-# test.visualize_ROI_data()
 
-# test = ROIPlot(ini_path=r'/Users/simon/Desktop/envs/troubleshooting/two_animals_16bp_032023/project_folder/project_config.ini',
-#                video_path="Together_1.avi",
+# test = ROIPlot(ini_path=r'/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini',
+#                video_path="Together_2.avi",
 #                style_attr={'Show_body_part': True, 'Show_animal_name': False})
 # test.insert_data()
 # test.visualize_ROI_data()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/heat_mapper_clf.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/heat_mapper_clf.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,28 +1,24 @@
 __author__ = "Simon Nilsson"
 
 import pandas as pd
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.misc_tools import (get_fn_ext,
-                              SimbaTimer,
-                              )
-from simba.utils.printing import stdout_success
-from simba.plotting.misc_visualizations import make_clf_heatmap_plot
-from simba.rw_dfs import read_df
 import numpy as np
 import os
 import cv2
 from numba import jit, prange
 import matplotlib.pyplot as plt
+from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas
 from simba.enums import Formats
+from simba.utils.printing import stdout_success, SimbaTimer
 from simba.mixins.config_reader import ConfigReader
-from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas
+from simba.mixins.plotting_mixin import PlottingMixin
+from simba.utils.read_write import get_fn_ext, read_df
 from simba.utils.errors import NoSpecifiedOutputError
 
-class HeatMapperClfSingleCore(ConfigReader):
+class HeatMapperClfSingleCore(ConfigReader, PlottingMixin):
 
     """
     Class for creating heatmaps representing the locations of the classified behavior.
 
     Parameters
     ----------
     config_path: str
@@ -65,26 +61,26 @@
                  frame_setting: bool,
                  bodypart: str,
                  clf_name: str,
                  files_found: list,
                  style_attr: dict
                  ):
 
-        super().__init__(config_path=config_path)
+        ConfigReader.__init__(self, config_path=config_path)
+        PlottingMixin.__init__(self)
 
         if (not frame_setting) and (not video_setting) and (not final_img_setting):
             raise NoSpecifiedOutputError(msg='Please choose to select either heatmap videos, frames, and/or final image.')
         self.frame_setting, self.video_setting = frame_setting, video_setting
         self.final_img_setting, self.bp = final_img_setting, bodypart
         self.bin_size, self.max_scale, self.palette, self.shading = style_attr['bin_size'], style_attr['max_scale'], style_attr['palette'], style_attr['shading']
         self.clf_name, self.files_found = clf_name, files_found
         if not os.path.exists(self.heatmap_clf_location_dir): os.makedirs(self.heatmap_clf_location_dir)
         self.bp_lst = [self.bp + '_x', self.bp + '_y']
-        self.timer = SimbaTimer()
-        self.timer.start_timer()
+        self.timer = SimbaTimer(start=True)
         print('Processing {} video(s)...'.format(str(len(self.files_found))))
 
     @staticmethod
     @jit(nopython=True)
     def __calculate_cum_array(clf_array: np.array,
                               fps: int):
         cum_sum_arr = np.full(clf_array.shape, np.nan)
@@ -157,15 +153,15 @@
         None
         '''
 
         for file_cnt, file_path in enumerate(self.files_found):
             video_timer = SimbaTimer()
             video_timer.start_timer()
             _, self.video_name, _ = get_fn_ext(file_path)
-            self.video_info, self.px_per_mm, self.fps = read_video_info(vid_info_df=self.video_info_df, video_name=self.video_name)
+            self.video_info, self.px_per_mm, self.fps = self.read_video_info(video_name=self.video_name)
             self.width, self.height = int(self.video_info['Resolution_width'].values[0]), int(self.video_info['Resolution_height'].values[0])
             if self.video_setting:
                 self.fourcc = cv2.VideoWriter_fourcc(*Formats.MP4_CODEC.value)
                 self.video_save_path = os.path.join(self.heatmap_clf_location_dir, self.video_name + '.mp4')
                 self.writer = cv2.VideoWriter(self.video_save_path, self.fourcc, self.fps, (self.width, self.height))
             if self.frame_setting:
                 self.save_video_folder = os.path.join(self.heatmap_clf_location_dir, self.video_name)
@@ -182,23 +178,23 @@
                                                                 fps=self.fps)
 
             if self.max_scale == 'auto':
                 self.max_scale = self.__calculate_max_scale(clf_array=clf_array)
                 if self.max_scale == 0: self.max_scale = 1
 
             if self.final_img_setting:
-                make_clf_heatmap_plot(frm_data=clf_array[-1, :, :],
-                                      max_scale=self.max_scale,
-                                      palette=self.palette,
-                                      aspect_ratio=aspect_ratio,
-                                      file_name=os.path.join(self.heatmap_clf_location_dir, self.video_name + '_final_frm.png'),
-                                      shading=self.shading,
-                                      clf_name=self.clf_name,
-                                      img_size=(self.width, self.height),
-                                      final_img=True)
+                self.make_clf_heatmap_plot(frm_data=clf_array[-1, :, :],
+                                           max_scale=self.max_scale,
+                                           palette=self.palette,
+                                           aspect_ratio=aspect_ratio,
+                                           file_name=os.path.join(self.heatmap_clf_location_dir, self.video_name + '_final_frm.png'),
+                                           shading=self.shading,
+                                           clf_name=self.clf_name,
+                                           img_size=(self.width, self.height),
+                                           final_img=True)
 
             if self.video_setting or self.frame_setting:
                 for frm_cnt, cumulative_frm_idx in enumerate(range(clf_array.shape[0])):
                     frm_data = clf_array[cumulative_frm_idx,:,:]
                     cum_df = pd.DataFrame(frm_data).reset_index()
                     cum_df = cum_df.melt(id_vars='index', value_vars=None, var_name=None, value_name='seconds', col_level=None).rename(columns={'index':'vertical_idx', 'variable': 'horizontal_idx'})
                     cum_df['color'] = (cum_df['seconds'].astype(float) / float(self.max_scale)).round(2).clip(upper=100)
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/distance_plotter.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/distance_plotter.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,29 +1,25 @@
 __author__ = "Simon Nilsson"
 
-from simba.read_config_unit_tests import check_if_filepath_list_is_empty
-from simba.feature_extractors.unit_tests import (read_video_info)
-from simba.misc_tools import (get_fn_ext,
-                              SimbaTimer,
-                              get_color_dict,
-                              )
-from simba.utils.printing import stdout_success
-from simba.plotting.misc_visualizations import make_distance_plot
-from simba.enums import Formats
-from simba.rw_dfs import read_df
-import numpy as np
-import matplotlib.pyplot as plt
-from simba.mixins.config_reader import ConfigReader
-from simba.utils.errors import NoSpecifiedOutputError
 import PIL
 import io
 import cv2
 import os
+import numpy as np
+import matplotlib.pyplot as plt
+from simba.mixins.config_reader import ConfigReader
+from simba.mixins.plotting_mixin import PlottingMixin
+from simba.utils.errors import NoSpecifiedOutputError
+from simba.utils.lookups import get_color_dict
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.utils.checks import check_if_filepath_list_is_empty
+from simba.enums import Formats
+from simba.utils.read_write import read_df, get_fn_ext
 
-class DistancePlotterSingleCore(ConfigReader):
+class DistancePlotterSingleCore(ConfigReader, PlottingMixin):
     """
      Class for visualizing the distance between two pose-estimated body-parts (e.g., two animals) through line
      charts. Results are saved as individual line charts, and/or a video of line charts.
 
      Parameters
      ----------
      config_path: str
@@ -49,16 +45,16 @@
                  frame_setting: bool,
                  video_setting: bool,
                  final_img: bool,
                  files_found: list,
                  style_attr: dict,
                  line_attr: dict):
 
-        super().__init__(config_path=config_path)
-
+        ConfigReader.__init__(self, config_path=config_path)
+        PlottingMixin.__init__(self)
         self.video_setting, self.frame_setting, self.files_found, self.style_attr, self.line_attr, self.final_img = video_setting, frame_setting, files_found, style_attr, line_attr, final_img
         if (not frame_setting) and (not video_setting) and (not self.final_img):
             raise NoSpecifiedOutputError('Please choice to create frames and/or video distance plots')
         self.colors_dict = get_color_dict()
         if not os.path.exists(self.line_plot_dir): os.makedirs(self.line_plot_dir)
         check_if_filepath_list_is_empty(filepaths=self.outlier_corrected_paths,
                                         error_msg='SIMBA ERROR: Zero files found in the project_folder/csv/machine_results directory. Create classification results before visualizing distances.')
@@ -70,39 +66,38 @@
 
         Returns
         ----------
         None
         '''
 
         for file_cnt, file_path in enumerate(self.files_found):
-            video_timer = SimbaTimer()
-            video_timer.start_timer()
+            video_timer = SimbaTimer(start=True)
             self.data_df = read_df(file_path, self.file_type)
             distance_arr = np.full((len(self.data_df), len(self.line_attr.keys())), np.nan)
             _, self.video_name, _ = get_fn_ext(file_path)
-            self.video_info, self.px_per_mm, self.fps = read_video_info(self.video_info_df, self.video_name)
+            self.video_info, self.px_per_mm, self.fps = self.read_video_info(video_name=self.video_name)
             for distance_cnt, data in enumerate(self.line_attr.values()):
                 distance_arr[:, distance_cnt] = (np.sqrt((self.data_df[data[0] + '_x'] - self.data_df[data[1] + '_x']) ** 2 + (self.data_df[data[0] + '_y'] - self.data_df[data[1] + '_y']) ** 2) / self.px_per_mm) / 10
             if self.video_setting:
                 self.fourcc = cv2.VideoWriter_fourcc(*Formats.MP4_CODEC.value)
                 self.video_save_path = os.path.join(self.line_plot_dir, self.video_name + '.mp4')
                 writer = cv2.VideoWriter(self.video_save_path, self.fourcc, self.fps, (self.style_attr['width'], self.style_attr['height']))
             if self.frame_setting:
                 self.save_video_folder = os.path.join(self.line_plot_dir, self.video_name)
                 if not os.path.exists(self.save_video_folder): os.makedirs(self.save_video_folder)
 
             distance_arr = np.nan_to_num(distance_arr, nan=0.0)
             if self.final_img:
                 self.final_img_path = os.path.join(self.line_plot_dir, self.video_name + '_final_img.png')
-                make_distance_plot(data=distance_arr,
-                                   line_attr=self.line_attr,
-                                   style_attr=self.style_attr,
-                                   fps=self.fps,
-                                   save_path=self.final_img_path,
-                                   save_img=True)
+                self.make_distance_plot(data=distance_arr,
+                                        line_attr=self.line_attr,
+                                        style_attr=self.style_attr,
+                                        fps=self.fps,
+                                        save_path=self.final_img_path,
+                                        save_img=True)
 
             if self.video_setting or self.frame_setting:
                 if self.style_attr['y_max'] == 'auto':
                     max_y = np.amax(distance_arr)
                 else:
                     max_y = float(self.style_attr['y_max'])
                 y_ticks_locs = y_lbls = np.round(np.linspace(0, max_y, 10), 2)
@@ -141,25 +136,30 @@
 
                 if self.video_setting:
                     writer.release()
                 video_timer.stop_timer()
                 print('Distance plot for video {} saved (elapsed time: {}s)...'.format(self.video_name, video_timer.elapsed_time_str))
         self.timer.stop_timer()
         stdout_success(msg='All distance visualizations created in project_folder/frames/output/line_plot directory', elapsed_time=self.timer.elapsed_time_str)
-
-# style_attr = {'width': 640, 'height': 480, 'line width': 6, 'font size': 8, 'y_max': 'auto', 'opacity': 0.9}
+#
+# style_attr = {'width': 640,
+#               'height': 480,
+#               'line width': 6,
+#               'font size': 8,
+#               'y_max': 'auto',
+#               'opacity': 0.9}
 # line_attr = {0: ['Center_1', 'Center_2', 'Green'], 1: ['Ear_left_2', 'Ear_left_1', 'Red']}
 #
 # test = DistancePlotterSingleCore(config_path=r'/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini',
-#                        frame_setting=False,
-#                        video_setting=True,
-#                        style_attr=style_attr,
+#                                  frame_setting=False,
+#                                  video_setting=True,
+#                                  style_attr=style_attr,
 #                                  final_img=True,
-#                        files_found=['/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/csv/machine_results/Together_1.csv'],
-#                        line_attr=line_attr)
+#                                  files_found=['/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/csv/machine_results/Together_1.csv'],
+#                                  line_attr=line_attr)
 # test.create_distance_plot()
 
 # style_attr = {'width': 640, 'height': 480, 'line width': 6, 'font size': 8}
 # line_attr = {0: ['Termite_1_Head_1', 'Termite_1_Thorax_1', 'Dark-red']}
 
 # test = DistancePlotterSingleCore(config_path=r'/Users/simon/Desktop/envs/troubleshooting/Termites_5/project_folder/project_config.ini',
 #                                  frame_setting=False,
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/single_run_model_validation_video_mp.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/single_run_model_validation_video_mp.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,136 +1,126 @@
 __author__ = "Simon Nilsson"
 
 import warnings
-import time
-import pandas as pd
-from tqdm import tqdm
 warnings.filterwarnings('ignore',category=FutureWarning)
 warnings.filterwarnings('ignore',category=DeprecationWarning)
-import pickle
-import imutils
-from PIL import Image
-from simba.mixins.config_reader import ConfigReader
+import pandas as pd
+import numpy as np
 import cv2
-import warnings
-from simba.drop_bp_cords import drop_bp_cords
+import os
 import matplotlib.pyplot as plt
-import numpy as np
-from simba.rw_dfs import *
-from simba.misc_tools import (find_video_of_file,
-                              get_fn_ext,
-                              get_video_meta_data,
-                              plug_holes_shortest_bout,
-                              get_bouts_for_gantt,
-                              create_gantt_img,
-                              resize_gantt,
-                              )
-from simba.utils.printing import stdout_success
-from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas
-from simba.misc_tools import concatenate_videos_in_folder
-from simba.feature_extractors.unit_tests import read_video_info
 import platform
 import functools
 import multiprocessing
 import matplotlib
 
-def _multiprocess_validation_video(data: pd.DataFrame,
-                                   bp_dict: dict,
-                                   video_save_dir: str,
-                                   settings: dict,
-                                   video_path: str,
-                                   video_meta_data: dict,
-                                   gantt_setting: str or None,
-                                   final_gantt: np.array or None,
-                                   clf_data: np.array,
-                                   clrs: list,
-                                   clf_name: str,
-                                   bouts_df: pd.DataFrame):
-
-    dpi = plt.rcParams['figure.dpi']
-    def create_gantt(bouts_df: pd.DataFrame,
-                         clf_name: str,
-                         image_index: int,
-                         fps: int):
-
-        fig, ax = plt.subplots(figsize=(final_gantt.shape[1]/dpi, final_gantt.shape[0]/dpi))
-        matplotlib.font_manager._get_font.cache_clear()
-        relRows = bouts_df.loc[bouts_df['End_frame'] <= image_index]
-
-        for i, event in enumerate(relRows.groupby("Event")):
-            data_event = event[1][["Start_time", "Bout_time"]]
-            ax.broken_barh(data_event.values, (4, 4), facecolors='red')
-        xLength = (round(image_index / fps)) + 1
-        if xLength < 10: xLength = 10
-
-        ax.set_xlim(0, xLength)
-        ax.set_ylim([0, 12])
-        ax.set_xlabel('Session (s)', fontsize=12)
-        ax.set_ylabel(clf_name, fontsize=12)
-        ax.set_title(f'{clf_name} GANTT CHART', fontsize=12)
-        ax.set_yticks([])
-        ax.yaxis.set_ticklabels([])
-        ax.yaxis.grid(True)
-        canvas = FigureCanvas(fig)
-        canvas.draw()
-        img = np.array(np.uint8(np.array(canvas.renderer._renderer)))[:, :, :3]
-        plt.close(fig)
-        return img
-
-    fourcc, font = cv2.VideoWriter_fourcc(*'mp4v'), cv2.FONT_HERSHEY_COMPLEX
-    cap = cv2.VideoCapture(video_path)
-    group = data['group'].iloc[0]
-    start_frm, current_frm, end_frm = data.index[0], data.index[0], data.index[-1]
-    video_save_path = os.path.join(video_save_dir, '{}.mp4'.format(str(group)))
-    if gantt_setting is not None:
-        writer = cv2.VideoWriter(video_save_path, fourcc, video_meta_data['fps'], (int(video_meta_data['width'] + final_gantt.shape[1]), int(video_meta_data['height'])))
-    else:
-        writer = cv2.VideoWriter(video_save_path, fourcc, video_meta_data['fps'], (video_meta_data['width'], video_meta_data['height']))
-    cap.set(1, start_frm)
-
-    while current_frm < end_frm:
-        clf_frm_cnt = np.sum(clf_data[0:current_frm])
-        ret, img = cap.read()
-        if settings['pose']:
-            for animal_cnt, (animal_name, animal_data) in enumerate(bp_dict.items()):
-                for bp_cnt, bp in enumerate(range(len(animal_data['X_bps']))):
-                    x_header, y_header = animal_data['X_bps'][bp], animal_data['Y_bps'][bp]
-                    animal_cords = tuple(data.loc[current_frm, [x_header, y_header]])
-                    cv2.circle(img, (int(animal_cords[0]), int(animal_cords[1])), 0, clrs[animal_cnt][bp_cnt], settings['styles']['circle size'])
-        if settings['animal_names']:
-            for animal_cnt, (animal_name, animal_data) in enumerate(bp_dict.items()):
-                x_header, y_header = animal_data['X_bps'][0], animal_data['Y_bps'][0]
-                animal_cords = tuple(data.loc[current_frm, [x_header, y_header]])
-                cv2.putText(img, animal_name, (int(animal_cords[0]), int(animal_cords[1])), font, settings['styles']['font size'], clrs[animal_cnt][0], 1)
-        target_timer = round((1 / video_meta_data['fps']) * clf_frm_cnt, 2)
-        cv2.putText(img, 'Timer', (10, settings['styles']['space_scale']), font, settings['styles']['font size'], (0, 255, 0), 2)
-        addSpacer = 2
-        cv2.putText(img, (f'{clf_name} {target_timer}s'), (10, settings['styles']['space_scale'] * addSpacer), font, settings['styles']['font size'], (0, 0, 255), 2)
-        addSpacer += 1
-        cv2.putText(img, 'Ensemble prediction', (10, settings['styles']['space_scale'] * addSpacer), font, settings['styles']['font size'], (0, 255, 0), 2)
-        addSpacer += 2
-        if clf_data[current_frm] == 1:
-            cv2.putText(img, clf_name, (10, + settings['styles']['space_scale'] * addSpacer), font, settings['styles']['font size'], (2, 166, 249), 2)
-            addSpacer += 1
-        if gantt_setting == 'Gantt chart: final frame only (slightly faster)':
-            img = np.concatenate((img, final_gantt), axis=1)
-        elif gantt_setting == 'Gantt chart: video':
-            gantt_img = create_gantt(bouts_df, clf_name, current_frm, video_meta_data['fps'], 'Behavior gantt chart')
-            img = np.concatenate((img, gantt_img), axis=1)
-
-        writer.write(np.uint8(img))
-        current_frm += 1
-        print('Multi-processing video frame {} on core {}...'.format(str(current_frm), str(group)))
+from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas
+from simba.mixins.config_reader import ConfigReader
+from simba.mixins.plotting_mixin import PlottingMixin
+from simba.utils.data import plug_holes_shortest_bout
+from simba.utils.read_write import get_fn_ext, read_df, write_df, get_video_meta_data, concatenate_videos_in_folder
+from simba.utils.printing import stdout_success
 
-    cap.release()
-    writer.release()
 
-    return group
+# def _multiprocess_validation_video(data: pd.DataFrame,
+#                                    bp_dict: dict,
+#                                    video_save_dir: str,
+#                                    settings: dict,
+#                                    video_path: str,
+#                                    video_meta_data: dict,
+#                                    gantt_setting: str or None,
+#                                    final_gantt: np.array or None,
+#                                    clf_data: np.array,
+#                                    clrs: list,
+#                                    clf_name: str,
+#                                    bouts_df: pd.DataFrame):
+#
+#     dpi = plt.rcParams['figure.dpi']
+#
+#     def create_gantt(bouts_df: pd.DataFrame,
+#                          clf_name: str,
+#                          image_index: int,
+#                          fps: int):
+#
+#         fig, ax = plt.subplots(figsize=(final_gantt.shape[1]/dpi, final_gantt.shape[0]/dpi))
+#         matplotlib.font_manager._get_font.cache_clear()
+#         relRows = bouts_df.loc[bouts_df['End_frame'] <= image_index]
+#
+#         for i, event in enumerate(relRows.groupby("Event")):
+#             data_event = event[1][["Start_time", "Bout_time"]]
+#             ax.broken_barh(data_event.values, (4, 4), facecolors='red')
+#         xLength = (round(image_index / fps)) + 1
+#         if xLength < 10: xLength = 10
+#
+#         ax.set_xlim(0, xLength)
+#         ax.set_ylim([0, 12])
+#         ax.set_xlabel('Session (s)', fontsize=12)
+#         ax.set_ylabel(clf_name, fontsize=12)
+#         ax.set_title(f'{clf_name} GANTT CHART', fontsize=12)
+#         ax.set_yticks([])
+#         ax.yaxis.set_ticklabels([])
+#         ax.yaxis.grid(True)
+#         canvas = FigureCanvas(fig)
+#         canvas.draw()
+#         img = np.array(np.uint8(np.array(canvas.renderer._renderer)))[:, :, :3]
+#         plt.close(fig)
+#         return img
+#
+#     fourcc, font = cv2.VideoWriter_fourcc(*'mp4v'), cv2.FONT_HERSHEY_COMPLEX
+#     cap = cv2.VideoCapture(video_path)
+#     group = data['group'].iloc[0]
+#     start_frm, current_frm, end_frm = data.index[0], data.index[0], data.index[-1]
+#     video_save_path = os.path.join(video_save_dir, '{}.mp4'.format(str(group)))
+#     if gantt_setting is not None:
+#         writer = cv2.VideoWriter(video_save_path, fourcc, video_meta_data['fps'], (int(video_meta_data['width'] + final_gantt.shape[1]), int(video_meta_data['height'])))
+#     else:
+#         writer = cv2.VideoWriter(video_save_path, fourcc, video_meta_data['fps'], (video_meta_data['width'], video_meta_data['height']))
+#     cap.set(1, start_frm)
+#
+#     while current_frm < end_frm:
+#         clf_frm_cnt = np.sum(clf_data[0:current_frm])
+#         ret, img = cap.read()
+#         if settings['pose']:
+#             for animal_cnt, (animal_name, animal_data) in enumerate(bp_dict.items()):
+#                 for bp_cnt, bp in enumerate(range(len(animal_data['X_bps']))):
+#                     x_header, y_header = animal_data['X_bps'][bp], animal_data['Y_bps'][bp]
+#                     animal_cords = tuple(data.loc[current_frm, [x_header, y_header]])
+#                     cv2.circle(img, (int(animal_cords[0]), int(animal_cords[1])), 0, clrs[animal_cnt][bp_cnt], settings['styles']['circle size'])
+#         if settings['animal_names']:
+#             for animal_cnt, (animal_name, animal_data) in enumerate(bp_dict.items()):
+#                 x_header, y_header = animal_data['X_bps'][0], animal_data['Y_bps'][0]
+#                 animal_cords = tuple(data.loc[current_frm, [x_header, y_header]])
+#                 cv2.putText(img, animal_name, (int(animal_cords[0]), int(animal_cords[1])), font, settings['styles']['font size'], clrs[animal_cnt][0], 1)
+#         target_timer = round((1 / video_meta_data['fps']) * clf_frm_cnt, 2)
+#         cv2.putText(img, 'Timer', (10, settings['styles']['space_scale']), font, settings['styles']['font size'], (0, 255, 0), 2)
+#         addSpacer = 2
+#         cv2.putText(img, (f'{clf_name} {target_timer}s'), (10, settings['styles']['space_scale'] * addSpacer), font, settings['styles']['font size'], (0, 0, 255), 2)
+#         addSpacer += 1
+#         cv2.putText(img, 'Ensemble prediction', (10, settings['styles']['space_scale'] * addSpacer), font, settings['styles']['font size'], (0, 255, 0), 2)
+#         addSpacer += 2
+#         if clf_data[current_frm] == 1:
+#             cv2.putText(img, clf_name, (10, + settings['styles']['space_scale'] * addSpacer), font, settings['styles']['font size'], (2, 166, 249), 2)
+#             addSpacer += 1
+#         if gantt_setting == 'Gantt chart: final frame only (slightly faster)':
+#             img = np.concatenate((img, final_gantt), axis=1)
+#         elif gantt_setting == 'Gantt chart: video':
+#             gantt_img = create_gantt(bouts_df, clf_name, current_frm, video_meta_data['fps'])
+#             img = np.concatenate((img, gantt_img), axis=1)
+#
+#         writer.write(np.uint8(img))
+#         current_frm += 1
+#         print('Multi-processing video frame {} on core {}...'.format(str(current_frm), str(group)))
+#
+#     cap.release()
+#     writer.release()
+#
+#     return group
 
-class ValidateModelOneVideoMultiprocess(ConfigReader):
+class ValidateModelOneVideoMultiprocess(ConfigReader,
+                                        PlottingMixin):
     """
     Class for creating classifier validation video for a single input video. Results are stored in the
     `project_folder/frames/output/validation directory`.
 
     Parameters
     ----------
     config_path: str
@@ -158,104 +148,108 @@
                  model_path: str,
                  discrimination_threshold: float,
                  shortest_bout: int,
                  cores:int,
                  create_gantt: str,
                  settings: None=None):
 
-        super().__init__(config_path=config_path)
+        ConfigReader.__init__(self, config_path=config_path)
+        PlottingMixin.__init__(self)
         if platform.system() == "Darwin":
             multiprocessing.set_start_method('spawn', force=True)
 
         _, self.feature_filename, ext = get_fn_ext(feature_file_path)
         self.discrimination_threshold, self.cores, self.shortest_bout, self.create_gantt, self.settings = float(discrimination_threshold), cores, shortest_bout, create_gantt, settings
         if not os.path.exists(self.single_validation_video_save_dir): os.makedirs(self.single_validation_video_save_dir)
-        _, _, self.fps = read_video_info(self.video_info_df, self.feature_filename)
+        _, _, self.fps = self.read_video_info(video_name=self.feature_filename)
         self.clf_name = os.path.basename(model_path).replace('.sav', '')
-        self.video_path = find_video_of_file(self.video_dir, self.feature_filename)
+        self.video_path = self.find_video_of_file(self.video_dir, self.feature_filename)
         self.clf_data_save_path = os.path.join(self.clf_data_validation_dir, self.feature_filename + '.csv')
         self.video_meta_data = get_video_meta_data(video_path=self.video_path)
-        self.clf = pickle.load(open(model_path, 'rb'))
+        self.clf = read_df(file_path=model_path, file_type='pickle')
         self.in_df = read_df(feature_file_path, self.file_type)
         self.temp_dir = os.path.join(self.single_validation_video_save_dir, 'temp')
         self.video_save_path = os.path.join(self.single_validation_video_save_dir, self.feature_filename + '.mp4')
         if not os.path.exists(self.temp_dir): os.makedirs(self.temp_dir)
 
     def __run_clf(self):
         self.prob_col_name = f'Probability_{self.clf_name}'
-        self.in_df[self.prob_col_name] = self.clf.predict_proba(drop_bp_cords(self.in_df, self.config_path))[:, 1]
+        self.in_df[self.prob_col_name] = self.clf.predict_proba(self.drop_bp_cords(df=self.in_df))[:, 1]
         self.in_df[self.clf_name] = np.where(self.in_df[self.prob_col_name] > self.discrimination_threshold, 1, 0)
 
-
-
     def __plug_bouts(self):
         self.data_df = plug_holes_shortest_bout(data_df=self.in_df, clf_name=self.clf_name, fps=self.fps, shortest_bout=self.shortest_bout)
 
     def __save(self):
-        save_df(self.data_df, self.file_type, self.clf_data_save_path)
+        write_df(df=self.data_df, file_type=self.file_type, save_path=self.clf_data_save_path)
         print(f'Predictions created for video {self.feature_filename}...')
 
     def __index_df_for_multiprocessing(self, data: list) -> list:
         for cnt, df in enumerate(data):
             df['group'] = cnt
         return data
 
     def __create_video(self):
         self.final_gantt_img = None
         self.bouts_df = None
         if self.create_gantt is not None:
-            self.bouts_df = get_bouts_for_gantt(data_df=self.data_df, clf_name=self.clf_name, fps=self.fps)
-            self.final_gantt_img = create_gantt_img(self.bouts_df, self.clf_name, len(self.data_df), self.fps, 'Behavior gantt chart (entire session)')
-            self.final_gantt_img = resize_gantt(self.final_gantt_img, self.video_meta_data['height'])
+            self.bouts_df = self.get_bouts_for_gantt(data_df=self.data_df, clf_name=self.clf_name, fps=self.fps)
+            self.final_gantt_img = self.create_gantt_img(self.bouts_df, self.clf_name, len(self.data_df), self.fps, 'Behavior gantt chart (entire session)')
+            self.final_gantt_img = self.resize_gantt(self.final_gantt_img, self.video_meta_data['height'])
 
         if self.settings['styles'] is None:
             self.settings['styles'] = {}
             space_scaler, radius_scaler, resolution_scaler, font_scaler = 60, 20, 1500, 1.5
             max_dim = max(self.video_meta_data['width'], self.video_meta_data['height'])
             self.settings['styles']['circle size'] = int(radius_scaler / (resolution_scaler / max_dim))
             self.settings['styles']['font size'] = float(font_scaler / (resolution_scaler / max_dim))
             self.settings['styles']['space_scale'] = int(space_scaler / (resolution_scaler / max_dim))
 
         data = np.array_split(self.in_df, self.cores)
         frm_per_core = data[0].shape[0]
         data = self.__index_df_for_multiprocessing(data=data)
         with multiprocessing.Pool(self.cores, maxtasksperchild=self.maxtasksperchild) as pool:
-            constants = functools.partial(_multiprocess_validation_video,
+            constants = functools.partial(self.validation_video_mp,
                                           bp_dict=self.animal_bp_dict,
                                           video_save_dir=self.temp_dir,
                                           settings=self.settings,
                                           video_meta_data=self.video_meta_data,
                                           video_path=self.video_path,
                                           gantt_setting=self.create_gantt,
                                           final_gantt=self.final_gantt_img,
                                           clf_data=self.data_df[self.clf_name].values,
                                           clrs=self.clr_lst,
                                           clf_name=self.clf_name,
                                           bouts_df=self.bouts_df)
-            for cnt, result in enumerate(pool.imap(constants, data, chunksize=self.multiprocess_chunksize)):
-                print('Image {}/{}, Video {}...'.format(str(int(frm_per_core * (result+1))), str(len(self.data_df)), self.feature_filename))
-            print('Joining {} multiprocessed video...'.format(self.feature_filename))
+            try:
+                for cnt, result in enumerate(pool.imap(constants, data, chunksize=self.multiprocess_chunksize)):
+                    print('Image {}/{}, Video {}...'.format(str(int(frm_per_core * (result+1))), str(len(self.data_df)), self.feature_filename))
+                print('Joining {} multiprocessed video...'.format(self.feature_filename))
+            except:
+                pass
         concatenate_videos_in_folder(in_folder=self.temp_dir, save_path=self.video_save_path)
         self.timer.stop_timer()
         pool.terminate()
         pool.join()
         stdout_success(msg=f'Video {self.feature_filename} complete', elapsed_time=self.timer.elapsed_time_str)
 
     def run(self):
         self.__run_clf()
         if self.shortest_bout > 1:
             self.__plug_bouts()
         self.__save()
         self.__create_video()
 
-# test = ValidateModelOneVideoMultiprocess(config_path=r'/Users/simon/Desktop/envs/troubleshooting/naresh/project_folder/project_config.ini',
-#                              feature_file_path=r'/Users/simon/Desktop/envs/troubleshooting/naresh/project_folder/csv/features_extracted/SF2.csv',
-#                              model_path='/Users/simon/Desktop/envs/troubleshooting/naresh/models/generated_models/Top.sav',
+#
+
+
+# test = ValidateModelOneVideoMultiprocess(config_path=r'/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini',
+#                              feature_file_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/csv/features_extracted/Together_2.csv',
+#                              model_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/models/generated_models/Attack.sav',
 #                              discrimination_threshold=0.6,
 #                              shortest_bout=50,
 #                              cores=6,
 #                              settings={'pose': True, 'animal_names': True, 'styles': None},
 #                              create_gantt='Gantt chart: video')
 # test.run()
 
-#  final frame only (slightly faster), (494, 1318, 3)
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/Directing_animals_visualizer.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/Directing_animals_visualizer.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,30 +1,25 @@
 __author__ = "Simon Nilsson", "JJ Choong"
 
 import pandas as pd
-
-from simba.Directing_animals_analyzer import DirectingOtherAnimalsAnalyzer
 import os
-from simba.drop_bp_cords import (get_fn_ext, createColorListofList, create_body_part_dictionary)
-from simba.misc_tools import (find_video_of_file,
-                              get_video_meta_data,
-                              SimbaTimer,
-                              get_color_dict,
-                              )
-from simba.utils.printing import stdout_success
-from simba.utils.warnings import NoDataFoundWarning
 import cv2
 import numpy as np
 import random
-from simba.rw_dfs import read_df
+from simba.Directing_animals_analyzer import DirectingOtherAnimalsAnalyzer
 from simba.enums import Formats
 from simba.mixins.config_reader import ConfigReader
+from simba.mixins.plotting_mixin import PlottingMixin
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.utils.warnings import NoDataFoundWarning
+from simba.utils.lookups import get_color_dict
+from simba.utils.read_write import read_df, get_video_meta_data, get_fn_ext
 
 
-class DirectingOtherAnimalsVisualizer(ConfigReader):
+class DirectingOtherAnimalsVisualizer(ConfigReader, PlottingMixin):
     """
     Class for visualizing when animals are directing towards body-parts of other animals.
 
     > Note: Requires the pose-estimation data for the left ear, right ears and nose of individual animals.
 
     Parameters
     ----------
@@ -50,34 +45,34 @@
 
 
     def __init__(self,
                  config_path: str,
                  data_path: str,
                  style_attr: dict):
 
-        super().__init__(config_path=config_path)
+        ConfigReader.__init__(self, config_path=config_path)
+        PlottingMixin.__init__(self)
 
         self.data_path = data_path
         _, self.video_name, _ = get_fn_ext(self.data_path)
         self.direction_analyzer = DirectingOtherAnimalsAnalyzer(config_path=config_path)
         self.direction_analyzer.process_directionality()
         self.direction_analyzer.create_directionality_dfs()
         self.fourcc = cv2.VideoWriter_fourcc(*Formats.MP4_CODEC.value)
         self.style_attr, self.pose_colors = style_attr, []
         self.colors = get_color_dict()
         if self.style_attr['Show_pose']:
-            self.pose_colors = createColorListofList(self.animal_cnt, int(len(self.x_cols) + 1))
+            self.pose_colors = self.create_color_lst_of_lst(self.animal_cnt, int(len(self.x_cols) + 1))
         if self.style_attr['Direction_color'] == 'Random':
-            self.direction_colors = createColorListofList(1, int(self.animal_cnt**2))
+            self.direction_colors = self.create_color_lst_of_lst(1, int(self.animal_cnt**2))
         else:
             self.direction_colors = [self.colors[self.style_attr['Direction_color']]]
         self.data_dict = self.direction_analyzer.directionality_df_dict
-        self.video_path = find_video_of_file(video_dir=self.video_dir, filename=self.video_name)
+        self.video_path = self.find_video_of_file(video_dir=self.video_dir, filename=self.video_name)
         if not os.path.exists(self.directing_animals_video_output_path): os.makedirs(self.directing_animals_video_output_path)
-        self.animal_bp_dict = create_body_part_dictionary(self.multi_animal_status, self.multi_animal_id_list, self.animal_cnt, self.x_cols, self.y_cols, [], self.pose_colors)
         print(f'Processing video {self.video_name}...')
 
     def run(self):
         """
         Method to create directionality videos. Results are stored in
         the `project_folder/frames/output/ROI_directionality_visualize` directory of the SimBA project
 
@@ -161,15 +156,15 @@
                     break
 
             except IndexError:
                 self.cap.release()
                 self.writer.release()
 
         video_timer.stop_timer()
-        stdout_success(msg=f'Directionality video {self.video_name} saved in {self.directing_animals_video_output_path} directory', elapsed_time=self.timer.elapsed_time_str)
+        stdout_success(msg=f'Directionality video {self.video_name} saved in {self.directing_animals_video_output_path} directory', elapsed_time=video_timer.elapsed_time_str)
 
 # style_attr = {'Show_pose': True, 'Pose_circle_size': 3, "Direction_color": 'Random', 'Direction_thickness': 4, 'Highlight_endpoints': True, 'Polyfill': True}
 # test = DirectingOtherAnimalsVisualizer(config_path='/Users/simon/Desktop/envs/troubleshooting/sleap_5_animals/project_folder/project_config.ini',
 #                                        data_path='/Users/simon/Desktop/envs/troubleshooting/sleap_5_animals/project_folder/csv/outlier_corrected_movement_location/Testing_Video_3.csv',
 #                                        style_attr=style_attr)
 #
 # test.run()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/plotting/heat_mapper_location_mp.py` & `Simba-UW-tf-dev-1.57.6/simba/plotting/heat_mapper_location_mp.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,61 +1,56 @@
 __author__ = "Simon Nilsson", "JJ Choong"
 
 import pandas as pd
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.misc_tools import (get_fn_ext,
-                              SimbaTimer,
-                              remove_a_folder,
-                              concatenate_videos_in_folder,
-                              )
-from simba.utils.printing import stdout_success
-from simba.plotting.misc_visualizations import make_location_heatmap_plot
-from simba.rw_dfs import read_df
 import numpy as np
 import os
 import cv2
 from numba import jit, prange
-from simba.enums import Formats
 import platform
 import multiprocessing
 import functools
+from simba.enums import Formats
 from simba.mixins.config_reader import ConfigReader
+from simba.mixins.plotting_mixin import PlottingMixin
 from simba.utils.errors import NoSpecifiedOutputError
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.utils.read_write import get_fn_ext, remove_a_folder, concatenate_videos_in_folder, read_df
 
 def _heatmap_location(data: np.array,
                      video_setting: bool,
                      frame_setting: bool,
                      video_temp_dir: str,
                      video_name: str,
                      frame_dir: str,
                      fps: int,
                      style_attr: dict,
                      max_scale: float,
                      aspect_ratio: float,
-                     size: tuple):
+                     size: tuple,
+                     make_location_heatmap_plot: PlottingMixin.make_location_heatmap_plot):
 
     group = int(data[0][0][1])
     if video_setting:
         fourcc = cv2.VideoWriter_fourcc(*Formats.MP4_CODEC.value)
         video_save_path = os.path.join(video_temp_dir, '{}.mp4'.format(str(group)))
         video_writer = cv2.VideoWriter(video_save_path, fourcc, fps, size)
 
 
     for i in range(data.shape[0]):
         frame_id = int(data[i, 0, 0])
         frm_data = data[i, :, 2:]
 
         img = make_location_heatmap_plot(frm_data=frm_data,
-                                       max_scale= float(max_scale),
-                                       palette= style_attr['palette'],
-                                       aspect_ratio= aspect_ratio,
-                                       shading=style_attr['shading'],
-                                       img_size=size,
-                                       file_name=None,
-                                       final_img=False)
+                                         max_scale= float(max_scale),
+                                         palette= style_attr['palette'],
+                                         aspect_ratio= aspect_ratio,
+                                         shading=style_attr['shading'],
+                                         img_size=size,
+                                         file_name=None,
+                                         final_img=False)
 
         print('Heatmap frame created: {}, Video: {}, Processing core: {}'.format(str(frame_id+1), video_name, str(group+1)))
 
         if video_setting:
             video_writer.write(img)
 
         if frame_setting:
@@ -63,15 +58,15 @@
             cv2.imwrite(file_path, img)
 
     if video_setting:
         video_writer.release()
 
     return group
 
-class HeatMapperLocationMultiprocess(ConfigReader):
+class HeatMapperLocationMultiprocess(ConfigReader, PlottingMixin):
 
     """
     Class for creating heatmaps representing the locations of animal body-part
 
     Parameters
     ----------
     config_path: str
@@ -111,15 +106,16 @@
                  frame_setting: bool,
                  bodypart: str,
                  files_found: list,
                  style_attr: dict,
                  core_cnt: int
                  ):
 
-        super().__init__(config_path=config_path)
+        ConfigReader.__init__(self, config_path=config_path)
+        PlottingMixin.__init__(self)
 
         if platform.system() == "Darwin":
             multiprocessing.set_start_method('spawn', force=True)
 
         if (not frame_setting) and (not video_setting) and (not final_img_setting):
             raise NoSpecifiedOutputError(msg='Please choose to select either heatmap videos, frames, and/or final image.')
         self.frame_setting, self.video_setting = frame_setting, video_setting
@@ -216,18 +212,17 @@
 
         Returns
         ----------
         None
         '''
 
         for file_cnt, file_path in enumerate(self.files_found):
-            video_timer = SimbaTimer()
-            video_timer.start_timer()
+            video_timer = SimbaTimer(start=True)
             _, self.video_name, _ = get_fn_ext(file_path)
-            self.video_info, self.px_per_mm, self.fps = read_video_info(vid_info_df=self.video_info_df, video_name=self.video_name)
+            self.video_info, self.px_per_mm, self.fps = self.read_video_info(video_name=self.video_name)
             self.width, self.height = int(self.video_info['Resolution_width'].values[0]), int(self.video_info['Resolution_height'].values[0])
             self.save_frame_folder_dir = os.path.join(self.heatmap_location_dir, self.video_name)
             self.video_folder = os.path.join(self.heatmap_location_dir, self.video_name)
             self.temp_folder = os.path.join(self.heatmap_location_dir, self.video_name, 'temp')
             if self.frame_setting:
                 if os.path.exists(self.save_frame_folder_dir):
                     remove_a_folder(folder_dir=self.save_frame_folder_dir)
@@ -247,24 +242,27 @@
                                                                 img_height=self.height,
                                                                 bin_size=self.bin_size,
                                                                 fps=self.fps)
 
 
             if self.max_scale == 'auto':
                 self.max_scale = self.__calculate_max_scale(clf_array=location_array)
+            else:
+                self.max_scale = self.style_attr['max_scale']
+
 
             if self.final_img_setting:
-                make_location_heatmap_plot(frm_data=location_array[-1, :, :],
-                                           max_scale=self.max_scale,
-                                           palette=self.palette,
-                                           aspect_ratio=aspect_ratio,
-                                           file_name=os.path.join(self.heatmap_location_dir, self.video_name + '_final_frm.png'),
-                                           shading=self.shading,
-                                           img_size=(self.width, self.height),
-                                           final_img=True)
+                self.make_location_heatmap_plot(frm_data=location_array[-1, :, :],
+                                                max_scale=self.max_scale,
+                                                palette=self.palette,
+                                                aspect_ratio=aspect_ratio,
+                                                file_name=os.path.join(self.heatmap_location_dir, self.video_name + '_final_frm.png'),
+                                                shading=self.shading,
+                                                img_size=(self.width, self.height),
+                                                final_img=True)
 
             if self.video_setting or self.frame_setting:
                 frame_arrays = np.array_split(location_array, self.core_cnt)
                 last_frm_idx = 0
                 for frm_group in range(len(frame_arrays)):
                     split_arr = frame_arrays[frm_group]
                     frame_arrays[frm_group] = self.__insert_group_idx_column(data=split_arr, group=frm_group, last_frm_idx=last_frm_idx)
@@ -277,15 +275,16 @@
                                                   style_attr=self.style_attr,
                                                   fps=self.fps,
                                                   video_temp_dir=self.temp_folder,
                                                   frame_dir=self.save_frame_folder_dir,
                                                   max_scale=self.max_scale,
                                                   aspect_ratio=aspect_ratio,
                                                   size=(self.width, self.height),
-                                                  video_name=self.video_name)
+                                                  video_name=self.video_name,
+                                                  make_location_heatmap_plot=self.make_location_heatmap_plot)
 
                     for cnt, result in enumerate(pool.imap(constants, frame_arrays, chunksize=self.multiprocess_chunksize)):
                         print('Image {}/{}, Video {}/{}...'.format(str(int(frm_per_core * (result + 1))),
                                                                    str(len(self.data_df)), str(file_cnt + 1),
                                                                    str(len(self.files_found))))
                     pool.terminate()
                     pool.join()
@@ -294,15 +293,15 @@
                     print('Joining {} multiprocessed heatmap location video...'.format(self.video_name))
                     concatenate_videos_in_folder(in_folder=self.temp_folder, save_path=self.save_video_path)
 
                 video_timer.stop_timer()
                 print('Heatmap video {} complete (elapsed time: {}s) ...'.format(self.video_name, video_timer.elapsed_time_str))
 
             self.timer.stop_timer()
-            stdout_success(msg='Heatmap location videos visualizations for {} videos created in project_folder/frames/output/heatmaps_locations directory', elapsed_time=self.timer.elapsed_time_str)
+            stdout_success(msg=f'Heatmap location videos visualizations for {len(self.files_found)} videos created in project_folder/frames/output/heatmaps_locations directory', elapsed_time=self.timer.elapsed_time_str)
 
 # test = HeatMapperLocationMultiprocess(config_path='/Users/simon/Desktop/envs/troubleshooting/locomotion/project_folder/project_config.ini',
 #                                       style_attr = {'palette': 'jet', 'shading': 'gouraud', 'bin_size': 50, 'max_scale': 'auto'},
 #                                       final_img_setting=False,
 #                                       video_setting=True,
 #                                       frame_setting=False,
 #                                       bodypart='Nose',
@@ -310,12 +309,12 @@
 #                                       files_found=['/Users/simon/Desktop/envs/troubleshooting/locomotion/project_folder/csv/outlier_corrected_movement_location/PD1406_2022-05-24_RVDG_GCaMP8s-Gi_Video_Day_22_Baseline.csv'])
 # test.create_heatmaps()
 
 
 # test = HeatMapperLocationMultiprocess(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini',
 #                                       style_attr = {'palette': 'jet', 'shading': 'gouraud', 'bin_size': 50, 'max_scale': 'auto'},
 #                                       final_img_setting=True,
-#                                       video_setting=False,
+#                                       video_setting=True,
 #                                       frame_setting=False,
 #                                       bodypart='Nose_1', core_cnt=5,
 #                                       files_found=['/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/csv/machine_results/Together_1.csv'])
 # test.create_heatmaps()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/run_dash_tkinter.py` & `Simba-UW-tf-dev-1.57.6/simba/run_dash_tkinter.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/dash_app.py` & `Simba-UW-tf-dev-1.57.6/simba/dash_app.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/extract_annotation_frames.py` & `Simba-UW-tf-dev-1.57.6/simba/extract_annotation_frames.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,26 +1,28 @@
 import os.path
+import cv2
 from simba.mixins.config_reader import ConfigReader
-from simba.misc_tools import (find_video_of_file,
-                              get_fn_ext,
-                              get_video_meta_data)
+from simba.utils.read_write import read_df, find_video_of_file, get_fn_ext, get_video_meta_data
 from simba.utils.printing import stdout_success
-from simba.read_config_unit_tests import check_that_column_exist
-from simba.rw_dfs import read_df
 from simba.enums import Dtypes
 from simba.utils.errors import FrameRangeError
-import cv2
+from simba.utils.checks import check_that_column_exist
 
 
 class AnnotationFrameExtractor(ConfigReader):
     def __init__(self,
                  clfs: list,
                  settings: dict,
                  config_path=str):
 
+        """
+        Extracts all human annotated frames into .pngs within a SimBA project
+
+        """
+
         self.clfs = clfs
         self.settings = settings
         super().__init__(config_path=config_path)
 
     def run(self):
         if not os.path.exists(self.annotated_frm_dir): os.makedirs(self.annotated_frm_dir)
         for file_path in self.target_file_paths:
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/roi_tools/ROI_time_bin_calculator.py` & `Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_time_bin_calculator.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,25 +1,17 @@
-from datetime import datetime
-from simba.read_config_unit_tests import (read_config_entry,
-                                          read_config_file,
-                                          read_project_path_and_file_type)
-from simba.feature_extractors.unit_tests import (read_video_info_csv,
-                                               read_video_info)
 import os
 import pandas as pd
+import itertools
 from simba.roi_tools.ROI_analyzer import ROIAnalyzer
-from simba.misc_tools import (get_fn_ext,
-                              SimbaTimer,
-                              )
 from simba.utils.printing import stdout_success
-from simba.enums import ReadConfig, Paths, DirNames, Dtypes
-from simba.rw_dfs import read_df
-import itertools
+from simba.enums import ReadConfig, DirNames, Dtypes
+from simba.mixins.config_reader import ConfigReader
+from simba.utils.read_write import get_fn_ext, read_config_entry, read_df
 
-class ROITimebinCalculator(object):
+class ROITimebinCalculator(ConfigReader):
     """
     Class for calulating how much time and how many entries animals are making into user-defined ROIs
     in user-defined time bins. Results are stored in the `project_folder/logs` directory of the SimBA project.
 
     Parameters
     ----------
     config_path: str
@@ -29,49 +21,42 @@
 
     Notes
     ----------
 
     Examples
     ----------
     >>> roi_time_bin_calculator = ROITimebinCalculator(config_path='MySimBaConfigPath', bin_length=15)
-    >>> roi_time_bin_calculator.analyze_time_bins()
+    >>> roi_time_bin_calculator.run()
     >>> roi_time_bin_calculator.save_results()
     """
 
     def __init__(self,
                  config_path: str,
                  bin_length: int):
 
-        self.config_path, self.bin_length = config_path, bin_length
-        self.date_time = datetime.now().strftime('%Y%m%d%H%M%S')
-        self.config = read_config_file(config_path)
-        self.project_path, self.file_type = read_project_path_and_file_type(config=self.config)
+        ConfigReader.__init__(self, config_path=config_path)
+        self.bin_length = bin_length
         self.roi_animal_cnt = read_config_entry(config=self.config, section=ReadConfig.ROI_SETTINGS.value, option=ReadConfig.ROI_ANIMAL_CNT.value, data_type=Dtypes.INT.value)
         self.probability_threshold = read_config_entry(config=self.config, section=ReadConfig.ROI_SETTINGS.value, option=ReadConfig.PROBABILITY_THRESHOLD.value, data_type=Dtypes.FLOAT.value,default_value=0.00)
-        self.logs_path = os.path.join(self.project_path, 'logs')
-        self.save_path_time = os.path.join(self.logs_path, 'ROI_time_bins_{}s_time_data_{}.csv'.format(str(bin_length), self.date_time))
-        self.save_path_entries = os.path.join(self.logs_path, 'ROI_time_bins_{}s_entry_data_{}.csv'.format(str(bin_length), self.date_time))
-        self.video_info_df = read_video_info_csv(file_path=os.path.join(self.project_path, Paths.VIDEO_INFO.value))
+        self.save_path_time = os.path.join(self.logs_path, 'ROI_time_bins_{}s_time_data_{}.csv'.format(str(bin_length), self.datetime))
+        self.save_path_entries = os.path.join(self.logs_path, 'ROI_time_bins_{}s_entry_data_{}.csv'.format(str(bin_length), self.datetime))
         self.roi_analyzer = ROIAnalyzer(ini_path=self.config_path, data_path=DirNames.OUTLIER_MOVEMENT_LOCATION.value, calculate_distances=False)
-        self.roi_analyzer.read_roi_dfs()
-        self.roi_analyzer.analyze_ROIs()
+        self.roi_analyzer.run()
         self.shape_names = self.roi_analyzer.shape_names
         self.animal_names = list(self.roi_analyzer.bp_dict.keys())
         self.entries_exits_df = self.roi_analyzer.detailed_df
-        self.timer = SimbaTimer()
-        self.timer.start_timer()
 
-    def analyze_time_bins(self):
+    def run(self):
         self.files_found = self.roi_analyzer.files_found
         self.out_dict_time, self.out_dict_entries = {}, {}
         print('Analyzing time-bin data for {} videos...'.format(str(len(self.files_found))))
         for file_cnt, file_path in enumerate(self.files_found):
             _, self.video_name, _ = get_fn_ext(filepath=file_path)
             self.out_dict_time[self.video_name], self.out_dict_entries[self.video_name] = {}, {}
-            _, _, fps = read_video_info(vid_info_df=self.video_info_df, video_name=self.video_name)
+            _, _, fps = self.read_video_info(video_name=self.video_name)
             frames_per_bin = int(fps * self.bin_length)
             video_frms = list(range(0, len(read_df(file_path=file_path, file_type=self.file_type))))
             frame_bins = [video_frms[i * frames_per_bin:(i + 1) * frames_per_bin] for i in range((len(video_frms) + frames_per_bin - 1) // frames_per_bin )]
             self.video_data = self.entries_exits_df[self.entries_exits_df['VIDEO'] == self.video_name]
             for animal_name, shape_name in list(itertools.product(self.animal_names, self.shape_names)):
                 self.results_time, self.results_entries = {}, {}
                 self.results_time[shape_name], self.results_entries[shape_name] = {}, {}
@@ -111,9 +96,9 @@
 
 # test = ROITimebinCalculator(config_path='/Users/simon/Desktop/troubleshooting/train_model_project/project_folder/project_config.ini',bin_length=5)
 # test.analyze_time_bins()
 # test.save_results()
 
 
 # test = ROITimebinCalculator(config_path=r"/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini",bin_length=5)
-# test.analyze_time_bins()
+# test.run()
 # test.save_results()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/roi_tools/ROI_movement_analyzer.py` & `Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_movement_analyzer.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,19 +1,15 @@
 __author__ = "Simon Nilsson", "JJ Choong"
 
-
-from datetime import datetime
-from simba.read_config_unit_tests import (read_config_file,
-                                          read_project_path_and_file_type)
-from simba.misc_tools import SimbaTimer
-from simba.utils.printing import stdout_success
 import os
+from simba.utils.printing import stdout_success
+from simba.mixins.config_reader import ConfigReader
 from simba.roi_tools.ROI_analyzer import ROIAnalyzer
 
-class ROIMovementAnalyzer(object):
+class ROIMovementAnalyzer(ConfigReader):
     """
 
     Class for computing movements of individual animals within individual user-defined ROIs.
 
     Parameters
     ----------
     config_path: str
@@ -27,22 +23,17 @@
     ----------
     >>> _ = ROIMovementAnalyzer(config_path='MyProjectConfig')
     """
 
     def __init__(self,
                  config_path: str):
 
-        self.timer = SimbaTimer()
-        self.timer.start_timer()
-        self.config = read_config_file(config_path)
-        self.datetime = datetime.now().strftime('%Y%m%d%H%M%S')
-        self.project_path, self.file_type = read_project_path_and_file_type(config=self.config)
+        ConfigReader.__init__(self, config_path=config_path)
         self.roi_analyzer = ROIAnalyzer(ini_path=config_path, data_path='outlier_corrected_movement_location', calculate_distances=True)
-        self.roi_analyzer.read_roi_dfs()
-        self.roi_analyzer.analyze_ROIs()
+        self.roi_analyzer.run()
         self.save_data()
 
     def save_data(self):
         """
         Save ROI movement analysis. Results are stored in the ``project_folder/logs`` directory
         of the SimBA project.
 
@@ -51,8 +42,8 @@
         None
         """
         save_path = os.path.join(self.roi_analyzer.logs_path, 'ROI_movement_data_' + self.roi_analyzer.datetime + '.csv')
         self.roi_analyzer.movements_df.to_csv(save_path)
         self.timer.stop_timer()
         stdout_success('ROI movement data saved in the "project_folder/logs/" directory', elapsed_time=self.timer.elapsed_time_str)
 
-#test = ROIMovementAnalyzer(config_path='/Users/simon/Desktop/train_model_project/project_folder/project_config.ini')
+#test = ROIMovementAnalyzer(config_path='/Users/simon/Desktop/envs/troubleshooting/two_animals_16bp_032023/project_folder/project_config.ini')
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/roi_tools/.DS_Store` & `Simba-UW-tf-dev-1.57.6/simba/roi_tools/.DS_Store`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/roi_tools/ROI_define.py` & `Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_define.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,30 +1,27 @@
 import copy
 import os, glob
 from tkinter import *
-from configparser import ConfigParser
 import cv2
 from simba.roi_tools.ROI_image import ROI_image_class
 import pandas as pd
 from simba.tkinter_functions import hxtScrollbar
 from simba.roi_tools.ROI_move_shape import (update_all_tags, move_edge)
 from simba.roi_tools.ROI_multiply import create_emty_df
 from simba.roi_tools.ROI_size_calculations import (rectangle_size_calc,
                                                    circle_size_calc,
                                                    polygon_size_calc)
-from simba.misc_tools import get_color_dict
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.drop_bp_cords import get_fn_ext
-from simba.feature_extractors.unit_tests import read_video_info_csv
-from simba.enums import Paths, ReadConfig
+from simba.utils.read_write import get_fn_ext
 from simba.utils.warnings import NoDataFoundWarning
 from simba.utils.printing import stdout_success
+from simba.utils.lookups import get_color_dict
+from simba.mixins.config_reader import ConfigReader
 
 
-class ROI_definitions:
+class ROI_definitions(ConfigReader):
     """
     Class for creating ROI user-interface for drawing user-defined shapes in a video.
 
     Parameters
     ----------
     config_path: str
         path to SimBA project config file in Configparser format
@@ -41,50 +38,34 @@
 
     """
 
     def __init__(self,
                  config_path: str,
                  video_path: str):
 
-        self.config_path = config_path
-        config = ConfigParser()
-        config.read(config_path)
+        ConfigReader.__init__(self, config_path=config_path)
         self.video_path = video_path
         _, self.file_name, self.file_ext = get_fn_ext(self.video_path)
-        self.project_path = config.get(ReadConfig.GENERAL_SETTINGS.value, ReadConfig.PROJECT_PATH.value)
-        self.roi_data_folder = os.path.join(self.project_path, 'logs', 'measures')
-        if not os.path.exists(self.roi_data_folder):
-            os.makedirs(self.roi_data_folder)
-        self.store_fn = os.path.join(self.roi_data_folder, 'ROI_definitions.h5')
-        self.video_info_path = os.path.join(self.project_path, Paths.VIDEO_INFO.value)
-        self.video_folder_path = os.path.join(self.project_path, 'videos')
-        self.other_video_paths = glob.glob(self.video_folder_path + '/*.mp4') + glob.glob(self.video_folder_path + '/*.avi')
+        self.roi_data_folder = os.path.join(self.logs_path, 'measures')
+        if not os.path.exists(self.roi_data_folder): os.makedirs(self.roi_data_folder)
+        self.other_video_paths = glob.glob(self.video_dir + '/*.mp4') + glob.glob(self.video_dir + '/*.avi')
         self.other_video_paths.remove(video_path)
         self.other_video_file_names = []
         for video in self.other_video_paths:
             self.other_video_file_names.append(os.path.basename(video))
         self.master_win_h, self.master_win_w = 800, 750
-
-        try:
-            self.video_info_df = read_video_info_csv(self.video_info_path)
-        except Exception as e:
-            print(e.args)
-            NoDataFoundWarning(msg='Could not find the video parameters file. Make sure you have defined the video parameters in the [Video parameters] tab')
-        self.video_info, self.curr_px_mm, self.curr_fps = read_video_info(self.video_info_df, self.file_name)
+        self.video_info, self.curr_px_mm, self.curr_fps = self.read_video_info(video_name=self.file_name)
         self.master = Tk()
         self.master.minsize(self.master_win_w, self.master_win_h)
         self.screen_width = self.master.winfo_screenwidth()
         self.screen_height = self.master.winfo_screenheight()
         self.default_top_left_x = self.screen_width - self.master_win_w
         self.master.geometry('%dx%d+%d+%d' % (self.master_win_w, self.master_win_h, self.default_top_left_x, 0))
         self.master.wm_title("Region of Interest Settings")
 
-
-
-
         self.shape_thickness_list = list(range(1, 26))
         self.ear_tag_size_list = list(range(1, 26))
         self.select_color = 'red'
         self.non_select_color = 'black'
         self.video_ROIs = ['None']
         self.c_shape = None
         self.stored_interact = None
@@ -114,15 +95,15 @@
                                           self.duplicate_jump_size, self.line_type, self.click_sens, self.text_size, self.text_thickness,
                                           self.master_win_h, self.master_win_w)
         self.video_frame_count = int(self.image_data.video_frame_count)
         self.get_all_ROI_names()
         if len(self.video_ROIs) > 0:
             self.update_delete_ROI_menu()
 
-        mainloop()
+        self.master.mainloop()
 
     def show_video_info(self):
         self.video_info_frame = LabelFrame(self.master, text='Video information', font=("Arial", 14, "bold"), padx=5, pady=5)
         self.video_info_frame.grid_configure(ipadx=55)
         self.video_name_lbl_1 = Label(self.video_info_frame, text="Video name: ", font=("Arial", 10)).grid(row=0, column=0)
         self.video_name_lbl_2 = Label(self.video_info_frame, text=str(self.file_name), font=("Arial", 10, "bold"))
 
@@ -194,17 +175,17 @@
 
         self.video_frame_lbl_2.config(text = str(self.img_no))
         self.video_frame_time_2.config(text = str(round((self.img_no / self.curr_fps), 2)))
         self.image_data.update_frame_no(self.img_no)
 
     def get_other_videos_w_data(self):
         self.other_videos_w_ROIs = []
-        if os.path.isfile(self.store_fn):
+        if os.path.isfile(self.roi_coordinates_path):
             for shape_type in ['rectangles', 'circleDf', 'polygons']:
-                c_df = pd.read_hdf(self.store_fn, key=shape_type)
+                c_df = pd.read_hdf(self.roi_coordinates_path, key=shape_type)
                 if len(c_df) > 0:
                     self.other_videos_w_ROIs = list(set(self.other_videos_w_ROIs + list(c_df['Video'].unique())))
         if len(self.other_videos_w_ROIs) == 0:
             self.other_videos_w_ROIs = ['None']
 
     def get_all_ROI_names(self):
         self.video_ROIs = []
@@ -215,17 +196,17 @@
                 self.video_ROIs.append(shape_type + ': ' + shape_name)
 
 
 
     def apply_rois_from_other_video(self):
         target_video = self.selected_other_video.get()
         if target_video != 'None':
-            if os.path.isfile(self.store_fn):
+            if os.path.isfile(self.roi_coordinates_path):
                 for shape_type in ['rectangles', 'circleDf', 'polygons']:
-                    c_df = pd.read_hdf(self.store_fn, key=shape_type)
+                    c_df = pd.read_hdf(self.roi_coordinates_path, key=shape_type)
                     if len(c_df) > 0:
                         c_df = c_df[c_df['Video'] == target_video].reset_index(drop=True)
                         c_df['Video'] = self.file_name
                         c_df = c_df.to_dict('records')
                         if shape_type == 'rectangles':
                             for r in c_df:
                                 self.image_data.out_rectangles.append(r)
@@ -515,15 +496,15 @@
             self.new_shape_x = int(self.current_shape_data['centerX'] + self.duplicate_jump_size)
             self.new_shape_y = int(self.current_shape_data['centerY'] + self.duplicate_jump_size)
             for shape in self.image_data.out_circles:
                 if (shape['centerY'] == self.new_shape_x) and (shape['centerY'] == self.new_shape_y):
                     self.new_shape_x += self.duplicate_jump_size
                     self.new_shape_y += self.duplicate_jump_size
         if self.shape_type == 'Polygon':
-            self.new_shape_x = int(self.current_shape_data['centerY'] + self.duplicate_jump_size)
+            self.new_shape_x = int(self.current_shape_data['centerX'] + self.duplicate_jump_size)
             self.new_shape_y = int(self.current_shape_data['centerY'] + self.duplicate_jump_size)
             for shape in self.image_data.out_polygon:
                 if (shape['Center_X'] == self.new_shape_x) and (shape['centerY'] == self.new_shape_y):
                     self.new_shape_x += self.duplicate_jump_size
                     self.new_shape_y += self.duplicate_jump_size
 
     def call_duplicate_ROI(self):
@@ -585,18 +566,18 @@
 
     def update_delete_ROI_menu(self):
         self.selected_video.set(self.video_ROIs[0])
         self.roi_dropdown = OptionMenu(self.draw_frame, self.selected_video, *self.video_ROIs)
         self.roi_dropdown.grid(row=1, column=4, sticky=W, pady=10)
 
     def save_data(self):
-        if os.path.isfile(self.store_fn):
-            rectangles_found = pd.read_hdf(self.store_fn, key='rectangles')
-            circles_found = pd.read_hdf(self.store_fn, key='circleDf')
-            polygons_found = pd.read_hdf(self.store_fn, key='polygons')
+        if os.path.isfile(self.roi_coordinates_path):
+            rectangles_found = pd.read_hdf(self.roi_coordinates_path, key='rectangles')
+            circles_found = pd.read_hdf(self.roi_coordinates_path, key='circleDf')
+            polygons_found = pd.read_hdf(self.roi_coordinates_path, key='polygons')
             other_vid_rectangles = rectangles_found[rectangles_found['Video'] != self.file_name]
             other_vid_circles = circles_found[circles_found['Video'] != self.file_name]
             other_vid_polygons = polygons_found[polygons_found['Video'] != self.file_name]
 
             new_rectangles = pd.DataFrame.from_dict(self.image_data.out_rectangles)
             new_circles = pd.DataFrame.from_dict(self.image_data.out_circles)
             new_polygons = pd.DataFrame.from_dict(self.image_data.out_polygon)
@@ -625,20 +606,20 @@
                 out_rectangles = create_emty_df('rectangles')
             if len(out_circles) == 0:
                 out_circles = create_emty_df('circleDf')
             if len(out_polygons) == 0:
                 out_polygons = create_emty_df('polygons')
 
 
-        store = pd.HDFStore(self.store_fn, mode='w')
+        store = pd.HDFStore(self.roi_coordinates_path, mode='w')
         store['rectangles'] = out_rectangles
         store['circleDf'] = out_circles
         store['polygons'] = out_polygons
         store.close()
-        stdout_success(msg='ROI definitions saved for video: {self.file_name}')
+        stdout_success(msg=f'ROI definitions saved for video: {self.file_name}')
 
     class ChangeAttrMenu:
         def __init__(self, shape_data, image_data):
             shape_name = shape_data.selected_video.get().split(': ')
             if shape_name[0] != 'None':
                 self.all_roi_list = shape_data.image_data.out_rectangles + shape_data.image_data.out_circles + shape_data.image_data.out_polygon
                 self.shape_type, self.shape_name = shape_name[0], shape_name[1]
@@ -698,16 +679,16 @@
                         e['Color name'] = new_shape_color
                         e['Color BGR'] = shape_data.named_shape_colors[new_shape_color]
                         shape_data.video_ROIs = [w.replace(str(shape_type) + ': ' + self.shape_name, str(shape_type) + ': ' + new_shape_name) for w in shape_data.video_ROIs]
             image_data.insert_all_ROIs_into_image()
             shape_data.update_delete_ROI_menu()
             self.attr_win.destroy()
             self.attr_win.update()
-
-
+#
+#
     def window_menus(self):
         menu = Menu(self.master)
         file_menu = Menu(menu)
         menu.add_cascade(label='File', menu=file_menu)
         file_menu.add_command(label='Preferences...', command=lambda:PreferenceMenu(self.image_data))
         file_menu.add_separator()
         file_menu.add_command(label='Exit', command=self.Exit)
@@ -769,12 +750,9 @@
         image_data.text_thickness = self.text_thickness.get()
         image_data.line_type = self.line_type.get()
         image_data.duplicate_jump_size = self.duplicate_jump_size.get()
         stdout_success(msg='Saved ROI preference settings.')
 
 
 
-#test = ROI_definitions(config_path='/Users/simon/Desktop/troubleshooting/Open_field_5/project_folder/project_config.ini', video_path='/Users/simon/Desktop/troubleshooting/Open_field_5/project_folder/videos/SI_DAY3_308_CD1_PRESENT_2.mp4')
-
-
-# class ROI_definitions:
-#     def __init__(self, config_path, video_path):
+#test = ROI_definitions(config_path='/Users/simon/Desktop/envs/simba_dev/tests/test_data/mouse_open_field/project_folder/project_config.ini',
+#                       video_path='/Users/simon/Desktop/envs/simba_dev/tests/test_data/mouse_open_field/project_folder/videos/Video1.mp4')
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/roi_tools/ROI_reset.py` & `Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_reset.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,17 +1,16 @@
 
 from tkinter import *
 import os
 from configparser import ConfigParser
 import pandas as pd
-from simba.drop_bp_cords import get_fn_ext
-from simba.enums import ReadConfig, Keys, Paths
-from simba.read_config_unit_tests import read_config_file
+from simba.utils.read_write import get_fn_ext, read_config_file
 from simba.utils.errors import NoROIDataError
-from simba.enums import Formats
+from simba.enums import Formats, ReadConfig, Keys, Paths
+from simba.utils.printing import stdout_trash
 
 def reset_video_ROIs(config_path, filename):
 
     _, file_name_wo_ext, VideoExtension = get_fn_ext(filename)
     config = ConfigParser()
     configFile = str(config_path)
     config.read(configFile)
@@ -47,24 +46,24 @@
 
     print('Deleted ROI record: ' + str(file_name_wo_ext))
     store.close()
 
 def delete_all_ROIs(config_path: str):
 
     def delete_file(config_path):
-        config = read_config_file(ini_path=config_path)
+        config = read_config_file(config_path=config_path)
         project_path = config.get(ReadConfig.GENERAL_SETTINGS.value, ReadConfig.PROJECT_PATH.value)
         roi_data_path = os.path.join(project_path, 'logs', Paths.ROI_DEFINITIONS.value)
 
         if not os.path.isfile(roi_data_path):
             raise NoROIDataError(msg=f'No ROI definitions exist in this SimBA project. Expected file at path {roi_data_path}')
         else:
             os.remove(roi_data_path)
             close_window()
-            print('SIMBA COMPLETE: All ROI definitions deleted in this SimBA project')
+            stdout_trash(msg=f'SIMBA COMPLETE: All ROI definitions deleted in this SimBA project ({roi_data_path})')
 
     def close_window():
         delete_confirm_win.destroy()
         delete_confirm_win.update()
 
     delete_confirm_win = Toplevel()
     delete_confirm_win.minsize(200, 200)
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/roi_tools/ROI_analyzer.py` & `Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_analyzer.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,23 +1,19 @@
 __author__ = "Simon Nilsson", "JJ Choong"
 
 import os, glob, itertools
 import numpy as np
 from shapely.geometry import Point, Polygon
-from simba.drop_bp_cords import getBpHeaders, get_fn_ext
-from simba.rw_dfs import read_df
 import pandas as pd
-from simba.misc_tools import find_animal_name_from_body_part_name
 from simba.utils.printing import stdout_success
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.enums import Paths, Keys, ReadConfig, Dtypes
+from simba.enums import ReadConfig, Dtypes
 from simba.mixins.config_reader import ConfigReader
-from simba.read_config_unit_tests import read_config_entry
-from simba.utils.errors import NoFilesFoundError, NoROIDataError, BodypartColumnNotFoundError
+from simba.utils.errors import NoFilesFoundError, BodypartColumnNotFoundError
 from simba.utils.warnings import NoDataFoundWarning
+from simba.utils.read_write import get_fn_ext, read_df, read_config_entry
 
 class ROIAnalyzer(ConfigReader):
     """
 
     Class for analyzing movements, entries, exits, and time-spent-in user-defined ROIs. Results are stored in the
     'project_folder/logs' directory of the SimBA project.
 
@@ -38,100 +34,72 @@
     ----------
     `ROI tutorials <https://github.com/sgoldenlab/simba/blob/master/docs/ROI_tutorial_new.md>`__.
 
     Examples
     ----------
     >>> settings = {'body_parts': {'Simon': 'Ear_left_1', 'JJ': 'Ear_left_2'}, 'threshold': 0.4}
     >>> roi_analyzer = ROIAnalyzer(ini_path='MyProjectConfig', data_path='outlier_corrected_movement_location', settings=settings, calculate_distances=True)
-    >>> roi_analyzer.read_roi_dfs()
-    >>> roi_analyzer.analyze_ROIs()
+    >>> roi_analyzer.run()
     >>> roi_analyzer.save_data()
     """
 
     def __init__(self,
                  ini_path: str,
                  data_path: str or None,
                  settings: dict or None = None,
                  calculate_distances: bool = False):
 
-        super().__init__(config_path=ini_path)
+        ConfigReader.__init__(self, config_path=ini_path)
         self.calculate_distances, self.settings = calculate_distances, settings
-        self.bp_headers = getBpHeaders(ini_path)
         if not os.path.exists(self.detailed_roi_data_dir): os.makedirs(self.detailed_roi_data_dir)
         if data_path != None:
             self.input_folder = os.path.join(self.project_path, 'csv', data_path)
             self.files_found = glob.glob(self.input_folder + '/*.' + self.file_type)
             if len(self.files_found) == 0:
-                raise NoFilesFoundError(msg=f'SIMBA ERROR: No data files found in {self.input_folder}')
+                raise NoFilesFoundError(msg=f'No data files found in {self.input_folder}')
 
         if not self.settings:
             self.roi_config = dict(self.config.items(ReadConfig.ROI_SETTINGS.value))
             if 'animal_1_bp' not in self.roi_config.keys():
                 raise BodypartColumnNotFoundError(msg='Please analyze ROI data FIRST.')
             self.settings = {}
             self.settings['threshold'] = read_config_entry(self.config, ReadConfig.ROI_SETTINGS.value, ReadConfig.PROBABILITY_THRESHOLD.value, Dtypes.FLOAT.value, 0.00)
             self.settings['body_parts'] = {}
             self.__check_that_roi_config_data_is_valid()
             for animal_name, bp in self.roi_bp_config.items():
                 self.settings['body_parts'][animal_name] = bp
 
         self.body_part_to_animal_lookup = {}
         for animal_cnt, body_part_name in self.settings['body_parts'].items():
-            animal_name = find_animal_name_from_body_part_name(bp_name=body_part_name, bp_dict=self.animal_bp_dict)
+            animal_name = self.find_animal_name_from_body_part_name(bp_name=body_part_name, bp_dict=self.animal_bp_dict)
             self.body_part_to_animal_lookup[animal_cnt] = animal_name
 
         self.bp_dict, self.bp_names = {}, []
         for animal_name, bp in self.settings['body_parts'].items():
             self.bp_dict[animal_name] = []
             self.bp_dict[animal_name].extend([f'{bp}_{"x"}', f'{bp}_{"y"}', f'{bp}_{"p"}'])
             self.bp_names.extend([f'{bp}_{"x"}', f'{bp}_{"y"}', f'{bp}_{"p"}'])
+        self.read_roi_data()
 
     def __check_that_roi_config_data_is_valid(self):
         all_bps = list(set([x[:-2] for x in self.bp_headers]))
         self.roi_bp_config = {}
         for k, v in self.roi_config.items():
             if ''.join([i for i in k if not i.isdigit()]) == 'animal__bp':
                 id = int(''.join(c for c in k if c.isdigit())) - 1
                 self.roi_bp_config[self.multi_animal_id_list[id]] = v
         for animal, bp in self.roi_bp_config.items():
             if bp not in all_bps:
                 raise BodypartColumnNotFoundError(msg=f'Project config setting [{ReadConfig.ROI_SETTINGS.value}][{animal}] is not a valid body-part. Please make sure you have analyzed ROI data.')
 
-    def read_roi_dfs(self):
-
-        """
-        Method to read in ROI definitions from SimBA project
-
-        Returns
-        -------
-        Attribute: pd.DataFrame
-            rectangles_df
-        Attribute: pd.DataFrame
-            circles_df
-        Attribute: pd.DataFrame
-            polygon_df
-        Attribute: list
-            shape_names
-        """
-
-
-        if not os.path.isfile(os.path.join(self.logs_path, Paths.ROI_DEFINITIONS.value)):
-            raise NoROIDataError(msg='SIMBA ERROR: No ROI definitions were found in your SimBA project. Please draw some ROIs before analyzing your ROI data')
-        else:
-            self.roi_h5_path = os.path.join(self.logs_path, Paths.ROI_DEFINITIONS.value)
-            self.rectangles_df = pd.read_hdf(self.roi_h5_path, key=Keys.ROI_RECTANGLES.value).dropna(how='any')
-            self.circles_df = pd.read_hdf(self.roi_h5_path, key=Keys.ROI_CIRCLES.value).dropna(how='any')
-            self.polygon_df = pd.read_hdf(self.roi_h5_path, key=Keys.ROI_POLYGONS.value).dropna(how='any')
-            self.shape_names = list(itertools.chain(self.rectangles_df['Name'].unique(), self.circles_df['Name'].unique(), self.polygon_df['Name'].unique()))
-
     def __get_bouts(self, lst=None):
         lst=list(lst)
         return lst[0], lst[-1]
 
-    def analyze_ROIs(self):
+    def run(self):
         """
         Method to analyze ROI statistics.
 
         Returns
         -------
         Attribute: list
             dist_lst, list of pd.DataFrame holding ROI-dependent movement statistics.
@@ -147,15 +115,15 @@
             video_shapes = list(itertools.chain(self.video_recs['Name'].unique(), self.video_circs['Name'].unique(), self.video_polys['Name'].unique()))
 
             if video_shapes == 0:
                 NoDataFoundWarning(msg=f'Skipping video {video_name}: No user-defined ROI data found for this video...')
                 continue
 
             else:
-                video_settings, pix_per_mm, self.fps = read_video_info(self.video_info_df, video_name)
+                video_settings, pix_per_mm, self.fps = self.read_video_info(video_name=video_name)
                 self.data_df = read_df(file_path, self.file_type).reset_index(drop=True)
                 self.data_df.columns = self.bp_headers
                 data_df_sliced = self.data_df[self.bp_names]
                 self.video_length_s = data_df_sliced.shape[0] / self.fps
                 for animal_name in self.bp_dict:
                     animal_df = self.data_df[self.bp_dict[animal_name]]
                     self.time_dict[video_name][animal_name], self.entries_dict[video_name][animal_name] = {}, {}
@@ -310,16 +278,15 @@
 
 
 # settings = {'body_parts': {'animal_1_bp': 'Ear_left_1', 'animal_2_bp': 'Ear_left_2', 'animal_3_bp': 'Ear_right_1',}, 'threshold': 0.4}
 # test = ROIAnalyzer(ini_path = r"/Users/simon/Desktop/envs/troubleshooting/two_animals_16bp_032023/project_folder/project_config.ini",
 #                    data_path = "outlier_corrected_movement_location",
 #                    settings=settings,
 #                    calculate_distances=True)
-# test.read_roi_dfs()
-# test.analyze_ROIs()
+# test.run()
 # test.save_data()
 
 
 # settings = {'body_parts': {'Simon': 'Ear_left_1', 'JJ': 'Ear_left_2'}, 'threshold': 0.4}
 # test = ROIAnalyzer(ini_path = r"/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini",
 #                    data_path = "outlier_corrected_movement_location",
 #                    settings=settings,
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/roi_tools/ROI_feature_analyzer.py` & `Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_feature_analyzer.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,28 +1,24 @@
 __author__ = "Simon Nilsson"
 
-from simba.roi_tools.ROI_directing_analyzer import DirectingROIAnalyzer
 import numpy as np
 import os, glob
-from simba.rw_dfs import read_df, save_df
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.misc_tools import (check_directionality_viable,
-                              find_animal_name_from_body_part_name,
-                              )
-from simba.utils.printing import stdout_success
-from simba.drop_bp_cords import createColorListofList, create_body_part_dictionary, get_fn_ext
-from simba.roi_tools.ROI_analyzer import ROIAnalyzer
 import itertools
 from copy import deepcopy
+from simba.utils.printing import stdout_success
+from simba.roi_tools.ROI_analyzer import ROIAnalyzer
+from simba.roi_tools.ROI_directing_analyzer import DirectingROIAnalyzer
 from simba.mixins.config_reader import ConfigReader
+from simba.mixins.feature_extraction_mixin import FeatureExtractionMixin
 from simba.utils.errors import NoFilesFoundError, NoROIDataError
 from simba.utils.warnings import NoFileFoundWarning
+from simba.utils.read_write import read_df, write_df, get_fn_ext
 
 
-class ROIFeatureCreator(ConfigReader):
+class ROIFeatureCreator(ConfigReader, FeatureExtractionMixin):
     """
     Class for computing features based on the relationships between the location of the animals and the location of
     user-defined ROIs.
 
     Parameters
     ----------
     config_path: str
@@ -31,29 +27,26 @@
     Notes
     ----------
     `ROI tutorials <https://github.com/sgoldenlab/simba/blob/master/docs/ROI_tutorial_new.md>`__.
 
     Examples
     ----------
     >>> roi_featurizer = ROIFeatureCreator(config_path='MyProjectConfig')
-    >>> roi_featurizer.analyze_ROI_data()
-    >>> roi_featurizer.save_new_features_files()
+    >>> roi_featurizer.run()
+    >>> roi_featurizer.save()
 
     """
 
     def __init__(self,
                  config_path: str,
                  settings: dict or None=None):
 
-        super().__init__(config_path=config_path)
-        self.color_lst_of_lst = createColorListofList(self.animal_cnt, int(len(self.x_cols) + 1))
-        self.animal_bp_dict = create_body_part_dictionary(self.multi_animal_status, self.multi_animal_id_list,
-                                                          self.animal_cnt, self.x_cols, self.y_cols, [],
-                                                          self.color_lst_of_lst)
-        self.roi_directing_viable = check_directionality_viable(self.animal_bp_dict)[0]
+        ConfigReader.__init__(self, config_path=config_path)
+        FeatureExtractionMixin.__init__(self, config_path=config_path)
+        self.roi_directing_viable = self.check_directionality_viable()[0]
         self.settings = settings
         if self.roi_directing_viable:
             print('Directionality calculations are VIABLE.')
             self.directing_analyzer = DirectingROIAnalyzer(config_path=config_path, data_path=self.outlier_corrected_dir, settings=settings)
         else:
             self.directing_analyzer = None
 
@@ -68,43 +61,42 @@
         if len(self.files_found) == 0:
             raise NoFilesFoundError(msg=f'SIMBA ERROR: No data files found in {self.outlier_corrected_dir}')
         self.features_files = glob.glob(self.features_dir + '/*.' + self.file_type)
         if len(self.features_files) == 0:
             NoFileFoundWarning(msg=f'No data files found in {self.features_dir}')
         print('Processing {} videos for ROI features...'.format(str(len(self.files_found))))
 
-    def analyze_ROI_data(self):
+    def run(self):
         """
         Method to run the ROI feature analysis
 
         Returns
         -------
         Attribute: dict
             data
         """
 
         self.roi_analyzer = ROIAnalyzer(ini_path=self.config_path,
                                         data_path=self.outlier_corrected_dir,
                                         calculate_distances=True,
                                         settings=self.settings)
         self.roi_analyzer.files_found = self.files_found
-        self.roi_analyzer.read_roi_dfs()
         self.all_shape_names = self.roi_analyzer.shape_names
-        self.roi_analyzer.analyze_ROIs()
+        self.roi_analyzer.run()
         self.roi_analyzer.compute_framewise_distance_to_roi_centroids()
         self.roi_distances_dict = self.roi_analyzer.roi_centroid_distance
         self.roi_entries_df = self.roi_analyzer.detailed_df
         if self.roi_directing_viable:
             self.directing_analyzer.calc_directing_to_ROIs()
             self.roi_direction_df = self.directing_analyzer.results_df
 
         self.data = {}
         for file_cnt, file_path in enumerate(self.features_files):
             _, self.video_name, _ = get_fn_ext(file_path)
-            _, _, self.fps = read_video_info(self.video_info_df, self.video_name)
+            _, _, self.fps = self.read_video_info(video_name=self.video_name)
             data_df = read_df(file_path, self.file_type)
             self.out_df = deepcopy(data_df)
             self.__process_within_rois()
             self.__distance_to_roi_centroids()
             if self.roi_directing_viable:
                 self.__process_directionality()
             self.data[self.video_name] = self.out_df
@@ -126,15 +118,15 @@
                     self.out_df.loc[inside_roi_idx, column_name] = 1
                 self.out_df[column_name + '_cumulative_time'] = self.out_df[column_name].cumsum() * float(1 / self.fps)
                 self.out_df[column_name + '_cumulative_percent'] = self.out_df[column_name].cumsum() / (self.out_df.index + 1)
                 self.out_df.replace([np.inf, -np.inf], 1, inplace=True)
         else:
             for animal_cnt, shape_name in itertools.product(list(self.settings['body_parts'].keys()), self.all_shape_names):
                 bp_name = self.settings['body_parts'][animal_cnt]
-                animal_name = find_animal_name_from_body_part_name(bp_name=self.settings['body_parts'][animal_cnt], bp_dict=self.animal_bp_dict)
+                animal_name = self.find_animal_name_from_body_part_name(bp_name=self.settings['body_parts'][animal_cnt], bp_dict=self.animal_bp_dict)
                 column_name = '{} {} {} {}'.format(shape_name, animal_name, bp_name, 'zone')
                 self.inside_roi_columns.append(column_name)
                 video_body_part_shape_df = self.roi_entries_df.loc[(self.roi_entries_df['VIDEO'] == self.video_name) &
                                                                    (self.roi_entries_df['SHAPE'] == shape_name) &
                                                                    (self.roi_entries_df['ANIMAL'] == animal_name) &
                                                                    (self.roi_entries_df['BODY-PART'] == bp_name)]
                 self.out_df[column_name] = 0
@@ -152,20 +144,20 @@
         if not self.settings:
             for animal_name, shape_name in itertools.product(self.multi_animal_id_list, self.all_shape_names):
                 column_name = '{} {} {}'.format(shape_name, animal_name, 'distance')
                 self.roi_distance_columns.append(column_name)
                 try:
                     video_animal_shape_df = video_distances[animal_name][shape_name]
                 except KeyError:
-                    raise NoROIDataError(msg='The ROI named {} could not be find in video {}'.format(shape_name, self.video_name))
+                    raise NoROIDataError(msg=f'The ROI named {shape_name} could not be find in video {self.video_name}. Draw the shape or remove the file from the SimBA project')
                 self.out_df[column_name] = video_animal_shape_df
         else:
             for animal_cnt, shape_name in itertools.product(list(self.settings['body_parts'].keys()), self.all_shape_names):
                 bp_name = self.settings['body_parts'][animal_cnt]
-                animal_name = find_animal_name_from_body_part_name(bp_name=self.settings['body_parts'][animal_cnt], bp_dict=self.animal_bp_dict)
+                animal_name = self.find_animal_name_from_body_part_name(bp_name=self.settings['body_parts'][animal_cnt], bp_dict=self.animal_bp_dict)
                 column_name = '{} {} {} {}'.format(shape_name, animal_name, bp_name, 'distance')
                 self.roi_distance_columns.append(column_name)
                 try:
                     video_animal_shape_df = video_distances[animal_cnt][shape_name]
                 except KeyError:
                     raise NoROIDataError(msg='The ROI named {} could not be find in video {}'.format(shape_name, self.video_name))
                 self.out_df[column_name] = video_animal_shape_df
@@ -180,34 +172,33 @@
                                                                  (video_directionality['Animal'] == animal_name)]
             if len(video_animal_shape_df) > 0:
                 directing_idx = list(video_animal_shape_df['Frame'])
                 self.out_df.loc[directing_idx, column_name] = 1
             else:
                 self.out_df[column_name] = 0
 
-    def save_new_features_files(self):
+    def save(self):
         """
         Method to save new featurized files inside the ``project_folder/csv/features_extracted`` directory
         of the SimBA project
 
         > Note: Method **overwrites** existing files in the project_folder/csv/features_extracted directory.
 
         Returns
         -------
         None
 
         """
 
         for video_name, video_data in self.data.items():
             save_path = os.path.join(self.features_dir, video_name + '.' + self.file_type)
-            save_df(video_data.fillna(0), self.file_type, save_path)
+            write_df(df=video_data.fillna(0), file_type=self.file_type, save_path=save_path)
             print('Created additional ROI features for {}...'.format(video_name))
         self.timer.stop_timer()
         stdout_success(msg='Created additional ROI features for files within the project_folder/csv/features_extracted directory', elapsed_time=self.timer.elapsed_time_str)
 
-
 # roi_featurizer = ROIFeatureCreator(config_path='/Users/simon/Desktop/envs/troubleshooting/two_animals_16bp_032023/project_folder/project_config.ini')
-# roi_featurizer.analyze_ROI_data()
-#roi_featurizer.save_new_features_files()
+# roi_featurizer.run()
+# roi_featurizer.save()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/roi_tools/ROI_size_calculations.py` & `Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_size_calculations.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/roi_tools/ROI_zoom.py` & `Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_zoom.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/roi_tools/ROI_directing_analyzer.py` & `Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_directing_analyzer.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,20 +1,19 @@
 __author__ = "Simon Nilsson", "JJ Choong"
 
 from simba.roi_tools.ROI_analyzer import ROIAnalyzer
 import pandas as pd
 from numba import jit, prange
 from copy import deepcopy
-from simba.drop_bp_cords import (checkDirectionalityCords,
-                                 get_fn_ext)
-from simba.misc_tools import (line_length_numba_to_static_location)
 import numpy as np
 from simba.mixins.config_reader import ConfigReader
+from simba.mixins.feature_extraction_mixin import FeatureExtractionMixin
+from simba.utils.read_write import get_fn_ext
 
-class DirectingROIAnalyzer(ConfigReader):
+class DirectingROIAnalyzer(ConfigReader, FeatureExtractionMixin):
     """
     Class for computing aggregate statistics for animals are directing towards ROIs.
 
     Parameters
     ----------
     config_path: str
         Path to SimBA project config file in Configparser format
@@ -31,19 +30,19 @@
     """
 
     def __init__(self,
                  config_path: str=None,
                  data_path: str=None,
                  settings: dict or None=None):
 
-        super().__init__(config_path=config_path)
+        ConfigReader.__init__(self, config_path=config_path)
+        FeatureExtractionMixin.__init__(self, config_path=config_path)
         self.roi_analyzer = ROIAnalyzer(ini_path=config_path, data_path=self.outlier_corrected_dir, settings=settings)
-        self.roi_analyzer.read_roi_dfs()
         self.files_found = deepcopy(self.roi_analyzer.files_found)
-        self.direct_bp_dict = checkDirectionalityCords(self.animal_bp_dict)
+        self.direct_bp_dict = self.check_directionality_cords()
 
     def __format_direction_data(self):
         x_min = np.minimum(self.direction_data[:, 1], self.nose_arr[:, 0])
         y_min = np.minimum(self.direction_data[:, 2], self.nose_arr[:, 1])
         delta_x = abs((self.direction_data[:, 1] - self.nose_arr[:, 0]) / 2)
         delta_y = abs((self.direction_data[:, 2] - self.nose_arr[:, 1]) / 2)
         x_middle, y_middle = np.add(x_min, delta_x), np.add(y_min, delta_y)
@@ -130,54 +129,54 @@
             results_df
         """
 
         self.results_lst = []
         for file_cnt, file_path in enumerate(self.files_found):
             _, self.video_name, _ = get_fn_ext(file_path)
             self.roi_analyzer.files_found = [file_path]
-            self.roi_analyzer.analyze_ROIs()
+            self.roi_analyzer.run()
             video_data_df = self.roi_analyzer.data_df
             for animal_name in self.roi_analyzer.multi_animal_id_list:
                 self.animal_name = animal_name
                 animal_bp_names = self.animal_bp_dict[animal_name]['X_bps'] + self.animal_bp_dict[animal_name]['Y_bps']
                 animal_data_df = video_data_df[animal_bp_names]
                 animal_direct_bps = self.direct_bp_dict[animal_name]
                 self.ear_left_arr = animal_data_df[[animal_direct_bps['Ear_left']['X_bps'], animal_direct_bps['Ear_left']['Y_bps']]].to_numpy()
                 self.ear_right_arr = animal_data_df[[animal_direct_bps['Ear_right']['X_bps'], animal_direct_bps['Ear_right']['Y_bps']]].to_numpy()
                 self.nose_arr = animal_data_df[[animal_direct_bps['Nose']['X_bps'], animal_direct_bps['Nose']['Y_bps']]].to_numpy()
                 for _, row in self.roi_analyzer.video_recs.iterrows():
                     self.shape_info = row
                     center_cord = ((int(row['topLeftX'] + (row['width'] / 2))), (int(row['topLeftY'] + (row['height'] / 2))))
                     self.center_cord = np.asarray(center_cord)
-                    self.direction_data = line_length_numba_to_static_location(left_ear_array=self.ear_left_arr,
-                                                                               right_ear_array=self.ear_right_arr,
-                                                                               nose_array=self.nose_arr,
-                                                                               target_array=self.center_cord)
+                    self.direction_data = self.jitted_line_crosses_to_static_targets(left_ear_array=self.ear_left_arr,
+                                                                                     right_ear_array=self.ear_right_arr,
+                                                                                     nose_array=self.nose_arr,
+                                                                                     target_array=self.center_cord)
                     self.bp_data = self.__format_direction_data()
                     eye_roi_intersections = pd.DataFrame(self.__find_roi_intersections(), columns=['ROI_edge_1_x', 'ROI_edge_1_y', 'ROI_edge_2_x', 'ROI_edge_2_y'])
                     self.bp_data = pd.concat([self.bp_data, eye_roi_intersections], axis=1)
                     self.results_lst.append(self.bp_data)
                 for _, row in self.roi_analyzer.video_circs.iterrows():
                     self.shape_info = row
                     self.center_cord = np.asarray((row['centerX'], row['centerY']))
-                    self.direction_data = line_length_numba_to_static_location(left_ear_array=self.ear_left_arr,
-                                                                               right_ear_array=self.ear_right_arr,
-                                                                               nose_array=self.nose_arr,
-                                                                               target_array=self.center_cord)
+                    self.direction_data = self.jitted_line_crosses_to_static_targets(left_ear_array=self.ear_left_arr,
+                                                                                     right_ear_array=self.ear_right_arr,
+                                                                                     nose_array=self.nose_arr,
+                                                                                     target_array=self.center_cord)
                     self.bp_data = self.__format_direction_data()
                     eye_roi_intersections = pd.DataFrame(self.__find_roi_intersections(), columns=['ROI_edge_1_x', 'ROI_edge_1_y', 'ROI_edge_2_x', 'ROI_edge_2_y'])
                     self.bp_data = pd.concat([self.bp_data, eye_roi_intersections], axis=1)
                     self.results_lst.append(self.bp_data)
                 for _, row in self.roi_analyzer.video_polys.iterrows():
                     self.shape_info = row
                     self.center_cord = np.asarray((row['Center_X'], row['Center_Y']))
-                    self.direction_data = line_length_numba_to_static_location(left_ear_array=self.ear_left_arr,
-                                                                               right_ear_array=self.ear_right_arr,
-                                                                               nose_array=self.nose_arr,
-                                                                               target_array=self.center_cord)
+                    self.direction_data = self.jitted_line_crosses_to_static_targets(left_ear_array=self.ear_left_arr,
+                                                                                     right_ear_array=self.ear_right_arr,
+                                                                                     nose_array=self.nose_arr,
+                                                                                     target_array=self.center_cord)
                     self.bp_data = self.__format_direction_data()
                     eye_roi_intersections = pd.DataFrame(self.__find_roi_intersections(), columns=['ROI_edge_1_x', 'ROI_edge_1_y', 'ROI_edge_2_x', 'ROI_edge_2_y'])
                     self.bp_data = pd.concat([self.bp_data, eye_roi_intersections], axis=1)
                     self.results_lst.append(self.bp_data)
         self.results_df = pd.concat(self.results_lst, axis=0)
 #
 # test = DirectingROIAnalyzer(config_path='/Users/simon/Desktop/envs/simba_dev/tests/test_data/mouse_open_field/project_folder/project_config.ini')
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/roi_tools/ROI_move_shape.py` & `Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_move_shape.py`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/roi_tools/ROI_menus.py` & `Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_menus.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,17 +2,16 @@
 from configparser import ConfigParser
 from tkinter import *
 import platform
 from simba.roi_tools.ROI_define import ROI_definitions
 from simba.roi_tools.ROI_reset import reset_video_ROIs
 from simba.roi_tools.ROI_multiply import multiply_ROIs
 from simba.tkinter_functions import CreateLabelFrameWithIcon
-from simba.enums import ReadConfig
+from simba.enums import ReadConfig, Keys, Links
 from simba.utils.errors import NoFilesFoundError
-from simba.enums import Keys, Links
 
 class ROI_menu:
     def __init__(self, config_path, new_roi=True):
         self.config_path = config_path
         config = ConfigParser()
         config.read(config_path)
         self.project_path = config.get(ReadConfig.GENERAL_SETTINGS.value, ReadConfig.PROJECT_PATH.value)
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/roi_tools/ROI_clf_calculator.py` & `Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_clf_calculator.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,30 +1,23 @@
 __author__ = "Simon Nilsson"
 
 import pandas as pd
-from simba.rw_dfs import read_df
 import numpy as np
 from shapely import geometry
 from shapely.geometry import Point, Polygon
-from datetime import datetime
-from simba.misc_tools import (get_fn_ext,
-                              detect_bouts,
-                              )
-from simba.utils.printing import stdout_success
 import os
-from simba.read_config_unit_tests import (read_config_entry,
-                                          check_that_column_exist,
-                                          check_if_filepath_list_is_empty)
-from simba.feature_extractors.unit_tests import read_video_info
-from simba.enums import Keys
+
+from simba.utils.data import detect_bouts
+from simba.utils.printing import stdout_success
 from simba.mixins.config_reader import ConfigReader
-from simba.utils.errors import (ROICoordinatesNotFoundError,
-                                NoChoosenClassifierError,
+from simba.utils.errors import (NoChoosenClassifierError,
                                 NoROIDataError)
 from simba.utils.warnings import ROIWarning, NoDataFoundWarning
+from simba.utils.read_write import get_fn_ext, read_config_entry, read_df
+from simba.utils.checks import check_that_column_exist, check_if_filepath_list_is_empty
 
 
 class ROIClfCalculator(ConfigReader):
     """
     Class for computing aggregate statistics of classification results within user-defined ROIs.
     results are stored in `project_folder/logs` directory of the SimBA project.
 
@@ -35,34 +28,23 @@
 
     Notes
     -----
     'GitHub tutorial <https://github.com/sgoldenlab/simba/blob/master/docs/Scenario2.md#part-4--analyze-machine-results`__.
 
     Examples
     -----
-    >>> clf_ROI_analyzer = clf_within_ROI(config_ini="MyConfigPath")
+    >>> clf_ROI_analyzer = ROIClfCalculator(config_ini="MyConfigPath")
     >>> clf_ROI_analyzer.run(behavior_list=['Attack', 'Sniffing'], ROI_dict_lists={'Rectangle': ['rec'], 'Circle': ['Stimulus 1', 'Stimulus 2', 'Stimulus 3']}, body_part_list=['Nose_1'], measurements=['Total time by ROI (s)', 'Started bouts by ROI (count)', 'Ended bouts by ROI (count)'])
     """
 
     def __init__(self,
                  config_ini: str):
 
-        super().__init__(config_path=config_ini)
-        body_parts_df = pd.read_csv(self.body_parts_path, names=['bodyparts'])
-        self.body_part_list = list(body_parts_df['bodyparts'])
-        if not os.path.isfile(self.roi_coordinates_path):
-            raise ROICoordinatesNotFoundError(expected_file_path=self.roi_coordinates_path)
-        self.rectangles_df = pd.read_hdf(self.roi_coordinates_path, key=Keys.ROI_RECTANGLES.value)
-        self.circles_df = pd.read_hdf(self.roi_coordinates_path, key=Keys.ROI_CIRCLES.value)
-        self.polygon_df = pd.read_hdf(self.roi_coordinates_path, key=Keys.ROI_POLYGONS.value)
-        self.ROI_str_name_list = []
-        for index, row in self.rectangles_df.iterrows(): self.ROI_str_name_list.append(row['Shape_type'] + ': ' + row['Name'])
-        for index, row in self.circles_df.iterrows(): self.ROI_str_name_list.append(row['Shape_type'] + ': ' + row['Name'])
-        for index, row in self.polygon_df.iterrows(): self.ROI_str_name_list.append(row['Shape_type'] + ': ' + row['Name'])
-        self.ROI_str_name_list = list(set(self.ROI_str_name_list))
+        ConfigReader.__init__(self, config_path=config_ini)
+        self.read_roi_data()
 
     def __inside_rectangle(self, bp_x, bp_y, top_left_x, top_left_y, bottom_right_x, bottom_right_y):
         """
         Private helper to calculate if body-part is inside a rectangle.
         """
         if (((top_left_x) <= bp_x <= (bottom_right_x)) and ((top_left_y) <= bp_y <= (bottom_right_y))):
             return 1
@@ -159,15 +141,14 @@
         body_part_col_names = []
         body_part_col_names_x, body_part_col_names_y = [], []
         for body_part in body_part_list:
             body_part_col_names.extend((body_part + '_x', body_part + '_y', body_part + '_p'))
             body_part_col_names_x.append(body_part + '_x')
             body_part_col_names_y.append(body_part + '_y')
         all_columns = body_part_col_names + self.behavior_list
-        self.date_time = datetime.now().strftime('%Y%m%d%H%M%S')
         self.results_dict = {}
 
         self.frame_counter_dict = {}
         for file_cnt, file_path in enumerate(self.machine_results_paths):
             _, self.video_name, ext = get_fn_ext(file_path)
             print('Analyzing {}....'.format(self.video_name))
             data_df = read_df(file_path, self.file_type)
@@ -175,15 +156,15 @@
                 check_that_column_exist(file_name=self.video_name, df=data_df, column_name=column)
             data_df = data_df[all_columns]
             self.results = data_df[self.behavior_list]
             shapes_in_video = len(self.rectangles_df.loc[(self.rectangles_df['Video'] == self.video_name)]) + len(self.circles_df.loc[(self.circles_df['Video'] == self.video_name)]) + len(self.polygon_df.loc[(self.polygon_df['Video'] == self.video_name)])
             if shapes_in_video == 0:
                 NoDataFoundWarning(msg='Skipping {self.video_name}: Video {self.video_name} has 0 user-defined ROI shapes.')
                 continue
-            _, _, self.fps = read_video_info(self.video_info_df, self.video_name)
+            _, _, self.fps = self.read_video_info(video_name=self.video_name)
             self.found_rois = []
             for roi_type, roi_data in self.ROI_dict_lists.items():
                 shape_info = pd.DataFrame()
                 for roi_name in roi_data:
                     if roi_type.lower() == 'rectangle':
                         shape_info = self.rectangles_df.loc[(self.rectangles_df['Video'] == self.video_name) & (self.rectangles_df['Shape_type'] == roi_type) & (self.rectangles_df['Name'] == roi_name)]
                     elif roi_type.lower() == 'circle':
@@ -217,27 +198,26 @@
                 self.__compute_agg_statistics(data=self.results)
         self.__organize_output_data()
 
     def __organize_output_data(self):
         """
         Helper to organize the results[dict] into a human-readable CSV file.
         """
-
         if len(self.results_dict.keys()) == 0:
-            raise NoROIDataError(msg='SIMBA ERROR: ZERO ROIs found the videos represented in the project_folder/csv/machine_results directory')
+            raise NoROIDataError(msg='ZERO ROIs found the videos represented in the project_folder/csv/machine_results directory')
         out_df = pd.DataFrame(columns=['VIDEO', 'CLASSIFIER', 'ROI', 'MEASUREMENT', 'VALUE'])
         for video_name, video_data in self.results_dict.items():
             for clf, clf_data in video_data.items():
                 for roi_name, roi_data in clf_data.items():
                     for measurement_name, mesurement_value in roi_data.items():
                         out_df.loc[len(out_df)] = [video_name, clf, roi_name, measurement_name, mesurement_value]
-        out_path = os.path.join(self.logs_path, 'Classification_time_by_ROI_{}.csv'.format(self.date_time))
+        out_path = os.path.join(self.logs_path, f'Classification_time_by_ROI_{self.datetime}.csv')
         out_df.to_csv(out_path)
         self.timer.stop_timer()
         stdout_success(msg=f'Classification data by ROIs saved in {out_path}.', elapsed_time=self.timer.elapsed_time_str)
 #
 # clf_ROI_analyzer = clf_within_ROI(config_ini="/Users/simon/Desktop/troubleshooting/train_model_project/project_folder/project_config.ini")
 # clf_ROI_analyzer.run(behavior_list=['Attack', 'Sniffing'], ROI_dict_lists={'Rectangle': ['rec'], 'Circle': ['Stimulus 1', 'Stimulus 2', 'Stimulus 3']}, body_part_list=['Nose_1'], measurements=['Total time by ROI (s)', 'Started bouts by ROI (count)', 'Ended bouts by ROI (count)'])
 #
 
-# clf_ROI_analyzer = clf_within_ROI(config_ini="/Users/simon/Desktop/envs/troubleshooting/Two_animals_16bps/project_folder/project_config.ini")
-# clf_ROI_analyzer.perform_ROI_clf_analysis(behavior_list=['Attack', 'Sniffing'], ROI_dict_lists={'Rectangle': ['DAMN'], 'Circle': [], 'Polygon': ['YOU_SUCK_SIMON']}, body_part_list=['Nose_1'], measurements=['Total time by ROI (s)', 'Started bouts by ROI (count)', 'Ended bouts by ROI (count)'])
+# test = ROIClfCalculator(config_ini="/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini")
+# test.run(behavior_list=['Attack', 'Sniffing'], ROI_dict_lists={'Rectangle': ['DAMN'], 'Circle': [], 'Polygon': ['YOU_SUCK_SIMON']}, body_part_list=['Nose_1'], measurements=['Total time by ROI (s)', 'Started bouts by ROI (count)', 'Ended bouts by ROI (count)'])
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/roi_tools/ROI_image.py` & `Simba-UW-tf-dev-1.57.6/simba/roi_tools/ROI_image.py`

 * *Files 0% similar despite different names*

```diff
@@ -4,17 +4,17 @@
 import itertools
 import numpy as np
 from configparser import ConfigParser
 import re
 from copy import deepcopy
 from simba.roi_tools.ROI_move_shape import move_edge, move_edge_align
 from simba.roi_tools.ROI_zoom import zoom_in
-from simba.drop_bp_cords import get_fn_ext
-from simba.misc_tools import add_missing_ROI_cols
 from simba.enums import ReadConfig, Keys, Paths
+from simba.utils.read_write import get_fn_ext
+from simba.utils.data import add_missing_ROI_cols
 
 class ROI_image_class():
     def __init__(self, config_path, video_path, img_no, colors_dict, master_top_left_x, duplicate_jump_size, line_type, click_sens, text_size, text_thickness, master_win_h, master_win_w):
         config = ConfigParser()
         configFile = str(config_path)
         config.read(configFile)
         self.project_path = config.get(ReadConfig.GENERAL_SETTINGS.value, ReadConfig.PROJECT_PATH.value)
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pose_importers/read_DANNCE_mat.py` & `Simba-UW-tf-dev-1.57.6/simba/pose_importers/read_DANNCE_mat.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 __author__ = "Simon Nilsson", "JJ Choong"
 
 import scipy.io
 import pandas as pd
 import ast
 import os, glob
 from configparser import ConfigParser, NoSectionError, NoOptionError
-from simba.rw_dfs import save_df
-from simba.drop_bp_cords import get_fn_ext
+from simba.utils.read_write import get_fn_ext, write_df
+
 
 def read_config(config_path):
     config = ConfigParser()
     config.read(str(config_path))
     project_path = config.get('General settings', 'project_path')
     output_path = os.path.join(project_path, 'csv', 'input_csv')
 
@@ -44,18 +44,18 @@
     output_path, wfileType = read_config(config_path)
     files_found = glob.glob(folder_path + '/*.mat')
     for file in files_found:
         dir_name, file_name, ext = get_fn_ext(file)
         out_df = read_data(file)
         out_df = insert_multi_index_header(out_df)
         out_path_name = os.path.join(output_path, file_name + '.' + wfileType)
-        save_df(out_df, wfileType, out_path_name)
+        write_df(out_df, wfileType, out_path_name)
         print('Imported: ' + str(os.path.basename(file)))
 
 def import_DANNCE_file(config_path, file_path, interpolation_method):
     output_path, wfileType = read_config(config_path)
     dir_name, file_name, ext = get_fn_ext(file_path)
     out_df = read_data(file_path)
     out_df = insert_multi_index_header(out_df)
     out_path_name = os.path.join(output_path, file_name + '.' + wfileType)
-    save_df(out_df, wfileType, out_path_name)
+    write_df(out_df, wfileType, out_path_name)
     print('Imported: ' + str(os.path.basename(file_path)))
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pose_importers/sleap_importer_slp.py` & `Simba-UW-tf-dev-1.57.6/simba/pose_importers/sleap_importer_slp.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,42 +1,30 @@
 __author__ = "Simon Nilsson"
 
 import itertools
-from configparser import ConfigParser
 import os, glob
 import numpy as np
 import h5py
-from simba.drop_bp_cords import (get_fn_ext,
-                                 createColorListofList,
-                                 create_body_part_dictionary,
-                                 getBpNames,
-                                 getBpHeaders)
-from simba.misc_tools import (find_video_of_file,
-                              check_multi_animal_status,
-                              smooth_data_gaussian,
-                              smooth_data_savitzky_golay,
-                              get_video_meta_data,
-                              )
-from simba.utils.printing import stdout_success
-from simba.read_config_unit_tests import (check_if_filepath_list_is_empty,
-                                          read_project_path_and_file_type,
-                                          read_config_file)
-from simba.enums import Paths, ReadConfig, Methods
-from simba.rw_dfs import read_df
 import json
 from collections import defaultdict
 import pandas as pd
 import cv2
 import random
-from simba.interpolate_pose import Interpolate
-import pyarrow.parquet as pq
-import pyarrow as pa
 
 
-class SLEAPImporterSLP(object):
+from simba.mixins.config_reader import ConfigReader
+from simba.interpolate_smooth import Smooth, Interpolate
+from simba.utils.read_write import get_fn_ext, find_video_of_file, get_video_meta_data, read_df, write_df
+from simba.utils.checks import check_if_filepath_list_is_empty
+from simba.utils.data import create_color_palettes
+from simba.enums import Paths, ReadConfig, Methods
+
+
+
+class SLEAPImporterSLP(ConfigReader):
     """
     Class for importing SLEAP pose-estimation data into a SimBA project.
 
     Parameters
     ----------
     config_path: str
         path to SimBA project config file in Configparser format
@@ -65,21 +53,18 @@
     def __init__(self,
                  project_path: str,
                  data_folder: str,
                  actor_IDs: list,
                  interpolation_settings: str,
                  smoothing_settings: dict):
 
-        self.ini_path = project_path
+        ConfigReader.__init__(self, config_path=project_path)
         self.interpolation_settings = interpolation_settings
         self.smoothing_settings = smoothing_settings
-        self.config = ConfigParser()
         self.actors_IDs = actor_IDs
-        self.config = read_config_file(ini_path=project_path)
-        self.project_path, self.file_format = read_project_path_and_file_type(config=self.config)
         self.video_folder = os.path.join(self.project_path, 'videos')
         self.files_found = glob.glob(data_folder + '/*.slp')
         check_if_filepath_list_is_empty(filepaths=self.files_found,
                                         error_msg='SIMBA ERROR: Zero .slp files found in {} directory'.format(data_folder))
         self.save_folder = os.path.join(self.project_path, Paths.INPUT_CSV.value)
         self.animals_no = len(self.actors_IDs)
         self.add_spacer = 2
@@ -88,22 +73,17 @@
         if self.pose_settings is Methods.USER_DEFINED.value:
             self.__update_config()
 
         print('Converting .SLP file(s) into SimBA dataframes...')
 
     def visualize_sleap(self):
         self.frame_number = 0
-        multi_animal_status, multi_animal_id_lst = check_multi_animal_status(self.config, self.animals_no)
-        Xcols, Ycols, Pcols = getBpNames(self.ini_path)
-        color_lst = createColorListofList(self.animals_no, len(self.analysis_dict['ordered_bps']))
-        self.animal_bp_dict = create_body_part_dictionary(multi_animal_status, multi_animal_id_lst, self.animals_no, Xcols, Ycols, [], color_lst)
-
         for file_path in self.save_paths_lst:
-            self.data_df = read_df(file_path, self.file_format)
-            self.data_df.columns = getBpHeaders(self.ini_path)
+            self.data_df = read_df(file_path, self.file_type)
+            self.data_df.columns = self.bp_headers
             _, video_name, _ = get_fn_ext(file_path)
             video_path = find_video_of_file(self.video_folder, video_name)
             self.cap = cv2.VideoCapture(video_path)
             self.cap.set(1, self.frame_number)
             if not self.cap.isOpened():
                 raise Exception('Can\'t open video file ' + video_path)
             self.video_meta_data = get_video_meta_data(video_path)
@@ -184,15 +164,15 @@
             print('Analysing {}{}'.format(os.path.basename(file_path), '...'))
             self.file_path = file_path
             in_h5 = h5py.File(file_path, 'r')
             self.video_counter = vdn_cnt
             self.sleap_dict = in_h5.visititems(self.__h5_to_dict)
             self.video_path = self.__get_provenance()
             self.video_dir, self.video_name, self.video_ext = get_fn_ext(self.video_path)
-            self.save_path = os.path.join(self.save_folder, self.video_name + '.{}'.format(self.file_format))
+            self.save_path = os.path.join(self.save_folder, self.video_name + '.{}'.format(self.file_type))
             self.__get_video_frame_cnt()
             self.analysis_dict['bp_names'] = []
             self.analysis_dict['ordered_ids'] = []
             self.analysis_dict['ordered_bps'] = []
             self.analysis_dict['xy_headers'] = []
             self.analysis_dict['xyp_headers'] = []
             self.analysis_dict['animals_in_each_frame'] = []
@@ -259,22 +239,21 @@
                 self.data_df.loc[frame_idx] = frame_lst
             except ValueError:
                 break
 
         self.data_df.fillna(0, inplace=True)
         self.__fill_missing_indexes()
         self.data_df.sort_index(inplace=True)
-        multi_animal_status, multi_animal_id_lst = check_multi_animal_status(self.config, self.animals_no)
+        self.check_multi_animal_status()
         if self.animals_no < 2:
-            multi_animal_status = False
-        Xcols, Ycols, Pcols = getBpNames(self.ini_path)
-        color_lst = createColorListofList(self.animals_no, len(self.analysis_dict['ordered_bps']))
-        self.animal_bp_dict = create_body_part_dictionary(multi_animal_status, multi_animal_id_lst, self.animals_no, Xcols, Ycols, [], color_lst)
+            self.multi_animal_status = False
+        color_lst = create_color_palettes(self.animals_no, len(self.analysis_dict['ordered_bps']))
+        self.animal_bp_dict = self.create_body_part_dictionary(self.multi_animal_status, self.multi_animal_id_list, self.animals_no, self.x_cols, self.x_cols, [], color_lst)
         self.__update_bp_headers_file()
-        self.__save_multi_index_header_df(df=self.data_df,filetype=self.file_format,savepath=self.save_path)
+        self.__save_multi_index_header_df(df=self.data_df, filetype=self.file_type, savepath=self.save_path)
         print('Re-organized {} for SimBA analysis...'.format(os.path.basename(self.save_path)))
 
     def __create_first_side_img(self):
         self.side_img = np.ones((int(self.video_meta_data['height'] / 1.5), self.video_meta_data['width'], 3))
         cv2.putText(self.side_img, 'Current video: ' + self.video_name, (10, int(self.spacing_scale)), cv2.FONT_HERSHEY_SIMPLEX, self.font_scale, (255, 255, 255), 2)
         cv2.putText(self.side_img, 'Can you assign identities based on the displayed frame ?', (10, int(self.spacing_scale * (self.add_spacer * 2))), cv2.FONT_HERSHEY_SIMPLEX, self.font_scale,(255, 255, 255), 2)
         cv2.putText(self.side_img, 'Press "x" to display new - random - frame', (10, int(self.spacing_scale * (self.add_spacer * 3))), cv2.FONT_HERSHEY_SIMPLEX, self.font_scale, (255, 255, 0), 2)
@@ -387,88 +366,37 @@
 
         Returns
         -------
         None
 
         """
 
-
-
         if self.interpolation_settings != 'None':
-            print('Interpolating missing values (Method: {} {} {}'.format(self.interpolation_settings, '...', ')'))
-            self.data_df = read_df(self.save_path, self.file_format)
-            interpolate_body_parts = Interpolate(self.ini_path, self.data_df)
-            interpolate_body_parts.detect_headers()
-            interpolate_body_parts.fix_missing_values(self.interpolation_settings)
-            interpolate_body_parts.reorganize_headers()
-            self.__save_multi_index_header_df(df=interpolate_body_parts.new_df, filetype=self.file_format, savepath=self.save_path)
-            print('Interpolation complete for video {}{}'.format(self.video_name, '...'))
+            print('Interpolating missing values in video {} (Method: {})...'.format(self.video_name, self.interpolation_settings))
+            _ = Interpolate(input_path=self.save_path, config_path=self.config_path, method=self.interpolation_settings, initial_import_multi_index=True)
 
     def perform_smothing(self):
         """
         Method to save perform smoothing of imported SLEAP data.
 
         Returns
         -------
         None
         """
 
-        if self.smoothing_settings['Method'] == 'Gaussian':
-            print('Performing Gaussian smoothing on video {}{}'.format(self.video_name, '...'))
-            time_window = self.smoothing_settings['Parameters']['Time_window']
-            smooth_data_gaussian(config=self.config, file_path=self.save_path, time_window_parameter=time_window)
-
-        if self.smoothing_settings['Method'] == 'Savitzky Golay':
-            print('Performing Savitzky Golay smoothing on video {}{}'.format(self.video_name, '...'))
-            time_window = self.smoothing_settings['Parameters']['Time_window']
-            smooth_data_savitzky_golay(config=self.config, file_path=self.save_path, time_window_parameter=time_window)
-#
-# test = ImportSLEAP(project_path=r"Z:\DeepLabCut\DLC_extract\Troubleshooting\test_slp_import\project_folder\project_config.ini",
-#             data_folder=r'Z:\DeepLabCut\DLC_extract\Troubleshooting\test_slp_import\data\slp',
-#             actor_IDs=['Mouse_1'],
-#             interpolation_settings="Body-parts: Nearest", #
-#             smoothing_settings = {'Method': 'Savitzky Golay', 'Parameters': {'Time_window': '200'}}) #Savitzky Golay
-# test.initate_import_slp()
-# if test.animals_no > 1:
-#     test.visualize_sleap()
-# test.save_df()
-# test.perform_interpolation()
-# test.perform_smothing()
-# print('All SLEAP imports complete.')
-#
-
-# test = ImportSLEAP(project_path="Z:\DeepLabCut\DLC_extract\Troubleshooting\SLEAP_9Test_2\project_folder\project_config.ini",
-#             data_folder='Z:\DeepLabCut\DLC_extract\Troubleshooting\SLEAP_9Test_2\data',
-#             actor_IDs=['Animal_1', 'Animal_2', 'Animal_3', 'Animal_4', 'Animal_5'],
-#             interpolation_settings="None", #
-#             smoothing_settings = {'Method': 'None', 'Parameters': {'Time_window': '200'}}) #Savitzky Golay
-# test.initate_import_slp()
-# if test.animals_no > 1:
-#     test.visualize_sleap()
-# test.save_df()
-# test.perform_interpolation()
-# test.perform_smothing()
-# print('All SLEAP imports complete.')
-
-#
-# test = ImportSLEAP(project_path='/Volumes/GoogleDrive/My Drive/GitHub/SLEAP_import_2/project_folder/project_config.ini',
-#             data_folder='/Volumes/GoogleDrive/My Drive/GitHub/SLEAP_import_2/data',
-#             actor_IDs=['Animal_1'],
-#             interpolation_settings="Body-parts: Nearest", #
-#             smoothing_settings = {'Method': 'Savitzky Golay', 'Parameters': {'Time_window': '200'}}) #Savitzky Golay
-# test.initate_import_slp()
-# if test.animals_no > 1:
-#     test.visualize_sleap()
-# test.save_df()
-# test.perform_interpolation()
-# test.perform_smothing()
-# print('All SLEAP imports complete.')
-#
+        if (self.smoothing_settings['Method'] == Methods.GAUSSIAN.value) or (self.smoothing_settings['Method'] == Methods.SAVITZKY_GOLAY.value):
+            print(f'Performing {self.smoothing_settings["Method"]} smoothing on video {self.video_name}...')
+            Smooth(config_path=self.config_path,
+                   input_path=self.save_path,
+                   time_window=int(self.smoothing_settings['Parameters']['Time_window']),
+                   smoothing_method=self.smoothing_settings['Method'],
+                   initial_import_multi_index=True)
+
 
-# test = ImportSLEAP(project_path="/Users/simon/Desktop/envs/troubleshooting/sleap_5_animals/project_folder/project_config.ini",
+# test = SLEAPImporterSLP(project_path="/Users/simon/Desktop/envs/troubleshooting/sleap_5_animals/project_folder/project_config.ini",
 #                    data_folder=r'/Users/simon/Desktop/envs/troubleshooting/sleap_5_animals/data',
 #                    actor_IDs=['Simon', 'Nastacia', 'JJ', 'Sam', 'Liana'],
 #                    interpolation_settings="Body-parts: Nearest",
 #                    smoothing_settings = {'Method': 'Savitzky Golay', 'Parameters': {'Time_window': '200'}}) #Savitzky Golay
 # test.initate_import_slp()
 # if test.animals_no > 1:
 #     test.visualize_sleap()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pose_importers/sleap_importer_h5.py` & `Simba-UW-tf-dev-1.57.6/simba/pose_importers/dlc_multi_animal_importer.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,237 +1,252 @@
-#### CODE COPIED FROM @Toshea111 - https://github.com/Toshea111/sleap/blob/develop/docs/notebooks/Convert_HDF5_to_CSV_updated.ipynb
+__author__ = "Simon Nilsson", "JJ Choong"
 
-import numpy as np
-import pandas as pd
-import h5py
 import os, glob
-from simba.read_config_unit_tests import (read_config_entry,
-                                          read_config_file,
-                                          check_if_filepath_list_is_empty,
-                                          read_project_path_and_file_type)
-from simba.misc_tools import (find_video_of_file,
-                              check_multi_animal_status,
-                              smooth_data_gaussian,
-                              smooth_data_savitzky_golay,
-                              get_video_meta_data,
-                              get_fn_ext,
-                              SimbaTimer,
-                              )
-from simba.utils.printing import stdout_success
-from simba.drop_bp_cords import (createColorListofList,
-                                 create_body_part_dictionary,
-                                 getBpNames,
-                                 getBpHeaders)
 from datetime import datetime
-from simba.enums import ReadConfig, Paths
 import itertools
+import pandas as pd
+import numpy as np
 import cv2
-from numba import jit, prange
 from copy import deepcopy
-from simba.interpolate_pose import Interpolate
-from simba.utils.warnings import InvalidValueWarning, InValidUserInputWarning
-import pyarrow.parquet as pq
-import pyarrow
 
+from simba.interpolate_smooth import Smooth, Interpolate
+from simba.utils.errors import InvalidFilepathError, NoFilesFoundError, BodypartColumnNotFoundError, InvalidInputError
+from simba.utils.warnings import InValidUserInputWarning, InvalidValueWarning
+from simba.mixins.config_reader import ConfigReader
+from simba.mixins.plotting_mixin import PlottingMixin
+from simba.utils.read_write import read_df, write_df, read_config_entry, get_video_meta_data, get_fn_ext, find_all_videos_in_project
+from simba.utils.checks import check_if_filepath_list_is_empty
+from simba.utils.printing import stdout_success
+from simba.enums import Paths, ReadConfig, Dtypes, Formats
+
+class MADLC_Importer(ConfigReader, PlottingMixin):
+    """
+    Class for importing multi-animal deeplabcut (maDLC) pose-estimation data (in H5 format)
+    into a SimBA project in parquet or CSV format.
+
+    Parameters
+    ----------
+    config_path: str
+        path to SimBA project config file in Configparser format
+    data_folder: str
+        Path to folder containing maDLC data in `.h5` format.
+    file_type: str
+        Method used to perform pose-estimation in maDLC. OPTIONS: `skeleton`, `box`, `ellipse`.
+    id_lst: list
+        Animal names.
+    interpolation_settings: str
+        String defining the pose-estimation interpolation method. OPTIONS: 'None', 'Animal(s): Nearest',
+        'Animal(s): Linear', 'Animal(s): Quadratic','Body-parts: Nearest', 'Body-parts: Linear',
+        'Body-parts: Quadratic'.
+    smoothing_settings: dict
+        Dictionary defining the pose estimation smoothing method. EXAMPLE: {'Method': 'Savitzky Golay',
+        'Parameters': {'Time_window': '200'}})
+
+    Notes
+    -----
+    `Multi-animal import tutorial <https://github.com/sgoldenlab/simba/blob/master/docs/Multi_animal_pose.md>`__.
+
+    Examples
+    -----
+    >>> madlc_importer =MADLC_Importer(config_path=r'MyConfigPath', data_folder=r'maDLCDataFolder', file_type='ellipse', id_lst=['Animal_1', 'Animal_2'], interpolation_settings='None', smoothing_settings={'Method': 'None', 'Parameters': {'Time_window': '200'}})
+    >>> madlc_importer.run()
+
+    References
+    ----------
+    .. [1] Lauer et al., Multi-animal pose estimation, identification and tracking with DeepLabCut, `Nature Methods`,
+           2022.
+    """
 
 
-class SLEAPImporterH5(object):
     def __init__(self,
                  config_path: str,
                  data_folder: str,
-                 actor_IDs: list,
+                 file_type: str,
+                 id_lst: list,
                  interpolation_settings: str,
                  smoothing_settings: dict):
 
-        self.timer = SimbaTimer()
-        self.timer.start_timer()
-        self.config = read_config_file(ini_path=config_path)
-        self.interpolation_settings = interpolation_settings
-        self.smoothing_settings = smoothing_settings
-        self.actors_IDs, self.config_path = actor_IDs, config_path
-        self.files_found = glob.glob(data_folder + '/*.h5')
-        check_if_filepath_list_is_empty(filepaths=self.files_found,
-                                        error_msg='SIMBA ERROR: Zero .h5 files found in {} directory'.format(data_folder))
-        self.project_path, self.file_type = read_project_path_and_file_type(config=self.config)
-        self.import_log_path = os.path.join(self.project_path, 'logs', f'data_import_log_{datetime.now().strftime("%Y%m%d%H%M%S")}.csv')
+        ConfigReader.__init__(self, config_path=config_path, read_video_info=False)
+        PlottingMixin.__init__(self)
+
+        self.interpolation_settings, self.smoothing_settings = interpolation_settings, smoothing_settings
+        self.input_folder, self.id_lst = data_folder, id_lst
+        self.import_log_path = os.path.join(self.logs_path, f'data_import_log_{datetime.now().strftime("%Y%m%d%H%M%S")}.csv')
+        self.videos_in_project = find_all_videos_in_project(videos_dir=self.video_dir)
+        self.videos_in_project_lower_case = [os.path.basename(x).lower() for x in self.videos_in_project]
         self.save_folder = os.path.join(self.project_path, Paths.INPUT_CSV.value)
-        self.animals_cnt = len(self.actors_IDs)
-        self.add_spacer = 2
-        self.x_cols, self.y_cols, self.p_cols = getBpNames(config_path)
-        self.video_dir = os.path.join(self.project_path, 'videos')
-        color_lst = createColorListofList(self.animals_cnt, len(self.x_cols))
-        self.space_scaler, self.radius_scaler, self.res_scaler, self.font_scaler, self.add_spacer, self.frame_no = 40, 10, 1500, 1.2, 2, 1
-        multi_animal_status, multi_animal_id_lst = check_multi_animal_status(self.config, self.animals_cnt)
-        self.bp_names_csv_path = os.path.join(self.project_path, Paths.BP_NAMES.value)
-        self.pose_settings = self.config.get(ReadConfig.CREATE_ENSEMBLE_SETTINGS.value, ReadConfig.POSE_SETTING.value)
-        if (self.pose_settings is 'user_defined'):
-            self.__update_config_animal_cnt()
-        self.animal_bp_dict = create_body_part_dictionary(multi_animal_status, self.actors_IDs, self.animals_cnt, self.x_cols, self.y_cols, self.p_cols, color_lst)
-        if self.animals_cnt > 1:
-            self.__update_bp_headers_file()
-            multi_animal_status, multi_animal_id_lst = check_multi_animal_status(self.config, self.animals_cnt)
-            self.x_cols, self.y_cols, self.p_cols = getBpNames(config_path)
-            self.animal_bp_dict = create_body_part_dictionary(multi_animal_status, self.actors_IDs, self.animals_cnt, self.x_cols, self.y_cols, self.p_cols, color_lst)
-        self.df_headers = getBpHeaders(inifile=config_path)
-
-    def __update_config_animal_cnt(self):
-        self.config.set(ReadConfig.GENERAL_SETTINGS.value, ReadConfig.ANIMAL_CNT.value, str(self.animals_cnt))
-        with open(self.project_path, "w+") as f:
-            self.config.write(f)
-        f.close()
-
-    @staticmethod
-    @jit(nopython=True)
-    def __transpose_multi_animal_data_table(data: np.array, idx: np.array, animal_cnt: int) -> np.array:
-        results = np.full((np.max(idx[:, 1]), data.shape[1]*animal_cnt), 0.0)
-        for i in prange(np.max(idx[:, 1])):
-            for j in prange(animal_cnt):
-                data_idx = np.argwhere((idx[:, 0] == j) & (idx[:, 1] == i)).flatten()
-                if len(data_idx) == 1:
-                    animal_frm_data = data[data_idx[0]]
-                else:
-                    animal_frm_data = np.full((data.shape[1]), 0.0)
-                results[i][j*animal_frm_data.shape[0]:j*animal_frm_data.shape[0]+animal_frm_data.shape[0]] = animal_frm_data
-        return results
+        self.pose_setting = read_config_entry(self.config, ReadConfig.CREATE_ENSEMBLE_SETTINGS.value, ReadConfig.POSE_SETTING.value, data_type=Dtypes.STR.value)
+        if file_type == 'skeleton':
+            dlc_file_ending, dlc_filtered_file_ending = 'sk.h5', 'sk_filtered.h5'
+        elif file_type == 'box':
+            dlc_file_ending, dlc_filtered_file_ending = 'bx.h5', 'bx_filtered.h5'
+        elif file_type == 'ellipse':
+            dlc_file_ending, dlc_filtered_file_ending = 'el.h5', 'el_filtered.h5'
+        else:
+            raise InvalidInputError(f'DLC FILETYPE {file_type} NOT SUPPORTED')
+        self.files_found = glob.glob(self.input_folder + '/*' + dlc_file_ending) + glob.glob(self.input_folder + '/*' + dlc_filtered_file_ending)
+        self.files_in_folder = glob.glob(self.input_folder + '/*')
+        if not self.multi_animal_status:
+            self.config.set('Multi animal IDs', 'id_list', '')
+            self.id_lst = ['Animal_1']
+            with open(self.config_path, 'w') as configfile:
+                self.config.write(configfile)
+        self.split_file_exts = list(itertools.product(*[Formats.DLC_NETWORK_FILE_NAMES.value, ['.mp4', '.avi']]))
+        self.space_scaler, self.radius_scaler, self.res_scaler, self.font_scaler = 40, 10, 1500, 1.2
+        self.bp_lst = []
+        for animal in self.animal_bp_dict.keys():
+            for currXcol, currYcol, currPcol in zip(self.animal_bp_dict[animal]['X_bps'], self.animal_bp_dict[animal]['Y_bps'], self.animal_bp_dict[animal]['P_bps']):
+                self.bp_lst.extend((animal + '_' + currXcol, animal + '_' + currYcol, animal + '_' + currPcol))
 
+        check_if_filepath_list_is_empty(filepaths=self.files_found,
+                                        error_msg='SIMBA ERROR: Found 0 files in {} path that satisfy the criterion for maDLC {} filetype. SimBA detected {} other files within in directory'.format(self.input_folder, file_type, str(len(self.files_in_folder))))
+        print('Importing {} file(s)...'.format(str(len(self.files_found))))
+
+    def __find_video_file(self):
+        assessed_file_paths, self.video_path = [], None
+        for combination in self.split_file_exts:
+            possible_vid_name = self.file_name.lower().split(combination[0])[0] + combination[1]
+            for video_cnt, video_name in enumerate(self.videos_in_project_lower_case):
+                if possible_vid_name == video_name:
+                    self.video_path = self.videos_in_project[video_cnt]
+                else:
+                    assessed_file_paths.append(possible_vid_name)
+        if self.video_path is None:
+            print(assessed_file_paths)
+            raise NoFilesFoundError(msg=f'SimBA searched your project_folder/videos directory for a video file representing {self.file_name}, and could not find a match. Above is a list of possible video filenames that SimBA searched for within your projects video directory without success.')
+        else:
+             _, self.video_basename, _ = get_fn_ext(self.video_path)
 
     def __insert_all_bps(self, frame=None):
         for animal, bp_data in self.img_bp_cords_dict.items():
             for bp_cnt, bp_tuple in enumerate(bp_data):
                 try:
                     cv2.circle(frame, bp_tuple, self.vid_circle_scale, self.animal_bp_dict[animal]['colors'][bp_cnt], -1, lineType=cv2.LINE_AA)
                 except Exception as err:
                     if type(err) == OverflowError:
-                        InvalidValueWarning(f'SimBA encountered a pose-estimated body-part located at pixel position {str(bp_tuple)}. This value is too large to be converted to an integer. Please check your pose-estimation data to make sure that it is accurate.')
+                        InvalidValueWarning(f'SimBA encountered a pose-estimated body-part located at pixel position {str(bp_tuple)}. '
+                              'This value is too large to be converted to an integer. '
+                              'Please check your pose-estimation data to make sure that it is accurate.')
                     print(err.args)
 
-
     def __create_first_side_img(self):
         side_img = np.ones((int(self.video_info['height'] / 2), self.video_info['width'], 3))
-        cv2.putText(side_img, 'Current video: ' + self.video_name, (10, self.vid_space_scale), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 255), 2)
+        cv2.putText(side_img, 'Current video: ' + self.video_basename, (10, self.vid_space_scale), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 255), 3)
         cv2.putText(side_img, 'Can you assign identities based on the displayed frame ?', (10, int(self.vid_space_scale * (self.add_spacer * 2))), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 255), 2)
-        cv2.putText(side_img, 'Press "x" to display new, random, frame', (10, int(self.vid_space_scale * (self.add_spacer * 3))), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 0), 2)
+        cv2.putText(side_img, 'Press "x" to display new, random, frame', (10, int(self.vid_space_scale * (self.add_spacer * 3))), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 0), 3)
         cv2.putText(side_img, 'Press "c" to continue to start assigning identities using this frame', (10, int(self.vid_space_scale * (self.add_spacer * 4))), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (0, 255, 0), 2)
         self.img_concat = np.uint8(np.concatenate((self.img_overlay, side_img), axis=0))
 
-    def __get_x_y_loc(self, event, x, y, flags, param):
-        if event == 7:
-            self.click_loc = (x,y)
-            self.ID_cords[self.animal_cnt] = {}
-            self.ID_cords[self.animal_cnt]['cord'] = self.click_loc
-            self.ID_cords[self.animal_cnt]['name'] = self.animal_name
-
-    def __insert_all_animal_names(self):
-        for animal_cnt, animal_data in self.ID_cords.items():
-            cv2.putText(self.new_frame, animal_data['name'], animal_data['cord'], cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, self.animal_bp_dict[animal_data['name']]['colors'][0], 2)
-
+    def create_choose_animals_side_img(self, animal_id):
+        self.side_img = np.ones((int(self.video_info['height'] / 2), self.video_info['width'], 3))
+        cv2.putText(self.side_img, 'Double left mouse click on:', (10, self.vid_space_scale), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 255), 2)
+        cv2.putText(self.side_img, animal_id, (10, int(self.vid_space_scale * (self.add_spacer * 2))), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 0), 2)
+        self.img_concat = np.uint8(np.concatenate((self.img_overlay, self.side_img), axis=0))
 
-    def __initiate_confirm(self):
+    def __initiate_choose_frame(self):
         cv2.destroyAllWindows()
+        self.cap.set(1, self.frame_no)
+        self.all_frame_data = self.data_df.loc[self.frame_no, :]
         cv2.namedWindow('Define animal IDs', cv2.WINDOW_NORMAL)
-        cv2.resizeWindow('Define animal IDs', self.video_info['height'], self.video_info['width'])
-        self.new_frame = deepcopy(self.img)
-        self.side_img = np.ones((int(self.video_info['height'] / 2), self.video_info['width'], 3))
-        cv2.putText(self.side_img, 'Current video: {}'.format(self.video_name), (10, int(self.vid_space_scale)), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 255), 3)
-        cv2.putText(self.side_img, 'Are you happy with your assigned identities ?', (10, int(self.vid_space_scale * (self.add_spacer * 2))), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 255), 2)
-        cv2.putText(self.side_img, 'Press "c" to continue (to finish, or proceed to the next video)', (10, int(self.vid_space_scale * (self.add_spacer * 3))), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 0), 2)
-        cv2.putText(self.side_img, 'Press "x" to re-start assigning identities', (10, int(self.vid_space_scale * (self.add_spacer * 4))), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (0, 255, 255), 2)
-        self.__insert_all_bps(frame=self.new_frame)
-        self.__insert_all_animal_names()
-        self.img_concat = np.uint8(np.concatenate((self.new_frame, self.side_img), axis=0))
+        self.img_bp_cords_dict = {}
+        ret, self.img = self.cap.read()
+        self.img_overlay = deepcopy(self.img)
+        for animal_cnt, (animal_name, animal_bps) in enumerate(self.animal_bp_dict.items()):
+            self.img_bp_cords_dict[animal_name] = []
+            for bp_cnt in range(len(animal_bps['X_bps'])):
+                x_cord = int(self.data_df.loc[self.frame_no, animal_name + '_' + animal_bps['X_bps'][bp_cnt]])
+                y_cord = int(self.data_df.loc[self.frame_no, animal_name + '_' + animal_bps['Y_bps'][bp_cnt]])
+                self.img_bp_cords_dict[animal_name].append((x_cord, y_cord))
+        self.__insert_all_bps(frame=self.img_overlay)
+        self.__create_first_side_img()
         cv2.imshow('Define animal IDs', self.img_concat)
         cv2.resizeWindow('Define animal IDs', self.video_info['height'], self.video_info['width'])
+
         keyboard_choice = False
         while not keyboard_choice:
             k = cv2.waitKey(20)
             if k == ord('x'):
                 cv2.destroyWindow('Define animal IDs')
                 cv2.waitKey(0)
                 self.frame_no += 50
                 self.__initiate_choose_frame()
                 break
             elif k == ord('c'):
-                cv2.destroyAllWindows()
+                cv2.destroyWindow('Define animal IDs')
                 cv2.waitKey(0)
+                self.__initiate_choose_animals()
                 break
 
+    def __get_x_y_loc(self, event, x, y, flags, param):
+        if event == 7:
+            self.click_loc = (x,y)
+            self.ID_cords[self.animal_cnt] = {}
+            self.ID_cords[self.animal_cnt]['cord'] = self.click_loc
+            self.ID_cords[self.animal_cnt]['name'] = self.animal_name
+
+    def __insert_all_animal_names(self):
+        for animal_cnt, animal_data in self.ID_cords.items():
+            cv2.putText(self.new_frame, animal_data['name'], animal_data['cord'], cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 255), 3)
+
     def __initiate_choose_animals(self):
         self.ID_cords = {}
         for animal_cnt, animal in enumerate(self.animal_bp_dict.keys()):
             self.new_overlay = deepcopy(self.img_overlay)
             cv2.namedWindow('Define animal IDs', cv2.WINDOW_NORMAL)
             self.animal_name = animal
             self.animal_cnt = animal_cnt
             self.side_img = np.ones((int(self.video_info['height'] / 2), self.video_info['width'], 3))
             cv2.putText(self.side_img, 'Double left mouse click on:', (10, self.vid_space_scale), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 255), 3)
             cv2.putText(self.side_img, animal, (10, int(self.vid_space_scale * (self.add_spacer * 2))), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 0), 3)
             for id in self.ID_cords.keys():
-                cv2.putText(self.new_overlay, self.ID_cords[id]['name'], self.ID_cords[id]['cord'], cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, self.animal_bp_dict[self.ID_cords[id]['name']]['colors'][0], 3)
+                cv2.putText(self.new_overlay, self.ID_cords[id]['name'], self.ID_cords[id]['cord'], cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 255), 3)
             self.new_overlay = np.uint8(np.concatenate((self.new_overlay, self.side_img), axis=0))
             cv2.imshow('Define animal IDs', self.new_overlay)
             cv2.resizeWindow('Define animal IDs', self.video_info['height'], self.video_info['width'])
             while animal_cnt not in self.ID_cords.keys():
                 cv2.setMouseCallback('Define animal IDs', self.__get_x_y_loc)
                 cv2.waitKey(200)
         self.__initiate_confirm()
 
-    def __initiate_choose_frame(self):
+    def __initiate_confirm(self):
         cv2.destroyAllWindows()
-        self.cap.set(1, self.frame_no)
-        self.all_frame_data = self.data_df.loc[self.frame_no, :]
         cv2.namedWindow('Define animal IDs', cv2.WINDOW_NORMAL)
-        self.img_bp_cords_dict = {}
-        ret, self.img = self.cap.read()
-        self.img_overlay = deepcopy(self.img)
-        for animal_cnt, (animal_name, animal_bps) in enumerate(self.animal_bp_dict.items()):
-            self.img_bp_cords_dict[animal_name] = []
-            for bp_cnt in range(len(animal_bps['X_bps'])):
-                x_cord = int(self.data_df.loc[self.frame_no, animal_bps['X_bps'][bp_cnt]])
-                y_cord = int(self.data_df.loc[self.frame_no, animal_bps['Y_bps'][bp_cnt]])
-                self.img_bp_cords_dict[animal_name].append((x_cord, y_cord))
-        self.__insert_all_bps(frame=self.img_overlay)
-        self.__create_first_side_img()
+        cv2.resizeWindow('Define animal IDs', self.video_info['height'], self.video_info['width'])
+        self.new_frame = deepcopy(self.img)
+        self.side_img = np.ones((int(self.video_info['height'] / 2), self.video_info['width'], 3))
+        cv2.putText(self.side_img, 'Current video: {}'.format(self.video_basename), (10, int(self.vid_space_scale)), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 255), 3)
+        cv2.putText(self.side_img, 'Are you happy with your assigned identities ?', (10, int(self.vid_space_scale * (self.add_spacer * 2))), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 255), 2)
+        cv2.putText(self.side_img, 'Press "c" to continue (to finish, or proceed to the next video)', (10, int(self.vid_space_scale * (self.add_spacer * 3))), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 0), 2)
+        cv2.putText(self.side_img, 'Press "x" to re-start assigning identities', (10, int(self.vid_space_scale * (self.add_spacer * 4))), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (0, 255, 255), 2)
+        self.__insert_all_bps(frame=self.new_frame)
+        self.__insert_all_animal_names()
+        self.img_concat = np.uint8(np.concatenate((self.new_frame, self.side_img), axis=0))
         cv2.imshow('Define animal IDs', self.img_concat)
         cv2.resizeWindow('Define animal IDs', self.video_info['height'], self.video_info['width'])
-
         keyboard_choice = False
         while not keyboard_choice:
             k = cv2.waitKey(20)
             if k == ord('x'):
                 cv2.destroyWindow('Define animal IDs')
                 cv2.waitKey(0)
-                self.frame_no = np.random.randint(0, self.video_info['frame_count']-1, size=1)[0]
+                self.frame_no += 50
                 self.__initiate_choose_frame()
                 break
             elif k == ord('c'):
-                cv2.destroyWindow('Define animal IDs')
+                cv2.destroyAllWindows()
                 cv2.waitKey(0)
-                self.__initiate_choose_animals()
                 break
 
-    def __update_bp_headers_file(self):
-        new_headers = []
-        for animal_name in self.animal_bp_dict.keys():
-            for bp in self.animal_bp_dict[animal_name]['X_bps']:
-                if animal_name not in bp:
-                    new_headers.append('{}_{}'.format(animal_name, bp[:-2]))
-                else:
-                    new_headers.append(bp[:-2])
-        new_bp_df = pd.DataFrame(new_headers)
-        new_bp_df.to_csv(self.bp_names_csv_path, index=False, header=False)
-
-
-
     def __check_intergity_of_order(self):
         for click_key_combination in itertools.combinations(list(self.animal_order.keys()), 2):
             click_n, click_n1 = click_key_combination[0], click_key_combination[1]
             animal_1, animal_2 = self.animal_order[click_n]['animal_name'], self.animal_order[click_n1]['animal_name']
             if animal_1 == animal_2:
-                InValidUserInputWarning(msg=f'The animal most proximal to click number {click_n} is animal named {animal_1}. The animal most proximal to click number {click_n1} is also animal {animal_2}. Please indicate which animal is which using a video frame where the animals are clearly separated')
-                raise ValueError()
+                InValidUserInputWarning(msg=f'The animal most proximal to click number {str(click_n)} is animal named {animal_1}. The animal most proximal to click number {str(click_n1)} is also animal {animal_2}.'
+                      'Please indicate which animal is which using a video frame where the animals are clearly separated')
             else:
                 pass
 
     def __find_closest_animals(self):
         self.animal_order = {}
         for animal_number, animal_click_data in self.ID_cords.items():
             animal_name, animal_cord = animal_click_data['name'], animal_click_data['cord']
@@ -239,177 +254,134 @@
             closest_animal['animal_name'] = None
             closest_animal['body_part_name'] = None
             closest_animal['distance'] = np.inf
             for other_animal_name, animal_bps in self.animal_bp_dict.items():
                 animal_bp_names_x = self.animal_bp_dict[other_animal_name]['X_bps']
                 animal_bp_names_y = self.animal_bp_dict[other_animal_name]['Y_bps']
                 for x_col, y_col in zip(animal_bp_names_x, animal_bp_names_y):
-                    bp_location = (int(self.all_frame_data[x_col]), int(self.all_frame_data[y_col]))
+                    bp_location = (int(self.all_frame_data['{}_{}'.format(other_animal_name, x_col)]), int(self.all_frame_data['{}_{}'.format(other_animal_name, y_col)]))
                     distance = np.sqrt((animal_cord[0] - bp_location[0]) ** 2 + (animal_cord[1] - bp_location[1]) ** 2)
                     if distance < closest_animal['distance']:
                         closest_animal['animal_name'] = other_animal_name
                         closest_animal['body_part_name'] = (x_col, y_col)
                         closest_animal['distance'] = distance
             self.animal_order[animal_number] = closest_animal
         self.__check_intergity_of_order()
 
     def __organize_df(self):
         self.out_df = pd.DataFrame()
         for animal_cnt, animal_data in self.animal_order.items():
             closest_animal_dict = self.animal_bp_dict[animal_data['animal_name']]
             x_cols, y_cols, p_cols = closest_animal_dict['X_bps'], closest_animal_dict['Y_bps'], closest_animal_dict['P_bps']
+            x_cols = [animal_data['animal_name'] + '_' + x for x in x_cols]
+            y_cols = [animal_data['animal_name'] + '_' + x for x in y_cols]
+            p_cols = [animal_data['animal_name'] + '_' + x for x in p_cols]
             for x_col, y_col, p_cols in zip(x_cols, y_cols, p_cols):
                 df = self.data_df[[x_col, y_col, p_cols]]
                 self.out_df = pd.concat([self.out_df, df], axis=1)
 
-    def __insert_multi_idx_header(self):
-        multi_index_columns = []
-        for column in range(len(self.data_df.columns)):
-            multi_index_columns.append(tuple(('SLEAP_multi', 'SLEAP_multi', self.data_df.columns[column])))
-        self.out_df.columns = pd.MultiIndex.from_tuples(multi_index_columns, names=['scorer', 'bodypart', 'coords'])
+        self.out_df.columns = self.bp_lst
+        print(self.animal_bp_dict)
+        for animal_name in self.id_lst:
+            for x_col, y_col in zip(self.animal_bp_dict[animal_name]['X_bps'], self.animal_bp_dict[animal_name]['Y_bps']):
+                self.out_df['{}_{}'.format(animal_name, x_col)] = self.out_df['{}_{}'.format(animal_name, x_col)].astype(int)
+                self.out_df['{}_{}'.format(animal_name, y_col)] = self.out_df['{}_{}'.format(animal_name, y_col)].astype(int)
 
+    def __insert_multi_idx_header(self):
+        multi_idx_cols = []
+        for col_idx in range(len(self.out_df.columns)):
+            multi_idx_cols.append(tuple(('DLC_multi', 'DLC_multi', self.out_df.columns[col_idx])))
+        self.out_df.columns = pd.MultiIndex.from_tuples(multi_idx_cols, names=('scorer', 'bodypart', 'coords'))
 
     def __save_df(self):
-        save_name = os.path.join(self.video_name + '.' + self.file_type)
-        self.save_path = os.path.join(self.save_folder, save_name)
-        if self.file_type == 'parquet':
-            table = pyarrow.Table.from_pandas(self.out_df)
-            pyarrow.parquet.write_table(table, self.save_path)
-        if self.file_type == 'csv':
-            self.out_df.to_csv(self.save_path)
+        self.save_path = os.path.join(os.path.join(self.save_folder, f'{self.video_basename }.{self.file_type}'))
+        write_df(df=self.out_df, file_type=self.file_type, save_path=self.save_path, multi_idx_header=True)
 
     def __run_interpolation(self):
-        print('Interpolating missing values in video {} (Method: {}) ...'.format(self.video_name, self.interpolation_settings))
-        if self.file_type == 'parquet':
-            data_df = pd.read_parquet(self.save_path)
-        if self.file_type == 'csv':
-            data_df = pd.read_csv(self.save_path, index_col=0)
-        interpolate_body_parts = Interpolate(self.config_path, data_df)
-        interpolate_body_parts.detect_headers()
-        interpolate_body_parts.fix_missing_values(self.interpolation_settings)
-        interpolate_body_parts.reorganize_headers()
-        if self.file_type == 'parquet':
-            table = pyarrow.Table.from_pandas(interpolate_body_parts.new_df)
-            pyarrow.parquet.write_table(table, self.save_path)
-        if self.file_type == 'csv':
-            interpolate_body_parts.new_df.to_csv(self.save_path)
+        print('Interpolating missing values in video {} (Method: {}) ...'.format(self.video_basename, self.interpolation_settings))
+        _ = Interpolate(input_path=self.save_path,config_path=self.config_path, method=self.interpolation_settings, initial_import_multi_index=True)
+
 
     def __run_smoothing(self):
-        if self.smoothing_settings['Method'] == 'Gaussian':
-            print('Performing Gaussian smoothing on video "{}" ...'.format(self.video_name))
-            time_window = self.smoothing_settings['Parameters']['Time_window']
-            smooth_data_gaussian(config=self.config, file_path=self.save_path, time_window_parameter=time_window)
-
-        if self.smoothing_settings['Method'] == 'Savitzky Golay':
-            print('Performing Savitzky Golay smoothing on video {}...'.format(self.video_name))
-            time_window = self.smoothing_settings['Parameters']['Time_window']
-            smooth_data_savitzky_golay(config=self.config, file_path=self.save_path, time_window_parameter=time_window)
+        print(f'Performing {self.smoothing_settings["Method"]} smoothing on video {self.video_basename}...')
+        Smooth(config_path=self.config_path,
+               input_path=self.save_path,
+               time_window=int(self.smoothing_settings['Parameters']['Time_window']),
+               smoothing_method=self.smoothing_settings['Method'],
+               initial_import_multi_index=True)
+
+    def run(self):
+        """
+        Method for initializing maDLC importing GUI.
+
+        Returns
+        ----------
+        None
 
+        """
 
-    def import_sleap(self):
         import_log = pd.DataFrame(columns=['VIDEO', 'IMPORT_TIME', 'IMPORT_SOURCE', 'INTERPOLATION_SETTING', 'SMOOTHING_SETTING'])
         for file_cnt, file_path in enumerate(self.files_found):
-            video_timer = SimbaTimer()
-            video_timer.start_timer()
-            _, self.video_name, _ = get_fn_ext(filepath=file_path)
-            print('Importing {}...'.format(self.video_name))
-
+            self.add_spacer = 2
+            _, self.file_name, _ = get_fn_ext(file_path)
+            print('Processing file {} ...'.format(self.file_name))
+            self.__find_video_file()
+            self.data_df = pd.read_hdf(file_path).replace([np.inf, -np.inf], np.nan).fillna(0)
             try:
-                with h5py.File(file_path, "r") as sleap_dict:
-                    data = {k: v[()] for k, v in sleap_dict.items()}
-                    data["node_names"] = [s.decode() for s in data["node_names"].tolist()]
-                    data["track_names"] = [s.decode() for s in data["track_names"].tolist()]
-                    data["tracks"] = np.transpose(data["tracks"])
-                    data["track_occupancy"] = data["track_occupancy"].astype(bool)
-            except OSError:
-                print('SIMBA WARNING: {} is not a valid H5 file. Skipping {}...'.format(self.video_name, file_path))
-
-            valid_frame_idxs = np.argwhere(data["track_occupancy"].any(axis=1)).flatten()
-            tracks = []
-            for frame_idx in valid_frame_idxs:
-                frame_tracks = data["tracks"][frame_idx]
-                for i in range(frame_tracks.shape[-1]):
-                    pts = frame_tracks[..., i]
-                    if np.isnan(pts).all():
-                        continue
-                    detection = {"track": data["track_names"][i], "frame_idx": frame_idx}
-                    for node_name, (x, y) in zip(data["node_names"], pts):
-                        detection[f"{node_name}.x"] = x
-                        detection[f"{node_name}.y"] = y
-                    tracks.append(detection)
-
-            self.data_df = pd.DataFrame(tracks).fillna(0)
-            idx = self.data_df.iloc[:, :2]
-            idx['track'] = pd.Categorical(idx['track'])
-            idx['track'] = idx['track'].cat.codes.astype(int)
-            self.data_df = self.data_df.iloc[:, 2:]
-            if self.animals_cnt > 1:
-                self.data_df = pd.DataFrame(self.__transpose_multi_animal_data_table(data=self.data_df.values, idx=idx.values, animal_cnt=self.animals_cnt))
-                p_df = pd.DataFrame(1.0, index=self.data_df.index, columns=self.data_df.columns[1::2] + .5)
-                self.data_df = pd.concat([self.data_df, p_df], axis=1).sort_index(axis=1)
-                self.data_df.columns = self.df_headers
-
-            else:
-                idx = list(idx.drop('track', axis=1)['frame_idx'])
-                self.data_df = self.data_df.set_index([idx]).sort_index()
-                self.data_df.columns = np.arange(len(self.data_df.columns))
-                self.data_df = self.data_df.reindex(range(self.data_df.index[0], self.data_df.index[-1] + 1), fill_value=0)
-                p_df = pd.DataFrame(1.0, index=self.data_df.index, columns=self.data_df.columns[1::2] + .5)
-                self.data_df = pd.concat([self.data_df, p_df], axis=1).sort_index(axis=1)
-                self.data_df.columns = self.df_headers
-                self.out_df = deepcopy(self.data_df)
-
-            if self.animals_cnt > 1:
-                self.video_path = find_video_of_file(video_dir=self.video_dir, filename=self.video_name)
-                self.video_info = get_video_meta_data(self.video_path)
-                self.max_video_dimension = max(self.video_info['width'], self.video_info['height'])
-                self.vid_circle_scale = int(self.radius_scaler / (self.res_scaler / self.max_video_dimension))
-                self.vid_font_scale = float(self.font_scaler / (self.res_scaler / self.max_video_dimension))
-                self.vid_space_scale = int(self.space_scaler / (self.res_scaler / self.max_video_dimension))
-                self.cap = cv2.VideoCapture(self.video_path)
-                self.__initiate_choose_frame()
-                self.cap.release()
-                self.__find_closest_animals()
-                self.__organize_df()
+                self.data_df.columns = self.bp_lst
+            except ValueError as err:
+                raise BodypartColumnNotFoundError(msg=f'SIMBA ERROR: The number of body-parts in the input file {file_path} do not match the number of body-parts in your SimBA project. '
+                      f'The number of of body-parts expected by your SimBA project is {str(len(self.x_cols))}. '
+                      f'The number of of body-parts contained in file {file_path} is {str(int(len(self.data_df.columns) / 3))}. '
+                      f'Make sure you have specified the correct number of animals and body-parts in your project.')
+            self.video_info = get_video_meta_data(self.video_path)
+            self.max_video_dimension = max(self.video_info['width'], self.video_info['height'])
+            self.vid_circle_scale = int(self.radius_scaler / (self.res_scaler / self.max_video_dimension))
+            self.vid_font_scale = float(self.font_scaler / (self.res_scaler / self.max_video_dimension))
+            self.vid_space_scale = int(self.space_scaler / (self.res_scaler / self.max_video_dimension))
+            self.frame_no = 1
+            self.cap = cv2.VideoCapture(self.video_path)
+            self.__initiate_choose_frame()
+            self.cap.release()
+            self.__find_closest_animals()
+            self.__organize_df()
             self.__insert_multi_idx_header()
             self.__save_df()
             if self.interpolation_settings != 'None':
                 self.__run_interpolation()
             if self.smoothing_settings['Method'] != 'None':
                 self.__run_smoothing()
-            video_timer.stop_timer()
-            import_log.loc[len(import_log)] = [self.video_name,
+            import_log.loc[len(import_log)] = [self.file_name,
                                                datetime.now().strftime('%Y%m%d%H%M%S'),
-                                               'SLEAP H5',
+                                               'MADLC',
                                                str(self.interpolation_settings),
                                                str(self.smoothing_settings)]
-            print('Video "{}" imported (elapsed time {}s)...'.format(self.video_name, video_timer.elapsed_time_str))
+            print('SimBA import of file {} complete!'.format(self.file_name))
 
         import_log.to_csv(self.import_log_path)
-        self.timer.stop_timer()
-        stdout_success(msg=f'{str(len(self.files_found))} file(s) imported to the SimBA project (project_folder/csv/input_csv directory', elapsed_time=self.timer.elapsed_time_str)
+        stdout_success(msg=f'{str(len(self.files_found))} files imported to your SimBA project. Imported files are located in the project_folder/csv/input_csv directory.')
 
-# test = SLEAPImporterH5(config_path="/Users/simon/Desktop/envs/troubleshooting/Termites_5/project_folder/project_config.ini",
-#                    data_folder=r'/Users/simon/Desktop/envs/troubleshooting/Termites_5/test',
-#                    actor_IDs=['Simon', 'Nastacia'],
-#                    interpolation_settings="Body-parts: Nearest",
+# test = MADLC_Importer(config_path=r'/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini',
+#                    data_folder=r'/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/h5',
+#                    file_type='ellipse',
+#                    id_lst=['Simon', 'JJ'],
+#                    interpolation_settings='Body-parts: Nearest',
 #                    smoothing_settings = {'Method': 'Savitzky Golay', 'Parameters': {'Time_window': '200'}})
-# test.import_sleap()
-# print('All SLEAP imports complete.')
+# test.run()
 
 
-# test = SLEAPImporterH5(config_path="/Users/simon/Desktop/envs/troubleshooting/sleap_cody/project_folder/project_config.ini",
-#                    data_folder=r'/Users/simon/Desktop/envs/troubleshooting/sleap_cody/import_h5',
-#                    actor_IDs=['Nastacia', 'Sam'],
-#                    interpolation_settings="Body-parts: Nearest",
-#                    smoothing_settings = {'Method': 'Savitzky Golay', 'Parameters': {'Time_window': '200'}})
-# test.import_sleap()
-# print('All SLEAP imports complete.')
-
 
-# test = SLEAPImporterH5(config_path="/Users/simon/Desktop/envs/troubleshooting/sleap_cody/project_folder/project_config.ini",
-#                    data_folder=r'/Users/simon/Desktop/envs/troubleshooting/sleap_cody/import_h5',
-#                    actor_IDs=['Nastacia'],
-#                    interpolation_settings="Body-parts: Nearest",
-#                    smoothing_settings = {'Method': 'Savitzky Golay', 'Parameters': {'Time_window': '200'}})
-# test.import_sleap()
-# # print('All SLEAP imports complete.')
+# test = MADLC_Importer(config_path=r'/Users/simon/Desktop/troubleshooting/B1-MS_US/project_folder/project_config.ini',
+#                    data_folder=r'/Users/simon/Desktop/troubleshooting/B1-MS_US/el_import/other_2',
+#                    file_type='ellipse',
+#                    id_lst=['MS', 'US'],
+#                    interpolation_settings='None',
+#                    smoothing_settings={'Method': 'None', 'Parameters': {'Time_window': '200'}})
+# test.import_data()
+
+# test = MADLC_Importer(config_path=r'/Users/simon/Desktop/troubleshooting/Soong/project_folder/project_config.ini',
+#                    data_folder=r'/Users/simon/Desktop/troubleshooting/Soong/import',
+#                    file_type='ellipse',
+#                    id_lst=['Animal1'],
+#                    interpolation_settings='None',
+#                    smoothing_settings={'Method': 'None', 'Parameters': {'Time_window': '200'}})
+# test.import_data()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pose_importers/dlc_multi_animal_importer.py` & `Simba-UW-tf-dev-1.57.6/simba/pose_importers/sleap_importer_h5.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,283 +1,207 @@
-__author__ = "Simon Nilsson", "JJ Choong"
+#### CODE COPIED FROM @Toshea111 - https://github.com/Toshea111/sleap/blob/develop/docs/notebooks/Convert_HDF5_to_CSV_updated.ipynb
 
-from simba.read_config_unit_tests import (read_config_entry,
-                                          read_config_file,
-                                          check_if_filepath_list_is_empty,
-                                          read_project_path_and_file_type)
+import numpy as np
+import pandas as pd
+import h5py
 import os, glob
-from simba.misc_tools import (check_multi_animal_status,
-                              get_video_meta_data,
-                              smooth_data_gaussian,
-                              smooth_data_savitzky_golay,
-                              )
-from simba.utils.printing import stdout_success
-from simba.drop_bp_cords import (getBpNames,
-                                 get_fn_ext,
-                                 createColorListofList,
-                                 create_body_part_dictionary)
-from simba.utils.warnings import InvalidValueWarning
-from simba.enums import Paths, ReadConfig, Dtypes
-from datetime import datetime
 import itertools
-import pandas as pd
-import numpy as np
 import cv2
-from simba.interpolate_pose import Interpolate
+from numba import jit, prange
 from copy import deepcopy
-import pyarrow.parquet as pq
-import pyarrow
-from simba.utils.errors import InvalidFilepathError, NoFilesFoundError, BodypartColumnNotFoundError
-from simba.utils.warnings import InValidUserInputWarning
-
-class MADLC_Importer(object):
-    """
-    Class for importing multi-animal deeplabcut (maDLC) pose-estimation data (in H5 format)
-    into a SimBA project in parquet or CSV format.
-
-    Parameters
-    ----------
-    config_path: str
-        path to SimBA project config file in Configparser format
-    data_folder: str
-        Path to folder containing maDLC data in `.h5` format.
-    file_type: str
-        Method used to perform pose-estimation in maDLC. OPTIONS: `skeleton`, `box`, `ellipse`.
-    id_lst: list
-        List of animal names.
-    interpolation_settings: str
-        String defining the pose-estimation interpolation method. OPTIONS: 'None', 'Animal(s): Nearest',
-        'Animal(s): Linear', 'Animal(s): Quadratic','Body-parts: Nearest', 'Body-parts: Linear',
-        'Body-parts: Quadratic'.
-    smoothing_settings: dict
-        Dictionary defining the pose estimation smoothing method. EXAMPLE: {'Method': 'Savitzky Golay',
-        'Parameters': {'Time_window': '200'}})
-
-    Notes
-    -----
-    `Multi-animal import tutorial <https://github.com/sgoldenlab/simba/blob/master/docs/Multi_animal_pose.md>`__.
-
-    Examples
-    -----
-    >>> madlc_importer =MADLC_Importer(config_path=r'MyConfigPath', data_folder=r'maDLCDataFolder', file_type='ellipse', id_lst=['Animal_1', 'Animal_2'], interpolation_settings='None', smoothing_settings={'Method': 'None', 'Parameters': {'Time_window': '200'}})
-    >>> madlc_importer.import_data()
-
-    References
-    ----------
-    .. [1] Lauer et al., Multi-animal pose estimation, identification and tracking with DeepLabCut, `Nature Methods`,
-           2022.
-    """
 
+from simba.mixins.config_reader import ConfigReader
+from simba.interpolate_smooth import Smooth, Interpolate
+from simba.utils.warnings import InvalidValueWarning, InValidUserInputWarning
+from simba.utils.errors import BodypartColumnNotFoundError
+from simba.enums import ReadConfig, Methods
+from simba.utils.read_write import find_video_of_file, get_fn_ext, get_video_meta_data, write_df
+from simba.utils.checks import check_if_filepath_list_is_empty
+from simba.utils.printing import stdout_success, SimbaTimer
 
+
+
+class SLEAPImporterH5(ConfigReader):
     def __init__(self,
                  config_path: str,
                  data_folder: str,
-                 file_type: str,
-                 id_lst: list,
+                 actor_IDs: list,
                  interpolation_settings: str,
                  smoothing_settings: dict):
 
-        self.config_path = config_path
-        self.config = read_config_file(config_path)
-        self.interpolation_settings = interpolation_settings
-        self.smoothing_settings = smoothing_settings
-        self.input_folder = data_folder
-        self.id_lst = id_lst
-        self.project_path, self.file_type = read_project_path_and_file_type(config=self.config)
-        self.animal_cnt = read_config_entry(self.config, ReadConfig.GENERAL_SETTINGS.value, ReadConfig.ANIMAL_CNT.value, Dtypes.INT.value)
-        self.video_folder = os.path.join(self.project_path, 'videos')
-        self.import_log_path = os.path.join(self.project_path, 'logs', f'data_import_log_{datetime.now().strftime("%Y%m%d%H%M%S")}.csv')
-        self.videos_in_project = self.__find_all_videos_in_project(self.video_folder)
-        self.videos_in_project_lower_case = [os.path.basename(x).lower() for x in self.videos_in_project]
-        self.save_folder = os.path.join(self.project_path, Paths.INPUT_CSV.value)
-        self.pose_setting = read_config_entry(self.config, ReadConfig.CREATE_ENSEMBLE_SETTINGS.value, ReadConfig.POSE_SETTING.value, data_type=Dtypes.STR.value)
-        if file_type == 'skeleton': dlc_file_ending, dlc_filtered_file_ending = 'sk.h5', 'sk_filtered.h5'
-        elif file_type == 'box': dlc_file_ending, dlc_filtered_file_ending = 'bx.h5', 'bx_filtered.h5'
-        elif file_type == 'ellipse': dlc_file_ending, dlc_filtered_file_ending = 'el.h5', 'el_filtered.h5'
-        else: raise ValueError('SIMBA ERROR: DLC FILETYPE {} NOT SUPPORTED'.format(file_type))
-        self.files_found = glob.glob(self.input_folder + '/*' + dlc_file_ending) + glob.glob(self.input_folder + '/*' + dlc_filtered_file_ending)
-        self.files_in_folder = glob.glob(self.input_folder + '/*')
-        self.multi_animal_status, self.multi_animal_ids = check_multi_animal_status(self.config, self.animal_cnt)
-        if not self.multi_animal_status:
-            self.config.set('Multi animal IDs', 'id_list', '')
-            self.id_lst = ['Animal_1']
-            with open(self.config_path, 'w') as configfile:
-                self.config.write(configfile)
-        self.x_cols, self.y_cols, self.pcols = getBpNames(config_path)
-        self.clr_lst_of_lst = createColorListofList(self.animal_cnt, int(len(self.x_cols) / self.animal_cnt) + 1)
-        self.animal_bp_dict = create_body_part_dictionary(self.multi_animal_status, self.multi_animal_ids, self.animal_cnt, self.x_cols, self.y_cols, self.pcols, self.clr_lst_of_lst)
-        self.split_file_exts = list(itertools.product(*[['dlc_resnet50', 'dlc_resnet_50', 'dlc_dlcrnetms5', 'dlc_effnet_b0', 'dlc_resnet101'], ['.mp4', '.avi']]))
-        self.space_scaler, self.radius_scaler, self.res_scaler, self.font_scaler = 40, 10, 1500, 1.2
-        self.bp_lst = []
-        for animal in self.animal_bp_dict.keys():
-            for currXcol, currYcol, currPcol in zip(self.animal_bp_dict[animal]['X_bps'], self.animal_bp_dict[animal]['Y_bps'], self.animal_bp_dict[animal]['P_bps']):
-                self.bp_lst.extend((animal + '_' + currXcol, animal + '_' + currYcol, animal + '_' + currPcol))
-
+        ConfigReader.__init__(self, config_path=config_path)
+        self.interpolation_settings, self.smoothing_settings, self.actor_IDs = interpolation_settings, smoothing_settings, actor_IDs
+        self.files_found = glob.glob(data_folder + '/*.h5')
         check_if_filepath_list_is_empty(filepaths=self.files_found,
-                                        error_msg='SIMBA ERROR: Found 0 files in {} path that satisfy the criterion for maDLC {} filetype. SimBA detected {} other files within in directory'.format(self.input_folder, file_type, str(len(self.files_in_folder))))
-        print('Importing {} file(s)...'.format(str(len(self.files_found))))
-
-    def __find_all_videos_in_project(self, folder_path=None):
-        video_paths = []
-        file_paths_in_folder = [f for f in next(os.walk(folder_path))[2] if not f[0] == '.']
-        file_paths_in_folder = [os.path.join(self.video_folder, f) for f in file_paths_in_folder]
-        for file_cnt, file_path in enumerate(file_paths_in_folder):
-            try:
-                _, file_name, file_ext = get_fn_ext(file_path)
-            except ValueError:
-                raise InvalidFilepathError(msg='{} is not a valid filepath'.format(file_path))
-            if (file_ext.lower() == '.mp4') or (file_ext.lower() == '.avi'):
-                video_paths.append(file_path)
-        if len(video_paths) == 0:
-            raise NoFilesFoundError(msg='No videos in mp4 or avi format imported to SimBA project')
-        else:
-            return video_paths
-
-    def __find_video_file(self):
-        assessed_file_paths, self.video_path = [], None
-        for combination in self.split_file_exts:
-            possible_vid_name = self.file_name.lower().split(combination[0])[0] + combination[1]
-            for video_cnt, video_name in enumerate(self.videos_in_project_lower_case):
-                if possible_vid_name == video_name:
-                    self.video_path = self.videos_in_project[video_cnt]
+                                        error_msg='Zero .h5 files found in {} directory'.format(data_folder))
+        self.import_log_path = os.path.join(self.project_path, 'logs', f'data_import_log_{self.datetime}.csv')
+        self.add_spacer = 2
+        self.space_scaler, self.radius_scaler, self.res_scaler, self.font_scaler, self.add_spacer, self.frame_no = 40, 10, 1500, 1.2, 2, 1
+        if (self.pose_setting is Methods.USER_DEFINED.value):
+            self.__update_config_animal_cnt()
+        if self.animal_cnt > 1:
+            self.__update_bp_headers_file()
+            self.check_multi_animal_status()
+            self.animal_bp_dict = self.create_body_part_dictionary(self.multi_animal_status, self.multi_animal_id_list, self.animal_cnt, self.x_cols, self.y_cols, self.p_cols, self.clr_lst)
+
+    def __update_config_animal_cnt(self):
+        self.config.set(ReadConfig.GENERAL_SETTINGS.value, ReadConfig.ANIMAL_CNT.value, str(self.animal_cnt))
+        with open(self.project_path, "w+") as f:
+            self.config.write(f)
+        f.close()
+
+    @staticmethod
+    @jit(nopython=True)
+    def __transpose_multi_animal_data_table(data: np.array, idx: np.array, animal_cnt: int) -> np.array:
+        results = np.full((np.max(idx[:, 1]), data.shape[1]*animal_cnt), 0.0)
+        for i in prange(np.max(idx[:, 1])):
+            for j in prange(animal_cnt):
+                data_idx = np.argwhere((idx[:, 0] == j) & (idx[:, 1] == i)).flatten()
+                if len(data_idx) == 1:
+                    animal_frm_data = data[data_idx[0]]
                 else:
-                    assessed_file_paths.append(possible_vid_name)
-        if self.video_path is None:
-            print(assessed_file_paths)
-            raise NoFilesFoundError(msg=f'SimBA searched your project_folder/videos directory for a video file representing {self.file_name}, and could not find a match. Above is a list of possible video filenames that SimBA searched for within your projects video directory without success.')
-        else:
-             _, self.video_basename, _ = get_fn_ext(self.video_path)
+                    animal_frm_data = np.full((data.shape[1]), 0.0)
+                results[i][j*animal_frm_data.shape[0]:j*animal_frm_data.shape[0]+animal_frm_data.shape[0]] = animal_frm_data
+        return results
+
 
     def __insert_all_bps(self, frame=None):
         for animal, bp_data in self.img_bp_cords_dict.items():
             for bp_cnt, bp_tuple in enumerate(bp_data):
                 try:
                     cv2.circle(frame, bp_tuple, self.vid_circle_scale, self.animal_bp_dict[animal]['colors'][bp_cnt], -1, lineType=cv2.LINE_AA)
                 except Exception as err:
                     if type(err) == OverflowError:
-                        InvalidValueWarning(f'SimBA encountered a pose-estimated body-part located at pixel position {str(bp_tuple)}. '
-                              'This value is too large to be converted to an integer. '
-                              'Please check your pose-estimation data to make sure that it is accurate.')
+                        InvalidValueWarning(f'SimBA encountered a pose-estimated body-part located at pixel position {str(bp_tuple)}. This value is too large to be converted to an integer. Please check your pose-estimation data to make sure that it is accurate.')
                     print(err.args)
 
+
     def __create_first_side_img(self):
         side_img = np.ones((int(self.video_info['height'] / 2), self.video_info['width'], 3))
-        cv2.putText(side_img, 'Current video: ' + self.video_basename, (10, self.vid_space_scale), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 255), 3)
+        cv2.putText(side_img, 'Current video: ' + self.video_name, (10, self.vid_space_scale), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 255), 2)
         cv2.putText(side_img, 'Can you assign identities based on the displayed frame ?', (10, int(self.vid_space_scale * (self.add_spacer * 2))), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 255), 2)
-        cv2.putText(side_img, 'Press "x" to display new, random, frame', (10, int(self.vid_space_scale * (self.add_spacer * 3))), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 0), 3)
+        cv2.putText(side_img, 'Press "x" to display new, random, frame', (10, int(self.vid_space_scale * (self.add_spacer * 3))), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 0), 2)
         cv2.putText(side_img, 'Press "c" to continue to start assigning identities using this frame', (10, int(self.vid_space_scale * (self.add_spacer * 4))), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (0, 255, 0), 2)
         self.img_concat = np.uint8(np.concatenate((self.img_overlay, side_img), axis=0))
 
-    def create_choose_animals_side_img(self, animal_id):
-        self.side_img = np.ones((int(self.video_info['height'] / 2), self.video_info['width'], 3))
-        cv2.putText(self.side_img, 'Double left mouse click on:', (10, self.vid_space_scale), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 255), 2)
-        cv2.putText(self.side_img, animal_id, (10, int(self.vid_space_scale * (self.add_spacer * 2))), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 0), 2)
-        self.img_concat = np.uint8(np.concatenate((self.img_overlay, self.side_img), axis=0))
+    def __get_x_y_loc(self, event, x, y, flags, param):
+        if event == 7:
+            self.click_loc = (x,y)
+            self.ID_cords[self.animal_cnt] = {}
+            self.ID_cords[self.animal_cnt]['cord'] = self.click_loc
+            self.ID_cords[self.animal_cnt]['name'] = self.animal_name
 
-    def __initiate_choose_frame(self):
+    def __insert_all_animal_names(self):
+        for animal_cnt, animal_data in self.ID_cords.items():
+            cv2.putText(self.new_frame, animal_data['name'], animal_data['cord'], cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, self.animal_bp_dict[animal_data['name']]['colors'][0], 2)
+
+
+    def __initiate_confirm(self):
         cv2.destroyAllWindows()
-        self.cap.set(1, self.frame_no)
-        self.all_frame_data = self.data_df.loc[self.frame_no, :]
         cv2.namedWindow('Define animal IDs', cv2.WINDOW_NORMAL)
-        self.img_bp_cords_dict = {}
-        ret, self.img = self.cap.read()
-        self.img_overlay = deepcopy(self.img)
-        for animal_cnt, (animal_name, animal_bps) in enumerate(self.animal_bp_dict.items()):
-            self.img_bp_cords_dict[animal_name] = []
-            for bp_cnt in range(len(animal_bps['X_bps'])):
-                x_cord = int(self.data_df.loc[self.frame_no, animal_name + '_' + animal_bps['X_bps'][bp_cnt]])
-                y_cord = int(self.data_df.loc[self.frame_no, animal_name + '_' + animal_bps['Y_bps'][bp_cnt]])
-                self.img_bp_cords_dict[animal_name].append((x_cord, y_cord))
-        self.__insert_all_bps(frame=self.img_overlay)
-        self.__create_first_side_img()
+        cv2.resizeWindow('Define animal IDs', self.video_info['height'], self.video_info['width'])
+        self.new_frame = deepcopy(self.img)
+        self.side_img = np.ones((int(self.video_info['height'] / 2), self.video_info['width'], 3))
+        cv2.putText(self.side_img, 'Current video: {}'.format(self.video_name), (10, int(self.vid_space_scale)), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 255), 3)
+        cv2.putText(self.side_img, 'Are you happy with your assigned identities ?', (10, int(self.vid_space_scale * (self.add_spacer * 2))), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 255), 2)
+        cv2.putText(self.side_img, 'Press "c" to continue (to finish, or proceed to the next video)', (10, int(self.vid_space_scale * (self.add_spacer * 3))), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 0), 2)
+        cv2.putText(self.side_img, 'Press "x" to re-start assigning identities', (10, int(self.vid_space_scale * (self.add_spacer * 4))), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (0, 255, 255), 2)
+        self.__insert_all_bps(frame=self.new_frame)
+        self.__insert_all_animal_names()
+        self.img_concat = np.uint8(np.concatenate((self.new_frame, self.side_img), axis=0))
         cv2.imshow('Define animal IDs', self.img_concat)
         cv2.resizeWindow('Define animal IDs', self.video_info['height'], self.video_info['width'])
-
         keyboard_choice = False
         while not keyboard_choice:
             k = cv2.waitKey(20)
             if k == ord('x'):
                 cv2.destroyWindow('Define animal IDs')
                 cv2.waitKey(0)
                 self.frame_no += 50
                 self.__initiate_choose_frame()
                 break
             elif k == ord('c'):
-                cv2.destroyWindow('Define animal IDs')
+                cv2.destroyAllWindows()
                 cv2.waitKey(0)
-                self.__initiate_choose_animals()
                 break
 
-    def __get_x_y_loc(self, event, x, y, flags, param):
-        if event == 7:
-            self.click_loc = (x,y)
-            self.ID_cords[self.animal_cnt] = {}
-            self.ID_cords[self.animal_cnt]['cord'] = self.click_loc
-            self.ID_cords[self.animal_cnt]['name'] = self.animal_name
-
-    def __insert_all_animal_names(self):
-        for animal_cnt, animal_data in self.ID_cords.items():
-            cv2.putText(self.new_frame, animal_data['name'], animal_data['cord'], cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 255), 3)
-
     def __initiate_choose_animals(self):
         self.ID_cords = {}
         for animal_cnt, animal in enumerate(self.animal_bp_dict.keys()):
             self.new_overlay = deepcopy(self.img_overlay)
             cv2.namedWindow('Define animal IDs', cv2.WINDOW_NORMAL)
             self.animal_name = animal
             self.animal_cnt = animal_cnt
             self.side_img = np.ones((int(self.video_info['height'] / 2), self.video_info['width'], 3))
             cv2.putText(self.side_img, 'Double left mouse click on:', (10, self.vid_space_scale), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 255), 3)
             cv2.putText(self.side_img, animal, (10, int(self.vid_space_scale * (self.add_spacer * 2))), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 0), 3)
             for id in self.ID_cords.keys():
-                cv2.putText(self.new_overlay, self.ID_cords[id]['name'], self.ID_cords[id]['cord'], cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 255), 3)
+                cv2.putText(self.new_overlay, self.ID_cords[id]['name'], self.ID_cords[id]['cord'], cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, self.animal_bp_dict[self.ID_cords[id]['name']]['colors'][0], 3)
             self.new_overlay = np.uint8(np.concatenate((self.new_overlay, self.side_img), axis=0))
             cv2.imshow('Define animal IDs', self.new_overlay)
             cv2.resizeWindow('Define animal IDs', self.video_info['height'], self.video_info['width'])
             while animal_cnt not in self.ID_cords.keys():
                 cv2.setMouseCallback('Define animal IDs', self.__get_x_y_loc)
                 cv2.waitKey(200)
         self.__initiate_confirm()
 
-    def __initiate_confirm(self):
+    def __initiate_choose_frame(self):
         cv2.destroyAllWindows()
+        self.cap.set(1, self.frame_no)
+        self.all_frame_data = self.data_df.loc[self.frame_no, :]
         cv2.namedWindow('Define animal IDs', cv2.WINDOW_NORMAL)
-        cv2.resizeWindow('Define animal IDs', self.video_info['height'], self.video_info['width'])
-        self.new_frame = deepcopy(self.img)
-        self.side_img = np.ones((int(self.video_info['height'] / 2), self.video_info['width'], 3))
-        cv2.putText(self.side_img, 'Current video: {}'.format(self.video_basename), (10, int(self.vid_space_scale)), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 255), 3)
-        cv2.putText(self.side_img, 'Are you happy with your assigned identities ?', (10, int(self.vid_space_scale * (self.add_spacer * 2))), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 255), 2)
-        cv2.putText(self.side_img, 'Press "c" to continue (to finish, or proceed to the next video)', (10, int(self.vid_space_scale * (self.add_spacer * 3))), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (255, 255, 0), 2)
-        cv2.putText(self.side_img, 'Press "x" to re-start assigning identities', (10, int(self.vid_space_scale * (self.add_spacer * 4))), cv2.FONT_HERSHEY_SIMPLEX, self.vid_font_scale, (0, 255, 255), 2)
-        self.__insert_all_bps(frame=self.new_frame)
-        self.__insert_all_animal_names()
-        self.img_concat = np.uint8(np.concatenate((self.new_frame, self.side_img), axis=0))
+        self.img_bp_cords_dict = {}
+        ret, self.img = self.cap.read()
+        self.img_overlay = deepcopy(self.img)
+        for animal_cnt, (animal_name, animal_bps) in enumerate(self.animal_bp_dict.items()):
+            self.img_bp_cords_dict[animal_name] = []
+            for bp_cnt in range(len(animal_bps['X_bps'])):
+                x_cord = int(self.data_df.loc[self.frame_no, animal_bps['X_bps'][bp_cnt]])
+                y_cord = int(self.data_df.loc[self.frame_no, animal_bps['Y_bps'][bp_cnt]])
+                self.img_bp_cords_dict[animal_name].append((x_cord, y_cord))
+        self.__insert_all_bps(frame=self.img_overlay)
+        self.__create_first_side_img()
         cv2.imshow('Define animal IDs', self.img_concat)
         cv2.resizeWindow('Define animal IDs', self.video_info['height'], self.video_info['width'])
+
         keyboard_choice = False
         while not keyboard_choice:
             k = cv2.waitKey(20)
             if k == ord('x'):
                 cv2.destroyWindow('Define animal IDs')
                 cv2.waitKey(0)
-                self.frame_no += 50
+                self.frame_no = np.random.randint(0, self.video_info['frame_count']-1, size=1)[0]
                 self.__initiate_choose_frame()
                 break
             elif k == ord('c'):
-                cv2.destroyAllWindows()
+                cv2.destroyWindow('Define animal IDs')
                 cv2.waitKey(0)
+                self.__initiate_choose_animals()
                 break
 
+    def __update_bp_headers_file(self):
+        new_headers = []
+        for animal_name in self.animal_bp_dict.keys():
+            for bp in self.animal_bp_dict[animal_name]['X_bps']:
+                if animal_name not in bp:
+                    new_headers.append('{}_{}'.format(animal_name, bp[:-2]))
+                else:
+                    new_headers.append(bp[:-2])
+        new_bp_df = pd.DataFrame(new_headers)
+        new_bp_df.to_csv(self.body_parts_path, index=False, header=False)
+
+
+
     def __check_intergity_of_order(self):
         for click_key_combination in itertools.combinations(list(self.animal_order.keys()), 2):
             click_n, click_n1 = click_key_combination[0], click_key_combination[1]
             animal_1, animal_2 = self.animal_order[click_n]['animal_name'], self.animal_order[click_n1]['animal_name']
             if animal_1 == animal_2:
-                InValidUserInputWarning(msg=f'The animal most proximal to click number {str(click_n)} is animal named {animal_1}. The animal most proximal to click number {str(click_n1)} is also animal {animal_2}.'
-                      'Please indicate which animal is which using a video frame where the animals are clearly separated')
+                InValidUserInputWarning(msg=f'The animal most proximal to click number {click_n} is animal named {animal_1}. The animal most proximal to click number {click_n1} is also animal {animal_2}. Please indicate which animal is which using a video frame where the animals are clearly separated')
+                raise ValueError()
             else:
                 pass
 
     def __find_closest_animals(self):
         self.animal_order = {}
         for animal_number, animal_click_data in self.ID_cords.items():
             animal_name, animal_cord = animal_click_data['name'], animal_click_data['cord']
@@ -285,152 +209,182 @@
             closest_animal['animal_name'] = None
             closest_animal['body_part_name'] = None
             closest_animal['distance'] = np.inf
             for other_animal_name, animal_bps in self.animal_bp_dict.items():
                 animal_bp_names_x = self.animal_bp_dict[other_animal_name]['X_bps']
                 animal_bp_names_y = self.animal_bp_dict[other_animal_name]['Y_bps']
                 for x_col, y_col in zip(animal_bp_names_x, animal_bp_names_y):
-                    bp_location = (int(self.all_frame_data['{}_{}'.format(other_animal_name, x_col)]), int(self.all_frame_data['{}_{}'.format(other_animal_name, y_col)]))
+                    bp_location = (int(self.all_frame_data[x_col]), int(self.all_frame_data[y_col]))
                     distance = np.sqrt((animal_cord[0] - bp_location[0]) ** 2 + (animal_cord[1] - bp_location[1]) ** 2)
                     if distance < closest_animal['distance']:
                         closest_animal['animal_name'] = other_animal_name
                         closest_animal['body_part_name'] = (x_col, y_col)
                         closest_animal['distance'] = distance
             self.animal_order[animal_number] = closest_animal
         self.__check_intergity_of_order()
 
     def __organize_df(self):
         self.out_df = pd.DataFrame()
         for animal_cnt, animal_data in self.animal_order.items():
             closest_animal_dict = self.animal_bp_dict[animal_data['animal_name']]
             x_cols, y_cols, p_cols = closest_animal_dict['X_bps'], closest_animal_dict['Y_bps'], closest_animal_dict['P_bps']
-            x_cols = [animal_data['animal_name'] + '_' + x for x in x_cols]
-            y_cols = [animal_data['animal_name'] + '_' + x for x in y_cols]
-            p_cols = [animal_data['animal_name'] + '_' + x for x in p_cols]
             for x_col, y_col, p_cols in zip(x_cols, y_cols, p_cols):
                 df = self.data_df[[x_col, y_col, p_cols]]
                 self.out_df = pd.concat([self.out_df, df], axis=1)
 
-        self.out_df.columns = self.bp_lst
-        for animal_name in self.id_lst:
-            for x_col, y_col in zip(self.animal_bp_dict[animal_name]['X_bps'], self.animal_bp_dict[animal_name]['Y_bps']):
-                self.out_df['{}_{}'.format(animal_name, x_col)] = self.out_df['{}_{}'.format(animal_name, x_col)].astype(int)
-                self.out_df['{}_{}'.format(animal_name, y_col)] = self.out_df['{}_{}'.format(animal_name, y_col)].astype(int)
-
     def __insert_multi_idx_header(self):
-        multi_idx_cols = []
-        for col_idx in range(len(self.out_df.columns)):
-            multi_idx_cols.append(tuple(('DLC_multi', 'DLC_multi', self.out_df.columns[col_idx])))
-        self.out_df.columns = pd.MultiIndex.from_tuples(multi_idx_cols, names=('scorer', 'bodypart', 'coords'))
+        multi_index_columns = []
+        for column in range(len(self.data_df.columns)):
+            multi_index_columns.append(tuple(('SLEAP_multi', 'SLEAP_multi', self.data_df.columns[column])))
+        self.out_df.columns = pd.MultiIndex.from_tuples(multi_index_columns, names=['scorer', 'bodypart', 'coords'])
 
     def __save_df(self):
-        save_name = os.path.join(self.video_basename + '.' + self.file_type)
-        self.save_path = os.path.join(self.save_folder, save_name)
-        if self.file_type == 'parquet':
-            table = pyarrow.Table.from_pandas(self.out_df)
-            pyarrow.parquet.write_table(table, self.save_path)
-        if self.file_type == 'csv':
-            self.out_df.to_csv(self.save_path)
+        self.save_path = os.path.join(os.path.join(self.input_csv_dir, f'{self.video_name}.{self.file_type}'))
+        write_df(df=self.out_df, file_type=self.file_type, save_path=self.save_path, multi_idx_header=True)
 
     def __run_interpolation(self):
-        print('Interpolating missing values in video {} (Method: {} ...'.format(self.video_basename, self.interpolation_settings))
-        if self.file_type == 'parquet':
-            data_df = pd.read_parquet(self.save_path)
-        if self.file_type == 'csv':
-            data_df = pd.read_csv(self.save_path, index_col=0)
-        interpolate_body_parts = Interpolate(self.config_path, data_df)
-        interpolate_body_parts.detect_headers()
-        interpolate_body_parts.fix_missing_values(self.interpolation_settings)
-        interpolate_body_parts.reorganize_headers()
-        if self.file_type == 'parquet':
-            table = pyarrow.Table.from_pandas(interpolate_body_parts.new_df)
-            pyarrow.parquet.write_table(table, self.save_path)
-        if self.file_type == 'csv':
-            interpolate_body_parts.new_df.to_csv(self.save_path)
+        print('Interpolating missing values in video {} (Method: {})...'.format(self.video_name, self.interpolation_settings))
+        _ = Interpolate(input_path=self.save_path,config_path=self.config_path, method=self.interpolation_settings, initial_import_multi_index=True)
+
 
     def __run_smoothing(self):
-        if self.smoothing_settings['Method'] == 'Gaussian':
-            print('Performing Gaussian smoothing on video {}...'.format(self.video_basename))
-            time_window = self.smoothing_settings['Parameters']['Time_window']
-            smooth_data_gaussian(config=self.config, file_path=self.save_path, time_window_parameter=time_window)
-
-        if self.smoothing_settings['Method'] == 'Savitzky Golay':
-            print('Performing Savitzky Golay smoothing on video {}...'.format(self.video_basename))
-            time_window = self.smoothing_settings['Parameters']['Time_window']
-            smooth_data_savitzky_golay(config=self.config, file_path=self.save_path, time_window_parameter=time_window)
-
-    def import_data(self):
-        """
-        Method for initializing maDLC importing GUI.
-
-        Returns
-        ----------
-        None
+        print(f'Performing {self.smoothing_settings["Method"]} smoothing on video {self.video_name}...')
+        Smooth(config_path=self.config_path,
+               input_path=self.save_path,
+               time_window=int(self.smoothing_settings['Parameters']['Time_window']),
+               smoothing_method=self.smoothing_settings['Method'],
+               initial_import_multi_index=True)
 
-        """
 
+    def import_sleap(self):
         import_log = pd.DataFrame(columns=['VIDEO', 'IMPORT_TIME', 'IMPORT_SOURCE', 'INTERPOLATION_SETTING', 'SMOOTHING_SETTING'])
         for file_cnt, file_path in enumerate(self.files_found):
-            self.add_spacer = 2
-            _, self.file_name, _ = get_fn_ext(file_path)
-            print('Processing file {} ...'.format(self.file_name))
-            self.__find_video_file()
-            self.data_df = pd.read_hdf(file_path).replace([np.inf, -np.inf], np.nan).fillna(0)
+            video_timer = SimbaTimer()
+            video_timer.start_timer()
+            _, self.video_name, _ = get_fn_ext(filepath=file_path)
+            print('Importing {}...'.format(self.video_name))
+
             try:
-                self.data_df.columns = self.bp_lst
-            except ValueError as err:
-                raise BodypartColumnNotFoundError(msg=f'SIMBA ERROR: The number of body-parts in the input file {file_path} do not match the number of body-parts in your SimBA project. '
-                      f'The number of of body-parts expected by your SimBA project is {str(len(self.x_cols))}. '
-                      f'The number of of body-parts contained in file {file_path} is {str(int(len(self.data_df.columns) / 3))}. '
-                      f'Make sure you have specified the correct number of animals and body-parts in your project.')
-            self.video_info = get_video_meta_data(self.video_path)
-            self.max_video_dimension = max(self.video_info['width'], self.video_info['height'])
-            self.vid_circle_scale = int(self.radius_scaler / (self.res_scaler / self.max_video_dimension))
-            self.vid_font_scale = float(self.font_scaler / (self.res_scaler / self.max_video_dimension))
-            self.vid_space_scale = int(self.space_scaler / (self.res_scaler / self.max_video_dimension))
-            self.frame_no = 1
-            self.cap = cv2.VideoCapture(self.video_path)
-            self.__initiate_choose_frame()
-            self.cap.release()
-            self.__find_closest_animals()
-            self.__organize_df()
+                with h5py.File(file_path, "r") as sleap_dict:
+                    data = {k: v[()] for k, v in sleap_dict.items()}
+                    data["node_names"] = [s.decode() for s in data["node_names"].tolist()]
+                    data["track_names"] = [s.decode() for s in data["track_names"].tolist()]
+                    data["tracks"] = np.transpose(data["tracks"])
+                    data["track_occupancy"] = data["track_occupancy"].astype(bool)
+            except OSError:
+                print('SIMBA WARNING: {} is not a valid H5 file. Skipping {}...'.format(self.video_name, file_path))
+
+            valid_frame_idxs = np.argwhere(data["track_occupancy"].any(axis=1)).flatten()
+            tracks = []
+            for frame_idx in valid_frame_idxs:
+                frame_tracks = data["tracks"][frame_idx]
+                for i in range(frame_tracks.shape[-1]):
+                    pts = frame_tracks[..., i]
+                    if np.isnan(pts).all():
+                        continue
+                    detection = {"track": data["track_names"][i], "frame_idx": frame_idx}
+                    for node_name, (x, y) in zip(data["node_names"], pts):
+                        detection[f"{node_name}.x"] = x
+                        detection[f"{node_name}.y"] = y
+                    tracks.append(detection)
+
+            self.data_df = pd.DataFrame(tracks).fillna(0)
+            idx = self.data_df.iloc[:, :2]
+            idx['track'] = pd.Categorical(idx['track'])
+            idx['track'] = idx['track'].cat.codes.astype(int)
+            self.data_df = self.data_df.iloc[:, 2:]
+            if self.animal_cnt > 1:
+                self.data_df = pd.DataFrame(self.__transpose_multi_animal_data_table(data=self.data_df.values, idx=idx.values, animal_cnt=self.animal_cnt))
+                p_df = pd.DataFrame(1.0, index=self.data_df.index, columns=self.data_df.columns[1::2] + .5)
+                self.data_df = pd.concat([self.data_df, p_df], axis=1).sort_index(axis=1)
+                try:
+                    self.data_df.columns = self.bp_headers
+                except ValueError:
+                    raise BodypartColumnNotFoundError(
+                        msg=f'SIMBA ERROR: The number of body-parts in the input file {file_path} do not match the number of body-parts in your SimBA project. '
+                            f'The number of of body-parts expected by your SimBA project is {str(len(self.x_cols))}. '
+                            f'The number of of body-parts contained in file {file_path} is {str(int(len(self.data_df.columns) / 3))}. '
+                            f'Make sure you have specified the correct number of animals and body-parts in your project.')
+
+
+
+            else:
+                idx = list(idx.drop('track', axis=1)['frame_idx'])
+                self.data_df = self.data_df.set_index([idx]).sort_index()
+                self.data_df.columns = np.arange(len(self.data_df.columns))
+                self.data_df = self.data_df.reindex(range(self.data_df.index[0], self.data_df.index[-1] + 1), fill_value=0)
+                p_df = pd.DataFrame(1.0, index=self.data_df.index, columns=self.data_df.columns[1::2] + .5)
+                self.data_df = pd.concat([self.data_df, p_df], axis=1).sort_index(axis=1)
+                try:
+                    self.data_df.columns = self.bp_headers
+                except ValueError:
+                    raise BodypartColumnNotFoundError(
+                        msg=f'SIMBA ERROR: The number of body-parts in the input file {file_path} do not match the number of body-parts in your SimBA project. '
+                            f'The number of of body-parts expected by your SimBA project is {str(len(self.x_cols))}. '
+                            f'The number of of body-parts contained in file {file_path} is {str(int(len(self.data_df.columns) / 3))}. '
+                            f'Make sure you have specified the correct number of animals and body-parts in your project.')
+                self.out_df = deepcopy(self.data_df)
+
+            if self.animal_cnt > 1:
+                self.video_path = find_video_of_file(video_dir=self.video_dir, filename=self.video_name)
+                self.video_info = get_video_meta_data(self.video_path)
+                self.max_video_dimension = max(self.video_info['width'], self.video_info['height'])
+                self.vid_circle_scale = int(self.radius_scaler / (self.res_scaler / self.max_video_dimension))
+                self.vid_font_scale = float(self.font_scaler / (self.res_scaler / self.max_video_dimension))
+                self.vid_space_scale = int(self.space_scaler / (self.res_scaler / self.max_video_dimension))
+                self.cap = cv2.VideoCapture(self.video_path)
+                self.__initiate_choose_frame()
+                self.cap.release()
+                self.__find_closest_animals()
+                self.__organize_df()
             self.__insert_multi_idx_header()
             self.__save_df()
             if self.interpolation_settings != 'None':
                 self.__run_interpolation()
             if self.smoothing_settings['Method'] != 'None':
                 self.__run_smoothing()
-            import_log.loc[len(import_log)] = [self.file_name,
-                                               datetime.now().strftime('%Y%m%d%H%M%S'),
-                                               'MADLC',
+            video_timer.stop_timer()
+            import_log.loc[len(import_log)] = [self.video_name,
+                                               self.datetime,
+                                               'SLEAP H5',
                                                str(self.interpolation_settings),
                                                str(self.smoothing_settings)]
-            print('SimBA import of file {} complete!'.format(self.file_name))
+            print('Video "{}" imported (elapsed time {}s)...'.format(self.video_name, video_timer.elapsed_time_str))
 
         import_log.to_csv(self.import_log_path)
-        stdout_success(msg=f'{str(len(self.files_found))} files imported to your SimBA project. Imported files are located in the project_folder/csv/input_csv directory.')
+        self.timer.stop_timer()
+        stdout_success(msg=f'{str(len(self.files_found))} file(s) imported to the SimBA project (project_folder/csv/input_csv directory', elapsed_time=self.timer.elapsed_time_str)
 
-# test = MADLC_Importer(config_path=r'/Users/simon/Desktop/envs/troubleshooting/two_black_animals/project_folder/project_config.ini',
-#                    data_folder=r'/Users/simon/Desktop/envs/troubleshooting/two_black_animals/h5',
-#                    file_type='ellipse',
-#                    id_lst=['Simon', 'JJ'],
-#                    interpolation_settings='Body-parts: Nearest',
+# test = SLEAPImporterH5(config_path="/Users/simon/Desktop/envs/troubleshooting/Termites_5/project_folder/project_config.ini",
+#                    data_folder=r'/Users/simon/Desktop/envs/troubleshooting/Termites_5/import_h5',
+#                    actor_IDs=['Simon', 'Nastacia', 'Ben', 'John', 'JJ'],
+#                    interpolation_settings="Body-parts: Nearest",
 #                    smoothing_settings = {'Method': 'Savitzky Golay', 'Parameters': {'Time_window': '200'}})
-# test.import_data()
+# test.import_sleap()
+# print('All SLEAP imports complete.')
 
 
 
-# test = MADLC_Importer(config_path=r'/Users/simon/Desktop/troubleshooting/B1-MS_US/project_folder/project_config.ini',
-#                    data_folder=r'/Users/simon/Desktop/troubleshooting/B1-MS_US/el_import/other_2',
-#                    file_type='ellipse',
-#                    id_lst=['MS', 'US'],
+# test = SLEAPImporterH5(config_path="/Users/simon/Desktop/envs/troubleshooting/Termites_5/project_folder/project_config.ini",
+#                    data_folder=r'/Users/simon/Desktop/envs/troubleshooting/Termites_5/import_h5',
+#                    actor_IDs=['Simon', 'Nastacia', 'Ben', 'John', 'JJ'],
 #                    interpolation_settings='None',
-#                    smoothing_settings={'Method': 'None', 'Parameters': {'Time_window': '200'}})
-# test.import_data()
+#                    smoothing_settings = {'Method': 'None'})
+# test.import_sleap()
+# print('All SLEAP imports complete.')
+
+# test = SLEAPImporterH5(config_path="/Users/simon/Desktop/envs/troubleshooting/sleap_cody/project_folder/project_config.ini",
+#                    data_folder=r'/Users/simon/Desktop/envs/troubleshooting/sleap_cody/import_h5',
+#                    actor_IDs=['Nastacia', 'Sam'],
+#                    interpolation_settings="Body-parts: Nearest",
+#                    smoothing_settings = {'Method': 'Savitzky Golay', 'Parameters': {'Time_window': '200'}})
+# test.import_sleap()
+# print('All SLEAP imports complete.')
 
-# test = MADLC_Importer(config_path=r'/Users/simon/Desktop/troubleshooting/Soong/project_folder/project_config.ini',
-#                    data_folder=r'/Users/simon/Desktop/troubleshooting/Soong/import',
-#                    file_type='ellipse',
-#                    id_lst=['Animal1'],
-#                    interpolation_settings='None',
-#                    smoothing_settings={'Method': 'None', 'Parameters': {'Time_window': '200'}})
-# test.import_data()
+
+# test = SLEAPImporterH5(config_path="/Users/simon/Desktop/envs/troubleshooting/sleap_cody/project_folder/project_config.ini",
+#                    data_folder=r'/Users/simon/Desktop/envs/troubleshooting/sleap_cody/import_h5',
+#                    actor_IDs=['Nastacia'],
+#                    interpolation_settings="Body-parts: Nearest",
+#                    smoothing_settings = {'Method': 'Savitzky Golay', 'Parameters': {'Time_window': '200'}})
+# test.import_sleap()
+# # print('All SLEAP imports complete.')
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pose_importers/sleap_importer_csv.py` & `Simba-UW-tf-dev-1.57.6/simba/pose_importers/sleap_importer_csv.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,36 +1,26 @@
 import pandas as pd
-from simba.read_config_unit_tests import read_config_entry, read_config_file
 import os, glob
 from numba import jit, prange
 import numpy as np
 from copy import deepcopy
-from simba.misc_tools import (find_video_of_file,
-                              check_multi_animal_status,
-                              smooth_data_gaussian,
-                              smooth_data_savitzky_golay,
-                              get_video_meta_data,
-                              )
-from simba.utils.printing import stdout_success
-from simba.drop_bp_cords import (get_fn_ext,
-                                 createColorListofList,
-                                 create_body_part_dictionary,
-                                 getBpNames,
-                                 getBpHeaders)
 from datetime import datetime
 import itertools
 import cv2
-import pyarrow.parquet as pq
-import pyarrow
-from simba.interpolate_pose import Interpolate
+
+from simba.interpolate_smooth import Interpolate, Smooth
 from simba.utils.errors import NoFilesFoundError
 from simba.utils.warnings import InvalidValueWarning, InValidUserInputWarning
+from simba.mixins.config_reader import ConfigReader
+from simba.enums import Methods, ReadConfig
+from simba.utils.read_write import write_df, find_video_of_file, get_video_meta_data, get_fn_ext
+from simba.utils.data import create_color_palettes
+from simba.utils.printing import stdout_success
 
-
-class SLEAPImporterCSV(object):
+class SLEAPImporterCSV(ConfigReader):
 
     """
     Class for importing SLEAP pose-estimation data into SimBA project.
 
     Parameters
     ----------
     config_path: str
@@ -53,55 +43,43 @@
     `Example expected SLEAP csv data file for 5 animals / 4 pose-estimated body-parts  <https://github.com/sgoldenlab/simba/blob/master/misc/sleap_csv_example.csv>`__.
 
 
     Example
     ----------
 
     >>> sleap_csv_importer = SLEAPImporterCSV(config_path=r'/Users/simon/Desktop/envs/troubleshooting/slp_1_animal_1_bp/project_folder/project_config.ini', data_folder=r'/Users/simon/Desktop/envs/troubleshooting/slp_1_animal_1_bp/import/temp', actor_IDs=['Termite_1', 'Termite_2', 'Termite_3', 'Termite_4', 'Termite_5'], interpolation_settings="Body-parts: Nearest", smoothing_settings = {'Method': 'Savitzky Golay', 'Parameters': {'Time_window': '200'}})
-    >>> sleap_csv_importer.initate_import_slp()
+    >>> sleap_csv_importer.run()
     """
 
     def __init__(self,
                  config_path: str,
                  data_folder: str,
                  actor_IDs: list,
                  interpolation_settings: str,
                  smoothing_settings: dict):
 
-        self.config_path, self.config = config_path, read_config_file(ini_path=config_path)
-        self.interpolation_settings = interpolation_settings
-        self.smoothing_settings, self.actor_ids = smoothing_settings, actor_IDs
-        self.file_type = read_config_entry(self.config, 'General settings', 'workflow_file_type', 'str', 'csv')
-        self.project_path = read_config_entry(self.config, 'General settings', 'project_path', data_type='folder_path')
-        self.animal_cnt = len(self.actor_ids)
-        multi_animal_status, multi_animal_id_lst = check_multi_animal_status(self.config, self.animal_cnt)
-        self.x_cols, self.y_cols, self.p_cols = getBpNames(self.config_path)
-        color_lst = createColorListofList(self.animal_cnt, len(self.x_cols))
-        self.video_dir = os.path.join(self.project_path, 'videos')
+        ConfigReader.__init__(self, config_path=config_path, read_video_info=False)
+        self.interpolation_settings, self.smoothing_settings, actor_IDs = interpolation_settings, smoothing_settings, actor_IDs
+        color_lst = create_color_palettes(self.animal_cnt, len(self.x_cols))
         self.files_found = glob.glob(data_folder + '/*.csv')
-        self.import_log_path = os.path.join(self.project_path, 'logs', f'data_import_log_{datetime.now().strftime("%Y%m%d%H%M%S")}.csv')
         if len(self.files_found) == 0:
-            raise NoFilesFoundError(msg='SIMBA ERROR: Zero CSV files found in the data directory ({})'.format(data_folder))
+            raise NoFilesFoundError(msg='Zero CSV files found in the data directory ({})'.format(data_folder))
 
-        self.save_folder = os.path.join(self.project_path, 'csv', 'input_csv')
+        self.import_log_path = os.path.join(self.logs_path, f'data_import_log_{self.datetime}.csv')
         self.space_scaler, self.radius_scaler, self.res_scaler, self.font_scaler, self.add_spacer, self.frame_no = 40, 10, 1500, 1.2, 2, 1
-        self.bp_names_csv_path = os.path.join(self.project_path, 'logs', 'measures', 'pose_configs', 'bp_names', 'project_bp_names.csv')
-        self.pose_settings = self.config.get('create ensemble settings', 'pose_estimation_body_parts')
-        if (self.pose_settings is 'user_defined'):
+        if (self.pose_setting is Methods.USER_DEFINED.value):
             self.__update_config_animal_cnt()
-        self.animal_bp_dict = create_body_part_dictionary(multi_animal_status, self.actor_ids, self.animal_cnt, self.x_cols, self.y_cols, self.p_cols, color_lst)
         if self.animal_cnt > 1:
             self.__update_bp_headers_file()
-            multi_animal_status, multi_animal_id_lst = check_multi_animal_status(self.config, self.animal_cnt)
-            self.x_cols, self.y_cols, self.p_cols = getBpNames(self.config_path)
-            self.animal_bp_dict = create_body_part_dictionary(multi_animal_status, self.actor_ids, self.animal_cnt, self.x_cols, self.y_cols, self.p_cols, color_lst)
-        self.df_headers = getBpHeaders(inifile=self.config_path)
+            self.check_multi_animal_status()
+            self.get_body_part_names()
+            self.animal_bp_dict = self.create_body_part_dictionary(self.multi_animal_status, self.multi_animal_id_list, self.animal_cnt, self.x_cols, self.y_cols, self.p_cols, color_lst)
 
     def __update_config_animal_cnt(self):
-        self.config.set("General settings", "animal_no", str(self.animal_cnt))
+        self.config.set(ReadConfig.GENERAL_SETTINGS.value, ReadConfig.ANIMAL_CNT.value, str(self.animal_cnt))
         with open(self.project_path, "w+") as f:
             self.config.write(f)
         f.close()
 
     def __insert_all_bps(self, frame=None):
         for animal, bp_data in self.img_bp_cords_dict.items():
             for bp_cnt, bp_tuple in enumerate(bp_data):
@@ -228,15 +206,15 @@
         for animal_name in self.animal_bp_dict.keys():
             for bp in self.animal_bp_dict[animal_name]['X_bps']:
                 if animal_name not in bp:
                     new_headers.append('{}_{}'.format(animal_name, bp[:-2]))
                 else:
                     new_headers.append(bp[:-2])
         new_bp_df = pd.DataFrame(new_headers)
-        new_bp_df.to_csv(self.bp_names_csv_path, index=False, header=False)
+        new_bp_df.to_csv(self.body_parts_path, index=False, header=False)
 
     def __find_closest_animals(self):
         self.animal_order = {}
         for animal_number, animal_click_data in self.ID_cords.items():
             animal_name, animal_cord = animal_click_data['name'], animal_click_data['cord']
             closest_animal = {}
             closest_animal['animal_name'] = None
@@ -267,48 +245,28 @@
     def __insert_multi_idx_header(self):
         multi_index_columns = []
         for column in range(len(self.data_df.columns)):
             multi_index_columns.append(tuple(('SLEAP_multi', 'SLEAP_multi', self.data_df.columns[column])))
         self.out_df.columns = pd.MultiIndex.from_tuples(multi_index_columns, names=['scorer', 'bodypart', 'coords'])
 
     def __save_df(self):
-        save_name = os.path.join(self.video_basename + '.' + self.file_type)
-        self.save_path = os.path.join(self.save_folder, save_name)
-        if self.file_type == 'parquet':
-            table = pyarrow.Table.from_pandas(self.out_df)
-            pyarrow.parquet.write_table(table, self.save_path)
-        if self.file_type == 'csv':
-            self.out_df.to_csv(self.save_path)
+        self.save_path = os.path.join(os.path.join(self.input_csv_dir, f'{self.video_basename}.{self.file_type}'))
+        write_df(df=self.out_df, file_type=self.file_type, save_path=self.save_path, multi_idx_header=True)
 
     def __run_interpolation(self):
-        print('Interpolating missing values in video {} (Method: {}) ...'.format(self.video_basename, self.interpolation_settings))
-        if self.file_type == 'parquet':
-            data_df = pd.read_parquet(self.save_path)
-        if self.file_type == 'csv':
-            data_df = pd.read_csv(self.save_path, index_col=0)
-        interpolate_body_parts = Interpolate(self.config_path, data_df)
-        interpolate_body_parts.detect_headers()
-        interpolate_body_parts.fix_missing_values(self.interpolation_settings)
-        interpolate_body_parts.reorganize_headers()
-        if self.file_type == 'parquet':
-            table = pyarrow.Table.from_pandas(interpolate_body_parts.new_df)
-            pyarrow.parquet.write_table(table, self.save_path)
-        if self.file_type == 'csv':
-            interpolate_body_parts.new_df.to_csv(self.save_path)
+        print('Interpolating missing values in video {} (Method: {})...'.format(self.video_basename, self.interpolation_settings))
+        _ = Interpolate(input_path=self.save_path,config_path=self.config_path, method=self.interpolation_settings, initial_import_multi_index=True)
 
     def __run_smoothing(self):
-        if self.smoothing_settings['Method'] == 'Gaussian':
-            print('Performing Gaussian smoothing on video "{}" ...'.format(self.video_basename))
-            time_window = self.smoothing_settings['Parameters']['Time_window']
-            smooth_data_gaussian(config=self.config, file_path=self.save_path, time_window_parameter=time_window)
-
-        if self.smoothing_settings['Method'] == 'Savitzky Golay':
-            print('Performing Savitzky Golay smoothing on video {}...'.format(self.video_basename))
-            time_window = self.smoothing_settings['Parameters']['Time_window']
-            smooth_data_savitzky_golay(config=self.config, file_path=self.save_path, time_window_parameter=time_window)
+        print(f'Performing {self.smoothing_settings["Method"]} smoothing on video {self.video_basename}...')
+        Smooth(config_path=self.config_path,
+               input_path=self.save_path,
+               time_window=int(self.smoothing_settings['Parameters']['Time_window']),
+               smoothing_method=self.smoothing_settings['Method'],
+               initial_import_multi_index=True)
 
     @staticmethod
     @jit(nopython=True)
     def __transpose_multi_animal_data_table(data: np.array, idx: np.array, animal_cnt: int) -> np.array:
         results = np.full((np.max(idx[:, 1]), data.shape[1]*animal_cnt), 0.0)
         for i in prange(np.max(idx[:, 1])):
             for j in prange(animal_cnt):
@@ -316,36 +274,36 @@
                 if len(data_idx) == 1:
                     animal_frm_data = data[data_idx[0]]
                 else:
                     animal_frm_data = np.full((data.shape[1]), 0.0)
                 results[i][j*animal_frm_data.shape[0]:j*animal_frm_data.shape[0]+animal_frm_data.shape[0]] = animal_frm_data
         return results
 
-    def initate_import_slp(self):
+    def run(self):
         import_log = pd.DataFrame(columns=['VIDEO', 'IMPORT_TIME', 'IMPORT_SOURCE', 'INTERPOLATION_SETTING', 'SMOOTHING_SETTING'])
         for file_cnt, file_path in enumerate(self.files_found):
             _, self.video_basename, _ = get_fn_ext(filepath=file_path)
             print('Analysing {}...'.format(os.path.basename(file_path)))
             data_df = pd.read_csv(file_path)
             idx = data_df.iloc[:, :2]
             idx['track'] = idx['track'].str.replace(r'[^\d.]+', '').astype(int)
             data_df = data_df.iloc[:, 2:]
             if self.animal_cnt > 1:
                 self.data_df = pd.DataFrame(self.__transpose_multi_animal_data_table(data=data_df.values, idx=idx.values, animal_cnt=self.animal_cnt))
                 p_df = pd.DataFrame(1.0, index=self.data_df.index, columns=self.data_df.columns[1::2] + .5)
                 self.data_df = pd.concat([self.data_df, p_df], axis=1).sort_index(axis=1)
-                self.data_df.columns = self.df_headers
+                self.data_df.columns = self.bp_headers
             else:
                 idx = list(idx.drop('track', axis=1)['frame_idx'])
                 self.data_df = data_df.set_index([idx]).sort_index()
                 self.data_df.columns = np.arange(len(self.data_df.columns))
                 self.data_df = self.data_df.reindex(range(self.data_df.index[0], self.data_df.index[-1] + 1), fill_value=0)
                 p_df = pd.DataFrame(1.0, index=self.data_df.index, columns=self.data_df.columns[1::2] + .5)
                 self.data_df = pd.concat([self.data_df, p_df], axis=1).sort_index(axis=1)
-                self.data_df.columns = self.df_headers
+                self.data_df.columns = self.bp_headers
                 self.out_df = deepcopy(self.data_df)
 
             if self.animal_cnt > 1:
                 self.video_path = find_video_of_file(video_dir=self.video_dir, filename=self.video_basename)
                 self.video_info = get_video_meta_data(self.video_path)
                 self.max_video_dimension = max(self.video_info['width'], self.video_info['height'])
                 self.vid_circle_scale = int(self.radius_scaler / (self.res_scaler / self.max_video_dimension))
@@ -369,21 +327,21 @@
                                                str(self.smoothing_settings)]
             print('Video "{}" imported...'.format(self.video_basename))
 
         import_log.to_csv(self.import_log_path)
         stdout_success(msg=f'{str(len(self.files_found))} file(s) imported to the SimBA project (project_folder/csv/input_csv directory)')
 
 
-# test = SleapCsvImporter(config_path=r'/Users/simon/Desktop/envs/troubleshooting/Hornet/project_folder/project_config.ini',
+# test = SLEAPImporterCSV(config_path=r'/Users/simon/Desktop/envs/troubleshooting/Hornet/project_folder/project_config.ini',
 #                  data_folder=r'/Users/simon/Desktop/envs/troubleshooting/Hornet_single_slp/import',
 #                  actor_IDs=['Hornet'],
 #                  interpolation_settings="Body-parts: Nearest",
 #                  smoothing_settings = {'Method': 'Savitzky Golay', 'Parameters': {'Time_window': '200'}})
-# test.initate_import_slp()
+# test.run()
 
 
-# test = SleapCsvImporter(config_path=r'/Users/simon/Desktop/envs/troubleshooting/slp_1_animal_1_bp/project_folder/project_config.ini',
-#                  data_folder=r'/Users/simon/Desktop/envs/troubleshooting/slp_1_animal_1_bp/import',
-#                  actor_IDs=['Termite_1', 'Termite_2', 'Termite_3', 'Termite_4', 'Termite_5'],
+# test = SLEAPImporterCSV(config_path=r'/Users/simon/Desktop/envs/troubleshooting/slp_1_animal_1_bp/project_folder',
+#                  data_folder='/Users/simon/Desktop/envs/troubleshooting/slp_1_animal_1_bp/import',
+#                  actor_IDs=['Termite_1'],
 #                  interpolation_settings="Body-parts: Nearest",
 #                  smoothing_settings = {'Method': 'Savitzky Golay', 'Parameters': {'Time_window': '200'}})
-# test.initate_import_slp()
+# test.run()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pose_importers/dlc_importer_csv.py` & `Simba-UW-tf-dev-1.57.6/simba/pose_importers/dlc_importer_csv.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,29 +1,23 @@
 __author__ = "Simon Nilsson", "JJ Choong"
 
 import shutil
 import os, glob
 import pandas as pd
-from simba.drop_bp_cords import get_fn_ext
-from simba.read_config_unit_tests import (read_config_file,
-                                          read_project_path_and_file_type,
-                                          check_file_exist_and_readable,
-                                          check_if_filepath_list_is_empty,
-                                          check_int)
-from simba.misc_tools import (SimbaTimer,
-                              get_number_of_header_columns_in_df,
-                              )
-from simba.utils.printing import stdout_success
+
+from simba.interpolate_smooth import Interpolate, Smooth
+from simba.utils.printing import stdout_success, SimbaTimer
 from simba.enums import Methods
-from simba.interpolate_pose import Interpolate
-from simba.misc_tools import smooth_data_savitzky_golay, smooth_data_gaussian
 from simba.utils.errors import NoFilesFoundError, FileExistError
+from simba.utils.read_write import get_fn_ext, read_config_file, read_project_path_and_file_type, get_number_of_header_columns_in_df
+from simba.utils.checks import check_file_exist_and_readable, check_if_filepath_list_is_empty, check_int, check_if_dir_exists
+from simba.utils.data import smooth_data_savitzky_golay, smooth_data_gaussian
 
-
-def import_dlc_csv(config_path: str, source: str) -> list:
+def import_dlc_csv(config_path: str,
+                   source: str) -> list:
     """
     Imports file or folder DLC pose-estimation CSV files to SimBA project. Returns list of file paths to the imported files.
 
     Parameters
     ----------
     config_path: str
         path to SimBA project config file in Configparser format
@@ -36,34 +30,32 @@
 
     Examples
     ----------
     >>> import_dlc_csv(config_path='project_folder/project_config.ini', source='CSV_import/Together_1.csv')
     >>> ['project_folder/csv/input_csv/Together_1.csv']
     """
 
-    config = read_config_file(ini_path=config_path)
+    config = read_config_file(config_path=config_path)
     project_path, file_type = read_project_path_and_file_type(config=config)
     original_file_name_dir = os.path.join(project_path, 'csv', 'input_csv', 'original_filename')
     input_csv_dir = os.path.join(project_path, 'csv', 'input_csv')
     imported_files = glob.glob(input_csv_dir + '/*.' + file_type)
-    imported_file_names = []
-    imported_file_paths = []
+    imported_file_names, imported_file_paths = [], []
     for file_path in imported_files:
         _, video_name, _ = get_fn_ext(filepath=file_path)
         imported_file_names.append(video_name)
     if not os.path.exists(original_file_name_dir): os.makedirs(original_file_name_dir)
     if os.path.isdir(source):
         csv_files = glob.glob(source + '/*.csv')
         check_if_filepath_list_is_empty(csv_files, error_msg=f'SIMBA ERROR: NO .csv files found in {source} directory.')
     else:
         csv_files = [source]
 
     for file_path in csv_files:
-        video_timer = SimbaTimer()
-        video_timer.start_timer()
+        video_timer = SimbaTimer(start=True)
         check_file_exist_and_readable(file_path=file_path)
         _, video_name, file_ext = get_fn_ext(filepath=file_path)
         if 'DLC_' in video_name:
             new_file_name = video_name.split('DLC_')[0] + '.csv'
         elif 'DeepCut' in video_name:
             new_file_name = video_name.split('DeepCut')[0] + '.csv'
         else:
@@ -85,76 +77,44 @@
             df = df.apply(pd.to_numeric, errors='coerce')
             df.to_parquet(os.path.join(input_csv_dir, new_file_name))
             os.remove(os.path.join(input_csv_dir, video_basename))
         if file_type == 'csv':
             df.to_csv(os.path.join(input_csv_dir, new_file_name), index=False)
         imported_file_paths.append(os.path.join(input_csv_dir, new_file_name))
         video_timer.stop_timer()
-        print(f'Pose-estimation data for video {video_name} imported to SimBA project (elapsed time: {video_timer.elapsed_time_str}s...')
+        print(f'Pose-estimation data for video {video_name} imported to SimBA project (elapsed time: {video_timer.elapsed_time_str}s)...')
     return imported_file_paths
 
 def import_single_dlc_tracking_csv_file(config_path: str,
                                         interpolation_setting: str,
                                         smoothing_setting: str,
                                         smoothing_time: int,
                                         file_path: str):
-    timer = SimbaTimer()
-    timer.start_timer()
+    timer = SimbaTimer(start=True)
     if (smoothing_setting == Methods.GAUSSIAN.value) or (smoothing_setting == Methods.SAVITZKY_GOLAY.value):
         check_int(name='SMOOTHING TIME WINDOW', value=smoothing_time, min_value=1)
-    if (config_path == 'No file selected') and (file_path == 'No file selected'):
-        raise NoFilesFoundError(msg='SIMBA ERROR: Please select a pose-estimation data path.')
-
     check_file_exist_and_readable(file_path=file_path)
-    imported_file_paths = import_dlc_csv(config_path=str(config_path), source=file_path)
-    config = read_config_file(ini_path=str(config_path))
-    csv_df = pd.read_csv(imported_file_paths[0], index_col=0)
+    imported_file_paths = import_dlc_csv(config_path=config_path, source=file_path)
     if interpolation_setting != 'None':
-        print(f'Interpolating missing values (Method: {interpolation_setting}) ...')
-        interpolate_body_parts = Interpolate(config_path, csv_df)
-        interpolate_body_parts.detect_headers()
-        interpolate_body_parts.fix_missing_values(interpolation_setting)
-        interpolate_body_parts.reorganize_headers()
-        interpolate_body_parts.new_df.to_csv(imported_file_paths[0])
-    if smoothing_setting == Methods.GAUSSIAN.value:
-        print(f'Smoothing data using Gaussian method and {str(smoothing_time)} ms time window ...')
-        smooth_data_gaussian(config=config, file_path=imported_file_paths[0], time_window_parameter=int(smoothing_time))
-    if smoothing_setting == Methods.SAVITZKY_GOLAY.value:
-        print(f'Smoothing data using Savitzky Golay method and {str(smoothing_time)} ms time window ...')
-        smooth_data_savitzky_golay(config=config, file_path=imported_file_paths[0], time_window_parameter=int(smoothing_time))
+        _ = Interpolate(input_path=imported_file_paths[0], config_path=config_path, method=interpolation_setting, initial_import_multi_index=True)
+    if (smoothing_setting == Methods.GAUSSIAN.value) or (smoothing_setting == Methods.SAVITZKY_GOLAY.value):
+        _ = Smooth(config_path=config_path, input_path=imported_file_paths[0], time_window=smoothing_time, smoothing_method=smoothing_setting, initial_import_multi_index=True)
     timer.stop_timer()
     stdout_success(msg=f'Imported {str(len(imported_file_paths))} pose estimation file(s)', elapsed_time=timer.elapsed_time_str)
 
 def import_multiple_dlc_tracking_csv_file(config_path: str,
                                           interpolation_setting: str,
                                           smoothing_setting: str,
                                           smoothing_time: int,
                                           folder_path: str):
-    timer = SimbaTimer()
-    timer.start_timer()
+    timer = SimbaTimer(start=True)
     if (smoothing_setting == Methods.GAUSSIAN.value) or (smoothing_setting == Methods.SAVITZKY_GOLAY.value):
         check_int(name='SMOOTHING TIME WINDOW', value=smoothing_time, min_value=1)
-    if (config_path== 'No file selected') and (folder_path == 'No folder selected'):
-        raise NoFilesFoundError(msg='Please select a pose-estimation data path.')
+    check_if_dir_exists(in_dir=folder_path)
     imported_file_paths = import_dlc_csv(config_path=config_path, source=folder_path)
-    config = read_config_file(ini_path=config_path)
+
     if interpolation_setting != 'None':
-        print(f'Interpolating missing values (Method: {interpolation_setting}) ...')
-        for file_path in imported_file_paths:
-            csv_df = pd.read_csv(file_path, index_col=0)
-            interpolate_body_parts = Interpolate(config_path, csv_df)
-            interpolate_body_parts.detect_headers()
-            interpolate_body_parts.fix_missing_values(interpolation_setting)
-            interpolate_body_parts.reorganize_headers()
-            interpolate_body_parts.new_df.to_csv(file_path)
-
-    if smoothing_setting == Methods.GAUSSIAN.value:
-        print(f'Smoothing data using Gaussian method and {str(smoothing_time)} ms time window ...')
-        for file_path in imported_file_paths:
-            smooth_data_gaussian(config=config, file_path=file_path, time_window_parameter=int(smoothing_time))
-
-    if smoothing_setting == Methods.SAVITZKY_GOLAY.value:
-        print(f'Smoothing data using Savitzky Golay method and {str(smoothing_time)} ms time window ...')
-        for file_path in imported_file_paths:
-            smooth_data_savitzky_golay(config=config, file_path=file_path, time_window_parameter=int(smoothing_time))
+        _ = Interpolate(input_path=os.path.dirname(imported_file_paths[0]), config_path=config_path, method=interpolation_setting, initial_import_multi_index=True)
+    if (smoothing_setting == Methods.GAUSSIAN.value) or (smoothing_setting == Methods.SAVITZKY_GOLAY.value):
+        _ = Smooth(config_path=config_path, input_path=os.path.dirname(imported_file_paths[0]), time_window=int(smoothing_time), smoothing_method=smoothing_setting, initial_import_multi_index=True)
     timer.stop_timer()
     stdout_success(msg=f'Imported {str(len(imported_file_paths))} pose estimation file(s)', elapsed_time=timer.elapsed_time_str)
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pose_importers/trk_importer.py` & `Simba-UW-tf-dev-1.57.6/simba/pose_importers/trk_importer.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,54 +1,40 @@
 from simba.read_config_unit_tests import read_config_file, read_config_entry
 import glob, os
 import scipy.io as sio
 import numpy as np
 import h5py
 import pandas as pd
-from simba.misc_tools import (check_multi_animal_status,
-                              get_fn_ext,
-                              find_video_of_file,
-                              get_video_meta_data)
-from simba.drop_bp_cords import (getBpNames,
-                                 createColorListofList,
-                                 create_body_part_dictionary,
-                                 getBpHeaders)
+from simba.utils.read_write import get_fn_ext, find_video_of_file, get_video_meta_data
 from simba.utils.errors import NoFilesFoundError, CountError
 from simba.utils.warnings import InvalidValueWarning
+from simba.mixins.config_reader import ConfigReader
 import cv2
 
-class TRKImporter(object):
+class TRKImporter(ConfigReader):
     def __init__(self,
                  config_path: str,
                  trk_folder: str,
                  animal_id_lst: list,
                  interpolation_method: str,
                  smooth_settings: dict):
 
-        self.config = read_config_file(config_path)
-        self.project_path = read_config_entry(self.config, 'General settings', 'project_path', data_type='folder_path')
+        ConfigReader.__init__(self, config_path=config_path)
         self.trk_folder, self.id_lst = trk_folder, animal_id_lst
         self.interpolation_method, self.smooth_settings = interpolation_method, smooth_settings
-        self.no_animals = read_config_entry(self.config, 'General settings', 'animal_no', 'int')
-        if self.no_animals == 1:
+        if self.animal_cnt == 1:
             self.animal_ids = ['Animal_1']
         else:
             self.animal_ids = read_config_entry(self.config, 'Multi animal IDs', 'id_list', 'str')
             self.animal_ids = self.animal_ids.split(",")
         self.files_found = glob.glob(self.trk_folder + '/*.trk')
         if len(self.files_found) == 0:
             raise NoFilesFoundError(msg=f'No TRK files (with .trk file-ending) found in {self.trk_folder}')
         self.video_folder = os.path.join(self.project_path, 'videos')
         self.save_folder = os.path.join(self.project_path, 'csv', 'input_csv')
-        self.file_type = read_config_entry(self.config, 'General settings', 'workflow_file_type', 'str', 'csv')
-        self.multi_animal_status, self.multi_animal_id_lst = check_multi_animal_status(self.config, self.no_animals)
-        self.x_cols, self.y_cols, self.p_cols = getBpNames(config_path)
-        self.color_lst = createColorListofList(self.no_animals, int(len(self.x_cols) / self.no_animals) + 1)
-        self.animal_pose_dict = create_body_part_dictionary(self.multi_animal_status, self.multi_animal_id_lst, self.no_animals, self.x_cols, self.y_cols, self.p_cols, self.color_lst)
-        self.bp_headers = getBpHeaders(config_path)
         self.space_scaler, self.radius_scaler, self.resolution_scaler, self.font_scaler = 40, 10, 1500, 1.2
         self.frm_number = 0
 
     def trk_read(self, file_path: str):
         print('Reading data using scipy.io...')
         try:
             trk_dict = sio.loadmat(file_path)
@@ -67,26 +53,26 @@
                     track_cnt = trk_coordinates.shape[3]
                     animals_tracked_list = [trk_coordinates[..., i] for i in range(track_cnt)]
                 else:
                     animals_tracked_list = np.swapaxes(t_second, 0, 2)
                     track_cnt = 1
 
         print('Number of animals detected in TRK {}: {}'.format(str(file_path), str(track_cnt)))
-        if track_cnt != self.no_animals:
-            raise CountError(msg=f'There are {str(track_cnt)} tracks in the .trk file {file_path}. But your SimBA project expects {str(self.no_animals)} tracks.')
+        if track_cnt != self.animal_cnt:
+            raise CountError(msg=f'There are {str(track_cnt)} tracks in the .trk file {file_path}. But your SimBA project expects {str(self.animal_cnt)} tracks.')
         return animals_tracked_list
 
     def import_trk(self):
         for file_cnt, file_path in enumerate(self.files_found):
             _, file_name, file_ext = get_fn_ext(file_path)
             video_path = find_video_of_file(self.video_folder, file_name)
             video_meta_data = get_video_meta_data(video_path=video_path)
             animal_tracks = self.trk_read(file_path=file_path)
 
-            if self.no_animals != 1:
+            if self.animal_cnt != 1:
                 animal_df_lst = []
                 for animal in animal_tracks:
                     m, n, r = animal.shape
                     out_arr = np.column_stack((np.repeat(np.arange(m), n), animal.reshape(m * n, -1)))
                     animal_df_lst.append(pd.DataFrame(out_arr).T.iloc[1:].reset_index(drop=True))
                 self.animal_df = pd.concat(animal_df_lst, axis=1).fillna(0)
             else:
@@ -107,27 +93,27 @@
             self.cap = cv2.VideoCapture(video_path)
             self.create_first_interface()
 
     def __insert_all_animal_bps(self, frame=None):
         for animal, bp_data in self.img_bp_cords_dict.items():
             for bp_cnt, bp_tuple in enumerate(bp_data):
                 try:
-                    cv2.circle(frame, bp_tuple, self.circle_scale, self.animal_pose_dict[animal]['colors'][bp_cnt], -1, lineType=cv2.LINE_AA)
+                    cv2.circle(frame, bp_tuple, self.circle_scale, self.animal_bp_dict[animal]['colors'][bp_cnt], -1, lineType=cv2.LINE_AA)
                 except Exception as err:
                     if type(err) == OverflowError:
                         InvalidValueWarning(f'SimBA encountered a pose-estimated body-part located at pixel position {str(bp_tuple)}. This value is too large to be converted to an integer. Please check your pose-estimation data to make sure that it is accurate.')
                     print(err.args)
 
     def create_first_interface(self):
         while True:
             self.cap.set(1, self.frm_number)
             _, self.frame = self.cap.read()
             self.overlay = self.frame.copy()
             self.img_bp_cords_dict = {}
-            for animal_cnt, (animal_name, animal_bps) in enumerate(self.animal_pose_dict.items()):
+            for animal_cnt, (animal_name, animal_bps) in enumerate(self.animal_bp_dict.items()):
                 self.img_bp_cords_dict[animal_name] = []
                 for bp_cnt in range(len(animal_bps['X_bps'])):
                     x_cord = int(self.animal_df.loc[self.frm_number, animal_name + '_' + animal_bps['X_bps'][bp_cnt]])
                     y_cord = int(self.animal_df.loc[self.frm_number, animal_name + '_' + animal_bps['Y_bps'][bp_cnt]])
                     self.img_bp_cords_dict[animal_name].append((x_cord, y_cord))
             self.__insert_all_animal_bps(frame=self.overlay)
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pop_up_classes.py` & `Simba-UW-tf-dev-1.57.6/simba/pop_up_classes.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,50 +1,58 @@
 __author__ = "Simon Nilsson"
 
 """
 Tkinter LabelFrame pop-up classes used in SimBA
 """
 
 import sys
-
-import numpy as np
-from simba.read_config_unit_tests import (read_config_file,
-                                          read_config_entry,
-                                          check_int,
-                                          check_float,
-                                          check_str,
-                                          check_file_exist_and_readable,
-                                          check_if_filepath_list_is_empty)
 import multiprocessing
-import webbrowser
 from tkinter import *
 import simba
-from simba.misc_tools import (get_video_meta_data,
-                              convert_parquet_to_csv,
-                              convert_csv_to_parquet,
-                              tabulate_clf_info,
-                              get_color_dict,
-                              find_all_videos_in_directory,
-                              get_file_name_info_in_directory,
-                              SimbaTimer,
-                              find_files_of_filetypes_in_directory,
-                              archive_processed_files,
-                              copy_img_folder,
-                              str_2_bool,
-                              concatenate_videos_in_folder)
-from simba.utils.printing import stdout_success, stdout_trash
-from simba.drop_bp_cords import get_fn_ext
-from simba.utils.lookups import get_third_party_appender_file_formats
+import numpy as np
+import pandas as pd
+import subprocess
+import urllib
+from collections import defaultdict
+from datetime import datetime
+from PIL import Image, ImageTk
+import atexit
+import os, glob
+
+from simba.utils.read_write import (read_config_file,
+                                    read_config_entry,
+                                    get_video_meta_data,
+                                    find_all_videos_in_directory,
+                                    concatenate_videos_in_folder,
+                                    find_files_of_filetypes_in_directory,
+                                    convert_parquet_to_csv,
+                                    convert_csv_to_parquet,
+                                    get_file_name_info_in_directory,
+                                    archive_processed_files,
+                                    str_2_bool,
+                                    get_all_clf_names,
+                                    read_df,
+                                    get_fn_ext,
+                                    read_video_info_csv,
+                                    tabulate_clf_info)
+
+from simba.utils.checks import (check_int,
+                                check_float,
+                                check_str,
+                                check_file_exist_and_readable,
+                                check_if_filepath_list_is_empty,
+                                check_if_dir_exists)
+from simba.utils.printing import stdout_success, stdout_trash, SimbaTimer
+from simba.utils.lookups import get_third_party_appender_file_formats, get_color_dict
 from simba.third_party_label_appenders.third_party_appender import ThirdPartyLabelAppender
 from simba.plotting.ROI_feature_visualizer import ROIfeatureVisualizer
 from simba.get_coordinates_tools_v2 import get_coordinates_nilsson
 from simba.roi_tools.ROI_clf_calculator import ROIClfCalculator
 from simba.tkinter_functions import hxtScrollbar, DropDownMenu, CreateToolTip, CreateLabelFrameWithIcon
-from simba.train_model_functions import get_all_clf_names
-from simba.interpolate_smooth_post_hoc import PostHocSmooth, PostHocInterpolate
+from simba.interpolate_smooth import Smooth, Interpolate
 from simba.tkinter_functions import Entry_Box, FileSelect, FolderSelect
 from simba.feature_extractors.feature_subsets import FeatureSubsetsCalculator
 from simba.reorganize_keypoint_in_pose import KeypointReorganizer
 from simba.plotting.ez_lineplot import DrawPathPlot
 from simba.FSTTC_calculator import FSTTCPerformer
 from simba.Kleinberg_calculator import KleinbergCalculator
 from simba.timebins_clf_analyzer import TimeBinsClf
@@ -62,15 +70,14 @@
 from simba.roi_tools.ROI_feature_analyzer import ROIFeatureCreator
 from simba.extract_seqframes import extract_seq_frames
 from simba.plotting.frame_mergerer_ffmpeg import FrameMergererFFmpeg
 from simba.plotting.ROI_feature_visualizer_mp import ROIfeatureVisualizerMultiprocess
 from simba.plotting.ROI_plotter import ROIPlot
 from simba.user_pose_config_creator import PoseConfigCreator
 from simba.pose_reset import PoseResetter
-from simba.read_config_unit_tests import check_if_dir_exists
 from simba.roi_tools.ROI_analyzer import ROIAnalyzer
 from simba.video_processing import (downsample_video,
                                     clahe_enhance_video,
                                     crop_single_video,
                                     crop_multiple_videos,
                                     clip_video_in_range,
                                     remove_beginning_of_video,
@@ -83,15 +90,16 @@
                                     extract_frames_single_video,
                                     batch_create_frames,
                                     change_single_video_fps,
                                     change_fps_of_multiple_videos,
                                     frames_to_movie,
                                     gif_creator,
                                     video_concatenator,
-                                    VideoRotator)
+                                    VideoRotator,
+                                    copy_img_folder)
 from simba.plotting.plot_clf_results import PlotSklearnResultsSingleCore
 from simba.plotting.plot_clf_results_mp import PlotSklearnResultsMultiProcess
 from simba.plotting.path_plotter import PathPlotterSingleCore
 from simba.plotting.path_plotter_mp import PathPlotterMulticore
 from simba.batch_process_videos.batch_process_menus import BatchProcessFrame
 from simba.plotting.Directing_animals_visualizer import DirectingOtherAnimalsVisualizer
 from simba.plotting.Directing_animals_visualizer_mp import DirectingOtherAnimalsVisualizerMultiprocess
@@ -100,70 +108,61 @@
 from simba.plotting.distance_plotter import DistancePlotterSingleCore
 from simba.plotting.clf_validator import ClassifierValidationClips
 from simba.plotting.single_run_model_validation_video import ValidateModelOneVideo
 from simba.plotting.single_run_model_validation_video_mp import ValidateModelOneVideoMultiprocess
 from simba.plotting.distance_plotter_mp import DistancePlotterMultiCore
 from simba.plotting.heat_mapper_clf import HeatMapperClfSingleCore
 from simba.plotting.heat_mapper_clf_mp import HeatMapperClfMultiprocess
-from simba.feature_extractors.unit_tests import read_video_info_csv
 from simba.plotting.data_plotter import DataPlotter
 from simba.severity_processor import SeverityProcessor
 from simba.enums import (ReadConfig,
                          Options,
                          Formats,
                          Paths,
                          Dtypes,
                          Links,
                          Keys)
-
-import pandas as pd
-import subprocess
-import urllib
-from collections import defaultdict
-from datetime import datetime
-from PIL import Image, ImageTk
-import atexit
-from simba.rw_dfs import read_df
-import os, glob
 from simba.pup_retrieval_protocol import PupRetrieverCalculator
 from simba.mixins.pop_up_mixin import PopUpMixin
 from simba.mixins.config_reader import ConfigReader
 from simba.utils.errors import (NoChoosenClassifierError,
                                 NoChoosenMeasurementError,
                                 NoChoosenROIError,
                                 NoFilesFoundError,
                                 CountError,
                                 FrameRangeError,
                                 NotDirectoryError,
                                 MixedMosaicError,
                                 DuplicationError,
                                 NoSpecifiedOutputError,
-                                NoROIDataError)
+                                NoROIDataError,
+                                AnimalNumberError)
 sys.setrecursionlimit(10**7)
 
-class HeatmapLocationPopup(PopUpMixin):
+class HeatmapLocationPopup(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str):
 
-        super().__init__(config_path=config_path, title='HEATMAPS: LOCATION')
+        PopUpMixin.__init__(self, title='HEATMAPS: LOCATION')
+        ConfigReader.__init__(self, config_path=config_path)
         self.data_path = os.path.join(self.project_path, Paths.OUTLIER_CORRECTED.value)
         self.files_found_dict = get_file_name_info_in_directory(directory=self.data_path, file_type=self.file_type)
         check_if_filepath_list_is_empty(filepaths=list(self.files_found_dict.keys()), error_msg='SIMBA ERROR: Zero files found in the project_folder/csv/outlier_corrected_movement_location directory. ')
         max_scales = list(np.linspace(5, 600, 5))
         max_scales.insert(0, 'Auto-compute')
         self.style_settings_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='STYLE SETTINGS', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.HEATMAP_LOCATION.value)
         self.palette_dropdown = DropDownMenu(self.style_settings_frm, 'Palette:', self.palette_options, '16')
         self.shading_dropdown = DropDownMenu(self.style_settings_frm, 'Shading:', self.shading_options, '16')
-        self.bp_dropdown = DropDownMenu(self.style_settings_frm, 'Body-part:', self.bp_names, '16')
+        self.bp_dropdown = DropDownMenu(self.style_settings_frm, 'Body-part:', self.body_parts_lst, '16')
         self.max_time_scale_dropdown = DropDownMenu(self.style_settings_frm, 'Max time scale (s):', max_scales, '16')
         self.bin_size_dropdown = DropDownMenu(self.style_settings_frm, 'Bin size (mm):', self.heatmap_bin_size_options, '16')
 
         self.palette_dropdown.setChoices(self.palette_options[0])
         self.shading_dropdown.setChoices(self.shading_options[0])
-        self.bp_dropdown.setChoices(self.bp_names[0])
+        self.bp_dropdown.setChoices(self.body_parts_lst[0])
         self.max_time_scale_dropdown.setChoices(max_scales[0])
         self.bin_size_dropdown.setChoices('8080')
 
         self.settings_frm = LabelFrame(self.main_frm, text='VISUALIZATION SETTINGS', font=("Helvetica", 14, 'bold'), pady=5, padx=5)
         self.heatmap_frames_var = BooleanVar()
         self.heatmap_videos_var = BooleanVar()
         self.heatmap_last_frm_var = BooleanVar()
@@ -174,16 +173,15 @@
         self.multiprocess_cb = Checkbutton(self.settings_frm, text='Multiprocess videos (faster)', variable=self.multiprocessing_var, command=lambda: self.enable_dropdown_from_checkbox(check_box_var=self.multiprocessing_var, dropdown_menus=[self.multiprocess_dropdown]))
         self.multiprocess_dropdown = DropDownMenu(self.settings_frm, 'CPU cores:', list(range(2, self.cpu_cnt)), '12')
         self.multiprocess_dropdown.setChoices(2)
         self.multiprocess_dropdown.disable()
 
         self.run_frm = LabelFrame(self.main_frm, text='RUN', font=Formats.LABELFRAME_HEADER_FORMAT.value, pady=5, padx=5, fg='black')
         self.run_single_video_frm = LabelFrame(self.run_frm, text='SINGLE VIDEO', font=Formats.LABELFRAME_HEADER_FORMAT.value, pady=5, padx=5, fg='black')
-        self.run_single_video_btn = Button(self.run_single_video_frm, text='Create single video', fg='blue',
-                                           command=lambda: self.__create_heatmap_plots(multiple_videos=False))
+        self.run_single_video_btn = Button(self.run_single_video_frm, text='Create single video', fg='blue', command=lambda: self.__create_heatmap_plots(multiple_videos=False))
         self.single_video_dropdown = DropDownMenu(self.run_single_video_frm, 'Video:', list(self.files_found_dict.keys()), '12')
         self.single_video_dropdown.setChoices(list(self.files_found_dict.keys())[0])
         self.run_multiple_videos = LabelFrame(self.run_frm, text='MULTIPLE VIDEO', font=Formats.LABELFRAME_HEADER_FORMAT.value, pady=5, padx=5, fg='black')
         self.run_multiple_video_btn = Button(self.run_multiple_videos, text='Create multiple videos ({} video(s) found)'.format(str(len(list(self.files_found_dict.keys())))), fg='blue', command=lambda: self.__create_heatmap_plots(multiple_videos=False))
 
         self.style_settings_frm.grid(row=0, sticky=NW)
         self.palette_dropdown.grid(row=0, sticky=NW)
@@ -214,15 +212,15 @@
 
         if multiple_videos:
             data_paths = list(self.files_found_dict.values())
         else:
             data_paths = [self.files_found_dict[self.single_video_dropdown.getChoices()]]
 
         if self.max_time_scale_dropdown.getChoices() != 'Auto-compute':
-            max_scale = int(self.max_time_scale_dropdown.getChoices().split('')[0])
+            max_scale = int(float(self.max_time_scale_dropdown.getChoices()))
         else:
             max_scale = 'auto'
 
         bin_size = int(self.bin_size_dropdown.getChoices().split('')[0])
 
         style_attr = {'palette': self.palette_dropdown.getChoices(),
                       'shading': self.shading_dropdown.getChoices(),
@@ -251,19 +249,20 @@
                                                             files_found=data_paths,
                                                             core_cnt=int(self.multiprocess_dropdown.getChoices()))
 
             heatmapper_clf.create_heatmaps()
 
 #_ = HeatmapLocationPopup(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini')
 
-class QuickLineplotPopup(PopUpMixin):
+class QuickLineplotPopup(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str):
 
-        super().__init__(config_path=config_path, title='SIMPLE LINE PLOT')
+        PopUpMixin.__init__(self, title='SIMPLE LINE PLOT')
+        ConfigReader.__init__(self, config_path=config_path)
         video_filepaths = find_all_videos_in_directory(directory=os.path.join(self.project_path, 'videos'))
         self.video_files = [os.path.basename(x) for x in video_filepaths]
         if len(self.video_files) == 0:
             raise NoFilesFoundError(msg='SIMBA ERROR: No files detected in the project_folder/videos directory.')
 
         self.all_body_parts = []
         for animal, bp_cords in self.animal_bp_dict.items():
@@ -288,102 +287,99 @@
         run_btn.grid(row=2, column=1, pady=10)
 
 
 #_ = QuickLineplotPopup(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini')
 
 
 
-class ClfByROIPopUp(PopUpMixin):
+class ClfByROIPopUp(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str):
 
-        super().__init__(config_path=config_path, title='CLASSIFICATIONS BY ROI')
-
-
+        PopUpMixin.__init__(self, title='CLASSIFICATIONS BY ROI')
+        ConfigReader.__init__(self, config_path=config_path)
+        self.read_roi_data()
         body_part_menu = CreateLabelFrameWithIcon(parent=self.main_frm, header='Select body part', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.ANALYZE_ML_RESULTS.value)
-        #body_part_menu = LabelFrame(self.main_frm, text='Select body part', padx=5, pady=5)
         ROI_menu = LabelFrame(self.main_frm, text='Select ROI(s)', padx=5, pady=5)
         classifier_menu = LabelFrame(self.main_frm, text='Select classifier(s)', padx=5, pady=5)
         measurements_menu = LabelFrame(self.main_frm, text='Select measurements', padx=5, pady=5)
-        self.clf_roi_analyzer = ROIClfCalculator(config_path)
         self.total_time_var = BooleanVar()
         self.start_bouts_var = BooleanVar()
         self.end_bouts_var = BooleanVar()
         self.total_time_cb = Checkbutton(measurements_menu, text='Total time by ROI (s)', variable=self.total_time_var)
         self.start_bouts_cb = Checkbutton(measurements_menu, text='Started bouts by ROI (count)', variable=self.start_bouts_var)
         self.end_bouts_cb = Checkbutton(measurements_menu, text='Ended bouts by ROI (count)', variable=self.end_bouts_var)
         self.ROI_check_boxes_status_dict = {}
         self.clf_check_boxes_status_dict = {}
 
-        for row_number, ROI in enumerate(self.clf_roi_analyzer.ROI_str_name_list):
+        for row_number, ROI in enumerate(self.roi_types_names_lst):
             self.ROI_check_boxes_status_dict[ROI] = IntVar()
             ROI_check_button = Checkbutton(ROI_menu, text=ROI, variable=self.ROI_check_boxes_status_dict[ROI])
             ROI_check_button.grid(row=row_number, sticky=W)
 
-        for row_number, clf_name in enumerate(self.clf_roi_analyzer.clf_names):
+        for row_number, clf_name in enumerate(self.clf_names):
             self.clf_check_boxes_status_dict[clf_name] = IntVar()
-            clf_check_button = Checkbutton(classifier_menu, text=clf_name,
-                                           variable=self.clf_check_boxes_status_dict[clf_name])
+            clf_check_button = Checkbutton(classifier_menu, text=clf_name, variable=self.clf_check_boxes_status_dict[clf_name])
             clf_check_button.grid(row=row_number, sticky=W)
 
-        self.choose_bp = DropDownMenu(body_part_menu, 'Body part', self.clf_roi_analyzer.body_part_list, '12')
-        self.choose_bp.setChoices(self.clf_roi_analyzer.body_part_list[0])
+        self.choose_bp = DropDownMenu(body_part_menu, 'Body part', self.body_parts_lst, '12')
+        self.choose_bp.setChoices(self.body_parts_lst[0])
         self.choose_bp.grid(row=0, sticky=W)
         run_analysis_button = Button(self.main_frm, text='Analyze classifications in each ROI',command=lambda: self.run_clf_by_ROI_analysis())
         body_part_menu.grid(row=0, sticky=W, padx=10, pady=10)
         ROI_menu.grid(row=1, sticky=W, padx=10, pady=10)
         classifier_menu.grid(row=2, sticky=W, padx=10, pady=10)
         self.total_time_cb.grid(row=0, sticky=NW)
         self.start_bouts_cb.grid(row=1, sticky=NW)
         self.end_bouts_cb.grid(row=2, sticky=NW)
         measurements_menu.grid(row=3, sticky=W, padx=10, pady=10)
         run_analysis_button.grid(row=4, sticky=W, padx=10, pady=10)
 
+        self.main_frm.mainloop()
+
     def run_clf_by_ROI_analysis(self):
         body_part_list = [self.choose_bp.getChoices()]
         ROI_dict_lists, behavior_list = defaultdict(list), []
         measurements_list = []
         for loop_val, ROI_entry in enumerate(self.ROI_check_boxes_status_dict):
             check_val = self.ROI_check_boxes_status_dict[ROI_entry]
             if check_val.get() == 1:
-                shape_type = self.clf_roi_analyzer.ROI_str_name_list[loop_val].split(':')[0].replace(':', '')
-                shape_name = self.clf_roi_analyzer.ROI_str_name_list[loop_val].split(':')[1][1:]
+                shape_type = self.roi_types_names_lst[loop_val].split(':')[0].replace(':', '')
+                shape_name = self.roi_types_names_lst[loop_val].split(':')[1][1:]
                 ROI_dict_lists[shape_type].append(shape_name)
 
         for measurement_var, measurement_name in zip([self.total_time_var.get(), self.start_bouts_var.get(), self.end_bouts_var.get()], ['Total time by ROI (s)', 'Started bouts by ROI (count)', 'Ended bouts by ROI (count)']):
             if measurement_var:
                 measurements_list.append(measurement_name)
 
 
         for loop_val, clf_entry in enumerate(self.clf_check_boxes_status_dict):
             check_val = self.clf_check_boxes_status_dict[clf_entry]
             if check_val.get() == 1:
-                behavior_list.append(self.clf_roi_analyzer.clf_names[loop_val])
+                behavior_list.append(self.clf_names[loop_val])
         if len(ROI_dict_lists) == 0:
             raise NoChoosenROIError()
         if len(behavior_list) == 0:
             raise NoChoosenClassifierError()
         if len(measurements_list) == 0:
             raise NoChoosenMeasurementError()
         else:
+            self.clf_roi_analyzer = ROIClfCalculator(config_ini=self.config_path)
             self.clf_roi_analyzer.run(ROI_dict_lists=ROI_dict_lists, behavior_list=behavior_list, body_part_list=body_part_list, measurements=measurements_list)
-
-#_ = ClfByROIPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini')
+#
+# _ = ClfByROIPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini')
 
 
-class FSTTCPopUp(PopUpMixin):
+class FSTTCPopUp(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str):
 
-        super().__init__(config_path=config_path, title='FORWARD SPIKE TIME TILING COEFFICIENTS')
-        fsttc_link_label = Label(self.main_frm, text='[Click here to learn about FSTTC]',cursor='hand2', fg='blue')
-        fsttc_link_label.bind('<Button-1>', lambda e: webbrowser.open_new('https://github.com/sgoldenlab/simba/blob/master/docs/FSTTC.md'))
-
+        PopUpMixin.__init__(self, title='FORWARD SPIKE TIME TILING COEFFICIENTS')
+        ConfigReader.__init__(self, config_path=config_path)
         fsttc_settings_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='FSTTC Settings', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.FSTTC.value)
-        #fsttc_settings_frm = LabelFrame(self.main_frm,text='FSTTC Settings', pady=5, padx=5,font=("Helvetica",12,'bold'),fg='black')
         graph_cb_var = BooleanVar()
         graph_cb = Checkbutton(fsttc_settings_frm,text='Create graph',variable=graph_cb_var)
         time_delta = Entry_Box(fsttc_settings_frm,'Time Delta','10', validation='numeric')
         behaviors_frm = LabelFrame(fsttc_settings_frm,text="Behaviors")
         clf_var_dict, clf_cb_dict = {}, {}
         for clf_cnt, clf in enumerate(self.clf_names):
             clf_var_dict[clf] = BooleanVar()
@@ -419,24 +415,21 @@
         FSTCC_performer.find_sequences()
         FSTCC_performer.calculate_FSTTC()
         FSTCC_performer.save_FSTTC()
         FSTCC_performer.plot_FSTTC()
 
 #_ = FSTTCPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/Two_animals_16bps/project_folder/project_config.ini')
 
-class KleinbergPopUp(PopUpMixin):
+class KleinbergPopUp(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str):
 
-        super().__init__(config_path=config_path, title='APPLY KLEINBERG BEHAVIOR CLASSIFICATION SMOOTHING')
+        PopUpMixin.__init__(self, title='APPLY KLEINBERG BEHAVIOR CLASSIFICATION SMOOTHING')
+        ConfigReader.__init__(self, config_path=config_path)
         kleinberg_settings_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='Kleinberg Settings', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.KLEINBERG.value)
-        #kleinberg_settings_frm = LabelFrame(self.main_frm,text='Kleinberg Settings', pady=5, padx=5, font=Formats.LABELFRAME_HEADER_FORMAT.value,fg='black')
-
-
-
         self.k_sigma = Entry_Box(kleinberg_settings_frm,'Sigma','10')
         self.k_sigma.entry_set('2')
         self.k_gamma = Entry_Box(kleinberg_settings_frm,'Gamma','10')
         self.k_gamma.entry_set('0.3')
         self.k_hierarchy = Entry_Box(kleinberg_settings_frm,'Hierarchy','10')
         self.k_hierarchy.entry_set('1')
         self.h_search_lbl = Label(kleinberg_settings_frm, text="Hierarchical search: ")
@@ -489,23 +482,22 @@
                                                  hierarchy=self.k_hierarchy.entry_get,
                                                  hierarchical_search=hierarchical_search)
         kleinberg_analyzer.perform_kleinberg()
 
 
 #_ = KleinbergPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/Two_animals_16bps/project_folder/project_config.ini')
 
-class TimeBinsClfPopUp(PopUpMixin):
+class TimeBinsClfPopUp(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str):
-        super().__init__(config_path=config_path, title='CLASSIFICATION BY TIME BINS')
-
+        PopUpMixin.__init__(self, title='CLASSIFICATION BY TIME BINS')
+        ConfigReader.__init__(self, config_path=config_path)
         cbox_titles = Options.TIMEBINS_MEASURMENT_OPTIONS.value
         self.timebin_entrybox = Entry_Box(self.main_frm, 'Set time bin size (s)', '15', validation='numeric')
         measures_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='MEASUREMENTS', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.ANALYZE_ML_RESULTS.value)
-        #measures_frm = LabelFrame(self.main_frm, text='MEASUREMENTS', font=Formats.LABELFRAME_HEADER_FORMAT.value, fg='black')
         clf_frm = LabelFrame(self.main_frm, text='CLASSIFIERS', font=Formats.LABELFRAME_HEADER_FORMAT.value, fg='black')
         self.measurements_var_dict, self.clf_var_dict = {}, {}
         for cnt, title in enumerate(cbox_titles):
             self.measurements_var_dict[title] = BooleanVar()
             cbox = Checkbutton(measures_frm, text=title, variable=self.measurements_var_dict[title])
             cbox.grid(row=cnt, sticky=NW)
         for cnt, clf_name in enumerate(self.clf_names):
@@ -533,20 +525,21 @@
             raise NoChoosenClassifierError()
         time_bins_clf_analyzer = TimeBinsClf(config_path=self.config_path, bin_length=int(self.timebin_entrybox.entry_get), measurements=measurement_lst, classifiers=clf_list)
         time_bins_clf_multiprocessor = multiprocessing.Process(target=time_bins_clf_analyzer.analyze_timebins_clf())
         time_bins_clf_multiprocessor.start()
 
 #_ = TimeBinsClfPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/Two_animals_16bps/project_folder/project_config.ini')
 
-class ClfDescriptiveStatsPopUp(PopUpMixin):
+class ClfDescriptiveStatsPopUp(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str):
-        super().__init__(config_path=config_path, title='ANALYZE CLASSIFICATIONS: DESCRIPTIVE STATISTICS')
+
+        PopUpMixin.__init__(self, title='ANALYZE CLASSIFICATIONS: DESCRIPTIVE STATISTICS')
+        ConfigReader.__init__(self, config_path=config_path)
         measures_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='MEASUREMENTS', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.ANALYZE_ML_RESULTS.value)
-       #measures_frm = LabelFrame(self.main_frm, text='MEASUREMENTS', font=Formats.LABELFRAME_HEADER_FORMAT.value, fg='black')
         clf_frm = LabelFrame(self.main_frm, text='CLASSIFIERS', font=Formats.LABELFRAME_HEADER_FORMAT.value, fg='black')
         self.measurements_var_dict, self.clf_var_dict = {}, {}
         cbox_titles = Options.CLF_DESCRIPTIVES_OPTIONS.value
         for cnt, title in enumerate(cbox_titles):
             self.measurements_var_dict[title] = BooleanVar()
             cbox = Checkbutton(measures_frm, text=title, variable=self.measurements_var_dict[title])
             cbox.grid(row=cnt, sticky=NW)
@@ -576,15 +569,15 @@
         data_log_analyzer.save()
 
 #_ = ClfDescriptiveStatsPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/Two_animals_16bps/project_folder/project_config.ini')
 
 class DownsampleVideoPopUp(PopUpMixin):
     def __init__(self):
 
-        super().__init__(title='DOWN-SAMPLE VIDEO RESOLUTION')
+        PopUpMixin.__init__(self, title='DOWN-SAMPLE VIDEO RESOLUTION')
         instructions = Label(self.main_frm, text='Choose only one of the following method (Custom or Default)')
         choose_video_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='SELECT VIDEO', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.DOWNSAMPLE.value)
         #choose_video_frm = LabelFrame(self.main_frm, text='SELECT VIDEO', font=Formats.LABELFRAME_HEADER_FORMAT.value, fg='black', padx=5, pady=5)
         self.video_path_selected = FileSelect(choose_video_frm, "Video path", title='Select a video file')
         custom_frm = LabelFrame(self.main_frm, text='Custom resolution', font=Formats.LABELFRAME_HEADER_FORMAT.value, fg='black', padx=5, pady=5)
         self.entry_width = Entry_Box(custom_frm, 'Width', '10', validation='numeric')
         self.entry_height = Entry_Box(custom_frm, 'Height', '10', validation='numeric')
@@ -624,15 +617,14 @@
 
 #_ = DownsampleVideoPopUp()
 
 class CLAHEPopUp(PopUpMixin):
     def __init__(self):
         super().__init__(title='CLAHE VIDEO CONVERSION')
         clahe_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='Contrast Limited Adaptive Histogram Equalization', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.VIDEO_TOOLS.value)
-        #clahe_frm = LabelFrame(self.main_frm, text='Contrast Limited Adaptive Histogram Equalization', font='bold', padx=5, pady=5)
         selected_video = FileSelect(clahe_frm, "Video path ", title='Select a video file')
         button_clahe = Button(clahe_frm, text='Apply CLAHE', command=lambda: clahe_enhance_video(file_path=selected_video.file_path))
         clahe_frm.grid(row=0,sticky=W)
         selected_video.grid(row=0,sticky=W)
         button_clahe.grid(row=1,pady=5)
         #self.main_frm.mainloop()
 
@@ -660,15 +652,14 @@
 
 #_ = CropVideoPopUp()
 
 class ClipVideoPopUp(PopUpMixin):
     def __init__(self):
         super().__init__(title='CLIP VIDEO')
         selected_video = CreateLabelFrameWithIcon(parent=self.main_frm, header='Video path', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.VIDEO_TOOLS.value)
-        #selected_video = FileSelect(self.main_frm, "Video path", title='Select a video file')
         method_1_frm = LabelFrame(self.main_frm, text='Method 1', font='bold', padx=5, pady=5)
         label_set_time_1 = Label(method_1_frm, text='Please enter the time frame in hh:mm:ss format')
         start_time = Entry_Box(method_1_frm, 'Start at (s):', '8', validation='numeric')
         end_time = Entry_Box(method_1_frm, 'End at (s):', '8', validation='numeric')
         CreateToolTip(method_1_frm, 'Method 1 will retrieve the specified time input. (eg: input of Start at: 00:00:00, End at: 00:01:00, will create a new video from the chosen video from the very start till it reaches the first minute of the video)')
         method_2_frm = LabelFrame(self.main_frm, text='Method 2', font='bold', padx=5, pady=5)
         method_2_time = Entry_Box(method_2_frm, 'Seconds:', '8', validation='numeric')
@@ -688,15 +679,14 @@
         #self.main_frm.mainloop()
 #_ = ClipVideoPopUp()
 
 class MultiShortenPopUp(PopUpMixin):
     def __init__(self):
         super().__init__(title='CLIP VIDEO INTO MULTIPLE VIDEOS')
         settings_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='Split videos into different parts', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.VIDEO_TOOLS.value)
-        #settings_frm = LabelFrame(self.main_frm, text='Split videos into different parts', font='bold', padx=5, pady=5)
         self.selected_video = FileSelect(settings_frm, "Video path", title='Select a video file', lblwidth=15)
         self.clip_cnt = Entry_Box(settings_frm, '# of clips', '15', validation='numeric')
         confirm_settings_btn = Button(settings_frm, text='Confirm', command=lambda: self.show_start_stop())
         settings_frm.grid(row=0, sticky=NW)
         self.selected_video.grid(row=1, sticky=NW, columnspan=2)
         self.clip_cnt.grid(row=2, sticky=NW)
         confirm_settings_btn.grid(row=2, column=1, sticky=W)
@@ -769,15 +759,14 @@
 class ConvertVideoPopUp(object):
     def __init__(self):
         main_frm = Toplevel()
         main_frm.minsize(200, 200)
         main_frm.wm_title("CONVERT VIDEO FORMAT")
 
         convert_multiple_videos_frm = CreateLabelFrameWithIcon(parent=main_frm, header='Convert multiple videos', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.VIDEO_TOOLS.value)
-        #convert_multiple_videos_frm = LabelFrame(main_frm, text='Convert multiple videos', font=Formats.LABELFRAME_HEADER_FORMAT.value, padx=5, pady=5)
         video_dir = FolderSelect(convert_multiple_videos_frm, 'Video directory', title='Select folder with videos')
         original_format = Entry_Box(convert_multiple_videos_frm, 'Input format', '12')
         output_format = Entry_Box(convert_multiple_videos_frm, 'Output format', '12')
         convert_multiple_btn = Button(convert_multiple_videos_frm, text='Convert multiple videos', command=lambda: batch_convert_video_format(directory=video_dir.folder_path, input_format=original_format.entry_get, output_format=output_format.entry_get))
 
         convert_single_video_frm = LabelFrame(main_frm,text='Convert single video',font=("Helvetica",12,'bold'),padx=5,pady=5)
         self.selected_video = FileSelect(convert_single_video_frm, "Video path", title='Select a video file')
@@ -962,26 +951,25 @@
 class PrintModelInfoPopUp(object):
     def __init__(self):
         model_info_win = Toplevel()
         model_info_win.minsize(250, 250)
         model_info_win.wm_title("PRINT MACHINE MODEL INFO")
         model_info_frame = LabelFrame(model_info_win, text='PRINT MODEL INFORMATION', padx=5, pady=5, font='bold')
         model_path_selector = FileSelect(model_info_frame, 'Model path', title='Select a video file')
-        btn_print_info = Button(model_info_frame,text='PRINT MODEL INFO',command=lambda:tabulate_clf_info(clf_path=model_path_selector.file_path))
+        btn_print_info = Button(model_info_frame,text='PRINT MODEL INFO',command=lambda: tabulate_clf_info(clf_path=model_path_selector.file_path))
         model_info_frame.grid(row=0, sticky=W)
         model_path_selector.grid(row=0, sticky=W, pady=5)
         btn_print_info.grid(row=1, sticky=W)
 
 class CreateGIFPopUP(object):
     def __init__(self):
         main_frm = Toplevel()
         main_frm.minsize(250, 250)
         main_frm.wm_title("CREATE GIF FROM VIDEO")
         settings_frm = CreateLabelFrameWithIcon(parent=main_frm, header='SETTINGS', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.VIDEO_TOOLS.value)
-        #settings_frm = LabelFrame(main_frm, text='SETTINGS', padx=5, pady=5, font=Formats.LABELFRAME_HEADER_FORMAT.value, fg='black')
         selected_video = FileSelect(settings_frm, 'Video path: ', title='Select a video file')
         start_time_entry_box = Entry_Box(settings_frm, 'Start time (s): ', '16', validation='numeric')
         duration_entry_box = Entry_Box(settings_frm, 'Duration (s): ', '16', validation='numeric')
         width_entry_box = Entry_Box(settings_frm, 'Width: ', '16', validation='numeric')
         width_instructions_1 = Label(settings_frm, text='example Width: 240, 360, 480, 720, 1080', font=("Times", 10, "italic"))
         width_instructions_2 = Label(settings_frm, text='Aspect ratio is kept (i.e., height is automatically computed)', font=("Times", 10, "italic"))
         run_btn = Button(settings_frm,text='CREATE GIF', command=lambda:gif_creator(file_path=selected_video.file_path, start_time=start_time_entry_box.entry_get, duration=duration_entry_box.entry_get, width=width_entry_box.entry_get))
@@ -1054,15 +1042,14 @@
         self.main_frm = Toplevel()
         self.main_frm.minsize(500,800)
         self.main_frm.wm_title('RE-ORGANIZE POSE_ESTIMATION DATA')
         self.main_frm.lift()
         self.main_frm = Canvas(hxtScrollbar(self.main_frm))
         self.main_frm.pack(fill="both", expand=True)
         settings_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='SETTINGS', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.VIDEO_TOOLS.value)
-        #settings_frm = LabelFrame(self.main_frm, text='SETTINGS', font=Formats.LABELFRAME_HEADER_FORMAT.value, pady=5, padx=5)
         self.data_folder = FolderSelect(settings_frm, 'DATA FOLDER: ', lblwidth='10')
         self.pose_tool_dropdown = DropDownMenu(settings_frm, 'Tracking tool', ['DLC', 'maDLC'], '10')
         self.pose_tool_dropdown.setChoices('DLC')
         self.file_format = DropDownMenu(settings_frm,'FILE TYPE: ',['csv','h5'],'10')
         self.file_format.setChoices('csv')
         confirm_btn = Button(settings_frm, text='Confirm', command=lambda: self.confirm())
         settings_frm.grid(row=0,sticky=NW)
@@ -1149,15 +1136,14 @@
 
 class ConcatenatingVideosPopUp(object):
     def __init__(self):
         main_frm = Toplevel()
         main_frm.minsize(300, 300)
         main_frm.wm_title("CONCATENATE VIDEOS")
         settings_frm = CreateLabelFrameWithIcon(parent=main_frm, header='SETTINGS', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.VIDEO_TOOLS.value)
-        #settings_frm = LabelFrame(main_frm, text='SETTINGS', font=Formats.LABELFRAME_HEADER_FORMAT.value, pady=5, padx=5)
         video_path_1 = FileSelect(settings_frm, "First video path: ", title='Select a video file')
         video_path_2 = FileSelect(settings_frm, "Second video path: ", title='Select a video file')
         resolutions = ['Video 1', 'Video 2', 320, 640, 720, 1280, 1980]
         resolution_dropdown = DropDownMenu(settings_frm, 'Resolution:', resolutions, '15')
         resolution_dropdown.setChoices(resolutions[0])
         horizontal = BooleanVar(value=False)
         horizontal_radio_btn = Radiobutton(settings_frm, text="Horizontal concatenation", variable=horizontal, value=True)
@@ -1296,21 +1282,21 @@
         for number, drop_down in enumerate(self.drop_down_list):
             bp_to_remove_list.append(drop_down.getChoices())
         if self.pose_tool == 'maDLC':
             for number, drop_down in enumerate(self.animal_names_lst):
                 animal_names_list.append(drop_down.getChoices())
         _ = self.keypoint_remover.run_bp_removal(bp_to_remove_list=bp_to_remove_list, animal_names=animal_names_list)
 
-class ConcatenatorPopUp(PopUpMixin):
+class ConcatenatorPopUp(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str or None):
-        super().__init__(config_path=config_path, title='MERGE (CONCATENATE) VIDEOS')
-        self.config_path = config_path
+
+        PopUpMixin.__init__(self, title='MERGE (CONCATENATE) VIDEOS')
+        ConfigReader.__init__(self, config_path=config_path)
         self.select_video_cnt_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='VIDEOS #', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.CONCAT_VIDEOS.value)
-        #self.select_video_cnt_frm = LabelFrame(self.main_frm, text='VIDEOS #', pady=5, padx=5, font=Formats.LABELFRAME_HEADER_FORMAT.value, fg='black')
         self.select_video_cnt_dropdown = DropDownMenu(self.select_video_cnt_frm, 'VIDEOS #', list(range(2,21)), '15')
         self.select_video_cnt_dropdown.setChoices(2)
         self.select_video_cnt_btn = Button(self.select_video_cnt_frm, text='SELECT', command=lambda: self.populate_table())
         self.select_video_cnt_frm.grid(row=0, column=0, sticky=NW)
         self.select_video_cnt_dropdown.grid(row=0, column=0, sticky=NW)
         self.select_video_cnt_btn.grid(row=0, column=1, sticky=NW)
 
@@ -1367,20 +1353,20 @@
 
         _ = FrameMergererFFmpeg(config_path=self.config_path,
                                 frame_types=videos_info,
                                 video_height=int(self.resolution_height.getChoices()),
                                 video_width=int(self.resolution_width.getChoices()),
                                 concat_type=self.join_type_var.get())
 
-class SetMachineModelParameters(PopUpMixin):
-
+class SetMachineModelParameters(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str):
 
-        super().__init__(config_path=config_path, title='SET MODEL PARAMETERS')
+        PopUpMixin.__init__(self, title='SET MODEL PARAMETERS')
+        ConfigReader.__init__(self, config_path=config_path)
         self.clf_table_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='SETTINGS', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.SET_RUN_ML_PARAMETERS.value)
         Label(self.clf_table_frm, text='CLASSIFIER', font=Formats.LABELFRAME_HEADER_FORMAT.value).grid(row=0, column=0)
         Label(self.clf_table_frm, text='MODEL PATH (.SAV)', font=Formats.LABELFRAME_HEADER_FORMAT.value).grid(row=0, column=1, sticky=NW)
         Label(self.clf_table_frm, text='DISCRIMINATION THRESHOLD', font=Formats.LABELFRAME_HEADER_FORMAT.value).grid(row=0, column=2, sticky=NW)
         Label(self.clf_table_frm, text='MINIMUM BOUT LENGTH (MS)', font=Formats.LABELFRAME_HEADER_FORMAT.value).grid(row=0, column=3, sticky=NW)
         self.clf_data = {}
         for clf_cnt, clf_name in enumerate(self.clf_names):
@@ -1411,23 +1397,24 @@
         with open(self.config_path, 'w') as f:
             self.config.write(f)
 
         stdout_success(msg='Model paths/settings saved in project_config.ini')
 
 #_ = SetMachineModelParameters(config_path='/Users/simon/Desktop/envs/troubleshooting/Two_animals_16bps/project_folder/project_config.ini')
 
-class OutlierSettingsPopUp(PopUpMixin):
+class OutlierSettingsPopUp(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str):
-        super().__init__(config_path=config_path, title='OUTLIER SETTINGS')
+
+        PopUpMixin.__init__(self, title='OUTLIER SETTINGS')
+        ConfigReader.__init__(self, config_path=config_path)
         self.animal_bps = {}
         for animal_name, animal_data in self.animal_bp_dict.items(): self.animal_bps[animal_name] = [x[:-2] for x in animal_data['X_bps']]
 
         self.location_correction_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='LOCATION CORRECTION', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.OULIERS.value)
-        #self.location_correction_frm = LabelFrame(self.main_frm, text='LOCATION CORRECTION', font=('Times', 12, 'bold'), pady=5, padx=5)
 
         bp_entry_cnt, self.criterion_dropdowns = 0, {}
         for animal_cnt, animal_name in enumerate(self.animal_bp_dict.keys()):
             self.criterion_dropdowns[animal_name] = {}
             self.criterion_dropdowns[animal_name]['location_bp_1'] = DropDownMenu(self.location_correction_frm, 'Choose {} body part 1:'.format(animal_name), self.animal_bps[animal_name], '30')
             self.criterion_dropdowns[animal_name]['location_bp_2'] = DropDownMenu(self.location_correction_frm, 'Choose {} body part 2:'.format(animal_name), self.animal_bps[animal_name], '30')
             self.criterion_dropdowns[animal_name]['location_bp_1'].setChoices(self.animal_bps[animal_name][0])
@@ -1478,21 +1465,21 @@
         with open(self.config_path, 'w') as f:
             self.config.write(f)
 
         stdout_success(msg='Outlier correction settings updated in the project_config.ini')
 
 # _ = OutlierSettingsPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/Two_animals_16bps/project_folder/project_config.ini')
 
-class RemoveAClassifierPopUp(PopUpMixin):
+class RemoveAClassifierPopUp(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str):
 
-        super().__init__(config_path=config_path, title='Warning: Remove classifier(s) settings')
+        PopUpMixin.__init__(self, title='Warning: Remove classifier(s) settings')
+        ConfigReader.__init__(self, config_path=config_path)
         self.remove_clf_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='SELECT A CLASSIFIER TO REMOVE', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.REMOVE_CLF.value)
-        #self.remove_clf_frm = LabelFrame(self.main_frm, text='SELECT A CLASSIFIER TO REMOVE')
         self.clf_dropdown = DropDownMenu(self.remove_clf_frm, 'Classifier', self.clf_names, '12')
         self.clf_dropdown.setChoices(self.clf_names[0])
 
         run_btn = Button(self.main_frm,text='REMOVE CLASSIFIER',command=lambda:self.run())
         self.remove_clf_frm.grid(row=0,sticky=W)
         self.clf_dropdown.grid(row=0,sticky=W)
         run_btn.grid(row=1,pady=10)
@@ -1515,31 +1502,31 @@
         with open(self.config_path, 'w') as f:
             self.config.write(f)
 
         stdout_trash(msg=f'{self.clf_dropdown.getChoices()} classifier removed from SimBA project.')
 
 #_ = RemoveAClassifierPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/Two_animals_16bps/project_folder/project_config.ini')
 
-class VisualizeROIFeaturesPopUp(PopUpMixin):
+class VisualizeROIFeaturesPopUp(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str):
 
-        super().__init__(config_path=config_path, title='VISUALIZE ROI FEATURES')
+        PopUpMixin.__init__(self, title='VISUALIZE ROI FEATURES')
+        ConfigReader.__init__(self, config_path=config_path)
         self.video_list = []
-        video_file_paths = find_files_of_filetypes_in_directory(directory=self.videos_dir, extensions=['.mp4', '.avi'])
+        video_file_paths = find_files_of_filetypes_in_directory(directory=self.video_dir, extensions=['.mp4', '.avi'])
         for file_path in video_file_paths:
             _, video_name, ext = get_fn_ext(filepath=file_path)
             self.video_list.append(video_name + ext)
 
         if len(self.video_list) == 0:
             raise NoFilesFoundError(msg='SIMBA ERROR: No videos in SimBA project. Import videos into you SimBA project to visualize ROI features.')
 
 
         self.settings_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='SETTINGS', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.ROI_FEATURES_PLOT.value)
-        #self.settings_frm = LabelFrame(self.main_frm, text='SETTINGS', pady=10, padx=10, font=Formats.LABELFRAME_HEADER_FORMAT.value, fg='black')
         self.threshold_entry_box = Entry_Box(self.settings_frm, 'Probability threshold', '15')
         self.threshold_entry_box.entry_set(0.0)
         threshold_label = Label(self.settings_frm, text='Note: body-part locations detected with probabilities below this threshold will be filtered out.', font=("Helvetica", 10, 'italic'))
         self.border_clr_dropdown = DropDownMenu(self.settings_frm, 'Border color:', list(self.colors_dict.keys()), '12')
         self.border_clr_dropdown.setChoices('Black')
 
         self.show_pose_var = BooleanVar(value=True)
@@ -1624,33 +1611,33 @@
                     roi_feature_visualizer_mp = multiprocessing.Process(target=roi_feature_visualizer.create_visualization())
                     roi_feature_visualizer_mp.start()
 
 #_ = VisualizeROIFeaturesPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/Two_animals_16bps/project_folder/project_config.ini')
 
 
 
-class VisualizeROITrackingPopUp(PopUpMixin):
+class VisualizeROITrackingPopUp(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str):
 
-        super().__init__(config_path=config_path, title='VISUALIZE ROI TRACKING')
+        PopUpMixin.__init__(self, title='VISUALIZE ROI TRACKING')
+        ConfigReader.__init__(self, config_path=config_path)
         self.video_list = []
-        video_file_paths = find_files_of_filetypes_in_directory(directory=self.videos_dir, extensions=['.mp4', '.avi'])
+        video_file_paths = find_files_of_filetypes_in_directory(directory=self.video_dir, extensions=['.mp4', '.avi'])
 
         for file_path in video_file_paths:
             _, video_name, ext = get_fn_ext(filepath=file_path)
             self.video_list.append(video_name + ext)
 
-        check_if_filepath_list_is_empty(filepaths=self.video_list, error_msg='SIMBA ERROR: No videos in SimBA project. Import videos into you SimBA project to visualize ROI tracking.')
+        check_if_filepath_list_is_empty(filepaths=self.video_list, error_msg='No videos in SimBA project. Import videos into you SimBA project to visualize ROI tracking.')
         self.multiprocess_var = BooleanVar()
         self.show_pose_var = BooleanVar(value=True)
         self.animal_name_var = BooleanVar(value=True)
 
         self.settings_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='SETTINGS', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.ROI_DATA_PLOT.value)
-        #self.settings_frm = LabelFrame(self.main_frm, text='SETTINGS', pady=10, padx=10, font=Formats.LABELFRAME_HEADER_FORMAT.value, fg='black')
         self.threshold_entry_box = Entry_Box(self.settings_frm, 'Body-part probability threshold', '30')
         self.threshold_entry_box.entry_set(0.0)
         threshold_label = Label(self.settings_frm, text='Note: body-part locations detected with probabilities below this threshold is removed from visualization.', font=("Helvetica", 10, 'italic'))
 
         self.show_pose_cb = Checkbutton(self.settings_frm, text='Show pose-estimated location', variable=self.show_pose_var)
         self.show_animal_name_cb = Checkbutton(self.settings_frm, text='Show animal names', variable=self.animal_name_var)
         self.multiprocess_cb = Checkbutton(self.settings_frm, text='Multi-process (faster)', variable=self.multiprocess_var, command=lambda: self.enable_dropdown_from_checkbox(check_box_var=self.multiprocess_var, dropdown_menus=[self.multiprocess_dropdown]))
@@ -1826,29 +1813,29 @@
         B2 = Button(popupframe, text="NO", fg='red', command=popup.destroy)
         popupframe.grid(row=0,columnspan=2)
         B1.grid(row=1,column=0,sticky=W)
         B2.grid(row=1,column=1,sticky=W)
         popup.mainloop()
 
 
-class SklearnVisualizationPopUp(PopUpMixin):
+class SklearnVisualizationPopUp(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str):
 
-        super().__init__(config_path=config_path, title='VISUALIZE CLASSIFICATION (SKLEARN) RESULTS')
-        self.video_lst = find_all_videos_in_directory(directory=self.videos_dir)
+        PopUpMixin.__init__(self, title='VISUALIZE CLASSIFICATION (SKLEARN) RESULTS')
+        ConfigReader.__init__(self, config_path=config_path)
+        self.video_lst = find_all_videos_in_directory(directory=self.video_dir)
         self.use_default_font_settings_val = BooleanVar(value=True)
         self.create_videos_var = BooleanVar()
         self.create_frames_var = BooleanVar()
         self.include_timers_var = BooleanVar()
         self.rotate_img_var = BooleanVar()
         self.multiprocess_var = BooleanVar()
 
         bp_threshold_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='BODY-PART VISUALIZATION THRESHOLD', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.SKLEARN_PLOTS.value)
-        #bp_threshold_frm = LabelFrame(self.main_frm,text='BODY-PART VISUALIZATION THRESHOLD',font=Formats.LABELFRAME_HEADER_FORMAT.value,padx=5,pady=5,fg='black')
         self.bp_threshold_lbl = Label(bp_threshold_frm,text='Body-parts detected below the set threshold won\'t be shown in the output videos.', font=("Helvetica", 11, 'italic'))
         self.bp_threshold_entry = Entry_Box(bp_threshold_frm,'Body-part probability threshold', '32')
         self.get_bp_probability_threshold()
 
         self.style_settings_frm = LabelFrame(self.main_frm, text='STYLE SETTINGS', font=Formats.LABELFRAME_HEADER_FORMAT.value, pady=5, padx=5, fg='black')
         self.auto_compute_font_cb = Checkbutton(self.style_settings_frm, text='Auto-compute font/key-point settings', variable=self.use_default_font_settings_val,
                                                 command= lambda: self.enable_entrybox_from_checkbox(check_box_var=self.use_default_font_settings_val, reverse=True, entry_boxes=[self.sklearn_text_size_entry_box, self.sklearn_text_spacing_entry_box, self.sklearn_text_thickness_entry_box, self.sklearn_circle_size_entry_box]))
@@ -1954,26 +1941,27 @@
                                                          print_timers=self.include_timers_var.get(),
                                                          text_settings=print_settings)
         simba_plotter.initialize_visualizations()
 
 #_ = SklearnVisualizationPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/Two_animals_16bps/project_folder/project_config.ini')
 
 
-class GanttPlotPopUp(PopUpMixin):
+class GanttPlotPopUp(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str):
-        super().__init__(config_path=config_path, title='VISUALIZE GANTT PLOTS')
+
+        PopUpMixin.__init__(self, config_path=config_path, title='VISUALIZE GANTT PLOTS')
+        ConfigReader.__init__(self, config_path=config_path)
         self.data_path = os.path.join(self.project_path, Paths.MACHINE_RESULTS_DIR.value)
         self.files_found_dict = get_file_name_info_in_directory(directory=self.data_path, file_type=self.file_type)
         check_if_filepath_list_is_empty(filepaths=list(self.files_found_dict.keys()),
                                         error_msg='SIMBA ERROR: Zero files found in the project_folder/csv/machine_results directory. Create classification results before visualizing gantt charts')
 
 
         self.style_settings_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='STYLE SETTINGS', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.GANTT_PLOTS.value)
-        #self.style_settings_frm = LabelFrame(self.main_frm, text='STYLE SETTINGS', font=Formats.LABELFRAME_HEADER_FORMAT.value, pady=5, padx=5)
         self.use_default_style_bool = BooleanVar(value=True)
         self.auto_compute_style_cb = Checkbutton(self.style_settings_frm, text='Use default style', variable=self.use_default_style_bool, command=lambda: self.enable_text_settings())
         self.resolution_dropdown = DropDownMenu(self.style_settings_frm, 'Resolution:', self.resolutions, '16')
         self.font_size_entry = Entry_Box(self.style_settings_frm, 'Font size: ', '16', validation='numeric')
         self.font_rotation_entry = Entry_Box(self.style_settings_frm, 'Font rotation degree: ', '16', validation='numeric')
         self.font_size_entry.entry_set(val=8)
         self.font_rotation_entry.entry_set(val=45)
@@ -2065,36 +2053,34 @@
         else:
             gantt_creator = GanttCreatorSingleProcess(config_path=self.config_path,
                                                       frame_setting=self.gantt_frames_var.get(),
                                                       video_setting=self.gantt_videos_var.get(),
                                                       last_frm_setting=self.gantt_last_frame_var.get(),
                                                       files_found=data_paths,
                                                       style_attr=style_attr)
-        gantt_creator.create_gannt()
+        gantt_creator.run()
 
 
 #_ = GanttPlotPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/Two_animals_16bps/project_folder/project_config.ini')
 
-
-
-class VisualizeClassificationProbabilityPopUp(PopUpMixin):
+class VisualizeClassificationProbabilityPopUp(PopUpMixin, ConfigReader):
 
     def __init__(self,
                  config_path: str):
-        super().__init__(config_path=config_path, title='CREATE CLASSIFICATION PROBABILITY PLOTS')
+        PopUpMixin.__init__(self, title='CREATE CLASSIFICATION PROBABILITY PLOTS')
+        ConfigReader.__init__(self, config_path=config_path)
         self.max_y_lst = [x for x in range(10, 110, 10)]
         self.max_y_lst.insert(0, 'auto')
         self.data_path = os.path.join(self.project_path, Paths.MACHINE_RESULTS_DIR.value)
         self.files_found_dict = get_file_name_info_in_directory(directory=self.data_path, file_type=self.file_type)
         check_if_filepath_list_is_empty(filepaths=list(self.files_found_dict.keys()),
                                         error_msg='SIMBA ERROR: Cant visualize probabilities, no data in project_folder/csv/machine_results directory')
 
 
         self.style_settings_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='STYLE SETTINGS', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.VISUALIZE_CLF_PROBABILITIES.value)
-        #self.style_settings_frm = LabelFrame(self.main_frm, text='STYLE SETTINGS', font=("Helvetica", 14, 'bold'), pady=5, padx=5)
         self.resolution_dropdown = DropDownMenu(self.style_settings_frm, 'Resolution:', self.resolutions, '16')
         self.max_y_dropdown = DropDownMenu(self.style_settings_frm, 'Max Y-axis:', self.max_y_lst, '16')
 
 
         self.line_clr_dropdown = DropDownMenu(self.style_settings_frm, 'Line color:', self.colors, '16')
         self.font_size_entry = Entry_Box(self.style_settings_frm, 'Font size: ', '16', validation='numeric')
         self.line_width = Entry_Box(self.style_settings_frm, 'Line width: ', '16', validation='numeric')
@@ -2195,19 +2181,20 @@
                                                                        clf_name=self.clf_dropdown.getChoices(),
                                                                        cores=int(self.multiprocess_dropdown.getChoices()),
                                                                        style_attr=style_attr)
         probability_plot_creator.create_plots()
 
 #_ = VisualizeClassificationProbabilityPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/Two_animals_16bps/project_folder/project_config.ini')
 
-class PathPlotPopUp(PopUpMixin):
+class PathPlotPopUp(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str):
 
-        super().__init__(config_path=config_path, title='CREATE PATH PLOTS')
+        PopUpMixin.__init__(self, title='CREATE PATH PLOTS')
+        ConfigReader.__init__(self, config_path=config_path)
         self.data_path = os.path.join(self.project_path, Paths.MACHINE_RESULTS_DIR.value)
         self.files_found_dict = get_file_name_info_in_directory(directory=self.data_path, file_type=self.file_type)
         check_if_filepath_list_is_empty(filepaths=list(self.files_found_dict.keys()),
                                         error_msg='SIMBA ERROR: Zero files found in the project_folder/csv/machine_results directory. Create classification results before visualizing path plots')
 
         self.resolutions.insert(0, 'As input')
         self.animal_cnt_options = list(range(1, self.project_animal_cnt+1))
@@ -2434,30 +2421,30 @@
                                                 input_clf_attr=clf_attr,
                                                 cores=int(self.multiprocess_dropdown.getChoices()))
 
         path_plotter.create_path_plots()
 
 #_ = PathPlotPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/Two_animals_16bps/project_folder/project_config.ini')
 
-class DistancePlotterPopUp(PopUpMixin):
+class DistancePlotterPopUp(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str):
 
-        super().__init__(config_path=config_path, title='CREATE DISTANCE PLOTS')
+        PopUpMixin.__init__(self, title='CREATE DISTANCE PLOTS')
+        ConfigReader.__init__(self, config_path=config_path)
 
         self.data_path = os.path.join(self.project_path, 'csv', 'outlier_corrected_movement_location')
         self.max_y_lst = list(range(10, 510, 10))
         self.max_y_lst.insert(0, 'auto')
         self.files_found_dict = get_file_name_info_in_directory(directory=self.data_path, file_type=self.file_type)
         check_if_filepath_list_is_empty(filepaths=list(self.files_found_dict.keys()),
                                         error_msg='SIMBA ERROR: Zero files found in the project_folder/csv/outlier_corrected_movement_location directory. ')
 
-        self.number_of_distances = list(range(1, len(self.bp_names)*2))
+        self.number_of_distances = list(range(1, len(self.body_parts_lst)*2))
         self.style_settings_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='STYLE SETTINGS', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.DISTANCE_PLOTS.value)
-        #self.style_settings_frm = LabelFrame(self.main_frm, text='STYLE SETTINGS', font=Formats.LABELFRAME_HEADER_FORMAT.value, pady=5, padx=5)
         self.resolution_dropdown = DropDownMenu(self.style_settings_frm, 'Resolution:', self.resolutions, '16')
         self.font_size_entry = Entry_Box(self.style_settings_frm, 'Font size: ', '16', validation='numeric')
         self.line_width = Entry_Box(self.style_settings_frm, 'Line width: ', '16', validation='numeric')
         self.opacity_dropdown = DropDownMenu(self.style_settings_frm, 'Line opacity:', list(np.round(np.arange(0.0, 1.1, 0.1), 1)), '16')
         self.max_y_dropdown = DropDownMenu(self.style_settings_frm, 'Max Y-axis:', self.max_y_lst, '16')
         self.resolution_dropdown.setChoices(self.resolutions[1])
         self.font_size_entry.entry_set(val=8)
@@ -2513,29 +2500,31 @@
         self.run_single_video_frm.grid(row=0, sticky=NW)
         self.run_single_video_btn.grid(row=0, column=0, sticky=NW)
         self.single_video_dropdown.grid(row=0, column=1, sticky=NW)
 
         self.run_multiple_videos.grid(row=1, sticky=NW)
         self.run_multiple_video_btn.grid(row=0, sticky=NW)
 
+        #self.main_frm.mainloop()
+
     def __populate_distances_menu(self, choice):
         if hasattr(self, 'bp_1'):
             for k,v in self.bp_1.items():
                 self.bp_1[k].destroy()
                 self.bp_2[k].destroy()
                 self.distance_clrs[k].destroy()
 
         self.bp_1, self.bp_2, self.distance_clrs = {}, {}, {}
         for distance_cnt in range(int(self.number_of_distances_dropdown.getChoices())):
-            self.bp_1[distance_cnt] = DropDownMenu(self.distances_frm, 'Distance {}:'.format(str(distance_cnt+1)), self.bp_names, '16')
-            self.bp_1[distance_cnt].setChoices(self.bp_names[distance_cnt])
+            self.bp_1[distance_cnt] = DropDownMenu(self.distances_frm, 'Distance {}:'.format(str(distance_cnt+1)), self.body_parts_lst, '16')
+            self.bp_1[distance_cnt].setChoices(self.body_parts_lst[distance_cnt])
             self.bp_1[distance_cnt].grid(row=distance_cnt+1, column=0, sticky=NW)
 
-            self.bp_2[distance_cnt] = DropDownMenu(self.distances_frm, '', self.bp_names, '2')
-            self.bp_2[distance_cnt].setChoices(self.bp_names[distance_cnt])
+            self.bp_2[distance_cnt] = DropDownMenu(self.distances_frm, '', self.body_parts_lst, '2')
+            self.bp_2[distance_cnt].setChoices(self.body_parts_lst[distance_cnt])
             self.bp_2[distance_cnt].grid(row=distance_cnt+1, column=1, sticky=NW)
 
             self.distance_clrs[distance_cnt] = DropDownMenu(self.distances_frm, '', self.colors_dict, '2')
             self.distance_clrs[distance_cnt].setChoices(list(self.colors_dict.keys())[distance_cnt])
             self.distance_clrs[distance_cnt].grid(row=distance_cnt + 1, column=3, sticky=NW)
 
     def __create_distance_plots(self,
@@ -2547,14 +2536,20 @@
             data_paths = [self.files_found_dict[self.single_video_dropdown.getChoices()]]
 
         line_attr = defaultdict(list)
         for attr in (self.bp_1, self.bp_2, self.distance_clrs):
             for key, value in attr.items():
                 line_attr[key].append(value.getChoices())
 
+        for cnt, (k, v) in enumerate(line_attr.items()):
+            if v[0] == v[1]:
+                raise DuplicationError(msg=f'DISTANCE LINE {cnt+1} ERROR: The two body-parts cannot be the same body-part.')
+
+
+
         width = int(self.resolution_dropdown.getChoices().split('')[0])
         height = int(self.resolution_dropdown.getChoices().split('')[1])
         check_int(name='DISTANCE FONT SIZE', value=self.font_size_entry.entry_get, min_value=1)
         check_int(name='DISTANCE LINE WIDTH', value=self.line_width.entry_get, min_value=1)
         style_attr = {'width': width,
                       'height': height,
                       'line width': int(self.line_width.entry_get),
@@ -2577,42 +2572,42 @@
                                                         style_attr=style_attr,
                                                         files_found=data_paths,
                                                         line_attr=line_attr,
                                                         core_cnt=int(self.multiprocess_dropdown.getChoices()))
 
         distance_plotter.create_distance_plot()
 
-# _ = DistancePlotterPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/Two_animals_16bps/project_folder/project_config.ini')
+#_ = DistancePlotterPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini')
 
 
-class HeatmapClfPopUp(PopUpMixin):
+class HeatmapClfPopUp(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str):
 
-        super().__init__(config_path=config_path, title='CREATE CLASSIFICATION HEATMAP PLOTS')
+        PopUpMixin.__init__(self, title='CREATE CLASSIFICATION HEATMAP PLOTS')
+        ConfigReader.__init__(self, config_path=config_path)
         self.data_path = os.path.join(self.project_path, Paths.MACHINE_RESULTS_DIR.value)
         self.files_found_dict = get_file_name_info_in_directory(directory=self.data_path, file_type=self.file_type)
         check_if_filepath_list_is_empty(filepaths=list(self.files_found_dict.keys()),
                                         error_msg='SIMBA ERROR: Zero files found in the project_folder/csv/machine_results directory. ')
         max_scales = list(np.linspace(5, 600, 5))
         max_scales.insert(0, 'Auto-compute')
 
         self.style_settings_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='STYLE SETTINGS', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.HEATMAP_CLF.value)
-        #self.style_settings_frm = LabelFrame(self.main_frm, text='STYLE SETTINGS', font=("Helvetica", 14, 'bold'), pady=5, padx=5)
         self.palette_dropdown = DropDownMenu(self.style_settings_frm, 'Palette:', self.palette_options, '16')
         self.shading_dropdown = DropDownMenu(self.style_settings_frm, 'Shading:', self.shading_options, '16')
         self.clf_dropdown = DropDownMenu(self.style_settings_frm, 'Classifier:', self.clf_names, '16')
-        self.bp_dropdown = DropDownMenu(self.style_settings_frm, 'Body-part:', self.bp_names, '16')
+        self.bp_dropdown = DropDownMenu(self.style_settings_frm, 'Body-part:', self.body_parts_lst, '16')
         self.max_time_scale_dropdown = DropDownMenu(self.style_settings_frm, 'Max time scale (s):', max_scales, '16')
         self.bin_size_dropdown = DropDownMenu(self.style_settings_frm, 'Bin size (mm):', self.heatmap_bin_size_options, '16')
 
         self.palette_dropdown.setChoices(self.palette_options[0])
         self.shading_dropdown.setChoices(self.shading_options[0])
         self.clf_dropdown.setChoices(self.clf_names[0])
-        self.bp_dropdown.setChoices(self.bp_names[0])
+        self.bp_dropdown.setChoices(self.body_parts_lst[0])
         self.max_time_scale_dropdown.setChoices(max_scales[0])
         self.bin_size_dropdown.setChoices('8080')
 
         self.settings_frm = LabelFrame(self.main_frm, text='VISUALIZATION SETTINGS', font=("Helvetica", 14, 'bold'), pady=5, padx=5)
         self.heatmap_frames_var = BooleanVar()
         self.heatmap_videos_var = BooleanVar()
         self.heatmap_last_frm_var = BooleanVar()
@@ -2704,25 +2699,25 @@
                                                        core_cnt=int(self.multiprocess_dropdown.getChoices()))
 
             heatmapper_clf.create_heatmaps()
 
 #_ = HeatmapClfPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/Two_animals_16bps/project_folder/project_config.ini')
 
 
-class DataPlotterPopUp(PopUpMixin):
+class DataPlotterPopUp(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str):
 
-        super().__init__(config_path=config_path, title='CREATE DATA PLOTS')
+        PopUpMixin.__init__(self, title='CREATE DATA PLOTS')
+        ConfigReader.__init__(self, config_path=config_path)
         self.color_lst = list(self.colors_dict.keys())
         self.data_path = os.path.join(self.project_path, Paths.OUTLIER_CORRECTED.value)
         self.files_found_dict = get_file_name_info_in_directory(directory=self.data_path, file_type=self.file_type)
-        self.animal_cnt_options = list(range(1, self.project_animal_cnt + 1))
+        self.animal_cnt_options = list(range(1, self.animal_cnt + 1))
         self.style_settings_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='STYLE SETTINGS', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.DATA_TABLES.value)
-        #self.style_settings_frm = LabelFrame(self.main_frm, text='STYLE SETTINGS', font=Formats.LABELFRAME_HEADER_FORMAT.value, pady=5, padx=5, fg='black')
         self.rounding_decimals_options = list(range(0, 11))
         self.font_thickness_options = list(range(1, 11))
         self.resolution_dropdown = DropDownMenu(self.style_settings_frm, 'RESOLUTION:', self.resolutions, '18')
         self.rounding_decimals_dropdown = DropDownMenu(self.style_settings_frm, 'DECIMAL ACCURACY:', self.rounding_decimals_options, '18')
         self.background_color_dropdown = DropDownMenu(self.style_settings_frm, 'BACKGROUND COLOR: ', self.color_lst, '18')
         self.font_color_dropdown = DropDownMenu(self.style_settings_frm, 'HEADER COLOR: ', self.color_lst, '18')
         self.font_thickness_dropdown = DropDownMenu(self.style_settings_frm, 'FONT THICKNESS: ', self.font_thickness_options, '18')
@@ -2771,21 +2766,21 @@
         self.run_single_video_btn.grid(row=0, sticky=NW)
         self.single_video_dropdown.grid(row=0, column=1, sticky=NW)
         self.run_multiple_videos.grid(row=1, sticky=NW)
         self.run_multiple_video_btn.grid(row=0, sticky=NW)
 
     def __populate_body_parts_menu(self, choice):
         if hasattr(self, 'bp_dropdowns'):
-            for (k, v), (k2, v2) in zip(self.bp_dropdowns.items(), self.bp_colors.items()):
+            for (k, v), (k2, v2) in zip(self.bp_dropdowns.items(), self.clr_lst.items()):
                 self.bp_dropdowns[k].destroy()
-                self.bp_colors[k].destroy()
+                self.clr_lst[k].destroy()
         self.bp_dropdowns, self.bp_colors = {}, {}
         for animal_cnt in range(int(self.number_of_animals_dropdown.getChoices())):
-            self.bp_dropdowns[animal_cnt] = DropDownMenu(self.body_parts_frm, 'Body-part {}:'.format(str(animal_cnt + 1)), self.bp_names, '16')
-            self.bp_dropdowns[animal_cnt].setChoices(self.bp_names[animal_cnt])
+            self.bp_dropdowns[animal_cnt] = DropDownMenu(self.body_parts_frm, 'Body-part {}:'.format(str(animal_cnt + 1)), self.body_parts_lst, '16')
+            self.bp_dropdowns[animal_cnt].setChoices(self.body_parts_lst[animal_cnt])
             self.bp_dropdowns[animal_cnt].grid(row=animal_cnt + 1, column=0, sticky=NW)
 
             self.bp_colors[animal_cnt] = DropDownMenu(self.body_parts_frm, '', self.color_lst, '2')
             self.bp_colors[animal_cnt].setChoices(self.color_lst[animal_cnt])
             self.bp_colors[animal_cnt].grid(row=animal_cnt + 1, column=1, sticky=NW)
 
     def __create_data_plots(self,
@@ -2816,20 +2811,23 @@
                                    video_setting=self.data_videos_var.get())
 
         _ = data_plotter.create_data_plots()
 
 #_ = DataPlotterPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/Two_animals_16bps/project_folder/project_config.ini')
 
 
-class DirectingOtherAnimalsVisualizerPopUp(PopUpMixin):
+class DirectingOtherAnimalsVisualizerPopUp(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str):
 
-        super().__init__(config_path=config_path, title='CREATE ANIMAL DIRECTION VIDEOS')
 
+        ConfigReader.__init__(self, config_path=config_path)
+        if self.animal_cnt == 1:
+            raise AnimalNumberError(msg='Cannot visualize directionality between animals in a 1 animal project.')
+        PopUpMixin.__init__(self, title='CREATE ANIMAL DIRECTION VIDEOS')
         self.color_lst = list(self.colors_dict.keys())
         self.color_lst.insert(0, 'Random')
         self.size_lst = list(range(1, 11))
         self.data_path = os.path.join(self.project_path, Paths.OUTLIER_CORRECTED.value)
         self.files_found_dict = get_file_name_info_in_directory(directory=self.data_path, file_type=self.file_type)
 
         self.show_pose_var = BooleanVar(value=True)
@@ -2953,26 +2951,26 @@
         self.dashboard_file.grid(row=0, column=0, sticky='NW')
         self.groups_file.grid(row=1, column=0, sticky='NW')
         self.load_btn.grid(row=2, column=0, sticky='NW')
 
         self.main_frm.mainloop()
 
     def save(self):
-        config = read_config_file(ini_path=self.config_path)
+        config = read_config_file(config_path=self.config_path)
         project_path = read_config_entry(config, 'General settings', 'project_path', data_type='folder_path')
         file_type = read_config_entry(config, 'General settings', 'workflow_file_type', 'str', 'csv')
         model_cnt = read_config_entry(config=config, section='SML settings', option='no_targets', data_type='int')
         logs_path = os.path.join(project_path, 'logs')
         datetime_stamp = datetime.now().strftime('%Y%m%d%H%M%S')
         self.storage_path = os.path.join(logs_path, 'SimBA_dash_storage_{}.h5'.format(datetime_stamp))
         storage_file = pd.HDFStore(self.storage_path, table=True, complib='blosc:zlib', complevel=9)
         video_info_path = os.path.join(project_path, 'logs', 'video_info.csv')
         video_info_df = read_video_info_csv(file_path=video_info_path)
         machine_results_dir = os.path.join(project_path, 'csv', 'machine_results')
-        clf_names = simba.train_model_functions.get_all_clf_names(config=config, target_cnt=model_cnt)
+        clf_names = get_all_clf_names(config=config, target_cnt=model_cnt)
         clf_col_names = clf_names + ['Probability_' + x for x in clf_names]
         storage_file['Classifier_names'] = pd.DataFrame(data=clf_names, columns=['Classifier_names'])
         storage_file['Video_info'] = video_info_df
         timer = SimbaTimer()
         timer.start_timer()
 
         if self.agg_clf_data_var.get():
@@ -3054,19 +3052,19 @@
 
 class PupRetrievalPopUp(object):
     def __init__(self,
                  config_path: str):
 
         self.smoothing_options, self.config_path = ['gaussian'], config_path
         self.smooth_factor_options = list(range(1, 11))
-        self.config = read_config_file(ini_path=config_path)
+        self.config = read_config_file(config_path=config_path)
         self.project_path = read_config_entry(self.config, ReadConfig.GENERAL_SETTINGS.value,  ReadConfig.PROJECT_PATH.value, data_type=ReadConfig.FOLDER_PATH.value)
         self.ROI_path = os.path.join(self.project_path, Paths.ROI_DEFINITIONS.value)
         self.roi_analyzer = ROIAnalyzer(ini_path=config_path, data_path=None)
-        self.roi_analyzer.read_roi_dfs()
+        self.roi_analyzer.run()
         self.shape_names = self.roi_analyzer.shape_names
         self.animal_names = self.roi_analyzer.multi_animal_id_list
         self.clf_names = get_all_clf_names(config=self.config, target_cnt=self.roi_analyzer.clf_cnt)
 
         self.distance_plots_var = BooleanVar(value=True)
         self.swarm_plot_var = BooleanVar(value=True)
         self.log_var = BooleanVar(value=True)
@@ -3178,73 +3176,108 @@
                     'distance_plots': distance_plot,
                     'log': log}
 
         pup_calculator = PupRetrieverCalculator(config_path=self.config_path, settings=settings)
         pup_calculator.run()
         pup_calculator.save_results()
 
-class ClassifierValidationPopUp(PopUpMixin):
+class ClassifierValidationPopUp(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str):
 
-        super().__init__(config_path=config_path, title='SIMBA CLASSIFIER VALIDATION CLIPS')
+        PopUpMixin.__init__(self, title='SIMBA CLASSIFIER VALIDATION CLIPS')
+        ConfigReader.__init__(self, config_path=config_path)
         color_names = list(self.colors_dict.keys())
         self.one_vid_per_bout_var = BooleanVar(value=False)
         self.one_vid_per_video_var = BooleanVar(value=True)
+        self.files_found_dict = get_file_name_info_in_directory(directory=self.machine_results_dir, file_type=self.file_type)
         self.settings_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='SETTINGS', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.CLF_VALIDATION.value)
-        #self.settings_frm = LabelFrame(self.main_frm, text='SETTINGS', font=Formats.LABELFRAME_HEADER_FORMAT.value, pady=5, padx=5, fg='black')
-        self.seconds_entry = Entry_Box(self.settings_frm, 'SECONDS: ', '15', validation='numeric')
-        self.clf_dropdown = DropDownMenu(self.settings_frm, 'CLASSIFIER: ', self.clf_names, '15')
-        self.clr_dropdown = DropDownMenu(self.settings_frm, 'TEXT COLOR: ', color_names, '15')
+        self.seconds_entry = Entry_Box(self.settings_frm, 'SECONDS PADDING: ', '20', validation='numeric')
+        self.clf_dropdown = DropDownMenu(self.settings_frm, 'CLASSIFIER: ', self.clf_names, '20')
+        self.clr_dropdown = DropDownMenu(self.settings_frm, 'TEXT COLOR: ', color_names, '20')
+        self.highlight_clr_dropdown = DropDownMenu(self.settings_frm, 'HIGHLIGHT TEXT COLOR: ', ['None'] + color_names, '20')
+        self.video_speed_dropdown = DropDownMenu(self.settings_frm, 'VIDEO SPEED: ', Options.SPEED_OPTIONS.value, '20')
         self.clf_dropdown.setChoices(self.clf_names[0])
         self.clr_dropdown.setChoices('Cyan')
         self.seconds_entry.entry_set(val=2)
-
+        self.highlight_clr_dropdown.setChoices('None')
+        self.video_speed_dropdown.setChoices(1.0)
         self.individual_bout_clips_cb = Checkbutton(self.settings_frm, text='CREATE ONE CLIP PER BOUT', variable=self.one_vid_per_bout_var)
         self.individual_clip_per_video_cb = Checkbutton(self.settings_frm, text='CREATE ONE CLIP PER VIDEO', variable=self.one_vid_per_video_var)
 
-        run_btn = Button(self.settings_frm, text='RUN VALIDATION', command= lambda: self.run())
-        self.settings_frm.grid(row=0,sticky=W)
-        self.seconds_entry.grid(row=0,sticky=W)
-        self.clf_dropdown.grid(row=1,sticky=W)
-        self.clr_dropdown.grid(row=2, sticky=W)
-        self.individual_bout_clips_cb.grid(row=3, column=0, sticky=NW)
-        self.individual_clip_per_video_cb.grid(row=4, column=0, sticky=NW)
-        run_btn.grid(row=5,sticky=NW)
+        self.run_frm = LabelFrame(self.main_frm, text='RUN', font=Formats.LABELFRAME_HEADER_FORMAT.value, pady=5, padx=5, fg='black')
+        self.run_single_video_frm = LabelFrame(self.run_frm, text='SINGLE VIDEO', font=Formats.LABELFRAME_HEADER_FORMAT.value, pady=5, padx=5, fg='black')
+        self.run_single_video_btn = Button(self.run_single_video_frm, text='Create single video', fg='blue', command=lambda: self.run(multiple_videos=False))
+        self.single_video_dropdown = DropDownMenu(self.run_single_video_frm, 'Video:', list(self.files_found_dict.keys()), '12')
+        self.single_video_dropdown.setChoices(list(self.files_found_dict.keys())[0])
+        self.run_multiple_videos = LabelFrame(self.run_frm, text='MULTIPLE VIDEO', font=Formats.LABELFRAME_HEADER_FORMAT.value, pady=5, padx=5, fg='black')
+        self.run_multiple_video_btn = Button(self.run_multiple_videos, text='Create multiple videos ({} video(s) found)'.format(str(len(list(self.files_found_dict.keys())))), fg='blue', command=lambda: self.run(multiple_videos=True))
+        run_btn = Button(self.run_frm, text='RUN VALIDATION', command= lambda: self.run())
+        self.settings_frm.grid(row=0,sticky=NW)
+        self.seconds_entry.grid(row=0, sticky=NW)
+        self.clf_dropdown.grid(row=1, sticky=NW)
+        self.clr_dropdown.grid(row=2, sticky=NW)
+        self.highlight_clr_dropdown.grid(row=3, sticky=NW)
+        self.video_speed_dropdown.grid(row=4, sticky=NW)
+        self.individual_bout_clips_cb.grid(row=5, column=0, sticky=NW)
+        self.individual_clip_per_video_cb.grid(row=6, column=0, sticky=NW)
 
-    def run(self):
+        self.run_frm.grid(row=1, column=0, sticky=NW)
+        self.run_single_video_frm.grid(row=0, column=0, sticky=NW)
+        self.run_single_video_btn.grid(row=0, column=0, sticky=NW)
+        self.single_video_dropdown.grid(row=0, column=1, sticky=NW)
+        self.run_multiple_videos.grid(row=1, column=0, sticky=NW)
+        self.run_multiple_video_btn.grid(row=0, column=0, sticky=NW)
+        run_btn.grid(row=2, column=0, sticky=NW)
+
+        #self.main_frm.mainloop()
+
+    def run(self, multiple_videos: bool):
         check_int(name='CLIP SECONDS', value=self.seconds_entry.entry_get)
+        if self.highlight_clr_dropdown.getChoices() == 'None':
+            highlight_clr = None
+        else:
+            highlight_clr = self.colors_dict[self.highlight_clr_dropdown.getChoices()]
+        if multiple_videos:
+            data_paths = list(self.files_found_dict.values())
+        else:
+            data_paths = [self.files_found_dict[self.single_video_dropdown.getChoices()]]
+
         clf_validator = ClassifierValidationClips(config_path=self.config_path,
                                                   window=int(self.seconds_entry.entry_get),
                                                   clf_name=self.clf_dropdown.getChoices(),
                                                   clips=self.one_vid_per_bout_var.get(),
                                                   text_clr=self.colors_dict[self.clr_dropdown.getChoices()],
-                                                  concat_video=self.one_vid_per_video_var.get())
-        clf_validator.create_clips()
+                                                  highlight_clr=highlight_clr,
+                                                  video_speed=float(self.video_speed_dropdown.getChoices()),
+                                                  concat_video=self.one_vid_per_video_var.get(),
+                                                  data_paths=data_paths)
+        clf_validator.run()
 
 
-#_ = ClassifierValidationPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/Two_animals_16bps/project_folder/project_config.ini')
+#_ = ClassifierValidationPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini')
 
-class AnalyzeSeverityPopUp(PopUpMixin):
+class AnalyzeSeverityPopUp(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str):
 
-        super().__init__(config_path=config_path, title='SIMBA SEVERITY ANALYSIS')
-        if len(self.multi_animal_id_lst) > 1:
-            self.multi_animal_id_lst.insert(0, 'ALL ANIMALS')
+        PopUpMixin.__init__(self, title='SIMBA SEVERITY ANALYSIS')
+        ConfigReader.__init__(self, config_path=config_path)
+
+        if len(self.multi_animal_id_list) > 1:
+            self.multi_animal_id_list.insert(0, 'ALL ANIMALS')
         self.frame_cnt_var = BooleanVar(value=False)
         self.seconds_cnt_var = BooleanVar(value=False)
         self.settings_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='SETTINGS', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.ANALYZE_ML_RESULTS.value)
-        #self.settings_frm = LabelFrame(self.main_frm, text='SETTINGS', font=Formats.LABELFRAME_HEADER_FORMAT.value, pady=5, padx=5, fg='black')
         self.clf_dropdown = DropDownMenu(self.settings_frm, 'CLASSIFIER:', self.clf_names, '25')
         self.clf_dropdown.setChoices(self.clf_names[0])
         self.brackets_dropdown = DropDownMenu(self.settings_frm, 'BRACKETS:', list(range(1,21)), '25')
         self.brackets_dropdown.setChoices(10)
-        self.animal_dropdown = DropDownMenu(self.settings_frm, 'ANIMALS', self.multi_animal_id_lst, '25')
-        self.animal_dropdown.setChoices(self.multi_animal_id_lst[0])
+        self.animal_dropdown = DropDownMenu(self.settings_frm, 'ANIMALS', self.multi_animal_id_list, '25')
+        self.animal_dropdown.setChoices(self.multi_animal_id_list[0])
 
         frame_cnt_cb = Checkbutton(self.settings_frm, text='FRAME COUNT', variable=self.frame_cnt_var)
         seconds_cnt_cb = Checkbutton(self.settings_frm, text='SECONDS', variable=self.seconds_cnt_var)
 
         run_frm = LabelFrame(self.main_frm, text='RUN', font=Formats.LABELFRAME_HEADER_FORMAT.value, pady=5, padx=5, fg='black')
         run_btn = Button(run_frm, text='RUN SEVERITY ANALYSIS', command= lambda: self.run())
 
@@ -3256,15 +3289,15 @@
         seconds_cnt_cb.grid(row=4, column=0, sticky=NW)
 
         run_frm.grid(row=1, column=0, sticky=NW)
         run_btn.grid(row=0, column=0, sticky=NW)
 
     def run(self):
         if self.animal_dropdown.getChoices() == 'ALL ANIMALS':
-            animals = self.multi_animal_id_lst[1:]
+            animals = self.multi_animal_id_list[1:]
         else:
             animals = [self.animal_dropdown.getChoices()]
         settings = {'brackets': int(self.brackets_dropdown.getChoices()),
                     'clf': self.clf_dropdown.getChoices(),
                     'animals': animals,
                     'time': self.seconds_cnt_var.get(),
                     'frames': self.frame_cnt_var.get()}
@@ -3272,18 +3305,20 @@
         if (not self.seconds_cnt_var.get()) and (not self.frame_cnt_var.get()):
             raise NoSpecifiedOutputError(msg='SIMBA ERROR: Please select frames and/or time output metrics')
         severity_processor = SeverityProcessor(config_path=self.config_path,
                                                settings=settings)
         severity_processor.run()
         severity_processor.save()
 
-class ImportFrameDirectoryPopUp(PopUpMixin):
+class ImportFrameDirectoryPopUp(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str):
-        super().__init__(config_path=config_path, title='IMPORT FRAME DIRECTORY')
+
+        PopUpMixin.__init__(self, title='IMPORT FRAME DIRECTORY')
+        ConfigReader.__init__(self, config_path=config_path)
         self.frame_folder = FolderSelect(self.main_frm, 'FRAME DIRECTORY:', title='Select the main directory with frame folders')
         import_btn = Button(self.main_frm, text='IMPORT FRAMES', fg='blue', command=lambda: self.run())
 
         self.frame_folder.grid(row=0, column=0, sticky=NW)
         import_btn.grid(row=1, column=0, sticky=NW)
 
     def run(self):
@@ -3310,52 +3345,60 @@
         self.config.set(ReadConfig.SML_SETTINGS.value, f'target_name_{str(self.target_cnt + 1)}', clf_name)
         self.config.set(ReadConfig.THRESHOLD_SETTINGS.value, f'threshold_{str(self.target_cnt + 1)}', 'None')
         self.config.set(ReadConfig.MIN_BOUT_LENGTH.value, f'min_bout_{str(self.target_cnt + 1)}', 'None')
         with open(self.config_path, 'w') as f:
             self.config.write(f)
         stdout_success(msg=f'{clf_name} classifier added to SimBA project')
 
-class ArchiveProcessedFilesPopUp(PopUpMixin):
+class ArchiveProcessedFilesPopUp(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str):
-        PopUpMixin.__init__(self, config_path=config_path, title='ADD CLASSIFIER')
+
+        PopUpMixin.__init__(self, title='ADD CLASSIFIER')
+        ConfigReader.__init__(self, config_path=config_path)
         self.archive_eb = Entry_Box(self.main_frm,'ARCHIVE DIRECTORY NAME', '25')
         archive_btn = Button(self.main_frm, text='RUN ARCHIVE', fg='blue', command=lambda: self.run())
         self.archive_eb.grid(row=0, column=0, sticky=NW)
         archive_btn.grid(row=1, column=0, sticky=NW)
 
     def run(self):
         archive_name = self.archive_eb.entry_get.strip()
         check_str(name='CLASSIFIER NAME', value=archive_name)
         archive_processed_files(config_path=self.config_path,
                                 archive_name=archive_name)
 
 
-class InterpolatePopUp(PopUpMixin):
+class InterpolatePopUp(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str):
-        PopUpMixin.__init__(self, config_path=config_path, title='INTERPOLATE POSE')
+
+        PopUpMixin.__init__(self, title='INTERPOLATE POSE')
+        ConfigReader.__init__(self, config_path=config_path)
         self.input_dir = FolderSelect(self.main_frm, 'DATA DIRECTORY:', lblwidth=25)
         self.method_dropdown = DropDownMenu(self.main_frm, 'INTERPOLATION METHOD:', Options.INTERPOLATION_OPTIONS.value, '25')
         self.method_dropdown.setChoices(Options.INTERPOLATION_OPTIONS.value[0])
         run_btn = Button(self.main_frm, text='RUN INTERPOLATION', fg='blue', command=lambda: self.run())
         self.input_dir.grid(row=0, column=0, sticky=NW)
         self.method_dropdown.grid(row=1, column=0, sticky=NW)
         run_btn.grid(row=2, column=0, sticky=NW)
 
     def run(self):
         if not os.path.isdir(self.input_dir.folder_path):
             raise NotDirectoryError(msg=f'{self.input_dir.folder_path} is not a valid directory.')
-        PostHocInterpolate(config_path=self.config_path, method=self.method_dropdown.getChoices(), input_dir=self.input_dir.folder_path)
+        Interpolate(config_path=self.config_path,
+                    method=self.method_dropdown.getChoices(),
+                    input_path=self.input_dir.folder_path)
 
 
-class SmoothingPopUp(PopUpMixin):
+class SmoothingPopUp(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str):
-        PopUpMixin.__init__(self, config_path=config_path, title='SMOOTH POSE')
+
+        PopUpMixin.__init__(self, title='SMOOTH POSE')
+        ConfigReader.__init__(self, config_path=config_path)
         self.input_dir = FolderSelect(self.main_frm, 'DATA DIRECTORY:', lblwidth=20)
         self.time_window = Entry_Box(self.main_frm, 'TIME WINDOW (MS):', '20', validation='numeric')
         self.method_dropdown = DropDownMenu(self.main_frm, 'SMOOTHING METHOD:', Options.SMOOTHING_OPTIONS.value, '20')
         self.method_dropdown.setChoices(Options.SMOOTHING_OPTIONS.value[0])
         run_btn = Button(self.main_frm, text='RUN SMOOTHING', fg='blue', command=lambda: self.run())
 
         self.input_dir.grid(row=0, column=0, sticky=NW)
@@ -3363,24 +3406,23 @@
         self.time_window.grid(row=2, column=0, sticky=NW)
         run_btn.grid(row=3, column=0, sticky=NW)
 
     def run(self):
         if not os.path.isdir(self.input_dir.folder_path):
             raise NotDirectoryError(msg=f'{self.input_dir.folder_path} is not a valid directory.')
         check_int(name='TIME WINDOW', value=self.time_window.entry_get, min_value=1)
-        _ = PostHocSmooth(config_path=self.config_path,
-                          input_dir=self.input_dir.folder_path,
-                          time_window=int(self.time_window.entry_get),
-                          smoothing_method=self.method_dropdown.getChoices())
+        _ = Smooth(config_path=self.config_path,
+                   input_path=self.input_dir.folder_path,
+                   time_window=self.time_window.entry_get,
+                   smoothing_method=self.method_dropdown.getChoices())
 
 class BatchPreProcessPopUp(PopUpMixin):
     def __init__(self):
         super().__init__(title='BATCH PROCESS VIDEO')
         selections_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='SELECTIONS', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.BATCH_PREPROCESS.value)
-        #selections_frm = LabelFrame(self.main_frm,text='SELECTIONS',font='bold',padx=5,pady=5)
         self.input_folder_select = FolderSelect(selections_frm,'INPUT VIDEO DIRECTORY:', title='Select Folder with Input Videos', lblwidth=20)
         self.output_folder_select = FolderSelect(selections_frm,'OUTPUT VIDEO DIRECTORY:',title='Select Folder for Output videos', lblwidth=20)
         confirm_btn = Button(selections_frm,text='CONFIRM', fg='blue', command=lambda: self.run())
         selections_frm.grid(row=0, column=0, sticky=NW)
         self.input_folder_select.grid(row=0, column=0, sticky=NW)
         self.output_folder_select.grid(row=1, column=0, sticky=NW)
         confirm_btn.grid(row=2, column=0, sticky=NW)
@@ -3394,15 +3436,15 @@
             raise DuplicationError(msg='The INPUT directory and OUTPUT directory CANNOT be the same folder')
         else:
             batch_preprocessor = BatchProcessFrame(input_dir=self.input_folder_select.folder_path, output_dir=self.output_folder_select.folder_path)
             batch_preprocessor.create_main_window()
             batch_preprocessor.create_video_table_headings()
             batch_preprocessor.create_video_rows()
             batch_preprocessor.create_execute_btn()
-            batch_preprocessor.batch_process_main_frame.mainloop()
+            batch_preprocessor.main_frm.mainloop()
 
 class AppendROIFeaturesByBodyPartPopUp(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str):
 
         PopUpMixin.__init__(self, config_path=config_path, title='APPEND ROI FEATURES')
         ConfigReader.__init__(self, config_path=config_path)
@@ -3414,22 +3456,22 @@
     def run(self):
         settings = {}
         settings['body_parts'] = {}
         settings['threshold'] = 0.00
         for bp_cnt, bp_dropdown in self.body_parts_dropdowns.items():
             settings['body_parts'][f'animal_{str(bp_cnt+1)}_bp'] = bp_dropdown.getChoices()
         roi_feature_creator = ROIFeatureCreator(config_path=self.config_path, settings=settings)
-        roi_feature_creator.analyze_ROI_data()
-        roi_feature_creator.save_new_features_files()
+        roi_feature_creator.run()
+        roi_feature_creator.save()
 
 
 #_ = AppendROIFeaturesByBodyPartPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/two_animals_16bp_032023/project_folder/project_config.ini')
 
 
-class ExtractAnnotationFramesPopUp(PopUpMixin):
+class ExtractAnnotationFramesPopUp(PopUpMixin, ConfigReader):
     def __init__(self, config_path: str):
         PopUpMixin.__init__(self, config_path=config_path, title='EXTRACT ANNOTATED FRAMES')
         ConfigReader.__init__(self, config_path=config_path)
         self.create_clf_checkboxes(main_frm=self.main_frm, clfs=self.clf_names)
         self.settings_frm = LabelFrame(self.main_frm, text='STYLE SETTINGS', font=("Helvetica", 12, 'bold'), pady=5, padx=5)
         down_sample_resolution_options = ['None', '2x', '3x', '4x', '5x']
         self.resolution_downsample_dropdown = DropDownMenu(self.settings_frm, 'Down-sample images:', down_sample_resolution_options, '25')
@@ -3450,55 +3492,57 @@
         if len(clfs) == 0: raise NoChoosenClassifierError()
         settings = {'downsample': downsample_setting}
 
         frame_extractor = AnnotationFrameExtractor(config_path=self.config_path, clfs=clfs, settings=settings)
         frame_extractor.run()
 
 
-class FeatureSubsetExtractorPopUp(PopUpMixin):
-    def __init__(self, config_path: str):
-        super().__init__(title='EXTRACT FEATURE SUBSETS', hyperlink='https://github.com/sgoldenlab/simba/blob/master/docs/kleinberg_filter.md')
+class FeatureSubsetExtractorPopUp(PopUpMixin, ConfigReader):
+    def __init__(self,
+                 config_path: str):
+        PopUpMixin.__init__(self, title='EXTRACT FEATURE SUBSETS')
+        ConfigReader.__init__(self, config_path=config_path)
         self.feature_subset_options = ['Two-point body-part distances (mm)',
                                        'Within-animal three-point body-part angles (degrees)',
                                        'Within-animal three-point convex hull perimeters (mm)',
                                        'Within-animal four-point convex hull perimeters (mm)',
                                        'Entire animal convex hull perimeters (mm)',
                                        'Entire animal convex hull area (mm2)',
                                        'Frame-by-frame body-part movements (mm)',
                                        'Frame-by-frame distance to ROI centers (mm)',
                                        'Frame-by-frame body-parts inside ROIs (Boolean)']
 
-        self.config_path = config_path
         self.settings_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='SETTINGS', icon_name='documentation', icon_link=Links.FEATURE_SUBSETS.value)
         self.feature_family_dropdown = DropDownMenu(self.settings_frm, 'FEATURE FAMILY:', self.feature_subset_options, '20')
         self.feature_family_dropdown.setChoices(self.feature_subset_options[0])
         self.save_dir = FolderSelect(self.settings_frm, 'SAVE DIRECTORY:', lblwidth=20)
         self.create_run_frm(run_function=self.run)
 
         self.settings_frm.grid(row=0, column=0, sticky=NW)
         self.feature_family_dropdown.grid(row=0, column=0, sticky=NW)
         self.save_dir.grid(row=1, column=0, sticky=NW)
 
-        self.main_frm.mainloop()
+        #self.main_frm.mainloop()
 
     def run(self):
         check_if_dir_exists(in_dir=self.save_dir.folder_path)
         feature_extractor = FeatureSubsetsCalculator(config_path=self.config_path,
                                                      feature_family=self.feature_family_dropdown.getChoices(),
                                                      save_dir=self.save_dir.folder_path)
         feature_extractor.run()
 
-class ThirdPartyAnnotatorAppenderPopUp(PopUpMixin):
-    def __init__(self, config_path: str):
-        self.config_path = config_path
-        super().__init__(config_path=config_path, title='APPEND THIRD-PARTY ANNOTATIONS')
+class ThirdPartyAnnotatorAppenderPopUp(PopUpMixin, ConfigReader):
+    def __init__(self,
+                 config_path: str):
+
+        PopUpMixin.__init__(self,  title='APPEND THIRD-PARTY ANNOTATIONS')
+        ConfigReader.__init__(self, config_path=config_path)
         apps_lst = Options.THIRD_PARTY_ANNOTATION_APPS_OPTIONS.value
         warnings_lst = Options.THIRD_PARTY_ANNOTATION_ERROR_OPTIONS.value
         app_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='THIRD-PARTY APPLICATION', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.THIRD_PARTY_ANNOTATION_NEW.value)
-        #app_frm = LabelFrame(self.main_frm, text='THIRD-PARTY APPLICATION', font=Formats.LABELFRAME_HEADER_FORMAT.value)
         self.app_dropdown = DropDownMenu(app_frm, 'THIRD-PARTY APPLICATION:', apps_lst, '35')
         self.app_dropdown.setChoices(apps_lst[0])
         app_frm.grid(row=0, column=0, sticky=NW)
         self.app_dropdown.grid(row=0, column=0, sticky=NW)
 
         select_data_frm = LabelFrame(self.main_frm, text='SELECT DATA', font=Formats.LABELFRAME_HEADER_FORMAT.value)
         self.data_folder = FolderSelect(select_data_frm, 'DATA DIRECTORY:', lblwidth=35)
@@ -3524,27 +3568,27 @@
         third_party_importer = ThirdPartyLabelAppender(app=self.app_dropdown.getChoices(),
                                                        config_path=self.config_path,
                                                        data_dir=self.data_folder.folder_path,
                                                        settings=settings)
         third_party_importer.run()
 
 
-class ValidationVideoPopUp(PopUpMixin):
+class ValidationVideoPopUp(PopUpMixin, ConfigReader):
     def __init__(self,
                  config_path: str,
                  simba_main_frm: object):
 
-        self.config_path = config_path
+        PopUpMixin.__init__(self, title='CREATE VALIDATION VIDEO')
+        ConfigReader.__init__(self, config_path=config_path)
         self.feature_file_path = simba_main_frm.csvfile.file_path
         self.model_path = simba_main_frm.modelfile.file_path
         self.discrimination_threshold = simba_main_frm.dis_threshold.entry_get
         self.shortest_bout = simba_main_frm.min_behaviorbout.entry_get
-        super().__init__(config_path=config_path, title='CREATE VALIDATION VIDEO')
+
         style_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='STYLE SETTINGS', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.OUT_OF_SAMPLE_VALIDATION.value)
-        #style_frm = LabelFrame(self.main_frm, text='STYLE SETTINGS', font=Formats.LABELFRAME_HEADER_FORMAT.value)
         self.default_style_var = BooleanVar(value=True)
         default_style_cb = Checkbutton(style_frm, text='AUTO-COMPUTE STYLES', variable=self.default_style_var, command= lambda: self.enable_entrybox_from_checkbox(check_box_var=self.default_style_var, entry_boxes=[self.font_size_eb, self.spacing_eb, self.circle_size], reverse=True))
         self.font_size_eb = Entry_Box(style_frm, 'Font size: ', '25', validation='numeric')
         self.spacing_eb = Entry_Box(style_frm, 'Text spacing: ', '25', validation='numeric')
         self.circle_size = Entry_Box(style_frm, 'Circle size: ', '25', validation='numeric')
         self.font_size_eb.entry_set(val=1)
         self.spacing_eb.entry_set(val=10)
@@ -3695,25 +3739,16 @@
 #_ = ThirdPartyAnnotatorAppenderPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini')
 
 
 
 
 
 #_ = FeatureSubsetExtractorPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini')
-
-
 #_ = ExtractAnnotationFramesPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini')
-
-
-
-
 #_ = AppendROIFeaturesByBodyPartPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini')
-
-
-
 #- = PupRetrievalPopUp(config_path='/Users/simon/Downloads/Automated PRT_test/project_folder/project_config.ini')
 #_ = CreateUserDefinedPoseConfigurationPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini')
 # _ = SklearnVisualizationPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini')
 # _ = GanttPlotPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini')
 #_ = VisualizeClassificationProbabilityPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini')
 #_ = PathPlotPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini')
 #_ = DistancePlotterPopUp(config_path='/Users/simon/Desktop/envs/troubleshooting/Termites_5/project_folder/project_config.ini')
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/extract_seqframes.py` & `Simba-UW-tf-dev-1.57.6/simba/extract_seqframes.py`

 * *Files 2% similar despite different names*

```diff
@@ -5,15 +5,15 @@
 @authors: Xiaoyu Tong, Jia Jie Choong, Simon Nilsson
 """
 from PIL import Image
 import io
 import os
 import numpy as np
 import struct
-from simba.drop_bp_cords import get_fn_ext
+from simba.utils.read_write import get_fn_ext
 
 class seqInfo:
     def __init__(self):
         self.version=0
         self.descr=''
         self.width=0
         self.height=0
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pose_configurations/.DS_Store` & `Simba-UW-tf-dev-1.57.6/simba/pose_configurations/.DS_Store`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pose_configurations/bp_names/.DS_Store` & `Simba-UW-tf-dev-1.57.6/simba/pose_configurations/bp_names/.DS_Store`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pose_configurations/bp_names/bp_names.csv` & `Simba-UW-tf-dev-1.57.6/simba/pose_configurations/bp_names/bp_names.csv`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pose_configurations/no_animals/.DS_Store` & `Simba-UW-tf-dev-1.57.6/simba/pose_configurations/no_animals/.DS_Store`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pose_configurations/configuration_names/.DS_Store` & `Simba-UW-tf-dev-1.57.6/simba/pose_configurations/configuration_names/.DS_Store`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pose_configurations/schematics/.DS_Store` & `Simba-UW-tf-dev-1.57.6/simba/pose_configurations/schematics/.DS_Store`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pose_configurations/schematics/8.png` & `Simba-UW-tf-dev-1.57.6/simba/pose_configurations/schematics/8.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pose_configurations/schematics/9.png` & `Simba-UW-tf-dev-1.57.6/simba/pose_configurations/schematics/9.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pose_configurations/schematics/12.png` & `Simba-UW-tf-dev-1.57.6/simba/pose_configurations/schematics/12.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pose_configurations/schematics/11.png` & `Simba-UW-tf-dev-1.57.6/simba/pose_configurations/schematics/11.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pose_configurations/schematics/10.png` & `Simba-UW-tf-dev-1.57.6/simba/pose_configurations/schematics/10.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pose_configurations/schematics/4.png` & `Simba-UW-tf-dev-1.57.6/simba/pose_configurations/schematics/4.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pose_configurations/schematics/5.png` & `Simba-UW-tf-dev-1.57.6/simba/pose_configurations/schematics/5.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pose_configurations/schematics/7.png` & `Simba-UW-tf-dev-1.57.6/simba/pose_configurations/schematics/7.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pose_configurations/schematics/6.png` & `Simba-UW-tf-dev-1.57.6/simba/pose_configurations/schematics/6.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pose_configurations/schematics/2.png` & `Simba-UW-tf-dev-1.57.6/simba/pose_configurations/schematics/2.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pose_configurations/schematics/3.png` & `Simba-UW-tf-dev-1.57.6/simba/pose_configurations/schematics/3.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pose_configurations/schematics/1.png` & `Simba-UW-tf-dev-1.57.6/simba/pose_configurations/schematics/1.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/get_coordinates_tools_v2.py` & `Simba-UW-tf-dev-1.57.6/simba/get_coordinates_tools_v2.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,13 @@
 __author__ = "Simon Nilsson", "JJ Choong"
 
 
 import os
 import cv2
 import numpy as np
-from simba.misc_tools import get_fn_ext, get_video_meta_data
-from copy import deepcopy
 
 def get_coordinates_nilsson(filenames,knownmm):
     global cordStatus
     global moveStatus
     global insertStatus
     global changeLoop
     cordStatus = False
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pup_retrieval_protocol.py` & `Simba-UW-tf-dev-1.57.6/simba/pup_retrieval_protocol.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,25 +1,31 @@
 import pandas as pd
-from simba.read_config_unit_tests import read_config_file, read_config_entry, read_project_path_and_file_type
-from simba.feature_extractors.unit_tests import read_video_info, read_video_info_csv
-from simba.misc_tools import check_if_filepath_list_is_empty, check_multi_animal_status, get_fn_ext, detect_bouts
-from simba.enums import Paths, ReadConfig, Dtypes
-from simba.rw_dfs import read_df
-from simba.drop_bp_cords import create_body_part_dictionary, getBpNames
+
+
 import os, glob
 from datetime import datetime
 import seaborn as sns
-import matplotlib
+from simba.mixins.config_reader import ConfigReader
+from simba.utils.read_write import (read_config_file,
+                                    read_config_entry,
+                                    read_project_path_and_file_type,
+                                    read_video_info_csv,
+                                    get_fn_ext,
+                                    read_df)
+from simba.utils.checks import check_if_filepath_list_is_empty
+from simba.utils.data import detect_bouts
+from simba.enums import Paths, ReadConfig, Dtypes
 
-class PupRetrieverCalculator(object):
+class PupRetrieverCalculator(ConfigReader):
     def __init__(self,
                  config_path: str,
                  settings: dict):
 
-        self.config = read_config_file(ini_path=config_path)
+        ConfigReader.__init__(config_path=config_path)
+        self.config = read_config_file(config_path=config_path)
         self.project_path, self.file_type = read_project_path_and_file_type(config=self.config)
         self.settings, self.datetime = settings, datetime.now().strftime('%Y%m%d%H%M%S')
         self.animal_cnt = read_config_entry(self.config, ReadConfig.GENERAL_SETTINGS.value, ReadConfig.ANIMAL_CNT.value, Dtypes.INT.value)
         self.clf_lst = [settings['clf_approach'], settings['clf_carry'], settings['clf_dig']]
         self.distance_pup_core_field = f'{self.settings["core_nest"]} {self.settings["pup_name"]} {"distance"}'
         self.distance_dam_core_field = f'{self.settings["core_nest"]} {self.settings["dam_name"]} {"distance"}'
         self.pup_in_core_field = f'{self.settings["core_nest"]} {self.settings["pup_name"]} {"in zone"}'
@@ -27,22 +33,14 @@
 
         machine_results_path = os.path.join(self.project_path, Paths.MACHINE_RESULTS_DIR.value)
         self.logs_dir_path = os.path.join(self.project_path, 'logs')
 
         self.data_files = glob.glob(machine_results_path + '/*.' + self.file_type)
         check_if_filepath_list_is_empty(filepaths=self.data_files, error_msg='SIMBA ERROR: NO FILES FOUND IN {}'.format(machine_results_path))
         self.vid_info_df = read_video_info_csv(os.path.join(self.project_path, Paths.VIDEO_INFO.value))
-        multi_animal_status, self.multi_animal_ids = check_multi_animal_status(self.config, self.animal_cnt)
-        x_cols, y_cols, p_cols = getBpNames(inifile=config_path)
-        self.bp_dict = create_body_part_dictionary(multiAnimalStatus=multi_animal_status,
-                                                   multiAnimalIDList=self.multi_animal_ids,
-                                                   animalsNo=self.animal_cnt,
-                                                   Xcols=x_cols,
-                                                   Ycols=y_cols,
-                                                   Pcols=p_cols)
 
     def __get_max_frames(self):
         self.max_frames = int(self.fps * self.settings['max_time'])
         if self.max_frames < len(self.data_df):
             self.data_df = self.data_df.head(self.max_frames)
 
 
@@ -103,21 +101,21 @@
 
     def run(self):
         self.out = []
         for file_cnt, file_path in enumerate(self.data_files):
             self.results = {}
             self.file_path = file_path
             _, video_name, _ = get_fn_ext(filepath=file_path)
-            _, _, self.fps = read_video_info(vid_info_df=self.vid_info_df, video_name=video_name)
+            _, _, self.fps = self.read_video_info(video_name=video_name)
             self.data_df = read_df(file_path=file_path, file_type=self.file_type).fillna(method='ffill')
             self.__get_max_frames()
             self.carry_frames = int(self.fps * self.settings['carry_time'])
 
-            self.data_df['mean_p_mother'] = self.data_df[self.bp_dict[self.settings['dam_name']]['P_bps']].mean(axis=1)
-            self.data_df['pup_p_mean'] = self.data_df[self.bp_dict[self.settings['pup_name']]['P_bps']].mean(axis=1)
+            self.data_df['mean_p_mother'] = self.data_df[self.animal_bp_dict[self.settings['dam_name']]['P_bps']].mean(axis=1)
+            self.data_df['pup_p_mean'] = self.data_df[self.animal_bp_dict[self.settings['pup_name']]['P_bps']].mean(axis=1)
             self.data_df['cumsum_nest_pup'] = self.data_df[self.pup_in_nest_field].cumsum()
 
             if self.settings['distance_plots']:
                 self.__generate_figure(data=self.data_df,
                                        y_col=self.distance_dam_core_field,
                                        x_lbl='frame number',
                                        y_lbl='distance (mm)',
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/outlier_tools/outlier_corrector_movement.py` & `Simba-UW-tf-dev-1.57.6/simba/outlier_tools/outlier_corrector_movement.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,18 +1,15 @@
-from simba.misc_tools import get_fn_ext
-from simba.utils.printing import stdout_success
-from simba.utils.warnings import DataHeaderWarning
-from simba.read_config_unit_tests import read_config_entry
-from simba.train_model_functions import insert_column_headers_for_outlier_correction
-from simba.enums import ReadConfig, Dtypes
 import os, glob
-from simba.rw_dfs import read_df, save_df
 import pandas as pd
 import numpy as np
 from simba.mixins.config_reader import ConfigReader
+from simba.utils.read_write import read_df, write_df, get_fn_ext, read_config_entry
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.utils.warnings import DataHeaderWarning
+from simba.enums import ReadConfig, Dtypes
 
 class OutlierCorrecterMovement(ConfigReader):
     """
     Class for detecting and amending outliers in pose-estimation data based on movement sizes of the body-parts
     in the current frame.
 
     Parameters
@@ -23,25 +20,23 @@
     Notes
     ----------
     `Outlier correction documentation <https://github.com/sgoldenlab/simba/blob/master/misc/Outlier_settings.pdf>`__.
 
     Examples
     ----------
     >>> outlier_correcter_movement = OutlierCorrecterMovement(config_path='MyProjectConfig')
-    >>> outlier_correcter_movement.correct_movement_outliers()
+    >>> outlier_correcter_movement.run()
 
     """
 
     def __init__(self,
                  config_path: str):
 
         super().__init__(config_path=config_path)
         if not os.path.exists(self.outlier_corrected_movement_dir): os.makedirs(self.outlier_corrected_movement_dir)
-        self.files_found = glob.glob(self.input_csv_dir + '/*.' + self.file_type)
-        self.body_parts = list(set([x[:-2] for x in self.column_headers]))
         if self.animal_cnt == 1:
             self.animal_id = read_config_entry(self.config, ReadConfig.MULTI_ANIMAL_ID_SETTING.value, ReadConfig.MULTI_ANIMAL_IDS.value, Dtypes.STR.value)
             if self.animal_id != 'None':
                 self.animal_bp_dict[self.animal_id] = self.animal_bp_dict.pop('Animal_1')
         self.above_criterion_dict_dict = {}
         self.criterion = read_config_entry(self.config, ReadConfig.OUTLIER_SETTINGS.value, ReadConfig.MOVEMENT_CRITERION.value, Dtypes.FLOAT.value)
         self.outlier_bp_dict = {}
@@ -51,59 +46,54 @@
             self.outlier_bp_dict[animal_name]['bp_2'] = read_config_entry(self.config, 'Outlier settings', 'movement_bodypart2_{}'.format(animal_name.lower()), 'str')
 
 
     def __outlier_replacer(self, bp_lst=None, animal_name=None):
         self.above_criterion_dict = {}
         self.below_criterion_dict = {}
         self.above_criterion_dict_dict[self.video_name][animal_name] = {}
-        for c in self.body_parts:
+        for c in self.body_parts_lst:
             self.data_df_combined[c + '_movement'] = np.sqrt((self.data_df_combined[c + '_x'] - self.data_df_combined[c + '_x_shifted']) ** 2 + (self.data_df_combined[c + '_y'] - self.data_df_combined[c + '_y_shifted']) ** 2)
             self.above_criterion_dict[c] = list(self.data_df_combined.index[self.data_df_combined[c + '_movement'] > self.animal_criteria[animal_name]])
             self.below_criterion_dict[c] = list(self.data_df_combined.index[self.data_df_combined[c + '_movement'] <= self.animal_criteria[animal_name]])
             self.above_criterion_dict_dict[self.video_name][animal_name][c] = self.above_criterion_dict[c]
         for body_part, body_part_idx in self.above_criterion_dict.items():
             body_part_x, body_part_y = body_part + '_x', body_part + '_y'
             for idx in body_part_idx:
                 try:
                     closest_idx = max([i for i in self.below_criterion_dict[body_part] if idx > i])
                 except ValueError:
                     closest_idx = idx
                 self.data_df.loc[[idx], body_part_x] = self.data_df.loc[[closest_idx], body_part_x].values[0]
                 self.data_df.loc[[idx], body_part_y] = self.data_df.loc[[closest_idx], body_part_y].values[0]
 
-    def correct_movement_outliers(self):
+    def run(self):
         """
         Runs outlier detection and correction. Results are stored in the
         ``project_folder/csv/outlier_corrected_movement`` directory of the SimBA project.
         """
-        for file_cnt, file_path in enumerate(self.files_found):
+        for file_cnt, file_path in enumerate(self.input_csv_paths):
+            video_timer = SimbaTimer(start=True)
             _, self.video_name, _ = get_fn_ext(file_path)
-            print('Processing video {}. Video {}/{}...'.format(self.video_name, str(file_cnt+1), str(len(self.files_found))))
+            print('Processing video {}. Video {}/{}...'.format(self.video_name, str(file_cnt+1), str(len(self.input_csv_paths))))
             self.above_criterion_dict_dict[self.video_name] = {}
             save_path = os.path.join(self.outlier_corrected_movement_dir, self.video_name + '.' + self.file_type)
-            self.data_df = read_df(file_path, self.file_type)
-            try:
-                self.data_df = self.data_df.drop(self.data_df.index[[0, 1]]).apply(pd.to_numeric).reset_index(drop=True)
-            except ValueError as e:
-                print(e.args)
-                DataHeaderWarning(msg='SIMBA WARNING: SimBA found more than the expected two header column rows. SimBA will try to proceed '
-                      'by removing one additional column header level. This can happen when you import multi-animal DLC data as standard DLC data.')
-                self.data_df = self.data_df.drop(self.data_df.index[[0, 1, 2]]).apply(pd.to_numeric).reset_index(drop=True)
-            self.data_df = insert_column_headers_for_outlier_correction(data_df=self.data_df, new_headers=list(self.column_headers), filepath=file_path)
+            self.data_df = read_df(file_path, self.file_type, check_multiindex=True)
+            self.data_df = self.insert_column_headers_for_outlier_correction(data_df=self.data_df, new_headers=self.bp_headers, filepath=file_path)
             self.data_df_shifted = self.data_df.shift(periods=1).add_suffix('_shifted').fillna(0)
             self.data_df_combined = pd.concat([self.data_df, self.data_df_shifted], axis=1, join='inner').fillna(0)
             self.animal_criteria = {}
             for animal_name, animal_bps in self.outlier_bp_dict.items():
                 animal_bp_distances = np.sqrt((self.data_df[animal_bps['bp_1'] + '_x'] - self.data_df[animal_bps['bp_2'] + '_x']) ** 2 + (self.data_df[animal_bps['bp_1'] + '_y'] - self.data_df[animal_bps['bp_2'] + '_y']) ** 2)
                 self.animal_criteria[animal_name] = animal_bp_distances.mean() * self.criterion
             for animal_name in self.outlier_bp_dict.keys():
-                animal_bps = [x for x in self.column_headers if x.startswith(animal_name + '_')]
+                animal_bps = [x for x in self.bp_headers if x.startswith(animal_name + '_')]
                 self.__outlier_replacer(bp_lst=animal_bps, animal_name=animal_name)
-            save_df(self.data_df, self.file_type, save_path)
-            print('Corrected movement outliers for file {} ...'.format(self.video_name))
+            write_df(df=self.data_df, file_type=self.file_type, save_path=save_path)
+            video_timer.stop_timer()
+            print(f'Corrected movement outliers for file {self.video_name} (elapsed time: {video_timer.elapsed_time_str}s)...')
         self.__save_log_file()
 
     def __save_log_file(self):
         out_df_lst = []
         for video_name, video_data in self.above_criterion_dict_dict.items():
             for animal_name, animal_data in video_data.items():
                 for bp_name, vid_idx_lst in animal_data.items():
@@ -111,13 +101,19 @@
                     out_df_lst.append(pd.DataFrame([[video_name, animal_name, bp_name, len(vid_idx_lst), correction_ratio]], columns=['Video', 'Animal', 'Body-part', 'Corrections', 'Correction ratio (%)']))
         out_df = pd.concat(out_df_lst, axis=0).reset_index(drop=True)
         log_fn = os.path.join(self.logs_path, 'Outliers_movement_{}.csv'.format(self.datetime))
         out_df.to_csv(log_fn)
         self.timer.stop_timer()
         stdout_success(msg='Log for corrected "movement outliers" saved in project_folder/logs', elapsed_time=self.timer.elapsed_time_str)
 
-# test = OutlierCorrecterMovement(config_path='/Users/simon/Desktop/troubleshooting/User_def_2/project_folder/project_config.ini')
+# test = OutlierCorrecterMovement(config_path='/Users/simon/Desktop/envs/troubleshooting/two_animals_16bp_032023/project_folder/project_config.ini')
 # test.correct_movement_outliers()
 
+# test = OutlierCorrecterMovement(config_path='/Users/simon/Desktop/envs/troubleshooting/naresh/project_folder/project_config.ini')
+# test.run()
+
+# test = OutlierCorrecterMovement(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini')
+# test.correct_movement_outliers()
+#
 # test = OutlierCorrecterMovement(config_path='/Users/simon/Desktop/envs/troubleshooting/two_animals_16bp_032023/project_folder/project_config.ini')
 # test.correct_movement_outliers()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/outlier_tools/.DS_Store` & `Simba-UW-tf-dev-1.57.6/simba/outlier_tools/.DS_Store`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/outlier_tools/outlier_corrector_location.py` & `Simba-UW-tf-dev-1.57.6/simba/outlier_tools/outlier_corrector_location.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,17 +1,15 @@
-from simba.read_config_unit_tests import read_config_entry
 import os, glob
-from simba.misc_tools import get_fn_ext
-from simba.utils.printing import stdout_success
-from simba.rw_dfs import (read_df,
-                          save_df)
-from simba.enums import ReadConfig, Dtypes
 import numpy as np
 import pandas as pd
+from simba.enums import ReadConfig, Dtypes
 from simba.mixins.config_reader import ConfigReader
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.utils.read_write import read_df, write_df, get_fn_ext, read_config_entry
+
 
 class OutlierCorrecterLocation(ConfigReader):
     """
     Class for detecting and amending outliers in pose-estimation data based in the location of the body-parts
     in the current frame relative to the location of the body-part in the preceding frame.
 
     Parameters
@@ -19,29 +17,25 @@
     config_path: str
         path to SimBA project config file in Configparser format
 
     Notes
     ----------
     Outlier correction documentation <https://github.com/sgoldenlab/simba/blob/master/misc/Outlier_settings.pdf>`__.
 
-
     Examples
     ----------
     >>> outlier_correcter_location = OutlierCorrecterLocation(config_path='MyProjectConfig')
-    >>> outlier_correcter_location.correct_location_outliers()
+    >>> outlier_correcter_location.run()
     """
 
     def __init__(self,
                  config_path: str):
 
         super().__init__(config_path=config_path)
-
         if not os.path.exists(self.outlier_corrected_dir): os.makedirs(self.outlier_corrected_dir)
-        self.files_found = glob.glob(self.outlier_corrected_movement_dir + '/*.' + self.file_type)
-        self.body_parts = list(set([x[:-2] for x in self.column_headers]))
         if self.animal_cnt == 1:
             self.animal_id = read_config_entry(self.config, ReadConfig.MULTI_ANIMAL_ID_SETTING.value, ReadConfig.MULTI_ANIMAL_IDS.value, Dtypes.STR.value)
             if self.animal_id != 'None':
                 self.animal_bp_dict[self.animal_id] = self.animal_bp_dict.pop('Animal_1')
         self.above_criterion_dict_dict = {}
         self.below_criterion_dict_dict = {}
         self.criterion = read_config_entry(self.config, ReadConfig.OUTLIER_SETTINGS.value, ReadConfig.LOCATION_CRITERION.value, Dtypes.FLOAT.value)
@@ -83,23 +77,24 @@
                     try:
                         closest_idx = max([i for i in self.below_criterion_dict_dict[self.video_name][animal_name][bp_name] if outlier_idx > i])
                     except ValueError:
                         closest_idx = outlier_idx
                     self.data_df.loc[[outlier_idx], body_part_x] = self.data_df.loc[[closest_idx], body_part_x].values[0]
                     self.data_df.loc[[outlier_idx], body_part_y] = self.data_df.loc[[closest_idx], body_part_y].values[0]
 
-    def correct_location_outliers(self):
+    def run(self):
         """
         Runs outlier detection and correction. Results are stored in the
         ``project_folder/csv/outlier_corrected_movement_location`` directory of the SimBA project.
         """
 
-        for file_cnt, file_path in enumerate(self.files_found):
+        for file_cnt, file_path in enumerate(self.outlier_corrected_movement_paths):
+            video_timer = SimbaTimer(start=True)
             _, self.video_name, _ = get_fn_ext(file_path)
-            print('Processing video {}. Video {}/{}..'.format(self.video_name, str(file_cnt+1), str(len(self.files_found))))
+            print(f'Processing video {self.video_name}. Video {file_cnt+1}/{len(self.outlier_corrected_movement_paths)}..')
             self.above_criterion_dict_dict[self.video_name] = {}
             self.below_criterion_dict_dict[self.video_name] = {}
             save_path = os.path.join(self.outlier_corrected_dir, self.video_name + '.' + self.file_type)
             self.data_df = read_df(file_path, self.file_type)
             self.animal_criteria = {}
             for animal_name, animal_bps in self.outlier_bp_dict.items():
                 animal_bp_distances = np.sqrt((self.data_df[animal_bps['bp_1'] + '_x'] - self.data_df[animal_bps['bp_2'] + '_x']) ** 2 + (self.data_df[animal_bps['bp_1'] + '_y'] - self.data_df[animal_bps['bp_2'] + '_y']) ** 2)
@@ -110,16 +105,17 @@
                 animal_arr = self.data_df[bp_col_names].to_numpy()
                 self.bp_dict[animal_name] = {}
                 for bp_cnt, bp_col_start in enumerate(range(0, animal_arr.shape[1], 2)):
                     bp_name = animal_bps['X_bps'][bp_cnt][:-2]
                     self.bp_dict[animal_name][bp_name] = animal_arr[:, bp_col_start:bp_col_start+2]
             self.__find_location_outliers()
             self.__correct_outliers()
-            save_df(self.data_df, self.file_type, save_path)
-            print('Corrected location outliers for file {} ...'.format(self.video_name))
+            write_df(df=self.data_df, file_type=self.file_type, save_path=save_path)
+            video_timer.stop_timer()
+            print(f'Corrected location outliers for file {self.video_name} (elapsed time: {video_timer.elapsed_time_str}s)...')
         self.__save_log_file()
 
     def __save_log_file(self):
         out_df_lst = []
         for video_name, video_data in self.above_criterion_dict_dict.items():
             for animal_name, animal_data in video_data.items():
                 for bp_name, vid_idx_lst in animal_data.items():
@@ -127,12 +123,13 @@
                     out_df_lst.append(pd.DataFrame([[video_name, animal_name, bp_name, len(vid_idx_lst), correction_ratio]], columns=['Video', 'Animal', 'Body-part', 'Corrections', 'Correction ratio (%)']))
         out_df = pd.concat(out_df_lst, axis=0).reset_index(drop=True)
         log_fn = os.path.join(self.logs_path, 'Outliers_location_{}.csv'.format(self.datetime))
         out_df.to_csv(log_fn)
         self.timer.stop_timer()
         stdout_success(msg='Log for corrected "location outliers" saved in project_folder/logs', elapsed_time=self.timer.elapsed_time_str)
 
-# test = OutlierCorrecterLocation(config_path='/Users/simon/Desktop/troubleshooting/Zebrafish/project_folder/project_config.ini')
-# test.correct_location_outliers()
 #
-# test = OutlierCorrecterLocation(config_path='/Users/simon/Desktop/envs/troubleshooting/two_animals_16bp_032023/project_folder/project_config.ini')
+# test = OutlierCorrecterLocation(config_path='/Users/simon/Desktop/envs/troubleshooting/naresh/project_folder/project_config.ini')
+# test.run()
+
+# test = OutlierCorrecterLocation(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini')
 # test.correct_location_outliers()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/outlier_tools/.idea/outlier_scripts.iml` & `Simba-UW-tf-dev-1.57.6/simba/outlier_tools/.idea/outlier_scripts.iml`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/outlier_tools/.idea/inspectionProfiles/Project_Default.xml` & `Simba-UW-tf-dev-1.57.6/simba/outlier_tools/.idea/inspectionProfiles/Project_Default.xml`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/outlier_tools/.idea/workspace.xml` & `Simba-UW-tf-dev-1.57.6/simba/outlier_tools/.idea/workspace.xml`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/pose_reset.py` & `Simba-UW-tf-dev-1.57.6/simba/pose_reset.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,17 @@
 __author__ = "Simon Nilsson"
 
 import os
 import simba
 import shutil
-from simba.misc_tools import check_file_exist_and_readable
+import pandas as pd
 from simba.utils.printing import stdout_trash
 from simba.utils.lookups import get_bp_config_codes
-import pandas as pd
+from simba.utils.checks import check_file_exist_and_readable
+
 
 class PoseResetter(object):
     """
     Class for deleting all user-defined pose-estimation schematics, diagrams and other settings from the
     SimBA installation
 
     Parameters
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/train_mutiple_models.py` & `Simba-UW-tf-dev-1.57.6/simba/train_mutiple_models.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,107 +1,76 @@
 __author__ = "Simon Nilsson"
 
-import os, glob
-
-import pandas as pd
-from simba.train_model_functions import (read_in_all_model_names_to_remove,
-                                         delete_other_annotation_columns,
-                                         split_df_to_x_y,
-                                         random_undersampler,
-                                         smoteen_oversampler,
-                                         smote_oversampler,
-                                         calc_permutation_importance,
-                                         calc_learning_curve,
-                                         calc_pr_curve,
-                                         create_example_dt,
-                                         create_clf_report,
-                                         create_x_importance_bar_chart,
-                                         create_shap_log,
-                                         dviz_classification_visualization,
-                                         create_x_importance_log,
-                                         create_meta_data_csv_training_multiple_models,
-                                         print_machine_model_information,
-                                         bout_train_test_splitter,
-                                         save_rf_model,
-                                         check_dataset_integrity,
-                                         read_all_files_in_folder_mp,
-                                         partial_dependence_calculator,
-                                         clf_fit)
-
-from simba.read_config_unit_tests import (check_int,
-                                          check_str,
-                                          check_float,
-                                          read_config_entry,
-                                          read_simba_meta_files,
-                                          read_meta_file,
-                                          check_if_filepath_list_is_empty,
-                                          check_if_valid_input)
+import os
+from sklearn.model_selection import train_test_split
+from sklearn.ensemble import RandomForestClassifier
 
+from simba.utils.checks import check_int, check_str, check_float, check_if_filepath_list_is_empty, check_if_valid_input
+from simba.utils.read_write import read_config_entry, read_meta_file, read_simba_meta_files, get_fn_ext
 from simba.tkinter_functions import TwoOptionQuestionPopUp
 from simba.utils.printing import stdout_success
-from simba.drop_bp_cords import drop_bp_cords
-from sklearn.model_selection import train_test_split
-from sklearn.ensemble import RandomForestClassifier
 from simba.utils.errors import InvalidInputError, NoDataError
 from simba.enums import (Options,
                          ReadConfig,
                          Dtypes,
                          Methods,
                          MetaKeys)
 from simba.mixins.config_reader import ConfigReader
+from simba.mixins.train_model_mixin import TrainModelMixin
 
 
-class TrainMultipleModelsFromMeta(ConfigReader):
+class TrainMultipleModelsFromMeta(ConfigReader, TrainModelMixin):
     """
     Class for grid-searching random forest models from hyperparameter setting and sampling methods
     stored within the `project_folder/configs` directory of a SimBA project.
 
     Parameters
     ----------
     config_path: str
         path to SimBA project config file in Configparser format
 
     Example
     ----------
     >>> model_trainer = TrainMultipleModelsFromMeta(config_path='MyConfigPath')
-    >>> model_trainer.train_models_from_meta()
+    >>> model_trainer.run()
     """
 
     def __init__(self,
                  config_path: str):
 
         ConfigReader.__init__(self, config_path=config_path)
-
+        TrainModelMixin.__init__(self)
         self.model_dir_out = os.path.join(read_config_entry(self.config, ReadConfig.SML_SETTINGS.value, ReadConfig.MODEL_DIR.value, data_type=Dtypes.STR.value), 'validations')
         if not os.path.exists(self.model_dir_out): os.makedirs(self.model_dir_out)
         check_if_filepath_list_is_empty(filepaths=self.target_file_paths,
                                         error_msg='Zero annotation files found in project_folder/csv/targets_inserted, cannot create models.')
         if not os.path.exists(self.configs_meta_dir): os.makedirs(self.configs_meta_dir)
         self.meta_file_lst = sorted(read_simba_meta_files(self.configs_meta_dir))
         print('Reading in {} annotated files...'.format(str(len(self.target_file_paths))))
-        self.data_df = read_all_files_in_folder_mp(self.target_file_paths, self.file_type)
-        self.data_df = drop_bp_cords(self.data_df, config_path)
+        self.data_df = self.check_raw_dataset_integrity(self.read_all_files_in_folder_mp(self.target_file_paths, self.file_type), logs_path=self.logs_path)
+        self.data_df = self.drop_bp_cords(df=self.data_df)
 
     def perform_sampling(self, meta_dict: dict):
         if meta_dict[MetaKeys.TRAIN_TEST_SPLIT_TYPE.value] == Methods.SPLIT_TYPE_FRAMES.value:
             self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.x_df, self.y_df, test_size=meta_dict['train_test_size'])
         elif meta_dict[MetaKeys.TRAIN_TEST_SPLIT_TYPE.value] == Methods.SPLIT_TYPE_BOUTS.value:
-            self.x_train, self.x_test, self.y_train, self.y_test = bout_train_test_splitter(x_df=self.x_df, y_df=self.y_df, test_size=meta_dict['train_test_size'])
+            self.x_train, self.x_test, self.y_train, self.y_test = self.bout_train_test_splitter(x_df=self.x_df, y_df=self.y_df, test_size=meta_dict['train_test_size'])
         else:
             raise InvalidInputError(msg=f'{meta_dict[MetaKeys.TRAIN_TEST_SPLIT_TYPE.value]} is not recognized as a valid SPLIT TYPE (OPTIONS: FRAMES, BOUTS')
         if meta_dict[ReadConfig.UNDERSAMPLE_SETTING.value].lower() == Methods.RANDOM_UNDERSAMPLE.value:
-            self.x_train, self.y_train = random_undersampler(self.x_train, self.y_train, meta_dict[ReadConfig.UNDERSAMPLE_RATIO.value])
+            self.x_train, self.y_train = self.random_undersampler(self.x_train, self.y_train, meta_dict[ReadConfig.UNDERSAMPLE_RATIO.value])
         if meta_dict[ReadConfig.OVERSAMPLE_SETTING.value].lower() == Methods.SMOTEENN.value:
-            self.x_train, self.y_train = smoteen_oversampler(self.x_train, self.y_train, meta_dict[ReadConfig.OVERSAMPLE_RATIO.value])
+            self.x_train, self.y_train = self.smoteen_oversampler(self.x_train, self.y_train, meta_dict[ReadConfig.OVERSAMPLE_RATIO.value])
         elif meta_dict[ReadConfig.OVERSAMPLE_SETTING.value].lower() == Methods.SMOTE.value:
-            self.x_train, self.y_train = smote_oversampler(self.x_train, self.y_train, meta_dict[ReadConfig.OVERSAMPLE_RATIO.value])
+            self.x_train, self.y_train = self.smote_oversampler(self.x_train, self.y_train, meta_dict[ReadConfig.OVERSAMPLE_RATIO.value])
 
     def __check_validity_of_meta_files(self, meta_file_paths: list):
         meta_dicts, errors = {}, []
         for config_cnt, path in enumerate(meta_file_paths):
+            _, meta_file_name, _ = get_fn_ext(path)
             meta_dict = read_meta_file(path)
             meta_dict = {k.lower(): v for k, v in meta_dict.items()}
             errors.append(check_str(name=meta_dict[MetaKeys.CLF_NAME.value], value=meta_dict[MetaKeys.CLF_NAME.value], raise_error=False)[1])
             errors.append(check_str(name=MetaKeys.CRITERION.value, value=meta_dict[MetaKeys.CRITERION.value], options=Options.CLF_CRITERION.value, raise_error=False)[1])
             errors.append(check_str(name=MetaKeys.RF_MAX_FEATURES.value, value=meta_dict[MetaKeys.RF_MAX_FEATURES.value], options=Options.CLF_MAX_FEATURES.value, raise_error=False)[1])
             errors.append(check_str(ReadConfig.UNDERSAMPLE_SETTING.value, meta_dict[ReadConfig.UNDERSAMPLE_SETTING.value].lower(), options=[x.lower() for x in Options.UNDERSAMPLE_OPTIONS.value], raise_error=False)[1])
             errors.append(check_str(ReadConfig.OVERSAMPLE_SETTING.value, meta_dict[ReadConfig.OVERSAMPLE_SETTING.value].lower(), options=[x.lower() for x in Options.OVERSAMPLE_OPTIONS.value], raise_error=False)[1])
@@ -157,15 +126,15 @@
                 if meta_dict[ReadConfig.CLASS_WEIGHTS.value] == Dtypes.NONE.value:
                     meta_dict[ReadConfig.CLASS_WEIGHTS.value] = None
             else:
                 meta_dict[ReadConfig.CLASS_WEIGHTS.value] = None
 
             errors = [x for x in errors if x != '']
             if errors:
-                option = TwoOptionQuestionPopUp(question=f'{errors[0]} \n \n  Do you want to skip this meta file or terminate training ?',
+                option = TwoOptionQuestionPopUp(question=f'{errors[0]} \n ({meta_file_name}) \n  Do you want to skip this meta file or terminate training ?',
                                                 title='META CONFIG FILE ERROR',
                                                 option_one='SKIP',
                                                 option_two='TERMINATE')
 
                 if option.selected_option == 'SKIP':
                     continue
                 else:
@@ -179,66 +148,71 @@
         self.meta_dicts = self.__check_validity_of_meta_files(meta_file_paths=self.meta_file_lst)
         if len(self.meta_dicts.keys()) == 0:
             raise NoDataError(msg='No valid hyper-parameter config files')
         for config_cnt, meta_dict in self.meta_dicts.items():
             self.clf_name = meta_dict[MetaKeys.CLF_NAME.value]
             print(f'Training model {config_cnt+1}/{len(self.meta_dicts.keys())} ({meta_dict[MetaKeys.CLF_NAME.value]})...')
             self.class_names = [f'Not_{meta_dict[MetaKeys.CLF_NAME.value]}', meta_dict[MetaKeys.CLF_NAME.value]]
-            annotation_cols_to_remove = read_in_all_model_names_to_remove(self.config, self.clf_cnt, meta_dict[MetaKeys.CLF_NAME.value])
-            self.x_y_df = delete_other_annotation_columns(self.data_df, annotation_cols_to_remove)
-            self.x_df, self.y_df = split_df_to_x_y(self.x_y_df, meta_dict[MetaKeys.CLF_NAME.value])
+            annotation_cols_to_remove = self.read_in_all_model_names_to_remove(self.config, self.clf_cnt, meta_dict[MetaKeys.CLF_NAME.value])
+            self.x_y_df = self.delete_other_annotation_columns(self.data_df, annotation_cols_to_remove)
+            self.x_df, self.y_df = self.split_df_to_x_y(self.x_y_df, meta_dict[MetaKeys.CLF_NAME.value])
             self.feature_names = self.x_df.columns
-            check_dataset_integrity(x_df=self.x_df, y_df=self.y_df)
+            self.check_sampled_dataset_integrity(x_df=self.x_df, y_df=self.y_df)
             self.perform_sampling(meta_dict=meta_dict)
             print(f'MODEL {config_cnt+1} settings')
-            print_machine_model_information(meta_dict)
+            self.print_machine_model_information(meta_dict)
             print('# {} features.'.format(len(self.feature_names)))
             self.rf_clf = RandomForestClassifier(n_estimators=meta_dict[MetaKeys.RF_ESTIMATORS.value],
                                                  max_features=meta_dict[MetaKeys.RF_MAX_FEATURES.value],
                                                  n_jobs=-1,
                                                  criterion=meta_dict[MetaKeys.CRITERION.value],
                                                  min_samples_leaf=meta_dict[MetaKeys.MIN_LEAF.value],
                                                  bootstrap=True,
                                                  verbose=1,
                                                  class_weight=meta_dict[ReadConfig.CLASS_WEIGHTS.value])
 
             print(f'Fitting {self.clf_name} model...')
-            self.rf_clf = clf_fit(clf=self.rf_clf, x_df=self.x_train, y_df=self.y_train)
+            self.rf_clf = self.clf_fit(clf=self.rf_clf, x_df=self.x_train, y_df=self.y_train)
             if meta_dict[MetaKeys.PERMUTATION_IMPORTANCE.value] in Options.PERFORM_FLAGS.value:
-                calc_permutation_importance(self.x_test, self.y_test, self.rf_clf, self.feature_names, self.clf_name, self.model_dir_out, save_file_no=config_cnt)
+                self.calc_permutation_importance(self.x_test, self.y_test, self.rf_clf, self.feature_names, self.clf_name, self.model_dir_out, save_file_no=config_cnt)
             if meta_dict[MetaKeys.LEARNING_CURVE.value] in Options.PERFORM_FLAGS.value:
-                calc_learning_curve(self.x_y_df, self.clf_name, meta_dict[MetaKeys.LEARNING_CURVE_K_SPLITS.value], meta_dict[MetaKeys.LEARNING_CURVE_DATA_SPLITS.value], meta_dict[MetaKeys.TT_SIZE.value], self.rf_clf, self.model_dir_out, save_file_no=config_cnt)
+                self.calc_learning_curve(self.x_y_df, self.clf_name, meta_dict[MetaKeys.LEARNING_CURVE_K_SPLITS.value], meta_dict[MetaKeys.LEARNING_CURVE_DATA_SPLITS.value], meta_dict[MetaKeys.TT_SIZE.value], self.rf_clf, self.model_dir_out, save_file_no=config_cnt)
             if meta_dict[MetaKeys.PRECISION_RECALL.value] in Options.PERFORM_FLAGS.value:
-                calc_pr_curve(self.rf_clf, self.x_test, self.y_test, self.clf_name, self.model_dir_out, save_file_no=config_cnt)
+                self.calc_pr_curve(self.rf_clf, self.x_test, self.y_test, self.clf_name, self.model_dir_out, save_file_no=config_cnt)
             if meta_dict[MetaKeys.EX_DECISION_TREE.value] in Options.PERFORM_FLAGS.value:
-                create_example_dt(self.rf_clf, self.clf_name, self.feature_names, self.class_names, self.model_dir_out, save_file_no=config_cnt)
+                self.create_example_dt(self.rf_clf, self.clf_name, self.feature_names, self.class_names, self.model_dir_out, save_file_no=config_cnt)
             if meta_dict[MetaKeys.CLF_REPORT.value] in Options.PERFORM_FLAGS.value:
-                create_clf_report(self.rf_clf, self.x_test, self.y_test, self.class_names, self.model_dir_out, save_file_no=config_cnt)
+                self.create_clf_report(self.rf_clf, self.x_test, self.y_test, self.class_names, self.model_dir_out, save_file_no=config_cnt)
             if meta_dict[MetaKeys.IMPORTANCE_LOG.value] in Options.PERFORM_FLAGS.value:
-                create_x_importance_log(self.rf_clf, self.feature_names, self.clf_name, self.model_dir_out, save_file_no=config_cnt)
+                self.create_x_importance_log(self.rf_clf, self.feature_names, self.clf_name, self.model_dir_out, save_file_no=config_cnt)
             if meta_dict[MetaKeys.IMPORTANCE_BAR_CHART.value] in Options.PERFORM_FLAGS.value:
-                create_x_importance_bar_chart(self.rf_clf, self.feature_names, self.clf_name, self.model_dir_out, meta_dict[MetaKeys.N_FEATURE_IMPORTANCE_BARS.value], save_file_no=config_cnt)
+                self.create_x_importance_bar_chart(self.rf_clf, self.feature_names, self.clf_name, self.model_dir_out, meta_dict[MetaKeys.N_FEATURE_IMPORTANCE_BARS.value], save_file_no=config_cnt)
             if MetaKeys.SHAP_SCORES.value in meta_dict.keys():
                 save_n = meta_dict[MetaKeys.SHAP_PRESENT.value] + meta_dict[MetaKeys.SHAP_ABSENT.value]
                 if MetaKeys.SHAP_SAVE_ITERATION.value in meta_dict.keys():
                     try:
                         save_n = int(meta_dict[MetaKeys.SHAP_SAVE_ITERATION.value])
                     except ValueError:
                         save_n = meta_dict[MetaKeys.SHAP_PRESENT.value] + meta_dict[MetaKeys.SHAP_ABSENT.value]
                 if meta_dict[MetaKeys.SHAP_SCORES.value] in Options.PERFORM_FLAGS.value:
-                    create_shap_log(self.config_path, self.rf_clf, self.x_train, self.y_train, self.feature_names, self.clf_name, meta_dict[MetaKeys.SHAP_PRESENT.value], meta_dict[MetaKeys.SHAP_ABSENT.value], self.model_dir_out, save_it=save_n, save_file_no=config_cnt)
+                    self.create_shap_log(self.config_path, self.rf_clf, self.x_train, self.y_train, self.feature_names, self.clf_name, meta_dict[MetaKeys.SHAP_PRESENT.value], meta_dict[MetaKeys.SHAP_ABSENT.value], self.model_dir_out, save_it=save_n, save_file_no=config_cnt)
             if MetaKeys.PARTIAL_DEPENDENCY.value in meta_dict.keys():
                 if meta_dict[MetaKeys.PARTIAL_DEPENDENCY.value] in Options.PERFORM_FLAGS.value:
-                    partial_dependence_calculator(clf=self.rf_clf, x_df=self.x_train, clf_name=self.clf_name, save_dir=self.model_dir_out)
-            create_meta_data_csv_training_multiple_models(meta_dict, self.clf_name, self.model_dir_out, save_file_no=config_cnt)
-            save_rf_model(self.rf_clf, self.clf_name, self.model_dir_out, save_file_no=config_cnt)
+                    self.partial_dependence_calculator(clf=self.rf_clf, x_df=self.x_train, clf_name=self.clf_name, save_dir=self.model_dir_out)
+            self.create_meta_data_csv_training_multiple_models(meta_dict, self.clf_name, self.model_dir_out, save_file_no=config_cnt)
+            self.save_rf_model(self.rf_clf, self.clf_name, self.model_dir_out, save_file_no=config_cnt)
             print('Classifier {} saved in models/validations/model_files directory ...'.format(str(self.clf_name + '_' + str(config_cnt))))
         stdout_success(msg='All models and evaluations complete. The models/evaluation files are in models/validations folders')
 
 # test = TrainMultipleModelsFromMeta(config_path='/Users/simon/Desktop/envs/troubleshooting/locomotion/project_folder/project_config.ini')
 # test.run()
 
+# test = TrainMultipleModelsFromMeta(config_path='/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/project_config.ini')
+# test.run()
 
+# file_paths = glob.glob('/Users/simon/Desktop/envs/troubleshooting/two_black_animals_14bp/project_folder/csv/targets_inserted' + '/*.csv')
+# df = read_all_files_in_folder_mp(file_paths=file_paths, file_type='csv')
+# check_dataset_integrity(df=df)
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/SimBA.py` & `Simba-UW-tf-dev-1.57.6/simba/SimBA.py`

 * *Files 0% similar despite different names*

```diff
@@ -23,32 +23,32 @@
 from simba.third_party_label_appenders.BENTO_appender import BentoAppender
 from simba.third_party_label_appenders.BORIS_appender import BorisAppender
 from simba.third_party_label_appenders.solomon_importer import SolomonImporter
 from simba.third_party_label_appenders.ethovision_import import ImportEthovision
 from simba.third_party_label_appenders.deepethogram_importer import DeepEthogramImporter
 from simba.third_party_label_appenders.observer_importer import NoldusObserverImporter
 from simba.Directing_animals_analyzer import DirectingOtherAnimalsAnalyzer
-from simba.pose_importers.import_trk import *
+
 from simba.train_single_model import TrainSingleModel
 from simba.train_mutiple_models import TrainMultipleModelsFromMeta
 from simba.run_inference import RunModel
 import urllib.request
 import threading
 import atexit
 from simba.video_info_table import VideoInfoTable
-from simba.read_config_unit_tests import check_int
+from simba.utils.checks import check_file_exist_and_readable, check_int
 from simba.roi_tools.ROI_define import *
 from simba.roi_tools.ROI_menus import *
 from simba.roi_tools.ROI_reset import *
-from simba.misc_tools import (run_user_defined_feature_extraction_class,
-                              extract_frames_from_all_videos_in_directory,
-                              get_video_meta_data)
-from simba.utils.printing import stdout_success
+from simba.utils.read_write import get_video_meta_data
+from simba.utils.data import run_user_defined_feature_extraction_class
+from simba.utils.printing import stdout_success, stdout_warning
 from simba.video_processing import (video_to_greyscale,
-                                    superimpose_frame_count)
+                                    superimpose_frame_count,
+                                    extract_frames_from_all_videos_in_directory)
 from simba.setting_menu import SettingsMenu
 from simba.pop_up_classes import (HeatmapLocationPopup,
                                   QuickLineplotPopup,
                                   ClfByROIPopUp,
                                   FSTTCPopUp,
                                   KleinbergPopUp,
                                   TimeBinsClfPopUp,
@@ -115,15 +115,14 @@
                          OS,
                          Defaults,
                          TagNames)
 from simba.utils.errors import InvalidInputError
 from simba.utils.lookups import get_bp_config_code_class_pairs, get_icons_paths
 from simba.mixins.pop_up_mixin import PopUpMixin
 from simba.create_project_pop_up import ProjectCreatorPopUp
-from simba.plotly_create_h5 import create_plotly_container
 from simba.utils.lookups import get_emojis
 #from simba.unsupervised.unsupervised_ui import UnsupervisedGUI
 import sys
 import subprocess
 
 sys.setrecursionlimit(10 ** 6)
 currentPlatform = platform.system()
@@ -205,15 +204,15 @@
 
         further_methods_frm = CreateLabelFrameWithIcon(parent=import_frm, header='FURTHER METHODS', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.ADDITIONAL_IMPORTS.value)
         extract_frm_btn = Button(further_methods_frm, text='EXTRACT FRAMES FOR ALL VIDEOS IN SIMBA PROJECT', fg='blue', command= lambda: extract_frames_from_all_videos_in_directory(config_path=self.config_path, directory=self.video_dir))
         import_frm_dir_btn = Button(further_methods_frm,text='IMPORT FRAMES DIRECTORY TO SIMBA PROJECT', fg='blue', command=lambda: ImportFrameDirectoryPopUp(config_path=self.config_path))
         add_clf_btn = Button(further_methods_frm, text='ADD CLASSIFIER TO SIMBA PROJECT', fg='blue', command=lambda: AddClfPopUp(config_path=self.config_path))
         remove_clf_btn = Button(further_methods_frm, text='REMOVE CLASSIFIER FROM SIMBA PROJECT', fg='blue', command=lambda: RemoveAClassifierPopUp(config_path=self.config_path))
         archive_files_btn = Button(further_methods_frm, text='ARCHIVE PROCESSED FILES IN SIMBA PROJECT', fg='blue', command=lambda: ArchiveProcessedFilesPopUp(config_path=self.config_path))
-        reverse_btn = Button(further_methods_frm, text='REVERSE TRACKING IDENTITIES IN SIMBA PROJECT',fg='blue', command=lambda: self.reverseid())
+        reverse_btn = Button(further_methods_frm, text='REVERSE TRACKING IDENTITIES IN SIMBA PROJECT',fg='blue', command=lambda: None)
         interpolate_btn = Button(further_methods_frm, text='INTERPOLATE POSE IN SIMBA PROJECT', fg='blue', command=lambda: InterpolatePopUp(config_path=self.config_path))
         smooth_btn = Button(further_methods_frm, text='SMOOTH POSE IN SIMBA PROJECT', fg='blue', command=lambda: SmoothingPopUp(config_path=self.config_path))
 
         label_setscale = CreateLabelFrameWithIcon(parent=tab3, header='VIDEO PARAMETERS (FPS, RESOLUTION, PPX/MM ....)', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.VIDEO_PARAMETERS.value)
         #label_setscale = LabelFrame(tab3,text='VIDEO PARAMETERS (FPS, RESOLUTION, PPX/MM ....)', font=Formats.LABELFRAME_HEADER_FORMAT.value, pady=5,padx=5,fg='black')
         self.distance_in_mm_eb = Entry_Box(label_setscale, 'KNOWN DISTANCE (MILLIMETERS)', '25', validation='numeric')
         button_setdistanceinmm = Button(label_setscale, text='AUTO-POPULATE', fg='green', command=lambda: self.set_distance_mm())
@@ -355,16 +354,15 @@
 
         lbl_tools_frm = LabelFrame(tab7, text='LABELLING TOOLS', font=Formats.LABELFRAME_HEADER_FORMAT.value, fg='black')
         visualize_annotation_img_btn = Button(lbl_tools_frm, text='Visualize annotations', fg='blue', command=lambda: ExtractAnnotationFramesPopUp(config_path=self.config_path))
         third_party_annotations_btn = Button(lbl_tools_frm, text='Append third-party annotations', fg='purple', command=lambda: ThirdPartyAnnotatorAppenderPopUp(config_path=self.config_path))
 
 
         label_trainmachinemodel = CreateLabelFrameWithIcon(parent=tab8, header='TRAIN MACHINE MODELS', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.TRAIN_ML_MODEL.value)
-        #label_trainmachinemodel = LabelFrame(tab8,text='TRAIN MACHINE MODELS',font=Formats.LABELFRAME_HEADER_FORMAT.value,padx=5,pady=5,fg='black')
-        button_trainmachinesettings = Button(label_trainmachinemodel,text='SETTINGS',command=self.trainmachinemodelsetting)
+        button_trainmachinesettings = Button(label_trainmachinemodel,text='SETTINGS', fg='darkorange', command=self.trainmachinemodelsetting)
         button_trainmachinemodel = Button(label_trainmachinemodel,text='TRAIN SINGLE MODEL (GLOBAL ENVIRONMENT)',fg='blue',command = lambda: threading.Thread(target=self.train_single_model(config_path=self.config_path)).start())
         button_train_multimodel = Button(label_trainmachinemodel, text='TRAIN MULTIPLE MODELS (ONE FOR EACH SAVED SETTING)',fg='green',command = lambda: threading.Thread(target=self.train_multiple_models_from_meta(config_path=self.config_path)).start())
 
         label_model_validation = CreateLabelFrameWithIcon(parent=tab9, header='VALIDATE MODEL ON SINGLE VIDEO', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.OUT_OF_SAMPLE_VALIDATION.value)
         #label_model_validation = LabelFrame(tab9, text='VALIDATE MODEL ON SINGLE VIDEO', pady=5, padx=5, font=("Helvetica", 12, 'bold'), fg='blue')
         self.csvfile = FileSelect(label_model_validation, 'SELECT DATA FEATURE FILE', color='blue', lblwidth=30)
         self.modelfile = FileSelect(label_model_validation, 'SELECT MODEL FILE', color='blue', lblwidth=30)
@@ -580,37 +578,24 @@
         directing_animals_analyzer.create_directionality_dfs()
         directing_animals_analyzer.save_directionality_dfs()
         directing_animals_analyzer.summary_statistics()
 
     def directing_other_animals_visualizer(self):
         _ = DirectingOtherAnimalsVisualizerPopUp(config_path=self.config_path)
 
-
-    def reverseid(self):
-        config = ConfigParser()
-        configFile = str(self.config_path)
-        config.read(configFile)
-        noanimal = int(config.get('General settings','animal_no'))
-
-        if noanimal ==2:
-            reverse_dlc_input_files(self.config_path)
-        else:
-            print('This only works if you have exactly 2 animals in your tracking data and video.')
-
     def train_single_model(self, config_path=None):
         model_trainer = TrainSingleModel(config_path=config_path)
         model_trainer.perform_sampling()
         model_trainer.train_model()
         model_trainer.save_model()
 
     def train_multiple_models_from_meta(self, config_path=None):
         model_trainer = TrainMultipleModelsFromMeta(config_path=config_path)
         model_trainer.run()
 
-
     def importBoris(self):
         ann_folder = askdirectory()
         boris_appender = BorisAppender(config_path=self.config_path, boris_folder=ann_folder)
         boris_appender.create_boris_master_file()
         boris_appender.run()
 
     def importSolomon(self):
@@ -657,16 +642,16 @@
         interactive_grapher.create_plots()
 
 
     def generateSimBPlotlyFile(self,var):
         inputList = []
         for i in var:
             inputList.append(i.get())
-
-        create_plotly_container(self.path_plot_frm, inputList)
+        stdout_warning(msg='SimBA plotly interface is not available.')
+        pass
 
     def open_plotly_interface(self, url):
 
         try:
             self.p.kill()
             self.p2.kill()
         except:
@@ -695,33 +680,34 @@
     def trainmachinemodelsetting(self):
         _ = MachineModelSettingsPopUp(config_path=self.config_path)
 
     def run_feature_extraction(self):
         print(f'Pose-estimation body part setting for feature extraction: {str(self.animal_cnt)} animals {str(self.pose_setting)} body-parts')
         feature_extractor_classes = get_bp_config_code_class_pairs()
         if self.user_defined_var.get():
-            _ = run_user_defined_feature_extraction_class(file_path=self.scriptfile.file_path, config_path=self.config_path)
+            _ = run_user_defined_feature_extraction_class(file_path=self.scriptfile.file_path,
+                                                          config_path=self.config_path)
         else:
             if (self.pose_setting == '8'):
                 feature_extractor = feature_extractor_classes[self.pose_setting][self.animal_cnt](config_path=self.config_path)
             else:
                 feature_extractor = feature_extractor_classes[self.pose_setting](config_path=self.config_path)
-            feature_extractor.extract_features()
+            feature_extractor.run()
 
     def set_distance_mm(self):
         check_int(name='DISTANCE IN MILLIMETER', value=self.distance_in_mm_eb.entry_get, min_value=1)
         self.config.set('Frame settings', 'distance_mm', self.distance_in_mm_eb.entry_get)
         with open(self.config_path, 'w') as f:
             self.config.write(f)
 
     def correct_outlier(self):
         outlier_correcter_movement = OutlierCorrecterMovement(config_path=self.config_path)
-        outlier_correcter_movement.correct_movement_outliers()
+        outlier_correcter_movement.run()
         outlier_correcter_location = OutlierCorrecterLocation(config_path=self.config_path)
-        outlier_correcter_location.correct_location_outliers()
+        outlier_correcter_location.run()
         stdout_success(msg='Outlier corrected files located in "project_folder/csv/outlier_corrected_movement_location" directory')
 
 
     def callback(self,url):
         webbrowser.open_new(url)
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/labelling_advanced_interface.py` & `Simba-UW-tf-dev-1.57.6/simba/labelling_advanced_interface.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,32 +1,29 @@
 __author__ = "Simon Nilsson", "JJ Choong"
 
-import cv2
-import pandas as pd
-from simba.rw_dfs import read_df, save_df
-from simba.read_config_unit_tests import (read_config_entry,
-                                          read_config_file,
-                                          check_file_exist_and_readable,
-                                          check_int,
-                                          read_project_path_and_file_type)
-from simba.misc_tools import (get_video_meta_data,
-                              get_fn_ext)
-from simba.utils.printing import stdout_success
 import simba
 from tkinter import *
 from tkinter import filedialog
 from PIL import Image, ImageTk
 from subprocess import Popen, PIPE
 import os
-from simba.train_model_functions import get_all_clf_names
-from simba.enums import ReadConfig, Paths, Dtypes
 from tabulate import tabulate
+import cv2
+import pandas as pd
+from simba.utils.checks import check_int, check_file_exist_and_readable
+from simba.utils.read_write import (read_config_entry,
+                                    get_video_meta_data,
+                                    get_fn_ext,
+                                    read_df,
+                                    write_df)
 from simba.utils.errors import FrameRangeError, AdvancedLabellingError
+from simba.utils.printing import stdout_success
+from simba.mixins.config_reader import ConfigReader
 
-class AdvancedLabellingInterface(object):
+class AdvancedLabellingInterface(ConfigReader):
     """
     Class for advanced labelling (annotation) interface in SimBA.
     https://github.com/sgoldenlab/simba/blob/master/docs/advanced_labelling.md
 
     Parameters
     ----------
     config_path: str
@@ -48,35 +45,28 @@
     """
 
     def __init__(self,
                  config_path: str,
                  file_path: str,
                  continuing: bool):
 
+        ConfigReader.__init__(self, config_path=config_path)
         self.padding, self.file_path = 5, file_path
-        self.frm_no, self.config_path = 0, config_path
-        self.config = read_config_file(config_path)
+        self.frm_no, self.video_path = 0, file_path
         self.continuing = continuing
         self.play_video_script_path = os.path.join(os.path.dirname(simba.__file__), 'play_annotation_video.py')
-        self.project_path, self.file_type = read_project_path_and_file_type(config=self.config)
-        self.target_cnt = read_config_entry(self.config, ReadConfig.SML_SETTINGS.value, ReadConfig.TARGET_CNT.value, Dtypes.INT.value)
-        self.videos_dir_path = os.path.join(self.project_path, 'videos')
         _, self.video_name, _ = get_fn_ext(filepath=file_path)
-        self.features_extracted_folder = os.path.join(self.project_path, Paths.FEATURES_EXTRACTED_DIR.value)
-        self.targets_inserted_folder = os.path.join(self.project_path, Paths.TARGETS_INSERTED_DIR.value)
-        self.machine_results_folder = os.path.join(self.project_path, Paths.MACHINE_RESULTS_DIR.value)
-        self.features_extracted_file_path = os.path.join(self.features_extracted_folder, self.video_name + '.' + self.file_type)
-        self.targets_inserted_file_path = os.path.join(self.targets_inserted_folder, self.video_name + '.' + self.file_type)
-        self.machine_results_file_path = os.path.join(self.machine_results_folder, self.video_name + '.' + self.file_type)
-        self.video_path = file_path
+        self.features_extracted_file_path = os.path.join(self.features_dir, self.video_name + '.' + self.file_type)
+        self.targets_inserted_file_path = os.path.join(self.targets_folder, self.video_name + '.' + self.file_type)
+        self.machine_results_file_path = os.path.join(self.machine_results_dir, self.video_name + '.' + self.file_type)
         self.cap = cv2.VideoCapture(self.video_path)
         self.video_meta_data = get_video_meta_data(video_path=self.video_path)
         self.frame_lst = list(range(0, self.video_meta_data['frame_count']))
         self.max_frm_no = max(self.frame_lst)
-        self.target_lst = get_all_clf_names(config=self.config, target_cnt=self.target_cnt)
+        self.target_lst = self.get_all_clf_names()
         self.max_frm_size = 1080, 650
         self.main_window = Toplevel()
         if continuing:
             check_file_exist_and_readable(file_path=self.targets_inserted_file_path)
             check_file_exist_and_readable(file_path=self.features_extracted_file_path)
             self.data_df = read_df(self.targets_inserted_file_path, self.file_type)
             self.data_df_features = read_df(self.features_extracted_file_path, self.file_type)
@@ -371,15 +361,15 @@
             self.create_print_statements(frame_range=True, start_frame=start_frm, end_frame=end_frm)
 
     def save_results(self):
         self.save_df = read_df(self.features_extracted_file_path, self.file_type)
         self.save_df = pd.concat([self.save_df, self.data_df_targets], axis=1)
         self.save_df = self.save_df.dropna(subset=self.target_lst)
         try:
-            save_df(self.save_df, self.file_type, self.targets_inserted_file_path)
+            write_df(self.save_df, self.file_type, self.targets_inserted_file_path)
         except Exception as e:
             print(e, 'SIMBA ERROR: File for video {} could not be saved.')
             raise FileExistsError
         stdout_success(msg=f'SAVED: Annotation file for video {self.video_name} saved within the project_folder/csv/targets_inserted directory.')
         if not self.config.has_section('Last annotated frames'):
             self.config.add_section('Last annotated frames')
         self.config.set('Last annotated frames', str(self.video_name), str(self.current_frm_n.get()))
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/unsupervised/.DS_Store` & `Simba-UW-tf-dev-1.57.6/simba/assets/unsupervised/.DS_Store`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/unsupervised/model_names.parquet` & `Simba-UW-tf-dev-1.57.6/simba/assets/unsupervised/model_names.parquet`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/unsupervised/features.csv` & `Simba-UW-tf-dev-1.57.6/simba/assets/unsupervised/features.csv`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/shap/down_arrow.jpg` & `Simba-UW-tf-dev-1.57.6/simba/assets/shap/down_arrow.jpg`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/shap/intruder_shape.jpg` & `Simba-UW-tf-dev-1.57.6/simba/assets/shap/intruder_shape.jpg`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/shap/feature_categories/shap_feature_categories.csv` & `Simba-UW-tf-dev-1.57.6/simba/assets/shap/feature_categories/shap_feature_categories.csv`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/shap/.DS_Store` & `Simba-UW-tf-dev-1.57.6/simba/assets/shap/.DS_Store`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/shap/resident_shape.jpg` & `Simba-UW-tf-dev-1.57.6/simba/assets/shap/resident_shape.jpg`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/shap/resident_intruder_shape.jpg` & `Simba-UW-tf-dev-1.57.6/simba/assets/shap/resident_intruder_shape.jpg`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/shap/animal_distances.jpg` & `Simba-UW-tf-dev-1.57.6/simba/assets/shap/animal_distances.jpg`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/shap/baseline_scale.jpg` & `Simba-UW-tf-dev-1.57.6/simba/assets/shap/baseline_scale.jpg`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/shap/ubuntu.regular.ttf` & `Simba-UW-tf-dev-1.57.6/simba/assets/shap/ubuntu.regular.ttf`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/shap/side_scale.jpg` & `Simba-UW-tf-dev-1.57.6/simba/assets/shap/side_scale.jpg`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/shap/UbuntuMono-Regular.ttf` & `Simba-UW-tf-dev-1.57.6/simba/assets/shap/UbuntuMono-Regular.ttf`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/shap/side_scale_5.jpg` & `Simba-UW-tf-dev-1.57.6/simba/assets/shap/side_scale_5.jpg`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/shap/intruder_movement.jpg` & `Simba-UW-tf-dev-1.57.6/simba/assets/shap/intruder_movement.jpg`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/shap/resident_movement.jpg` & `Simba-UW-tf-dev-1.57.6/simba/assets/shap/resident_movement.jpg`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/shap/color_bar.jpg` & `Simba-UW-tf-dev-1.57.6/simba/assets/shap/color_bar.jpg`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/shap/resident_intruder_movement.jpg` & `Simba-UW-tf-dev-1.57.6/simba/assets/shap/resident_intruder_movement.jpg`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/.DS_Store` & `Simba-UW-tf-dev-1.57.6/simba/assets/.DS_Store`

 * *Files 3% similar despite different names*

```diff
@@ -485,19 +485,19 @@
 00001e40: 013a 013f 0141 0142 0143 014c 0152 0154  .:.?.A.B.C.L.R.T
 00001e50: 0155 0156 015f 0167 0169 016a 016b 0174  .U.V._.g.i.j.k.t
 00001e60: 017d 0180 0181 0182 018b 019a 019c 019d  .}..............
 00001e70: 019e 01a7 01b1 01b2 01b3 01b4 01bd 01c2  ................
 00001e80: 01c3 0000 0000 0000 0201 0000 0000 0000  ................
 00001e90: 004a 0000 0000 0000 0000 0000 0000 0000  .J..............
 00001ea0: 01c5 6300 6f00 6e00 736d 6f44 4462 6c6f  ..c.o.n.smoDDblo
-00001eb0: 6200 0000 08c1 fc21 5522 f4c4 4100 0000  b......!U"..A...
+00001eb0: 6200 0000 08dc 0545 af18 fac4 4100 0000  b......E....A...
 00001ec0: 0500 6900 6300 6f00 6e00 736d 6f64 4462  ..i.c.o.n.smodDb
-00001ed0: 6c6f 6200 0000 08c1 fc21 5522 f4c4 4100  lob......!U"..A.
+00001ed0: 6c6f 6200 0000 08dc 0545 af18 fac4 4100  lob......E....A.
 00001ee0: 0000 0500 6900 6300 6f00 6e00 7370 6831  ....i.c.o.n.sph1
-00001ef0: 5363 6f6d 7000 0000 0000 0800 0000 0000  Scomp...........
+00001ef0: 5363 6f6d 7000 0000 0000 0810 0000 0000  Scomp...........
 00001f00: 0500 6900 6300 6f00 6e00 7376 5372 6e6c  ..i.c.o.n.svSrnl
 00001f10: 6f6e 6700 0000 0100 0000 0300 6900 6d00  ong.........i.m.
 00001f20: 6762 7773 7062 6c6f 6200 0000 ca62 706c  gbwspblob....bpl
 00001f30: 6973 7430 30d7 0102 0304 0506 0708 080a  ist00...........
 00001f40: 080a 0d0a 5d53 686f 7753 7461 7475 7342  ....]ShowStatusB
 00001f50: 6172 5b53 686f 7750 6174 6862 6172 5b53  ar[ShowPathbar[S
 00001f60: 686f 7754 6f6f 6c62 6172 5b53 686f 7754  howToolbar[ShowT
@@ -522,15 +522,15 @@
 00002090: 6e64 735b 5368 6f77 5369 6465 6261 7208  nds[ShowSidebar.
 000020a0: 0809 0809 5f10 197b 7b34 3139 2c20 3131  ...._..{{419, 11
 000020b0: 347d 2c20 7b31 3031 352c 2037 3637 7d7d  4}, {1015, 767}}
 000020c0: 0908 1725 313d 4960 6d79 7a7b 7c7d 7e9a  ...%1=I`myz{|}~.
 000020d0: 0000 0000 0000 0101 0000 0000 0000 000f  ................
 000020e0: 0000 0000 0000 0000 0000 0000 0000 009b  ................
 000020f0: 0000 0005 0069 0063 006f 006e 0073 6c67  .....i.c.o.n.slg
-00002100: 3153 636f 6d70 0000 0000 0005 98d9 0000  1Scomp..........
+00002100: 3153 636f 6d70 0000 0000 0005 a103 0000  1Scomp..........
 00002110: 0005 0069 0063 006f 006e 0073 6c73 7643  ...i.c.o.n.slsvC
 00002120: 626c 6f62 0000 02ba 6270 6c69 7374 3030  blob....bplist00
 00002130: da01 0203 0405 0607 0809 0a0b 0b0d 1a48  ...............H
 00002140: 494a 4b4c 4d5f 1010 7573 6552 656c 6174  IJKLM_..useRelat
 00002150: 6976 6544 6174 6573 5f10 0f73 686f 7749  iveDates_..showI
 00002160: 636f 6e50 7265 7669 6577 5763 6f6c 756d  conPreviewWcolum
 00002170: 6e73 5f10 1163 616c 6375 6c61 7465 416c  ns_..calculateAl
@@ -613,19 +613,19 @@
 00002640: 7901 7a01 7c01 7d01 7f01 8801 8901 8b01  y.z.|.}.........
 00002650: 8c01 8e01 9701 9801 9a01 9b01 9d01 a601  ................
 00002660: a701 a901 aa01 ac01 b501 b601 b801 b901  ................
 00002670: bb01 bc01 c501 ce01 d701 dc00 0000 0000  ................
 00002680: 0002 0100 0000 0000 0000 4d00 0000 0000  ..........M.....
 00002690: 0000 0000 0000 0000 0001 e500 0000 0500  ................
 000026a0: 6900 6300 6f00 6e00 736d 6f44 4462 6c6f  i.c.o.n.smoDDblo
-000026b0: 6200 0000 08c1 fc21 5522 f4c4 4100 0000  b......!U"..A...
+000026b0: 6200 0000 08dc 0545 af18 fac4 4100 0000  b......E....A...
 000026c0: 0500 6900 6300 6f00 6e00 736d 6f64 4462  ..i.c.o.n.smodDb
-000026d0: 6c6f 6200 0000 08c1 fc21 5522 f4c4 4100  lob......!U"..A.
+000026d0: 6c6f 6200 0000 08dc 0545 af18 fac4 4100  lob......E....A.
 000026e0: 0000 0500 6900 6300 6f00 6e00 7370 6831  ....i.c.o.n.sph1
-000026f0: 5363 6f6d 7000 0000 0000 0800 0000 0000  Scomp...........
+000026f0: 5363 6f6d 7000 0000 0000 0810 0000 0000  Scomp...........
 00002700: 0500 6900 6300 6f00 6e00 7376 5372 6e6c  ..i.c.o.n.svSrnl
 00002710: 6f6e 6700 0000 0100 0000 0300 6900 6d00  ong.........i.m.
 00002720: 6762 7773 7062 6c6f 6200 0000 ca62 706c  gbwspblob....bpl
 00002730: 6973 7430 30d7 0102 0304 0506 0708 080a  ist00...........
 00002740: 080a 0d0a 5d53 686f 7753 7461 7475 7342  ....]ShowStatusB
 00002750: 6172 5b53 686f 7750 6174 6862 6172 5b53  ar[ShowPathbar[S
 00002760: 686f 7754 6f6f 6c62 6172 5b53 686f 7754  howToolbar[ShowT
@@ -738,17 +738,17 @@
 00002e10: 7374 3030 d701 0203 0405 0607 0808 0a08  st00............
 00002e20: 0a0d 0a5d 5368 6f77 5374 6174 7573 4261  ...]ShowStatusBa
 00002e30: 725b 5368 6f77 5061 7468 6261 725b 5368  r[ShowPathbar[Sh
 00002e40: 6f77 546f 6f6c 6261 725b 5368 6f77 5461  owToolbar[ShowTa
 00002e50: 6256 6965 775f 1014 436f 6e74 6169 6e65  bView_..Containe
 00002e60: 7253 686f 7753 6964 6562 6172 5c57 696e  rShowSidebar\Win
 00002e70: 646f 7742 6f75 6e64 735b 5368 6f77 5369  dowBounds[ShowSi
-00002e80: 6465 6261 7208 0809 0809 5f10 177b 7b30  debar....._..{{0
-00002e90: 2c20 3131 367d 2c20 7b31 3235 302c 2037  , 116}, {1250, 7
-00002ea0: 3631 7d7d 0908 1725 313d 4960 6d79 7a7b  61}}...%1=I`myz{
+00002e80: 6465 6261 7208 0809 0809 5f10 177b 7b32  debar....._..{{2
+00002e90: 302c 2039 307d 2c20 7b31 3031 352c 2037  0, 90}, {1015, 7
+00002ea0: 3637 7d7d 0908 1725 313d 4960 6d79 7a7b  67}}...%1=I`myz{
 00002eb0: 7c7d 7e98 0000 0000 0000 0101 0000 0000  |}~.............
 00002ec0: 0000 000f 0000 0000 0000 0000 0000 0000  ................
 00002ed0: 0000 0099 0000 0007 006c 006f 006f 006b  .........l.o.o.k
 00002ee0: 0075 0070 0073 6c67 3153 636f 6d70 0000  .u.p.slg1Scomp..
 00002ef0: 0000 0004 b1fb 0000 0000 0000 0000 0000  ................
 00002f00: 0000 0000 0000 0000 0000 0000 0000 0000  ................
 00002f10: 0000 0000 0000 0000 0000 0000 0000 0000  ................
@@ -869,19 +869,19 @@
 00003640: 013a 013f 0141 0142 0143 014c 0152 0154  .:.?.A.B.C.L.R.T
 00003650: 0155 0156 015f 0167 0169 016a 016b 0174  .U.V._.g.i.j.k.t
 00003660: 017d 0180 0181 0182 018b 019a 019c 019d  .}..............
 00003670: 019e 01a7 01b1 01b2 01b3 01b4 01bd 01c2  ................
 00003680: 01c3 0000 0000 0000 0201 0000 0000 0000  ................
 00003690: 004a 0000 0000 0000 0000 0000 0000 0000  .J..............
 000036a0: 01c5 6300 6f00 6e00 736d 6f44 4462 6c6f  ..c.o.n.smoDDblo
-000036b0: 6200 0000 08c1 fc21 5522 f4c4 4100 0000  b......!U"..A...
+000036b0: 6200 0000 08dc 0545 af18 fac4 4100 0000  b......E....A...
 000036c0: 0500 6900 6300 6f00 6e00 736d 6f64 4462  ..i.c.o.n.smodDb
-000036d0: 6c6f 6200 0000 08c1 fc21 5522 f4c4 4100  lob......!U"..A.
+000036d0: 6c6f 6200 0000 08dc 0545 af18 fac4 4100  lob......E....A.
 000036e0: 0000 0500 6900 6300 6f00 6e00 7370 6831  ....i.c.o.n.sph1
-000036f0: 5363 6f6d 7000 0000 0000 0800 0000 0000  Scomp...........
+000036f0: 5363 6f6d 7000 0000 0000 0810 0000 0000  Scomp...........
 00003700: 0500 6900 6300 6f00 6e00 7376 5372 6e6c  ..i.c.o.n.svSrnl
 00003710: 6f6e 6700 0000 0100 0000 0300 6900 6d00  ong.........i.m.
 00003720: 6762 7773 7062 6c6f 6200 0000 ca62 706c  gbwspblob....bpl
 00003730: 6973 7430 30d7 0102 0304 0506 0708 080a  ist00...........
 00003740: 080a 0d0a 5d53 686f 7753 7461 7475 7342  ....]ShowStatusB
 00003750: 6172 5b53 686f 7750 6174 6862 6172 5b53  ar[ShowPathbar[S
 00003760: 686f 7754 6f6f 6c62 6172 5b53 686f 7754  howToolbar[ShowT
@@ -997,19 +997,19 @@
 00003e40: 013a 013f 0141 0142 0143 014c 0152 0154  .:.?.A.B.C.L.R.T
 00003e50: 0155 0156 015f 0167 0169 016a 016b 0174  .U.V._.g.i.j.k.t
 00003e60: 017d 0180 0181 0182 018b 019a 019c 019d  .}..............
 00003e70: 019e 01a7 01b1 01b2 01b3 01b4 01bd 01c2  ................
 00003e80: 01c3 0000 0000 0000 0201 0000 0000 0000  ................
 00003e90: 004a 0000 0000 0000 0000 0000 0000 0000  .J..............
 00003ea0: 01c5 6300 6f00 6e00 736d 6f44 4462 6c6f  ..c.o.n.smoDDblo
-00003eb0: 6200 0000 08c1 fc21 5522 f4c4 4100 0000  b......!U"..A...
+00003eb0: 6200 0000 08dc 0545 af18 fac4 4100 0000  b......E....A...
 00003ec0: 0500 6900 6300 6f00 6e00 736d 6f64 4462  ..i.c.o.n.smodDb
-00003ed0: 6c6f 6200 0000 08c1 fc21 5522 f4c4 4100  lob......!U"..A.
+00003ed0: 6c6f 6200 0000 08dc 0545 af18 fac4 4100  lob......E....A.
 00003ee0: 0000 0500 6900 6300 6f00 6e00 7370 6831  ....i.c.o.n.sph1
-00003ef0: 5363 6f6d 7000 0000 0000 0800 0000 0000  Scomp...........
+00003ef0: 5363 6f6d 7000 0000 0000 0810 0000 0000  Scomp...........
 00003f00: 0500 6900 6300 6f00 6e00 7376 5372 6e6c  ..i.c.o.n.svSrnl
 00003f10: 6f6e 6700 0000 0100 0000 0300 6900 6d00  ong.........i.m.
 00003f20: 6762 7773 7062 6c6f 6200 0000 ca62 706c  gbwspblob....bpl
 00003f30: 6973 7430 30d7 0102 0304 0506 0708 080a  ist00...........
 00003f40: 080a 0d0a 5d53 686f 7753 7461 7475 7342  ....]ShowStatusB
 00003f50: 6172 5b53 686f 7750 6174 6862 6172 5b53  ar[ShowPathbar[S
 00003f60: 686f 7754 6f6f 6c62 6172 5b53 686f 7754  howToolbar[ShowT
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/lookups/.DS_Store` & `Simba-UW-tf-dev-1.57.6/simba/assets/lookups/.DS_Store`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/lookups/model_names.parquet` & `Simba-UW-tf-dev-1.57.6/simba/assets/lookups/model_names.parquet`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/lookups/features.csv` & `Simba-UW-tf-dev-1.57.6/simba/assets/lookups/features.csv`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/lookups/unsupervised_example_x.csv` & `Simba-UW-tf-dev-1.57.6/simba/assets/lookups/unsupervised_example_x.csv`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/stl/operant_tray.stl` & `Simba-UW-tf-dev-1.57.6/simba/assets/stl/operant_tray.stl`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/stl/operant_lever.stl` & `Simba-UW-tf-dev-1.57.6/simba/assets/stl/operant_lever.stl`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/stl/operant_walls.stl` & `Simba-UW-tf-dev-1.57.6/simba/assets/stl/operant_walls.stl`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/stl/grid_floor.stl` & `Simba-UW-tf-dev-1.57.6/simba/assets/stl/grid_floor.stl`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/img/.DS_Store` & `Simba-UW-tf-dev-1.57.6/simba/assets/img/.DS_Store`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/img/about_me.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/img/about_me.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/img/splash.mp4` & `Simba-UW-tf-dev-1.57.6/simba/assets/img/splash.mp4`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/img/bg_2.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/img/bg_2.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/img/splash.pptx` & `Simba-UW-tf-dev-1.57.6/simba/assets/img/splash.pptx`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/img/bg.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/img/bg.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/UbuntuMono-Regular.ttf` & `Simba-UW-tf-dev-1.57.6/simba/assets/UbuntuMono-Regular.ttf`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/factory.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/factory.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/cluster.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/cluster.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/load.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/load.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/gif.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/gif.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/pose.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/pose.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/features.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/features.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/.DS_Store` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/.DS_Store`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/settings.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/settings.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/stopwatch.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/stopwatch.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/link.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/link.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/dash_simba.css` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/dash_simba.css`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/documentation.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/documentation.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/fps.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/fps.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/dimensionality_reduction.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/dimensionality_reduction.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/roi.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/roi.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/superimpose.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/superimpose.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/label.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/label.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/change.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/change.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/crop.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/crop.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/rotate.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/rotate.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/path.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/path.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/clip.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/clip.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/restart.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/restart.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/calipher.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/calipher.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/add_on.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/add_on.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/create.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/create.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/SimBA_logo.ico` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/SimBA_logo.ico`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/print.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/print.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/clf.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/clf.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/concat_icons/mosaic.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/concat_icons/mosaic.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/concat_icons/vertical.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/concat_icons/vertical.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/concat_icons/horizontal.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/concat_icons/horizontal.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/concat_icons/mixed_mosaic.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/concat_icons/mixed_mosaic.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/merge.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/merge.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/clean.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/clean.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/clf_2.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/clf_2.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/visualize.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/visualize.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/concat.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/concat.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/boris.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/boris.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/frames.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/frames.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/video.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/video.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/sample.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/sample.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/metrics.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/metrics.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/grey.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/grey.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/exit.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/exit.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/outlier.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/outlier.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/clahe.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/clahe.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/trash.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/trash.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/about.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/about.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/convert.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/convert.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/SimBA_logo.icns` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/SimBA_logo.icns`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/reorganize.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/reorganize.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/browse.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/browse.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/SimBA_logo.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/SimBA_logo.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/ethovision.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/ethovision.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/icons/close.png` & `Simba-UW-tf-dev-1.57.6/simba/assets/icons/close.png`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/dash_simba_base.css` & `Simba-UW-tf-dev-1.57.6/simba/assets/dash_simba_base.css`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/assets/TheGoldenLab.PNG` & `Simba-UW-tf-dev-1.57.6/simba/assets/TheGoldenLab.PNG`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/read_config_unit_tests.py` & `Simba-UW-tf-dev-1.57.6/simba/read_config_unit_tests.py`

 * *Files 2% similar despite different names*

```diff
@@ -153,15 +153,15 @@
         if default_value != None:
             return default_value
         else:
             raise MissingProjectConfigEntryError(msg=f'SimBA could not find an entry for option {option} under section {section} in the project_config.ini. Please specify the settings in the settings menu.')
 
 
 def read_simba_meta_files(folder_path: str):
-    from simba.misc_tools import find_files_of_filetypes_in_directory
+    from simba.utils.read_write import find_files_of_filetypes_in_directory
     file_paths = find_files_of_filetypes_in_directory(directory=folder_path, extensions=['.csv'])
     meta_file_lst = []
     for i in file_paths:
         if i.__contains__("meta"):
             meta_file_lst.append(os.path.join(folder_path, i))
     if len(meta_file_lst) == 0:
         NoFileFoundWarning(msg=f'The training meta-files folder in your project ({folder_path}) does not have any meta files inside it (no files in this folder has the "meta" substring in the filename)')
@@ -173,14 +173,16 @@
 
 
 def check_file_exist_and_readable(file_path: str):
     if not os.path.isfile(file_path):
         raise NoFilesFoundError(msg=f'{file_path} is not a valid file path')
     elif not os.access(file_path, os.R_OK):
         raise CorruptedFileError(f'{file_path} is not readable')
+    else:
+        pass
 
 def read_config_file(ini_path: str):
     config = ConfigParser()
     try:
         config.read(str(ini_path))
     except Exception as e:
         print(e.args)
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/project_config_creator.py` & `Simba-UW-tf-dev-1.57.6/simba/project_config_creator.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,23 +1,21 @@
 __author__ = "Simon Nilsson"
 
 import os
 import platform
 from configparser import ConfigParser
+import csv
+
 import simba
-from simba.misc_tools import SimbaTimer
-from simba.utils.printing import stdout_success
+from simba.utils.printing import stdout_success, SimbaTimer
 from simba.utils.errors import DirectoryExistError
-import csv
 from simba.enums import (DirNames,
                          ReadConfig,
                          Dtypes,
-                         Paths,
-                         Defaults,
-                         TagNames)
+                         Paths)
 
 class ProjectConfigCreator(object):
 
     """
     Class for creating SimBA project directory tree and project_config.ini
 
     Parameters
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/train_single_model.py` & `Simba-UW-tf-dev-1.57.6/simba/train_single_model.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,52 +1,24 @@
 __author__ = "Simon Nilsson"
 
-import os, glob, ast
-from simba.train_model_functions import (read_all_files_in_folder,
-                                         read_in_all_model_names_to_remove,
-                                         delete_other_annotation_columns,
-                                         split_df_to_x_y,
-                                         random_undersampler,
-                                         smoteen_oversampler,
-                                         smote_oversampler,
-                                         calc_permutation_importance,
-                                         calc_learning_curve,
-                                         calc_pr_curve,
-                                         create_example_dt,
-                                         create_clf_report,
-                                         create_x_importance_bar_chart,
-                                         create_shap_log,
-                                         dviz_classification_visualization,
-                                         create_x_importance_log,
-                                         create_meta_data_csv_training_one_model,
-                                         save_rf_model,
-                                         bout_train_test_splitter,
-                                         check_dataset_integrity,
-                                         partial_dependence_calculator,
-                                         read_all_files_in_folder_mp,
-                                         clf_fit)
-
-from simba.read_config_unit_tests import (check_int,
-                                          check_float,
-                                          read_config_entry,
-                                          read_config_file,
-                                          check_if_filepath_list_is_empty,
-                                          read_project_path_and_file_type)
-from simba.drop_bp_cords import drop_bp_cords
+import os, ast
+import numpy as np
+from simba.utils.checks import  check_int, check_float, check_if_filepath_list_is_empty
 from sklearn.model_selection import train_test_split
 from sklearn.ensemble import RandomForestClassifier
-from simba.misc_tools import (SimbaTimer)
-from simba.utils.printing import stdout_success
+from simba.utils.read_write import read_config_entry
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.mixins.config_reader import ConfigReader
+from simba.mixins.train_model_mixin import TrainModelMixin
 from simba.enums import (Options,
                          ReadConfig,
                          Dtypes,
-                         Paths,
                          Methods)
 
-class TrainSingleModel(object):
+class TrainSingleModel(ConfigReader, TrainModelMixin):
     """
     Class for training a single random forest model from hyper-parameter setting and sampling methods
     stored within the SimBA project config .ini file (`global environment`).
 
     Parameters
     ----------
     config_path: str
@@ -61,25 +33,22 @@
 
     """
 
 
     def __init__(self,
                  config_path: str):
 
-        self.config = read_config_file(config_path)
-        self.ini_path = config_path
+        ConfigReader.__init__(self, config_path=config_path)
+        TrainModelMixin.__init__(self)
         self.model_dir_out = os.path.join(read_config_entry(self.config, ReadConfig.SML_SETTINGS.value, ReadConfig.MODEL_DIR.value, data_type=Dtypes.STR.value), 'generated_models')
         if not os.path.exists(self.model_dir_out): os.makedirs(self.model_dir_out)
-        self.project_path, self.file_type = read_project_path_and_file_type(config=self.config)
-        self.data_in_path = os.path.join(self.project_path, Paths.TARGETS_INSERTED_DIR.value)
         self.eval_out_path = os.path.join(self.model_dir_out, 'model_evaluations')
         if not os.path.exists(self.eval_out_path): os.makedirs(self.eval_out_path)
         self.clf_name = read_config_entry(self.config, ReadConfig.CREATE_ENSEMBLE_SETTINGS.value, ReadConfig.CLASSIFIER.value, data_type=Dtypes.STR.value)
         self.tt_size = read_config_entry(self.config, ReadConfig.CREATE_ENSEMBLE_SETTINGS.value, ReadConfig.TT_SIZE.value, data_type=Dtypes.FLOAT.value)
-        self.model_cnt = read_config_entry(self.config, ReadConfig.SML_SETTINGS.value, ReadConfig.TARGET_CNT.value, data_type=Dtypes.INT.value)
         self.algo = read_config_entry(self.config, ReadConfig.CREATE_ENSEMBLE_SETTINGS.value, ReadConfig.MODEL_TO_RUN.value, data_type=Dtypes.STR.value)
         self.split_type = read_config_entry(self.config, ReadConfig.CREATE_ENSEMBLE_SETTINGS.value, ReadConfig.SPLIT_TYPE.value, data_type=Dtypes.STR.value, options=Options.TRAIN_TEST_SPLIT.value, default_value=Methods.SPLIT_TYPE_FRAMES.value)
         self.under_sample_setting = read_config_entry(self.config, ReadConfig.CREATE_ENSEMBLE_SETTINGS.value, ReadConfig.UNDERSAMPLE_SETTING.value, data_type=Dtypes.STR.value).lower().strip()
         self.over_sample_setting = read_config_entry(self.config, ReadConfig.CREATE_ENSEMBLE_SETTINGS.value, ReadConfig.OVERSAMPLE_SETTING.value, data_type=Dtypes.STR.value).lower().strip()
         if self.under_sample_setting == Methods.RANDOM_UNDERSAMPLE.value:
             self.under_sample_ratio = read_config_entry(self.config, ReadConfig.CREATE_ENSEMBLE_SETTINGS.value, ReadConfig.UNDERSAMPLE_RATIO.value, data_type=Dtypes.FLOAT.value, default_value=Dtypes.NAN.value)
             check_float(name=ReadConfig.UNDERSAMPLE_RATIO.value, value=self.under_sample_ratio)
@@ -87,30 +56,29 @@
             self.under_sample_ratio = Dtypes.NAN.value
         if (self.over_sample_setting == Methods.SMOTEENN.value.lower()) or (self.over_sample_setting == Methods.SMOTE.value.lower()):
             self.over_sample_ratio = read_config_entry(self.config, ReadConfig.CREATE_ENSEMBLE_SETTINGS.value, ReadConfig.OVERSAMPLE_RATIO.value, data_type=Dtypes.FLOAT.value, default_value=Dtypes.NAN.value)
             check_float(name=ReadConfig.OVERSAMPLE_RATIO.value, value=self.over_sample_ratio)
         else:
             self.over_sample_ratio = Dtypes.NAN.value
 
-        self.annotation_file_paths = glob.glob(self.data_in_path + '/*.' + self.file_type)
-        check_if_filepath_list_is_empty(filepaths=self.annotation_file_paths, error_msg='SIMBA ERROR: Zero annotation files found in project_folder/csv/targets_inserted, cannot create model.')
-        print('Reading in {} annotated files...'.format(str(len(self.annotation_file_paths))))
-        self.data_df = read_all_files_in_folder_mp(self.annotation_file_paths, self.file_type, [self.clf_name])
-        self.data_df_wo_cords = drop_bp_cords(self.data_df, config_path)
-        annotation_cols_to_remove = read_in_all_model_names_to_remove(self.config, self.model_cnt, self.clf_name)
-        self.x_y_df = delete_other_annotation_columns(self.data_df_wo_cords, list(annotation_cols_to_remove))
+        check_if_filepath_list_is_empty(filepaths=self.target_file_paths, error_msg='Zero annotation files found in project_folder/csv/targets_inserted, cannot create model.')
+        print('Reading in {} annotated files...'.format(str(len(self.target_file_paths))))
+        self.data_df = self.read_all_files_in_folder_mp(self.target_file_paths, self.file_type, [self.clf_name])
+        self.data_df = self.check_raw_dataset_integrity(df=self.data_df, logs_path=self.logs_path)
+        self.data_df_wo_cords = self.drop_bp_cords(df=self.data_df)
+        annotation_cols_to_remove = self.read_in_all_model_names_to_remove(self.config, self.clf_cnt, self.clf_name)
+        self.x_y_df = self.delete_other_annotation_columns(self.data_df_wo_cords, list(annotation_cols_to_remove))
         self.class_names = ['Not_' + self.clf_name, self.clf_name]
-        self.x_df, self.y_df = split_df_to_x_y(self.x_y_df, self.clf_name)
+        self.x_df, self.y_df = self.split_df_to_x_y(self.x_y_df, self.clf_name)
         self.feature_names = self.x_df.columns
-        check_dataset_integrity(x_df=self.x_df, y_df=self.y_df)
+        self.check_sampled_dataset_integrity(x_df=self.x_df, y_df=self.y_df)
         print('Number of features in dataset: ' + str(len(self.x_df.columns)))
         print('Number of {} frames in dataset: {} ({}%)'.format(self.clf_name, str(self.y_df.sum()), str(round(self.y_df.sum() / len(self.y_df), 4) * 100)))
         print('Training and evaluating model...')
-        self.timer = SimbaTimer()
-        self.timer.start_timer()
+        self.timer = SimbaTimer(start=True)
 
     def perform_sampling(self):
         """
         Method for sampling data for training and testing, and perform over and under-sampling of the training sets
         as indicated within the SimBA project config.
 
         Returns
@@ -124,22 +92,22 @@
         Attribute: array
             y_test
         """
 
         if self.split_type == Methods.SPLIT_TYPE_FRAMES.value:
             self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.x_df, self.y_df,test_size=self.tt_size)
         elif self.split_type == Methods.SPLIT_TYPE_BOUTS.value:
-            self.x_train, self.x_test, self.y_train, self.y_test = bout_train_test_splitter(x_df=self.x_df,y_df=self.y_df, test_size=self.tt_size)
+            self.x_train, self.x_test, self.y_train, self.y_test = self.bout_train_test_splitter(x_df=self.x_df,y_df=self.y_df, test_size=self.tt_size)
 
         if self.under_sample_setting == Methods.RANDOM_UNDERSAMPLE.value.lower():
-            self.x_train, self.y_train = random_undersampler(self.x_train, self.y_train, float(self.under_sample_ratio))
+            self.x_train, self.y_train = self.random_undersampler(self.x_train, self.y_train, float(self.under_sample_ratio))
         if self.over_sample_setting == Methods.SMOTEENN.value.lower():
-            self.x_train, self.y_train = smoteen_oversampler(self.x_train, self.y_train, float(self.over_sample_ratio))
+            self.x_train, self.y_train = self.smoteen_oversampler(self.x_train, self.y_train, float(self.over_sample_ratio))
         elif self.over_sample_setting == Methods.SMOTE.value.lower():
-            self.x_train, self.y_train = smote_oversampler(self.x_train, self.y_train, float(self.over_sample_ratio))
+            self.x_train, self.y_train = self.smote_oversampler(self.x_train, self.y_train, float(self.over_sample_ratio))
 
     def train_model(self):
         """
         Method for training single random forest model.
 
         Returns
         ----------
@@ -205,79 +173,79 @@
                                                  n_jobs=-1, criterion=criterion,
                                                  min_samples_leaf=min_sample_leaf,
                                                  bootstrap=True,
                                                  verbose=1,
                                                  class_weight=class_weights)
 
             print(f'Fitting {self.clf_name} model...')
-            self.rf_clf = clf_fit(clf=self.rf_clf, x_df=self.x_train, y_df=self.y_train)
+            self.rf_clf = self.clf_fit(clf=self.rf_clf, x_df=self.x_train, y_df=self.y_train)
 
             if compute_permutation_importance in Options.PERFORM_FLAGS.value:
-                calc_permutation_importance(self.x_test, self.y_test, self.rf_clf, self.feature_names, self.clf_name, self.eval_out_path)
+                self.calc_permutation_importance(self.x_test, self.y_test, self.rf_clf, self.feature_names, self.clf_name, self.eval_out_path)
             if generate_learning_curve in Options.PERFORM_FLAGS.value:
-                calc_learning_curve(x_y_df=self.x_y_df,
-                                    clf_name=self.clf_name,
-                                    shuffle_splits=shuffle_splits,
-                                    dataset_splits=dataset_splits,
-                                    tt_size=self.tt_size,
-                                    rf_clf=self.rf_clf,
-                                    save_dir=self.eval_out_path)
+                self.calc_learning_curve(x_y_df=self.x_y_df,
+                                         clf_name=self.clf_name,
+                                         shuffle_splits=shuffle_splits,
+                                         dataset_splits=dataset_splits,
+                                         tt_size=self.tt_size,
+                                         rf_clf=self.rf_clf,
+                                         save_dir=self.eval_out_path)
 
 
 
             if generate_precision_recall_curve in Options.PERFORM_FLAGS.value:
-                calc_pr_curve(self.rf_clf, self.x_test, self.y_test, self.clf_name, self.eval_out_path)
+                self.calc_pr_curve(self.rf_clf, self.x_test, self.y_test, self.clf_name, self.eval_out_path)
             if generate_example_decision_tree in Options.PERFORM_FLAGS.value:
-                create_example_dt(self.rf_clf, self.clf_name, self.feature_names, self.class_names, self.eval_out_path)
+                self.create_example_dt(self.rf_clf, self.clf_name, self.feature_names, self.class_names, self.eval_out_path)
             if generate_classification_report in Options.PERFORM_FLAGS.value:
-                create_clf_report(self.rf_clf, self.x_test, self.y_test, self.class_names, self.eval_out_path)
+                self.create_clf_report(self.rf_clf, self.x_test, self.y_test, self.class_names, self.eval_out_path)
             if generate_features_importance_log in Options.PERFORM_FLAGS.value:
-                create_x_importance_log(self.rf_clf, self.feature_names, self.clf_name, self.eval_out_path)
+                self.create_x_importance_log(self.rf_clf, self.feature_names, self.clf_name, self.eval_out_path)
             if generate_features_importance_bar_graph in Options.PERFORM_FLAGS.value:
-                create_x_importance_bar_chart(self.rf_clf, self.feature_names, self.clf_name, self.eval_out_path, feature_importance_bars)
+                self.create_x_importance_bar_chart(self.rf_clf, self.feature_names, self.clf_name, self.eval_out_path, feature_importance_bars)
             if generate_example_decision_tree_fancy in Options.PERFORM_FLAGS.value:
-                dviz_classification_visualization(self.x_train, self.y_train, self.clf_name, self.class_names, self.eval_out_path)
+                self.dviz_classification_visualization(self.x_train, self.y_train, self.clf_name, self.class_names, self.eval_out_path)
             if generate_shap_scores in Options.PERFORM_FLAGS.value:
-                create_shap_log(ini_file_path=self.ini_path,
+                self.create_shap_log(ini_file_path=self.config_path,
                                 rf_clf=self.rf_clf,
                                 x_df=self.x_train,
                                 y_df=self.y_train,
                                 x_names=self.feature_names,
                                 clf_name=self.clf_name,
                                 cnt_present=shap_target_present_cnt,
                                 cnt_absent=shap_target_absent_cnt,
                                 save_it=shap_save_n,
                                 save_path=self.eval_out_path)
 
             if compute_partial_dependency in Options.PERFORM_FLAGS.value:
-                partial_dependence_calculator(clf=self.rf_clf, x_df=self.x_train, clf_name=self.clf_name, save_dir=self.eval_out_path)
+                self.partial_dependence_calculator(clf=self.rf_clf, x_df=self.x_train, clf_name=self.clf_name, save_dir=self.eval_out_path)
 
             if save_meta_data in Options.PERFORM_FLAGS.value:
                 meta_data_lst = [self.clf_name, criterion, max_features, min_sample_leaf,
                                  n_estimators, compute_permutation_importance, generate_classification_report,
                                  generate_example_decision_tree, generate_features_importance_bar_graph,
                                  generate_features_importance_log, generate_precision_recall_curve, save_meta_data,
                                  generate_learning_curve, dataset_splits, shuffle_splits, feature_importance_bars,
                                  self.over_sample_ratio, self.over_sample_setting, self.tt_size, self.split_type,
                                  self.under_sample_ratio, self.under_sample_setting, str(class_weights)]
 
-                create_meta_data_csv_training_one_model(meta_data_lst, self.clf_name, self.eval_out_path)
+                self.create_meta_data_csv_training_one_model(meta_data_lst, self.clf_name, self.eval_out_path)
 
     def save_model(self):
         """
         Method for saving pickled RF model. The model is saved in the `models/generated_models` directory
         of the SimBA project tree.
 
         Returns
         ----------
         None
         """
 
         self.timer.stop_timer()
-        save_rf_model(self.rf_clf, self.clf_name, self.model_dir_out)
+        self.save_rf_model(self.rf_clf, self.clf_name, self.model_dir_out)
         stdout_success(msg=f'Classifier {self.clf_name} saved in models/generated_models directory', elapsed_time=self.timer.elapsed_time_str)
         stdout_success(msg=f'Evaluation files are in models/generated_models/model_evaluations folders')
 
 # test = TrainSingleModel(config_path='/Users/simon/Desktop/envs/troubleshooting/locomotion/project_folder/project_config.ini')
 # test.perform_sampling()
 # test.train_model()
 # test.save_model()
@@ -287,8 +255,13 @@
 # test.perform_sampling()
 # test.train_model()
 # test.save_model()
 
 # test = TrainSingleModel(config_path='/Users/simon/Desktop/envs/troubleshooting/naresh/project_folder/project_config.ini')
 # test.perform_sampling()
 # test.train_model()
+# test.save_model()
+
+# test = TrainSingleModel(config_path='/Users/simon/Desktop/envs/troubleshooting/Lucas/project_folder/project_config.ini')
+# test.perform_sampling()
+# test.train_model()
 # test.save_model()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/create_clf_log.py` & `Simba-UW-tf-dev-1.57.6/simba/create_clf_log.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,19 +1,16 @@
 __author__ = "Simon Nilsson", "JJ Choong"
 
 import pandas as pd
-from simba.read_config_unit_tests import (check_file_exist_and_readable,
-                                          check_if_filepath_list_is_empty)
-from simba.feature_extractors.unit_tests import read_video_info
 import os
+from simba.utils.checks import check_file_exist_and_readable, check_if_filepath_list_is_empty
 from simba.mixins.config_reader import ConfigReader
-from simba.drop_bp_cords import get_fn_ext
-from simba.misc_tools import detect_bouts
+from simba.utils.data import detect_bouts
 from simba.utils.printing import stdout_success
-from simba.rw_dfs import read_df
+from simba.utils.read_write import get_fn_ext, read_df
 
 class ClfLogCreator(ConfigReader):
     """
     Class for creating aggregate statistics from classification data.
 
     Parameters
     ----------
@@ -60,15 +57,15 @@
             results_df
         """
 
         self.results_df = pd.DataFrame()
         for file_cnt, file_path in enumerate(self.machine_results_paths):
             _, file_name, _ = get_fn_ext(file_path)
             print('Analyzing video {}...'.format(file_name))
-            _, _, fps = read_video_info(self.video_info_df, file_name)
+            _, _, fps = self.read_video_info(video_name=file_name)
             check_file_exist_and_readable(file_path)
             data_df = read_df(file_path, self.file_type)
             bouts_df = detect_bouts(data_df=data_df, target_lst=self.clf_names, fps=fps)
             bouts_df['Shifted start'] = bouts_df['Start_time'].shift(-1)
             bouts_df['Interval duration'] = bouts_df['Shifted start'] - bouts_df['End Time']
             for clf in self.clf_names:
                 clf_results_dict = {}
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/batch_process_videos/.DS_Store` & `Simba-UW-tf-dev-1.57.6/simba/batch_process_videos/.DS_Store`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/simba/batch_process_videos/batch_process_menus.py` & `Simba-UW-tf-dev-1.57.6/simba/batch_process_videos/batch_process_menus.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,21 +1,22 @@
 from tkinter import *
-import glob, os
-from simba.misc_tools import get_fn_ext, get_video_meta_data
-from simba.tkinter_functions import hxtScrollbar, CreateLabelFrameWithIcon
-import re
+import glob, os, re
 import datetime
 import cv2
-from simba.read_config_unit_tests import check_file_exist_and_readable
 import json
 from simba.batch_process_videos.batch_process_create_ffmpeg_commands import FFMPEGCommandCreator
-from simba.utils.errors import NoFilesFoundError
 from simba.enums import Options, Keys, Links
+from simba.mixins.pop_up_mixin import PopUpMixin
+from simba.utils.printing import stdout_success, SimbaTimer
+from simba.utils.errors import InvalidInputError, IntegerError, NoFilesFoundError
+from simba.utils.checks import check_file_exist_and_readable
+from simba.utils.read_write import get_fn_ext, get_video_meta_data
+from simba.tkinter_functions import CreateLabelFrameWithIcon
 
-class BatchProcessFrame(object):
+class BatchProcessFrame(PopUpMixin):
     """
     Class for creating interactive windows that collect user-inputs for batch processing videos (e.g., cropping,
     clipping etc.). User-selected output is stored in json file format within the user-defined `output_dir`
 
     Parameters
     ----------
     input_dir: str
@@ -30,24 +31,24 @@
     Examples
     ----------
     >>> batch_preprocessor = BatchProcessFrame(input_dir=r'MyInputVideosDir', output_dir=r'MyOutputVideosDir')
     >>> batch_preprocessor.create_main_window()
     >>> batch_preprocessor.create_video_table_headings()
     >>> batch_preprocessor.create_video_rows()
     >>> batch_preprocessor.create_execute_btn()
-    >>> batch_preprocessor.batch_process_main_frame.mainloop()
+    >>> batch_preprocessor.main_frm.mainloop()
 
     """
 
     def __init__(self,
                  input_dir: str,
                  output_dir: str):
 
-        self.input_dir = input_dir
-        self.output_dir = output_dir
+        PopUpMixin.__init__(self, title='BATCH PRE-PROCESS VIDEOS IN SIMBA', size=(1600, 600))
+        self.input_dir, self.output_dir = input_dir, output_dir
         if not os.path.exists(self.output_dir):
             os.makedirs(self.output_dir)
         self.videos_in_dir_dict, self.crop_dict = {}, {}
         self.get_input_files()
         if len(list(self.videos_in_dir_dict.keys())) == 0:
             raise NoFilesFoundError(msg=f'The input directory {self.input_dir} contains ZERO video files in either .avi, .mp4, .mov, .flv, or m4v format')
         self.max_char_vid_name = len(max(list(self.videos_in_dir_dict.keys()), key=len))
@@ -60,22 +61,15 @@
                 self.videos_in_dir_dict[video_name] = get_video_meta_data(file_path)
                 self.videos_in_dir_dict[video_name]['extension'] = ext
                 self.videos_in_dir_dict[video_name]['video_length'] = str(datetime.timedelta(seconds=int(self.videos_in_dir_dict[video_name]['frame_count'] / self.videos_in_dir_dict[video_name]['fps'])))
                 self.videos_in_dir_dict[video_name]['video_length'] = '0' + self.videos_in_dir_dict[video_name]['video_length']
                 self.videos_in_dir_dict[video_name]['file_path'] = file_path
 
     def create_main_window(self):
-        self.batch_process_main_frame = Toplevel()
-        self.batch_process_main_frame.minsize(1600, 600)
-        self.batch_process_main_frame.wm_title("BATCH PRE-PROCESS VIDEOS IN SIMBA")
-        self.batch_process_main_frame.lift()
-        self.batch_process_main_frame = Canvas(hxtScrollbar(self.batch_process_main_frame))
-        self.batch_process_main_frame.pack(fill="both", expand=True)
-
-        self.quick_settings_frm = CreateLabelFrameWithIcon(parent=self.batch_process_main_frame, header='QUICK SETTINGS', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.BATCH_PREPROCESS.value)
+        self.quick_settings_frm = CreateLabelFrameWithIcon(parent=self.main_frm, header='QUICK SETTINGS', icon_name=Keys.DOCUMENTATION.value, icon_link=Links.BATCH_PREPROCESS.value)
         self.clip_video_settings_frm = LabelFrame(self.quick_settings_frm, text='Clip Videos Settings', padx=5)
         self.quick_clip_start_entry_lbl = Label(self.clip_video_settings_frm, text="Start Time: ")
         self.quick_clip_start_entry_box_val = StringVar()
         self.quick_clip_start_entry_box_val.set('00:00:00')
         self.quick_clip_start_entry_box = Entry(self.clip_video_settings_frm, width=15, textvariable=self.quick_clip_start_entry_box_val)
         self.quick_clip_end_entry_lbl = Label(self.clip_video_settings_frm, text="End Time: ")
         self.quick_clip_end_entry_box_val = StringVar()
@@ -138,15 +132,15 @@
 
     def apply_fps_to_all(self):
         for video_name in self.videos.keys():
             self.videos[video_name]['fps_var'].set(self.quick_set_fps_val.get())
 
     def create_video_table_headings(self):
         self.headings = {}
-        self.videos_frm = LabelFrame(self.batch_process_main_frame, text='VIDEOS', font=('Helvetica', 15, 'bold'), pady=5, padx=15)
+        self.videos_frm = LabelFrame(self.main_frm, text='VIDEOS', font=('Helvetica', 15, 'bold'), pady=5, padx=15)
         self.headings['video_name_col_head'] = Label(self.videos_frm, text='Video Name', width=self.max_char_vid_name + 5)
         self.headings['crop_video_col_head'] = Label(self.videos_frm, text='Crop Video', width=8)
         self.headings['start_time_col_head'] = Label(self.videos_frm, text='Start Time', width=8)
         self.headings['end_time_col_head'] = Label(self.videos_frm, text='End Time', width=8)
         self.headings['clip_cb_var'] = BooleanVar()
         self.headings['shorten_all_videos_cbox'] = Checkbutton(self.videos_frm, text='Clip All Videos',variable=self.headings['clip_cb_var'], command=lambda: self.inverse_all_cb_ticks(variable_name='clip_cb_var'))
         self.headings['video_width_col_head'] = Label(self.videos_frm, text='Video Width', width=8)
@@ -224,15 +218,15 @@
             self.videos[name]['fps_entry'].grid(row=row, column=9, padx=5)
             self.videos[name]['fps_cb'].grid(row=row, column=10, sticky=W, padx=5)
             self.videos[name]['grayscale_cbox'].grid(row=row, column=11, sticky=W, padx=5)
             self.videos[name]['frame_cnt_cbox'].grid(row=row, column=12, sticky=W, padx=5)
             self.videos[name]['apply_clahe_cbox'].grid(row=row, column=13, sticky=W, padx=5)
 
     def create_execute_btn(self):
-        self.execute_frm = LabelFrame(self.batch_process_main_frame, text='EXECUTE', font=('Helvetica', 15, 'bold'), pady=5, padx=15)
+        self.execute_frm = LabelFrame(self.main_frm, text='EXECUTE', font=('Helvetica', 15, 'bold'), pady=5, padx=15)
         self.reset_all_btn = Button(self.execute_frm , text='RESET ALL', fg='red', command=lambda: self.create_video_rows())
         self.reset_crop_btn = Button(self.execute_frm, text='RESET CROP', fg='orange', command=lambda: self.reset_crop())
         self.execute_btn = Button(self.execute_frm, text='EXECUTE', fg='blue', command= lambda: self.execute())
 
         self.execute_frm.grid(row=2, column=0, sticky=W, padx=5, pady=30)
         self.reset_all_btn.grid(row=0, column=0, sticky=W, padx=5)
         self.reset_crop_btn.grid(row=0, column=1, sticky=W, padx=5)
@@ -317,54 +311,52 @@
 
         self.save_path = os.path.join(self.output_dir, 'batch_process_log.json')
         with open(self.save_path, 'w') as fp:
             json.dump(out_video_dict, fp)
         self.perform_unit_tests(out_video_dict['video_data'])
 
     def perform_unit_tests(self, out_video_dict):
+        timer = SimbaTimer(start=True)
         for video_name, video_data in out_video_dict.items():
             if video_data['crop']:
                 if not isinstance(video_data['crop_settings']['width'], int):
-                    print('SIMBA ERROR: Crop width for video {} is not an integer'.format(video_name))
-                    raise ValueError
+                    raise IntegerError(msg=f'Crop width for video {video_name} is not an integer')
                 if not isinstance(video_data['crop_settings']['height'], int):
-                    print('SIMBA ERROR: Crop height for video {} is not an integer'.format(video_name))
-                    raise ValueError
+                    raise IntegerError(msg=f'Crop height for video {video_name} is not an integer')
             if video_data['clip']:
                 r = re.compile('.{2}:.{2}:.{2}')
                 for variable in ['start', 'stop']:
                     if len(video_data['clip_settings'][variable]) != 8:
-                        print('SIMBA ERROR: Clip {} time for video {} is should be in the format XX:XX:XX where X is an integer between 0-9'.format(variable, video_name))
+                        raise InvalidInputError(msg=f'Clip {variable} time for video {video_name} is should be in the format XX:XX:XX where X is an integer between 0-9')
                     elif not r.match(video_data['clip_settings'][variable]):
-                        print('SIMBA ERROR: Clip {} time for video {} is should be in the format XX:XX:XX where X is an integer between 0-9'.format(variable, video_name))
+                        raise InvalidInputError(msg=f'Clip {variable} time for video {video_name} is should be in the format XX:XX:XX where X is an integer between 0-9')
                     elif re.search('[a-zA-Z]', video_data['clip_settings'][variable]):
-                        print('SIMBA ERROR: Clip {} time for video {} is should be in the format XX:XX:XX where X is an integer between 0-9'.format(variable, video_name))
+                        raise InvalidInputError(msg=f'Clip {variable} time for video {video_name} is should be in the format XX:XX:XX where X is an integer between 0-9')
             if video_data['downsample']:
                 if not isinstance(video_data['downsample_settings']['width'], int):
-                    print('SIMBA ERROR: Downsample width for video {} is not an integer'.format(video_name))
+                    raise IntegerError(msg=f'Downsample width for video {video_name} is not an integer')
                 if not isinstance(video_data['downsample_settings']['height'], int):
-                    print('SIMBA ERROR: Downsample height for video {} is not an integer'.format(video_name))
+                    raise IntegerError(msg=f'Downsample height for video {video_name} is not an integer')
             if video_data['fps']:
                 if not isinstance(video_data['fps_settings']['fps'], int):
-                    print('SIMBA ERROR: FPS settings for video {} is not an integer'.format(video_name))
-
-
+                    raise IntegerError(msg=f'FPS settings for video {video_name} is not an integer')
 
         ffmpeg_runner = FFMPEGCommandCreator(json_path=self.save_path)
         ffmpeg_runner.crop_videos()
         ffmpeg_runner.clip_videos()
         ffmpeg_runner.downsample_videos()
         ffmpeg_runner.apply_fps()
         ffmpeg_runner.apply_grayscale()
         ffmpeg_runner.apply_frame_count()
         ffmpeg_runner.apply_clahe()
         ffmpeg_runner.move_all_processed_files_to_output_folder()
-        print('SIMBA batch pre-process JSON saved at {}'.format(self.save_path))
-        print('SIMBA COMPLETE: Video batch pre-processing complete, new videos stored in {}'.format(self.output_dir))
+        timer.stop_timer()
+        stdout_success(msg=f'SimBA batch pre-process JSON saved at {self.save_path}')
+        stdout_success(msg=f'Video batch pre-processing complete, new videos stored in {self.output_dir}', elapsed_time=timer.elapsed_time_str)
 
 # test = BatchProcessFrame(input_dir=r'/Users/simon/Desktop/envs/troubleshooting/DLC_2_Black_animals/project_folder/videos',
 #                          output_dir=r'/Users/simon/Desktop/envs/troubleshooting/DLC_2_Black_animals/project_folder/video_edited')
 # test.create_main_window()
 # test.create_video_table_headings()
 # test.create_video_rows()
 # test.create_execute_btn()
-# test.batch_process_main_frame.mainloop()
+# test.main_frm.mainloop()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/batch_process_videos/batch_process_create_ffmpeg_commands.py` & `Simba-UW-tf-dev-1.57.6/simba/batch_process_videos/batch_process_create_ffmpeg_commands.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,31 +1,35 @@
 import os, glob
 import json
 import shutil
 import subprocess
 import cv2
-from simba.misc_tools import get_video_meta_data
-from simba.read_config_unit_tests import check_file_exist_and_readable
-import datetime
 import simba
 import pathlib
+import datetime
+from simba.utils.read_write import get_video_meta_data
+from simba.utils.checks import check_file_exist_and_readable
+
 
 class FFMPEGCommandCreator(object):
 
     """
     Class for executing FFmpeg commands from instructions stored in json format.
 
+
+
     Parameters
     ----------
     json_path: str
-        path to json file storing FFmpeg instructions
+        path to json file storing FFmpeg instructions as created by ``simba.batch_process_vides.BatchProcessFrame``.
 
     Notes
     ----------
     `Batch pre-process tutorials <https://github.com/sgoldenlab/simba/blob/master/docs/tutorial_process_videos.md>`__.
+    `Example expected JSON file <https://github.com/sgoldenlab/simba/blob/master/misc/batch_process_log.json>`__.
 
     Examples
     ----------
     >>> ffmpeg_executor = FFMPEGCommandCreator(json_path='MyJsonFilePath')
     >>> ffmpeg_executor.crop_videos()
     >>> ffmpeg_executor.clip_videos()
     >>> ffmpeg_executor.downsample_videos()
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/Kleinberg_calculator.py` & `Simba-UW-tf-dev-1.57.6/simba/Kleinberg_calculator.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,25 +1,24 @@
 __author__ = "Simon Nilsson"
 
-from simba.read_config_unit_tests import (check_that_column_exist,
-                                          check_int,
-                                          check_float,
-                                          check_if_filepath_list_is_empty)
-import os
-from simba.rw_dfs import read_df, save_df
-from simba.drop_bp_cords import get_fn_ext
 import pandas as pd
-from simba.pybursts import kleinberg_burst_detection
+import numpy as np
+import shutil, os
+from copy import deepcopy
+from simba.utils.checks import (check_that_column_exist,
+                                check_int,
+                                check_float,
+                                check_if_filepath_list_is_empty)
+from simba.utils.read_write import write_df, read_df, get_fn_ext
 from simba.utils.printing import stdout_success
-from simba.enums import Paths
 from simba.mixins.config_reader import ConfigReader
 from simba.utils.warnings import KleinbergWarning
-import numpy as np
-import shutil
-from copy import deepcopy
+from simba.pybursts import kleinberg_burst_detection
+from simba.enums import Paths
+
 
 class KleinbergCalculator(ConfigReader):
     '''
     Class for smoothing classification results using the Kleinberg burst
     detection algorithm.
 
     Parameters
@@ -141,15 +140,15 @@
                         self.hierarchical_searcher()
                     else:
                         self.clf_bouts_in_hierarchy = self.kleinberg_bouts[self.kleinberg_bouts['Hierarchy'] == self.hierarchy]
                     hierarchy_idx = list(self.clf_bouts_in_hierarchy.apply(lambda x: list(range(x['Start'], x['Stop'] + 1)), 1))
                     hierarchy_idx = [x for xs in hierarchy_idx for x in xs]
                     hierarchy_idx = [x for x in hierarchy_idx if x in list(data_df.index)]
                     video_out_df.loc[hierarchy_idx, clf] = 1
-            save_df(video_out_df, self.file_type, file_path)
+            write_df(video_out_df, self.file_type, file_path)
 
         self.timer.stop_timer()
         if len(detailed_df_lst) > 0:
             detailed_df = pd.concat(detailed_df_lst, axis=0)
             detailed_save_path = os.path.join(self.logs_path, 'Kleinberg_detailed_log_{}.csv'.format(str(self.datetime)))
             detailed_df.to_csv(detailed_save_path)
             stdout_success(msg='Kleinberg analysis complete. See {detailed_save_path} for details of detected bouts of all classifiers in all hierarchies', elapsed_time=self.timer.elapsed_time_str)
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/reorganize_keypoint_in_pose.py` & `Simba-UW-tf-dev-1.57.6/simba/reorganize_keypoint_in_pose.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,12 @@
 import glob, os
 import pandas as pd
 from collections import OrderedDict
 from datetime import datetime
-from simba.read_config_unit_tests import check_if_dir_exists
-from simba.misc_tools import check_if_filepath_list_is_empty
+from simba.utils.checks import check_if_filepath_list_is_empty, check_if_dir_exists
 from simba.utils.printing import stdout_success
 from simba.enums import Formats
 
 
 class KeypointReorganizer(object):
     """
     Class for re-organizing the order of pose-estimated keypoints in directory containing
```

### Comparing `Simba-UW-tf-dev-1.57.5/simba/play_annotation_video.py` & `Simba-UW-tf-dev-1.57.6/simba/play_annotation_video.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 __author__ = "Simon Nilsson", "JJ Choong"
 
 import cv2
 import sys
 import os
 import signal
-from simba.read_config_unit_tests import check_file_exist_and_readable
-from simba.misc_tools import get_video_meta_data
-from simba.misc_tools import get_color_dict
+from simba.utils.read_write import get_video_meta_data
+from simba.utils.lookups import get_color_dict
+from simba.utils.checks import check_file_exist_and_readable
 
 def annotation_video_player():
 
     def labelling_log_writer(frame_number: int) -> None:
         f.seek(0)
         f.write(str(frame_number))
         f.truncate()
```

### Comparing `Simba-UW-tf-dev-1.57.5/Simba_UW_tf_dev.egg-info/PKG-INFO` & `Simba-UW-tf-dev-1.57.6/Simba_UW_tf_dev.egg-info/PKG-INFO`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: Simba-UW-tf-dev
-Version: 1.57.5
+Version: 1.57.6
 Summary: Toolkit for computer classification of complex social behaviors in experimental animals
 Home-page: https://github.com/sgoldenlab/simba
 Author: Simon Nilsson, Jia Jie Choong, Sophia Hwang
 Author-email: sronilsson@gmail.com
 License: GNU Lesser General Public License v3 (LGPLv3)
 Platform: UNKNOWN
 Classifier: Programming Language :: Python :: 3
```

### Comparing `Simba-UW-tf-dev-1.57.5/Simba_UW_tf_dev.egg-info/SOURCES.txt` & `Simba-UW-tf-dev-1.57.6/Simba_UW_tf_dev.egg-info/SOURCES.txt`

 * *Files 7% similar despite different names*

```diff
@@ -13,55 +13,47 @@
 simba/FSTTC_calculator.py
 simba/Kleinberg_calculator.py
 simba/SimBA.py
 simba/SimBA_dash_app.py
 simba/Validate_model_one_video_run_clf.py
 simba/__init__.py
 simba/calculate_px_dist.py
-simba/concatenator_pop_up.py
 simba/create_clf_log.py
 simba/create_project_pop_up.py
 simba/dash_app.py
-simba/drop_bp_cords.py
 simba/enums.py
 simba/extract_annotation_frames.py
 simba/extract_frames_fast.py
 simba/extract_seqframes.py
 simba/get_coordinates_tools_v2.py
 simba/interpolate_pose.py
-simba/interpolate_smooth_post_hoc.py
+simba/interpolate_smooth.py
 simba/labelling_advanced_interface.py
 simba/labelling_interface.py
 simba/machine_model_settings_pop_up.py
-simba/misc_tools.py
 simba/movement_processor.py
 simba/multi_cropper.py
 simba/play_annotation_video.py
-simba/plotly_create_h5.py
 simba/pop_up_classes.py
 simba/pose_reset.py
 simba/project_config_creator.py
 simba/pup_retrieval_protocol.py
 simba/pybursts.py
 simba/read_config_unit_tests.py
 simba/remove_keypoints_in_pose.py
 simba/reorganize_keypoint_in_pose.py
 simba/requirements.txt
 simba/reverse_2_animal_tracking.py
-simba/reverse_tracking_order.py
 simba/run_dash_tkinter.py
 simba/run_inference.py
-simba/rw_dfs.py
-simba/set_hyperparameters.py
 simba/setting_menu.py
 simba/severity_processor.py
 simba/timebins_clf_analyzer.py
 simba/timebins_movement_analyzer.py
 simba/tkinter_functions.py
-simba/train_model_functions.py
 simba/train_mutiple_models.py
 simba/train_single_model.py
 simba/user_pose_config_creator.py
 simba/video_info_table.py
 simba/video_processing.py
 simba/~$features.pptx
 simba/assets/.DS_Store
@@ -164,37 +156,36 @@
 simba/batch_process_videos/batch_process_create_ffmpeg_commands.py
 simba/batch_process_videos/batch_process_menus.py
 simba/blob_storage/.DS_Store
 simba/bounding_box_tools/.DS_Store
 simba/bounding_box_tools/agg_boundary_stats.py
 simba/bounding_box_tools/boundary_menus.py
 simba/bounding_box_tools/boundary_statistics.py
-simba/bounding_box_tools/find_bounderies.py
+simba/bounding_box_tools/find_boundaries.py
 simba/bounding_box_tools/visualize_boundaries.py
 simba/cue_light_tools/.DS_Store
 simba/cue_light_tools/__init__.py
 simba/cue_light_tools/cue_light_analyzer.py
 simba/cue_light_tools/cue_light_clf_statistics.py
 simba/cue_light_tools/cue_light_menues.py
 simba/cue_light_tools/cue_light_movement_statistics.py
 simba/cue_light_tools/cue_light_tools.py
 simba/cue_light_tools/cue_light_visualizer.py
 simba/feature_extractors/.DS_Store
 simba/feature_extractors/__init__.py
-simba/feature_extractors/extract_features_9bp.py
 simba/feature_extractors/feature_extractor_14bp.py
 simba/feature_extractors/feature_extractor_16bp.py
 simba/feature_extractors/feature_extractor_4bp.py
 simba/feature_extractors/feature_extractor_7bp.py
 simba/feature_extractors/feature_extractor_8bp.py
 simba/feature_extractors/feature_extractor_8bps_2_animals.py
+simba/feature_extractors/feature_extractor_9bp.py
 simba/feature_extractors/feature_extractor_user_defined.py
 simba/feature_extractors/feature_subsets.py
 simba/feature_extractors/perimeter_jit.py
-simba/feature_extractors/unit_tests.py
 simba/feature_extractors/.idea/.gitignore
 simba/feature_extractors/.idea/.name
 simba/feature_extractors/.idea/encodings.xml
 simba/feature_extractors/.idea/features_scripts.iml
 simba/feature_extractors/.idea/misc.xml
 simba/feature_extractors/.idea/modules.xml
 simba/feature_extractors/.idea/workspace.xml
@@ -229,28 +220,37 @@
 simba/feature_extractors/misc/time_stamp_calculator.py
 simba/feature_extractors/misc/video_color.py
 simba/feature_extractors/misc/video_rotator.py
 simba/feature_extractors/misc/video_rotator_mp.py
 simba/mixins/.DS_Store
 simba/mixins/config_reader.py
 simba/mixins/feature_extraction_mixin.py
+simba/mixins/plotting_mixin.py
 simba/mixins/pop_up_mixin.py
+simba/mixins/train_model_mixin.py
 simba/mixins/unsupervised_mixin.py
+simba/mixins/__pycache__/feature_extraction_mixin.FeatureExtractionMixin.cdist-181.py36m.1.nbc
+simba/mixins/__pycache__/feature_extraction_mixin.FeatureExtractionMixin.cdist-181.py36m.nbi
+simba/mixins/__pycache__/feature_extraction_mixin.FeatureExtractionMixin.cdist-182.py36m.1.nbc
+simba/mixins/__pycache__/feature_extraction_mixin.FeatureExtractionMixin.cdist-182.py36m.nbi
+simba/mixins/__pycache__/feature_extraction_mixin.FeatureExtractionMixin.cdist-183.py36m.1.nbc
+simba/mixins/__pycache__/feature_extraction_mixin.FeatureExtractionMixin.cdist-183.py36m.nbi
 simba/outlier_tools/.DS_Store
 simba/outlier_tools/__init__.py
 simba/outlier_tools/outlier_corrector_location.py
 simba/outlier_tools/outlier_corrector_movement.py
 simba/outlier_tools/skip_outlier_correction.py
 simba/outlier_tools/.idea/encodings.xml
 simba/outlier_tools/.idea/misc.xml
 simba/outlier_tools/.idea/modules.xml
 simba/outlier_tools/.idea/outlier_scripts.iml
 simba/outlier_tools/.idea/workspace.xml
 simba/outlier_tools/.idea/inspectionProfiles/Project_Default.xml
 simba/outlier_tools/.idea/libraries/R_User_Library.xml
+simba/plotting/.DS_Store
 simba/plotting/Directing_animals_visualizer.py
 simba/plotting/Directing_animals_visualizer_mp.py
 simba/plotting/ROI_feature_visualizer.py
 simba/plotting/ROI_feature_visualizer_mp.py
 simba/plotting/ROI_plotter.py
 simba/plotting/ROI_plotter_mp.py
 simba/plotting/clf_validator.py
@@ -262,15 +262,14 @@
 simba/plotting/gantt_creator.py
 simba/plotting/gantt_creator_mp.py
 simba/plotting/heat_mapper_clf.py
 simba/plotting/heat_mapper_clf_mp.py
 simba/plotting/heat_mapper_location.py
 simba/plotting/heat_mapper_location_mp.py
 simba/plotting/interactive_probability_grapher.py
-simba/plotting/misc_visualizations.py
 simba/plotting/path_plotter.py
 simba/plotting/path_plotter_mp.py
 simba/plotting/plot_clf_results.py
 simba/plotting/plot_clf_results_mp.py
 simba/plotting/plot_pose_in_dir.py
 simba/plotting/probability_plot_creator.py
 simba/plotting/probability_plot_creator_mp.py
@@ -294,18 +293,18 @@
 simba/pose_configurations/schematics/3.png
 simba/pose_configurations/schematics/4.png
 simba/pose_configurations/schematics/5.png
 simba/pose_configurations/schematics/6.png
 simba/pose_configurations/schematics/7.png
 simba/pose_configurations/schematics/8.png
 simba/pose_configurations/schematics/9.png
+simba/pose_importers/.DS_Store
 simba/pose_importers/dlc_importer_csv.py
 simba/pose_importers/dlc_multi_animal_importer.py
 simba/pose_importers/import_mars.py
-simba/pose_importers/import_trk.py
 simba/pose_importers/read_DANNCE_mat.py
 simba/pose_importers/sleap_importer_csv.py
 simba/pose_importers/sleap_importer_h5.py
 simba/pose_importers/sleap_importer_slp.py
 simba/pose_importers/trk_importer.py
 simba/roi_tools/.DS_Store
 simba/roi_tools/ROI_analyzer.py
@@ -343,13 +342,15 @@
 simba/unsupervised/enums.py
 simba/unsupervised/grid_search_visualizers.py
 simba/unsupervised/hdbscan_clusterer.py
 simba/unsupervised/pop_up_classes.py
 simba/unsupervised/tsne.py
 simba/unsupervised/ui.py
 simba/unsupervised/umap_embedder.py
-simba/unsupervised/unsupervised_ui.py
 simba/utils/.DS_Store
+simba/utils/checks.py
+simba/utils/data.py
 simba/utils/errors.py
 simba/utils/lookups.py
 simba/utils/printing.py
+simba/utils/read_write.py
 simba/utils/warnings.py
```

### Comparing `Simba-UW-tf-dev-1.57.5/Simba_UW_tf_dev.egg-info/requires.txt` & `Simba-UW-tf-dev-1.57.6/Simba_UW_tf_dev.egg-info/requires.txt`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/LICENSE.md` & `Simba-UW-tf-dev-1.57.6/LICENSE.md`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/README.md` & `Simba-UW-tf-dev-1.57.6/README.md`

 * *Files identical despite different names*

### Comparing `Simba-UW-tf-dev-1.57.5/setup.py` & `Simba-UW-tf-dev-1.57.6/setup.py`

 * *Files 8% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 Licensed under GNU Lesser General Public License v3.0
 """
 
 import setuptools
 
 setuptools.setup(
     name="Simba-UW-tf-dev",
-    version="1.57.5",
+    version="1.57.6",
     author="Simon Nilsson, Jia Jie Choong, Sophia Hwang",
     author_email="sronilsson@gmail.com",
     description="Toolkit for computer classification of complex social behaviors in experimental animals",
     url="https://github.com/sgoldenlab/simba",
     install_requires=['Pillow == 5.4.1', 'pyyaml == 5.3.1','shapely == 1.7','wxpython == 4.0.4',
               'dtreeviz == 0.8.1','eli5 == 0.10.1','graphviz == 0.11',
               'imblearn == 0.0','imgaug == 0.4.0','imutils == 0.5.2','matplotlib == 3.0.3', 'numpy == 1.18.1',
```

