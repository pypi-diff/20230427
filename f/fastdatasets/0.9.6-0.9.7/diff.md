# Comparing `tmp/fastdatasets-0.9.6-py3-none-any.whl.zip` & `tmp/fastdatasets-0.9.7-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,38 +1,38 @@
-Zip file size: 43613 bytes, number of entries: 36
--rw-rw-rw-  2.0 fat    11172 b- defN 23-Feb-13 01:09 fastdatasets/README.md
--rw-rw-rw-  2.0 fat      116 b- defN 22-Oct-31 01:52 fastdatasets/__init__.py
--rw-rw-rw-  2.0 fat       76 b- defN 22-Oct-31 01:52 fastdatasets/common/__init__.py
--rw-rw-rw-  2.0 fat    14096 b- defN 23-Feb-13 00:59 fastdatasets/common/iterable_dataset.py
--rw-rw-rw-  2.0 fat    10767 b- defN 23-Feb-13 00:44 fastdatasets/common/random_dataset.py
--rw-rw-rw-  2.0 fat     4262 b- defN 22-Dec-28 05:38 fastdatasets/common/writer.py
--rw-rw-rw-  2.0 fat      209 b- defN 22-Oct-31 02:58 fastdatasets/leveldb/__init__.py
--rw-rw-rw-  2.0 fat     6031 b- defN 22-Nov-07 03:31 fastdatasets/leveldb/dataset.py
--rw-rw-rw-  2.0 fat     4408 b- defN 22-Dec-06 06:47 fastdatasets/leveldb/writer.py
--rw-rw-rw-  2.0 fat     7148 b- defN 22-Dec-13 07:01 fastdatasets/leveldb/iterable_dataset/__init__.py
--rw-rw-rw-  2.0 fat     4716 b- defN 22-Dec-13 06:57 fastdatasets/leveldb/random_dataset/__init__.py
--rw-rw-rw-  2.0 fat      209 b- defN 22-Oct-31 02:58 fastdatasets/lmdb/__init__.py
--rw-rw-rw-  2.0 fat     6763 b- defN 22-Nov-07 03:32 fastdatasets/lmdb/dataset.py
--rw-rw-rw-  2.0 fat     4613 b- defN 22-Dec-13 08:17 fastdatasets/lmdb/writer.py
--rw-rw-rw-  2.0 fat     7164 b- defN 22-Dec-13 07:01 fastdatasets/lmdb/iterable_dataset/__init__.py
--rw-rw-rw-  2.0 fat     5043 b- defN 22-Dec-13 09:25 fastdatasets/lmdb/random_dataset/__init__.py
--rw-rw-rw-  2.0 fat      209 b- defN 22-Nov-11 00:59 fastdatasets/memory/__init__.py
--rw-rw-rw-  2.0 fat     4704 b- defN 22-Dec-06 06:47 fastdatasets/memory/dataset.py
--rw-rw-rw-  2.0 fat     3652 b- defN 22-Dec-06 06:47 fastdatasets/memory/writer.py
--rw-rw-rw-  2.0 fat     6474 b- defN 22-Nov-11 00:32 fastdatasets/memory/iterable_dataset/__init__.py
--rw-rw-rw-  2.0 fat     4304 b- defN 22-Nov-11 06:33 fastdatasets/memory/random_dataset/__init__.py
--rw-rw-rw-  2.0 fat      209 b- defN 22-Oct-31 02:58 fastdatasets/record/__init__.py
--rw-rw-rw-  2.0 fat     6007 b- defN 22-Nov-07 08:36 fastdatasets/record/dataset.py
--rw-rw-rw-  2.0 fat     3709 b- defN 23-Jan-12 06:08 fastdatasets/record/writer.py
--rw-rw-rw-  2.0 fat     7358 b- defN 22-Dec-13 07:01 fastdatasets/record/iterable_dataset/__init__.py
--rw-rw-rw-  2.0 fat     6788 b- defN 22-Dec-13 07:01 fastdatasets/record/random_dataset/__init__.py
--rw-rw-rw-  2.0 fat     5576 b- defN 22-Oct-31 01:52 fastdatasets/torch_dataset/__init__.py
--rw-rw-rw-  2.0 fat      980 b- defN 22-Dec-06 06:47 fastdatasets/utils/MEMORY.py
--rw-rw-rw-  2.0 fat       51 b- defN 22-Nov-11 05:36 fastdatasets/utils/__init__.py
--rw-rw-rw-  2.0 fat    12197 b- defN 23-Feb-17 06:10 fastdatasets/utils/numpyadapter.py
--rw-rw-rw-  2.0 fat     5457 b- defN 22-Dec-06 06:47 fastdatasets/utils/parallel.py
--rw-rw-rw-  2.0 fat      346 b- defN 22-Dec-06 06:47 fastdatasets/utils/py_features.py
--rw-rw-rw-  2.0 fat    12198 b- defN 23-Feb-17 06:32 fastdatasets-0.9.6.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 23-Feb-17 06:32 fastdatasets-0.9.6.dist-info/WHEEL
--rw-rw-rw-  2.0 fat       13 b- defN 23-Feb-17 06:32 fastdatasets-0.9.6.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat     3242 b- defN 23-Feb-17 06:32 fastdatasets-0.9.6.dist-info/RECORD
-36 files, 170359 bytes uncompressed, 38347 bytes compressed:  77.5%
+Zip file size: 43809 bytes, number of entries: 36
+-rw-rw-rw-  2.0 fat    11195 b- defN 23-Apr-27 10:43 fastdatasets/README.md
+-rw-rw-rw-  2.0 fat      116 b- defN 22-Oct-30 02:10 fastdatasets/__init__.py
+-rw-rw-rw-  2.0 fat       76 b- defN 22-Oct-30 01:26 fastdatasets/common/__init__.py
+-rw-rw-rw-  2.0 fat    14096 b- defN 23-Feb-14 12:15 fastdatasets/common/iterable_dataset.py
+-rw-rw-rw-  2.0 fat    10767 b- defN 23-Feb-14 12:15 fastdatasets/common/random_dataset.py
+-rw-rw-rw-  2.0 fat     4262 b- defN 22-Dec-28 11:01 fastdatasets/common/writer.py
+-rw-rw-rw-  2.0 fat      209 b- defN 22-Oct-31 10:53 fastdatasets/leveldb/__init__.py
+-rw-rw-rw-  2.0 fat     6031 b- defN 22-Nov-07 10:41 fastdatasets/leveldb/dataset.py
+-rw-rw-rw-  2.0 fat     4408 b- defN 22-Dec-01 03:29 fastdatasets/leveldb/writer.py
+-rw-rw-rw-  2.0 fat     7148 b- defN 22-Dec-13 10:59 fastdatasets/leveldb/iterable_dataset/__init__.py
+-rw-rw-rw-  2.0 fat     4716 b- defN 22-Dec-13 10:59 fastdatasets/leveldb/random_dataset/__init__.py
+-rw-rw-rw-  2.0 fat      215 b- defN 23-Apr-27 10:43 fastdatasets/lmdb/__init__.py
+-rw-rw-rw-  2.0 fat     6778 b- defN 23-Apr-27 10:43 fastdatasets/lmdb/dataset.py
+-rw-rw-rw-  2.0 fat     4613 b- defN 22-Dec-13 10:59 fastdatasets/lmdb/writer.py
+-rw-rw-rw-  2.0 fat     7765 b- defN 23-Apr-27 10:43 fastdatasets/lmdb/iterable_dataset/__init__.py
+-rw-rw-rw-  2.0 fat     5796 b- defN 23-Apr-27 10:43 fastdatasets/lmdb/random_dataset/__init__.py
+-rw-rw-rw-  2.0 fat      209 b- defN 22-Nov-11 10:41 fastdatasets/memory/__init__.py
+-rw-rw-rw-  2.0 fat     4704 b- defN 22-Nov-26 09:38 fastdatasets/memory/dataset.py
+-rw-rw-rw-  2.0 fat     3652 b- defN 22-Dec-01 03:30 fastdatasets/memory/writer.py
+-rw-rw-rw-  2.0 fat     6474 b- defN 22-Nov-10 16:11 fastdatasets/memory/iterable_dataset/__init__.py
+-rw-rw-rw-  2.0 fat     4304 b- defN 22-Nov-11 10:41 fastdatasets/memory/random_dataset/__init__.py
+-rw-rw-rw-  2.0 fat      209 b- defN 22-Oct-31 10:53 fastdatasets/record/__init__.py
+-rw-rw-rw-  2.0 fat     6007 b- defN 22-Nov-07 10:41 fastdatasets/record/dataset.py
+-rw-rw-rw-  2.0 fat     3709 b- defN 23-Jan-12 14:50 fastdatasets/record/writer.py
+-rw-rw-rw-  2.0 fat     7358 b- defN 22-Dec-13 10:59 fastdatasets/record/iterable_dataset/__init__.py
+-rw-rw-rw-  2.0 fat     6788 b- defN 22-Dec-13 10:59 fastdatasets/record/random_dataset/__init__.py
+-rw-rw-rw-  2.0 fat     5576 b- defN 22-Oct-30 02:21 fastdatasets/torch_dataset/__init__.py
+-rw-rw-rw-  2.0 fat      980 b- defN 22-Nov-26 04:28 fastdatasets/utils/MEMORY.py
+-rw-rw-rw-  2.0 fat       51 b- defN 22-Nov-11 10:41 fastdatasets/utils/__init__.py
+-rw-rw-rw-  2.0 fat    12220 b- defN 23-Apr-27 10:43 fastdatasets/utils/numpyadapter.py
+-rw-rw-rw-  2.0 fat     5457 b- defN 22-Nov-26 04:28 fastdatasets/utils/parallel.py
+-rw-rw-rw-  2.0 fat      346 b- defN 22-Nov-26 09:33 fastdatasets/utils/py_features.py
+-rw-rw-rw-  2.0 fat    12233 b- defN 23-Apr-27 12:17 fastdatasets-0.9.7.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       92 b- defN 23-Apr-27 12:17 fastdatasets-0.9.7.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat       13 b- defN 23-Apr-27 12:17 fastdatasets-0.9.7.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat     3242 b- defN 23-Apr-27 12:17 fastdatasets-0.9.7.dist-info/RECORD
+36 files, 171815 bytes uncompressed, 38543 bytes compressed:  77.6%
```

## zipnote {}

```diff
@@ -90,20 +90,20 @@
 
 Filename: fastdatasets/utils/parallel.py
 Comment: 
 
 Filename: fastdatasets/utils/py_features.py
 Comment: 
 
-Filename: fastdatasets-0.9.6.dist-info/METADATA
+Filename: fastdatasets-0.9.7.dist-info/METADATA
 Comment: 
 
-Filename: fastdatasets-0.9.6.dist-info/WHEEL
+Filename: fastdatasets-0.9.7.dist-info/WHEEL
 Comment: 
 
-Filename: fastdatasets-0.9.6.dist-info/top_level.txt
+Filename: fastdatasets-0.9.7.dist-info/top_level.txt
 Comment: 
 
-Filename: fastdatasets-0.9.6.dist-info/RECORD
+Filename: fastdatasets-0.9.7.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## fastdatasets/README.md

```diff
@@ -350,15 +350,15 @@
     f.close()
 
 
 
 def test_random(db_path):
     options = DB.LmdbOptions(env_open_flag=DB.LmdbFlag.MDB_RDONLY,
                                env_open_mode=0o664,  # 8进制表示
-                               txn_flag=0,
+                               txn_flag=LMDB.LmdbFlag.MDB_RDONLY,
                                dbi_flag=0,
                                put_flag=0)
     dataset = load_dataset.RandomDataset(db_path,
                                         data_key_prefix_list=('input',),
                                         num_key='total_num',
                                         options = options)
```

## fastdatasets/lmdb/__init__.py

```diff
@@ -1,7 +1,9 @@
 # @Time    : 2022/10/27 18:11
 # @Author  : tk
 
 from ..common.iterable_dataset import IterableDatasetBase
 from ..common.random_dataset import RandomDatasetBase
 from .dataset import *
-from .writer import *
+from .writer import *
+
+
```

## fastdatasets/lmdb/dataset.py

```diff
@@ -18,15 +18,15 @@
             "DB",
            "load_dataset",
            "gfile",
            ]
 
 _DefaultOptions = DB.LmdbOptions(env_open_flag = DB.LmdbFlag.MDB_RDONLY,
                 env_open_mode = 0o664, # 8进制表示
-                txn_flag = 0,
+                txn_flag = DB.LmdbFlag.MDB_RDONLY,
                 dbi_flag = 0,
                 put_flag = 0)
 
 def LmdbIterableDatasetLoader(data_path: Union[List[Union[AnyStr, typing.Iterator]], AnyStr, typing.Iterator],
                                  buffer_size: typing.Optional[int] = 128,
                                  cycle_length=1,
                                  block_length=1,
@@ -144,10 +144,7 @@
                         ):
         return MultiLmdbRandomDataset(data_path,
                                     data_key_prefix_list,
                                     num_key,
                                     options=options,
                                     map_size=map_size)
 
-
-
-
```

## fastdatasets/lmdb/iterable_dataset/__init__.py

```diff
@@ -5,41 +5,44 @@
 import os
 import warnings
 import typing
 import tfrecords
 from tfrecords import LMDB
 from multiprocessing import cpu_count
 from .. import IterableDatasetBase
-import copy
 
 __all__ = ["SingleLmdbIterableDataset", "MultiLmdbIterableDataset", "tfrecords", "warnings"]
 
 
 
 DefaultOptions = LMDB.LmdbOptions(env_open_flag = LMDB.LmdbFlag.MDB_RDONLY,
                 env_open_mode = 0o664, # 8进制表示
-                txn_flag = 0,
+                txn_flag = LMDB.LmdbFlag.MDB_RDONLY,
                 dbi_flag = 0,
                 put_flag = 0)
 
    
 
 class SingleLmdbIterableDataset(IterableDatasetBase):
     def __init__(self,
                  data_path: typing.Union[typing.AnyStr,typing.Iterator],
                  buffer_size: typing.Optional[int] = 64,
                  block_length=1,
                  options=DefaultOptions,
-                 map_size=0
+                 map_size=0,
+                 max_readers: int = 128,
+                 max_dbs: int = 0
                  ):
 
 
         assert block_length > 0
 
         self.map_size = map_size
+        self.max_readers = max_readers
+        self.max_dbs = max_dbs
         self.block_length = block_length
         self.data_path = data_path
         self.options  = options
 
         self.block_id = -1
         if buffer_size is None:
             buffer_size = 1
@@ -64,15 +67,20 @@
             self.iterator_ = None
             self.iterator_obj = None
 
     def __reopen__(self):
         self.block_id = -1
         self.close()
         if os.path.exists(self.data_path):
-            self.iterator_ = LMDB.Lmdb(self.data_path, options=self.options,map_size=self.map_size)
+            self.iterator_ = LMDB.Lmdb(self.data_path,
+                                       options=self.options,
+                                       map_size=self.map_size,
+                                       max_readers=self.max_readers,
+                                       max_dbs=self.max_dbs)
+
             self.iterator_obj = self.iterator_.get_iterater(reverse=False)
         else:
             self.iterator_ = None
 
         self.repeat_done_num += 1
         return True
 
@@ -127,24 +135,28 @@
 
     def __init__(self,
                  data_path: typing.List[typing.Union[typing.AnyStr,typing.Iterator]],
                  buffer_size: typing.Optional[int]=64,
                  cycle_length=None,
                  block_length=1,
                  options =DefaultOptions,
-                 map_size=False
+                 map_size =0,
+                 max_readers: int = 128,
+                 max_dbs: int = 0
                  ) -> None:
         super(MultiLmdbIterableDataset, self).__init__()
 
         assert block_length > 0
 
         if cycle_length is None:
             cycle_length = cpu_count()
 
         self.map_size = map_size
+        self.max_readers = max_readers
+        self.max_dbs = max_dbs
         self.options = options
         self.cycle_length = min(cycle_length,len(data_path))
         self.block_length = block_length
         self.data_path = data_path
         self.buffer_size = buffer_size
 
         if self.buffer_size is None:
@@ -174,15 +186,17 @@
             self.cicle_iterators_.append(
                 {
                     "class": SingleLmdbIterableDataset,
                     "args": (it_obj["file"],
                              self.buffer_size,
                              self.block_length,
                              self.options,
-                             self.map_size
+                             self.map_size,
+                             self.max_readers,
+                             self.max_dbs,
                              ),
                     "instance": None
                 }
             )
 
 
     def get_iterator(self):
```

## fastdatasets/lmdb/random_dataset/__init__.py

```diff
@@ -4,40 +4,44 @@
 import logging
 import typing
 import os
 from typing import List
 import tfrecords
 from tfrecords import LMDB
 from .. import RandomDatasetBase
-import copy
 
 logging.basicConfig(level=logging.INFO)
 
 
 __all__ = ["SingleLmdbRandomDataset", "MultiLmdbRandomDataset", "tfrecords", "logging"]
 
 DefaultOptions = LMDB.LmdbOptions( env_open_flag = LMDB.LmdbFlag.MDB_RDONLY,
                 env_open_mode = 0o664, # 8进制表示
-                txn_flag = 0,
+                txn_flag = LMDB.LmdbFlag.MDB_RDONLY,
                 dbi_flag = 0,
                 put_flag = 0)
 class SingleLmdbRandomDataset(RandomDatasetBase):
     def __init__(self,
                  data_path: typing.Union[typing.AnyStr,typing.Sized],
                  data_key_prefix_list=('input',),
                  num_key='total_num',
                  options=DefaultOptions,
-                 map_size=0
+                 map_size=0,
+                 max_readers: int = 128,
+                 max_dbs: int = 0
                  ):
         super(SingleLmdbRandomDataset, self).__init__()
 
         self.data_key_prefix_list = data_key_prefix_list
         self.data_path = data_path
         self.options = options
         self.map_size = map_size
+        self.max_readers = max_readers
+        self.max_dbs = max_dbs
+
 
         self.file_reader_ : typing.Optional[LMDB.Lmdb] = None
         self.reset()
         if self.file_reader_ is not None:
             num_key_obj = self.file_reader_.get(num_key)
             assert num_key_obj is not None
             self.length = int(num_key_obj.decode(encoding='utf-8'))
@@ -57,15 +61,20 @@
             self.file_reader_ = None
 
     def __reopen__(self):
         self.block_id = -1
         self.close()
 
         if os.path.exists(self.data_path):
-            self.file_reader_ = LMDB.Lmdb(self.data_path,options=self.options,map_size=self.map_size)
+            self.file_reader_ = LMDB.Lmdb(self.data_path,
+                                          options=self.options,
+                                          map_size=self.map_size,
+                                          max_readers=self.max_readers,
+                                          max_dbs=self.max_dbs,
+                                          )
         else:
             self.file_reader_ = None
 
         self.repeat_done_num += 1
         return True
 
     def __len__(self):
@@ -89,19 +98,23 @@
 class MultiLmdbRandomDataset(RandomDatasetBase):
     def __init__(self,
                  data_path: List[typing.Union[typing.AnyStr,typing.Sized]],
                  data_key_prefix_list=('input',),
                  num_key='total_num',
                  options = DefaultOptions,
                  map_size=0,
+                 max_readers: int = 128,
+                 max_dbs: int = 0,
                  ) -> None:
         super(MultiLmdbRandomDataset, self).__init__()
 
         self.options = options
         self.map_size = map_size
+        self.max_readers = max_readers
+        self.max_dbs = max_dbs
         self.data_path = data_path
         self.data_key_prefix_list = data_key_prefix_list
         self.num_key = num_key
         self.reset()
 
     def reset(self):
         self.iterators_ = [{"valid": False,"file": self.data_path[i]} for i in range(len(self.data_path))]
@@ -119,15 +132,17 @@
 
     def __reopen__(self):
         for it_obj in self.iterators_:
             it_obj['inst'] = SingleLmdbRandomDataset(it_obj["file"],
                                                         data_key_prefix_list=self.data_key_prefix_list,
                                                         num_key=self.num_key,
                                                         options=self.options,
-                                                        map_size=self.map_size
+                                                        map_size=self.map_size,
+                                                        max_readers = self.max_readers,
+                                                        max_dbs = self.max_dbs
                                                      )
 
     def __len__(self):
         total_len = 0
         for it_obj in self.iterators_:
             total_len += len(it_obj['inst'])
         return total_len
```

## fastdatasets/utils/numpyadapter.py

```diff
@@ -181,15 +181,15 @@
                                                    data_key_prefix_list=data_key_prefix_list,
                                                    num_key=num_key,
                                                    options=options)
         elif data_backend == E_file_backend.lmdb:
             if options is None:
                 options = LMDB.LmdbOptions(env_open_flag=LMDB.LmdbFlag.MDB_RDONLY,
                                                                          env_open_mode=0o664,  # 8进制表示
-                                                                         txn_flag=0,
+                                                                         txn_flag=LMDB.LmdbFlag.MDB_RDONLY,
                                                                          dbi_flag=0,
                                                                          put_flag=0)
             dataset = lmdb_loader.RandomDataset(input_files,
                                                 data_key_prefix_list=data_key_prefix_list,
                                                 num_key=num_key,
                                                 options=options)
         elif data_backend == E_file_backend.memory:
```

## Comparing `fastdatasets-0.9.6.dist-info/METADATA` & `fastdatasets-0.9.7.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: fastdatasets
-Version: 0.9.6
+Version: 0.9.7
 Summary: fastdatasets: datasets for tfrecords
 Home-page: https://github.com/ssbuild/fastdatasets
 Author: ssbuild
 Author-email: 9727464@qq.com
 License: Apache 2.0
 Keywords: fastdatasets,fastdatasets,tfrecords,dataset,datasets
 Platform: win32_AMD64
@@ -24,15 +24,15 @@
 Classifier: Topic :: Scientific/Engineering :: Mathematics
 Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
 Classifier: Topic :: Software Development
 Classifier: Topic :: Software Development :: Libraries
 Classifier: Topic :: Software Development :: Libraries :: Python Modules
 Requires-Python: >=3, <4
 Description-Content-Type: text/markdown
-Requires-Dist: tfrecords (>=0.2.2)
+Requires-Dist: tfrecords (<0.3,>=0.2.6)
 Requires-Dist: data-serialize (>=0.2.1)
 Requires-Dist: numpy
 
 ## datasets for tfrecords
 
 ## The update statement 
 [usage:](https://github.com/ssbuild/fastdatasets-examples)  https://github.com/ssbuild/fastdatasets-examples
@@ -313,15 +313,15 @@
         values.append(train_node)
         if (i+1) % 10000 == 0:
             f.put_batch(keys,values)
             keys.clear()
             values.clear()
     if len(keys):
         f.put_batch(keys, values)
-
+        
     f.get_writer.put('total_num',str(n))
     f.close()
 
 
 
 def test_random(db_path):
     options = DB.LeveldbOptions(create_if_missing=False, error_if_exists=False)
@@ -384,15 +384,15 @@
     f.close()
 
 
 
 def test_random(db_path):
     options = DB.LmdbOptions(env_open_flag=DB.LmdbFlag.MDB_RDONLY,
                                env_open_mode=0o664,  # 8进制表示
-                               txn_flag=0,
+                               txn_flag=LMDB.LmdbFlag.MDB_RDONLY,
                                dbi_flag=0,
                                put_flag=0)
     dataset = load_dataset.RandomDataset(db_path,
                                         data_key_prefix_list=('input',),
                                         num_key='total_num',
                                         options = options)
 
@@ -401,8 +401,7 @@
     for i in tqdm(range(len(dataset)), total=len(dataset)):
         d = dataset[i]
         print(d)
 
 test_write(db_path)
 test_random(db_path)
 ```
-
```

## Comparing `fastdatasets-0.9.6.dist-info/RECORD` & `fastdatasets-0.9.7.dist-info/RECORD`

 * *Files 9% similar despite different names*

```diff
@@ -1,36 +1,36 @@
-fastdatasets/README.md,sha256=ebY1DdNIpIR6ityQOhIkyTSuB5nnD9q9Bb-B4XZfIfM,11172
+fastdatasets/README.md,sha256=Bz4QC7rq9qkxQjTQPHkek5cf2FsFbIhXMUphDi7dA3o,11195
 fastdatasets/__init__.py,sha256=IWbktO9_fb7lbkdmAGQtoCOcTJqMjDjOdYzqd_eol_I,116
 fastdatasets/common/__init__.py,sha256=sv6vMerE_nO2Y6W-Fav0GqpVrorbFHt1UN_UjzMW-Lw,76
 fastdatasets/common/iterable_dataset.py,sha256=3c9CqZZGUjZCQd-sxKcyb7_bmjIQ0leZQOFdZijZvSE,14096
 fastdatasets/common/random_dataset.py,sha256=Z7yuPgo9G2mi7lFrfSNYw7OGFOwLZSe83KwhkCeRhd0,10767
 fastdatasets/common/writer.py,sha256=wReE0D2iuS2S4youWObl2pQMpPallEKR2Q8VmcukzuE,4262
 fastdatasets/leveldb/__init__.py,sha256=6SYGU-XQEv88zoG69UiSpLydsLyBAWFz8nYu5oLQq1I,209
 fastdatasets/leveldb/dataset.py,sha256=NFJSACfRBmuR5CKVoxA7_Jg5OtW7gwl5tNNyYlc44e8,6031
 fastdatasets/leveldb/writer.py,sha256=TzWH6VLJpyPirT6X4JkO_vsDkOewIWFBKOi0_oodUFY,4408
 fastdatasets/leveldb/iterable_dataset/__init__.py,sha256=eFpT0GTxmtuPOQaPLVyDyKAi6HLbiNHJaQ00TuDi9TI,7148
 fastdatasets/leveldb/random_dataset/__init__.py,sha256=0gQTDFxc__uMdzKOXDNfiQgcEXgzp-aEAi89dj4t3H4,4716
-fastdatasets/lmdb/__init__.py,sha256=6SYGU-XQEv88zoG69UiSpLydsLyBAWFz8nYu5oLQq1I,209
-fastdatasets/lmdb/dataset.py,sha256=JSPzs4GEKcr3tjSJaU7m87a6Okl5343mmjBDmX7nOMM,6763
+fastdatasets/lmdb/__init__.py,sha256=L9E4x2kIuVDsOgXXylwQRsURWGtZNw41t-vIxImNwuM,215
+fastdatasets/lmdb/dataset.py,sha256=H2GgEKmMkBf9FTKtvawVPDX_cxFBEwGh1BviUqGdW0Q,6778
 fastdatasets/lmdb/writer.py,sha256=rnjGhadu05Xm3lg4_WB3YKL_W4goS2tqeL-T77jaiOE,4613
-fastdatasets/lmdb/iterable_dataset/__init__.py,sha256=o_F2q7j1RcKEt8k0PXwbZQWY1qeMNe-L1odLKswgZ84,7164
-fastdatasets/lmdb/random_dataset/__init__.py,sha256=7E8--5h2lfXJnqhRDx9DsaIWFiGdLuXy2BJA02n7qBQ,5043
+fastdatasets/lmdb/iterable_dataset/__init__.py,sha256=eNFFSJ7bubgga3BjM__fpcXjRj644A-55nt7315rwRE,7765
+fastdatasets/lmdb/random_dataset/__init__.py,sha256=HYRTZqia4uQcjE_OGWBx-xaSPDNAr2lSvIjd386vHxg,5796
 fastdatasets/memory/__init__.py,sha256=CYhm3FSbi0vO3UoZwpFtu3b1r4nAqGQrSOYTTF-HYa0,209
 fastdatasets/memory/dataset.py,sha256=_0cUbYO5nx2LQYmC6728Lj1nNBCO9yXYMJemIAbvjrE,4704
 fastdatasets/memory/writer.py,sha256=ew9WcEHnjlAhDvS7ZIH5Q0jO0qBIC5Sxiwrsp06kZio,3652
 fastdatasets/memory/iterable_dataset/__init__.py,sha256=D6J0wiumaGNS3a-869I7Ceir5VdxNYojZW9sJUkxrv4,6474
 fastdatasets/memory/random_dataset/__init__.py,sha256=NOtCwaZYuKbZBZpU2GIoBqQsiCW9ziwi4a3Zu4mhOj8,4304
 fastdatasets/record/__init__.py,sha256=CYhm3FSbi0vO3UoZwpFtu3b1r4nAqGQrSOYTTF-HYa0,209
 fastdatasets/record/dataset.py,sha256=LpT-C4N5hnLLl8zkF5JSYMYwS0HQExyBJnmFEE5126A,6007
 fastdatasets/record/writer.py,sha256=A1kdYk6mco2j2uwLAhi089Fb27b9oodUERTnZLTWTWI,3709
 fastdatasets/record/iterable_dataset/__init__.py,sha256=2T7quMNkxRH9X0PRJqV4dM1Fmin5T3EHN7HiIVTL97M,7358
 fastdatasets/record/random_dataset/__init__.py,sha256=GGTJ5kIoYrina58Vp7RV9fq9lzYwmn9DYVoRI2Bjjmc,6788
 fastdatasets/torch_dataset/__init__.py,sha256=yOgyipcBb3Eciz9RASpVl1Su_y_64DvFr9Za-oCZffs,5576
 fastdatasets/utils/MEMORY.py,sha256=Nbc6_x8BVj7yG8xs4mHVVk-K_dd3tIHXA3bHdyCcZpQ,980
 fastdatasets/utils/__init__.py,sha256=y8NZKf2Vim0cuGnafXjCDS2OUSDFfmkwcmE2CdS7mgU,51
-fastdatasets/utils/numpyadapter.py,sha256=q_nJJBZQNSZUtb-7KyNZH8kWpqMmQWIJcpuuRmjKkO8,12197
+fastdatasets/utils/numpyadapter.py,sha256=jE5Oha5DKNhdgOJlBzL7LHhR8G1skj-9UfdeLDDJZTM,12220
 fastdatasets/utils/parallel.py,sha256=7pxBQ7w26H5wo1gHEMJwFwrkl57PDUA7rF3y8GD5kjM,5457
 fastdatasets/utils/py_features.py,sha256=_yPn5zwI6SH5RLC8hTKSMp1el951_5qMDrVmTuP2xmk,346
-fastdatasets-0.9.6.dist-info/METADATA,sha256=JTI25ih9a_G93sF053mTWWoScLOgz8nyX9ODUQm6PIM,12198
-fastdatasets-0.9.6.dist-info/WHEEL,sha256=OqRkF0eY5GHssMorFjlbTIq072vpHpF60fIQA6lS9xA,92
-fastdatasets-0.9.6.dist-info/top_level.txt,sha256=cSNnK2OJMFJZoleds15VI1qc8MXMYTpgmVdwQ3jItzo,13
-fastdatasets-0.9.6.dist-info/RECORD,,
+fastdatasets-0.9.7.dist-info/METADATA,sha256=ocJarv28XUzw9cUZstPzQIBtsjoI8OCnk_C5l3ZWB8Y,12233
+fastdatasets-0.9.7.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+fastdatasets-0.9.7.dist-info/top_level.txt,sha256=cSNnK2OJMFJZoleds15VI1qc8MXMYTpgmVdwQ3jItzo,13
+fastdatasets-0.9.7.dist-info/RECORD,,
```

