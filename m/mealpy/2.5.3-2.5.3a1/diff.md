# Comparing `tmp/mealpy-2.5.3.tar.gz` & `tmp/mealpy-2.5.3a1.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "dist\mealpy-2.5.3.tar", last modified: Thu Apr 27 11:09:42 2023, max compression
+gzip compressed data, was "mealpy-2.5.3a1.tar", last modified: Tue Mar 21 15:12:13 2023, max compression
```

## Comparing `mealpy-2.5.3.tar` & `mealpy-2.5.3a1.tar`

### file list

```diff
@@ -1,179 +1,175 @@
-drwxrwxrwx   0        0        0        0 2023-04-27 11:09:42.082038 mealpy-2.5.3/
--rw-rw-rw-   0        0        0    58915 2023-04-27 10:41:33.000000 mealpy-2.5.3/ChangeLog.md
--rw-rw-rw-   0        0        0    35823 2022-03-04 15:32:50.000000 mealpy-2.5.3/LICENSE
--rw-rw-rw-   0        0        0       76 2022-03-22 03:44:32.000000 mealpy-2.5.3/MANIFEST.in
--rw-rw-rw-   0        0        0   100594 2023-04-27 11:09:42.081040 mealpy-2.5.3/PKG-INFO
--rw-rw-rw-   0        0        0    89173 2023-04-27 11:05:15.000000 mealpy-2.5.3/README.md
-drwxrwxrwx   0        0        0        0 2023-04-27 11:09:41.201259 mealpy-2.5.3/mealpy/
--rw-rw-rw-   0        0        0     2084 2023-04-27 11:06:15.000000 mealpy-2.5.3/mealpy/__init__.py
-drwxrwxrwx   0        0        0        0 2023-04-27 11:09:41.305478 mealpy-2.5.3/mealpy/bio_based/
--rw-rw-rw-   0        0        0     8239 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/bio_based/BBO.py
--rw-rw-rw-   0        0        0     4661 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/bio_based/BBOA.py
--rw-rw-rw-   0        0        0     3213 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/bio_based/BMO.py
--rw-rw-rw-   0        0        0     8126 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/bio_based/EOA.py
--rw-rw-rw-   0        0        0     5322 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/bio_based/IWO.py
--rw-rw-rw-   0        0        0     9311 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/bio_based/SBO.py
--rw-rw-rw-   0        0        0    10257 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/bio_based/SMA.py
--rw-rw-rw-   0        0        0     6833 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/bio_based/SOA.py
--rw-rw-rw-   0        0        0     4147 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/bio_based/SOS.py
--rw-rw-rw-   0        0        0     6138 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/bio_based/TPO.py
--rw-rw-rw-   0        0        0     3590 2023-04-11 02:41:21.000000 mealpy-2.5.3/mealpy/bio_based/TSA.py
--rw-rw-rw-   0        0        0    12005 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/bio_based/VCS.py
--rw-rw-rw-   0        0        0     9952 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/bio_based/WHO.py
--rw-rw-rw-   0        0        0      243 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/bio_based/__init__.py
-drwxrwxrwx   0        0        0        0 2023-04-27 11:09:41.356844 mealpy-2.5.3/mealpy/evolutionary_based/
--rw-rw-rw-   0        0        0    16417 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/evolutionary_based/CRO.py
--rw-rw-rw-   0        0        0    41423 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/evolutionary_based/DE.py
--rw-rw-rw-   0        0        0     9068 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/evolutionary_based/EP.py
--rw-rw-rw-   0        0        0    17365 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/evolutionary_based/ES.py
--rw-rw-rw-   0        0        0     4596 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/evolutionary_based/FPA.py
--rw-rw-rw-   0        0        0    39473 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/evolutionary_based/GA.py
--rw-rw-rw-   0        0        0     8690 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/evolutionary_based/MA.py
--rw-rw-rw-   0        0        0      243 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/evolutionary_based/__init__.py
-drwxrwxrwx   0        0        0        0 2023-04-27 11:09:41.476361 mealpy-2.5.3/mealpy/human_based/
--rw-rw-rw-   0        0        0    10605 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/human_based/BRO.py
--rw-rw-rw-   0        0        0    12983 2023-04-11 02:43:52.000000 mealpy-2.5.3/mealpy/human_based/BSO.py
--rw-rw-rw-   0        0        0     4294 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/human_based/CA.py
--rw-rw-rw-   0        0        0    12542 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/human_based/CHIO.py
--rw-rw-rw-   0        0        0    15112 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/human_based/FBIO.py
--rw-rw-rw-   0        0        0    12836 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/human_based/GSKA.py
--rw-rw-rw-   0        0        0     7278 2023-04-11 02:43:52.000000 mealpy-2.5.3/mealpy/human_based/HBO.py
--rw-rw-rw-   0        0        0     6415 2023-04-11 02:47:13.000000 mealpy-2.5.3/mealpy/human_based/HCO.py
--rw-rw-rw-   0        0        0    10549 2023-03-21 06:00:04.000000 mealpy-2.5.3/mealpy/human_based/ICA.py
--rw-rw-rw-   0        0        0    11914 2023-04-10 04:51:13.000000 mealpy-2.5.3/mealpy/human_based/ILA.py
--rw-rw-rw-   0        0        0    12569 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/human_based/LCO.py
--rw-rw-rw-   0        0        0      618 2022-10-15 17:40:49.000000 mealpy-2.5.3/mealpy/human_based/PO.py
--rw-rw-rw-   0        0        0    18263 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/human_based/QSA.py
--rw-rw-rw-   0        0        0    11707 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/human_based/SARO.py
--rw-rw-rw-   0        0        0     7604 2023-04-11 02:47:13.000000 mealpy-2.5.3/mealpy/human_based/SPBO.py
--rw-rw-rw-   0        0        0     4748 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/human_based/SSDO.py
--rw-rw-rw-   0        0        0    14142 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/human_based/TLO.py
--rw-rw-rw-   0        0        0     5652 2023-04-11 02:54:50.000000 mealpy-2.5.3/mealpy/human_based/TOA.py
--rw-rw-rw-   0        0        0     3997 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/human_based/WarSO.py
--rw-rw-rw-   0        0        0      243 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/human_based/__init__.py
-drwxrwxrwx   0        0        0        0 2023-04-27 11:09:41.545913 mealpy-2.5.3/mealpy/math_based/
--rw-rw-rw-   0        0        0     5354 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/math_based/AOA.py
--rw-rw-rw-   0        0        0     4292 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/math_based/CEM.py
--rw-rw-rw-   0        0        0     5247 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/math_based/CGO.py
--rw-rw-rw-   0        0        0     3203 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/math_based/CircleSA.py
--rw-rw-rw-   0        0        0     7365 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/math_based/GBO.py
--rw-rw-rw-   0        0        0     7019 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/math_based/HC.py
--rw-rw-rw-   0        0        0     7903 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/math_based/INFO.py
--rw-rw-rw-   0        0        0     6521 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/math_based/PSS.py
--rw-rw-rw-   0        0        0     8076 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/math_based/RUN.py
--rw-rw-rw-   0        0        0    14150 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/math_based/SCA.py
--rw-rw-rw-   0        0        0     3681 2023-04-11 03:01:23.000000 mealpy-2.5.3/mealpy/math_based/SHIO.py
--rw-rw-rw-   0        0        0      243 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/math_based/__init__.py
--rw-rw-rw-   0        0        0     8780 2023-03-22 03:14:38.000000 mealpy-2.5.3/mealpy/multitask.py
-drwxrwxrwx   0        0        0        0 2023-04-27 11:09:41.556394 mealpy-2.5.3/mealpy/music_based/
--rw-rw-rw-   0        0        0     7314 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/music_based/HS.py
--rw-rw-rw-   0        0        0      243 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/music_based/__init__.py
--rw-rw-rw-   0        0        0    33494 2023-03-21 13:23:27.000000 mealpy-2.5.3/mealpy/optimizer.py
-drwxrwxrwx   0        0        0        0 2023-04-27 11:09:41.641448 mealpy-2.5.3/mealpy/physics_based/
--rw-rw-rw-   0        0        0     7892 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/physics_based/ASO.py
--rw-rw-rw-   0        0        0     7414 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/physics_based/ArchOA.py
--rw-rw-rw-   0        0        0     4272 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/physics_based/CDO.py
--rw-rw-rw-   0        0        0    12153 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/physics_based/EFO.py
--rw-rw-rw-   0        0        0    13373 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/physics_based/EO.py
--rw-rw-rw-   0        0        0     5754 2023-04-11 03:03:13.000000 mealpy-2.5.3/mealpy/physics_based/EVO.py
--rw-rw-rw-   0        0        0    12520 2023-04-11 03:05:10.000000 mealpy-2.5.3/mealpy/physics_based/FLA.py
--rw-rw-rw-   0        0        0     6735 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/physics_based/HGSO.py
--rw-rw-rw-   0        0        0    10130 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/physics_based/MVO.py
--rw-rw-rw-   0        0        0    11134 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/physics_based/NRO.py
--rw-rw-rw-   0        0        0     4270 2023-04-11 03:06:55.000000 mealpy-2.5.3/mealpy/physics_based/RIME.py
--rw-rw-rw-   0        0        0     7182 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/physics_based/SA.py
--rw-rw-rw-   0        0        0    21271 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/physics_based/TWO.py
--rw-rw-rw-   0        0        0     5149 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/physics_based/WDO.py
--rw-rw-rw-   0        0        0      243 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/physics_based/__init__.py
-drwxrwxrwx   0        0        0        0 2023-04-27 11:09:42.008096 mealpy-2.5.3/mealpy/swarm_based/
--rw-rw-rw-   0        0        0     5242 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/ABC.py
--rw-rw-rw-   0        0        0     4961 2023-04-11 03:08:51.000000 mealpy-2.5.3/mealpy/swarm_based/ACOR.py
--rw-rw-rw-   0        0        0    12091 2023-04-01 00:53:48.000000 mealpy-2.5.3/mealpy/swarm_based/AGTO.py
--rw-rw-rw-   0        0        0     8357 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/ALO.py
--rw-rw-rw-   0        0        0     4503 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/AO.py
--rw-rw-rw-   0        0        0    13462 2023-03-31 11:06:58.000000 mealpy-2.5.3/mealpy/swarm_based/ARO.py
--rw-rw-rw-   0        0        0     6415 2023-04-27 10:44:01.000000 mealpy-2.5.3/mealpy/swarm_based/AVOA.py
--rw-rw-rw-   0        0        0    15788 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/BA.py
--rw-rw-rw-   0        0        0     7593 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/BES.py
--rw-rw-rw-   0        0        0    16180 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/BFO.py
--rw-rw-rw-   0        0        0    10809 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/BSA.py
--rw-rw-rw-   0        0        0    17515 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/BeesA.py
--rw-rw-rw-   0        0        0     7497 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/COA.py
--rw-rw-rw-   0        0        0     3811 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/CSA.py
--rw-rw-rw-   0        0        0     8859 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/CSO.py
--rw-rw-rw-   0        0        0      567 2022-10-16 05:57:00.000000 mealpy-2.5.3/mealpy/swarm_based/ChOA.py
--rw-rw-rw-   0        0        0     5379 2023-04-11 04:02:40.000000 mealpy-2.5.3/mealpy/swarm_based/CoatiOA.py
--rw-rw-rw-   0        0        0    10783 2023-04-11 03:48:57.000000 mealpy-2.5.3/mealpy/swarm_based/DMOA.py
--rw-rw-rw-   0        0        0     7511 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/DO.py
--rw-rw-rw-   0        0        0     5101 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/EHO.py
--rw-rw-rw-   0        0        0     6773 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/ESOA.py
--rw-rw-rw-   0        0        0     6658 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/FA.py
--rw-rw-rw-   0        0        0     5828 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/FFA.py
--rw-rw-rw-   0        0        0     4705 2023-04-11 04:02:40.000000 mealpy-2.5.3/mealpy/swarm_based/FFO.py
--rw-rw-rw-   0        0        0     2409 2022-10-26 15:43:38.000000 mealpy-2.5.3/mealpy/swarm_based/FHO.py
--rw-rw-rw-   0        0        0     9225 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/FOA.py
--rw-rw-rw-   0        0        0     4493 2023-04-11 03:55:07.000000 mealpy-2.5.3/mealpy/swarm_based/FOX.py
--rw-rw-rw-   0        0        0     4586 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/GJO.py
--rw-rw-rw-   0        0        0     4482 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/GOA.py
--rw-rw-rw-   0        0        0    20049 2023-04-27 10:20:10.000000 mealpy-2.5.3/mealpy/swarm_based/GTO.py
--rw-rw-rw-   0        0        0    10989 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/GWO.py
--rw-rw-rw-   0        0        0     4733 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/HBA.py
--rw-rw-rw-   0        0        0     6784 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/HGS.py
--rw-rw-rw-   0        0        0     6349 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/HHO.py
--rw-rw-rw-   0        0        0     8315 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/JA.py
--rw-rw-rw-   0        0        0     7477 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/MFO.py
--rw-rw-rw-   0        0        0     5109 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/MGO.py
--rw-rw-rw-   0        0        0     5815 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/MPA.py
--rw-rw-rw-   0        0        0    14923 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/MRFO.py
--rw-rw-rw-   0        0        0     6127 2023-04-11 03:56:37.000000 mealpy-2.5.3/mealpy/swarm_based/MSA.py
--rw-rw-rw-   0        0        0     4912 2023-04-11 04:02:40.000000 mealpy-2.5.3/mealpy/swarm_based/NGO.py
--rw-rw-rw-   0        0        0     8665 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/NMRA.py
--rw-rw-rw-   0        0        0     5156 2023-04-11 04:05:05.000000 mealpy-2.5.3/mealpy/swarm_based/OOA.py
--rw-rw-rw-   0        0        0      573 2022-05-21 10:46:10.000000 mealpy-2.5.3/mealpy/swarm_based/OPA.py
--rw-rw-rw-   0        0        0     4062 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/PFA.py
--rw-rw-rw-   0        0        0     4812 2023-04-11 04:05:05.000000 mealpy-2.5.3/mealpy/swarm_based/POA.py
--rw-rw-rw-   0        0        0    27961 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/PSO.py
--rw-rw-rw-   0        0        0     4135 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/SCSO.py
--rw-rw-rw-   0        0        0    12738 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/SFO.py
--rw-rw-rw-   0        0        0     4891 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/SHO.py
--rw-rw-rw-   0        0        0    15104 2023-04-11 04:07:21.000000 mealpy-2.5.3/mealpy/swarm_based/SLO.py
--rw-rw-rw-   0        0        0    14478 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/SRSR.py
--rw-rw-rw-   0        0        0    12286 2023-04-11 04:07:21.000000 mealpy-2.5.3/mealpy/swarm_based/SSA.py
--rw-rw-rw-   0        0        0     3612 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/SSO.py
--rw-rw-rw-   0        0        0     7500 2023-04-11 04:10:22.000000 mealpy-2.5.3/mealpy/swarm_based/SSpiderA.py
--rw-rw-rw-   0        0        0    13712 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/SSpiderO.py
--rw-rw-rw-   0        0        0     5160 2023-04-11 04:11:47.000000 mealpy-2.5.3/mealpy/swarm_based/STO.py
--rw-rw-rw-   0        0        0     6032 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/SeaHO.py
--rw-rw-rw-   0        0        0     4400 2023-04-11 04:07:21.000000 mealpy-2.5.3/mealpy/swarm_based/ServalOA.py
--rw-rw-rw-   0        0        0     6068 2023-04-11 04:13:55.000000 mealpy-2.5.3/mealpy/swarm_based/TDO.py
--rw-rw-rw-   0        0        0     6256 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/TSO.py
--rw-rw-rw-   0        0        0     8497 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/WOA.py
--rw-rw-rw-   0        0        0      554 2022-05-21 10:44:26.000000 mealpy-2.5.3/mealpy/swarm_based/WSO.py
--rw-rw-rw-   0        0        0     4653 2023-04-11 04:17:20.000000 mealpy-2.5.3/mealpy/swarm_based/WaOA.py
--rw-rw-rw-   0        0        0     5625 2023-04-11 04:17:20.000000 mealpy-2.5.3/mealpy/swarm_based/ZOA.py
--rw-rw-rw-   0        0        0      243 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/swarm_based/__init__.py
-drwxrwxrwx   0        0        0        0 2023-04-27 11:09:42.030658 mealpy-2.5.3/mealpy/system_based/
--rw-rw-rw-   0        0        0    28723 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/system_based/AEO.py
--rw-rw-rw-   0        0        0     8501 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/system_based/GCO.py
--rw-rw-rw-   0        0        0     7142 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/system_based/WCA.py
--rw-rw-rw-   0        0        0      243 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/system_based/__init__.py
--rw-rw-rw-   0        0        0    14229 2023-03-22 03:57:59.000000 mealpy-2.5.3/mealpy/tuner.py
-drwxrwxrwx   0        0        0        0 2023-04-27 11:09:42.068613 mealpy-2.5.3/mealpy/utils/
--rw-rw-rw-   0        0        0      408 2023-03-18 00:48:50.000000 mealpy-2.5.3/mealpy/utils/__init__.py
--rw-rw-rw-   0        0        0    13278 2022-10-26 19:05:53.000000 mealpy-2.5.3/mealpy/utils/history.py
--rw-rw-rw-   0        0        0      873 2022-09-11 15:57:04.000000 mealpy-2.5.3/mealpy/utils/io.py
--rw-rw-rw-   0        0        0     2572 2022-09-11 15:57:04.000000 mealpy-2.5.3/mealpy/utils/logger.py
--rw-rw-rw-   0        0        0     9156 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/utils/problem.py
--rw-rw-rw-   0        0        0     6490 2023-03-21 04:48:48.000000 mealpy-2.5.3/mealpy/utils/termination.py
--rw-rw-rw-   0        0        0     5702 2022-10-26 19:05:53.000000 mealpy-2.5.3/mealpy/utils/validator.py
-drwxrwxrwx   0        0        0        0 2023-04-27 11:09:42.080040 mealpy-2.5.3/mealpy/utils/visualize/
--rw-rw-rw-   0        0        0      405 2022-10-26 19:05:53.000000 mealpy-2.5.3/mealpy/utils/visualize/__init__.py
--rw-rw-rw-   0        0        0     9265 2022-10-26 19:05:53.000000 mealpy-2.5.3/mealpy/utils/visualize/linechart.py
-drwxrwxrwx   0        0        0        0 2023-04-27 11:09:41.225171 mealpy-2.5.3/mealpy.egg-info/
--rw-rw-rw-   0        0        0   100594 2023-04-27 11:09:41.000000 mealpy-2.5.3/mealpy.egg-info/PKG-INFO
--rw-rw-rw-   0        0        0     4310 2023-04-27 11:09:41.000000 mealpy-2.5.3/mealpy.egg-info/SOURCES.txt
--rw-rw-rw-   0        0        0        1 2023-04-27 11:09:41.000000 mealpy-2.5.3/mealpy.egg-info/dependency_links.txt
--rw-rw-rw-   0        0        0      105 2023-04-27 11:09:41.000000 mealpy-2.5.3/mealpy.egg-info/requires.txt
--rw-rw-rw-   0        0        0        7 2023-04-27 11:09:41.000000 mealpy-2.5.3/mealpy.egg-info/top_level.txt
--rw-rw-rw-   0        0        0       42 2023-04-27 11:09:42.082038 mealpy-2.5.3/setup.cfg
--rw-rw-rw-   0        0        0     3518 2023-04-27 10:45:32.000000 mealpy-2.5.3/setup.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 15:12:13.465481 mealpy-2.5.3a1/
+-rw-r--r--   0 runner    (1001) docker     (123)    57487 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/ChangeLog.md
+-rw-r--r--   0 runner    (1001) docker     (123)    35149 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/LICENSE
+-rw-r--r--   0 runner    (1001) docker     (123)       69 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/MANIFEST.in
+-rw-r--r--   0 runner    (1001) docker     (123)    90293 2023-03-21 15:12:13.465481 mealpy-2.5.3a1/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (123)    87752 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/README.md
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 15:12:13.433481 mealpy-2.5.3a1/mealpy/
+-rw-r--r--   0 runner    (1001) docker     (123)     2044 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 15:12:13.437481 mealpy-2.5.3a1/mealpy/bio_based/
+-rw-r--r--   0 runner    (1001) docker     (123)     8056 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/bio_based/BBO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4560 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/bio_based/BBOA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3135 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/bio_based/BMO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7966 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/bio_based/EOA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5207 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/bio_based/IWO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9098 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/bio_based/SBO.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10032 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/bio_based/SMA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6675 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/bio_based/SOA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4056 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/bio_based/SOS.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6015 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/bio_based/TPO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3456 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/bio_based/TSA.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11744 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/bio_based/VCS.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9772 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/bio_based/WHO.py
+-rw-r--r--   0 runner    (1001) docker     (123)      238 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/bio_based/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 15:12:13.437481 mealpy-2.5.3a1/mealpy/evolutionary_based/
+-rw-r--r--   0 runner    (1001) docker     (123)    16080 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/evolutionary_based/CRO.py
+-rw-r--r--   0 runner    (1001) docker     (123)    40520 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/evolutionary_based/DE.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8853 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/evolutionary_based/EP.py
+-rw-r--r--   0 runner    (1001) docker     (123)    16955 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/evolutionary_based/ES.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4492 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/evolutionary_based/FPA.py
+-rw-r--r--   0 runner    (1001) docker     (123)    38686 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/evolutionary_based/GA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8495 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/evolutionary_based/MA.py
+-rw-r--r--   0 runner    (1001) docker     (123)      238 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/evolutionary_based/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 15:12:13.441481 mealpy-2.5.3a1/mealpy/human_based/
+-rw-r--r--   0 runner    (1001) docker     (123)    10374 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/human_based/BRO.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12629 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/human_based/BSO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4185 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/human_based/CA.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12294 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/human_based/CHIO.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14812 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/human_based/FBIO.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12588 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/human_based/GSKA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7123 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/human_based/HBO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6267 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/human_based/HCO.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10356 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/human_based/ICA.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12285 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/human_based/LCO.py
+-rw-r--r--   0 runner    (1001) docker     (123)    17806 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/human_based/QSA.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11442 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/human_based/SARO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7385 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/human_based/SPBO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4635 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/human_based/SSDO.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13823 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/human_based/TLO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5251 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/human_based/TOA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3908 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/human_based/WarSO.py
+-rw-r--r--   0 runner    (1001) docker     (123)      238 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/human_based/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 15:12:13.445481 mealpy-2.5.3a1/mealpy/math_based/
+-rw-r--r--   0 runner    (1001) docker     (123)     5245 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/math_based/AOA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4192 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/math_based/CEM.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5133 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/math_based/CGO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3128 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/math_based/CircleSA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7225 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/math_based/GBO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6857 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/math_based/HC.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7750 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/math_based/INFO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6381 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/math_based/PSS.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7923 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/math_based/RUN.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13819 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/math_based/SCA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3674 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/math_based/SHIO.py
+-rw-r--r--   0 runner    (1001) docker     (123)      238 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/math_based/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8749 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/multitask.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 15:12:13.445481 mealpy-2.5.3a1/mealpy/music_based/
+-rw-r--r--   0 runner    (1001) docker     (123)     7131 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/music_based/HS.py
+-rw-r--r--   0 runner    (1001) docker     (123)      238 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/music_based/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    32769 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/optimizer.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 15:12:13.445481 mealpy-2.5.3a1/mealpy/physics_based/
+-rw-r--r--   0 runner    (1001) docker     (123)     7707 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/physics_based/ASO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7253 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/physics_based/ArchOA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4172 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/physics_based/CDO.py
+-rw-r--r--   0 runner    (1001) docker     (123)    11920 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/physics_based/EFO.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13064 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/physics_based/EO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5600 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/physics_based/EVO.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12233 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/physics_based/FLA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6584 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/physics_based/HGSO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9907 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/physics_based/MVO.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10924 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/physics_based/NRO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4132 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/physics_based/RIME.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7040 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/physics_based/SA.py
+-rw-r--r--   0 runner    (1001) docker     (123)    20823 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/physics_based/TWO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5034 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/physics_based/WDO.py
+-rw-r--r--   0 runner    (1001) docker     (123)      238 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/physics_based/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 15:12:13.461481 mealpy-2.5.3a1/mealpy/swarm_based/
+-rw-r--r--   0 runner    (1001) docker     (123)     5130 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/ABC.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4834 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/ACOR.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5934 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/AGTO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8154 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/ALO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4399 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/AO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4334 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/ARO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6290 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/AVOA.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15447 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/BA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7438 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/BES.py
+-rw-r--r--   0 runner    (1001) docker     (123)    15836 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/BFO.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10607 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/BSA.py
+-rw-r--r--   0 runner    (1001) docker     (123)    17152 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/BeesA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7337 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/COA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3718 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/CSA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8679 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/CSO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5206 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/CoatiOA.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10466 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/DMOA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7349 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/DO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4992 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/EHO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6622 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/ESOA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6525 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/FA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5708 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/FFA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4530 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/FFO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8988 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/FOA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4428 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/FOX.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4484 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/GJO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4379 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/GOA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6883 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/GTO.py
+-rw-r--r--   0 runner    (1001) docker     (123)    10737 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/GWO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4626 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/HBA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6627 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/HGS.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6223 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/HHO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8103 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/JA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7296 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/MFO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5006 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/MGO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5694 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/MPA.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14640 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/MRFO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6002 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/MSA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4720 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/NGO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8465 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/NMRA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4980 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/OOA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3966 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/PFA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4630 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/POA.py
+-rw-r--r--   0 runner    (1001) docker     (123)    27340 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/PSO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4038 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/SCSO.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12476 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/SFO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4781 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/SHO.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14777 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/SLO.py
+-rw-r--r--   0 runner    (1001) docker     (123)    14226 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/SRSR.py
+-rw-r--r--   0 runner    (1001) docker     (123)    12027 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/SSA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     3525 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/SSO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     7311 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/SSpiderA.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13417 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/SSpiderO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4963 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/STO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5903 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/SeaHO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4273 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/ServalOA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5871 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/TDO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6127 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/TSO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8296 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/WOA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     4472 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/WaOA.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5346 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/ZOA.py
+-rw-r--r--   0 runner    (1001) docker     (123)      238 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/swarm_based/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 15:12:13.461481 mealpy-2.5.3a1/mealpy/system_based/
+-rw-r--r--   0 runner    (1001) docker     (123)    28103 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/system_based/AEO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8307 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/system_based/GCO.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6992 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/system_based/WCA.py
+-rw-r--r--   0 runner    (1001) docker     (123)      238 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/system_based/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13359 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/tuner.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 15:12:13.461481 mealpy-2.5.3a1/mealpy/utils/
+-rw-r--r--   0 runner    (1001) docker     (123)      395 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)    13065 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/utils/history.py
+-rw-r--r--   0 runner    (1001) docker     (123)      848 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/utils/io.py
+-rw-r--r--   0 runner    (1001) docker     (123)     2519 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/utils/logger.py
+-rw-r--r--   0 runner    (1001) docker     (123)     8956 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/utils/problem.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6371 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/utils/termination.py
+-rw-r--r--   0 runner    (1001) docker     (123)     5577 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/utils/validator.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 15:12:13.465481 mealpy-2.5.3a1/mealpy/utils/visualize/
+-rw-r--r--   0 runner    (1001) docker     (123)      397 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/utils/visualize/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     9053 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/mealpy/utils/visualize/linechart.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 15:12:13.433481 mealpy-2.5.3a1/mealpy.egg-info/
+-rw-r--r--   0 runner    (1001) docker     (123)    90293 2023-03-21 15:12:13.000000 mealpy-2.5.3a1/mealpy.egg-info/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (123)     4178 2023-03-21 15:12:13.000000 mealpy-2.5.3a1/mealpy.egg-info/SOURCES.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        1 2023-03-21 15:12:13.000000 mealpy-2.5.3a1/mealpy.egg-info/dependency_links.txt
+-rw-r--r--   0 runner    (1001) docker     (123)      105 2023-03-21 15:12:13.000000 mealpy-2.5.3a1/mealpy.egg-info/requires.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        7 2023-03-21 15:12:13.000000 mealpy-2.5.3a1/mealpy.egg-info/top_level.txt
+-rw-r--r--   0 runner    (1001) docker     (123)       38 2023-03-21 15:12:13.465481 mealpy-2.5.3a1/setup.cfg
+-rw-r--r--   0 runner    (1001) docker     (123)     3455 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/setup.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-03-21 15:12:13.465481 mealpy-2.5.3a1/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)     9403 2023-03-21 15:09:26.000000 mealpy-2.5.3a1/tests/test_optimizer.py
```

### Comparing `mealpy-2.5.3/ChangeLog.md` & `mealpy-2.5.3a1/ChangeLog.md`

 * *Files 16% similar despite different names*

```diff
@@ -1,1424 +1,1422 @@
-
-Different versions of mealpy in terms of passing hyper-parameters. So please careful check your version before
-  using this library. (All releases can be found here: [Link](https://pypi.org/project/mealpy/#history))
-  * mealpy < 1.0.5
-  * 1.1.0 < mealpy < 1.2.2
-  * 2.0.0 <= mealpy <= 2.1.2
-  * mealpy == 2.2.0 
-  * mealpy == 2.3.0 
-  * 2.4.0 <= mealpy <= 2.4.2 (From this version, algorithms can solve discrete problem)
-  * mealpy >= 2.5.1 (Define model 1 time, solve multiple problems)
-
-
-# Version 2.5.3
-
-### Update 
-+ Fix bug in roulette-wheel-selection in Optimizer
-+ Update multitask with input modes and terminations
-+ Update Tuner with more input parameters
-+ Add LÃ©vy flight, and the selective opposition version of the artificial rabbit algorithm (LARO)
-+ Add Modified Gorilla Troops Optimization (MGTO)
-+ Update Giant Trevally Optimizer as requested by the authors
-  + Matlab101GTO: This version was used to produce the results presented in the paper.
-  + Matlab102GTO: This is a new version provided by the authors (Matlab link), which has been updated recently to 
-    reduce computation time.
-  + OriginalGTO: This version is implemented exactly as described in the paper.
-
-
-
-
-
-# Version 2.5.2
-
-### Update
-
-+ Fixed bug all fitness values are equals in function "get index roulette wheel selection" in Optimizer class
-+ Rename AdaptiveAEO by AugmentedAEO (Add reference)
-+ Update text of Dwarf Mongoose Optimization Algorithm belongs to Swarm-based group
-+ Fixed all tests and update all documents
-+ Update Termination class, you can now design multiple Stopping Conditions for Optimizer
-
-+ Bio-based group:
-  + Add Brown-Bear Optimization Algorithm (BBOA)
-    + Ref: A Novel Brown-bear Optimization Algorithm for Solving Economic Dispatch Problem 
-
-+ Human-based group:
-  + Add Heap-based optimizer (HBO)
-    + Ref: Heap-based optimizer inspired by corporate rank hierarchy for global optimization 
-  + Add War Strategy Optimization (WarSO)
-    + Ref: War Strategy Optimization Algorithm: A New Effective Metaheuristic Algorithm for Global Optimization
-  + Add Human Conception Optimizer (HCO)
-    + Ref: A novel Human Conception Optimizer for solving optimization problems
-
-+ Math-based group:
-  + Add Q-Learning Embedded Sine Cosine Algorithm (QLESCA)
-    + Ref: Q-learning embedded sine cosine algorithm (QLESCA)
-  + Add Success History Intelligent Optimizer (SHIO)
-    + Ref: Success history intelligent optimizer
-
-+ Physics-based group:
-  + Add rime-ice (RIME)
-    + Ref: RIME: A physics-based optimization
-  + Add Energy Valley Optimizer (EVO)
-    + Ref: Energy valley optimizer: a novel metaheuristic algorithm
-  + Add Chernobyl Disaster Optimizer (CDO)
-    + Ref: Chernobyl disaster optimizer (CDO): a novel meta-heuristic method for global optimization
-  + Add Fick's Law Algorithm (FLA)
-    + Ref: Not accepted yet
-
-+ Evolutionary-based group:
-  + Add CMA-ES and Simple-CMA-ES 
-    + Ref: Completely derandomized self-adaptation in evolution strategies.
-
-+ Swarm-based group:
-  + Add Wavelet Mutation and Quadratic Interpolation MRFO (WMQIMRFO)
-    + Ref: An enhanced manta ray foraging optimization algorithm for shape optimization of complex CCG-Ball curves
-  + Add Egret Swarm Optimization Algorithm (ESOA)
-    + Ref: Egret Swarm Optimization Algorithm: An Evolutionary Computation Approach for Model Free Optimization
-  + Add Sea-Horse Optimization (SeaHO)
-    + Ref: Sea-horse optimizer: A nature-inspired meta-heuristic for global optimization and engineering application
-  + Add Mountain Gazelle Optimizer (MGO)
-    + Ref: Mountain Gazelle Optimizer: A new Nature-inspired Metaheuristic Algorithm for Global Optimization Problems
-  + Add Golden jackal optimization (GJO)
-    + Ref: Golden jackal optimization: A novel nature-inspired optimizer for engineering applications
-  + Add Fox Optimizer (FOX)
-    + Ref: FOX: a FOX-inspired optimization algorithm
-  + Add Giant Trevally Optimizer (GTO)
-    + Ref: Giant Trevally Optimizer (GTO): A Novel Metaheuristic Algorithm for Global Optimization and Challenging Engineering Problems
-    
-+ **Warning**: Please check the original paper before you want to use these algorithms.
-  + Add Zebra Optimization Algorithm (ZOA)
-    + Ref: Zebra Optimization Algorithm: A New Bio-Inspired Optimization Algorithm for Solving Optimization Algorithm
-  + Add Osprey Optimization Algorithm (OOA)
-    + Ref: Osprey optimization algorithm: A new bio-inspired metaheuristic algorithm for solving engineering optimization problems
-  + Add Coati Optimization Algorithm (CoatiOA)
-    + Ref: Coati Optimization Algorithm: A New Bio-Inspired Metaheuristic Algorithm for Solving Optimization Problems
-  + Add Pelican Optimization Algorithm (POA)
-    + Ref: Pelican optimization algorithm: A novel nature-inspired algorithm for engineering applications
-  + Add Northern Goshawk Optimization (NGO)
-    + Ref: Northern Goshawk Optimization: A New Swarm-Based Algorithm for Solving Optimization Problems
-  + Add Serval Optimization Algorithm (ServalOA) 
-    + Ref: Serval Optimization Algorithm: A New Bio-Inspired Approach for Solving Optimization Problems
-  + Add Siberian Tiger Optimization (STO)
-    + Ref: Siberian Tiger Optimization: A New Bio-Inspired Metaheuristic Algorithm for Solving Engineering Optimization Problems
-  + Add Walrus Optimization Algorithm (WaOA)
-    + Ref: Walrus Optimization Algorithm: A New Bio-Inspired Metaheuristic Algorithm
-  + Add Tasmanian Devil Optimization (TDO)
-    + Ref: Tasmanian devil optimization: a new bio-inspired optimization algorithm for solving optimization algorithm
-  + Add Fennec Fox Optimization (FFO)
-    + Ref: Fennec Fox Optimization: A New Nature-Inspired Optimization Algorithm
-  + Add Teamwork Optimization Algorithm (TOA)
-    + Ref: Teamwork Optimization Algorithm: A New Optimization Approach for Function Minimization/Maximization
-
-
-
-
----------------------------------------------------------------------
-
-
-# Version 2.5.1
-
-### Update
-
-+ Add validator when variable can be both int/float value
-+ Add algorithms to evolutionary-based group:
-  + EliteSingleGA and EliteMultiGA class
-+ Add algorithms to math-based group:
-  + weIghted meaN oF vectOrs (INFO) algorithm 
-  + RUNge Kutta optimizer (RUN) 
-  + Circle Search Algorithm (CSA) 
-+ Add algorithms to bio-based group:
-  + Barnacles Mating Optimizer (BMO) 
-  + Symbiotic Organisms Search (SOS) 
-  + Seagull Optimization Algorithm (SOA) 
-  + Tunicate Swarm Optimization (TSA) 
-+ Add algorithms to swarm-based group:
-  + Hybrid Grey Wolf - Whale Optimization Algorithm (GWO_WOA)
-  + Marine Predators Algorithm (MPO) 
-  + Honey Badger Algorithm (HBA) 
-  + Sand Cat Swarm Optimization (SCSO) 
-  + Tuna Swarm Optimization (TSO)
-  + African Vultures Optimization Algorithm (AVOA) 
-  + Artificial Rabbits Optimization (ARO) 
-  + Artificial Gorilla Troops Optimization (AGTO) 
-  + Dwarf Mongoose Optimization Algorithm (DMOA) (weak algorithm)
-  
-+ Add algorithms to human-based group:
-  + Student Psychology Based Optimization (SPBO) (weak algorithm)
-
-+ Fix problem with 1 dimension
-+ Enhanced the get index roulette wheel selection in Optimizer class
-
-+ Update check parallel mode in Optimizer
-+ Update algorithms that don't support parallel modes
-+ Update the shebang #! with python codes
-+ Update examples
-
----------------------------------------------------------------------
-
-
-# Version 2.5.0
-
-### Update
-
-+ Add save and load model functionalities in mealpy.utils.io module.
-+ Add object that hold global/current worst solution in history object
-+ Add method create_pop_group() in Optimizer class 
-+ Add method before_initialization() in Optimizer class
-+ Refactor initialization() and after_initialization() in Optimizer class
-+ Remove before_evolve(), after_evolve(), and levy_flight() in Optimizer class
-+ Convert termination_start() and termination_end() to check_termination() in Optimizer class
-+ Remove boundary.py in utils
-+ Add set_parameters() and get_parameters() in all optimizers
-+ **Update new Problem class, move problem parameter from Optimizer to solve() function.**
-+ Fix bug printing same entry multiple times in logger.
-+ Fix bug exit() in Optimizer and utils package.
-+ **Update new Termination class, move termination parameter from Optimizer to solve() function.**
-+ **Add Multitask class that can run multiple optimizers on multiple problems with multiple trials.**
-+ Refactor all optimizers.
-+ **Add Tuner class that can help tuning hyper-parameters of optimizer.**
-+ Add examples how to build new optimizer.
-+ Add examples for Multitask and Tuner class.
-+ Update documents, examples, tests
-
-
----------------------------------------------------------------------
-
-# Version 2.4.2
-
-### Update
-
-+ Add n_workers variable to solve() function in Optimizer class
-  + n_workers only effect by parallel mode such as "process" and "thread"
-  + n_workers default value is None and based on concurrent.futures module
-+ Add 1 more Optional input parameter to the fitness function
-+ Fix bug trajectory chart
-+ Update fitness and objective chart
-+ Remove supporting Python < 3.7, Mealpy only supports Python >=3.7
-+ Group probabilistic is merged into math-based group
-+ Update documents, examples, tests
-
-
----------------------------------------------------------------------
-
-# Version 2.4.1
-
-### Update
-
-+ Add after_initialization(), termination_end() to Optimizer class 
-+ Update create_solution(), initialization() in Optimizer class
-+ Add "starting_positions" parameter to solve() function in Optimizer class
-+ Fix missing amend_position function in GA
-+ Fix bug fitness value in history object
-+ Update 4 training modes in all algorithms
-```code 
-Type: Parallel (no effect on updating process of agents) has 2 training modes:
-
-1. Process: Using multi-cores to update fitness for whole population
-2. Thread: Using multi-threads to update fitness for whole population
-
-Type: Sequential has 2 training modes
-
-3. Swarm (no effect on updating process): Updating fitness after the whole population move
-4. Single (effect on updating process): Updating fitness after each agent move
-```
-+ Add agent's history and starting positions to docs.
-
-
----------------------------------------------------------------------
-
-
-# Version 2.4.0
-
-### Update
-
-+ Add mealpy's support functions in terminal: help(mealpy), dir(mealpy)
-+ Add logger module (Logger class)
-+ Add validator module (Validator class)
-+ Change in Optimizer class:
-  + remove function get_global_best_global_worst_solution()
-  + replace save_optimization_process() by track_optimize_step() and track_optimize_process()
-  + update input of Problem and Termination object in Optimizer.
-  + add logger
-  + add validator and update all algorithms
-  + update function: get_special_solutions()
-  + rename function: crossover_arthmetic_recombination() to crossover_arithmetic()
-  + rename function: get_fitness_position() to get_target_wrapper()
-  + rename function: update_fitness_population() to update_target_wrapper_population()
-
-+ A default method: generate_position() in Problem class.
-+ Due to nature's characteristics of different problems, 2 methods can be designed for Optimizer to fit the problem 
-  are generate_position() and amend_position(). Both methods are moved from Optimizer 
-  class to Problem class, the create_solution() in Optimizer class will call these methods to create a new solution.
-+ Update History and Problem class
-  + design default amend_position function in Problem class 
-  + parameter: obj_weight changed to obj_weights
-  + add parameter: save_population to control 
-+ Add Pareto-like Sequential Sampling (PSS) to math_based group
-
-
----------------------------------------------------------------------
-
-# Version 2.3.0
-
-### Update
-
-+ All algorithms have been updated with the amend_position function for solving the discrete problem.
-+ Required packages are version reduction to fit python 3.6
-+ Add examples of how to design and custom a new algorithm based on this framework
-+ Add examples mealpy solve discrete problems (combinatorial, permutation)
-
-
----------------------------------------------------------------------
-
-# Version 2.2.0
-
-### Update models
-
-* You can pass the Problem dictionary or Problem object to the model.
-* You can pass the Termination dictionary or Termination object to the model.
-* The objective function is renamed as fitness function (obj_func -> fit_func)
-* The general format of a solution is: **\[position, target\]**
-    * position: numpy vector (1-D array)
-    * target: **\[fitness, list_objectives\]**
-    * list_objectives: **\[objective 1, objective 2, ...\]**
-    * After the training process, everything can be accessed via the objective "history" (model.history)
-
-* You can name your model and name your fitness function when creating a model 
-  * model(epoch, pop_size, ...., name='your model name', fit_name='your fitness function name')
-* Add new algorithms: 
-  * Gradient-Based Optimizer (GBO) in math_based group
-  * Chaos Game Optimization (CGO) in math_based group
-* Remove all dummy algorithms (Not supported anymore)
-* Fix bugs:
-  * Find idx of min-distance in BRO algorithm
-  * Update more strategy for GA algorithm
-  * Update child selection process in MA algorithm
-
-### Update others
-
-+ examples: Update several scenarios for mealpy with other frameworks
-+ document: Add document website (https://mealpy.readthedocs.io/)
-
----------------------------------------------------------------------
-
-# Version 2.1.2
-
-### Update
-
-+ Some algorithms have been updated in the GitHub release but not on PyPI such as Sparrow Search Algorithm.
-+ I try to synchronize the version on GitHub and PyPI by trying to delete the vers
-+ Add examples for applications of mealpy such as:
-  + Tuning hyper-parameter of neural network
-  + Replacing Gradient Descent optimizer in neural network
-  + Tuning hyper-parameter for other models such as SVM,...
-
----------------------------------------------------------------------
-
-# Version 2.1.1
-
-### Update
-
-+ Replace all .copy() operator by deepcopy() operator in module copy. Because shallow copy causing the problem with 
-  nested list inside list. Especially when copying population with nested of list position inside agent.
-+ Add the Knapsack Problem example: examples/applications/discrete-problems/knapsack-problem.py
-+ Add the Linear Regression example with Pytorch: examples/applications/pytorch/linear_regression.py
-+ Add tutorial videos "How to use Mealpy library" to README.md
-
----------------------------------------------------------------------
-
-# Version 2.1.0
-
-### Change models
-
-+ Move all parallel function to Optimizer class
-+ Remove unused methods in Optimizer class
-+ Update all algorithm models with the same code-style as previous version
-+ Restructure some hard algorithms include BFO, CRO.
-
-### Change others
-
-+ examples: Update examples for all new algorithms
-+ history: Update history of MHAs
-+ parallel: Add comment on parallel and sequential mode
-+ Add code-of-conduct
-+ Add the complete example: examples/example_full_v210.py
-
----------------------------------------------------------------------
-
-# Version 2.0.0
-
-### Change models
-+ Update entire the library based on Optimizer class:
-    + Add class Problem and class Termination
-    + Add 3 training modes (sequential, thread and process)
-    + Add visualization charts:
-        + Global fitness value after generations
-        + Local fitness value after generations
-        + Global Objectives chart (For multi-objective functions)
-        + Local Objective chart (For multi-objective functions)
-        + The Diversity of population chart
-        + The Exploration verse Exploitation chart
-        + The Running time chart for each iteration (epoch / generation)
-        + The Trajectory of some agents after generations 
-+ My batch-size idea is removed due to the parallel training mode
-+ User can define the Stopping Condition based on:
-    + Epoch (Generation / Iteration) - default
-    + Function Evaluation 
-    + Early Stopping
-    + Time-bound (The running time for a single algorithm for a single task)
-
-
-### Change others
-
-+ examples: Update examples for all new algorithms
-+ history: Update history of MHAs
-
----------------------------------------------------------------------
-
-# Version 1.2.2
-
-### Change models
-
-+ Add Raven Roosting Optimization (RRO) and its variants to Dummy group
-    + OriginalRRO: The original version of RRO
-    + IRRO: The improved version of RRO
-    + BaseRRO: My developed version (On this version work)
-    
-+ Add some newest algorithm to the library
-    + Arithmetic Optimization Algorithm (AOA) to Math-based group
-        + OriginalAOA: The original version of AOA
-    + Aquila Optimizer (AO) to Swarm-based group
-        + OriginalAO: The original version of AO 
-    + Archimedes Optimization Algorithm (ArchOA) to Physics-based group
-        + OriginalArchOA: The original version of ArchOA
-
-### Change others
-
-+ examples: Update examples for all new algorithms
-+ history: Update history of MHAs
-
----------------------------------------------------------------------
-
-# Version 1.2.1
-
-### Change models
-
-+ Add Coyote Optimization Algorithm (COA) to Swarm-based group
-+ Update code LCBO and MLCO
-+ Add variant version of:
-    + WOA: Hybrid Improved WOA 
-    + DE:
-        + SADE: Self-Adaptive DE
-        + JADE: Adaptive DE with Optional External Archive
-        + SHADE: Success-History Based Parameter Adaptation DE 
-        + LSHADE: Linear Population Size Reduction for SHADE
-    + PSO: Comprehensive Learning PSO (CL-PSO)
-    
-### Change others
-
-+ examples: Update examples for all new algorithms
-
----------------------------------------------------------------------
-
-# Version 1.2.0
-
-### Change models
-
-+ Fix bug reduction dimension in FOA
-+ Update Firefly Algorithm for better timing performance
-  
-+ Add Hunger Games Optimization (HGS) to swarm-based group
-+ Add Cuckoo Search Algorithm (CSA) to swarm-based group
-
-+ Replace Root.\_\_init\_\_() function by super().\_\_init()\_\_ function in all algorithms.
-
-### Change others
-
-+ history: Update new algorithms
-+ examples: Update all the examples based on algorithm's input
-
----------------------------------------------------------------------
-
-
-# Version 1.1.0
-
-### Change models
-
-+ Update the way to passing hyper-parameters to root.py file (Big change)
-
-+ Update all the hyper-parameters to all algorithms available.
-  
-+ Fix all the division by 0 in some algorithms.
-
-### Change others
-
-+ examples: Update all the examples of all algorithms
-
----------------------------------------------------------------------
-
-
-# Version 1.0.5
-
-### Change models
-+ System-based group added: 
-    + Water Cycle Algorithm (WCA)
-
-+ Human-based group added:
-    + Imperialist Competitive Algorithm (ICA)
-    + Culture Algorithm (CA)
-
-+ Swarm-based group added:
-    + Salp Swarm Optimization (SalpSO)
-    + Dragonfly Optimization (DO)
-    + Firefly Algorithm (FA)
-    + Bees Algorithm (Standard and Probilistic version)
-    + Ant Colony Optimization (ACO) for continuous domain
-    
-+ Math-based group:
-    + Add Hill Climbing (HC) 
-
-+ Physics-based group:
-    + Add Simulated Annealling (SA) 
-    
-### Change others
-
-+ models_history.csv: Update history of meta-heuristic algorithms
-+ examples: Add examples for all of above added algorithms.
-
----------------------------------------------------------------------
-
-
-# Version 1.0.4
-
-### Change models
-
-+ Changed category of Sparrow Search Algorithm (SpaSA) from Fake to Swarm-based group:
-    + Added the: OriginalSpaSA
-        + This version is taken from the original paper, very weak algorithm
-    + BaseSpaSA: My changed version
-        + Changed equations
-        + Changed flows and operators
-        + This version become the BEST algorithm 
-
-+ Added Jaya Algorithm to Swarm-based group:
-    + OriginalJA: The original version from original paper
-    + BaseJA: My version of original JA for better running time.
-        + Remove all third loop in algorithm
-        + Change the second random variable r2 to Gaussian instead of uniform
-    + LJA: The original version of: Levy-flight Jaya Algorithm (LJA)
-        + Paper: An improved Jaya optimization algorithm with Levy flight
-        + Link: https://doi.org/10.1016/j.eswa.2020.113902
-        + Notes:
-            + This version I still remove all third loop in algorithm
-            + The beta value of Levy-flight equal to 1.8 as the best value in the paper.
-
-+ DE, its state-of-the-art variants.
-    + DESAP: including DESAP-Abs and DESAP-Rel
-        + The main ideas is identified the population size without user-defined. Proposed equation: 
-            + Initial ps_init = 10*n (n: is the problem size, number of dimensions)
-            + DESAP-Abs: ps = round(ps_init + N (0, 1)), (N: is Gaussian value)
-            + DESAP-Rel: ps = round(ps_init + U (-0.5, 0.5)), (U: is uniform random function)
-            
-+ Added Battle Royale Optimization Algorithm to Fake-algorithm
-    + OriginalBRO:
-        + The paper is very different than the author's matlab code. Even the algorithm's flow is wrong with index i, j.
-        + I tested the results is very slow convergence, even with small #dimensions. I guess that is why he cloned the
-        crossover process of Genetic Algorithm to his algorithm in the code (but not even mention it in the paper) to
-         get the results in the paper. Don't know what to say about this. 
-    + BaseBRO:
-        + First, I removed all third loop in the algorithm for faster computation.
-        + Second, Re-defined the algorithm's flow and algorithm's ideas
-        
-+ Added Fruit-fly Optimization Algorithm and its variants to Swarm-based group:
-    + OriginalFOA:
-        + This algorithm is the weakest algorithm in MHAs. It can't run with complicated objective function.
-    + BaseFOA:
-        + I changed the fitness function (smell function) by taking the distance each 2 adjacent dimensions
-         --> Number of variables reduce from N to N-1
-        + Update the position if only it find the better fitness value.
-    + WFOA:
-        + The original version of Whale Fruit-fly Optimization Algorithm (WFOA)
-        + Paper: Boosted Hunting-based Fruit Fly Optimization and Advances in Real-world Problems
-        + From my point of view, this algorithm is almost the same as Whale, only different in calculate fitness
-         function. So it is not surprise that It outperforms BaseFOA
-         
-        https://www.sciencedirect.com/science/article/abs/pii/S0957417420307545
-        https://sci-hub.se/10.1016/j.eswa.2020.113976
-        https://sci-hub.se/10.1016/j.eij.2020.08.003
-        https://sci-hub.se/10.1016/j.eswa.2020.113902
-        https://www.x-mol.com/paper/1239433029684543488
-    
-+ Update root.py
-    + Added improved_ms() function based on mutation and search mechanism - current better than levy-flight technique
-
-  
-
-### Change others
-+ models_history.csv: Update history of meta-heuristic algorithms        
-+ examples: 
-    + Add FBIO examples with large-scale benchmark functions
-    
----------------------------------------------------------------------
-
-# Version 1.0.3
-
-### Change models
-+ Update AEO and its variants
-    + Replace LevyAEO by AdaptiveAEO by using levy-flight in both Consumption and Decomposition process.
-    + Added Improved version by paper "Artificial ecosystem optimizer for parameters identification of proton exchange
-     membrane fuel cells model"
-    + Added Enhanced version by paper "An Enhanced Artificial Ecosystem-Based Optimization for Optimal Allocation of
-      Multiple Distributed Generations"
-    + Added Modified version by paper "Effective Parameter Extraction of Different Polymer Electrolyte Membrane Fuel
-     Cell Stack Models Using a Modified Artificial Ecosystem Optimization Algorithm"
-
-+ Update LCBO and its variants (ILCO > MLCO > LCBO)
-    + Changed LevyLCBO to ModifiedLCO 
-    + Added the best version ImprovedLCO -- current best version
-    
-+ Update EO and its variants (MEO > AEO > LevyEO > EO))
-    + Added ModifiedEO by paper "An efficient equilibrium optimizer with mutation strategy for numerical optimization"
-        + Currently the best version of EO
-        + Based on mutation strategy and gaussian distribution search
-    + Added AdaptiveEO by paper "A novel interdependence based multilevel thresholding technique using adaptive equilibrium optimizer"
-        + The second best version of EO, after ModifiedEO
-        + Based on Fitness average and memory saving of previous iteration
-
-+ Update GWO and its variants (GWO > RW_GWO)
-    + Added Random Walk Grey Wolf Optimization - RW_GWO
-    + OriginalGWO always perform better than RW_GWO
-    
-    
-+ Update root.py
-    + Added improved_ms() function based on mutation and search mechanism - current better than levy-flight technique
-    
-+ Add Forensic-Based Investigation Optimization (FBIO) to human_based group: 
-
-  
-
-### Change others
-+ models_history.csv: Update history of meta-heuristic algorithms        
-+ examples: 
-    + Add FBIO examples with large-scale benchmark functions
-    
----------------------------------------------------------------------
-
-# Version 1.0.2
-
-### Change models
-+ Update : CEM
-+ Fix bug division by 0 in: IWO, SMA
-
-+ Add Forensic-Based Investigation Optimization (FBIO) to human_based group: 
-    + OriginalFBIO: the original version
-    + BaseFBIO: my modified version:
-        + Implement the fastest way (Remove all third loop)
-        + Change equations
-        + Change the flow of algorithm
-  
-
-### Change others
-+ models_history.csv: Update history of meta-heuristic algorithms        
-+ examples: 
-    + Add FBIO examples with large-scale benchmark functions
-    
----------------------------------------------------------------------
-
-
-# Version 1.0.1
-
-### Change models
-+ Added Slime Mould Algorithm (SMA) to bio_based group:
-    + OriginalSMA: the original version of SMA
-    + BaseSMA: my modified version:
-        + Selected 2 unique and random solution to create new solution (not to create variable) --> remove third loop in original version
-        + Check bound and update fitness after each individual move instead of after the whole population move in the original version
-        + My version not only faster but also better
-        
-+ Added Spotted Hyena Optimizer (SHO) to swarm_based group:
-    + OriginalSHO: my modified version
-
-       
-+ Add category for questionable algorithm or papers (called fake): 
-    + Butterfly Optimization Algorithm (BOA) to swarm_based group:
-        + OriginalBOA: this algorithm is made up one 
-        + AdaptiveBOA:
-        + BaseBOA:
-            + Look at the author of this algorithm
-            + https://scholar.google.co.in/citations?hl=en&user=KvcHovcAAAAJ&view_op=list_works&sortby=pubdate
-            + It is interesting to note that there have been many variant versions of BOA created since 2015, even though the inventor of BOA only published it in 2019. This raises some questions about the origins of these variant algorithms and how they came to be.
-             
-    + Sandpiper Optimization Algorithm (SOA) to swarm_based group:
-        + OriginalSOA: the original version is made up one
-            + This algorithm suffers from local optimal and lower convergence rate. 
-            + It cannot update the position, so how to converge without update position?
-            + I am curious about the algorithm's publication history, as I have found it submitted to multiple journals.
-            + A detailed explain in this comment section 
-            (https://www.researchgate.net/publication/334897831_Sandpiper_optimization_algorithm_a_novel_approach_for_solving_real-life_engineering_problems/comments)
-        + BaseSOA: my modified version which changed some equations and flow.
-        
-    + Sooty Tern Optimization Algorithm (STOA) is another name of Sandpiper Optimization Algorithm (SOA) 
-        + If you read the paper, you will see the similarity between these two 
-    
-    + Blue Monkey Optimization (BMO) to swarm_based group:
-        + OriginalBMO: 
-            + It is a made-up algorithm with a similar idea to "Chicken Swarm Optimization," which raises questions about its originality.
-            + The pseudo-code is confusing, particularly the "Rate equation," which starts as a random number and then becomes a vector after the first loop. 
-            + The movement of the blue monkey and children is the same equations???
-            + The algorithm does not check the bound after updating the position, which can cause issues with the search space.
-            + The algorithm does not provide guidance on how to find the global best from the blue monkey group or child group.
-        + BaseBMO: my modified version which used my knowledge about meta-heuristics to do it. 
-
-
-### Change others
-+ models_history.csv: Update history of meta-heuristic algorithms        
-+ examples: 
-    + Update and Add examples for all algorithms
-    + All examples tested with CEC benchmark and large-scale problem (1000 - 2000 dimensions)
-    
----------------------------------------------------------------------
-
-
-# Version 1.0.0
-
-### Change models
-+ Change root model, then all of the algorithms are now change
-    + domain_range -> lower bound and upper bound
-    + log -> verbose
-    + objective_func -> obj_func
-    + batch-size training -> Inspired by the idea of batch-size training in gradient descent algorithm
-+ Idea of batch-size training in meta-heuristics
-    + Some algorithms update the global best solution when all of the individuals in the population have moved to a new position.
-        + This idea is a similarity to the training the whole dataset in GD
-    + But some algorithms update after each move to a new position.
-        + This idea is a similarity as SGD
-    + But the point here is if the algorithm doesn't take advantage of the global best solution when updating individual 
-    the position then GD or SGD gives the same results.
-    
-    + So my idea of batch-size training here is very simple, after batch-size of individuals move, then we will update
-    the global best solution. So:
-        + batch-size = 1 ==> SGD
-        + batch-size = population-size ==> GD 
-        + batch-size should set = 10% / 25% / 50% of your population size
-    
-    + Some algorithms can't apply the idea of batch-size. For examples:
-        + If the original algorithm has already divided the population into m-clan (m-group) --> No need batch-size here
-        + If the original algorithm contains multiple-part. Each part contains several types of updating --> No need too.
-        
-+ For music_based:
-    + BaseHS (HS): Is the one can't use batch-size idea, but not belong to any reason above.
-
-+ For math_based:
-    + BaseSCA (SCA): Updated with batch-size idea. Keep the original version for reference.
-    
-+ For system_based:
-    + BaseAEO (AEO): Updated with the batch-size ideas and some of my new ideas. Still keep the original version 
-    + BaseGCO (GCO): Updated with batch-size idea. Keep the original version
-    
-+ For bio_based:
-    + BaseIWO (IWO):
-    + OriginalWHO (WHO):
-    + BaseBBO (BBO):
-        + Remove all third loop, make algorithm n-times faster than original 
-        + In the migration step, instead of select solution based on the wheel in every variable in position, 
-                  using the wheel and select a single position and update based on its all variable of that position.
-    + BaseVCS (VCS):
-        + Remove all third loop, make algorithm n-times faster than original
-        + In Immune response process, updating the whole position instead of updating each variable in position 
-        + Drop batch-size idea to 3 main processes of this algorithm, make it more robust
-    + BaseSBO (SBO):
-        + Remove all third loop, n-times faster than original
-        + No need equation (1, 2) in the paper, calculate the probability by roulette-wheel. Also can handle negative values
-        + Apply batch-size idea
-    + BaseBWO (BWO): This is my changed version and worked. 
-        + Using k-way tournament selection to select parent instead of randomizing
-        + Repeat cross-over population_size / 2 instead of n_var/2
-        + Mutation 50% of position instead of swap only 2 variable in a single position
-        + OriginalBWO: is made up algorithm and just a variant of Genetic Algorithm
-    + BaseAAA (AAA): This is my changed version but still not working
-        + OriginalAAA: is made up algorithm taken from DE and CRO 
-        + I realize in the original paper, parameters, and equations not clear.
-        + In the Adaptation phase, what is the point of saving starving value when it doesn't affect the solution at all?
-        + The size of the solution always = 2/3, so the friction surface will always stay at the same value.
-        + The idea of the equation seems like taken from DE, the adaptation and reproduction process seem like taken from CRO.
-        + Appearance from 2015, but still now 2020 none of Matlab code or python code about this algorithm.
-    + EOA: 
-        + OriginalEOA: My modified version from original Matlab version
-            + The original version from Matlab code above will not work well, even with small dimensions.
-            + I changed updating process
-            + Changed the Cauchy process using x_mean
-            + Used global best solution
-            + Remove the third loop for faster 
-   
-+ For human_based:
-    + BaseTLO (TLO):
-        + Remove all third loop
-        + Apply batch-size idea
-    + BSO:
-        + OriginalBSO: This is original version
-        + ImprovedBSO: My improved version with levy-flight and removal of some parameters.
-    + QSA: 4 variant version now runs faster than n-times Original version
-        + BaseQSA: Remove all third loop, apply the idea of the global best solution
-        + OppoQSA: Based on BaseQSA, apply the idea of opposition-based learning technique
-        + LevyQSA: Based on BaseQSA, apply the idea of levy-flight in business 2
-        + ImprovedQSA: Combination of OppoQSA and LevyQSA
-        + OriginalQSA: The original version of QSA. Not working well
-    + SARO:
-        + BaseSARO: My version but not better than the original version, just faster than
-        + OriginalSARO: Convergence rate better than base version but very slow in time comparison.
-    + LCBO:
-        + BaseLCBO: Is the original version
-        + LevyLCBO: Use levy-flight and is the best among 3 version
-        + ImprovedLCBO: 
-    + SSDO:
-        + OriginalSSDO: This is the original version
-        + LevySSDO: Apply the idea of levy-flight
-    + GSKA:
-        + OriginalGSKA: This is the original version, very slow for large-scale and slow convergence
-        + BaseGSKA: Remove all third loop, change equations and ideas, faster than Original version
-    + CHIO: This algorithm hasn't done yet. Don't use it yet
-        + OriginalCHIO: Can fail at any time 
-        + BaseCHIO: Can't convergence
-        
-
-+ For physics_based group:
-    + WDO: 
-        + OriginalWDO: is the original version
-    + MVO:
-        + OriginalMVO: is weak and slow algorithm 
-        + BaseMVO: can solve large-scale optimization problems
-    + TWO:
-        + OriginalTWO: is the original version
-        + OppoTWO: using opposition-based techniques (better than original version)
-        + LevyTWO: using only levy-flight and better than OppoTWO
-        + ImprovedTWO: using opposition-based and levy-flight and better than all others
-    + EFO:
-        + OriginalEFO: is the original version, run fast but slow convergence
-        + BaseEFO: using levy-flight for large-scale dimension
-    + NRO:
-        + OriginalNRO: is the original version, efficient even with large-scale due to levy-flight techniques
-        but running-time will slow because third loop.
-    + HGSO:
-        + OriginalHGSO: is the original version
-        + OppoHGSO: uses opposition-based technique
-        + LevyHGSO: uses levy-flight technique
-    + ASO:
-        + OriginalASO: is the original version
-    + EO:
-        + OriginalEO: is the original version
-        + LevyEO: uses levy-flight technique for large-scale dimensions
-
-+ For probabilistic_based group:
-    + CEM:
-        + OriginalCEM: is the original version
-        + CEBaseSBO: is the hybrid version of Satin Bowerbird Optimizer (SBO) and CEM
-        + CEBaseSSDO: is the hybrid version of Social-Sky Driving Optimization (SSDO) and CEM
-        + CEBaseLCBO and CEBaseLCBONew: are the hybrid version of Life Choice Based Optimization and CEM
-
-+ For evolutionary_based group: (Not good for large-scale problems)
-    + EP:
-        + OriginalEP: is the original version
-        + LevyEP: applied levy-flight 
-    + ES:
-        + OriginalES: is the original version
-        + LevyES: applied levy-flight
-    + MA:
-        + OriginalMA: is the original version, can't remove third loop, very slow algorithm
-    + GA:
-        + BaseGA: is the original version 
-    + DE:
-        + BaseDE: is the original version
-    + FPA:
-        + OriginalFPA: is the original version (already use levy-flight in it)
-    + CRO:
-        + OriginalCRO: is the original version
-        + OCRO: is the opposition-based version
-
-+ For swarm_based group: 
-    + PSO:
-        + OriginalPSO: is the original version
-        + PPSO: Phasor particle swarm optimization: a simple and efficient variant of PSO
-        + PSO_W: A modified particle swarm optimizer
-        + HPSO_TVA: New self-organising  hierarchical PSO with jumping time-varying acceleration coefficients
-    + ABC:
-        + OriginalABC: my version and taken from Clever Algorithms
-    + FA:
-        + OriginalFA: is the original version, running slow even the all third loop already removed
-    + BA:
-        + OriginalBA: is the original version 
-        + BasicBA: is also the original version with improved parameters
-        + AdaptiveBA: my modified version without A parameter
-    + PIO: 
-        + This is made up algorithm, after changing almost everything, the algorithm works
-        + BasePIO: My base version
-        + LevyPIO: My version based on levy-flight for large-scale dimensions
-    + GWO:
-        + OriginalGWO: is the original version
-    + ALO:
-        + OriginalALO: is the original version, slow and less efficient
-        + BaseALO: my modified version which using matrix multiplication for faster 
-    + MFO:
-        + OriginalMFO: is the original version
-        + BaseMFO: my modified version which remove third loop, change equations and flow
-    + EHO:
-        + OriginalEHO: is the original version
-        + LevyEHO: my levy-flight version of EHO
-    + WOA:
-        + OriginalWOA: is the original version
-    + BSA:
-        + OriginalBSA: is the original version
-    + SRSR:
-        + OriginalSRSR: is the original version
-    + GOA:
-        + OriginalGOA: is the original version with some changed from me:
-            + I added normal() component to Eq, 2.7
-            + Changed the way to calculate distance between two location
-            + Used batch-size idea    
-    + MSA:
-        + OriginalMSA: is my modified version with some changed from original matlab code version
-    + RHO:
-        + OriginalRHO: is the original version, not working 
-        + BaseRHO: my changed version 
-        + LevyRHO: levy-flight for large-scale dimensions
-            + Change the flow of algorithm
-            + Uses normal in equation instead of uniform
-            + Uses levy-flight instead of uniform-equation
-    + EPO:
-        + Original: is the original version, can't converge at all
-        + BaseEPO: my modified version:
-            + First: I changed the Eq. T_s and no need T and random R.
-            + Second: Updated the old position if fitness value better or kept the old position if otherwise
-            + Third: Remove the third loop for faster
-            + Fourth: Batch size idea
-            + Fifth: Add normal() component and change minus sign to a plus
-    + NMRA:
-        + OriginalNMRA: The original version
-            + The Matlab code of paper's author here: https://github.com/rohitsalgotra/Naked-Mole-Rat-Algorithm
-            + Matlab code and paper are very different. 
-        + LevyNMRA: My levy-flight version 
-        + ImprovedNMRA:
-            + Using mutation probability
-            + Using levy-flight
-            + Using crossover operator
-    + BES:
-        + OriginalBES: the original version
-    + PFA:
-        + OriginalPFA: is the original version, I did redesign the equation based on distance.
-            + The problem with using the distance is that when increasing the bound and dimensions 
-            --> distance increase very fast --> new position will always over the bound
-            --> we should divide the distance to a number of dimensions and the distance of the bound (upper-lower) to
-            stabilize the distance 
-            + The second problem is a new solution based on all other solutions --> we should also divide the new solution
-            by the population size to stabilize it.
-        + OPFA: is an enhanced version of PFA based on Opposition-based Learning (better than OriginalPFA)
-        + ImprovedPFA: (sometime better than OPFA)
-            + using opposition-based learning
-            + using levy-flight 2 times
-    + SFO:
-        + OriginalSFO: is the original version
-        + ImprovedSFO: my improved version in which
-            + Reform Energy equation,
-            + No need parameter A and epxilon
-            + Based on idea of Opposition-based Learning
-    + SLO:
-        + OriginalSLO: is the changed version from my student
-        + ImprovedSLO: is the improved version 
-    + SpaSA:
-        + BaseSpaSA: is my modified version, the original paper has several unclear parameters and equations
-    + MRFO:
-        + OriginalMRFO: is the original version
-        + LevyMRFO: is my modified version based on levy-flight
-    + HHO:
-        + OriginalHHO: is the original version 
-    + SSA:
-        + OriginalSSA: is the original version
-        + BaseSSA: my modified version 
-    + CSO:
-        + OriginalCSO: is the original version
-    + BFO:
-        + BaseBFO: is the adaptive version of BFO
-        + OriginalBFO: is the original version taken from Clever Algorithms
-    + SSO:
-        + OriginalSSO: is the original version
-    
-
-### Change others
-+ models_history.csv: Update history of meta-heuristic algorithms        
-+ examples: 
-    + Update and Add examples for all algorithms
-    + All examples tested with CEC benchmark and large-scale problem (1000 - 2000 dimensions)
-    
----------------------------------------------------------------------
-
-
-
-# Version 0.8.6
-
-### Change models
-+ Fix bug return position instead of fitness value in:
-    + TLO 
-    + SARO
-+ Update some algorithms:
-    + SLO
-    + NRO
-    + ABC
-    
-+ Added some variant version of PSO:
-    + PPSO (Phasor particle swarm optimization: a simple and efficient variant of PSO)
-    + PSO_W (A modified particle swarm optimizer)
-    + HPSO_TVA (New self-organising  hierarchical PSO with jumping time-varying acceleration coefficients)
-    
-+ Added more algorithm in Swarm-based algorithm
-    + SpaSA: Sparrow Search Algorithm (Same name SSA as Social Spider Algorithm --> I changed it to SpaSA)
-
-### Change others
-+ models_history.csv: Update history of meta-heuristic algorithms        
-+ examples: Added new examples of: 
-    + PSO and variant of PSO
-    + Update all examples which now using CEC functions
-    
----------------------------------------------------------------------
-
-# Version 0.8.5
-
-### Change models
-+ Fix bugs in several algorithm related to Division by 0, sqrt(0), 
-+ Added more algorithm in Probabilistic-based algorithm
-    + CEBaseSBO
-+ Added selection by roulette wheel in root (This method now can handle negative fitness values)
-+ Changed GA using roulette wheel selection instead of k-tournament method
-
-### Change others
-+ models_history.csv: Update history of meta-heuristic algorithms        
-+ examples: Added new examples of: 
-    + CE_SSDO, CE_SBO
-    + GA, SBO
-    
----------------------------------------------------------------------
-
-# Version 0.8.4
-
-### Change models
-+ Fix bugs in Probabilistic-based algorithm
-    + OriginalCEM
-    + CEBaseLCBO
-    + CEBaseLCBONew: No levy
-    + CEBaseSSDO
-+ Fix bugs in Physics-based algorithm
-    + LevyEO
-+ Fix bug in Human-based algorithm
-    + LCBO
-
-+ Added Coronavirus Herd Immunity Optimization (CHIO) in Human-based group
-    + Original version: OriginalCHIO
-        + This version stuck in local optimal and early stopping because the infected case quickly become immunity
-        + In my version, when infected case all change to immunity. I make 1/3 population become infected then
-         optimization step keep going.
-    + My version: BaseCHIO
-    
----------------------------------------------------------------------
-
-# Version 0.8.3
-
-### Change models
-+ Probabilistic-based algorithm
-    + Added Cross-Entropy Method (CEM)
-    + Added CEM + LCBO
-    + Added CEM + SSDO
-    
----------------------------------------------------------------------
-
-# Version 0.8.2
-
-### Change models
-+ Bio-based group 
-    + Added Virus Colony Search (VCS)
-        + BaseVCS: This is the very simple version of VCS. Not the original one in the paper 
-        
-+ Physics-based group
-    + Remove EO not good version
-    
-+ Human-based group
-    + Fix LCBO sort population in initialization process
-    
-+ Added new group: Probabilistic-based algorithm
-    + Added Cross-Entropy Method (CEM)
-    
-### Change others
-+ models_history.csv: Update history of meta-heuristic algorithms        
-+ examples: Added new examples of: 
-    + BaseVCS
-    + OriginalCEM
-
----------------------------------------------------------------------
-
-
-# Version 0.8.1
-
-### Change models
-+ Evolutionary-based group 
-    + Added Evolution Strategies (ES)
-        + OriginalES
-        + LevyES: Idea ==> Top population being mutated based on strategy, Left population try to get out of their
-         position based on levy-flight. 
-    + Added Evolution Programming (EP)
-        + OriginalEP: Different than ES by operator and bout_size
-        + LevyEP: Idea ==> Top population being selected based on tournament strategy round, 50% Left population
-             try to make a comeback to take the good position with levy jump.
-    + Added Memetic Algorithm (MA)
-        + OriginalMA
-    
-### Change others
-+ models_history.csv: Update history of meta-heuristic algorithms        
-+ examples: Added new examples of: 
-    + OriginalES and LevyES
-    + OriginalEP and LevyEP
-    + OriginalMA
-
----------------------------------------------------------------------
-
-
-# Version 0.8.0
-
-### Change models
-+ Swarm-based group
-    + Added Elephant Herding Optimization (EHO) in Swarm-based group
-        + OriginalEHO
-        + LevyEHO: Changed the Uniform distribution the "Separating operator" by Levy-flight (50%) and Gaussian(50%) 
-    + Added Pigeon-Inspired Optimization (PIO) in Swarm-based group
-        + BasePIO (Changed almost everything include flow the algorithm)
-        + LevyPIO 
-            + Changed flow of algorithm
-            + Removed some unnecessary loop
-            + Removed some parameters
-            + Added the levy-flight in second step make algorithm more robust
-    + Added Fireworks Algorithm  (FA)
-    
-+ Human-based group
-    + Added Gaining Sharing Knowledge-based Algorithm (GSKA)
-    + Added Brain Storm Optimization Algorithm (BSO)
-        + OriginalBSO
-        + ImprovedBSO (Remove some parameters + Changed Equations + Levy-flight + OriginalBSO)
-
-+ Evolutionary-based group 
-    + Added Flower Pollination Algorithm (FPA)
-
-+ Bio-based group
-    + Added Artificial Algae Algorithm (Not working yet)
- 
- 
-### Change others
-+ models_history.csv: Update history of meta-heuristic algorithms        
-+ examples: Added new examples of: 
-    + OriginalFA 
-    + OriginalAAA
-    + OriginalBSO and ImprovedBSO 
-    + BaseGSKA
-    + BasePIO and LevyPIO
-    + OriginalEHO and LevyEHO
-    + OriginalFPA
-    
-
-
----------------------------------------------------------------------
-
-# Version 0.7.5
-
-### Change models
-+ Added Sea Lion Optimization in Swarm-based group
-    + OriginalSLO
-    + ImprovedSLO (Shrinking Encircling + Levy + SLO)
- 
-### Change others
-+ models_history.csv: Update history of meta-heuristic algorithms        
-+ examples: Added new examples of: OriginalSLO and ImprovedSLO 
-
-
----------------------------------------------------------------------
-
-
-# Version 0.7.4
-
-### Change models
-+ Added Coral Reefs Optimization in Evolutionary-based group
-    + OriginalCRO
-    + OCRO (Opposition-based CRO)
- 
-### Change others
-+ models_history.csv: Update history of meta-heuristic algorithms        
-+ examples: Added new examples of: OriginalCRO and CRO   
-
-
----------------------------------------------------------------------
-
-
-# Version 0.7.3
-
-### Change models
-+ Added Levy-flight and Opposition-based techniques in Root.py
-+ Fixed codes include levy-flight and opposition-based of:
-    + QSA
-    + HGSO
-    + TWO
-    + NMRA
-    + PFA
-    + SFO
-    + SSO
-+ Added new modified version of models based on Levy-flight:
-    + LCBO (LevyLCBO)
-    + SSDO (LevySSDO)
-    + EO (LevyEO)
-    + AEO (LevyAEO)
-    + MRFO (LevyMRFO)
-    + NMRA (LevyNMRA)
- 
-### Change others
-+ models_history.csv: Update history of meta-heuristic algorithms        
-+ examples: Added new examples tested base-version and levy-version of: LCBO, SSDO, EO, AEO, MRFO, NMRA   
-
----------------------------------------------------------------------
-
-# Version 0.7.2
-
-### Change 
-+ Fix GA and WOA errors
-
----------------------------------------------------------------------
-
-# Version 0.7.1
-
-### Change 
-+ Change input parameters of the root.py file 
-+ Update the changed of input parameters of all algorithms
-+ Update examples folders
-
----------------------------------------------------------------------
-
-# Version 0.7.0
-
-### Change models
-+ Added new kind of meta-heuristics: math-based and music-based
-+ Math_based:
-    * SCA - Sine Cosine Algorithm
-        + OriginalSCA: The original version
-        + BaseSCA: My version changed the flow 
-+ Music_based:
-    * HS - Harmony Search
-        + OriginalHS: The original version - not working
-        + BaseHS: My version which changed a few things 
-            * First I changed the random usaged of harmony memory by best harmoney memory
-            * The fw_rate = 0.0001, fw_damp = 0.9995, number of new harmonies = population size (n_new = pop_size)
-            
-### Change others
-+ models_history.csv: Update history of meta-heuristic algorithms        
-        
----------------------------------------------------------------------
-
-# Version 0.6.0
-
-### Change models
-+ Added new kind of meta-heuristics: system-based 
-+ System_based: Added the latest system-inspired meta-heuristic algorithms
-    * GCO - Germinal Center Optimization
-    * AEO - Artificial Ecosystem-based Optimization
-     
-### Change others
-+ models_history.csv: Update history of meta-heuristic algorithms        
-        
----------------------------------------------------------------------
-
-# Version 0.5.1
-
-### Change models
-+ Bio_based: Added the latest bio-inspired meta-heuristic algorithms
-    * SBO - Satin Bowerbird Optimizer
-    * WHO - Wildebeest Herd Optimization
-        + OriginalWHO: The original version
-        + OriginalWHO: I changed the flow of algorithm
-    * BWO - Black Widow Optimization
-    
-### Change others
-+ models_history.csv: Update history of meta-heuristic algorithms        
-        
----------------------------------------------------------------------
-
-
-# Version 0.5.0
-
-### Change models
-+ Added new kind of meta-heuristics: bio-based (biology-inspired) 
-+ Bio_based: Added some classical bio-inspired meta-heuristic algorithms
-    * IWO - Invasive Weed Optimization
-    * BBO - Biogeography-Based Optimization
-        
-### Change others
-+ models_history.csv: Update history of meta-heuristic algorithms        
-        
----------------------------------------------------------------------
-
-
-# Version 0.4.1
-
-### Change models
-+ Human_based: Added the newest human-based meta-heuristic algorithms
-    * SARO - Search And Rescue Optimization
-    * LCBO: Life Choice-Based Optimization
-    * SSDO - Social Ski-Driver Optimization
-        + OriginalSSDO: The original version
-        + OriginalSSDO: The flow changed + SSDO
-        
-### Change others
-+ models_history.csv: Update history of meta-heuristic algorithms        
-        
----------------------------------------------------------------------
-
-# Version 0.4.0
-
-### Change models
-+ Human_based: Added some recent human-based meta-heuristic algorithms
-    * TLO - Teaching Learning Optimization
-        + OriginalTLO: The original version
-        + BaseTLO: The elitist version
-    * QSA - Queuing Search Algorithm
-        + BaseQSA: The original version
-        + OppoQSA: Opposition-based + QSA
-        + LevyQSA: Levy + QSA
-        + ImprovedQSA: Levy + Opposition-based + QSA
-    
-### Change others
-+ models_history.csv: Update history of meta-heuristic algorithms
-    
----------------------------------------------------------------------
-
-# Version 0.3.1
-
-### Change models
-+ Physics_based: Added the cutting-edge physics-based meta-heuristic algorithms
-    * NRO - Nuclear Reaction Optimization  
-    * HGSO - Henry Gas Solubility Optimization
-        + OriginalHGSO: The original version
-        + OppoHGSO: Opposition-based + HGSO
-        + LevyHGSO: Levy + HGSO
-    * ASO - Atom Search Optimization
-    * EO - Equilibrium Optimizer
-    
-### Change others
-+ models_history.csv: Update history of meta-heuristic algorithms
-    
----------------------------------------------------------------------
-
-
-# Version 0.3.0
-
-### Change models
-+ Physics_based: Added some recent physics-based meta-heuristic algorithms
-    * WDO - Wind Driven Optimization 
-    * MVO - Multi-Verse Optimizer 
-    * TWO - Tug of War Optimization
-        + OriginalTWO: The original version
-        + OppoTWO / OppoTWO: Opposition-based + TWO
-        + LevyTWO: Levy + TWO
-        + ITWO: Levy + Opposition-based + TWO
-    * EFO - Electromagnetic Field Optimization
-        + OriginalEFO: The original version
-        + BaseEFO: My version (changed the flow of the algorithm)
-    
-### Change others
-+ models_history.csv: Update history of meta-heuristic algorithms
-    
----------------------------------------------------------------------
-
-
-# Version 0.2.2
-
-### Change models
-+ Swarm_based: Added the state-of-the-art swarm-based meta-heuristic algorithms
-    * SRSR - Swarm Robotics Search And Rescue 
-    * GOA - Grasshopper Optimisation Algorithm
-    * EOA - Earthworm Optimisation Algorithm 
-    * MSA - Moth Search Algorithm 
-    * RHO - Rhino Herd Optimization 
-        + BaseRHO: The original 
-        + MyRHO: A little bit changed from BaseRHO version
-        + Version3RH: A little bit changed from MyRHO version
-    * EPO - Emperor Penguin Optimizer
-        + OriginalEPO: Not working
-        + BaseEPO: My version and works
-    * NMRA - Nake Mole\-rat Algorithm
-        + OriginalNMRA: The original 
-        + LevyNMR: Levy + OriginalNMRA 
-    * BES - Bald Eagle Search 
-    * PFA - Pathfinder Algorithm
-        + OriginalPFA: The original
-        + OPFA: Opposition-based PFA
-        + LPFA: Levy-based PFA
-        + IPFA: Improved PFA (Levy + Opposition + PFA)
-        + DePFA: DE + PFA
-        + LevyDePFA: Levy + DE + PFA
-    * SFO - Sailfish Optimizer
-        + OriginalSFO: The original
-        + ImprovedSFO: Changed Equations + Opposition-based + SFO
-    * HHO - Harris Hawks Optimization 
-    * MRFO - Manta Ray Foraging Optimization
-        + OriginalMRFO: The original
-        + MyMRFO: The version I changed the flow of the original one
-    
-    
-### Change others
-+ models_history.csv: Update history of meta-heuristic algorithms
-    
----------------------------------------------------------------------
-
-# Version 0.2.1
-
-### Change models
-+ Swarm_based: Added more recently algorithm (since 2010 to 2016)
-    * OriginalALO, BaseALO - Ant Lion Optimizer
-    * OriginalBA, AdaptiveBA, AdaptiveBA - Bat Algorithm
-    * BSA - Bird Swarm Algorithm 
-    * GWO - Grey Wolf Optimizer
-    * MFO - Moth-flame optimization 
-    * SSA - Social Spider Algorithm 
-    * SSO - Social Spider Optimization
-    
-### Change others
-+ models_history.csv: Update history of meta-heuristic algorithms
-    
----------------------------------------------------------------------
-
-# Version 0.2.0 
-
-### Change models
-+ root.py : Add 1 more helper functions
-+ Swarm_based: Added
-    * PSO - Particle Swarm Optimization
-    * BFO, ABFOLS (Adaptive version of BFO) - Bacterial Foraging Optimization
-    * CSO - Cat Swarm Optimization
-    * ABC - Artificial Bee Colony
-    * WOA - Whale Optimization Algorithm
-
-### Change others
-+ models_history.csv: Adding history of meta-heuristic algorithms
-    
----------------------------------------------------------------------
-# Version 0.1.1 
-
-### Change models
-+ root.py : Add more helper functions
-+ Evolutionary_based
-    * GA : Change the format of input parameters
-    * DE : Change the format of input parameters
-### Change others
-+ Examples: Adding more complex examples
-+ Library: "Opfunu" update the latest version 0.4.3
-    
----------------------------------------------------------------------
-# Version 0.1.0 (First version)
-
-### Changed models
-+ root.py (Very first file, the root of all algorithms)
-+ Evolutionary_based
-    * GA - Genetic Algorithm
-    * DE - Differential Evolution
-
+
+Different versions of mealpy in terms of passing hyper-parameters. So please careful check your version before
+  using this library. (All releases can be found here: [Link](https://pypi.org/project/mealpy/#history))
+  * mealpy < 1.0.5
+  * 1.1.0 < mealpy < 1.2.2
+  * 2.0.0 <= mealpy <= 2.1.2
+  * mealpy == 2.2.0 
+  * mealpy == 2.3.0 
+  * 2.4.0 <= mealpy <= 2.4.2 (From this version, algorithms can solve discrete problem)
+  * mealpy >= 2.5.1 (Define model 1 time, solve multiple problems)
+
+
+
+
+# Version 2.5.2
+
+### Update
+
++ Fixed bug all fitness values are equals in function "get index roulette wheel selection" in Optimizer class
++ Rename AdaptiveAEO by AugmentedAEO (Add reference)
++ Update text of Dwarf Mongoose Optimization Algorithm belongs to Swarm-based group
++ Fixed all tests and update all documents
++ Update Termination class, you can now design multiple Stopping Conditions for Optimizer
+
++ Bio-based group:
+  + Add Brown-Bear Optimization Algorithm (BBOA)
+    + Ref: A Novel Brown-bear Optimization Algorithm for Solving Economic Dispatch Problem 
+
++ Human-based group:
+  + Add Heap-based optimizer (HBO)
+    + Ref: Heap-based optimizer inspired by corporate rank hierarchy for global optimization 
+  + Add War Strategy Optimization (WarSO)
+    + Ref: War Strategy Optimization Algorithm: A New Effective Metaheuristic Algorithm for Global Optimization
+  + Add Human Conception Optimizer (HCO)
+    + Ref: A novel Human Conception Optimizer for solving optimization problems
+
++ Math-based group:
+  + Add Q-Learning Embedded Sine Cosine Algorithm (QLESCA)
+    + Ref: Q-learning embedded sine cosine algorithm (QLESCA)
+  + Add Success History Intelligent Optimizer (SHIO)
+    + Ref: Success history intelligent optimizer
+
++ Physics-based group:
+  + Add rime-ice (RIME)
+    + Ref: RIME: A physics-based optimization
+  + Add Energy Valley Optimizer (EVO)
+    + Ref: Energy valley optimizer: a novel metaheuristic algorithm
+  + Add Chernobyl Disaster Optimizer (CDO)
+    + Ref: Chernobyl disaster optimizer (CDO): a novel meta-heuristic method for global optimization
+  + Add Fick's Law Algorithm (FLA)
+    + Ref: Not accepted yet
+
++ Evolutionary-based group:
+  + Add CMA-ES and Simple-CMA-ES 
+    + Ref: Completely derandomized self-adaptation in evolution strategies.
+
++ Swarm-based group:
+  + Add Wavelet Mutation and Quadratic Interpolation MRFO (WMQIMRFO)
+    + Ref: An enhanced manta ray foraging optimization algorithm for shape optimization of complex CCG-Ball curves
+  + Add Egret Swarm Optimization Algorithm (ESOA)
+    + Ref: Egret Swarm Optimization Algorithm: An Evolutionary Computation Approach for Model Free Optimization
+  + Add Sea-Horse Optimization (SeaHO)
+    + Ref: Sea-horse optimizer: A nature-inspired meta-heuristic for global optimization and engineering application
+  + Add Mountain Gazelle Optimizer (MGO)
+    + Ref: Mountain Gazelle Optimizer: A new Nature-inspired Metaheuristic Algorithm for Global Optimization Problems
+  + Add Golden jackal optimization (GJO)
+    + Ref: Golden jackal optimization: A novel nature-inspired optimizer for engineering applications
+  + Add Fox Optimizer (FOX)
+    + Ref: FOX: a FOX-inspired optimization algorithm
+  + Add Giant Trevally Optimizer (GTO)
+    + Ref: Giant Trevally Optimizer (GTO): A Novel Metaheuristic Algorithm for Global Optimization and Challenging Engineering Problems
+    
++ **Warning**: The list of all algorithms below we should avoid to use it
+  + Add Zebra Optimization Algorithm (ZOA)
+    + Ref: Zebra Optimization Algorithm: A New Bio-Inspired Optimization Algorithm for Solving Optimization Algorithm
+  + Add Osprey Optimization Algorithm (OOA)
+    + Ref: Osprey optimization algorithm: A new bio-inspired metaheuristic algorithm for solving engineering optimization problems
+  + Add Coati Optimization Algorithm (CoatiOA)
+    + Ref: Coati Optimization Algorithm: A New Bio-Inspired Metaheuristic Algorithm for Solving Optimization Problems
+  + Add Pelican Optimization Algorithm (POA)
+    + Ref: Pelican optimization algorithm: A novel nature-inspired algorithm for engineering applications
+  + Add Northern Goshawk Optimization (NGO)
+    + Ref: Northern Goshawk Optimization: A New Swarm-Based Algorithm for Solving Optimization Problems
+  + Add Serval Optimization Algorithm (ServalOA) 
+    + Ref: Serval Optimization Algorithm: A New Bio-Inspired Approach for Solving Optimization Problems
+  + Add Siberian Tiger Optimization (STO)
+    + Ref: Siberian Tiger Optimization: A New Bio-Inspired Metaheuristic Algorithm for Solving Engineering Optimization Problems
+  + Add Walrus Optimization Algorithm (WaOA)
+    + Ref: Walrus Optimization Algorithm: A New Bio-Inspired Metaheuristic Algorithm
+  + Add Tasmanian Devil Optimization (TDO)
+    + Ref: Tasmanian devil optimization: a new bio-inspired optimization algorithm for solving optimization algorithm
+  + Add Fennec Fox Optimization (FFO)
+    + Ref: Fennec Fox Optimization: A New Nature-Inspired Optimization Algorithm
+  + Add Teamwork Optimization Algorithm (TOA)
+    + Ref: Teamwork Optimization Algorithm: A New Optimization Approach for Function Minimization/Maximization
+
++ **Notes on plagiarism and fake algorithm:**
+    + OOA and STO with the same exact code 
+    + POA ServalOA, NGO, WaOA, and TDO with almost the same exact code 
+    + ZOA and CoatiOA with almost the same exact code 
+    + FFO is swap two phases of POA
+    + TOA is kinda same as OOA and POA 
+
+
+---------------------------------------------------------------------
+
+
+# Version 2.5.1
+
+### Update
+
++ Add validator when variable can be both int/float value
++ Add algorithms to evolutionary-based group:
+  + EliteSingleGA and EliteMultiGA class
++ Add algorithms to math-based group:
+  + weIghted meaN oF vectOrs (INFO) algorithm 
+  + RUNge Kutta optimizer (RUN) 
+  + Circle Search Algorithm (CSA) 
++ Add algorithms to bio-based group:
+  + Barnacles Mating Optimizer (BMO) 
+  + Symbiotic Organisms Search (SOS) 
+  + Seagull Optimization Algorithm (SOA) 
+  + Tunicate Swarm Optimization (TSA) 
++ Add algorithms to swarm-based group:
+  + Hybrid Grey Wolf - Whale Optimization Algorithm (GWO_WOA)
+  + Marine Predators Algorithm (MPO) 
+  + Honey Badger Algorithm (HBA) 
+  + Sand Cat Swarm Optimization (SCSO) 
+  + Tuna Swarm Optimization (TSO)
+  + African Vultures Optimization Algorithm (AVOA) 
+  + Artificial Rabbits Optimization (ARO) 
+  + Artificial Gorilla Troops Optimization (AGTO) 
+  + Dwarf Mongoose Optimization Algorithm (DMOA) (weak algorithm)
+  
++ Add algorithms to human-based group:
+  + Student Psychology Based Optimization (SPBO) (weak algorithm)
+
++ Fix problem with 1 dimension
++ Enhanced the get index roulette wheel selection in Optimizer class
+
++ Update check parallel mode in Optimizer
++ Update algorithms that don't support parallel modes
++ Update the shebang #! with python codes
++ Update examples
+
+---------------------------------------------------------------------
+
+
+# Version 2.5.0
+
+### Update
+
++ Add save and load model functionalities in mealpy.utils.io module.
++ Add object that hold global/current worst solution in history object
++ Add method create_pop_group() in Optimizer class 
++ Add method before_initialization() in Optimizer class
++ Refactor initialization() and after_initialization() in Optimizer class
++ Remove before_evolve(), after_evolve(), and levy_flight() in Optimizer class
++ Convert termination_start() and termination_end() to check_termination() in Optimizer class
++ Remove boundary.py in utils
++ Add set_parameters() and get_parameters() in all optimizers
++ **Update new Problem class, move problem parameter from Optimizer to solve() function.**
++ Fix bug printing same entry multiple times in logger.
++ Fix bug exit() in Optimizer and utils package.
++ **Update new Termination class, move termination parameter from Optimizer to solve() function.**
++ **Add Multitask class that can run multiple optimizers on multiple problems with multiple trials.**
++ Refactor all optimizers.
++ **Add Tuner class that can help tuning hyper-parameters of optimizer.**
++ Add examples how to build new optimizer.
++ Add examples for Multitask and Tuner class.
++ Update documents, examples, tests
+
+
+---------------------------------------------------------------------
+
+# Version 2.4.2
+
+### Update
+
++ Add n_workers variable to solve() function in Optimizer class
+  + n_workers only effect by parallel mode such as "process" and "thread"
+  + n_workers default value is None and based on concurrent.futures module
++ Add 1 more Optional input parameter to the fitness function
++ Fix bug trajectory chart
++ Update fitness and objective chart
++ Remove supporting Python < 3.7, Mealpy only supports Python >=3.7
++ Group probabilistic is merged into math-based group
++ Update documents, examples, tests
+
+
+---------------------------------------------------------------------
+
+# Version 2.4.1
+
+### Update
+
++ Add after_initialization(), termination_end() to Optimizer class 
++ Update create_solution(), initialization() in Optimizer class
++ Add "starting_positions" parameter to solve() function in Optimizer class
++ Fix missing amend_position function in GA
++ Fix bug fitness value in history object
++ Update 4 training modes in all algorithms
+```code 
+Type: Parallel (no effect on updating process of agents) has 2 training modes:
+
+1. Process: Using multi-cores to update fitness for whole population
+2. Thread: Using multi-threads to update fitness for whole population
+
+Type: Sequential has 2 training modes
+
+3. Swarm (no effect on updating process): Updating fitness after the whole population move
+4. Single (effect on updating process): Updating fitness after each agent move
+```
++ Add agent's history and starting positions to docs.
+
+
+---------------------------------------------------------------------
+
+
+# Version 2.4.0
+
+### Update
+
++ Add mealpy's support functions in terminal: help(mealpy), dir(mealpy)
++ Add logger module (Logger class)
++ Add validator module (Validator class)
++ Change in Optimizer class:
+  + remove function get_global_best_global_worst_solution()
+  + replace save_optimization_process() by track_optimize_step() and track_optimize_process()
+  + update input of Problem and Termination object in Optimizer.
+  + add logger
+  + add validator and update all algorithms
+  + update function: get_special_solutions()
+  + rename function: crossover_arthmetic_recombination() to crossover_arithmetic()
+  + rename function: get_fitness_position() to get_target_wrapper()
+  + rename function: update_fitness_population() to update_target_wrapper_population()
+
++ A default method: generate_position() in Problem class.
++ Due to nature's characteristics of different problems, 2 methods can be designed for Optimizer to fit the problem 
+  are generate_position() and amend_position(). Both methods are moved from Optimizer 
+  class to Problem class, the create_solution() in Optimizer class will call these methods to create a new solution.
++ Update History and Problem class
+  + design default amend_position function in Problem class 
+  + parameter: obj_weight changed to obj_weights
+  + add parameter: save_population to control 
++ Add Pareto-like Sequential Sampling (PSS) to math_based group
+
+
+---------------------------------------------------------------------
+
+# Version 2.3.0
+
+### Update
+
++ All algorithms have been updated with the amend_position function for solving the discrete problem.
++ Required packages are version reduction to fit python 3.6
++ Add examples of how to design and custom a new algorithm based on this framework
++ Add examples mealpy solve discrete problems (combinatorial, permutation)
+
+
+---------------------------------------------------------------------
+
+# Version 2.2.0
+
+### Update models
+
+* You can pass the Problem dictionary or Problem object to the model.
+* You can pass the Termination dictionary or Termination object to the model.
+* The objective function is renamed as fitness function (obj_func -> fit_func)
+* The general format of a solution is: **\[position, target\]**
+    * position: numpy vector (1-D array)
+    * target: **\[fitness, list_objectives\]**
+    * list_objectives: **\[objective 1, objective 2, ...\]**
+    * After the training process, everything can be accessed via the objective "history" (model.history)
+
+* You can name your model and name your fitness function when creating a model 
+  * model(epoch, pop_size, ...., name='your model name', fit_name='your fitness function name')
+* Add new algorithms: 
+  * Gradient-Based Optimizer (GBO) in math_based group
+  * Chaos Game Optimization (CGO) in math_based group
+* Remove all dummy algorithms (Not supported anymore)
+* Fix bugs:
+  * Find idx of min-distance in BRO algorithm
+  * Update more strategy for GA algorithm
+  * Update child selection process in MA algorithm
+
+### Update others
+
++ examples: Update several scenarios for mealpy with other frameworks
++ document: Add document website (https://mealpy.readthedocs.io/)
+
+---------------------------------------------------------------------
+
+# Version 2.1.2
+
+### Update
+
++ Some algorithms have been updated in the GitHub release but not on PyPI such as Sparrow Search Algorithm.
++ I try to synchronize the version on GitHub and PyPI by trying to delete the vers
++ Add examples for applications of mealpy such as:
+  + Tuning hyper-parameter of neural network
+  + Replacing Gradient Descent optimizer in neural network
+  + Tuning hyper-parameter for other models such as SVM,...
+
+---------------------------------------------------------------------
+
+# Version 2.1.1
+
+### Update
+
++ Replace all .copy() operator by deepcopy() operator in module copy. Because shallow copy causing the problem with 
+  nested list inside list. Especially when copying population with nested of list position inside agent.
++ Add the Knapsack Problem example: examples/applications/discrete-problems/knapsack-problem.py
++ Add the Linear Regression example with Pytorch: examples/applications/pytorch/linear_regression.py
++ Add tutorial videos "How to use Mealpy library" to README.md
+
+---------------------------------------------------------------------
+
+# Version 2.1.0
+
+### Change models
+
++ Move all parallel function to Optimizer class
++ Remove unused methods in Optimizer class
++ Update all algorithm models with the same code-style as previous version
++ Restructure some hard algorithms include BFO, CRO.
+
+### Change others
+
++ examples: Update examples for all new algorithms
++ history: Update history of MHAs
++ parallel: Add comment on parallel and sequential mode
++ Add code-of-conduct
++ Add the complete example: examples/example_full_v210.py
+
+---------------------------------------------------------------------
+
+# Version 2.0.0
+
+### Change models
++ Update entire the library based on Optimizer class:
+    + Add class Problem and class Termination
+    + Add 3 training modes (sequential, thread and process)
+    + Add visualization charts:
+        + Global fitness value after generations
+        + Local fitness value after generations
+        + Global Objectives chart (For multi-objective functions)
+        + Local Objective chart (For multi-objective functions)
+        + The Diversity of population chart
+        + The Exploration verse Exploitation chart
+        + The Running time chart for each iteration (epoch / generation)
+        + The Trajectory of some agents after generations 
++ My batch-size idea is removed due to the parallel training mode
++ User can define the Stopping Condition based on:
+    + Epoch (Generation / Iteration) - default
+    + Function Evaluation 
+    + Early Stopping
+    + Time-bound (The running time for a single algorithm for a single task)
+
+
+### Change others
+
++ examples: Update examples for all new algorithms
++ history: Update history of MHAs
+
+---------------------------------------------------------------------
+
+# Version 1.2.2
+
+### Change models
+
++ Add Raven Roosting Optimization (RRO) and its variants to Dummy group
+    + OriginalRRO: The original version of RRO
+    + IRRO: The improved version of RRO
+    + BaseRRO: My developed version (On this version work)
+    
++ Add some newest algorithm to the library
+    + Arithmetic Optimization Algorithm (AOA) to Math-based group
+        + OriginalAOA: The original version of AOA
+    + Aquila Optimizer (AO) to Swarm-based group
+        + OriginalAO: The original version of AO 
+    + Archimedes Optimization Algorithm (ArchOA) to Physics-based group
+        + OriginalArchOA: The original version of ArchOA
+
+### Change others
+
++ examples: Update examples for all new algorithms
++ history: Update history of MHAs
+
+---------------------------------------------------------------------
+
+# Version 1.2.1
+
+### Change models
+
++ Add Coyote Optimization Algorithm (COA) to Swarm-based group
++ Update code LCBO and MLCO
++ Add variant version of:
+    + WOA: Hybrid Improved WOA 
+    + DE:
+        + SADE: Self-Adaptive DE
+        + JADE: Adaptive DE with Optional External Archive
+        + SHADE: Success-History Based Parameter Adaptation DE 
+        + LSHADE: Linear Population Size Reduction for SHADE
+    + PSO: Comprehensive Learning PSO (CL-PSO)
+    
+### Change others
+
++ examples: Update examples for all new algorithms
+
+---------------------------------------------------------------------
+
+# Version 1.2.0
+
+### Change models
+
++ Fix bug reduction dimension in FOA
++ Update Firefly Algorithm for better timing performance
+  
++ Add Hunger Games Optimization (HGS) to swarm-based group
++ Add Cuckoo Search Algorithm (CSA) to swarm-based group
+
++ Replace Root.\_\_init\_\_() function by super().\_\_init()\_\_ function in all algorithms.
+
+### Change others
+
++ history: Update new algorithms
++ examples: Update all the examples based on algorithm's input
+
+---------------------------------------------------------------------
+
+
+# Version 1.1.0
+
+### Change models
+
++ Update the way to passing hyper-parameters to root.py file (Big change)
+
++ Update all the hyper-parameters to all algorithms available.
+  
++ Fix all the division by 0 in some algorithms.
+
+### Change others
+
++ examples: Update all the examples of all algorithms
+
+---------------------------------------------------------------------
+
+
+# Version 1.0.5
+
+### Change models
++ System-based group added: 
+    + Water Cycle Algorithm (WCA)
+
++ Human-based group added:
+    + Imperialist Competitive Algorithm (ICA)
+    + Culture Algorithm (CA)
+
++ Swarm-based group added:
+    + Salp Swarm Optimization (SalpSO)
+    + Dragonfly Optimization (DO)
+    + Firefly Algorithm (FA)
+    + Bees Algorithm (Standard and Probilistic version)
+    + Ant Colony Optimization (ACO) for continuous domain
+    
++ Math-based group:
+    + Add Hill Climbing (HC) 
+
++ Physics-based group:
+    + Add Simulated Annealling (SA) 
+    
+### Change others
+
++ models_history.csv: Update history of meta-heuristic algorithms
++ examples: Add examples for all of above added algorithms.
+
+---------------------------------------------------------------------
+
+
+# Version 1.0.4
+
+### Change models
+
++ Changed category of Sparrow Search Algorithm (SpaSA) from Fake to Swarm-based group:
+    + Added the: OriginalSpaSA
+        + This version is taken from the original paper, very weak algorithm
+    + BaseSpaSA: My changed version
+        + Changed equations
+        + Changed flows and operators
+        + This version become the BEST algorithm 
+
++ Added Jaya Algorithm to Swarm-based group:
+    + OriginalJA: The original version from original paper
+    + BaseJA: My version of original JA for better running time.
+        + Remove all third loop in algorithm
+        + Change the second random variable r2 to Gaussian instead of uniform
+    + LJA: The original version of: Levy-flight Jaya Algorithm (LJA)
+        + Paper: An improved Jaya optimization algorithm with Levy flight
+        + Link: https://doi.org/10.1016/j.eswa.2020.113902
+        + Notes:
+            + This version I still remove all third loop in algorithm
+            + The beta value of Levy-flight equal to 1.8 as the best value in the paper.
+
++ DE, its state-of-the-art variants.
+    + DESAP: including DESAP-Abs and DESAP-Rel
+        + The main ideas is identified the population size without user-defined. Proposed equation: 
+            + Initial ps_init = 10*n (n: is the problem size, number of dimensions)
+            + DESAP-Abs: ps = round(ps_init + N (0, 1)), (N: is Gaussian value)
+            + DESAP-Rel: ps = round(ps_init + U (-0.5, 0.5)), (U: is uniform random function)
+            
++ Added Battle Royale Optimization Algorithm to Fake-algorithm
+    + OriginalBRO:
+        + The paper is very different than the author's matlab code. Even the algorithm's flow is wrong with index i, j.
+        + I tested the results is very slow convergence, even with small #dimensions. I guess that is why he cloned the
+        crossover process of Genetic Algorithm to his algorithm in the code (but not even mention it in the paper) to
+         get the results in the paper. Don't know what to say about this. 
+    + BaseBRO:
+        + First, I removed all third loop in the algorithm for faster computation.
+        + Second, Re-defined the algorithm's flow and algorithm's ideas
+        
++ Added Fruit-fly Optimization Algorithm and its variants to Swarm-based group:
+    + OriginalFOA:
+        + This algorithm is the weakest algorithm in MHAs. It can't run with complicated objective function.
+    + BaseFOA:
+        + I changed the fitness function (smell function) by taking the distance each 2 adjacent dimensions
+         --> Number of variables reduce from N to N-1
+        + Update the position if only it find the better fitness value.
+    + WFOA:
+        + The original version of Whale Fruit-fly Optimization Algorithm (WFOA)
+        + Paper: Boosted Hunting-based Fruit Fly Optimization and Advances in Real-world Problems
+        + From my point of view, this algorithm is almost the same as Whale, only different in calculate fitness
+         function. So it is not surprise that It outperforms BaseFOA
+         
+        https://www.sciencedirect.com/science/article/abs/pii/S0957417420307545
+        https://sci-hub.se/10.1016/j.eswa.2020.113976
+        https://sci-hub.se/10.1016/j.eij.2020.08.003
+        https://sci-hub.se/10.1016/j.eswa.2020.113902
+        https://www.x-mol.com/paper/1239433029684543488
+    
++ Update root.py
+    + Added improved_ms() function based on mutation and search mechanism - current better than levy-flight technique
+
+  
+
+### Change others
++ models_history.csv: Update history of meta-heuristic algorithms        
++ examples: 
+    + Add FBIO examples with large-scale benchmark functions
+    
+---------------------------------------------------------------------
+
+# Version 1.0.3
+
+### Change models
++ Update AEO and its variants
+    + Replace LevyAEO by AdaptiveAEO by using levy-flight in both Consumption and Decomposition process.
+    + Added Improved version by paper "Artificial ecosystem optimizer for parameters identification of proton exchange
+     membrane fuel cells model"
+    + Added Enhanced version by paper "An Enhanced Artificial Ecosystem-Based Optimization for Optimal Allocation of
+      Multiple Distributed Generations"
+    + Added Modified version by paper "Effective Parameter Extraction of Different Polymer Electrolyte Membrane Fuel
+     Cell Stack Models Using a Modified Artificial Ecosystem Optimization Algorithm"
+
++ Update LCBO and its variants (ILCO > MLCO > LCBO)
+    + Changed LevyLCBO to ModifiedLCO 
+    + Added the best version ImprovedLCO -- current best version
+    
++ Update EO and its variants (MEO > AEO > LevyEO > EO))
+    + Added ModifiedEO by paper "An efficient equilibrium optimizer with mutation strategy for numerical optimization"
+        + Currently the best version of EO
+        + Based on mutation strategy and gaussian distribution search
+    + Added AdaptiveEO by paper "A novel interdependence based multilevel thresholding technique using adaptive equilibrium optimizer"
+        + The second best version of EO, after ModifiedEO
+        + Based on Fitness average and memory saving of previous iteration
+
++ Update GWO and its variants (GWO > RW_GWO)
+    + Added Random Walk Grey Wolf Optimization - RW_GWO
+    + OriginalGWO always perform better than RW_GWO
+    
+    
++ Update root.py
+    + Added improved_ms() function based on mutation and search mechanism - current better than levy-flight technique
+    
++ Add Forensic-Based Investigation Optimization (FBIO) to human_based group: 
+
+  
+
+### Change others
++ models_history.csv: Update history of meta-heuristic algorithms        
++ examples: 
+    + Add FBIO examples with large-scale benchmark functions
+    
+---------------------------------------------------------------------
+
+# Version 1.0.2
+
+### Change models
++ Update : CEM
++ Fix bug division by 0 in: IWO, SMA
+
++ Add Forensic-Based Investigation Optimization (FBIO) to human_based group: 
+    + OriginalFBIO: the original version
+    + BaseFBIO: my modified version:
+        + Implement the fastest way (Remove all third loop)
+        + Change equations
+        + Change the flow of algorithm
+  
+
+### Change others
++ models_history.csv: Update history of meta-heuristic algorithms        
++ examples: 
+    + Add FBIO examples with large-scale benchmark functions
+    
+---------------------------------------------------------------------
+
+
+# Version 1.0.1
+
+### Change models
++ Added Slime Mould Algorithm (SMA) to bio_based group:
+    + OriginalSMA: the original version of SMA
+    + BaseSMA: my modified version:
+        + Selected 2 unique and random solution to create new solution (not to create variable) --> remove third loop in original version
+        + Check bound and update fitness after each individual move instead of after the whole population move in the original version
+        + My version not only faster but also better
+        
++ Added Spotted Hyena Optimizer (SHO) to swarm_based group:
+    + OriginalSHO: my modified version
+
+       
++ Add category for fake algorithms (papers) and proofs: 
+    + Butterfly Optimization Algorithm (BOA) to swarm_based group:
+        + OriginalBOA: this is fake algorithm 
+        + AdaptiveBOA:
+        + BaseBOA:
+            + Look at this guy (the author of this algorithm):
+            + https://scholar.google.co.in/citations?hl=en&user=KvcHovcAAAAJ&view_op=list_works&sortby=pubdate
+            + He invent BOA algorithm and public it in 2019, but so many variant version of BOA has been created since 2015.
+            + How the hell that happened?
+            + This is a plagiarism? I think this is one of the most biggest reason why mathematician researchers
+             calling out meta-heuristics community is completely bullshit and unethical.
+            + Just for producing more trash paper without any knowledge in it? This is why I listed BOA as the totally
+             trash and fake
+             
+    + Sandpiper Optimization Algorithm (SOA) to swarm_based group:
+        + OriginalSOA: the original version is fake
+            + This algorithm is trash, unethical when summit a paper to 2 journals.
+            + Can't even update its position.
+            + A detailed explain in this comment section 
+            (https://www.researchgate.net/publication/334897831_Sandpiper_optimization_algorithm_a_novel_approach_for_solving_real-life_engineering_problems/comments)
+        + BaseSOA: my modified version which changed some equations and flow.
+        
+    + Sooty Tern Optimization Algorithm (STOA) is another name of Sandpiper Optimization Algorithm (SOA) 
+        + Amandeep Kaur, Sushma Jain, Shivani Goel,  Gaurav Dhiman. What they are doing are plagiarism, uneducated
+         and unethical to meta-heuristics community.
+    
+    + Blue Monkey Optimization (BMO) to swarm_based group:
+        + OriginalBMO: the original version is fake 
+            + The idea look like "Chicken Swarm Optimization"
+            + The pseudo-code totally bullshit in my opinion, just read the paper you will understand.
+            + The unclear point here is the "Rate equation": really confuse because It's contain the position. As you know,
+                The position is the vector, but finally, the author conclude that Rate is random number in range [0, 1]
+                Luckily, using number we can plus/add number and vector or vector and vector.
+                So at first, Rate is random number then after the 1st loop, its become vector. 
+            + Morever, both equtions movement of blue monkey and children is the same.
+            + In addition, they don't check the bound after update position.
+            + Keep going, they don't tell you the how to find the global best (I mean from blue monkey group or child group)
+        + BaseBMO: my modified version which used my knowledge about meta-heuristics to do it. 
+
+
+### Change others
++ models_history.csv: Update history of meta-heuristic algorithms        
++ examples: 
+    + Update and Add examples for all algorithms
+    + All examples tested with CEC benchmark and large-scale problem (1000 - 2000 dimensions)
+    
+---------------------------------------------------------------------
+
+
+# Version 1.0.0
+
+### Change models
++ Change root model, then all of the algorithms are now change
+    + domain_range -> lower bound and upper bound
+    + log -> verbose
+    + objective_func -> obj_func
+    + batch-size training -> Inspired by the idea of batch-size training in gradient descent algorithm
++ Idea of batch-size training in meta-heuristics
+    + Some algorithms update the global best solution when all of the individuals in the population have moved to a new position.
+        + This idea is a similarity to the training the whole dataset in GD
+    + But some algorithms update after each move to a new position.
+        + This idea is a similarity as SGD
+    + But the point here is if the algorithm doesn't take advantage of the global best solution when updating individual 
+    the position then GD or SGD gives the same results.
+    
+    + So my idea of batch-size training here is very simple, after batch-size of individuals move, then we will update
+    the global best solution. So:
+        + batch-size = 1 ==> SGD
+        + batch-size = population-size ==> GD 
+        + batch-size should set = 10% / 25% / 50% of your population size
+    
+    + Some algorithms can't apply the idea of batch-size. For examples:
+        + If the original algorithm has already divided the population into m-clan (m-group) --> No need batch-size here
+        + If the original algorithm contains multiple-part. Each part contains several types of updating --> No need too.
+        
++ For music_based:
+    + BaseHS (HS): Is the one can't use batch-size idea, but not belong to any reason above.
+
++ For math_based:
+    + BaseSCA (SCA): Updated with batch-size idea. Keep the original version for reference.
+    
++ For system_based:
+    + BaseAEO (AEO): Updated with the batch-size ideas and some of my new ideas. Still keep the original version 
+    + BaseGCO (GCO): Updated with batch-size idea. Keep the original version
+    
++ For bio_based:
+    + BaseIWO (IWO):
+    + OriginalWHO (WHO):
+    + BaseBBO (BBO):
+        + Remove all third loop, make algorithm n-times faster than original 
+        + In the migration step, instead of select solution based on the wheel in every variable in position, 
+                  using the wheel and select a single position and update based on its all variable of that position.
+    + BaseVCS (VCS):
+        + Remove all third loop, make algorithm n-times faster than original
+        + In Immune response process, updating the whole position instead of updating each variable in position 
+        + Drop batch-size idea to 3 main processes of this algorithm, make it more robust
+    + BaseSBO (SBO):
+        + Remove all third loop, n-times faster than original
+        + No need equation (1, 2) in the paper, calculate the probability by roulette-wheel. Also can handle negative values
+        + Apply batch-size idea
+    + BaseBWO (BWO): This is my changed version and worked. 
+        + Using k-way tournament selection to select parent instead of randomizing
+        + Repeat cross-over population_size / 2 instead of n_var/2
+        + Mutation 50% of position instead of swap only 2 variable in a single position
+        + OriginalBWO: is fake and just a variant of Genetic Algorithm
+    + BaseAAA (AAA): This is my changed version but still not working
+        + OriginalAAA: is fake taken from DE and CRO 
+        + I realize in the original paper, parameters, and equations not clear.
+        + In the Adaptation phase, what is the point of saving starving value when it doesn't affect the solution at all?
+        + The size of the solution always = 2/3, so the friction surface will always stay at the same value.
+        + The idea of the equation seems like taken from DE, the adaptation and reproduction process seem like taken from CRO.
+        + Appearance from 2015, but still now 2020 none of Matlab code or python code about this algorithm.
+    + EOA: 
+        + OriginalEOA: My modified version from original Matlab version
+            + The original version from Matlab code above will not work well, even with small dimensions.
+            + I changed updating process
+            + Changed the Cauchy process using x_mean
+            + Used global best solution
+            + Remove the third loop for faster 
+   
++ For human_based:
+    + BaseTLO (TLO):
+        + Remove all third loop
+        + Apply batch-size idea
+    + BSO:
+        + OriginalBSO: This is original version
+        + ImprovedBSO: My improved version with levy-flight and removal of some parameters.
+    + QSA: 4 variant version now runs faster than n-times Original version
+        + BaseQSA: Remove all third loop, apply the idea of the global best solution
+        + OppoQSA: Based on BaseQSA, apply the idea of opposition-based learning technique
+        + LevyQSA: Based on BaseQSA, apply the idea of levy-flight in business 2
+        + ImprovedQSA: Combination of OppoQSA and LevyQSA
+        + OriginalQSA: The original version of QSA. Not working well
+    + SARO:
+        + BaseSARO: My version but not better than the original version, just faster than
+        + OriginalSARO: Convergence rate better than base version but very slow in time comparison.
+    + LCBO:
+        + BaseLCBO: Is the original version
+        + LevyLCBO: Use levy-flight and is the best among 3 version
+        + ImprovedLCBO: 
+    + SSDO:
+        + OriginalSSDO: This is the original version
+        + LevySSDO: Apply the idea of levy-flight
+    + GSKA:
+        + OriginalGSKA: This is the original version, very slow for large-scale and slow convergence
+        + BaseGSKA: Remove all third loop, change equations and ideas, faster than Original version
+    + CHIO: This algorithm hasn't done yet. Don't use it yet
+        + OriginalCHIO: Can fail at any time 
+        + BaseCHIO: Can't convergence
+        
+
++ For physics_based group:
+    + WDO: 
+        + OriginalWDO: is the original version
+    + MVO:
+        + OriginalMVO: is weak and slow algorithm 
+        + BaseMVO: can solve large-scale optimization problems
+    + TWO:
+        + OriginalTWO: is the original version
+        + OppoTWO: using opposition-based techniques (better than original version)
+        + LevyTWO: using only levy-flight and better than OppoTWO
+        + ImprovedTWO: using opposition-based and levy-flight and better than all others
+    + EFO:
+        + OriginalEFO: is the original version, run fast but slow convergence
+        + BaseEFO: using levy-flight for large-scale dimension
+    + NRO:
+        + OriginalNRO: is the original version, efficient even with large-scale due to levy-flight techniques
+        but running-time will slow because third loop.
+    + HGSO:
+        + OriginalHGSO: is the original version
+        + OppoHGSO: uses opposition-based technique
+        + LevyHGSO: uses levy-flight technique
+    + ASO:
+        + OriginalASO: is the original version
+    + EO:
+        + OriginalEO: is the original version
+        + LevyEO: uses levy-flight technique for large-scale dimensions
+
++ For probabilistic_based group:
+    + CEM:
+        + OriginalCEM: is the original version
+        + CEBaseSBO: is the hybrid version of Satin Bowerbird Optimizer (SBO) and CEM
+        + CEBaseSSDO: is the hybrid version of Social-Sky Driving Optimization (SSDO) and CEM
+        + CEBaseLCBO and CEBaseLCBONew: are the hybrid version of Life Choice Based Optimization and CEM
+
++ For evolutionary_based group: (Not good for large-scale problems)
+    + EP:
+        + OriginalEP: is the original version
+        + LevyEP: applied levy-flight 
+    + ES:
+        + OriginalES: is the original version
+        + LevyES: applied levy-flight
+    + MA:
+        + OriginalMA: is the original version, can't remove third loop, very slow algorithm
+    + GA:
+        + BaseGA: is the original version 
+    + DE:
+        + BaseDE: is the original version
+    + FPA:
+        + OriginalFPA: is the original version (already use levy-flight in it)
+    + CRO:
+        + OriginalCRO: is the original version
+        + OCRO: is the opposition-based version
+
++ For swarm_based group: 
+    + PSO:
+        + OriginalPSO: is the original version
+        + PPSO: Phasor particle swarm optimization: a simple and efficient variant of PSO
+        + PSO_W: A modified particle swarm optimizer
+        + HPSO_TVA: New self-organising  hierarchical PSO with jumping time-varying acceleration coefficients
+    + ABC:
+        + OriginalABC: my version and taken from Clever Algorithms
+    + FA:
+        + OriginalFA: is the original version, running slow even the all third loop already removed
+    + BA:
+        + OriginalBA: is the original version 
+        + BasicBA: is also the original version with improved parameters
+        + AdaptiveBA: my modified version without A parameter
+    + PIO: 
+        + This is fake algorithm, after changing almost everything, the algorithm works
+        + BasePIO: My base version
+        + LevyPIO: My version based on levy-flight for large-scale dimensions
+    + GWO:
+        + OriginalGWO: is the original version
+    + ALO:
+        + OriginalALO: is the original version, slow and less efficient
+        + BaseALO: my modified version which using matrix multiplication for faster 
+    + MFO:
+        + OriginalMFO: is the original version
+        + BaseMFO: my modified version which remove third loop, change equations and flow
+    + EHO:
+        + OriginalEHO: is the original version
+        + LevyEHO: my levy-flight version of EHO
+    + WOA:
+        + OriginalWOA: is the original version
+    + BSA:
+        + OriginalBSA: is the original version
+    + SRSR:
+        + OriginalSRSR: is the original version
+    + GOA:
+        + OriginalGOA: is the original version with some changed from me:
+            + I added normal() component to Eq, 2.7
+            + Changed the way to calculate distance between two location
+            + Used batch-size idea    
+    + MSA:
+        + OriginalMSA: is my modified version with some changed from original matlab code version
+    + RHO:
+        + OriginalRHO: is the original version, not working 
+        + BaseRHO: my changed version 
+        + LevyRHO: levy-flight for large-scale dimensions
+            + Change the flow of algorithm
+            + Uses normal in equation instead of uniform
+            + Uses levy-flight instead of uniform-equation
+    + EPO:
+        + Original: is the original version, can't converge at all
+        + BaseEPO: my modified version:
+            + First: I changed the Eq. T_s and no need T and random R.
+            + Second: Updated the old position if fitness value better or kept the old position if otherwise
+            + Third: Remove the third loop for faster
+            + Fourth: Batch size idea
+            + Fifth: Add normal() component and change minus sign to a plus
+    + NMRA:
+        + OriginalNMRA: The original version
+            + The Matlab code of paper's author here: https://github.com/rohitsalgotra/Naked-Mole-Rat-Algorithm
+            + Matlab code and paper are very different. 
+        + LevyNMRA: My levy-flight version 
+        + ImprovedNMRA:
+            + Using mutation probability
+            + Using levy-flight
+            + Using crossover operator
+    + BES:
+        + OriginalBES: the original version
+    + PFA:
+        + OriginalPFA: is the original version, I did redesign the equation based on distance.
+            + The problem with using the distance is that when increasing the bound and dimensions 
+            --> distance increase very fast --> new position will always over the bound
+            --> we should divide the distance to a number of dimensions and the distance of the bound (upper-lower) to
+            stabilize the distance 
+            + The second problem is a new solution based on all other solutions --> we should also divide the new solution
+            by the population size to stabilize it.
+        + OPFA: is an enhanced version of PFA based on Opposition-based Learning (better than OriginalPFA)
+        + ImprovedPFA: (sometime better than OPFA)
+            + using opposition-based learning
+            + using levy-flight 2 times
+    + SFO:
+        + OriginalSFO: is the original version
+        + ImprovedSFO: my improved version in which
+            + Reform Energy equation,
+            + No need parameter A and epxilon
+            + Based on idea of Opposition-based Learning
+    + SLO:
+        + OriginalSLO: is the changed version from my student
+        + ImprovedSLO: is the improved version 
+    + SpaSA:
+        + BaseSpaSA: is my modified version, the original paper is fake, tons of unclear like parameters or equations
+    + MRFO:
+        + OriginalMRFO: is the original version
+        + LevyMRFO: is my modified version based on levy-flight
+    + HHO:
+        + OriginalHHO: is the original version 
+    + SSA:
+        + OriginalSSA: is the original version
+        + BaseSSA: my modified version 
+    + CSO:
+        + OriginalCSO: is the original version
+    + BFO:
+        + BaseBFO: is the adaptive version of BFO
+        + OriginalBFO: is the original version taken from Clever Algorithms
+    + SSO:
+        + OriginalSSO: is the original version
+    
+
+### Change others
++ models_history.csv: Update history of meta-heuristic algorithms        
++ examples: 
+    + Update and Add examples for all algorithms
+    + All examples tested with CEC benchmark and large-scale problem (1000 - 2000 dimensions)
+    
+---------------------------------------------------------------------
+
+
+
+# Version 0.8.6
+
+### Change models
++ Fix bug return position instead of fitness value in:
+    + TLO 
+    + SARO
++ Update some algorithms:
+    + SLO
+    + NRO
+    + ABC
+    
++ Added some variant version of PSO:
+    + PPSO (Phasor particle swarm optimization: a simple and efficient variant of PSO)
+    + PSO_W (A modified particle swarm optimizer)
+    + HPSO_TVA (New self-organising  hierarchical PSO with jumping time-varying acceleration coefficients)
+    
++ Added more algorithm in Swarm-based algorithm
+    + SpaSA: Sparrow Search Algorithm (Same name SSA as Social Spider Algorithm --> I changed it to SpaSA)
+
+### Change others
++ models_history.csv: Update history of meta-heuristic algorithms        
++ examples: Added new examples of: 
+    + PSO and variant of PSO
+    + Update all examples which now using CEC functions
+    
+---------------------------------------------------------------------
+
+# Version 0.8.5
+
+### Change models
++ Fix bugs in several algorithm related to Division by 0, sqrt(0), 
++ Added more algorithm in Probabilistic-based algorithm
+    + CEBaseSBO
++ Added selection by roulette wheel in root (This method now can handle negative fitness values)
++ Changed GA using roulette wheel selection instead of k-tournament method
+
+### Change others
++ models_history.csv: Update history of meta-heuristic algorithms        
++ examples: Added new examples of: 
+    + CE_SSDO, CE_SBO
+    + GA, SBO
+    
+---------------------------------------------------------------------
+
+# Version 0.8.4
+
+### Change models
++ Fix bugs in Probabilistic-based algorithm
+    + OriginalCEM
+    + CEBaseLCBO
+    + CEBaseLCBONew: No levy
+    + CEBaseSSDO
++ Fix bugs in Physics-based algorithm
+    + LevyEO
++ Fix bug in Human-based algorithm
+    + LCBO
+
++ Added Coronavirus Herd Immunity Optimization (CHIO) in Human-based group
+    + Original version: OriginalCHIO
+        + This version stuck in local optimal and early stopping because the infected case quickly become immunity
+        + In my version, when infected case all change to immunity. I make 1/3 population become infected then
+         optimization step keep going.
+    + My version: BaseCHIO
+    
+---------------------------------------------------------------------
+
+# Version 0.8.3
+
+### Change models
++ Probabilistic-based algorithm
+    + Added Cross-Entropy Method (CEM)
+    + Added CEM + LCBO
+    + Added CEM + SSDO
+    
+---------------------------------------------------------------------
+
+# Version 0.8.2
+
+### Change models
++ Bio-based group 
+    + Added Virus Colony Search (VCS)
+        + BaseVCS: This is the very simple version of VCS. Not the original one in the paper 
+        
++ Physics-based group
+    + Remove EO not good version
+    
++ Human-based group
+    + Fix LCBO sort population in initialization process
+    
++ Added new group: Probabilistic-based algorithm
+    + Added Cross-Entropy Method (CEM)
+    
+### Change others
++ models_history.csv: Update history of meta-heuristic algorithms        
++ examples: Added new examples of: 
+    + BaseVCS
+    + OriginalCEM
+
+---------------------------------------------------------------------
+
+
+# Version 0.8.1
+
+### Change models
++ Evolutionary-based group 
+    + Added Evolution Strategies (ES)
+        + OriginalES
+        + LevyES: Idea ==> Top population being mutated based on strategy, Left population try to get out of their
+         position based on levy-flight. 
+    + Added Evolution Programming (EP)
+        + OriginalEP: Different than ES by operator and bout_size
+        + LevyEP: Idea ==> Top population being selected based on tournament strategy round, 50% Left population
+             try to make a comeback to take the good position with levy jump.
+    + Added Memetic Algorithm (MA)
+        + OriginalMA
+    
+### Change others
++ models_history.csv: Update history of meta-heuristic algorithms        
++ examples: Added new examples of: 
+    + OriginalES and LevyES
+    + OriginalEP and LevyEP
+    + OriginalMA
+
+---------------------------------------------------------------------
+
+
+# Version 0.8.0
+
+### Change models
++ Swarm-based group
+    + Added Elephant Herding Optimization (EHO) in Swarm-based group
+        + OriginalEHO
+        + LevyEHO: Changed the Uniform distribution the "Separating operator" by Levy-flight (50%) and Gaussian(50%) 
+    + Added Pigeon-Inspired Optimization (PIO) in Swarm-based group
+        + BasePIO (Changed almost everything include flow the algorithm)
+        + LevyPIO 
+            + Changed flow of algorithm
+            + Removed some unnecessary loop
+            + Removed some parameters
+            + Added the levy-flight in second step make algorithm more robust
+    + Added Fireworks Algorithm  (FA)
+    
++ Human-based group
+    + Added Gaining Sharing Knowledge-based Algorithm (GSKA)
+    + Added Brain Storm Optimization Algorithm (BSO)
+        + OriginalBSO
+        + ImprovedBSO (Remove some parameters + Changed Equations + Levy-flight + OriginalBSO)
+
++ Evolutionary-based group 
+    + Added Flower Pollination Algorithm (FPA)
+
++ Bio-based group
+    + Added Artificial Algae Algorithm (Not working yet)
+ 
+ 
+### Change others
++ models_history.csv: Update history of meta-heuristic algorithms        
++ examples: Added new examples of: 
+    + OriginalFA 
+    + OriginalAAA
+    + OriginalBSO and ImprovedBSO 
+    + BaseGSKA
+    + BasePIO and LevyPIO
+    + OriginalEHO and LevyEHO
+    + OriginalFPA
+    
+
+
+---------------------------------------------------------------------
+
+# Version 0.7.5
+
+### Change models
++ Added Sea Lion Optimization in Swarm-based group
+    + OriginalSLO
+    + ImprovedSLO (Shrinking Encircling + Levy + SLO)
+ 
+### Change others
++ models_history.csv: Update history of meta-heuristic algorithms        
++ examples: Added new examples of: OriginalSLO and ImprovedSLO 
+
+
+---------------------------------------------------------------------
+
+
+# Version 0.7.4
+
+### Change models
++ Added Coral Reefs Optimization in Evolutionary-based group
+    + OriginalCRO
+    + OCRO (Opposition-based CRO)
+ 
+### Change others
++ models_history.csv: Update history of meta-heuristic algorithms        
++ examples: Added new examples of: OriginalCRO and CRO   
+
+
+---------------------------------------------------------------------
+
+
+# Version 0.7.3
+
+### Change models
++ Added Levy-flight and Opposition-based techniques in Root.py
++ Fixed codes include levy-flight and opposition-based of:
+    + QSA
+    + HGSO
+    + TWO
+    + NMRA
+    + PFA
+    + SFO
+    + SSO
++ Added new modified version of models based on Levy-flight:
+    + LCBO (LevyLCBO)
+    + SSDO (LevySSDO)
+    + EO (LevyEO)
+    + AEO (LevyAEO)
+    + MRFO (LevyMRFO)
+    + NMRA (LevyNMRA)
+ 
+### Change others
++ models_history.csv: Update history of meta-heuristic algorithms        
++ examples: Added new examples tested base-version and levy-version of: LCBO, SSDO, EO, AEO, MRFO, NMRA   
+
+---------------------------------------------------------------------
+
+# Version 0.7.2
+
+### Change 
++ Fix GA and WOA errors
+
+---------------------------------------------------------------------
+
+# Version 0.7.1
+
+### Change 
++ Change input parameters of the root.py file 
++ Update the changed of input parameters of all algorithms
++ Update examples folders
+
+---------------------------------------------------------------------
+
+# Version 0.7.0
+
+### Change models
++ Added new kind of meta-heuristics: math-based and music-based
++ Math_based:
+    * SCA - Sine Cosine Algorithm
+        + OriginalSCA: The original version
+        + BaseSCA: My version changed the flow 
++ Music_based:
+    * HS - Harmony Search
+        + OriginalHS: The original version - not working
+        + BaseHS: My version which changed a few things 
+            * First I changed the random usaged of harmony memory by best harmoney memory
+            * The fw_rate = 0.0001, fw_damp = 0.9995, number of new harmonies = population size (n_new = pop_size)
+            
+### Change others
++ models_history.csv: Update history of meta-heuristic algorithms        
+        
+---------------------------------------------------------------------
+
+# Version 0.6.0
+
+### Change models
++ Added new kind of meta-heuristics: system-based 
++ System_based: Added the latest system-inspired meta-heuristic algorithms
+    * GCO - Germinal Center Optimization
+    * AEO - Artificial Ecosystem-based Optimization
+     
+### Change others
++ models_history.csv: Update history of meta-heuristic algorithms        
+        
+---------------------------------------------------------------------
+
+# Version 0.5.1
+
+### Change models
++ Bio_based: Added the latest bio-inspired meta-heuristic algorithms
+    * SBO - Satin Bowerbird Optimizer
+    * WHO - Wildebeest Herd Optimization
+        + OriginalWHO: The original version
+        + OriginalWHO: I changed the flow of algorithm
+    * BWO - Black Widow Optimization
+    
+### Change others
++ models_history.csv: Update history of meta-heuristic algorithms        
+        
+---------------------------------------------------------------------
+
+
+# Version 0.5.0
+
+### Change models
++ Added new kind of meta-heuristics: bio-based (biology-inspired) 
++ Bio_based: Added some classical bio-inspired meta-heuristic algorithms
+    * IWO - Invasive Weed Optimization
+    * BBO - Biogeography-Based Optimization
+        
+### Change others
++ models_history.csv: Update history of meta-heuristic algorithms        
+        
+---------------------------------------------------------------------
+
+
+# Version 0.4.1
+
+### Change models
++ Human_based: Added the newest human-based meta-heuristic algorithms
+    * SARO - Search And Rescue Optimization
+    * LCBO: Life Choice-Based Optimization
+    * SSDO - Social Ski-Driver Optimization
+        + OriginalSSDO: The original version
+        + OriginalSSDO: The flow changed + SSDO
+        
+### Change others
++ models_history.csv: Update history of meta-heuristic algorithms        
+        
+---------------------------------------------------------------------
+
+# Version 0.4.0
+
+### Change models
++ Human_based: Added some recent human-based meta-heuristic algorithms
+    * TLO - Teaching Learning Optimization
+        + OriginalTLO: The original version
+        + BaseTLO: The elitist version
+    * QSA - Queuing Search Algorithm
+        + BaseQSA: The original version
+        + OppoQSA: Opposition-based + QSA
+        + LevyQSA: Levy + QSA
+        + ImprovedQSA: Levy + Opposition-based + QSA
+    
+### Change others
++ models_history.csv: Update history of meta-heuristic algorithms
+    
+---------------------------------------------------------------------
+
+# Version 0.3.1
+
+### Change models
++ Physics_based: Added the cutting-edge physics-based meta-heuristic algorithms
+    * NRO - Nuclear Reaction Optimization  
+    * HGSO - Henry Gas Solubility Optimization
+        + OriginalHGSO: The original version
+        + OppoHGSO: Opposition-based + HGSO
+        + LevyHGSO: Levy + HGSO
+    * ASO - Atom Search Optimization
+    * EO - Equilibrium Optimizer
+    
+### Change others
++ models_history.csv: Update history of meta-heuristic algorithms
+    
+---------------------------------------------------------------------
+
+
+# Version 0.3.0
+
+### Change models
++ Physics_based: Added some recent physics-based meta-heuristic algorithms
+    * WDO - Wind Driven Optimization 
+    * MVO - Multi-Verse Optimizer 
+    * TWO - Tug of War Optimization
+        + OriginalTWO: The original version
+        + OppoTWO / OppoTWO: Opposition-based + TWO
+        + LevyTWO: Levy + TWO
+        + ITWO: Levy + Opposition-based + TWO
+    * EFO - Electromagnetic Field Optimization
+        + OriginalEFO: The original version
+        + BaseEFO: My version (changed the flow of the algorithm)
+    
+### Change others
++ models_history.csv: Update history of meta-heuristic algorithms
+    
+---------------------------------------------------------------------
+
+
+# Version 0.2.2
+
+### Change models
++ Swarm_based: Added the state-of-the-art swarm-based meta-heuristic algorithms
+    * SRSR - Swarm Robotics Search And Rescue 
+    * GOA - Grasshopper Optimisation Algorithm
+    * EOA - Earthworm Optimisation Algorithm 
+    * MSA - Moth Search Algorithm 
+    * RHO - Rhino Herd Optimization 
+        + BaseRHO: The original 
+        + MyRHO: A little bit changed from BaseRHO version
+        + Version3RH: A little bit changed from MyRHO version
+    * EPO - Emperor Penguin Optimizer
+        + OriginalEPO: Not working
+        + BaseEPO: My version and works
+    * NMRA - Nake Mole\-rat Algorithm
+        + OriginalNMRA: The original 
+        + LevyNMR: Levy + OriginalNMRA 
+    * BES - Bald Eagle Search 
+    * PFA - Pathfinder Algorithm
+        + OriginalPFA: The original
+        + OPFA: Opposition-based PFA
+        + LPFA: Levy-based PFA
+        + IPFA: Improved PFA (Levy + Opposition + PFA)
+        + DePFA: DE + PFA
+        + LevyDePFA: Levy + DE + PFA
+    * SFO - Sailfish Optimizer
+        + OriginalSFO: The original
+        + ImprovedSFO: Changed Equations + Opposition-based + SFO
+    * HHO - Harris Hawks Optimization 
+    * MRFO - Manta Ray Foraging Optimization
+        + OriginalMRFO: The original
+        + MyMRFO: The version I changed the flow of the original one
+    
+    
+### Change others
++ models_history.csv: Update history of meta-heuristic algorithms
+    
+---------------------------------------------------------------------
+
+# Version 0.2.1
+
+### Change models
++ Swarm_based: Added more recently algorithm (since 2010 to 2016)
+    * OriginalALO, BaseALO - Ant Lion Optimizer
+    * OriginalBA, AdaptiveBA, AdaptiveBA - Bat Algorithm
+    * BSA - Bird Swarm Algorithm 
+    * GWO - Grey Wolf Optimizer
+    * MFO - Moth-flame optimization 
+    * SSA - Social Spider Algorithm 
+    * SSO - Social Spider Optimization
+    
+### Change others
++ models_history.csv: Update history of meta-heuristic algorithms
+    
+---------------------------------------------------------------------
+
+# Version 0.2.0 
+
+### Change models
++ root.py : Add 1 more helper functions
++ Swarm_based: Added
+    * PSO - Particle Swarm Optimization
+    * BFO, ABFOLS (Adaptive version of BFO) - Bacterial Foraging Optimization
+    * CSO - Cat Swarm Optimization
+    * ABC - Artificial Bee Colony
+    * WOA - Whale Optimization Algorithm
+
+### Change others
++ models_history.csv: Adding history of meta-heuristic algorithms
+    
+---------------------------------------------------------------------
+# Version 0.1.1 
+
+### Change models
++ root.py : Add more helper functions
++ Evolutionary_based
+    * GA : Change the format of input parameters
+    * DE : Change the format of input parameters
+### Change others
++ Examples: Adding more complex examples
++ Library: "Opfunu" update the latest version 0.4.3
+    
+---------------------------------------------------------------------
+# Version 0.1.0 (First version)
+
+### Changed models
++ root.py (Very first file, the root of all algorithms)
++ Evolutionary_based
+    * GA - Genetic Algorithm
+    * DE - Differential Evolution
+
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `mealpy-2.5.3/LICENSE` & `mealpy-2.5.3a1/LICENSE`

 * *Ordering differences only*

 * *Files 7% similar despite different names*

```diff
@@ -1,674 +1,674 @@
-                    GNU GENERAL PUBLIC LICENSE
-                       Version 3, 29 June 2007
-
- Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>
- Everyone is permitted to copy and distribute verbatim copies
- of this license document, but changing it is not allowed.
-
-                            Preamble
-
-  The GNU General Public License is a free, copyleft license for
-software and other kinds of works.
-
-  The licenses for most software and other practical works are designed
-to take away your freedom to share and change the works.  By contrast,
-the GNU General Public License is intended to guarantee your freedom to
-share and change all versions of a program--to make sure it remains free
-software for all its users.  We, the Free Software Foundation, use the
-GNU General Public License for most of our software; it applies also to
-any other work released this way by its authors.  You can apply it to
-your programs, too.
-
-  When we speak of free software, we are referring to freedom, not
-price.  Our General Public Licenses are designed to make sure that you
-have the freedom to distribute copies of free software (and charge for
-them if you wish), that you receive source code or can get it if you
-want it, that you can change the software or use pieces of it in new
-free programs, and that you know you can do these things.
-
-  To protect your rights, we need to prevent others from denying you
-these rights or asking you to surrender the rights.  Therefore, you have
-certain responsibilities if you distribute copies of the software, or if
-you modify it: responsibilities to respect the freedom of others.
-
-  For example, if you distribute copies of such a program, whether
-gratis or for a fee, you must pass on to the recipients the same
-freedoms that you received.  You must make sure that they, too, receive
-or can get the source code.  And you must show them these terms so they
-know their rights.
-
-  Developers that use the GNU GPL protect your rights with two steps:
-(1) assert copyright on the software, and (2) offer you this License
-giving you legal permission to copy, distribute and/or modify it.
-
-  For the developers' and authors' protection, the GPL clearly explains
-that there is no warranty for this free software.  For both users' and
-authors' sake, the GPL requires that modified versions be marked as
-changed, so that their problems will not be attributed erroneously to
-authors of previous versions.
-
-  Some devices are designed to deny users access to install or run
-modified versions of the software inside them, although the manufacturer
-can do so.  This is fundamentally incompatible with the aim of
-protecting users' freedom to change the software.  The systematic
-pattern of such abuse occurs in the area of products for individuals to
-use, which is precisely where it is most unacceptable.  Therefore, we
-have designed this version of the GPL to prohibit the practice for those
-products.  If such problems arise substantially in other domains, we
-stand ready to extend this provision to those domains in future versions
-of the GPL, as needed to protect the freedom of users.
-
-  Finally, every program is threatened constantly by software patents.
-States should not allow patents to restrict development and use of
-software on general-purpose computers, but in those that do, we wish to
-avoid the special danger that patents applied to a free program could
-make it effectively proprietary.  To prevent this, the GPL assures that
-patents cannot be used to render the program non-free.
-
-  The precise terms and conditions for copying, distribution and
-modification follow.
-
-                       TERMS AND CONDITIONS
-
-  0. Definitions.
-
-  "This License" refers to version 3 of the GNU General Public License.
-
-  "Copyright" also means copyright-like laws that apply to other kinds of
-works, such as semiconductor masks.
-
-  "The Program" refers to any copyrightable work licensed under this
-License.  Each licensee is addressed as "you".  "Licensees" and
-"recipients" may be individuals or organizations.
-
-  To "modify" a work means to copy from or adapt all or part of the work
-in a fashion requiring copyright permission, other than the making of an
-exact copy.  The resulting work is called a "modified version" of the
-earlier work or a work "based on" the earlier work.
-
-  A "covered work" means either the unmodified Program or a work based
-on the Program.
-
-  To "propagate" a work means to do anything with it that, without
-permission, would make you directly or secondarily liable for
-infringement under applicable copyright law, except executing it on a
-computer or modifying a private copy.  Propagation includes copying,
-distribution (with or without modification), making available to the
-public, and in some countries other activities as well.
-
-  To "convey" a work means any kind of propagation that enables other
-parties to make or receive copies.  Mere interaction with a user through
-a computer network, with no transfer of a copy, is not conveying.
-
-  An interactive user interface displays "Appropriate Legal Notices"
-to the extent that it includes a convenient and prominently visible
-feature that (1) displays an appropriate copyright notice, and (2)
-tells the user that there is no warranty for the work (except to the
-extent that warranties are provided), that licensees may convey the
-work under this License, and how to view a copy of this License.  If
-the interface presents a list of user commands or options, such as a
-menu, a prominent item in the list meets this criterion.
-
-  1. Source Code.
-
-  The "source code" for a work means the preferred form of the work
-for making modifications to it.  "Object code" means any non-source
-form of a work.
-
-  A "Standard Interface" means an interface that either is an official
-standard defined by a recognized standards body, or, in the case of
-interfaces specified for a particular programming language, one that
-is widely used among developers working in that language.
-
-  The "System Libraries" of an executable work include anything, other
-than the work as a whole, that (a) is included in the normal form of
-packaging a Major Component, but which is not part of that Major
-Component, and (b) serves only to enable use of the work with that
-Major Component, or to implement a Standard Interface for which an
-implementation is available to the public in source code form.  A
-"Major Component", in this context, means a major essential component
-(kernel, window system, and so on) of the specific operating system
-(if any) on which the executable work runs, or a compiler used to
-produce the work, or an object code interpreter used to run it.
-
-  The "Corresponding Source" for a work in object code form means all
-the source code needed to generate, install, and (for an executable
-work) run the object code and to modify the work, including scripts to
-control those activities.  However, it does not include the work's
-System Libraries, or general-purpose tools or generally available free
-programs which are used unmodified in performing those activities but
-which are not part of the work.  For example, Corresponding Source
-includes interface definition files associated with source files for
-the work, and the source code for shared libraries and dynamically
-linked subprograms that the work is specifically designed to require,
-such as by intimate data communication or control flow between those
-subprograms and other parts of the work.
-
-  The Corresponding Source need not include anything that users
-can regenerate automatically from other parts of the Corresponding
-Source.
-
-  The Corresponding Source for a work in source code form is that
-same work.
-
-  2. Basic Permissions.
-
-  All rights granted under this License are granted for the term of
-copyright on the Program, and are irrevocable provided the stated
-conditions are met.  This License explicitly affirms your unlimited
-permission to run the unmodified Program.  The output from running a
-covered work is covered by this License only if the output, given its
-content, constitutes a covered work.  This License acknowledges your
-rights of fair use or other equivalent, as provided by copyright law.
-
-  You may make, run and propagate covered works that you do not
-convey, without conditions so long as your license otherwise remains
-in force.  You may convey covered works to others for the sole purpose
-of having them make modifications exclusively for you, or provide you
-with facilities for running those works, provided that you comply with
-the terms of this License in conveying all material for which you do
-not control copyright.  Those thus making or running the covered works
-for you must do so exclusively on your behalf, under your direction
-and control, on terms that prohibit them from making any copies of
-your copyrighted material outside their relationship with you.
-
-  Conveying under any other circumstances is permitted solely under
-the conditions stated below.  Sublicensing is not allowed; section 10
-makes it unnecessary.
-
-  3. Protecting Users' Legal Rights From Anti-Circumvention Law.
-
-  No covered work shall be deemed part of an effective technological
-measure under any applicable law fulfilling obligations under article
-11 of the WIPO copyright treaty adopted on 20 December 1996, or
-similar laws prohibiting or restricting circumvention of such
-measures.
-
-  When you convey a covered work, you waive any legal power to forbid
-circumvention of technological measures to the extent such circumvention
-is effected by exercising rights under this License with respect to
-the covered work, and you disclaim any intention to limit operation or
-modification of the work as a means of enforcing, against the work's
-users, your or third parties' legal rights to forbid circumvention of
-technological measures.
-
-  4. Conveying Verbatim Copies.
-
-  You may convey verbatim copies of the Program's source code as you
-receive it, in any medium, provided that you conspicuously and
-appropriately publish on each copy an appropriate copyright notice;
-keep intact all notices stating that this License and any
-non-permissive terms added in accord with section 7 apply to the code;
-keep intact all notices of the absence of any warranty; and give all
-recipients a copy of this License along with the Program.
-
-  You may charge any price or no price for each copy that you convey,
-and you may offer support or warranty protection for a fee.
-
-  5. Conveying Modified Source Versions.
-
-  You may convey a work based on the Program, or the modifications to
-produce it from the Program, in the form of source code under the
-terms of section 4, provided that you also meet all of these conditions:
-
-    a) The work must carry prominent notices stating that you modified
-    it, and giving a relevant date.
-
-    b) The work must carry prominent notices stating that it is
-    released under this License and any conditions added under section
-    7.  This requirement modifies the requirement in section 4 to
-    "keep intact all notices".
-
-    c) You must license the entire work, as a whole, under this
-    License to anyone who comes into possession of a copy.  This
-    License will therefore apply, along with any applicable section 7
-    additional terms, to the whole of the work, and all its parts,
-    regardless of how they are packaged.  This License gives no
-    permission to license the work in any other way, but it does not
-    invalidate such permission if you have separately received it.
-
-    d) If the work has interactive user interfaces, each must display
-    Appropriate Legal Notices; however, if the Program has interactive
-    interfaces that do not display Appropriate Legal Notices, your
-    work need not make them do so.
-
-  A compilation of a covered work with other separate and independent
-works, which are not by their nature extensions of the covered work,
-and which are not combined with it such as to form a larger program,
-in or on a volume of a storage or distribution medium, is called an
-"aggregate" if the compilation and its resulting copyright are not
-used to limit the access or legal rights of the compilation's users
-beyond what the individual works permit.  Inclusion of a covered work
-in an aggregate does not cause this License to apply to the other
-parts of the aggregate.
-
-  6. Conveying Non-Source Forms.
-
-  You may convey a covered work in object code form under the terms
-of sections 4 and 5, provided that you also convey the
-machine-readable Corresponding Source under the terms of this License,
-in one of these ways:
-
-    a) Convey the object code in, or embodied in, a physical product
-    (including a physical distribution medium), accompanied by the
-    Corresponding Source fixed on a durable physical medium
-    customarily used for software interchange.
-
-    b) Convey the object code in, or embodied in, a physical product
-    (including a physical distribution medium), accompanied by a
-    written offer, valid for at least three years and valid for as
-    long as you offer spare parts or customer support for that product
-    model, to give anyone who possesses the object code either (1) a
-    copy of the Corresponding Source for all the software in the
-    product that is covered by this License, on a durable physical
-    medium customarily used for software interchange, for a price no
-    more than your reasonable cost of physically performing this
-    conveying of source, or (2) access to copy the
-    Corresponding Source from a network server at no charge.
-
-    c) Convey individual copies of the object code with a copy of the
-    written offer to provide the Corresponding Source.  This
-    alternative is allowed only occasionally and noncommercially, and
-    only if you received the object code with such an offer, in accord
-    with subsection 6b.
-
-    d) Convey the object code by offering access from a designated
-    place (gratis or for a charge), and offer equivalent access to the
-    Corresponding Source in the same way through the same place at no
-    further charge.  You need not require recipients to copy the
-    Corresponding Source along with the object code.  If the place to
-    copy the object code is a network server, the Corresponding Source
-    may be on a different server (operated by you or a third party)
-    that supports equivalent copying facilities, provided you maintain
-    clear directions next to the object code saying where to find the
-    Corresponding Source.  Regardless of what server hosts the
-    Corresponding Source, you remain obligated to ensure that it is
-    available for as long as needed to satisfy these requirements.
-
-    e) Convey the object code using peer-to-peer transmission, provided
-    you inform other peers where the object code and Corresponding
-    Source of the work are being offered to the general public at no
-    charge under subsection 6d.
-
-  A separable portion of the object code, whose source code is excluded
-from the Corresponding Source as a System Library, need not be
-included in conveying the object code work.
-
-  A "User Product" is either (1) a "consumer product", which means any
-tangible personal property which is normally used for personal, family,
-or household purposes, or (2) anything designed or sold for incorporation
-into a dwelling.  In determining whether a product is a consumer product,
-doubtful cases shall be resolved in favor of coverage.  For a particular
-product received by a particular user, "normally used" refers to a
-typical or common use of that class of product, regardless of the status
-of the particular user or of the way in which the particular user
-actually uses, or expects or is expected to use, the product.  A product
-is a consumer product regardless of whether the product has substantial
-commercial, industrial or non-consumer uses, unless such uses represent
-the only significant mode of use of the product.
-
-  "Installation Information" for a User Product means any methods,
-procedures, authorization keys, or other information required to install
-and execute modified versions of a covered work in that User Product from
-a modified version of its Corresponding Source.  The information must
-suffice to ensure that the continued functioning of the modified object
-code is in no case prevented or interfered with solely because
-modification has been made.
-
-  If you convey an object code work under this section in, or with, or
-specifically for use in, a User Product, and the conveying occurs as
-part of a transaction in which the right of possession and use of the
-User Product is transferred to the recipient in perpetuity or for a
-fixed term (regardless of how the transaction is characterized), the
-Corresponding Source conveyed under this section must be accompanied
-by the Installation Information.  But this requirement does not apply
-if neither you nor any third party retains the ability to install
-modified object code on the User Product (for example, the work has
-been installed in ROM).
-
-  The requirement to provide Installation Information does not include a
-requirement to continue to provide support service, warranty, or updates
-for a work that has been modified or installed by the recipient, or for
-the User Product in which it has been modified or installed.  Access to a
-network may be denied when the modification itself materially and
-adversely affects the operation of the network or violates the rules and
-protocols for communication across the network.
-
-  Corresponding Source conveyed, and Installation Information provided,
-in accord with this section must be in a format that is publicly
-documented (and with an implementation available to the public in
-source code form), and must require no special password or key for
-unpacking, reading or copying.
-
-  7. Additional Terms.
-
-  "Additional permissions" are terms that supplement the terms of this
-License by making exceptions from one or more of its conditions.
-Additional permissions that are applicable to the entire Program shall
-be treated as though they were included in this License, to the extent
-that they are valid under applicable law.  If additional permissions
-apply only to part of the Program, that part may be used separately
-under those permissions, but the entire Program remains governed by
-this License without regard to the additional permissions.
-
-  When you convey a copy of a covered work, you may at your option
-remove any additional permissions from that copy, or from any part of
-it.  (Additional permissions may be written to require their own
-removal in certain cases when you modify the work.)  You may place
-additional permissions on material, added by you to a covered work,
-for which you have or can give appropriate copyright permission.
-
-  Notwithstanding any other provision of this License, for material you
-add to a covered work, you may (if authorized by the copyright holders of
-that material) supplement the terms of this License with terms:
-
-    a) Disclaiming warranty or limiting liability differently from the
-    terms of sections 15 and 16 of this License; or
-
-    b) Requiring preservation of specified reasonable legal notices or
-    author attributions in that material or in the Appropriate Legal
-    Notices displayed by works containing it; or
-
-    c) Prohibiting misrepresentation of the origin of that material, or
-    requiring that modified versions of such material be marked in
-    reasonable ways as different from the original version; or
-
-    d) Limiting the use for publicity purposes of names of licensors or
-    authors of the material; or
-
-    e) Declining to grant rights under trademark law for use of some
-    trade names, trademarks, or service marks; or
-
-    f) Requiring indemnification of licensors and authors of that
-    material by anyone who conveys the material (or modified versions of
-    it) with contractual assumptions of liability to the recipient, for
-    any liability that these contractual assumptions directly impose on
-    those licensors and authors.
-
-  All other non-permissive additional terms are considered "further
-restrictions" within the meaning of section 10.  If the Program as you
-received it, or any part of it, contains a notice stating that it is
-governed by this License along with a term that is a further
-restriction, you may remove that term.  If a license document contains
-a further restriction but permits relicensing or conveying under this
-License, you may add to a covered work material governed by the terms
-of that license document, provided that the further restriction does
-not survive such relicensing or conveying.
-
-  If you add terms to a covered work in accord with this section, you
-must place, in the relevant source files, a statement of the
-additional terms that apply to those files, or a notice indicating
-where to find the applicable terms.
-
-  Additional terms, permissive or non-permissive, may be stated in the
-form of a separately written license, or stated as exceptions;
-the above requirements apply either way.
-
-  8. Termination.
-
-  You may not propagate or modify a covered work except as expressly
-provided under this License.  Any attempt otherwise to propagate or
-modify it is void, and will automatically terminate your rights under
-this License (including any patent licenses granted under the third
-paragraph of section 11).
-
-  However, if you cease all violation of this License, then your
-license from a particular copyright holder is reinstated (a)
-provisionally, unless and until the copyright holder explicitly and
-finally terminates your license, and (b) permanently, if the copyright
-holder fails to notify you of the violation by some reasonable means
-prior to 60 days after the cessation.
-
-  Moreover, your license from a particular copyright holder is
-reinstated permanently if the copyright holder notifies you of the
-violation by some reasonable means, this is the first time you have
-received notice of violation of this License (for any work) from that
-copyright holder, and you cure the violation prior to 30 days after
-your receipt of the notice.
-
-  Termination of your rights under this section does not terminate the
-licenses of parties who have received copies or rights from you under
-this License.  If your rights have been terminated and not permanently
-reinstated, you do not qualify to receive new licenses for the same
-material under section 10.
-
-  9. Acceptance Not Required for Having Copies.
-
-  You are not required to accept this License in order to receive or
-run a copy of the Program.  Ancillary propagation of a covered work
-occurring solely as a consequence of using peer-to-peer transmission
-to receive a copy likewise does not require acceptance.  However,
-nothing other than this License grants you permission to propagate or
-modify any covered work.  These actions infringe copyright if you do
-not accept this License.  Therefore, by modifying or propagating a
-covered work, you indicate your acceptance of this License to do so.
-
-  10. Automatic Licensing of Downstream Recipients.
-
-  Each time you convey a covered work, the recipient automatically
-receives a license from the original licensors, to run, modify and
-propagate that work, subject to this License.  You are not responsible
-for enforcing compliance by third parties with this License.
-
-  An "entity transaction" is a transaction transferring control of an
-organization, or substantially all assets of one, or subdividing an
-organization, or merging organizations.  If propagation of a covered
-work results from an entity transaction, each party to that
-transaction who receives a copy of the work also receives whatever
-licenses to the work the party's predecessor in interest had or could
-give under the previous paragraph, plus a right to possession of the
-Corresponding Source of the work from the predecessor in interest, if
-the predecessor has it or can get it with reasonable efforts.
-
-  You may not impose any further restrictions on the exercise of the
-rights granted or affirmed under this License.  For example, you may
-not impose a license fee, royalty, or other charge for exercise of
-rights granted under this License, and you may not initiate litigation
-(including a cross-claim or counterclaim in a lawsuit) alleging that
-any patent claim is infringed by making, using, selling, offering for
-sale, or importing the Program or any portion of it.
-
-  11. Patents.
-
-  A "contributor" is a copyright holder who authorizes use under this
-License of the Program or a work on which the Program is based.  The
-work thus licensed is called the contributor's "contributor version".
-
-  A contributor's "essential patent claims" are all patent claims
-owned or controlled by the contributor, whether already acquired or
-hereafter acquired, that would be infringed by some manner, permitted
-by this License, of making, using, or selling its contributor version,
-but do not include claims that would be infringed only as a
-consequence of further modification of the contributor version.  For
-purposes of this definition, "control" includes the right to grant
-patent sublicenses in a manner consistent with the requirements of
-this License.
-
-  Each contributor grants you a non-exclusive, worldwide, royalty-free
-patent license under the contributor's essential patent claims, to
-make, use, sell, offer for sale, import and otherwise run, modify and
-propagate the contents of its contributor version.
-
-  In the following three paragraphs, a "patent license" is any express
-agreement or commitment, however denominated, not to enforce a patent
-(such as an express permission to practice a patent or covenant not to
-sue for patent infringement).  To "grant" such a patent license to a
-party means to make such an agreement or commitment not to enforce a
-patent against the party.
-
-  If you convey a covered work, knowingly relying on a patent license,
-and the Corresponding Source of the work is not available for anyone
-to copy, free of charge and under the terms of this License, through a
-publicly available network server or other readily accessible means,
-then you must either (1) cause the Corresponding Source to be so
-available, or (2) arrange to deprive yourself of the benefit of the
-patent license for this particular work, or (3) arrange, in a manner
-consistent with the requirements of this License, to extend the patent
-license to downstream recipients.  "Knowingly relying" means you have
-actual knowledge that, but for the patent license, your conveying the
-covered work in a country, or your recipient's use of the covered work
-in a country, would infringe one or more identifiable patents in that
-country that you have reason to believe are valid.
-
-  If, pursuant to or in connection with a single transaction or
-arrangement, you convey, or propagate by procuring conveyance of, a
-covered work, and grant a patent license to some of the parties
-receiving the covered work authorizing them to use, propagate, modify
-or convey a specific copy of the covered work, then the patent license
-you grant is automatically extended to all recipients of the covered
-work and works based on it.
-
-  A patent license is "discriminatory" if it does not include within
-the scope of its coverage, prohibits the exercise of, or is
-conditioned on the non-exercise of one or more of the rights that are
-specifically granted under this License.  You may not convey a covered
-work if you are a party to an arrangement with a third party that is
-in the business of distributing software, under which you make payment
-to the third party based on the extent of your activity of conveying
-the work, and under which the third party grants, to any of the
-parties who would receive the covered work from you, a discriminatory
-patent license (a) in connection with copies of the covered work
-conveyed by you (or copies made from those copies), or (b) primarily
-for and in connection with specific products or compilations that
-contain the covered work, unless you entered into that arrangement,
-or that patent license was granted, prior to 28 March 2007.
-
-  Nothing in this License shall be construed as excluding or limiting
-any implied license or other defenses to infringement that may
-otherwise be available to you under applicable patent law.
-
-  12. No Surrender of Others' Freedom.
-
-  If conditions are imposed on you (whether by court order, agreement or
-otherwise) that contradict the conditions of this License, they do not
-excuse you from the conditions of this License.  If you cannot convey a
-covered work so as to satisfy simultaneously your obligations under this
-License and any other pertinent obligations, then as a consequence you may
-not convey it at all.  For example, if you agree to terms that obligate you
-to collect a royalty for further conveying from those to whom you convey
-the Program, the only way you could satisfy both those terms and this
-License would be to refrain entirely from conveying the Program.
-
-  13. Use with the GNU Affero General Public License.
-
-  Notwithstanding any other provision of this License, you have
-permission to link or combine any covered work with a work licensed
-under version 3 of the GNU Affero General Public License into a single
-combined work, and to convey the resulting work.  The terms of this
-License will continue to apply to the part which is the covered work,
-but the special requirements of the GNU Affero General Public License,
-section 13, concerning interaction through a network will apply to the
-combination as such.
-
-  14. Revised Versions of this License.
-
-  The Free Software Foundation may publish revised and/or new versions of
-the GNU General Public License from time to time.  Such new versions will
-be similar in spirit to the present version, but may differ in detail to
-address new problems or concerns.
-
-  Each version is given a distinguishing version number.  If the
-Program specifies that a certain numbered version of the GNU General
-Public License "or any later version" applies to it, you have the
-option of following the terms and conditions either of that numbered
-version or of any later version published by the Free Software
-Foundation.  If the Program does not specify a version number of the
-GNU General Public License, you may choose any version ever published
-by the Free Software Foundation.
-
-  If the Program specifies that a proxy can decide which future
-versions of the GNU General Public License can be used, that proxy's
-public statement of acceptance of a version permanently authorizes you
-to choose that version for the Program.
-
-  Later license versions may give you additional or different
-permissions.  However, no additional obligations are imposed on any
-author or copyright holder as a result of your choosing to follow a
-later version.
-
-  15. Disclaimer of Warranty.
-
-  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY
-APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT
-HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY
-OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,
-THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
-PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM
-IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF
-ALL NECESSARY SERVICING, REPAIR OR CORRECTION.
-
-  16. Limitation of Liability.
-
-  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
-WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS
-THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY
-GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE
-USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF
-DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD
-PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),
-EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF
-SUCH DAMAGES.
-
-  17. Interpretation of Sections 15 and 16.
-
-  If the disclaimer of warranty and limitation of liability provided
-above cannot be given local legal effect according to their terms,
-reviewing courts shall apply local law that most closely approximates
-an absolute waiver of all civil liability in connection with the
-Program, unless a warranty or assumption of liability accompanies a
-copy of the Program in return for a fee.
-
-                     END OF TERMS AND CONDITIONS
-
-            How to Apply These Terms to Your New Programs
-
-  If you develop a new program, and you want it to be of the greatest
-possible use to the public, the best way to achieve this is to make it
-free software which everyone can redistribute and change under these terms.
-
-  To do so, attach the following notices to the program.  It is safest
-to attach them to the start of each source file to most effectively
-state the exclusion of warranty; and each file should have at least
-the "copyright" line and a pointer to where the full notice is found.
-
-    <one line to give the program's name and a brief idea of what it does.>
-    Copyright (C) <year>  <name of author>
-
-    This program is free software: you can redistribute it and/or modify
-    it under the terms of the GNU General Public License as published by
-    the Free Software Foundation, either version 3 of the License, or
-    (at your option) any later version.
-
-    This program is distributed in the hope that it will be useful,
-    but WITHOUT ANY WARRANTY; without even the implied warranty of
-    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-    GNU General Public License for more details.
-
-    You should have received a copy of the GNU General Public License
-    along with this program.  If not, see <https://www.gnu.org/licenses/>.
-
-Also add information on how to contact you by electronic and paper mail.
-
-  If the program does terminal interaction, make it output a short
-notice like this when it starts in an interactive mode:
-
-    <program>  Copyright (C) <year>  <name of author>
-    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
-    This is free software, and you are welcome to redistribute it
-    under certain conditions; type `show c' for details.
-
-The hypothetical commands `show w' and `show c' should show the appropriate
-parts of the General Public License.  Of course, your program's commands
-might be different; for a GUI interface, you would use an "about box".
-
-  You should also get your employer (if you work as a programmer) or school,
-if any, to sign a "copyright disclaimer" for the program, if necessary.
-For more information on this, and how to apply and follow the GNU GPL, see
-<https://www.gnu.org/licenses/>.
-
-  The GNU General Public License does not permit incorporating your program
-into proprietary programs.  If your program is a subroutine library, you
-may consider it more useful to permit linking proprietary applications with
-the library.  If this is what you want to do, use the GNU Lesser General
-Public License instead of this License.  But first, please read
-<https://www.gnu.org/licenses/why-not-lgpl.html>.
+                    GNU GENERAL PUBLIC LICENSE
+                       Version 3, 29 June 2007
+
+ Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>
+ Everyone is permitted to copy and distribute verbatim copies
+ of this license document, but changing it is not allowed.
+
+                            Preamble
+
+  The GNU General Public License is a free, copyleft license for
+software and other kinds of works.
+
+  The licenses for most software and other practical works are designed
+to take away your freedom to share and change the works.  By contrast,
+the GNU General Public License is intended to guarantee your freedom to
+share and change all versions of a program--to make sure it remains free
+software for all its users.  We, the Free Software Foundation, use the
+GNU General Public License for most of our software; it applies also to
+any other work released this way by its authors.  You can apply it to
+your programs, too.
+
+  When we speak of free software, we are referring to freedom, not
+price.  Our General Public Licenses are designed to make sure that you
+have the freedom to distribute copies of free software (and charge for
+them if you wish), that you receive source code or can get it if you
+want it, that you can change the software or use pieces of it in new
+free programs, and that you know you can do these things.
+
+  To protect your rights, we need to prevent others from denying you
+these rights or asking you to surrender the rights.  Therefore, you have
+certain responsibilities if you distribute copies of the software, or if
+you modify it: responsibilities to respect the freedom of others.
+
+  For example, if you distribute copies of such a program, whether
+gratis or for a fee, you must pass on to the recipients the same
+freedoms that you received.  You must make sure that they, too, receive
+or can get the source code.  And you must show them these terms so they
+know their rights.
+
+  Developers that use the GNU GPL protect your rights with two steps:
+(1) assert copyright on the software, and (2) offer you this License
+giving you legal permission to copy, distribute and/or modify it.
+
+  For the developers' and authors' protection, the GPL clearly explains
+that there is no warranty for this free software.  For both users' and
+authors' sake, the GPL requires that modified versions be marked as
+changed, so that their problems will not be attributed erroneously to
+authors of previous versions.
+
+  Some devices are designed to deny users access to install or run
+modified versions of the software inside them, although the manufacturer
+can do so.  This is fundamentally incompatible with the aim of
+protecting users' freedom to change the software.  The systematic
+pattern of such abuse occurs in the area of products for individuals to
+use, which is precisely where it is most unacceptable.  Therefore, we
+have designed this version of the GPL to prohibit the practice for those
+products.  If such problems arise substantially in other domains, we
+stand ready to extend this provision to those domains in future versions
+of the GPL, as needed to protect the freedom of users.
+
+  Finally, every program is threatened constantly by software patents.
+States should not allow patents to restrict development and use of
+software on general-purpose computers, but in those that do, we wish to
+avoid the special danger that patents applied to a free program could
+make it effectively proprietary.  To prevent this, the GPL assures that
+patents cannot be used to render the program non-free.
+
+  The precise terms and conditions for copying, distribution and
+modification follow.
+
+                       TERMS AND CONDITIONS
+
+  0. Definitions.
+
+  "This License" refers to version 3 of the GNU General Public License.
+
+  "Copyright" also means copyright-like laws that apply to other kinds of
+works, such as semiconductor masks.
+
+  "The Program" refers to any copyrightable work licensed under this
+License.  Each licensee is addressed as "you".  "Licensees" and
+"recipients" may be individuals or organizations.
+
+  To "modify" a work means to copy from or adapt all or part of the work
+in a fashion requiring copyright permission, other than the making of an
+exact copy.  The resulting work is called a "modified version" of the
+earlier work or a work "based on" the earlier work.
+
+  A "covered work" means either the unmodified Program or a work based
+on the Program.
+
+  To "propagate" a work means to do anything with it that, without
+permission, would make you directly or secondarily liable for
+infringement under applicable copyright law, except executing it on a
+computer or modifying a private copy.  Propagation includes copying,
+distribution (with or without modification), making available to the
+public, and in some countries other activities as well.
+
+  To "convey" a work means any kind of propagation that enables other
+parties to make or receive copies.  Mere interaction with a user through
+a computer network, with no transfer of a copy, is not conveying.
+
+  An interactive user interface displays "Appropriate Legal Notices"
+to the extent that it includes a convenient and prominently visible
+feature that (1) displays an appropriate copyright notice, and (2)
+tells the user that there is no warranty for the work (except to the
+extent that warranties are provided), that licensees may convey the
+work under this License, and how to view a copy of this License.  If
+the interface presents a list of user commands or options, such as a
+menu, a prominent item in the list meets this criterion.
+
+  1. Source Code.
+
+  The "source code" for a work means the preferred form of the work
+for making modifications to it.  "Object code" means any non-source
+form of a work.
+
+  A "Standard Interface" means an interface that either is an official
+standard defined by a recognized standards body, or, in the case of
+interfaces specified for a particular programming language, one that
+is widely used among developers working in that language.
+
+  The "System Libraries" of an executable work include anything, other
+than the work as a whole, that (a) is included in the normal form of
+packaging a Major Component, but which is not part of that Major
+Component, and (b) serves only to enable use of the work with that
+Major Component, or to implement a Standard Interface for which an
+implementation is available to the public in source code form.  A
+"Major Component", in this context, means a major essential component
+(kernel, window system, and so on) of the specific operating system
+(if any) on which the executable work runs, or a compiler used to
+produce the work, or an object code interpreter used to run it.
+
+  The "Corresponding Source" for a work in object code form means all
+the source code needed to generate, install, and (for an executable
+work) run the object code and to modify the work, including scripts to
+control those activities.  However, it does not include the work's
+System Libraries, or general-purpose tools or generally available free
+programs which are used unmodified in performing those activities but
+which are not part of the work.  For example, Corresponding Source
+includes interface definition files associated with source files for
+the work, and the source code for shared libraries and dynamically
+linked subprograms that the work is specifically designed to require,
+such as by intimate data communication or control flow between those
+subprograms and other parts of the work.
+
+  The Corresponding Source need not include anything that users
+can regenerate automatically from other parts of the Corresponding
+Source.
+
+  The Corresponding Source for a work in source code form is that
+same work.
+
+  2. Basic Permissions.
+
+  All rights granted under this License are granted for the term of
+copyright on the Program, and are irrevocable provided the stated
+conditions are met.  This License explicitly affirms your unlimited
+permission to run the unmodified Program.  The output from running a
+covered work is covered by this License only if the output, given its
+content, constitutes a covered work.  This License acknowledges your
+rights of fair use or other equivalent, as provided by copyright law.
+
+  You may make, run and propagate covered works that you do not
+convey, without conditions so long as your license otherwise remains
+in force.  You may convey covered works to others for the sole purpose
+of having them make modifications exclusively for you, or provide you
+with facilities for running those works, provided that you comply with
+the terms of this License in conveying all material for which you do
+not control copyright.  Those thus making or running the covered works
+for you must do so exclusively on your behalf, under your direction
+and control, on terms that prohibit them from making any copies of
+your copyrighted material outside their relationship with you.
+
+  Conveying under any other circumstances is permitted solely under
+the conditions stated below.  Sublicensing is not allowed; section 10
+makes it unnecessary.
+
+  3. Protecting Users' Legal Rights From Anti-Circumvention Law.
+
+  No covered work shall be deemed part of an effective technological
+measure under any applicable law fulfilling obligations under article
+11 of the WIPO copyright treaty adopted on 20 December 1996, or
+similar laws prohibiting or restricting circumvention of such
+measures.
+
+  When you convey a covered work, you waive any legal power to forbid
+circumvention of technological measures to the extent such circumvention
+is effected by exercising rights under this License with respect to
+the covered work, and you disclaim any intention to limit operation or
+modification of the work as a means of enforcing, against the work's
+users, your or third parties' legal rights to forbid circumvention of
+technological measures.
+
+  4. Conveying Verbatim Copies.
+
+  You may convey verbatim copies of the Program's source code as you
+receive it, in any medium, provided that you conspicuously and
+appropriately publish on each copy an appropriate copyright notice;
+keep intact all notices stating that this License and any
+non-permissive terms added in accord with section 7 apply to the code;
+keep intact all notices of the absence of any warranty; and give all
+recipients a copy of this License along with the Program.
+
+  You may charge any price or no price for each copy that you convey,
+and you may offer support or warranty protection for a fee.
+
+  5. Conveying Modified Source Versions.
+
+  You may convey a work based on the Program, or the modifications to
+produce it from the Program, in the form of source code under the
+terms of section 4, provided that you also meet all of these conditions:
+
+    a) The work must carry prominent notices stating that you modified
+    it, and giving a relevant date.
+
+    b) The work must carry prominent notices stating that it is
+    released under this License and any conditions added under section
+    7.  This requirement modifies the requirement in section 4 to
+    "keep intact all notices".
+
+    c) You must license the entire work, as a whole, under this
+    License to anyone who comes into possession of a copy.  This
+    License will therefore apply, along with any applicable section 7
+    additional terms, to the whole of the work, and all its parts,
+    regardless of how they are packaged.  This License gives no
+    permission to license the work in any other way, but it does not
+    invalidate such permission if you have separately received it.
+
+    d) If the work has interactive user interfaces, each must display
+    Appropriate Legal Notices; however, if the Program has interactive
+    interfaces that do not display Appropriate Legal Notices, your
+    work need not make them do so.
+
+  A compilation of a covered work with other separate and independent
+works, which are not by their nature extensions of the covered work,
+and which are not combined with it such as to form a larger program,
+in or on a volume of a storage or distribution medium, is called an
+"aggregate" if the compilation and its resulting copyright are not
+used to limit the access or legal rights of the compilation's users
+beyond what the individual works permit.  Inclusion of a covered work
+in an aggregate does not cause this License to apply to the other
+parts of the aggregate.
+
+  6. Conveying Non-Source Forms.
+
+  You may convey a covered work in object code form under the terms
+of sections 4 and 5, provided that you also convey the
+machine-readable Corresponding Source under the terms of this License,
+in one of these ways:
+
+    a) Convey the object code in, or embodied in, a physical product
+    (including a physical distribution medium), accompanied by the
+    Corresponding Source fixed on a durable physical medium
+    customarily used for software interchange.
+
+    b) Convey the object code in, or embodied in, a physical product
+    (including a physical distribution medium), accompanied by a
+    written offer, valid for at least three years and valid for as
+    long as you offer spare parts or customer support for that product
+    model, to give anyone who possesses the object code either (1) a
+    copy of the Corresponding Source for all the software in the
+    product that is covered by this License, on a durable physical
+    medium customarily used for software interchange, for a price no
+    more than your reasonable cost of physically performing this
+    conveying of source, or (2) access to copy the
+    Corresponding Source from a network server at no charge.
+
+    c) Convey individual copies of the object code with a copy of the
+    written offer to provide the Corresponding Source.  This
+    alternative is allowed only occasionally and noncommercially, and
+    only if you received the object code with such an offer, in accord
+    with subsection 6b.
+
+    d) Convey the object code by offering access from a designated
+    place (gratis or for a charge), and offer equivalent access to the
+    Corresponding Source in the same way through the same place at no
+    further charge.  You need not require recipients to copy the
+    Corresponding Source along with the object code.  If the place to
+    copy the object code is a network server, the Corresponding Source
+    may be on a different server (operated by you or a third party)
+    that supports equivalent copying facilities, provided you maintain
+    clear directions next to the object code saying where to find the
+    Corresponding Source.  Regardless of what server hosts the
+    Corresponding Source, you remain obligated to ensure that it is
+    available for as long as needed to satisfy these requirements.
+
+    e) Convey the object code using peer-to-peer transmission, provided
+    you inform other peers where the object code and Corresponding
+    Source of the work are being offered to the general public at no
+    charge under subsection 6d.
+
+  A separable portion of the object code, whose source code is excluded
+from the Corresponding Source as a System Library, need not be
+included in conveying the object code work.
+
+  A "User Product" is either (1) a "consumer product", which means any
+tangible personal property which is normally used for personal, family,
+or household purposes, or (2) anything designed or sold for incorporation
+into a dwelling.  In determining whether a product is a consumer product,
+doubtful cases shall be resolved in favor of coverage.  For a particular
+product received by a particular user, "normally used" refers to a
+typical or common use of that class of product, regardless of the status
+of the particular user or of the way in which the particular user
+actually uses, or expects or is expected to use, the product.  A product
+is a consumer product regardless of whether the product has substantial
+commercial, industrial or non-consumer uses, unless such uses represent
+the only significant mode of use of the product.
+
+  "Installation Information" for a User Product means any methods,
+procedures, authorization keys, or other information required to install
+and execute modified versions of a covered work in that User Product from
+a modified version of its Corresponding Source.  The information must
+suffice to ensure that the continued functioning of the modified object
+code is in no case prevented or interfered with solely because
+modification has been made.
+
+  If you convey an object code work under this section in, or with, or
+specifically for use in, a User Product, and the conveying occurs as
+part of a transaction in which the right of possession and use of the
+User Product is transferred to the recipient in perpetuity or for a
+fixed term (regardless of how the transaction is characterized), the
+Corresponding Source conveyed under this section must be accompanied
+by the Installation Information.  But this requirement does not apply
+if neither you nor any third party retains the ability to install
+modified object code on the User Product (for example, the work has
+been installed in ROM).
+
+  The requirement to provide Installation Information does not include a
+requirement to continue to provide support service, warranty, or updates
+for a work that has been modified or installed by the recipient, or for
+the User Product in which it has been modified or installed.  Access to a
+network may be denied when the modification itself materially and
+adversely affects the operation of the network or violates the rules and
+protocols for communication across the network.
+
+  Corresponding Source conveyed, and Installation Information provided,
+in accord with this section must be in a format that is publicly
+documented (and with an implementation available to the public in
+source code form), and must require no special password or key for
+unpacking, reading or copying.
+
+  7. Additional Terms.
+
+  "Additional permissions" are terms that supplement the terms of this
+License by making exceptions from one or more of its conditions.
+Additional permissions that are applicable to the entire Program shall
+be treated as though they were included in this License, to the extent
+that they are valid under applicable law.  If additional permissions
+apply only to part of the Program, that part may be used separately
+under those permissions, but the entire Program remains governed by
+this License without regard to the additional permissions.
+
+  When you convey a copy of a covered work, you may at your option
+remove any additional permissions from that copy, or from any part of
+it.  (Additional permissions may be written to require their own
+removal in certain cases when you modify the work.)  You may place
+additional permissions on material, added by you to a covered work,
+for which you have or can give appropriate copyright permission.
+
+  Notwithstanding any other provision of this License, for material you
+add to a covered work, you may (if authorized by the copyright holders of
+that material) supplement the terms of this License with terms:
+
+    a) Disclaiming warranty or limiting liability differently from the
+    terms of sections 15 and 16 of this License; or
+
+    b) Requiring preservation of specified reasonable legal notices or
+    author attributions in that material or in the Appropriate Legal
+    Notices displayed by works containing it; or
+
+    c) Prohibiting misrepresentation of the origin of that material, or
+    requiring that modified versions of such material be marked in
+    reasonable ways as different from the original version; or
+
+    d) Limiting the use for publicity purposes of names of licensors or
+    authors of the material; or
+
+    e) Declining to grant rights under trademark law for use of some
+    trade names, trademarks, or service marks; or
+
+    f) Requiring indemnification of licensors and authors of that
+    material by anyone who conveys the material (or modified versions of
+    it) with contractual assumptions of liability to the recipient, for
+    any liability that these contractual assumptions directly impose on
+    those licensors and authors.
+
+  All other non-permissive additional terms are considered "further
+restrictions" within the meaning of section 10.  If the Program as you
+received it, or any part of it, contains a notice stating that it is
+governed by this License along with a term that is a further
+restriction, you may remove that term.  If a license document contains
+a further restriction but permits relicensing or conveying under this
+License, you may add to a covered work material governed by the terms
+of that license document, provided that the further restriction does
+not survive such relicensing or conveying.
+
+  If you add terms to a covered work in accord with this section, you
+must place, in the relevant source files, a statement of the
+additional terms that apply to those files, or a notice indicating
+where to find the applicable terms.
+
+  Additional terms, permissive or non-permissive, may be stated in the
+form of a separately written license, or stated as exceptions;
+the above requirements apply either way.
+
+  8. Termination.
+
+  You may not propagate or modify a covered work except as expressly
+provided under this License.  Any attempt otherwise to propagate or
+modify it is void, and will automatically terminate your rights under
+this License (including any patent licenses granted under the third
+paragraph of section 11).
+
+  However, if you cease all violation of this License, then your
+license from a particular copyright holder is reinstated (a)
+provisionally, unless and until the copyright holder explicitly and
+finally terminates your license, and (b) permanently, if the copyright
+holder fails to notify you of the violation by some reasonable means
+prior to 60 days after the cessation.
+
+  Moreover, your license from a particular copyright holder is
+reinstated permanently if the copyright holder notifies you of the
+violation by some reasonable means, this is the first time you have
+received notice of violation of this License (for any work) from that
+copyright holder, and you cure the violation prior to 30 days after
+your receipt of the notice.
+
+  Termination of your rights under this section does not terminate the
+licenses of parties who have received copies or rights from you under
+this License.  If your rights have been terminated and not permanently
+reinstated, you do not qualify to receive new licenses for the same
+material under section 10.
+
+  9. Acceptance Not Required for Having Copies.
+
+  You are not required to accept this License in order to receive or
+run a copy of the Program.  Ancillary propagation of a covered work
+occurring solely as a consequence of using peer-to-peer transmission
+to receive a copy likewise does not require acceptance.  However,
+nothing other than this License grants you permission to propagate or
+modify any covered work.  These actions infringe copyright if you do
+not accept this License.  Therefore, by modifying or propagating a
+covered work, you indicate your acceptance of this License to do so.
+
+  10. Automatic Licensing of Downstream Recipients.
+
+  Each time you convey a covered work, the recipient automatically
+receives a license from the original licensors, to run, modify and
+propagate that work, subject to this License.  You are not responsible
+for enforcing compliance by third parties with this License.
+
+  An "entity transaction" is a transaction transferring control of an
+organization, or substantially all assets of one, or subdividing an
+organization, or merging organizations.  If propagation of a covered
+work results from an entity transaction, each party to that
+transaction who receives a copy of the work also receives whatever
+licenses to the work the party's predecessor in interest had or could
+give under the previous paragraph, plus a right to possession of the
+Corresponding Source of the work from the predecessor in interest, if
+the predecessor has it or can get it with reasonable efforts.
+
+  You may not impose any further restrictions on the exercise of the
+rights granted or affirmed under this License.  For example, you may
+not impose a license fee, royalty, or other charge for exercise of
+rights granted under this License, and you may not initiate litigation
+(including a cross-claim or counterclaim in a lawsuit) alleging that
+any patent claim is infringed by making, using, selling, offering for
+sale, or importing the Program or any portion of it.
+
+  11. Patents.
+
+  A "contributor" is a copyright holder who authorizes use under this
+License of the Program or a work on which the Program is based.  The
+work thus licensed is called the contributor's "contributor version".
+
+  A contributor's "essential patent claims" are all patent claims
+owned or controlled by the contributor, whether already acquired or
+hereafter acquired, that would be infringed by some manner, permitted
+by this License, of making, using, or selling its contributor version,
+but do not include claims that would be infringed only as a
+consequence of further modification of the contributor version.  For
+purposes of this definition, "control" includes the right to grant
+patent sublicenses in a manner consistent with the requirements of
+this License.
+
+  Each contributor grants you a non-exclusive, worldwide, royalty-free
+patent license under the contributor's essential patent claims, to
+make, use, sell, offer for sale, import and otherwise run, modify and
+propagate the contents of its contributor version.
+
+  In the following three paragraphs, a "patent license" is any express
+agreement or commitment, however denominated, not to enforce a patent
+(such as an express permission to practice a patent or covenant not to
+sue for patent infringement).  To "grant" such a patent license to a
+party means to make such an agreement or commitment not to enforce a
+patent against the party.
+
+  If you convey a covered work, knowingly relying on a patent license,
+and the Corresponding Source of the work is not available for anyone
+to copy, free of charge and under the terms of this License, through a
+publicly available network server or other readily accessible means,
+then you must either (1) cause the Corresponding Source to be so
+available, or (2) arrange to deprive yourself of the benefit of the
+patent license for this particular work, or (3) arrange, in a manner
+consistent with the requirements of this License, to extend the patent
+license to downstream recipients.  "Knowingly relying" means you have
+actual knowledge that, but for the patent license, your conveying the
+covered work in a country, or your recipient's use of the covered work
+in a country, would infringe one or more identifiable patents in that
+country that you have reason to believe are valid.
+
+  If, pursuant to or in connection with a single transaction or
+arrangement, you convey, or propagate by procuring conveyance of, a
+covered work, and grant a patent license to some of the parties
+receiving the covered work authorizing them to use, propagate, modify
+or convey a specific copy of the covered work, then the patent license
+you grant is automatically extended to all recipients of the covered
+work and works based on it.
+
+  A patent license is "discriminatory" if it does not include within
+the scope of its coverage, prohibits the exercise of, or is
+conditioned on the non-exercise of one or more of the rights that are
+specifically granted under this License.  You may not convey a covered
+work if you are a party to an arrangement with a third party that is
+in the business of distributing software, under which you make payment
+to the third party based on the extent of your activity of conveying
+the work, and under which the third party grants, to any of the
+parties who would receive the covered work from you, a discriminatory
+patent license (a) in connection with copies of the covered work
+conveyed by you (or copies made from those copies), or (b) primarily
+for and in connection with specific products or compilations that
+contain the covered work, unless you entered into that arrangement,
+or that patent license was granted, prior to 28 March 2007.
+
+  Nothing in this License shall be construed as excluding or limiting
+any implied license or other defenses to infringement that may
+otherwise be available to you under applicable patent law.
+
+  12. No Surrender of Others' Freedom.
+
+  If conditions are imposed on you (whether by court order, agreement or
+otherwise) that contradict the conditions of this License, they do not
+excuse you from the conditions of this License.  If you cannot convey a
+covered work so as to satisfy simultaneously your obligations under this
+License and any other pertinent obligations, then as a consequence you may
+not convey it at all.  For example, if you agree to terms that obligate you
+to collect a royalty for further conveying from those to whom you convey
+the Program, the only way you could satisfy both those terms and this
+License would be to refrain entirely from conveying the Program.
+
+  13. Use with the GNU Affero General Public License.
+
+  Notwithstanding any other provision of this License, you have
+permission to link or combine any covered work with a work licensed
+under version 3 of the GNU Affero General Public License into a single
+combined work, and to convey the resulting work.  The terms of this
+License will continue to apply to the part which is the covered work,
+but the special requirements of the GNU Affero General Public License,
+section 13, concerning interaction through a network will apply to the
+combination as such.
+
+  14. Revised Versions of this License.
+
+  The Free Software Foundation may publish revised and/or new versions of
+the GNU General Public License from time to time.  Such new versions will
+be similar in spirit to the present version, but may differ in detail to
+address new problems or concerns.
+
+  Each version is given a distinguishing version number.  If the
+Program specifies that a certain numbered version of the GNU General
+Public License "or any later version" applies to it, you have the
+option of following the terms and conditions either of that numbered
+version or of any later version published by the Free Software
+Foundation.  If the Program does not specify a version number of the
+GNU General Public License, you may choose any version ever published
+by the Free Software Foundation.
+
+  If the Program specifies that a proxy can decide which future
+versions of the GNU General Public License can be used, that proxy's
+public statement of acceptance of a version permanently authorizes you
+to choose that version for the Program.
+
+  Later license versions may give you additional or different
+permissions.  However, no additional obligations are imposed on any
+author or copyright holder as a result of your choosing to follow a
+later version.
+
+  15. Disclaimer of Warranty.
+
+  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY
+APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT
+HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY
+OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,
+THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM
+IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF
+ALL NECESSARY SERVICING, REPAIR OR CORRECTION.
+
+  16. Limitation of Liability.
+
+  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
+WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS
+THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY
+GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE
+USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF
+DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD
+PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),
+EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF
+SUCH DAMAGES.
+
+  17. Interpretation of Sections 15 and 16.
+
+  If the disclaimer of warranty and limitation of liability provided
+above cannot be given local legal effect according to their terms,
+reviewing courts shall apply local law that most closely approximates
+an absolute waiver of all civil liability in connection with the
+Program, unless a warranty or assumption of liability accompanies a
+copy of the Program in return for a fee.
+
+                     END OF TERMS AND CONDITIONS
+
+            How to Apply These Terms to Your New Programs
+
+  If you develop a new program, and you want it to be of the greatest
+possible use to the public, the best way to achieve this is to make it
+free software which everyone can redistribute and change under these terms.
+
+  To do so, attach the following notices to the program.  It is safest
+to attach them to the start of each source file to most effectively
+state the exclusion of warranty; and each file should have at least
+the "copyright" line and a pointer to where the full notice is found.
+
+    <one line to give the program's name and a brief idea of what it does.>
+    Copyright (C) <year>  <name of author>
+
+    This program is free software: you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation, either version 3 of the License, or
+    (at your option) any later version.
+
+    This program is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with this program.  If not, see <https://www.gnu.org/licenses/>.
+
+Also add information on how to contact you by electronic and paper mail.
+
+  If the program does terminal interaction, make it output a short
+notice like this when it starts in an interactive mode:
+
+    <program>  Copyright (C) <year>  <name of author>
+    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
+    This is free software, and you are welcome to redistribute it
+    under certain conditions; type `show c' for details.
+
+The hypothetical commands `show w' and `show c' should show the appropriate
+parts of the General Public License.  Of course, your program's commands
+might be different; for a GUI interface, you would use an "about box".
+
+  You should also get your employer (if you work as a programmer) or school,
+if any, to sign a "copyright disclaimer" for the program, if necessary.
+For more information on this, and how to apply and follow the GNU GPL, see
+<https://www.gnu.org/licenses/>.
+
+  The GNU General Public License does not permit incorporating your program
+into proprietary programs.  If your program is a subroutine library, you
+may consider it more useful to permit linking proprietary applications with
+the library.  If this is what you want to do, use the GNU Lesser General
+Public License instead of this License.  But first, please read
+<https://www.gnu.org/licenses/why-not-lgpl.html>.
```

### Comparing `mealpy-2.5.3/PKG-INFO` & `mealpy-2.5.3a1/PKG-INFO`

 * *Files 20% similar despite different names*

```diff
@@ -1,1147 +1,1136 @@
-Metadata-Version: 2.1
-Name: mealpy
-Version: 2.5.3
-Summary: MEALPY: An Open-source Library for Latest Meta-heuristic Algorithms in Python
-Home-page: https://github.com/thieu1995/mealpy
-Author: Thieu
-Author-email: nguyenthieu2102@gmail.com
-License: GPLv3
-Project-URL: Documentation, https://mealpy.readthedocs.io/
-Project-URL: Source Code, https://github.com/thieu1995/mealpy
-Project-URL: Bug Tracker, https://github.com/thieu1995/mealpy/issues
-Project-URL: Change Log, https://github.com/thieu1995/mealpy/blob/master/ChangeLog.md
-Project-URL: Forum, https://t.me/+fRVCJGuGJg1mNDg1
-Description: 
-        <p align="center">
-        <img style="height:400px;" 
-        src="https://thieu1995.github.io/post/2022-04/19-mealpy-tutorials/mealpy5-nobg.png" 
-        alt="MEALPY"/>
-        </p>
-        
-        ---
-        
-        
-        [![GitHub release](https://img.shields.io/badge/release-2.5.3-yellow.svg)](https://github.com/thieu1995/mealpy/releases)
-        [![Wheel](https://img.shields.io/pypi/wheel/gensim.svg)](https://pypi.python.org/pypi/mealpy) 
-        [![PyPI version](https://badge.fury.io/py/mealpy.svg)](https://badge.fury.io/py/mealpy)
-        ![PyPI - Python Version](https://img.shields.io/pypi/pyversions/mealpy.svg)
-        ![PyPI - Status](https://img.shields.io/pypi/status/mealpy.svg)
-        ![PyPI - Downloads](https://img.shields.io/pypi/dm/mealpy.svg)
-        [![Downloads](https://pepy.tech/badge/mealpy)](https://pepy.tech/project/mealpy)
-        [![Tests & Publishes to PyPI](https://github.com/thieu1995/mealpy/actions/workflows/publish-package.yaml/badge.svg)](https://github.com/thieu1995/mealpy/actions/workflows/publish-package.yaml)
-        ![GitHub Release Date](https://img.shields.io/github/release-date/thieu1995/mealpy.svg)
-        [![Documentation Status](https://readthedocs.org/projects/mealpy/badge/?version=latest)](https://mealpy.readthedocs.io/en/latest/?badge=latest)
-        [![Chat](https://img.shields.io/badge/Chat-on%20Telegram-blue)](https://t.me/+fRVCJGuGJg1mNDg1)
-        [![Average time to resolve an issue](http://isitmaintained.com/badge/resolution/thieu1995/mealpy.svg)](http://isitmaintained.com/project/thieu1995/mealpy "Average time to resolve an issue")
-        [![Percentage of issues still open](http://isitmaintained.com/badge/open/thieu1995/mealpy.svg)](http://isitmaintained.com/project/thieu1995/mealpy "Percentage of issues still open")
-        ![GitHub contributors](https://img.shields.io/github/contributors/thieu1995/mealpy.svg)
-        [![GitTutorial](https://img.shields.io/badge/PR-Welcome-%23FF8300.svg?)](https://git-scm.com/book/en/v2/GitHub-Contributing-to-a-Project)
-        [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3711948.svg)](https://doi.org/10.5281/zenodo.3711948)
-        [![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)
-        
-        
-        MEALPY is the largest python library for most of the cutting-edge nature-inspired meta-heuristic algorithms (population-based). Population meta-heuristic algorithms (PMA) are the most popular algorithms in the field of 
-        approximate optimization.
-        
-        * **Free software:** GNU General Public License (GPL) V3 license
-        * **Total algorithms**: 174 (102 original, 45 official variants, 27 developed variants)
-        * **Documentation:** https://mealpy.readthedocs.io/en/latest/
-        * **Python versions:** 3.7.x, 3.8.x, 3.9.x, 3.10.x, 3.11.x
-        * **Dependencies:** numpy, scipy, pandas, matplotlib
-        
-        
-        # Goals
-        
-        Our goals are to implement all of the classical as well as the state-of-the-art nature-inspired algorithms, create a simple interface that helps researchers access optimization algorithms as quickly as possible, and share knowledge of the optimization field with everyone without a fee. What you can do with mealpy:
-        
-        - Analyse parameters of meta-heuristic algorithms.
-        - Perform Qualitative and Quantitative Analysis of algorithms.
-        - Analyse rate of convergence of algorithms.
-        - Test and Analyse the scalability and the robustness of algorithms.
-        - Save results in various formats (csv, json, pickle, png, pdf, jpeg)
-        - Export and import models can also be done with Mealpy.
-        
-        
-        
-        # Installation
-        
-        ### Install with pip
-        Install the [current PyPI release](https://pypi.python.org/pypi/mealpy):
-        ```sh 
-        $ pip install mealpy==2.5.3
-        ```
-        
-        ### Install from source
-        In case you want to install directly from the source code, use:
-        ```sh 
-        $ git clone https://github.com/thieu1995/mealpy.git
-        $ cd mealpy
-        $ python setup.py install
-        ```
-        
-        
-        # Usage
-        
-        After installation, you can import Mealpy as any other Python module:
-        
-        ```sh
-        $ python
-        >>> import mealpy
-        >>> mealpy.__version__
-        ```
-        
-        Let's go through a basic and advanced example.
-        
-        
-        ## Examples
-        
-        ### Simple Benchmark Function
-        
-        ```python 
-        from mealpy.bio_based import SMA
-        import numpy as np
-        
-        def fitness_function(solution):
-            return np.sum(solution**2)
-        
-        problem = {
-            "fit_func": fitness_function,
-            "lb": [-100, ] * 30,
-            "ub": [100, ] * 30,
-            "minmax": "min",
-            "log_to": None,
-            "save_population": False,
-        }
-        
-        ## Run the algorithm
-        model = SMA.BaseSMA(epoch=100, pop_size=50, pr=0.03)
-        best_position, best_fitness = model.solve(problem)
-        print(f"Best solution: {best_position}, Best fitness: {best_fitness}")
-        ```
-        
-        ### Constrained Benchmark Function
-        * [The Constrained Benchmark Function](https://github.com/thieu1995/mealpy/tree/master/examples/applications/run_constraint_functions.py)
-        
-        
-        ### Multi-objective Benchmark Function
-        * [Multi-objective benchmark functions](https://github.com/thieu1995/mealpy/tree/master/examples/applications/run_multi_objective_functions.py)
-        
-        
-        ### Custom Problem 
-        
-        For our custom problem, we can create a class and inherit from the Problem class, named the child class the  
-        'Squared' class. In the initialization method of the 'Squared' class, we have to set the *lb*, *ub*, and *minmax*  
-        of the problem (lb: a list of lower bound values, ub: a list of upper bound values, and minmax: a string specifying 
-        whether the problem is a 'min' or 'max' problem). 
-        
-        Afterwards, we have to override the abstract method 'fit_func()', which takes a parameter 'solution' (the solution 
-        to be evaluated) and returns the function value. The resulting code should look something like the code snippet 
-        below. 'Name' is an additional parameter we want to include in this class, and you can include any other additional 
-        parameters you need.
-        
-        
-        ```python 
-        import numpy as np
-        from mealpy.bio_based import BBO
-        from mealpy.utils.problem import Problem
-        
-        # Our custom problem class
-        class Squared(Problem):
-            def __init__(self, lb=(-5, -5, -5, -5, -5, -5), ub=(5, 5, 5, 5, 5, 5), minmax="min", name="Squared", **kwargs):
-                super().__init__(lb, ub, minmax, **kwargs)
-                self.name = name
-        
-            def fit_func(self, solution):
-                return np.sum(solution ** 2)
-        ```
-        
-        Now, we define an algorithm, and pass an instance of our *Squared* class as the problem argument. 
-        
-        ```python
-        problem = Squared(lb=[-10] * 20, ub=[10] * 20, minmax="min")
-        model = BBO.BaseBBO(epoch=10, pop_size=50)
-        best_position, best_fitness = model.solve(problem)
-        
-        print(best_position)
-        print(best_fitness)
-        print(model.get_parameters())
-        print(model.get_name())
-        print(model.get_attributes()["solution"])
-        print(model.problem.get_name())
-        print(model.problem.n_dims)
-        ```
-        
-        
-        ### Tuner class (GridSearchCV/ParameterSearch, Hyper-parameter tuning)
-        
-        We build a dedicated class, Tuner, that can help you tune your algorithm's parameters.
-        
-        ```python
-        import numpy as np
-        from mealpy.bio_based import BBO
-        from mealpy.tuner import Tuner          # Remember this
-        
-        
-        def fitness(solution):
-            return np.sum(solution**2)
-        
-        problem = {
-            "lb": [-100, ]*50,
-            "ub": [100, ]*50,
-            "minmax": "min",
-            "fit_func": fitness,
-            "name": "Squared Problem",
-            "log_to": None,
-        }
-        
-        paras_bbo_grid = {
-            "epoch": [100],
-            "pop_size": [50],
-            "elites": [2, 3, 4, 5],
-            "p_m": [0.01, 0.02, 0.05, 0.1, 0.15, 0.2]
-        }
-        
-        term = {
-          "max_fe": 10000
-        }
-        
-        if __name__ == "__main__":
-            model = BBO.BaseBBO()
-        
-            tuner = Tuner(model, paras_bbo_grid)
-            tuner.execute(problem=problem, termination=term, n_trials=5, n_jobs=5, mode="thread", n_workers=4, verbose=True)
-            ## Solve this problem 5 times (n_trials) using 5 processes (n_jobs), each process will handle 1 trial. 
-            ## The mode to run the solver is thread (mode), we will calculate the fitness of 4 solutions (n_workers) at the same time 
-        
-            print(tuner.best_score)
-            print(tuner.best_params)
-            print(tuner.best_algorithm)
-            print(tuner.best_algorithm.get_name())
-            
-            ## Save results to csv file 
-            tuner.export_results(save_path="history/tuning", save_as="csv")
-            
-            ## Re-solve the best model on your problem 
-            best_position, best_fitness = tuner.resolve()
-        
-            print(best_position, best_fitness)
-            print(tuner.problem.get_name())
-        ```
-        
-        
-        ### Multitask class (Multitask solving)
-        
-        We also build a dedicated class, Multitask, that can help you run several scenarios. For example:
-        
-        1. Run 1 algorithm with 1 problem, and multiple trials
-        2. Run 1 algorithm with multiple problems, and multiple trials
-        3. Run multiple algorithms with 1 problem, and multiple trials
-        4. Run multiple algorithms with multiple problems, and multiple trials
-        
-        
-        ```python
-        #### Using multiple algorithm to solve multiple problems with multiple trials
-        
-        ## Import libraries
-        ## For example, we want to solve F5, F10, F29 problem in CEC-2017
-        from opfunu.cec_based.cec2017 import F52017, F102017, F292017
-        
-        from mealpy.bio_based import BBO
-        from mealpy.evolutionary_based import DE
-        from mealpy.multitask import Multitask          # Remember this
-        
-        
-        ## You can define your own problems
-        
-        f1 = F52017(30, f_bias=0)
-        f2 = F102017(30, f_bias=0)
-        f3 = F292017(30, f_bias=0)
-        
-        p1 = {
-            "lb": f1.lb.tolist(),
-            "ub": f1.ub.tolist(),
-            "minmax": "min",
-            "fit_func": f1.evaluate,
-            "name": "F5-CEC2017",
-            "log_to": None,
-        }
-        
-        p2 = {
-            "lb": f2.lb.tolist(),
-            "ub": f2.ub.tolist(),
-            "minmax": "min",
-            "fit_func": f2.evaluate,
-            "name": "F10-CEC2017",
-            "log_to": None,
-        }
-        
-        p3 = {
-            "lb": f3.lb.tolist(),
-            "ub": f3.ub.tolist(),
-            "minmax": "min",
-            "fit_func": f3.evaluate,
-            "name": "F29-CEC2017",
-            "log_to": None,
-        }
-        
-        ## Define models
-        
-        model1 = BBO.BaseBBO(epoch=10, pop_size=50)
-        model2 = BBO.OriginalBBO(epoch=10, pop_size=50)
-        model3 = DE.BaseDE(epoch=10, pop_size=50)
-        
-        ## Define termination if needed
-        term = {
-            "max_fe": 10000
-        }
-        
-        ## Define and run Multitask
-        if __name__ == "__main__":
-            multitask = Multitask(algorithms=(model1, model2, model3), problems=(p1, p2, p3), terminations=(term, ), modes=("thread", ))
-            # default modes = "single", default termination = epoch (as defined in problem dictionary)
-            multitask.execute(n_trials=5, n_jobs=5, save_path="history", save_as="csv", save_convergence=False, verbose=False)
-            
-            ## Check the directory: history/, you will see list of .csv result files
-        ```
-        
-        For more usage examples please look at [examples](/examples) folder.
-        
-        More advanced examples can also be found in the [Mealpy-examples repository](https://github.com/thieu1995/mealpy_examples).
-        
-        
-        ### Get Visualize Figures
-        
-        
-        * [Tutorials](/examples/utils/visualize/all_charts.py)
-        
-        <p align="center"><img src="https://thieu1995.github.io/post/2022-04/19-mealpy-tutorials/mealpy2.png" alt="MEALPY"/>
-        </p>
-        
-        
-        ## Mealpy Application
-        
-        ### Mealpy + Neural Network (Replace the Gradient Descent Optimizer)
-        
-        * Time-series Problem:
-          * Traditional MLP
-            code: [Link](https://github.com/thieu1995/mealpy/tree/master/examples/applications/keras/traditional-mlp-time-series.py)
-          * Hybrid code (Mealpy +
-            MLP): [Link](https://github.com/thieu1995/mealpy/tree/master/examples/applications/keras/mha-hybrid-mlp-time-series.py)
-        * Classification Problem:
-          * Traditional MLP
-            code: [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/keras/traditional-mlp-classification.py)
-          * Hybrid code (Mealpy +
-            MLP): [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/keras/mha-hybrid-mlp-classification.py)
-        
-        ### Mealpy + Neural Network (Optimize Neural Network Hyper-parameter)
-        
-        Code: [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/keras/mha-hyper-parameter-mlp-time-series.py)
-        
-        ### Other Applications
-        
-        * Solving Knapsack Problem (Discrete
-          problems): [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/discrete-problems/knapsack-problem.py)
-        
-        * Optimize SVM (SVC)
-          model: [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/sklearn/svm_classification.py)
-        
-        * Optimize Linear Regression
-          Model: [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/pytorch/linear_regression.py)
-        
-        * Travelling Salesman Problem: https://github.com/thieu1995/MHA-TSP 
-        
-        * Feature selection problem: https://github.com/thieu1995/MHA-FS
-        
-        
-        
-        ## Tutorial Videos
-        
-        All tutorial videos: [Link](https://mealpy.readthedocs.io/en/latest/pages/general/video_tutorials.html)
-        
-        All code examples: [Link](https://github.com/thieu1995/mealpy/tree/master/examples)
-        
-        All visualization examples: [Link](https://mealpy.readthedocs.io/en/latest/pages/visualization.html)
-        
-        
-        
-        ### Get helps (questions, problems)
-        
-        * Official source code repo: https://github.com/thieu1995/mealpy
-        * Official document: https://mealpy.readthedocs.io/
-        * Download releases: https://pypi.org/project/mealpy/
-        * Issue tracker: https://github.com/thieu1995/mealpy/issues
-        * Notable changes log: https://github.com/thieu1995/mealpy/blob/master/ChangeLog.md
-        * Examples with different meapy version: https://github.com/thieu1995/mealpy/blob/master/EXAMPLES.md
-        
-        * This project also related to our another projects which are "meta-heuristics" and "neural-network", check it here
-            * https://github.com/thieu1995/opfunu
-            * https://github.com/thieu1995/metaheuristics
-            * https://github.com/aiir-team
-        
-        **Want to have an instant assistant? Join our telegram community at [link](https://t.me/+fRVCJGuGJg1mNDg1)**
-        We share lots of information, questions, and answers there. You will get more support and knowledge there.
-        
-        ### Cite Us
-        
-        If you are using mealpy in your project, we would appreciate citations:
-        
-        ```bibtex 
-        @article{van2023mealpy,
-          title={MEALPY: An open-source library for latest meta-heuristic algorithms in Python},
-          author={Van Thieu, Nguyen and Mirjalili, Seyedali},
-          journal={Journal of Systems Architecture},
-          year={2023},
-          publisher={Elsevier}
-        }
-        
-        @article{van2023groundwater,
-          title={Groundwater level modeling using Augmented Artificial Ecosystem Optimization},
-          author={Van Thieu, Nguyen and Barma, Surajit Deb and Van Lam, To and Kisi, Ozgur and Mahesha, Amai},
-          journal={Journal of Hydrology},
-          volume={617},
-          pages={129034},
-          year={2023},
-          publisher={Elsevier}
-        }
-        ```
-        
-        
-        
-        # List of papers used MEALPY
-        
-        - Min, J., Oh, M., Kim, W., Seo, H., & Paek, J. (2022, October). Evaluation of Metaheuristic Algorithms for TAS Scheduling in Time-Sensitive Networking. In 2022 13th International Conference on Information and Communication Technology Convergence (ICTC) (pp. 809-812). IEEE.
-        - Khozeimeh, F., Sharifrazi, D., Izadi, N. H., Joloudari, J. H., Shoeibi, A., Alizadehsani, R., ... & Islam, S. M. S. (2021). Combining a convolutional neural network with autoencoders to predict the survival chance of COVID-19 patients. Scientific Reports, 11(1), 15343.
-        - Rajesh, K., Jain, E., & Kotecha, P. (2022). A Multi-Objective approach to the Electric Vehicle Routing Problem. arXiv preprint arXiv:2208.12440.
-        - SÃ¡nchez, A. J. H., & Upegui, F. R. (2022). Una herramienta para el diseÃ±o de redes MSMN de banda ancha en lÃ­neas de transmisiÃ³n basada en algoritmos heurÃ­sticos de optimizaciÃ³n comparados. Revista IngenierÃ­a UC, 29(2), 106-123.
-        - Khanmohammadi, M., Armaghani, D. J., & Sabri Sabri, M. M. (2022). Prediction and Optimization of Pile Bearing Capacity Considering Effects of Time. Mathematics, 10(19), 3563.
-        - Kudela, J. (2023). The Evolutionary Computation Methods No One Should Use. arXiv preprint arXiv:2301.01984.
-        - Vieira, M., Faia, R., Pinto, T., & Vale, Z. (2022, September). Schedule Peer-to-Peer Transactions of an Energy Community Using Particle Swarm. In 2022 18th International Conference on the European Energy Market (EEM) (pp. 1-6). IEEE.
-        - Bui, X. N., Nguyen, H., Le, Q. T., & Le, T. N. Forecasting PM. MINING SCIENCE ANDTECHNOLOGY (Russia), 111.
-        - Bui, X. N., Nguyen, H., Le, Q. T., & Le, T. N. (2022). Forecasting PM 2.5 emissions in open-pit minesusing a functional link neural network optimized by various optimization algorithms. Gornye nauki i tekhnologii= Mining Science and Technology (Russia), 7(2), 111-125.
-        - DoÄan, E., & YÃ¶rÃ¼keren, N. (2022). Enhancement of Transmission System Security with Archimedes Optimization Algorithm.
-        - Ayub, N., Aurangzeb, K., Awais, M., & Ali, U. (2020, November). Electricity theft detection using CNN-GRU and manta ray foraging optimization algorithm. In 2020 IEEE 23Rd international multitopic conference (INMIC) (pp. 1-6). IEEE.
-        - Pintilie, L., Nechita, M. T., Suditu, G. D., Dafinescu, V., & DrÄgoi, E. N. (2022). Photo-decolorization of Eriochrome Black T: process optimization with Differential Evolution algorithm. In PASEW-22, MESSH-22 & CABES-22 April 19â21, 2022 Paris (France). Eminent Association of Pioneers.
-        - LaTorre, A., Molina, D., Osaba, E., Poyatos, J., Del Ser, J., & Herrera, F. (2021). A prescription of methodological guidelines for comparing bio-inspired optimization algorithms. Swarm and Evolutionary Computation, 67, 100973.
-        - Gottam, S., Nanda, S. J., & Maddila, R. K. (2021, December). A CNN-LSTM Model Trained with Grey Wolf Optimizer for Prediction of Household Power Consumption. In 2021 IEEE International Symposium on Smart Electronic Systems (iSES)(Formerly iNiS) (pp. 355-360). IEEE.
-        - Darius, P. S., Devadason, J., & Solomon, D. G. (2022, December). Prospects of Ant Colony Optimization (ACO) in Various Domains. In 2022 4th International Conference on Circuits, Control, Communication and Computing (I4C) (pp. 79-84). IEEE.
-        - Ayub, N., Irfan, M., Awais, M., Ali, U., Ali, T., Hamdi, M., ... & Muhammad, F. (2020). Big data analytics for short and medium-term electricity load forecasting using an AI techniques ensembler. Energies, 13(19), 5193.
-        - Biundini, I. Z., Melo, A. G., Coelho, F. O., HonÃ³rio, L. M., Marcato, A. L., & Pinto, M. F. (2022). Experimentation and Simulation with Autonomous Coverage Path Planning for UAVs. Journal of Intelligent & Robotic Systems, 105(2), 46.
-        - Yousaf, I., Anwar, F., Imtiaz, S., Almadhor, A. S., Ishmanov, F., & Kim, S. W. (2022). An Optimized Hyperparameter of Convolutional Neural Network Algorithm for Bug Severity Prediction in Alzheimerâs-Based IoT System. Computational Intelligence and Neuroscience, 2022.
-        - Xu, L., Yan, W., & Ji, J. (2023). The research of a novel WOG-YOLO algorithm for autonomous driving object detection. Scientific reports, 13(1), 3699.
-        - Costache, R. D., Arabameri, A., Islam, A. R. M. T., Abba, S. I., Pandey, M., Ajin, R. S., & Pham, B. T. (2022). Flood susceptibility computation using state-of-the-art machine learning and optimization algorithms.
-        - Del Ser, J., Osaba, E., Martinez, A. D., Bilbao, M. N., Poyatos, J., Molina, D., & Herrera, F. (2021, December). More is not always better: insights from a massive comparison of meta-heuristic algorithms over real-parameter optimization problems. In 2021 IEEE Symposium Series on Computational Intelligence (SSCI) (pp. 1-7). IEEE.
-        - Rustam, F., Aslam, N., De La Torre DÃ­ez, I., Khan, Y. D., MazÃ³n, J. L. V., RodrÃ­guez, C. L., & Ashraf, I. (2022, November). White Blood Cell Classification Using Texture and RGB Features of Oversampled Microscopic Images. In Healthcare (Vol. 10, No. 11, p. 2230). MDPI.
-        - Neupane, D., Kafle, S., Gurung, S., Neupane, S., & Bhattarai, N. (2021). Optimal sizing and financial analysis of a stand-alone SPV-micro-hydropower hybrid system considering generation uncertainty. International Journal of Low-Carbon Technologies, 16(4), 1479-1491.
-        - Liang, R., Le-Hung, T., & Nguyen-Thoi, T. (2022). Energy consumption prediction of air-conditioning systems in eco-buildings using hunger games search optimization-based artificial neural network model. Journal of Building Engineering, 59, 105087.
-        - He, Z., Nguyen, H., Vu, T. H., Zhou, J., Asteris, P. G., & Mammou, A. (2022). Novel integrated approaches for predicting the compressibility of clay using cascade forward neural networks optimized by swarm-and evolution-based algorithms. Acta Geotechnica, 1-16.
-        - Xu, L., Yan, W., & Ji, J. (2022). The research of a novel WOG-YOLO algorithm forautonomous driving object detection.
-        - Nasir Ayub, M. I., Awais, M., Ali, U., Ali, T., Hamdi, M., Alghamdi, A., & Muhammad, F. Big Data Analytics for Short and Medium Term Electricity Load Forecasting using AI Techniques Ensembler.
-        - Xie, C., Nguyen, H., Choi, Y., & Armaghani, D. J. (2022). Optimized functional linked neural network for predicting diaphragm wall deflection induced by braced excavations in clays. Geoscience Frontiers, 13(2), 101313.
-        - Hakemi, S., Houshmand, M., & Hosseini, S. A. (2022). A Dynamic Quantum-Inspired Genetic Algorithm with Lengthening Chromosome Size.
-        - Kashifi, M. T. City-Wide Crash Risk Prediction and Interpretation Using Deep Learning Model with Multi-Source Big Data. Available at SSRN 4329686.
-        - Nguyen, H., & Hoang, N. D. (2022). Computer vision-based classification of concrete spall severity using metaheuristic-optimized Extreme Gradient Boosting Machine and Deep Convolutional Neural Network. Automation in Construction, 140, 104371.
-        - Zheng, J., Lu, Z., Wu, K., Ning, G. H., & Li, D. (2020). Coinage-metal-based cyclic trinuclear complexes with metalâmetal interactions: Theories to experiments and structures to functions. Chemical Reviews, 120(17), 9675-9742.
-        - Van Thieu, N., Barma, S. D., Van Lam, T., Kisi, O., & Mahesha, A. (2023). Groundwater level modeling using Augmented Artificial Ecosystem Optimization. Journal of Hydrology, 617, 129034.
-        - Mo, Z., Zhang, Z., Miao, Q., & Tsui, K. L. (2022). Intelligent Informative Frequency Band Searching Assisted by a Dynamic Bandit Tree Method for Machine Fault Diagnosis. IEEE/ASME Transactions on Mechatronics.
-        - Dangi, D., Chandel, S. T., Dixit, D. K., Sharma, S., & Bhagat, A. (2023). An Efficient Model for Sentiment Analysis using Artificial Rabbits Optimized Vector Functional Link Network. Expert Systems with Applications, 119849.
-        - Dey, S., Roychoudhury, R., Malakar, S., & Sarkar, R. (2022). An optimized fuzzy ensemble of convolutional neural networks for detecting tuberculosis from Chest X-ray images. Applied Soft Computing, 114, 108094.
-        - Mousavirad, S. J., & Alexandre, L. A. (2022). Population-based JPEG Image Compression: Problem Re-Formulation. arXiv preprint arXiv:2212.06313.
-        - Tsui, K. L. Intelligent Informative Frequency Band Searching Assisted by A Dynamic Bandit Tree Method for Machine Fault Diagnosis.
-        - Neupane, D. (2020). Optimal Sizing and Performance Analysis of Solar PV-Micro hydropower Hybrid System in the Context of Rural Area of Nepal (Doctoral dissertation, Pulchowk Campus).
-        - LaTorre, A., Molina, D., Osaba, E., Poyatos, J., Del Ser, J., & Herrera, F. Swarm and Evolutionary Computation.
-        - Vieira, M. A. (2022). OtimizaÃ§Ã£o dos custos operacionais de uma comunidade energÃ©tica considerando transaÃ§Ãµes locais em âpeer-to-peerâ (Doctoral dissertation).
-        - ToÄaÃ§ar, M. (2022). Using DarkNet models and metaheuristic optimization methods together to detect weeds growing along with seedlings. Ecological Informatics, 68, 101519.
-        - ToÄaÃ§ar, M. (2021). Detection of segmented uterine cancer images by Hotspot Detection method using deep learning models, Pigeon-Inspired Optimization, types-based dominant activation selection approaches. Computers in Biology and Medicine, 136, 104659.
-        - Khan, N. A Short Term Electricity Load and Price Forecasting Model Based on BAT Algorithm in Logistic Regression and CNN-GRU with WOA.
-        - Yelisetti, S., Saini, V. K., Kumar, R., & Lamba, R. (2022, May). Energy Consumption Cost Benefits through Smart Home Energy Management in Residential Buildings: An Indian Case Study. In 2022 IEEE IAS Global Conference on Emerging Technologies (GlobConET) (pp. 930-935). IEEE.
-        - Nguyen, H., Cao, M. T., Tran, X. L., Tran, T. H., & Hoang, N. D. (2022). A novel whale optimization algorithm optimized XGBoost regression for estimating bearing capacity of concrete piles. Neural Computing and Applications, 1-28.
-        - Hirsching, C., de Jongh, S., Eser, D., Suriyah, M., & Leibfried, T. (2022). Meta-heuristic optimization of control structure and design for MMC-HVdc applications. Electric Power Systems Research, 213, 108371.
-        - Amelin, V., Gatiyatullin, E., Romanov, N., Samarkhanov, R., Vasilyev, R., & Yanovich, Y. (2022). Black-Box for Blockchain Parameters Adjustment. IEEE Access, 10, 101795-101802.
-        - Ngo, T. Q., Nguyen, L. Q., & Tran, V. Q. (2022). Novel hybrid machine learning models including support vector machine with meta-heuristic algorithms in predicting unconfined compressive strength of organic soils stabilised with cement and lime. International Journal of Pavement Engineering, 1-18.
-        - Zhu, Y., & Iiduka, H. (2021). Unified Algorithm Framework for Nonconvex Stochastic Optimization in Deep Neural Networks. IEEE Access, 9, 143807-143823.
-        - Hakemi, S., Houshmand, M., KheirKhah, E., & Hosseini, S. A. (2022). A review of recent advances in quantum-inspired metaheuristics. Evolutionary Intelligence, 1-16.
-        - Das, A., Das, S. R., Panda, J. P., Dey, A., Gajrani, K. K., Somani, N., & Gupta, N. (2022). Machine learning based modelling and optimization in hard turning of AISI D6 steel with newly developed AlTiSiN coated carbide tool. arXiv preprint arXiv:2202.00596.
-        - Yelisetti, S., Saini, V. K., Kumar, R., Lamba, R., & Saxena, A. (2022). Optimal energy management system for residential buildings considering the time of use price with swarm intelligence algorithms. Journal of Building Engineering, 59, 105062.
-        - ValdÃ©s, G. T. (2022). Algoritmo para la detecciÃ³n de vehÃ­culos y peatones combinando CNNÂ´ sy tÃ©cnicas de bÃºsqueda.
-        - Sallam, N. M., Saleh, A. I., Ali, H. A., & Abdelsalam, M. M. (2023). An efficient EGWO algorithm as feature selection for B-ALL diagnoses and its subtypes classification using peripheral blood smear images. Alexandria Engineering Journal, 68, 39-66.
-        
-        
-        
-        
-        # Documents
-        
-        * Meta-heuristic Categories: (Based on this article: [link](https://doi.org/10.1016/j.procs.2020.09.075))
-            + Evolutionary-based: Idea from Darwin's law of natural selection, evolutionary computing 
-            + Swarm-based: Idea from movement, interaction of birds, organization of social ...
-            + Physics-based: Idea from physics law such as Newton's law of universal gravitation, black hole, multiverse 
-            + Human-based: Idea from human interaction such as queuing search, teaching learning, ... 
-            + Biology-based: Idea from biology creature (or microorganism),...
-            + System-based: Idea from eco-system, immune-system, network-system, ...
-            + Math-based: Idea from mathematical form or mathematical law such as sin-cosin 
-            + Music-based: Idea from music instrument
-        
-        * Difficulty - Difficulty Level (Personal Opinion): **Objective observation from author**. Depend on the number of 
-          parameters, number of equations, the original ideas, time spend for coding, source lines of code (SLOC).
-            + Easy: A few paras, few equations, SLOC very short
-            + Medium: more equations than Easy level, SLOC longer than Easy level
-            + Hard: Lots of equations, SLOC longer than Medium level, the paper hard to read.
-            + Hard* - Very hard: Lots of equations, SLOC too long, the paper is very hard to read.
-            
-        ** For newbie, we recommend to read the paper of algorithms which difficulty is "easy" or "medium" difficulty level.
-        
-        
-        | **Group**    | **Name**                                        | **Module** | **Class**        | **Year** | **Paras** | **Difficulty** |
-        |--------------|-------------------------------------------------|------------|------------------|----------|-----------|----------------|
-        | Evolutionary | Evolutionary Programming                        | EP         | OriginalEP       | 1964     | 3         | easy           |
-        | Evolutionary | -                                               | -          | LevyEP           | -        | 3         | easy           |
-        | Evolutionary | Evolution Strategies                            | ES         | OriginalES       | 1971     | 3         | easy           |
-        | Evolutionary | -                                               | -          | LevyES           | -        | 3         | easy           |
-        | Evolutionary | Memetic Algorithm                               | MA         | OriginalMA       | 1989     | 7         | easy           |
-        | Evolutionary | Genetic Algorithm                               | GA         | BaseGA           | 1992     | 4         | easy           |
-        | Evolutionary | -                                               | -          | SingleGA         | -        | 7         | easy           |
-        | Evolutionary | -                                               | -          | MultiGA          | -        | 7         | easy           |
-        | Evolutionary | -                                               | -          | EliteSingleGA    | -        | 10        | easy           |
-        | Evolutionary | -                                               | -          | EliteMultiGA     | -        | 10        | easy           |
-        | Evolutionary | Differential Evolution                          | DE         | BaseDE           | 1997     | 5         | easy           |
-        | Evolutionary | -                                               | -          | JADE             | 2009     | 6         | medium         |
-        | Evolutionary | -                                               | -          | SADE             | 2005     | 2         | medium         |
-        | Evolutionary | -                                               | -          | SHADE            | 2013     | 4         | medium         |
-        | Evolutionary | -                                               | -          | L_SHADE          | 2014     | 4         | medium         |
-        | Evolutionary | -                                               | -          | SAP_DE           | 2006     | 3         | medium         |
-        | Evolutionary | Flower Pollination Algorithm                    | FPA        | OriginalFPA      | 2014     | 4         | medium         |
-        | Evolutionary | Coral Reefs Optimization                        | CRO        | OriginalCRO      | 2014     | 11        | medium         |
-        | Evolutionary | -                                               | -          | OCRO             | 2019     | 12        | medium         |
-        | -            | -                                               | -          | -                | -        | -         | -              |
-        | Swarm        | Particle Swarm Optimization                     | PSO        | OriginalPSO      | 1995     | 6         | easy           |
-        | Swarm        | -                                               | -          | PPSO             | 2019     | 2         | medium         |
-        | Swarm        | -                                               | -          | HPSO_TVAC        | 2017     | 4         | medium         |
-        | Swarm        | -                                               | -          | C_PSO            | 2015     | 6         | medium         |
-        | Swarm        | -                                               | -          | CL_PSO           | 2006     | 6         | medium         |
-        | Swarm        | Bacterial Foraging Optimization                 | BFO        | OriginalBFO      | 2002     | 10        | hard           |
-        | Swarm        | -                                               | -          | ABFO             | 2019     | 8         | medium         |
-        | Swarm        | Bees Algorithm                                  | BeesA      | OriginalBeesA    | 2005     | 8         | medium         |
-        | Swarm        | -                                               | -          | ProbBeesA        | 2015     | 5         | medium         |
-        | Swarm        | Cat Swarm Optimization                          | CSO        | OriginalCSO      | 2006     | 11        | hard           |
-        | Swarm        | Artificial Bee Colony                           | ABC        | OriginalABC      | 2007     | 8         | medium         |
-        | Swarm        | Ant Colony Optimization                         | ACO-R      | OriginalACOR     | 2008     | 5         | easy           |
-        | Swarm        | Cuckoo Search Algorithm                         | CSA        | OriginalCSA      | 2009     | 3         | medium         |
-        | Swarm        | Firefly Algorithm                               | FFA        | OriginalFFA      | 2009     | 8         | easy           |
-        | Swarm        | Fireworks Algorithm                             | FA         | OriginalFA       | 2010     | 7         | medium         |
-        | Swarm        | Bat Algorithm                                   | BA         | OriginalBA       | 2010     | 6         | medium         |
-        | Swarm        | -                                               | -          | AdaptiveBA       | -        | 8         | medium         |
-        | Swarm        | -                                               | -          | ModifiedBA       | -        | 5         | medium         |
-        | Swarm        | Fruit-fly Optimization Algorithm                | FOA        | OriginalFOA      | 2012     | 2         | easy           |
-        | Swarm        | -                                               | -          | BaseFOA          | -        | 2         | easy           |
-        | Swarm        | -                                               | -          | WhaleFOA         | 2020     | 2         | medium         |
-        | Swarm        | Social Spider Optimization                      | SSpiderO   | OriginalSSpiderO | 2018     | 4         | hard*          |
-        | Swarm        | Grey Wolf Optimizer                             | GWO        | OriginalGWO      | 2014     | 2         | easy           |
-        | Swarm        | -                                               | -          | RW_GWO           | 2019     | 2         | easy           |
-        | Swarm        | Social Spider Algorithm                         | SSpiderA   | OriginalSSpiderA | 2015     | 5         | medium         |
-        | Swarm        | Ant Lion Optimizer                              | ALO        | OriginalALO      | 2015     | 2         | easy           |
-        | Swarm        | -                                               | -          | BaseALO          | -        | 2         | easy           |
-        | Swarm        | Moth Flame Optimization                         | MFO        | OriginalMFO      | 2015     | 2         | easy           |
-        | Swarm        | -                                               | -          | BaseMFO          | -        | 2         | easy           |
-        | Swarm        | Elephant Herding Optimization                   | EHO        | OriginalEHO      | 2015     | 5         | easy           |
-        | Swarm        | Jaya Algorithm                                  | JA         | OriginalJA       | 2016     | 2         | easy           |
-        | Swarm        | -                                               | -          | BaseJA           | -        | 2         | easy           |
-        | Swarm        | -                                               | -          | LevyJA           | 2021     | 2         | easy           |
-        | Swarm        | Whale Optimization Algorithm                    | WOA        | OriginalWOA      | 2016     | 2         | medium         |
-        | Swarm        | -                                               | -          | HI_WOA           | 2019     | 3         | medium         |
-        | Swarm        | Dragonfly Optimization                          | DO         | OriginalDO       | 2016     | 2         | medium         |
-        | Swarm        | Bird Swarm Algorithm                            | BSA        | OriginalBSA      | 2016     | 9         | medium         |
-        | Swarm        | Spotted Hyena Optimizer                         | SHO        | OriginalSHO      | 2017     | 4         | medium         |
-        | Swarm        | Salp Swarm Optimization                         | SSO        | OriginalSSO      | 2017     | 2         | easy           |
-        | Swarm        | Swarm Robotics Search And Rescue                | SRSR       | OriginalSRSR     | 2017     | 2         | hard*          |
-        | Swarm        | Grasshopper Optimisation Algorithm              | GOA        | OriginalGOA      | 2017     | 4         | easy           |
-        | Swarm        | Coyote Optimization Algorithm                   | COA        | OriginalCOA      | 2018     | 3         | medium         |
-        | Swarm        | Moth Search Algorithm                           | MSA        | OriginalMSA      | 2018     | 5         | easy           |
-        | Swarm        | Sea Lion Optimization                           | SLO        | OriginalSLO      | 2019     | 2         | medium         |
-        | Swarm        | -                                               | -          | ModifiedSLO      | -        | 2         | medium         |
-        | Swarm        | -                                               | -          | ImprovedSLO      | -        | 4         | medium         |
-        | Swarm        | Nake Mole-Rat Algorithm                         | NMRA       | OriginalNMRA     | 2019     | 3         | easy           |
-        | Swarm        | -                                               | -          | ImprovedNMRA     | -        | 4         | medium         |
-        | Swarm        | Pathfinder Algorithm                            | PFA        | OriginalPFA      | 2019     | 2         | medium         |
-        | Swarm        | Sailfish Optimizer                              | SFO        | OriginalSFO      | 2019     | 5         | easy           |
-        | Swarm        | -                                               | -          | ImprovedSFO      | -        | 3         | medium         |
-        | Swarm        | Harris Hawks Optimization                       | HHO        | OriginalHHO      | 2019     | 2         | medium         |
-        | Swarm        | Manta Ray Foraging Optimization                 | MRFO       | OriginalMRFO     | 2020     | 3         | medium         |
-        | Swarm        | Bald Eagle Search                               | BES        | OriginalBES      | 2020     | 7         | easy           |
-        | Swarm        | Sparrow Search Algorithm                        | SSA        | OriginalSSA      | 2020     | 5         | medium         |
-        | Swarm        | -                                               | -          | BaseSSA          | -        | 5         | medium         |
-        | Swarm        | Hunger Games Search                             | HGS        | OriginalHGS      | 2021     | 4         | medium         |
-        | Swarm        | Aquila Optimizer                                | AO         | OriginalAO       | 2021     | 2         | easy           |
-        | Swarm        | Hybrid Grey Wolf - Whale Optimization Algorithm | GWO        | GWO_WOA          | 2022     | 2         | easy           |
-        | Swarm        | Marine Predators Algorithm                      | MPA        | OriginalMPA      | 2020     | 2         | medium         |
-        | Swarm        | Honey Badger Algorithm                          | HBA        | OriginalHBA      | 2022     | 2         | easy           |
-        | Swarm        | Sand Cat Swarm Optimization                     | SCSO       | OriginalSCSO     | 2022     | 2         | easy           |
-        | Swarm        | Tuna Swarm Optimization                         | TSO        | OriginalTSO      | 2021     | 2         | medium         |
-        | Swarm        | African Vultures Optimization Algorithm         | AVOA       | OriginalAVOA     | 2022     | 7         | medium         |
-        | Swarm        | Artificial Gorilla Troops Optimization          | AGTO       | OriginalAGTO     | 2021     | 5         | medium         |
-        | Swarm        | Artificial Rabbits Optimization                 | ARO        | OriginalARO      | 2022     | 2         | easy           |
-        | Swarm        | Dwarf Mongoose Optimization Algorithm           | DMOA       | OriginalDMOA     | 2022     | 4         | medium         |
-        | Swarm        | -                                               | -          | DevDMOA          | -        | 3         | medium         |
-        | -            | -                                               | -          | -                | -        | -         | -              |
-        | Physics      | Simulated Annealling                            | SA         | OriginalSA       | 1987     | 9         | medium         |
-        | Physics      | Wind Driven Optimization                        | WDO        | OriginalWDO      | 2013     | 7         | easy           |
-        | Physics      | Multi-Verse Optimizer                           | MVO        | OriginalMVO      | 2016     | 4         | easy           |
-        | Physics      | -                                               | -          | BaseMVO          | -        | 4         | easy           |
-        | Physics      | Tug of War Optimization                         | TWO        | OriginalTWO      | 2016     | 2         | easy           |
-        | Physics      | -                                               | -          | OppoTWO          | -        | 2         | medium         |
-        | Physics      | -                                               | -          | LevyTWO          | -        | 2         | medium         |
-        | Physics      | -                                               | -          | EnhancedTWO      | 2020     | 2         | medium         |
-        | Physics      | Electromagnetic Field Optimization              | EFO        | OriginalEFO      | 2016     | 6         | easy           |
-        | Physics      | -                                               | -          | BaseEFO          | -        | 6         | medium         |
-        | Physics      | Nuclear Reaction Optimization                   | NRO        | OriginalNRO      | 2019     | 2         | hard*          |
-        | Physics      | Henry Gas Solubility Optimization               | HGSO       | OriginalHGSO     | 2019     | 3         | medium         |
-        | Physics      | Atom Search Optimization                        | ASO        | OriginalASO      | 2019     | 4         | medium         |
-        | Physics      | Equilibrium Optimizer                           | EO         | OriginalEO       | 2019     | 2         | easy           |
-        | Physics      | -                                               | -          | ModifiedEO       | 2020     | 2         | medium         |
-        | Physics      | -                                               | -          | AdaptiveEO       | 2020     | 2         | medium         |
-        | Physics      | Archimedes Optimization Algorithm               | ArchOA     | OriginalArchOA   | 2021     | 8         | medium         |
-        | -            | -                                               | -          | -                | -        | -         | -              |
-        | Human        | Culture Algorithm                               | CA         | OriginalCA       | 1994     | 3         | easy           |
-        | Human        | Imperialist Competitive Algorithm               | ICA        | OriginalICA      | 2007     | 8         | hard*          |
-        | Human        | Teaching Learning-based Optimization            | TLO        | OriginalTLO      | 2011     | 2         | easy           |
-        | Human        | -                                               | -          | BaseTLO          | 2012     | 2         | easy           |
-        | Human        | -                                               | -          | ITLO             | 2013     | 3         | medium         |
-        | Human        | Brain Storm Optimization                        | BSO        | OriginalBSO      | 2011     | 8         | medium         |
-        | Human        | -                                               | -          | ImprovedBSO      | 2017     | 7         | medium         |
-        | Human        | Queuing Search Algorithm                        | QSA        | OriginalQSA      | 2019     | 2         | hard           |
-        | Human        | -                                               | -          | BaseQSA          | -        | 2         | hard           |
-        | Human        | -                                               | -          | OppoQSA          | -        | 2         | hard           |
-        | Human        | -                                               | -          | LevyQSA          | -        | 2         | hard           |
-        | Human        | -                                               | -          | ImprovedQSA      | 2021     | 2         | hard           |
-        | Human        | Search And Rescue Optimization                  | SARO       | OriginalSARO     | 2019     | 4         | medium         |
-        | Human        | -                                               | -          | BaseSARO         | -        | 4         | medium         |
-        | Human        | Life Choice-Based Optimization                  | LCO        | OriginalLCO      | 2019     | 3         | easy           |
-        | Human        | -                                               | -          | BaseLCO          | -        | 3         | easy           |
-        | Human        | -                                               | -          | ImprovedLCO      | -        | 2         | easy           |
-        | Human        | Social Ski-Driver Optimization                  | SSDO       | OriginalSSDO     | 2019     | 2         | easy           |
-        | Human        | Gaining Sharing Knowledge-based Algorithm       | GSKA       | OriginalGSKA     | 2019     | 6         | medium         |
-        | Human        | -                                               | -          | BaseGSKA         | -        | 4         | medium         |
-        | Human        | Coronavirus Herd Immunity Optimization          | CHIO       | OriginalCHIO     | 2020     | 4         | medium         |
-        | Human        | -                                               | -          | BaseCHIO         | -        | 4         | medium         |
-        | Human        | Forensic-Based Investigation Optimization       | FBIO       | OriginalFBIO     | 2020     | 2         | medium         |
-        | Human        | -                                               | -          | BaseFBIO         | -        | 2         | medium         |
-        | Human        | Battle Royale Optimization                      | BRO        | OriginalBRO      | 2020     | 3         | medium         |
-        | Human        | -                                               | -          | BaseBRO          | -        | 3         | medium         |
-        | Human        | Student Psychology Based Optimization           | SPBO       | OriginalSPBO     | 2020     | 2         | medium         |
-        | Human        | -                                               | -          | DevSPBO          |          | 2         | medium         |
-        | -            | -                                               | -          | -                | -        | -         | -              |
-        | Bio          | Invasive Weed Optimization                      | IWO        | OriginalIWO      | 2006     | 7         | easy           |
-        | Bio          | Biogeography-Based Optimization                 | BBO        | OriginalBBO      | 2008     | 4         | easy           |
-        | Bio          | -                                               | -          | BaseBBO          | -        | 4         | easy           |
-        | Bio          | Virus Colony Search                             | VCS        | OriginalVCS      | 2016     | 4         | hard*          |
-        | Bio          | -                                               | -          | BaseVCS          | -        | 4         | hard*          |
-        | Bio          | Satin Bowerbird Optimizer                       | SBO        | OriginalSBO      | 2017     | 5         | easy           |
-        | Bio          | -                                               | -          | BaseSBO          | -        | 5         | easy           |
-        | Bio          | Earthworm Optimisation Algorithm                | EOA        | OriginalEOA      | 2018     | 8         | medium         |
-        | Bio          | Wildebeest Herd Optimization                    | WHO        | OriginalWHO      | 2019     | 12        | hard           |
-        | Bio          | Slime Mould Algorithm                           | SMA        | OriginalSMA      | 2020     | 3         | easy           |
-        | Bio          | -                                               | -          | BaseSMA          | -        | 3         | easy           |
-        | Bio          | Barnacles Mating Optimizer                      | BMO        | OriginalBMO      | 2018     | 3         | easy           |
-        | Bio          | Tunicate Swarm Algorithm                        | TSA        | OriginalTSA      | 2020     | 2         | easy           |
-        | Bio          | Symbiotic Organisms Search                      | SOS        | OriginalSOS      | 2014     | 2         | medium         |
-        | Bio          | Seagull Optimization Algorithm                  | SOA        | OriginalSOA      | 2019     | 3         | easy           |
-        | Bio          | -                                               | -          | DevSOA           | -        | 3         | easy           |
-        | -            | -                                               | -          | -                | -        | -         | -              |
-        | System       | Germinal Center Optimization                    | GCO        | OriginalGCO      | 2018     | 4         | medium         |
-        | System       | -                                               | -          | BaseGCO          | -        | 4         | medium         |
-        | System       | Water Cycle Algorithm                           | WCA        | OriginalWCA      | 2012     | 5         | medium         |
-        | System       | Artificial Ecosystem-based Optimization         | AEO        | OriginalAEO      | 2019     | 2         | easy           |
-        | System       | -                                               | -          | EnhancedAEO      | 2020     | 2         | medium         |
-        | System       | -                                               | -          | ModifiedAEO      | 2020     | 2         | medium         |
-        | System       | -                                               | -          | ImprovedAEO      | 2021     | 2         | medium         |
-        | System       | -                                               | -          | AugmentedAEO     | 2022     | 2         | medium         |
-        | -            | -                                               | -          | -                | -        | -         | -              |
-        | Math         | Hill Climbing                                   | HC         | OriginalHC       | 1993     | 3         | easy           |
-        | Math         | -                                               | -          | SwarmHC          | -        | 3         | easy           |
-        | Math         | Cross-Entropy Method                            | CEM        | OriginalCEM      | 1997     | 4         | easy           |
-        | Math         | Sine Cosine Algorithm                           | SCA        | OriginalSCA      | 2016     | 2         | easy           |
-        | Math         | -                                               | -          | BaseSCA          | -        | 2         | easy           |
-        | Math         | Gradient-Based Optimizer                        | GBO        | OriginalGBO      | 2020     | 5         | medium         |
-        | Math         | Arithmetic Optimization Algorithm               | AOA        | OrginalAOA       | 2021     | 6         | easy           |
-        | Math         | Chaos Game Optimization                         | CGO        | OriginalCGO      | 2021     | 2         | easy           |
-        | Math         | Pareto-like Sequential Sampling                 | PSS        | OriginalPSS      | 2021     | 4         | medium         |
-        | Math         | weIghted meaN oF vectOrs                        | INFO       | OriginalINFO     | 2022     | 2         | medium         |
-        | Math         | RUNge Kutta optimizer                           | RUN        | OriginalRUN      | 2021     | 2         | hard           |
-        | Math         | Circle Search Algorithm                         | CircleSA   | OriginalCircleSA | 2022     | 3         | easy           |
-        | -            | -                                               | -          | -                | -        | -         | -              |
-        | Music        | Harmony Search                                  | HS         | OriginalHS       | 2001     | 4         | easy           |
-        | Music        | -                                               | -          | BaseHS           | -        | 4         | easy           |
-        
-        
-        
-        
-        
-        ### A
-        
-        * **ABC - Artificial Bee Colony**
-          * **OriginalABC**: Karaboga, D. (2005). An idea based on honey bee swarm for numerical optimization (Vol. 200, pp. 1-10). Technical report-tr06, Erciyes university, engineering faculty, computer engineering department.
-        
-        * **ACOR - Ant Colony Optimization**. 
-          * **OriginalACOR**: Socha, K., & Dorigo, M. (2008). Ant colony optimization for continuous domains. European journal of operational research, 185(3), 1155-1173.
-        
-        * **ALO - Ant Lion Optimizer** 
-          * **OriginalALO**: Mirjalili S (2015). âThe Ant Lion Optimizer.â Advances in Engineering Software, 83, 80-98. doi: [10.1016/j.advengsoft.2015.01.010](https://doi.org/10.1016/j.advengsoft.2015.01.010)
-          * **BaseALO**: The developed version
-        
-        * **AEO - Artificial Ecosystem-based Optimization** 
-          * **OriginalAEO**: Zhao, W., Wang, L., & Zhang, Z. (2019). Artificial ecosystem-based optimization: a novel nature-inspired meta-heuristic algorithm. Neural Computing and Applications, 1-43.
-          * **AugmentedAEO**: Van Thieu, N., Barma, S. D., Van Lam, T., Kisi, O., & Mahesha, A. (2022). Groundwater level modeling using Augmented Artificial Ecosystem Optimization. Journal of Hydrology, 129034.
-          * **ImprovedAEO**: Rizk-Allah, R. M., & El-Fergany, A. A. (2020). Artificial ecosystem optimizer for parameters identification of proton exchange membrane fuel cells model. International Journal of Hydrogen Energy.
-          * **EnhancedAEO**: Eid, A., Kamel, S., Korashy, A., & Khurshaid, T. (2020). An Enhanced Artificial Ecosystem-Based Optimization for Optimal Allocation of Multiple Distributed Generations. IEEE Access, 8, 178493-178513.
-          * **ModifiedAEO**: Menesy, A. S., Sultan, H. M., Korashy, A., Banakhr, F. A., Ashmawy, M. G., & Kamel, S. (2020). Effective parameter extraction of different polymer electrolyte membrane fuel cell stack models using a modified artificial ecosystem optimization algorithm. IEEE Access, 8, 31892-31909.
-          
-        * **ASO - Atom Search Optimization**   
-          * **OriginalASO**: Zhao, W., Wang, L., & Zhang, Z. (2019). Atom search optimization and its application to solve a hydrogeologic parameter estimation problem. Knowledge-Based Systems, 163, 283-304.
-        
-        * **ArchOA - Archimedes Optimization Algorithm**
-          * **OriginalArchOA**: Hashim, F. A., Hussain, K., Houssein, E. H., Mabrouk, M. S., & Al-Atabany, W. (2021). Archimedes optimization algorithm: a new metaheuristic algorithm for solving optimization problems. Applied Intelligence, 51(3), 1531-1551.
-        
-        * **AOA - Arithmetic Optimization Algorithm**
-          * **OriginalAOA**: Abualigah, L., Diabat, A., Mirjalili, S., Abd Elaziz, M., & Gandomi, A. H. (2021). The arithmetic optimization algorithm. Computer methods in applied mechanics and engineering, 376, 113609.
-        
-        * **AO - Aquila Optimizer**
-          * **OriginalAO**: Abualigah, L., Yousri, D., Abd Elaziz, M., Ewees, A. A., Al-qaness, M. A., & Gandomi, A. H. (2021). Aquila Optimizer: A novel meta-heuristic optimization Algorithm. Computers & Industrial Engineering, 157, 107250.
-        
-        * **AVOA - African Vultures Optimization Algorithm**
-          * **OriginalAVOA**: Abdollahzadeh, B., Gharehchopogh, F. S., & Mirjalili, S. (2021). African vultures optimization algorithm: A new nature-inspired metaheuristic algorithm for global optimization problems. Computers & Industrial Engineering, 158, 107408.
-        
-        * **AGTO - Artificial Gorilla Troops Optimization**
-          * **OriginalAGTO**: Abdollahzadeh, B., Soleimanian Gharehchopogh, F., & Mirjalili, S. (2021). Artificial gorilla troops optimizer: a new natureâinspired metaheuristic algorithm for global optimization problems. International Journal of Intelligent Systems, 36(10), 5887-5958.
-        
-        * **ARO - Artificial Rabbits Optimization**:
-          * **OriginalARO**: Wang, L., Cao, Q., Zhang, Z., Mirjalili, S., & Zhao, W. (2022). Artificial rabbits optimization: A new bio-inspired meta-heuristic algorithm for solving engineering optimization problems. Engineering Applications of Artificial Intelligence, 114, 105082.
-        
-        
-        
-        ### B
-        
-        
-        * **BFO - Bacterial Foraging Optimization** 
-          * **OriginalBFO**: Passino, K. M. (2002). Biomimicry of bacterial foraging for distributed optimization and control. IEEE control systems magazine, 22(3), 52-67.
-          * **ABFO**: Nguyen, T., Nguyen, B. M., & Nguyen, G. (2019, April). Building resource auto-scaler with functional-link neural network and adaptive bacterial foraging optimization. In International Conference on Theory and Applications of Models of Computation (pp. 501-517). Springer, Cham.
-        
-        * **BeesA - Bees Algorithm** 
-          * **OriginalBeesA**: Pham, D. T., Ghanbarzadeh, A., Koc, E., Otri, S., Rahim, S., & Zaidi, M. (2005). The bees algorithm. Technical Note, Manufacturing Engineering Centre, Cardiff University, UK.
-          * **ProbBeesA**: The probabilitic version of: Pham, D. T., Ghanbarzadeh, A., KoÃ§, E., Otri, S., Rahim, S., & Zaidi, M. (2006). The bees algorithmâa novel tool for complex optimisation problems. In Intelligent production machines and systems (pp. 454-459). Elsevier Science Ltd.
-          
-        * **BBO - Biogeography-Based Optimization** 
-          * **OriginalBBO**: Simon, D. (2008). Biogeography-based optimization. IEEE transactions on evolutionary computation, 12(6), 702-713.
-          * **BaseBBO**: The developed version
-          
-        * **BA - Bat Algorithm** 
-          * **OriginalBA**: Yang, X. S. (2010). A new metaheuristic bat-inspired algorithm. In Nature inspired cooperative strategies for optimization (NICSO 2010) (pp. 65-74). Springer, Berlin, Heidelberg.
-          * **AdaptiveBA**: Wang, X., Wang, W. and Wang, Y., 2013, July. An adaptive bat algorithm. In International Conference on Intelligent Computing(pp. 216-223). Springer, Berlin, Heidelberg.
-          * **ModifiedBA**: Dong, H., Li, T., Ding, R. and Sun, J., 2018. A novel hybrid genetic algorithm with granular information for feature selection and optimization. Applied Soft Computing, 65, pp.33-46.
-        
-        * **BSO - Brain Storm Optimization** 
-          * **OriginalBSO**: . Shi, Y. (2011, June). Brain storm optimization algorithm. In International conference in swarm intelligence (pp. 303-309). Springer, Berlin, Heidelberg.
-          * **ImprovedBSO**: El-Abd, M., 2017. Global-best brain storm optimization algorithm. Swarm and evolutionary computation, 37, pp.27-44.
-        
-        * **BSA - Bird Swarm Algorithm** 
-          * **OriginalBSA**: Meng, X. B., Gao, X. Z., Lu, L., Liu, Y., & Zhang, H. (2016). A new bio-inspired optimisation algorithm:Bird Swarm Algorithm. Journal of Experimental & Theoretical Artificial Intelligence, 28(4), 673-687.
-        
-        * **BMO - Barnacles Mating Optimizer**:
-          * **OriginalBMO**: Sulaiman, M. H., Mustaffa, Z., Saari, M. M., Daniyal, H., Daud, M. R., Razali, S., & Mohamed, A. I. (2018, June). Barnacles mating optimizer: a bio-inspired algorithm for solving optimization problems. In 2018 19th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD) (pp. 265-270). IEEE.
-        
-        * **BES - Bald Eagle Search** 
-          * **OriginalBES**: Alsattar, H. A., Zaidan, A. A., & Zaidan, B. B. (2019). Novel meta-heuristic bald eagle search optimisation algorithm. Artificial Intelligence Review, 1-28.
-          
-        * **BRO - Battle Royale Optimization**
-          * **OriginalBRO**: Rahkar Farshi, T. (2020). Battle royale optimization algorithm. Neural Computing and Applications, 1-19.
-          * **BaseBRO**: The developed version
-        
-        ### C
-        
-        * **CA - Culture Algorithm** 
-          * **OriginalCA**: Reynolds, R.G., 1994, February. An introduction to cultural algorithms. In Proceedings of the third annual conference on evolutionary programming (Vol. 24, pp. 131-139). River Edge, NJ: World Scientific.
-        
-        * **CEM - Cross Entropy Method**
-          * **OriginalCEM**: Rubinstein, R. (1999). The cross-entropy method for combinatorial and continuous optimization. Methodology and computing in applied probability, 1(2), 127-190.
-          
-        * **CSO - Cat Swarm Optimization** 
-          * **OriginalCSO**: Chu, S. C., Tsai, P. W., & Pan, J. S. (2006, August). Cat swarm optimization. In Pacific Rim international conference on artificial intelligence (pp. 854-858). Springer, Berlin, Heidelberg.
-        
-        * **CSA - Cuckoo Search Algorithm** 
-          * **OriginalCSA**: Yang, X. S., & Deb, S. (2009, December). Cuckoo search via LÃ©vy flights. In 2009 World congress on nature & biologically inspired computing (NaBIC) (pp. 210-214). Ieee.
-        
-        * **CRO - Coral Reefs Optimization** 
-          * **OriginalCRO**: Salcedo-Sanz, S., Del Ser, J., Landa-Torres, I., Gil-LÃ³pez, S., & Portilla-Figueras, J. A. (2014). The coral reefs optimization algorithm: a novel metaheuristic for efficiently solving optimization problems. The Scientific World Journal, 2014.
-          * **OCRO**: Nguyen, T., Nguyen, T., Nguyen, B. M., & Nguyen, G. (2019). Efficient time-series forecasting using neural network and opposition-based coral reefs optimization. International Journal of Computational Intelligence Systems, 12(2), 1144-1161.
-        
-        * **COA - Coyote Optimization Algorithm**
-          * **OriginalCOA**: Pierezan, J., & Coelho, L. D. S. (2018, July). Coyote optimization algorithm: a new metaheuristic for global optimization problems. In 2018 IEEE congress on evolutionary computation (CEC) (pp. 1-8). IEEE.
-        
-        * **CHIO - Coronavirus Herd Immunity Optimization**
-          * **OriginalCHIO**: Al-Betar, M. A., Alyasseri, Z. A. A., Awadallah, M. A., & Abu Doush, I. (2021). Coronavirus herd immunity optimizer (CHIO). Neural Computing and Applications, 33(10), 5011-5042.
-          * **BaseCHIO**: The developed version
-        
-        * **CGO - Chaos Game Optimization** 
-          * **OriginalCGO**: Talatahari, S., & Azizi, M. (2021). Chaos Game Optimization: a novel metaheuristic algorithm. Artificial Intelligence Review, 54(2), 917-1004.
-        
-        * **CSA - Circle Search Algorithm**
-          * **OriginalCSA**: Qais, M. H., Hasanien, H. M., Turky, R. A., Alghuwainem, S., Tostado-VÃ©liz, M., & Jurado, F. (2022). Circle Search Algorithm: A Geometry-Based Metaheuristic Optimization Algorithm. Mathematics, 10(10), 1626.
-        
-        ### D
-        
-        * **DE - Differential Evolution** 
-          * **BaseDE**: Storn, R., & Price, K. (1997). Differential evolutionâa simple and efficient heuristic for global optimization over continuous spaces. Journal of global optimization, 11(4), 341-359.
-          * **JADE**: Zhang, J., & Sanderson, A. C. (2009). JADE: adaptive differential evolution with optional external archive. IEEE Transactions on evolutionary computation, 13(5), 945-958.
-          * **SADE**: Qin, A. K., & Suganthan, P. N. (2005, September). Self-adaptive differential evolution algorithm for numerical optimization. In 2005 IEEE congress on evolutionary computation (Vol. 2, pp. 1785-1791). IEEE.
-          * **SHADE**: Tanabe, R., & Fukunaga, A. (2013, June). Success-history based parameter adaptation for differential evolution. In 2013 IEEE congress on evolutionary computation (pp. 71-78). IEEE.
-          * **L_SHADE**: Tanabe, R., & Fukunaga, A. S. (2014, July). Improving the search performance of SHADE using linear population size reduction. In 2014 IEEE congress on evolutionary computation (CEC) (pp. 1658-1665). IEEE.
-          * **SAP_DE**: Teo, J. (2006). Exploring dynamic self-adaptive populations in differential evolution. Soft Computing, 10(8), 673-686.
-          
-        * **DSA - Differential Search Algorithm (not done)** 
-          * **BaseDSA**: Civicioglu, P. (2012). Transforming geocentric cartesian coordinates to geodetic coordinates by using differential search algorithm. Computers & Geosciences, 46, 229-247.
-          
-        * **DO - Dragonfly Optimization** 
-          * **OriginalDO**: Mirjalili, S. (2016). Dragonfly algorithm: a new meta-heuristic optimization technique for solving single-objective, discrete, and multi-objective problems. Neural Computing and Applications, 27(4), 1053-1073.
-        
-        * **DMOA - Dwarf Mongoose Optimization Algorithm**
-          * **OriginalDMOA**: Agushaka, J. O., Ezugwu, A. E., & Abualigah, L. (2022). Dwarf mongoose optimization algorithm. Computer methods in applied mechanics and engineering, 391, 114570.
-          * **DevDMOA**: The developed version
-        
-        ### E
-        
-        * **ES - Evolution Strategies** . 
-          * **OriginalES**: Schwefel, H. P. (1984). Evolution strategies: A family of non-linear optimization techniques based on imitating some principles of organic evolution. Annals of Operations Research, 1(2), 165-167.
-          * **LevyES**: Zhang, S., & Salari, E. (2005). Competitive learning vector quantization with evolution strategies for image compression. Optical Engineering, 44(2), 027006.
-        
-        * **EP - Evolutionary programming** . 
-          * **OriginalEP**: Fogel, L. J. (1994). Evolutionary programming in perspective: The top-down view. Computational intelligence: Imitating life.
-          * **LevyEP**: Lee, C.Y. and Yao, X., 2001, May. Evolutionary algorithms with adaptive lÃ©vy mutations. In Proceedings of the 2001 congress on evolutionary computation (IEEE Cat. No. 01TH8546) (Vol. 1, pp. 568-575). IEEE.
-        
-        * **EHO - Elephant Herding Optimization** . 
-          * **OriginalEHO**: Wang, G. G., Deb, S., & Coelho, L. D. S. (2015, December). Elephant herding optimization. In 2015 3rd International Symposium on Computational and Business Intelligence (ISCBI) (pp. 1-5). IEEE.
-        
-        * **EFO - Electromagnetic Field Optimization** . 
-          * **OriginalEFO**:Abedinpourshotorban, H., Shamsuddin, S. M., Beheshti, Z., & Jawawi, D. N. (2016). Electromagnetic field optimization: A physics-inspired metaheuristic optimization algorithm. Swarm and Evolutionary Computation, 26, 8-22.
-          * **BaseEFO**: The developed version
-        
-        * **EOA - Earthworm Optimisation Algorithm** . 
-          * **OriginalEOA**: Wang, G. G., Deb, S., & dos Santos Coelho, L. (2018). Earthworm optimisation algorithm: a bio-inspired metaheuristic algorithm for global optimisation problems. IJBIC, 12(1), 1-22.
-        
-        * **EO - Equilibrium Optimizer** . 
-          * **OriginalEO**: Faramarzi, A., Heidarinejad, M., Stephens, B., & Mirjalili, S. (2019). Equilibrium optimizer: A novel optimization algorithm. Knowledge-Based Systems.
-          * **ModifiedEO**: Gupta, S., Deep, K., & Mirjalili, S. (2020). An efficient equilibrium optimizer with mutation strategy for numerical optimization. Applied Soft Computing, 96, 106542.
-          * **AdaptiveEO**: Wunnava, A., Naik, M. K., Panda, R., Jena, B., & Abraham, A. (2020). A novel interdependence based multilevel thresholding technique using adaptive equilibrium optimizer. Engineering Applications of Artificial Intelligence, 94, 103836.
-        
-        ### F
-        
-        * **FFA - Firefly Algorithm** 
-          * **OriginalFFA**: Åukasik, S., & Å»ak, S. (2009, October). Firefly algorithm for continuous constrained optimization tasks. In International conference on computational collective intelligence (pp. 97-106). Springer, Berlin, Heidelberg.
-          
-        * **FA - Fireworks algorithm** 
-          * **OriginalFA**: Tan, Y., & Zhu, Y. (2010, June). Fireworks algorithm for optimization. In International conference in swarm intelligence (pp. 355-364). Springer, Berlin, Heidelberg.
-        
-        * **FPA - Flower Pollination Algorithm** 
-          * **OriginalFPA**: Yang, X. S. (2012, September). Flower pollination algorithm for global optimization. In International conference on unconventional computing and natural computation (pp. 240-249). Springer, Berlin, Heidelberg.
-        
-        * **FOA - Fruit-fly Optimization Algorithm**
-          * **OriginalFOA**: Pan, W. T. (2012). A new fruit fly optimization algorithm: taking the financial distress model as an example. Knowledge-Based Systems, 26, 69-74.
-          * **BaseFOA**: The developed version
-          * **WhaleFOA**: Fan, Y., Wang, P., Heidari, A. A., Wang, M., Zhao, X., Chen, H., & Li, C. (2020). Boosted hunting-based fruit fly optimization and advances in real-world problems. Expert Systems with Applications, 159, 113502.
-        
-        * **FBIO - Forensic-Based Investigation Optimization** 
-          * **OriginalFBIO**: Chou, J.S. and Nguyen, N.M., 2020. FBI inspired meta-optimization. Applied Soft Computing, p.106339.
-          * **BaseFBIO**: Fathy, A., Rezk, H. and Alanazi, T.M., 2021. Recent approach of forensic-based investigation algorithm for optimizing fractional order PID-based MPPT with proton exchange membrane fuel cell.IEEE Access,9, pp.18974-18992.
-        
-        * **FHO - Fire Hawk Optimization**
-          * **OriginalFHO**: Azizi, M., Talatahari, S., & Gandomi, A. H. (2022). Fire Hawk Optimizer: a novel metaheuristic algorithm. Artificial Intelligence Review, 1-77.
-        
-        ### G
-        
-        * **GA - Genetic Algorithm** 
-          * **BaseGA**: Holland, J. H. (1992). Genetic algorithms. Scientific american, 267(1), 66-73.
-          * **SingleGA**: De Falco, I., Della Cioppa, A. and Tarantino, E., 2002. Mutation-based genetic algorithm: performance evaluation.Â Applied Soft Computing,Â 1(4), pp.285-299.
-          * **MultiGA**: De Jong, K.A. and Spears, W.M., 1992. A formal analysis of the role of multi-point crossover in genetic algorithms.Â Annals of mathematics and Artificial intelligence,Â 5(1), pp.1-26.
-          * **EliteSingleGA**: Elite version of Single-point mutation GA
-          * **EliteMultiGA**: Elite version of Multiple-point mutation GA
-        
-        * **GWO - Grey Wolf Optimizer** 
-          * **OriginalGWO**: Mirjalili, S., Mirjalili, S. M., & Lewis, A. (2014). Grey wolf optimizer. Advances in engineering software, 69, 46-61.
-          * **RW_GWO**: Gupta, S., & Deep, K. (2019). A novel random walk grey wolf optimizer. Swarm and evolutionary computation, 44, 101-112.
-          * **GWO_WOA**: Obadina, O. O., Thaha, M. A., Althoefer, K., & Shaheed, M. H. (2022). Dynamic characterization of a masterâslave robotic manipulator using a hybrid grey wolfâwhale optimization algorithm. Journal of Vibration and Control, 28(15-16), 1992-2003.
-        
-        * **GOA - Grasshopper Optimisation Algorithm** 
-          * **OriginalGOA**: Saremi, S., Mirjalili, S., & Lewis, A. (2017). Grasshopper optimisation algorithm: theory and application. Advances in Engineering Software, 105, 30-47.
-        
-        * **GCO - Germinal Center Optimization** 
-          * **OriginalGCO**: VillaseÃ±or, C., Arana-Daniel, N., Alanis, A. Y., LÃ³pez-Franco, C., & Hernandez-Vargas, E. A. (2018). Germinal center optimization algorithm. International Journal of Computational Intelligence Systems, 12(1), 13-27.
-          * **BaseGCO**: The developed version
-        
-        * **GSKA - Gaining Sharing Knowledge-based Algorithm** 
-          * **OriginalGSKA**: Mohamed, A. W., Hadi, A. A., & Mohamed, A. K. (2019). Gaining-sharing knowledge based algorithm for solving optimization problems: a novel nature-inspired algorithm. International Journal of Machine Learning and Cybernetics, 1-29.
-          * **BaseGSKA**: Mohamed, A.W., Hadi, A.A., Mohamed, A.K. and Awad, N.H., 2020, July. Evaluating the performance of adaptive GainingSharing knowledge based algorithm on CEC 2020 benchmark problems. InÂ 2020 IEEE Congress on Evolutionary Computation (CEC)Â (pp. 1-8). IEEE.
-        
-        * **GBO - Gradient-Based Optimizer**
-          * **OriginalGBO**: Ahmadianfar, I., Bozorg-Haddad, O., & Chu, X. (2020). Gradient-based optimizer: A new metaheuristic optimization algorithm. Information Sciences, 540, 131-159.
-        
-        ### H
-        
-        * **HC - Hill Climbing** . 
-          * **OriginalHC**: Talbi, E. G., & Muntean, T. (1993, January). Hill-climbing, simulated annealing and genetic algorithms: a comparative study and application to the mapping problem. In [1993] Proceedings of the Twenty-sixth Hawaii International Conference on System Sciences (Vol. 2, pp. 565-573). IEEE.
-          * **SwarmHC**: The developed version based on swarm-based idea (Original is single-solution based method)
-        
-        * **HS - Harmony Search** . 
-          * **OriginalHS**: Geem, Z. W., Kim, J. H., & Loganathan, G. V. (2001). A new heuristic optimization algorithm:harmony search. simulation, 76(2), 60-68.
-          * **BaseHS**: The developed version
-        
-        * **HHO - Harris Hawks Optimization** . 
-          * **OriginalHHO**: Heidari, A. A., Mirjalili, S., Faris, H., Aljarah, I., Mafarja, M., & Chen, H. (2019). Harris hawks optimization: Algorithm and applications. Future Generation Computer Systems, 97, 849-872.
-        
-        * **HGSO - Henry Gas Solubility Optimization** . 
-          * **OriginalHGSO**: Hashim, F. A., Houssein, E. H., Mabrouk, M. S., Al-Atabany, W., & Mirjalili, S. (2019). Henry gas solubility optimization: A novel physics-based algorithm. Future Generation Computer Systems, 101, 646-667.
-        
-        * **HGS - Hunger Games Search** . 
-          * **OriginalHGS**: Yang, Y., Chen, H., Heidari, A. A., & Gandomi, A. H. (2021). Hunger games search:Visions, conception, implementation, deep analysis, perspectives, and towards performance shifts. Expert Systems with Applications, 177, 114864.
-          
-        * **HHOA - Horse Herd Optimization Algorithm (not done)** . 
-          * **BaseHHOA**: MiarNaeimi, F., Azizyan, G., & Rashki, M. (2021). Horse herd optimization algorithm: A nature-inspired algorithm for high-dimensional optimization problems. Knowledge-Based Systems, 213, 106711.
-          
-        * **HBA - Honey Badger Algorithm**:
-          * **OriginalHBA**: Hashim, F. A., Houssein, E. H., Hussain, K., Mabrouk, M. S., & Al-Atabany, W. (2022). Honey Badger Algorithm: New metaheuristic algorithm for solving optimization problems. Mathematics and Computers in Simulation, 192, 84-110.
-        
-        
-        ### I
-        
-        * **IWO - Invasive Weed Optimization** . 
-          * **OriginalIWO**: Mehrabian, A. R., & Lucas, C. (2006). A novel numerical optimization algorithm inspired from weed colonization. Ecological informatics, 1(4), 355-366.
-        
-        * **ICA - Imperialist Competitive Algorithm** 
-          * **OriginalICA**: Atashpaz-Gargari, E., & Lucas, C. (2007, September). Imperialist competitive algorithm: an algorithm for optimization inspired by imperialistic competition. In 2007 IEEE congress on evolutionary computation (pp. 4661-4667). Ieee.
-        
-        * **INFO - weIghted meaN oF vectOrs**:
-          * **OriginalINFO**: Ahmadianfar, I., Heidari, A. A., Gandomi, A. H., Chu, X., & Chen, H. (2021). RUN beyond the metaphor: An efficient     optimization algorithm based on Runge Kutta method. Expert Systems with Applications, 181, 115079.
-        
-        ### J
-        
-        * **JA - Jaya Algorithm** 
-          * **OriginalJA**: Rao, R. (2016). Jaya: A simple and new optimization algorithm for solving constrained and unconstrained optimization problems. International Journal of Industrial Engineering Computations, 7(1), 19-34.
-          * **BaseJA**: The developed version
-          * **LevyJA**: Iacca, G., dos Santos Junior, V. C., & de Melo, V. V. (2021). An improved Jaya optimization algorithm with Levy flight. Expert Systems with Applications, 165, 113902.
-        
-        ### K
-        
-        ### L
-        
-        * **LCO - Life Choice-based Optimization** 
-          * **OriginalLCO**: Khatri, A., Gaba, A., Rana, K. P. S., & Kumar, V. (2019). A novel life choice-based optimizer. Soft Computing, 1-21.
-          * **BaseLCO**: The developed version
-          * **ImprovedLCO**: The improved version using Gaussian distribution and Mutation Mechanism
-        
-        
-        ### M
-        
-        * **MA - Memetic Algorithm**
-          * **OriginalMA**: Moscato, P. (1989). On evolution, search, optimization, genetic algorithms and martial arts: Towards memetic algorithms. Caltech concurrent computation program, C3P Report, 826, 1989.
-        
-        * **MFO - Moth Flame Optimization** 
-          * **OriginalMFO**: Mirjalili, S. (2015). Moth-flame optimization algorithm: A novel nature-inspired heuristic paradigm. Knowledge-based systems, 89, 228-249.
-          * **BaseMFO**: The developed version
-        
-        * **MVO - Multi-Verse Optimizer** 
-          * **OriginalMVO**: Mirjalili, S., Mirjalili, S. M., & Hatamlou, A. (2016). Multi-verse optimizer: a nature-inspired algorithm for global optimization. Neural Computing and Applications, 27(2), 495-513.
-          * **BaseMVO**: The developed version
-        
-        * **MSA - Moth Search Algorithm** 
-          * **OriginalMSA**: Wang, G. G. (2018). Moth search algorithm: a bio-inspired metaheuristic algorithm for global optimization problems. Memetic Computing, 10(2), 151-164.
-          
-        * **MRFO - Manta Ray Foraging Optimization** 
-          * **OriginalMRFO**: Zhao, W., Zhang, Z., & Wang, L. (2020). Manta ray foraging optimization: An effective bio-inspired optimizer for engineering applications. Engineering Applications of Artificial Intelligence, 87, 103300.
-        
-        * **MPA - Marine Predators Algorithm**:
-          * **OriginalMPA**: Faramarzi, A., Heidarinejad, M., Mirjalili, S., & Gandomi, A. H. (2020). Marine Predators Algorithm: A nature-inspired metaheuristic. Expert systems with applications, 152, 113377.
-        
-        
-        ### N
-        
-        
-        * **NRO - Nuclear Reaction Optimization** 
-          * **OriginalNRO**: Wei, Z., Huang, C., Wang, X., Han, T., & Li, Y. (2019). Nuclear Reaction Optimization: A novel and powerful physics-based algorithm for global optimization. IEEE Access. 
-        
-        * **NMRA - Nake Mole-Rat Algorithm**
-          * **OriginalNMRA**: Salgotra, R., & Singh, U. (2019). The naked mole-rat algorithm. Neural Computing and Applications, 31(12), 8837-8857.
-          * **ImprovedNMRA**: Singh, P., Mittal, N., Singh, U. and Salgotra, R., 2021. Naked mole-rat algorithm with improved exploration and exploitation capabilities to determine 2D and 3D coordinates of sensor nodes in WSNs.Â Arabian Journal for Science and Engineering,Â 46(2), pp.1155-1178.
-        
-        
-        ### O
-        
-        ### P
-        
-        * **PSO - Particle Swarm Optimization** 
-          * **OriginalPSO**: Eberhart, R., & Kennedy, J. (1995, October). A new optimizer using particle swarm theory. In MHS'95. Proceedings of the Sixth International Symposium on Micro Machine and Human Science (pp. 39-43). Ieee.
-          * **PPSO**: Ghasemi, M., Akbari, E., Rahimnejad, A., Razavi, S. E., Ghavidel, S., & Li, L. (2019). Phasor particle swarm optimization: a simple and efficient variant of PSO. Soft Computing, 23(19), 9701-9718.
-          * **HPSO_TVAC**: Ghasemi, M., Aghaei, J., & Hadipour, M. (2017). New self-organising hierarchical PSO with jumping time-varying acceleration coefficients. Electronics Letters, 53(20), 1360-1362.
-          * **C_PSO**: Liu, B., Wang, L., Jin, Y. H., Tang, F., & Huang, D. X. (2005). Improved particle swarm optimization combined with chaos. Chaos, Solitons & Fractals, 25(5), 1261-1271.
-          * **CL_PSO**: Liang, J. J., Qin, A. K., Suganthan, P. N., & Baskar, S. (2006). Comprehensive learning particle swarm optimizer for global optimization of multimodal functions. IEEE transactions on evolutionary computation, 10(3), 281-295.
-        
-        * **PFA - Pathfinder Algorithm** 
-          * **OriginalPFA**: Yapici, H., & Cetinkaya, N. (2019). A new meta-heuristic optimizer: Pathfinder algorithm. Applied Soft Computing, 78, 545-568.
-        
-        * **PSS - Pareto-like Sequential Sampling**
-          * **OriginalPSS**: Shaqfa, M., & Beyer, K. (2021). Pareto-like sequential sampling heuristic for global optimisation. Soft Computing, 25(14), 9077-9096.
-        
-        
-        ### Q
-        
-        * **QSA - Queuing Search Algorithm** 
-          * **OriginalQSA**: Zhang, J., Xiao, M., Gao, L., & Pan, Q. (2018). Queuing search algorithm: A novel metaheuristic algorithm for solving engineering optimization problems. Applied Mathematical Modelling, 63, 464-490.
-          * **BaseQSA**: The developed version
-          * **OppoQSA**: Zheng, X. and Nguyen, H., 2022. A novel artificial intelligent model for predicting water treatment efficiency of various biochar systems based on artificial neural network and queuing search algorithm. Chemosphere, 287, p.132251.
-          * **LevyQSA**: Abderazek, H., Hamza, F., Yildiz, A.R., Gao, L. and Sait, S.M., 2021. A comparative analysis of the queuing search algorithm, the sine-cosine algorithm, the ant lion algorithm to determine the optimal weight design problem of a spur gear drive system. Materials Testing, 63(5), pp.442-447.
-          * **ImprovedQSA**: Nguyen, B.M., Hoang, B., Nguyen, T. and Nguyen, G., 2021. nQSV-Net: a novel queuing search variant for global space search and workload modeling.Â Journal of Ambient Intelligence and Humanized Computing,Â 12(1), pp.27-46.
-        
-        ### R
-        
-        * **RUN - RUNge Kutta optimizer**:
-          * **OriginalRUN**: Ahmadianfar, I., Heidari, A. A., Gandomi, A. H., Chu, X., & Chen, H. (2021). RUN beyond the metaphor: An efficient optimization algorithm based on Runge Kutta method. Expert Systems with Applications, 181, 115079.
-        
-        ### S
-        
-        * **SA - Simulated Annealling** 
-          * **OriginalSA**: . Van Laarhoven, P. J., & Aarts, E. H. (1987). Simulated annealing. In Simulated annealing: Theory and applications (pp. 7-15). Springer, Dordrecht.
-        
-        * **SSpiderO - Social Spider Optimization** 
-          * **OriginalSSpiderO**: Cuevas, E., Cienfuegos, M., ZaldÃ­Var, D., & PÃ©rez-Cisneros, M. (2013). A swarm optimization algorithm inspired in the behavior of the social-spider. Expert Systems with Applications, 40(16), 6374-6384.
-        
-        * **SOS - Symbiotic Organisms Search**:
-          * **OriginalSOS**: Cheng, M. Y., & Prayogo, D. (2014). Symbiotic organisms search: a new metaheuristic optimization algorithm. Computers & Structures, 139, 98-112.
-        
-        * **SSpiderA - Social Spider Algorithm** 
-          * **OriginalSSpiderA**: James, J. Q., & Li, V. O. (2015). A social spider algorithm for global optimization. Applied Soft Computing, 30, 614-627.
-        
-        * **SCA - Sine Cosine Algorithm** 
-          * **OriginalSCA**: Mirjalili, S. (2016). SCA: a sine cosine algorithm for solving optimization problems. Knowledge-Based Systems, 96, 120-133.
-          * **BaseSCA**: Attia, A.F., El Sehiemy, R.A. and Hasanien, H.M., 2018. Optimal power flow solution in power systems using a novel Sine-Cosine algorithm.Â International Journal of Electrical Power & Energy Systems,Â 99, pp.331-343.
-        
-        * **SRSR - Swarm Robotics Search And Rescue** 
-          * **OriginalSRSR**: Bakhshipour, M., Ghadi, M. J., & Namdari, F. (2017). Swarm robotics search & rescue: A novel artificial intelligence-inspired optimization approach. Applied Soft Computing, 57, 708-726.
-        
-        * **SBO - Satin Bowerbird Optimizer** 
-          * **OriginalSBO**: Moosavi, S. H. S., & Bardsiri, V. K. (2017). Satin bowerbird optimizer: a new optimization algorithm to optimize ANFIS for software development effort estimation. Engineering Applications of Artificial Intelligence, 60, 1-15.
-          * **BaseSBO**: The developed version
-        
-        * **SHO - Spotted Hyena Optimizer**
-          * **OriginalSHO**: Dhiman, G., & Kumar, V. (2017). Spotted hyena optimizer: a novel bio-inspired based metaheuristic technique for engineering applications. Advances in Engineering Software, 114, 48-70.
-        
-        * **SSO - Salp Swarm Optimization**
-          * **OriginalSSO**: Mirjalili, S., Gandomi, A. H., Mirjalili, S. Z., Saremi, S., Faris, H., & Mirjalili, S. M. (2017). Salp Swarm Algorithm: A bio-inspired optimizer for engineering design problems. Advances in Engineering Software, 114, 163-191.
-        
-        * **SFO - Sailfish Optimizer** 
-          * **OriginalSFO**: Shadravan, S., Naji, H. R., & Bardsiri, V. K. (2019). The Sailfish Optimizer: A novel nature-inspired metaheuristic algorithm for solving constrained engineering optimization problems. Engineering Applications of Artificial Intelligence, 80, 20-34.
-          * **ImprovedSFO**: Li, L.L., Shen, Q., Tseng, M.L. and Luo, S., 2021. Power system hybrid dynamic economic emission dispatch with wind energy based on improved sailfish algorithm.Â Journal of Cleaner Production,Â 316, p.128318.
-        
-        * **SARO - Search And Rescue Optimization** 
-          * **OriginalSARO**: Shabani, A., Asgarian, B., Gharebaghi, S. A., Salido, M. A., & Giret, A. (2019). A New Optimization Algorithm Based on Search and Rescue Operations. Mathematical Problems in Engineering, 2019.
-          * **BaseSARO**: The developed version using Levy-flight
-        
-        * **SSDO - Social Ski-Driver Optimization** 
-          * **OriginalSSDO**: Tharwat, A., & Gabel, T. (2019). Parameters optimization of support vector machines for imbalanced data using social ski driver algorithm. Neural Computing and Applications, 1-14.
-        
-        * **SLO - Sea Lion Optimization**
-          * **OriginalSLO**: Masadeh, R., Mahafzah, B. A., & Sharieh, A. (2019). Sea Lion Optimization Algorithm. Sea, 10(5).
-          * **ImprovedSLO**: The developed version
-          * **ModifiedSLO**: Masadeh, R., Alsharman, N., Sharieh, A., Mahafzah, B.A. and Abdulrahman, A., 2021. Task scheduling on cloud computing based on sea lion optimization algorithm.Â International Journal of Web Information Systems.
-        
-        * **Seagull Optimization Algorithm**
-          * **OriginalSOA**: Dhiman, G., & Kumar, V. (2019). Seagull optimization algorithm: Theory and its applications for large-scale industrial engineering problems. Knowledge-based systems, 165, 169-196.
-          * **DevSOA**: The developed version
-        
-        * **SMA - Slime Mould Algorithm**
-          * **OriginalSMA**: Li, S., Chen, H., Wang, M., Heidari, A. A., & Mirjalili, S. (2020). Slime mould algorithm: A new method for stochastic optimization. Future Generation Computer Systems.
-          * **BaseSMA**: The developed version
-        
-        * **SSA - Sparrow Search Algorithm** 
-          * **OriginalSSA**: Jiankai Xue & Bo Shen (2020) A novel swarm intelligence optimization approach: sparrow search algorithm, Systems Science & Control Engineering, 8:1, 22-34, DOI: 10.1080/21642583.2019.1708830
-          * **BaseSSA**: The developed version
-        
-        * **SPBO - Student Psychology Based Optimization**
-          * **OriginalSPBO**: Das, B., Mukherjee, V., & Das, D. (2020). Student psychology based optimization algorithm: A new population based optimization algorithm for solving optimization problems. Advances in Engineering software, 146, 102804.
-          * **DevSPBO**: The developed version
-        
-        * **SCSO - Sand Cat Swarm Optimization**
-          * **OriginalSCSO**: Seyyedabbasi, A., & Kiani, F. (2022). Sand Cat swarm optimization: a nature-inspired algorithm to solve global optimization problems. Engineering with Computers, 1-25.
-        
-        ### T
-        
-        * **TLO - Teaching Learning Optimization** 
-          * **OriginalTLO**: Rao, R. V., Savsani, V. J., & Vakharia, D. P. (2011). Teachingâlearning-based optimization: a novel method for constrained mechanical design optimization problems. Computer-Aided Design, 43(3), 303-315.
-          * **BaseTLO**: Rao, R., & Patel, V. (2012). An elitist teaching-learning-based optimization algorithm for solving complex constrained optimization problems. International Journal of Industrial Engineering Computations, 3(4), 535-560.
-          * **ImprovedTLO**: Rao, R. V., & Patel, V. (2013). An improved teaching-learning-based optimization algorithm for solving unconstrained optimization problems. Scientia Iranica, 20(3), 710-720.
-        
-        * **TWO - Tug of War Optimization** 
-          * **OriginalTWO**: Kaveh, A., & Zolghadr, A. (2016). A novel meta-heuristic algorithm: tug of war optimization. Iran University of Science & Technology, 6(4), 469-492.
-          * **OppoTWO**: Kaveh, A., Almasi, P. and Khodagholi, A., 2022. Optimum Design of Castellated Beams Using Four Recently Developed Meta-heuristic Algorithms.Â Iranian Journal of Science and Technology, Transactions of Civil Engineering, pp.1-13.
-          * **LevyTWO**: The developed version using Levy-flight
-          * **ImprovedTWO**: Nguyen, T., Hoang, B., Nguyen, G., & Nguyen, B. M. (2020). A new workload prediction model using extreme learning machine and enhanced tug of war optimization. Procedia Computer Science, 170, 362-369.
-        
-        * **TSA - Tunicate Swarm Algorithm**
-          * **OriginalTSA**: Kaur, S., Awasthi, L. K., Sangal, A. L., & Dhiman, G. (2020). Tunicate Swarm Algorithm: A new bio-inspired based metaheuristic paradigm for global optimization. Engineering Applications of Artificial Intelligence, 90, 103541.
-        
-        * **TSO - Tuna Swarm Optimization**
-          * **OriginalTSO**: Xie, L., Han, T., Zhou, H., Zhang, Z. R., Han, B., & Tang, A. (2021). Tuna swarm optimization: a novel swarm-based metaheuristic algorithm for global optimization. Computational intelligence and Neuroscience, 2021.
-        
-        
-        ### U
-        
-        ### V
-        
-        * **VCS - Virus Colony Search** 
-          * **OriginalVCS**: Li, M. D., Zhao, H., Weng, X. W., & Han, T. (2016). A novel nature-inspired algorithm for optimization: Virus colony search. Advances in Engineering Software, 92, 65-88.
-          * **BaseVCS**: The developed version
-        
-        ### W
-        
-        * **WCA - Water Cycle Algorithm** 
-          * **OriginalWCA**: Eskandar, H., Sadollah, A., Bahreininejad, A., & Hamdi, M. (2012). Water cycle algorithmâA novel metaheuristic optimization method for solving constrained engineering optimization problems. Computers & Structures, 110, 151-166.
-          
-        * **WOA - Whale Optimization Algorithm** 
-          * **OriginalWOA**: Mirjalili, S., & Lewis, A. (2016). The whale optimization algorithm. Advances in engineering software, 95, 51-67.
-          * **HI_WOA**: Tang, C., Sun, W., Wu, W., & Xue, M. (2019, July). A hybrid improved whale optimization algorithm. In 2019 IEEE 15th International Conference on Control and Automation (ICCA) (pp. 362-367). IEEE.
-        
-        * **WHO - Wildebeest Herd Optimization** 
-          * **OriginalWHO**: Amali, D., & Dinakaran, M. (2019). Wildebeest herd optimization: A new global optimization algorithm inspired by wildebeest herding behaviour. Journal of Intelligent & Fuzzy Systems, (Preprint), 1-14.
-        
-        * **WDO - Wind Driven Optimization** 
-          * **OriginalWDO**: Bayraktar, Z., Komurcu, M., Bossard, J.A. and Werner, D.H., 2013. The wind driven optimization technique and its application in electromagnetics. IEEE transactions on antennas and propagation, 61(5), pp.2745-2757.
-        
-        
-        ### X
-        
-        ### Y
-        
-        ### Z
-        
-Keywords: optimization,metaheuristics,MHA,mathematical optimization,nature-inspired algorithms,evolutionary computation,soft computing,population-based algorithms,Stochastic optimization,Global optimization,Convergence analysis,Search space exploration,Local search,Computational intelligence,Black-box optimization,Robust optimization,Hybrid algorithms,Benchmark functions,Metaheuristic design,Performance analysis,Exploration versus exploitation,Self-adaptation,Constrained optimization,Intelligent optimization,Adaptive search,Simulations,Algorithm selection
-Platform: UNKNOWN
-Classifier: Development Status :: 5 - Production/Stable
-Classifier: Intended Audience :: Developers
-Classifier: Intended Audience :: Education
-Classifier: Intended Audience :: Information Technology
-Classifier: Intended Audience :: Science/Research
-Classifier: License :: OSI Approved :: GNU General Public License v3 (GPLv3)
-Classifier: Natural Language :: English
-Classifier: Programming Language :: Python :: 3
-Classifier: Programming Language :: Python :: 3.7
-Classifier: Programming Language :: Python :: 3.8
-Classifier: Programming Language :: Python :: 3.9
-Classifier: Programming Language :: Python :: 3.10
-Classifier: Programming Language :: Python :: 3.11
-Classifier: Topic :: System :: Benchmark
-Classifier: Topic :: Scientific/Engineering
-Classifier: Topic :: Scientific/Engineering :: Mathematics
-Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
-Classifier: Topic :: Scientific/Engineering :: Information Analysis
-Classifier: Topic :: Scientific/Engineering :: Visualization
-Classifier: Topic :: Scientific/Engineering :: Bio-Informatics
-Classifier: Topic :: Software Development :: Build Tools
-Classifier: Topic :: Software Development :: Libraries
-Classifier: Topic :: Software Development :: Libraries :: Python Modules
-Classifier: Topic :: Utilities
-Requires-Python: >=3.7
-Description-Content-Type: text/markdown
-Provides-Extra: dev
+Metadata-Version: 2.1
+Name: mealpy
+Version: 2.5.3a1
+Summary: MEALPY: A Framework Of The State-Of-The-Art Meta-Heuristic Algorithms In Python
+Home-page: https://github.com/thieu1995/mealpy
+Author: Thieu
+Author-email: nguyenthieu2102@gmail.com
+License: GPLv3
+Project-URL: Documentation, https://mealpy.readthedocs.io/
+Project-URL: Source Code, https://github.com/thieu1995/mealpy
+Project-URL: Bug Tracker, https://github.com/thieu1995/mealpy/issues
+Project-URL: Change Log, https://github.com/thieu1995/mealpy/blob/master/ChangeLog.md
+Project-URL: Forum, https://t.me/+fRVCJGuGJg1mNDg1
+Keywords: optimization,metaheuristics,MHA,mathematical optimization,nature-inspired algorithms,evolutionary computation,soft computing,population-based algorithms,Stochastic optimization,Global optimization,Convergence analysis,Search space exploration,Local search,Computational intelligence,Black-box optimization,Robust optimization,Hybrid algorithms,Benchmark functions,Metaheuristic design,Performance analysis,Exploration versus exploitation,Self-adaptation,Constrained optimization,Intelligent optimization,Adaptive search,Simulations,Algorithm selection
+Classifier: Development Status :: 5 - Production/Stable
+Classifier: Intended Audience :: Developers
+Classifier: Intended Audience :: Education
+Classifier: Intended Audience :: Information Technology
+Classifier: Intended Audience :: Science/Research
+Classifier: License :: OSI Approved :: GNU General Public License v3 (GPLv3)
+Classifier: Natural Language :: English
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3.7
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3.9
+Classifier: Programming Language :: Python :: 3.10
+Classifier: Programming Language :: Python :: 3.11
+Classifier: Topic :: System :: Benchmark
+Classifier: Topic :: Scientific/Engineering
+Classifier: Topic :: Scientific/Engineering :: Mathematics
+Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
+Classifier: Topic :: Scientific/Engineering :: Information Analysis
+Classifier: Topic :: Scientific/Engineering :: Visualization
+Classifier: Topic :: Scientific/Engineering :: Bio-Informatics
+Classifier: Topic :: Software Development :: Build Tools
+Classifier: Topic :: Software Development :: Libraries
+Classifier: Topic :: Software Development :: Libraries :: Python Modules
+Classifier: Topic :: Utilities
+Requires-Python: >=3.7
+Description-Content-Type: text/markdown
+Provides-Extra: dev
+License-File: LICENSE
+
+
+<p align="center"><img src="https://thieu1995.github.io/post/2022-04/19-mealpy-tutorials/mealpy1.png" alt="MEALPY"/></p>
+
+---
+
+
+[![GitHub release](https://img.shields.io/badge/release-2.5.2-yellow.svg)](https://github.com/thieu1995/mealpy/releases)
+[![Wheel](https://img.shields.io/pypi/wheel/gensim.svg)](https://pypi.python.org/pypi/mealpy) 
+[![PyPI version](https://badge.fury.io/py/mealpy.svg)](https://badge.fury.io/py/mealpy)
+![PyPI - Python Version](https://img.shields.io/pypi/pyversions/mealpy.svg)
+![PyPI - Status](https://img.shields.io/pypi/status/mealpy.svg)
+![PyPI - Downloads](https://img.shields.io/pypi/dm/mealpy.svg)
+[![Downloads](https://pepy.tech/badge/mealpy)](https://pepy.tech/project/mealpy)
+[![Tests & Publishes to PyPI](https://github.com/thieu1995/mealpy/actions/workflows/publish-package.yaml/badge.svg)](https://github.com/thieu1995/mealpy/actions/workflows/publish-package.yaml)
+![GitHub Release Date](https://img.shields.io/github/release-date/thieu1995/mealpy.svg)
+[![Documentation Status](https://readthedocs.org/projects/mealpy/badge/?version=latest)](https://mealpy.readthedocs.io/en/latest/?badge=latest)
+[![Chat](https://img.shields.io/badge/Chat-on%20Telegram-blue)](https://t.me/+fRVCJGuGJg1mNDg1)
+[![Average time to resolve an issue](http://isitmaintained.com/badge/resolution/thieu1995/mealpy.svg)](http://isitmaintained.com/project/thieu1995/mealpy "Average time to resolve an issue")
+[![Percentage of issues still open](http://isitmaintained.com/badge/open/thieu1995/mealpy.svg)](http://isitmaintained.com/project/thieu1995/mealpy "Percentage of issues still open")
+![GitHub contributors](https://img.shields.io/github/contributors/thieu1995/mealpy.svg)
+[![GitTutorial](https://img.shields.io/badge/PR-Welcome-%23FF8300.svg?)](https://git-scm.com/book/en/v2/GitHub-Contributing-to-a-Project)
+[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3711948.svg)](https://doi.org/10.5281/zenodo.3711948)
+[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)
+
+
+MEALPY is the largest python library for most of the cutting-edge nature-inspired meta-heuristic algorithms (population-based). Population meta-heuristic algorithms (PMA) are the most popular algorithms in the field of 
+approximate optimization.
+
+* **Free software:** GNU General Public License (GPL) V3 license
+* **Total algorithms**: 172 (102 original, 45 official variants, 25 developed variants)
+* **Documentation:** https://mealpy.readthedocs.io/en/latest/
+* **Python versions:** 3.7.x, 3.8.x, 3.9.x, 3.10.x, 3.11.x
+* **Dependencies:** numpy, scipy, pandas, matplotlib
+
+
+# Goals
+
+Our goals are to implement all of the classical as well as the state-of-the-art nature-inspired algorithms, create a simple interface that helps researchers access optimization algorithms as quickly as possible, and share knowledge of the optimization field with everyone without a fee. What you can do with mealpy:
+
+- Analyse parameters of meta-heuristic algorithms.
+- Perform Qualitative and Quantitative Analysis of algorithms.
+- Analyse rate of convergence of algorithms.
+- Test and Analyse the scalability and the robustness of algorithms.
+- Save results in various formats (csv, json, pickle, png, pdf, jpeg)
+- Export and import models can also be done with Mealpy.
+
+
+
+# Installation
+
+### Install with pip
+Install the [current PyPI release](https://pypi.python.org/pypi/mealpy):
+```sh 
+$ pip install mealpy==2.5.2
+```
+
+### Install from source
+In case you want to install directly from the source code, use:
+```sh 
+$ git clone https://github.com/thieu1995/mealpy.git
+$ cd mealpy
+$ python setup.py install
+```
+
+
+# Usage
+
+After installation, you can import Mealpy as any other Python module:
+
+```sh
+$ python
+>>> import mealpy
+>>> mealpy.__version__
+```
+
+Let's go through a basic and advanced example.
+
+
+## Examples
+
+### Simple Benchmark Function
+
+```python 
+from mealpy.bio_based import SMA
+import numpy as np
+
+def fitness_function(solution):
+    return np.sum(solution**2)
+
+problem = {
+    "fit_func": fitness_function,
+    "lb": [-100, ] * 30,
+    "ub": [100, ] * 30,
+    "minmax": "min",
+    "log_to": None,
+    "save_population": False,
+}
+
+## Run the algorithm
+model = SMA.BaseSMA(epoch=100, pop_size=50, pr=0.03)
+best_position, best_fitness = model.solve(problem)
+print(f"Best solution: {best_position}, Best fitness: {best_fitness}")
+```
+
+### Constrained Benchmark Function
+* [The Constrained Benchmark Function](https://github.com/thieu1995/mealpy/tree/master/examples/applications/run_constraint_functions.py)
+
+
+### Multi-objective Benchmark Function
+* [Multi-objective benchmark functions](https://github.com/thieu1995/mealpy/tree/master/examples/applications/run_multi_objective_functions.py)
+
+
+### Custom Problem 
+
+For our custom problem, we can create a class and inherit from the Problem class, named the child class the  
+'Squared' class. In the initialization method of the 'Squared' class, we have to set the *lb*, *ub*, and *minmax*  
+of the problem (lb: a list of lower bound values, ub: a list of upper bound values, and minmax: a string specifying 
+whether the problem is a 'min' or 'max' problem). 
+
+Afterwards, we have to override the abstract method 'fit_func()', which takes a parameter 'solution' (the solution 
+to be evaluated) and returns the function value. The resulting code should look something like the code snippet 
+below. 'Name' is an additional parameter we want to include in this class, and you can include any other additional 
+parameters you need.
+
+
+```python 
+import numpy as np
+from mealpy.bio_based import BBO
+from mealpy.utils.problem import Problem
+
+# Our custom problem class
+class Squared(Problem):
+    def __init__(self, lb=(-5, -5, -5, -5, -5, -5), ub=(5, 5, 5, 5, 5, 5), minmax="min", name="Squared", **kwargs):
+        super().__init__(lb, ub, minmax, **kwargs)
+        self.name = name
+
+    def fit_func(self, solution):
+        return np.sum(solution ** 2)
+```
+
+Now, we define an algorithm, and pass an instance of our *Squared* class as the problem argument. 
+
+```python
+problem = Squared(lb=[-10] * 20, ub=[10] * 20, minmax="min")
+model = BBO.BaseBBO(epoch=10, pop_size=50)
+best_position, best_fitness = model.solve(problem)
+
+print(best_position)
+print(best_fitness)
+print(model.get_parameters())
+print(model.get_name())
+print(model.get_attributes()["solution"])
+print(model.problem.get_name())
+print(model.problem.n_dims)
+```
+
+
+### Tuner class (GridSearchCV/ParameterSearch, Hyper-parameter tuning)
+
+We build a dedicated class, Tuner, that can help you tune your algorithm's parameters.
+
+```python
+import numpy as np
+from mealpy.bio_based import BBO
+from mealpy.tuner import Tuner          # Remember this
+
+
+def fitness(solution):
+    return np.sum(solution**2)
+
+problem = {
+    "lb": [-100, ]*50,
+    "ub": [100, ]*50,
+    "minmax": "min",
+    "fit_func": fitness,
+    "name": "Squared Problem",
+    "log_to": None,
+}
+
+paras_bbo_grid = {
+    "epoch": [100],
+    "pop_size": [50],
+    "elites": [2, 3, 4, 5],
+    "p_m": [0.01, 0.02, 0.05, 0.1, 0.15, 0.2]
+}
+
+if __name__ == "__main__":
+    model = BBO.BaseBBO()
+
+    tuner = Tuner(model, paras_bbo_grid)
+    tuner.execute(problem=problem, n_trials=10, mode="parallel", n_workers=4)
+
+    print(tuner.best_score)
+    print(tuner.best_params)
+    print(tuner.best_algorithm)
+    print(tuner.best_algorithm.get_name())
+    
+    ## Save results to csv file 
+    tuner.export_results(save_path="history/tuning", save_as="csv")
+    
+    ## Re-solve the best model on your problem 
+    best_position, best_fitness = tuner.resolve()
+
+    print(best_position, best_fitness)
+    print(tuner.problem.get_name())
+```
+
+
+### Multitask class (Multitask solving)
+
+We also build a dedicated class, Multitask, that can help you run several scenarios. For example:
+
+1. Run 1 algorithm with 1 problem, and multiple trials
+2. Run 1 algorithm with multiple problems, and multiple trials
+3. Run multiple algorithms with 1 problem, and multiple trials
+4. Run multiple algorithms with multiple problems, and multiple trials
+
+
+```python
+#### Using multiple algorithm to solve multiple problems with multiple trials
+
+## Import libraries
+## For example, we want to solve F5, F10, F29 problem in CEC-2017
+from opfunu.cec_based.cec2017 import F52017, F102017, F292017
+
+from mealpy.bio_based import BBO
+from mealpy.evolutionary_based import DE
+from mealpy.multitask import Multitask          # Remember this
+
+
+## You can define your own problems
+
+f1 = F52017(30, f_bias=0)
+f2 = F102017(30, f_bias=0)
+f3 = F292017(30, f_bias=0)
+
+p1 = {
+    "lb": f1.lb.tolist(),
+    "ub": f1.ub.tolist(),
+    "minmax": "min",
+    "fit_func": f1.evaluate,
+    "name": "F5-CEC2017",
+    "log_to": None,
+}
+
+p2 = {
+    "lb": f2.lb.tolist(),
+    "ub": f2.ub.tolist(),
+    "minmax": "min",
+    "fit_func": f2.evaluate,
+    "name": "F10-CEC2017",
+    "log_to": None,
+}
+
+p3 = {
+    "lb": f3.lb.tolist(),
+    "ub": f3.ub.tolist(),
+    "minmax": "min",
+    "fit_func": f3.evaluate,
+    "name": "F29-CEC2017",
+    "log_to": None,
+}
+
+## Define models
+
+model1 = BBO.BaseBBO(epoch=10, pop_size=50)
+model2 = BBO.OriginalBBO(epoch=10, pop_size=50)
+model3 = DE.BaseDE(epoch=10, pop_size=50)
+
+
+## Define and run Multitask
+
+if __name__ == "__main__":
+    multitask = Multitask(algorithms=(model1, model2, model3), problems=(p1, p2, p3))
+    multitask.execute(n_trials=3, mode="parallel", n_workers=6, save_path="history", save_as="csv", save_convergence=True, verbose=True)
+    
+    ## Check the directory: history/, you will see list of .csv result files
+```
+
+For more usage examples please look at [examples](/examples) folder.
+
+More advanced examples can also be found in the [Mealpy-examples repository](https://github.com/thieu1995/mealpy_examples).
+
+
+### Get Visualize Figures
+
+
+* [Tutorials](/examples/utils/visualize/all_charts.py)
+
+<p align="center"><img src="https://thieu1995.github.io/post/2022-04/19-mealpy-tutorials/mealpy2.png" alt="MEALPY"/>
+</p>
+
+
+## Mealpy Application
+
+### Mealpy + Neural Network (Replace the Gradient Descent Optimizer)
+
+* Time-series Problem:
+  * Traditional MLP
+    code: [Link](https://github.com/thieu1995/mealpy/tree/master/examples/applications/keras/traditional-mlp-time-series.py)
+  * Hybrid code (Mealpy +
+    MLP): [Link](https://github.com/thieu1995/mealpy/tree/master/examples/applications/keras/mha-hybrid-mlp-time-series.py)
+* Classification Problem:
+  * Traditional MLP
+    code: [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/keras/traditional-mlp-classification.py)
+  * Hybrid code (Mealpy +
+    MLP): [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/keras/mha-hybrid-mlp-classification.py)
+
+### Mealpy + Neural Network (Optimize Neural Network Hyper-parameter)
+
+Code: [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/keras/mha-hyper-parameter-mlp-time-series.py)
+
+### Other Applications
+
+* Solving Knapsack Problem (Discrete
+  problems): [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/discrete-problems/knapsack-problem.py)
+
+* Optimize SVM (SVC)
+  model: [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/sklearn/svm_classification.py)
+
+* Optimize Linear Regression
+  Model: [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/pytorch/linear_regression.py)
+
+* Travelling Salesman Problem: https://github.com/thieu1995/MHA-TSP 
+
+* Feature selection problem: https://github.com/thieu1995/MHA-FS
+
+
+
+## Tutorial Videos
+
+All tutorial videos: [Link](https://mealpy.readthedocs.io/en/latest/pages/general/video_tutorials.html)
+
+All code examples: [Link](https://github.com/thieu1995/mealpy/tree/master/examples)
+
+All visualization examples: [Link](https://mealpy.readthedocs.io/en/latest/pages/visualization.html)
+
+
+
+### Get helps (questions, problems)
+
+* Official source code repo: https://github.com/thieu1995/mealpy
+* Official document: https://mealpy.readthedocs.io/
+* Download releases: https://pypi.org/project/mealpy/
+* Issue tracker: https://github.com/thieu1995/mealpy/issues
+* Notable changes log: https://github.com/thieu1995/mealpy/blob/master/ChangeLog.md
+* Examples with different meapy version: https://github.com/thieu1995/mealpy/blob/master/EXAMPLES.md
+
+* This project also related to our another projects which are "meta-heuristics" and "neural-network", check it here
+    * https://github.com/thieu1995/opfunu
+    * https://github.com/thieu1995/metaheuristics
+    * https://github.com/aiir-team
+
+**Want to have an instant assistant? Join our telegram community at [link](https://t.me/+fRVCJGuGJg1mNDg1)**
+We share lots of information, questions, and answers there. You will get more support and knowledge there.
+
+### Cite Us
+
+If you are using mealpy in your project, we would appreciate citations:
+
+```bibtex 
+@software{nguyen_van_thieu_2022_6684223,
+  author       = {Nguyen Van Thieu and Seyedali Mirjalili},
+  title        = {{MEALPY: a Framework of The State-of-The-Art Meta-Heuristic Algorithms in Python}},
+  month        = jun,
+  year         = 2022,
+  publisher    = {Zenodo},
+  version      = {v2.4.2},
+  doi          = {10.5281/zenodo.6684223},
+  url          = {https://doi.org/10.5281/zenodo.6684223}
+}
+
+@article{van2023groundwater,
+  title={Groundwater level modeling using Augmented Artificial Ecosystem Optimization},
+  author={Van Thieu, Nguyen and Barma, Surajit Deb and Van Lam, To and Kisi, Ozgur and Mahesha, Amai},
+  journal={Journal of Hydrology},
+  volume={617},
+  pages={129034},
+  year={2023},
+  publisher={Elsevier}
+}
+```
+
+
+
+# List of papers used MEALPY
+
+- Min, J., Oh, M., Kim, W., Seo, H., & Paek, J. (2022, October). Evaluation of Metaheuristic Algorithms for TAS Scheduling in Time-Sensitive Networking. In 2022 13th International Conference on Information and Communication Technology Convergence (ICTC) (pp. 809-812). IEEE.
+- Khozeimeh, F., Sharifrazi, D., Izadi, N. H., Joloudari, J. H., Shoeibi, A., Alizadehsani, R., ... & Islam, S. M. S. (2021). Combining a convolutional neural network with autoencoders to predict the survival chance of COVID-19 patients. Scientific Reports, 11(1), 15343.
+- Rajesh, K., Jain, E., & Kotecha, P. (2022). A Multi-Objective approach to the Electric Vehicle Routing Problem. arXiv preprint arXiv:2208.12440.
+- SÃ¡nchez, A. J. H., & Upegui, F. R. (2022). Una herramienta para el diseÃ±o de redes MSMN de banda ancha en lÃ­neas de transmisiÃ³n basada en algoritmos heurÃ­sticos de optimizaciÃ³n comparados. Revista IngenierÃ­a UC, 29(2), 106-123.
+- Khanmohammadi, M., Armaghani, D. J., & Sabri Sabri, M. M. (2022). Prediction and Optimization of Pile Bearing Capacity Considering Effects of Time. Mathematics, 10(19), 3563.
+- Kudela, J. (2023). The Evolutionary Computation Methods No One Should Use. arXiv preprint arXiv:2301.01984.
+- Vieira, M., Faia, R., Pinto, T., & Vale, Z. (2022, September). Schedule Peer-to-Peer Transactions of an Energy Community Using Particle Swarm. In 2022 18th International Conference on the European Energy Market (EEM) (pp. 1-6). IEEE.
+- Bui, X. N., Nguyen, H., Le, Q. T., & Le, T. N. Forecasting PM. MINING SCIENCE ANDTECHNOLOGY (Russia), 111.
+- Bui, X. N., Nguyen, H., Le, Q. T., & Le, T. N. (2022). Forecasting PM 2.5 emissions in open-pit minesusing a functional link neural network optimized by various optimization algorithms. Gornye nauki i tekhnologii= Mining Science and Technology (Russia), 7(2), 111-125.
+- DoÄan, E., & YÃ¶rÃ¼keren, N. (2022). Enhancement of Transmission System Security with Archimedes Optimization Algorithm.
+- Ayub, N., Aurangzeb, K., Awais, M., & Ali, U. (2020, November). Electricity theft detection using CNN-GRU and manta ray foraging optimization algorithm. In 2020 IEEE 23Rd international multitopic conference (INMIC) (pp. 1-6). IEEE.
+- Pintilie, L., Nechita, M. T., Suditu, G. D., Dafinescu, V., & DrÄgoi, E. N. (2022). Photo-decolorization of Eriochrome Black T: process optimization with Differential Evolution algorithm. In PASEW-22, MESSH-22 & CABES-22 April 19â21, 2022 Paris (France). Eminent Association of Pioneers.
+- LaTorre, A., Molina, D., Osaba, E., Poyatos, J., Del Ser, J., & Herrera, F. (2021). A prescription of methodological guidelines for comparing bio-inspired optimization algorithms. Swarm and Evolutionary Computation, 67, 100973.
+- Gottam, S., Nanda, S. J., & Maddila, R. K. (2021, December). A CNN-LSTM Model Trained with Grey Wolf Optimizer for Prediction of Household Power Consumption. In 2021 IEEE International Symposium on Smart Electronic Systems (iSES)(Formerly iNiS) (pp. 355-360). IEEE.
+- Darius, P. S., Devadason, J., & Solomon, D. G. (2022, December). Prospects of Ant Colony Optimization (ACO) in Various Domains. In 2022 4th International Conference on Circuits, Control, Communication and Computing (I4C) (pp. 79-84). IEEE.
+- Ayub, N., Irfan, M., Awais, M., Ali, U., Ali, T., Hamdi, M., ... & Muhammad, F. (2020). Big data analytics for short and medium-term electricity load forecasting using an AI techniques ensembler. Energies, 13(19), 5193.
+- Biundini, I. Z., Melo, A. G., Coelho, F. O., HonÃ³rio, L. M., Marcato, A. L., & Pinto, M. F. (2022). Experimentation and Simulation with Autonomous Coverage Path Planning for UAVs. Journal of Intelligent & Robotic Systems, 105(2), 46.
+- Yousaf, I., Anwar, F., Imtiaz, S., Almadhor, A. S., Ishmanov, F., & Kim, S. W. (2022). An Optimized Hyperparameter of Convolutional Neural Network Algorithm for Bug Severity Prediction in Alzheimerâs-Based IoT System. Computational Intelligence and Neuroscience, 2022.
+- Xu, L., Yan, W., & Ji, J. (2023). The research of a novel WOG-YOLO algorithm for autonomous driving object detection. Scientific reports, 13(1), 3699.
+- Costache, R. D., Arabameri, A., Islam, A. R. M. T., Abba, S. I., Pandey, M., Ajin, R. S., & Pham, B. T. (2022). Flood susceptibility computation using state-of-the-art machine learning and optimization algorithms.
+- Del Ser, J., Osaba, E., Martinez, A. D., Bilbao, M. N., Poyatos, J., Molina, D., & Herrera, F. (2021, December). More is not always better: insights from a massive comparison of meta-heuristic algorithms over real-parameter optimization problems. In 2021 IEEE Symposium Series on Computational Intelligence (SSCI) (pp. 1-7). IEEE.
+- Rustam, F., Aslam, N., De La Torre DÃ­ez, I., Khan, Y. D., MazÃ³n, J. L. V., RodrÃ­guez, C. L., & Ashraf, I. (2022, November). White Blood Cell Classification Using Texture and RGB Features of Oversampled Microscopic Images. In Healthcare (Vol. 10, No. 11, p. 2230). MDPI.
+- Neupane, D., Kafle, S., Gurung, S., Neupane, S., & Bhattarai, N. (2021). Optimal sizing and financial analysis of a stand-alone SPV-micro-hydropower hybrid system considering generation uncertainty. International Journal of Low-Carbon Technologies, 16(4), 1479-1491.
+- Liang, R., Le-Hung, T., & Nguyen-Thoi, T. (2022). Energy consumption prediction of air-conditioning systems in eco-buildings using hunger games search optimization-based artificial neural network model. Journal of Building Engineering, 59, 105087.
+- He, Z., Nguyen, H., Vu, T. H., Zhou, J., Asteris, P. G., & Mammou, A. (2022). Novel integrated approaches for predicting the compressibility of clay using cascade forward neural networks optimized by swarm-and evolution-based algorithms. Acta Geotechnica, 1-16.
+- Xu, L., Yan, W., & Ji, J. (2022). The research of a novel WOG-YOLO algorithm forautonomous driving object detection.
+- Nasir Ayub, M. I., Awais, M., Ali, U., Ali, T., Hamdi, M., Alghamdi, A., & Muhammad, F. Big Data Analytics for Short and Medium Term Electricity Load Forecasting using AI Techniques Ensembler.
+- Xie, C., Nguyen, H., Choi, Y., & Armaghani, D. J. (2022). Optimized functional linked neural network for predicting diaphragm wall deflection induced by braced excavations in clays. Geoscience Frontiers, 13(2), 101313.
+- Hakemi, S., Houshmand, M., & Hosseini, S. A. (2022). A Dynamic Quantum-Inspired Genetic Algorithm with Lengthening Chromosome Size.
+- Kashifi, M. T. City-Wide Crash Risk Prediction and Interpretation Using Deep Learning Model with Multi-Source Big Data. Available at SSRN 4329686.
+- Nguyen, H., & Hoang, N. D. (2022). Computer vision-based classification of concrete spall severity using metaheuristic-optimized Extreme Gradient Boosting Machine and Deep Convolutional Neural Network. Automation in Construction, 140, 104371.
+- Zheng, J., Lu, Z., Wu, K., Ning, G. H., & Li, D. (2020). Coinage-metal-based cyclic trinuclear complexes with metalâmetal interactions: Theories to experiments and structures to functions. Chemical Reviews, 120(17), 9675-9742.
+- Van Thieu, N., Barma, S. D., Van Lam, T., Kisi, O., & Mahesha, A. (2023). Groundwater level modeling using Augmented Artificial Ecosystem Optimization. Journal of Hydrology, 617, 129034.
+- Mo, Z., Zhang, Z., Miao, Q., & Tsui, K. L. (2022). Intelligent Informative Frequency Band Searching Assisted by a Dynamic Bandit Tree Method for Machine Fault Diagnosis. IEEE/ASME Transactions on Mechatronics.
+- Dangi, D., Chandel, S. T., Dixit, D. K., Sharma, S., & Bhagat, A. (2023). An Efficient Model for Sentiment Analysis using Artificial Rabbits Optimized Vector Functional Link Network. Expert Systems with Applications, 119849.
+- Dey, S., Roychoudhury, R., Malakar, S., & Sarkar, R. (2022). An optimized fuzzy ensemble of convolutional neural networks for detecting tuberculosis from Chest X-ray images. Applied Soft Computing, 114, 108094.
+- Mousavirad, S. J., & Alexandre, L. A. (2022). Population-based JPEG Image Compression: Problem Re-Formulation. arXiv preprint arXiv:2212.06313.
+- Tsui, K. L. Intelligent Informative Frequency Band Searching Assisted by A Dynamic Bandit Tree Method for Machine Fault Diagnosis.
+- Neupane, D. (2020). Optimal Sizing and Performance Analysis of Solar PV-Micro hydropower Hybrid System in the Context of Rural Area of Nepal (Doctoral dissertation, Pulchowk Campus).
+- LaTorre, A., Molina, D., Osaba, E., Poyatos, J., Del Ser, J., & Herrera, F. Swarm and Evolutionary Computation.
+- Vieira, M. A. (2022). OtimizaÃ§Ã£o dos custos operacionais de uma comunidade energÃ©tica considerando transaÃ§Ãµes locais em âpeer-to-peerâ (Doctoral dissertation).
+- ToÄaÃ§ar, M. (2022). Using DarkNet models and metaheuristic optimization methods together to detect weeds growing along with seedlings. Ecological Informatics, 68, 101519.
+- ToÄaÃ§ar, M. (2021). Detection of segmented uterine cancer images by Hotspot Detection method using deep learning models, Pigeon-Inspired Optimization, types-based dominant activation selection approaches. Computers in Biology and Medicine, 136, 104659.
+- Khan, N. A Short Term Electricity Load and Price Forecasting Model Based on BAT Algorithm in Logistic Regression and CNN-GRU with WOA.
+- Yelisetti, S., Saini, V. K., Kumar, R., & Lamba, R. (2022, May). Energy Consumption Cost Benefits through Smart Home Energy Management in Residential Buildings: An Indian Case Study. In 2022 IEEE IAS Global Conference on Emerging Technologies (GlobConET) (pp. 930-935). IEEE.
+- Nguyen, H., Cao, M. T., Tran, X. L., Tran, T. H., & Hoang, N. D. (2022). A novel whale optimization algorithm optimized XGBoost regression for estimating bearing capacity of concrete piles. Neural Computing and Applications, 1-28.
+- Hirsching, C., de Jongh, S., Eser, D., Suriyah, M., & Leibfried, T. (2022). Meta-heuristic optimization of control structure and design for MMC-HVdc applications. Electric Power Systems Research, 213, 108371.
+- Amelin, V., Gatiyatullin, E., Romanov, N., Samarkhanov, R., Vasilyev, R., & Yanovich, Y. (2022). Black-Box for Blockchain Parameters Adjustment. IEEE Access, 10, 101795-101802.
+- Ngo, T. Q., Nguyen, L. Q., & Tran, V. Q. (2022). Novel hybrid machine learning models including support vector machine with meta-heuristic algorithms in predicting unconfined compressive strength of organic soils stabilised with cement and lime. International Journal of Pavement Engineering, 1-18.
+- Zhu, Y., & Iiduka, H. (2021). Unified Algorithm Framework for Nonconvex Stochastic Optimization in Deep Neural Networks. IEEE Access, 9, 143807-143823.
+- Hakemi, S., Houshmand, M., KheirKhah, E., & Hosseini, S. A. (2022). A review of recent advances in quantum-inspired metaheuristics. Evolutionary Intelligence, 1-16.
+- Das, A., Das, S. R., Panda, J. P., Dey, A., Gajrani, K. K., Somani, N., & Gupta, N. (2022). Machine learning based modelling and optimization in hard turning of AISI D6 steel with newly developed AlTiSiN coated carbide tool. arXiv preprint arXiv:2202.00596.
+- Yelisetti, S., Saini, V. K., Kumar, R., Lamba, R., & Saxena, A. (2022). Optimal energy management system for residential buildings considering the time of use price with swarm intelligence algorithms. Journal of Building Engineering, 59, 105062.
+- ValdÃ©s, G. T. (2022). Algoritmo para la detecciÃ³n de vehÃ­culos y peatones combinando CNNÂ´ sy tÃ©cnicas de bÃºsqueda.
+- Sallam, N. M., Saleh, A. I., Ali, H. A., & Abdelsalam, M. M. (2023). An efficient EGWO algorithm as feature selection for B-ALL diagnoses and its subtypes classification using peripheral blood smear images. Alexandria Engineering Journal, 68, 39-66.
+
+
+
+
+# Documents
+
+* Meta-heuristic Categories: (Based on this article: [link](https://doi.org/10.1016/j.procs.2020.09.075))
+    + Evolutionary-based: Idea from Darwin's law of natural selection, evolutionary computing 
+    + Swarm-based: Idea from movement, interaction of birds, organization of social ...
+    + Physics-based: Idea from physics law such as Newton's law of universal gravitation, black hole, multiverse 
+    + Human-based: Idea from human interaction such as queuing search, teaching learning, ... 
+    + Biology-based: Idea from biology creature (or microorganism),...
+    + System-based: Idea from eco-system, immune-system, network-system, ...
+    + Math-based: Idea from mathematical form or mathematical law such as sin-cosin 
+    + Music-based: Idea from music instrument
+
+* Difficulty - Difficulty Level (Personal Opinion): Objective observation from author. Depend on the number of 
+  parameters, number of equations, the original ideas, time spend for coding, source lines of code (SLOC).
+    + Easy: A few paras, few equations, SLOC very short
+    + Medium: more equations than Easy level, SLOC longer than Easy level
+    + Hard: Lots of equations, SLOC longer than Medium level, the paper hard to read.
+    + Hard* - Very hard: Lots of equations, SLOC too long, the paper is very hard to read.
+    
+** For newbie, we recommend to read the paper of algorithms which difficulty is "easy" or "medium" difficulty level.
+
+
+| **Group**    | **Name**                                        | **Module** | **Class**        | **Year** | **Paras** | **Difficulty** |
+|--------------|-------------------------------------------------|------------|------------------|----------|-----------|----------------|
+| Evolutionary | Evolutionary Programming                        | EP         | OriginalEP       | 1964     | 3         | easy           |
+| Evolutionary | -                                               | -          | LevyEP           | -        | 3         | easy           |
+| Evolutionary | Evolution Strategies                            | ES         | OriginalES       | 1971     | 3         | easy           |
+| Evolutionary | -                                               | -          | LevyES           | -        | 3         | easy           |
+| Evolutionary | Memetic Algorithm                               | MA         | OriginalMA       | 1989     | 7         | easy           |
+| Evolutionary | Genetic Algorithm                               | GA         | BaseGA           | 1992     | 4         | easy           |
+| Evolutionary | -                                               | -          | SingleGA         | -        | 7         | easy           |
+| Evolutionary | -                                               | -          | MultiGA          | -        | 7         | easy           |
+| Evolutionary | -                                               | -          | EliteSingleGA    | -        | 10        | easy           |
+| Evolutionary | -                                               | -          | EliteMultiGA     | -        | 10        | easy           |
+| Evolutionary | Differential Evolution                          | DE         | BaseDE           | 1997     | 5         | easy           |
+| Evolutionary | -                                               | -          | JADE             | 2009     | 6         | medium         |
+| Evolutionary | -                                               | -          | SADE             | 2005     | 2         | medium         |
+| Evolutionary | -                                               | -          | SHADE            | 2013     | 4         | medium         |
+| Evolutionary | -                                               | -          | L_SHADE          | 2014     | 4         | medium         |
+| Evolutionary | -                                               | -          | SAP_DE           | 2006     | 3         | medium         |
+| Evolutionary | Flower Pollination Algorithm                    | FPA        | OriginalFPA      | 2014     | 4         | medium         |
+| Evolutionary | Coral Reefs Optimization                        | CRO        | OriginalCRO      | 2014     | 11        | medium         |
+| Evolutionary | -                                               | -          | OCRO             | 2019     | 12        | medium         |
+| -            | -                                               | -          | -                | -        | -         | -              |
+| Swarm        | Particle Swarm Optimization                     | PSO        | OriginalPSO      | 1995     | 6         | easy           |
+| Swarm        | -                                               | -          | PPSO             | 2019     | 2         | medium         |
+| Swarm        | -                                               | -          | HPSO_TVAC        | 2017     | 4         | medium         |
+| Swarm        | -                                               | -          | C_PSO            | 2015     | 6         | medium         |
+| Swarm        | -                                               | -          | CL_PSO           | 2006     | 6         | medium         |
+| Swarm        | Bacterial Foraging Optimization                 | BFO        | OriginalBFO      | 2002     | 10        | hard           |
+| Swarm        | -                                               | -          | ABFO             | 2019     | 8         | medium         |
+| Swarm        | Bees Algorithm                                  | BeesA      | OriginalBeesA    | 2005     | 8         | medium         |
+| Swarm        | -                                               | -          | ProbBeesA        | 2015     | 5         | medium         |
+| Swarm        | Cat Swarm Optimization                          | CSO        | OriginalCSO      | 2006     | 11        | hard           |
+| Swarm        | Artificial Bee Colony                           | ABC        | OriginalABC      | 2007     | 8         | medium         |
+| Swarm        | Ant Colony Optimization                         | ACO-R      | OriginalACOR     | 2008     | 5         | easy           |
+| Swarm        | Cuckoo Search Algorithm                         | CSA        | OriginalCSA      | 2009     | 3         | medium         |
+| Swarm        | Firefly Algorithm                               | FFA        | OriginalFFA      | 2009     | 8         | easy           |
+| Swarm        | Fireworks Algorithm                             | FA         | OriginalFA       | 2010     | 7         | medium         |
+| Swarm        | Bat Algorithm                                   | BA         | OriginalBA       | 2010     | 6         | medium         |
+| Swarm        | -                                               | -          | AdaptiveBA       | -        | 8         | medium         |
+| Swarm        | -                                               | -          | ModifiedBA       | -        | 5         | medium         |
+| Swarm        | Fruit-fly Optimization Algorithm                | FOA        | OriginalFOA      | 2012     | 2         | easy           |
+| Swarm        | -                                               | -          | BaseFOA          | -        | 2         | easy           |
+| Swarm        | -                                               | -          | WhaleFOA         | 2020     | 2         | medium         |
+| Swarm        | Social Spider Optimization                      | SSpiderO   | OriginalSSpiderO | 2018     | 4         | hard*          |
+| Swarm        | Grey Wolf Optimizer                             | GWO        | OriginalGWO      | 2014     | 2         | easy           |
+| Swarm        | -                                               | -          | RW_GWO           | 2019     | 2         | easy           |
+| Swarm        | Social Spider Algorithm                         | SSpiderA   | OriginalSSpiderA | 2015     | 5         | medium         |
+| Swarm        | Ant Lion Optimizer                              | ALO        | OriginalALO      | 2015     | 2         | easy           |
+| Swarm        | -                                               | -          | BaseALO          | -        | 2         | easy           |
+| Swarm        | Moth Flame Optimization                         | MFO        | OriginalMFO      | 2015     | 2         | easy           |
+| Swarm        | -                                               | -          | BaseMFO          | -        | 2         | easy           |
+| Swarm        | Elephant Herding Optimization                   | EHO        | OriginalEHO      | 2015     | 5         | easy           |
+| Swarm        | Jaya Algorithm                                  | JA         | OriginalJA       | 2016     | 2         | easy           |
+| Swarm        | -                                               | -          | BaseJA           | -        | 2         | easy           |
+| Swarm        | -                                               | -          | LevyJA           | 2021     | 2         | easy           |
+| Swarm        | Whale Optimization Algorithm                    | WOA        | OriginalWOA      | 2016     | 2         | medium         |
+| Swarm        | -                                               | -          | HI_WOA           | 2019     | 3         | medium         |
+| Swarm        | Dragonfly Optimization                          | DO         | OriginalDO       | 2016     | 2         | medium         |
+| Swarm        | Bird Swarm Algorithm                            | BSA        | OriginalBSA      | 2016     | 9         | medium         |
+| Swarm        | Spotted Hyena Optimizer                         | SHO        | OriginalSHO      | 2017     | 4         | medium         |
+| Swarm        | Salp Swarm Optimization                         | SSO        | OriginalSSO      | 2017     | 2         | easy           |
+| Swarm        | Swarm Robotics Search And Rescue                | SRSR       | OriginalSRSR     | 2017     | 2         | hard*          |
+| Swarm        | Grasshopper Optimisation Algorithm              | GOA        | OriginalGOA      | 2017     | 4         | easy           |
+| Swarm        | Coyote Optimization Algorithm                   | COA        | OriginalCOA      | 2018     | 3         | medium         |
+| Swarm        | Moth Search Algorithm                           | MSA        | OriginalMSA      | 2018     | 5         | easy           |
+| Swarm        | Sea Lion Optimization                           | SLO        | OriginalSLO      | 2019     | 2         | medium         |
+| Swarm        | -                                               | -          | ModifiedSLO      | -        | 2         | medium         |
+| Swarm        | -                                               | -          | ImprovedSLO      | -        | 4         | medium         |
+| Swarm        | Nake Mole-Rat Algorithm                         | NMRA       | OriginalNMRA     | 2019     | 3         | easy           |
+| Swarm        | -                                               | -          | ImprovedNMRA     | -        | 4         | medium         |
+| Swarm        | Pathfinder Algorithm                            | PFA        | OriginalPFA      | 2019     | 2         | medium         |
+| Swarm        | Sailfish Optimizer                              | SFO        | OriginalSFO      | 2019     | 5         | easy           |
+| Swarm        | -                                               | -          | ImprovedSFO      | -        | 3         | medium         |
+| Swarm        | Harris Hawks Optimization                       | HHO        | OriginalHHO      | 2019     | 2         | medium         |
+| Swarm        | Manta Ray Foraging Optimization                 | MRFO       | OriginalMRFO     | 2020     | 3         | medium         |
+| Swarm        | Bald Eagle Search                               | BES        | OriginalBES      | 2020     | 7         | easy           |
+| Swarm        | Sparrow Search Algorithm                        | SSA        | OriginalSSA      | 2020     | 5         | medium         |
+| Swarm        | -                                               | -          | BaseSSA          | -        | 5         | medium         |
+| Swarm        | Hunger Games Search                             | HGS        | OriginalHGS      | 2021     | 4         | medium         |
+| Swarm        | Aquila Optimizer                                | AO         | OriginalAO       | 2021     | 2         | easy           |
+| Swarm        | Hybrid Grey Wolf - Whale Optimization Algorithm | GWO        | GWO_WOA          | 2022     | 2         | easy           |
+| Swarm        | Marine Predators Algorithm                      | MPA        | OriginalMPA      | 2020     | 2         | medium         |
+| Swarm        | Honey Badger Algorithm                          | HBA        | OriginalHBA      | 2022     | 2         | easy           |
+| Swarm        | Sand Cat Swarm Optimization                     | SCSO       | OriginalSCSO     | 2022     | 2         | easy           |
+| Swarm        | Tuna Swarm Optimization                         | TSO        | OriginalTSO      | 2021     | 2         | medium         |
+| Swarm        | African Vultures Optimization Algorithm         | AVOA       | OriginalAVOA     | 2022     | 7         | medium         |
+| Swarm        | Artificial Gorilla Troops Optimization          | AGTO       | OriginalAGTO     | 2021     | 5         | medium         |
+| Swarm        | Artificial Rabbits Optimization                 | ARO        | OriginalARO      | 2022     | 2         | easy           |
+| Swarm        | Dwarf Mongoose Optimization Algorithm           | DMOA       | OriginalDMOA     | 2022     | 4         | medium         |
+| Swarm        | -                                               | -          | DevDMOA          | -        | 3         | medium         |
+| -            | -                                               | -          | -                | -        | -         | -              |
+| Physics      | Simulated Annealling                            | SA         | OriginalSA       | 1987     | 9         | medium         |
+| Physics      | Wind Driven Optimization                        | WDO        | OriginalWDO      | 2013     | 7         | easy           |
+| Physics      | Multi-Verse Optimizer                           | MVO        | OriginalMVO      | 2016     | 4         | easy           |
+| Physics      | -                                               | -          | BaseMVO          | -        | 4         | easy           |
+| Physics      | Tug of War Optimization                         | TWO        | OriginalTWO      | 2016     | 2         | easy           |
+| Physics      | -                                               | -          | OppoTWO          | -        | 2         | medium         |
+| Physics      | -                                               | -          | LevyTWO          | -        | 2         | medium         |
+| Physics      | -                                               | -          | EnhancedTWO      | 2020     | 2         | medium         |
+| Physics      | Electromagnetic Field Optimization              | EFO        | OriginalEFO      | 2016     | 6         | easy           |
+| Physics      | -                                               | -          | BaseEFO          | -        | 6         | medium         |
+| Physics      | Nuclear Reaction Optimization                   | NRO        | OriginalNRO      | 2019     | 2         | hard*          |
+| Physics      | Henry Gas Solubility Optimization               | HGSO       | OriginalHGSO     | 2019     | 3         | medium         |
+| Physics      | Atom Search Optimization                        | ASO        | OriginalASO      | 2019     | 4         | medium         |
+| Physics      | Equilibrium Optimizer                           | EO         | OriginalEO       | 2019     | 2         | easy           |
+| Physics      | -                                               | -          | ModifiedEO       | 2020     | 2         | medium         |
+| Physics      | -                                               | -          | AdaptiveEO       | 2020     | 2         | medium         |
+| Physics      | Archimedes Optimization Algorithm               | ArchOA     | OriginalArchOA   | 2021     | 8         | medium         |
+| -            | -                                               | -          | -                | -        | -         | -              |
+| Human        | Culture Algorithm                               | CA         | OriginalCA       | 1994     | 3         | easy           |
+| Human        | Imperialist Competitive Algorithm               | ICA        | OriginalICA      | 2007     | 8         | hard*          |
+| Human        | Teaching Learning-based Optimization            | TLO        | OriginalTLO      | 2011     | 2         | easy           |
+| Human        | -                                               | -          | BaseTLO          | 2012     | 2         | easy           |
+| Human        | -                                               | -          | ITLO             | 2013     | 3         | medium         |
+| Human        | Brain Storm Optimization                        | BSO        | OriginalBSO      | 2011     | 8         | medium         |
+| Human        | -                                               | -          | ImprovedBSO      | 2017     | 7         | medium         |
+| Human        | Queuing Search Algorithm                        | QSA        | OriginalQSA      | 2019     | 2         | hard           |
+| Human        | -                                               | -          | BaseQSA          | -        | 2         | hard           |
+| Human        | -                                               | -          | OppoQSA          | -        | 2         | hard           |
+| Human        | -                                               | -          | LevyQSA          | -        | 2         | hard           |
+| Human        | -                                               | -          | ImprovedQSA      | 2021     | 2         | hard           |
+| Human        | Search And Rescue Optimization                  | SARO       | OriginalSARO     | 2019     | 4         | medium         |
+| Human        | -                                               | -          | BaseSARO         | -        | 4         | medium         |
+| Human        | Life Choice-Based Optimization                  | LCO        | OriginalLCO      | 2019     | 3         | easy           |
+| Human        | -                                               | -          | BaseLCO          | -        | 3         | easy           |
+| Human        | -                                               | -          | ImprovedLCO      | -        | 2         | easy           |
+| Human        | Social Ski-Driver Optimization                  | SSDO       | OriginalSSDO     | 2019     | 2         | easy           |
+| Human        | Gaining Sharing Knowledge-based Algorithm       | GSKA       | OriginalGSKA     | 2019     | 6         | medium         |
+| Human        | -                                               | -          | BaseGSKA         | -        | 4         | medium         |
+| Human        | Coronavirus Herd Immunity Optimization          | CHIO       | OriginalCHIO     | 2020     | 4         | medium         |
+| Human        | -                                               | -          | BaseCHIO         | -        | 4         | medium         |
+| Human        | Forensic-Based Investigation Optimization       | FBIO       | OriginalFBIO     | 2020     | 2         | medium         |
+| Human        | -                                               | -          | BaseFBIO         | -        | 2         | medium         |
+| Human        | Battle Royale Optimization                      | BRO        | OriginalBRO      | 2020     | 3         | medium         |
+| Human        | -                                               | -          | BaseBRO          | -        | 3         | medium         |
+| Human        | Student Psychology Based Optimization           | SPBO       | OriginalSPBO     | 2020     | 2         | medium         |
+| Human        | -                                               | -          | DevSPBO          |          | 2         | medium         |
+| -            | -                                               | -          | -                | -        | -         | -              |
+| Bio          | Invasive Weed Optimization                      | IWO        | OriginalIWO      | 2006     | 7         | easy           |
+| Bio          | Biogeography-Based Optimization                 | BBO        | OriginalBBO      | 2008     | 4         | easy           |
+| Bio          | -                                               | -          | BaseBBO          | -        | 4         | easy           |
+| Bio          | Virus Colony Search                             | VCS        | OriginalVCS      | 2016     | 4         | hard*          |
+| Bio          | -                                               | -          | BaseVCS          | -        | 4         | hard*          |
+| Bio          | Satin Bowerbird Optimizer                       | SBO        | OriginalSBO      | 2017     | 5         | easy           |
+| Bio          | -                                               | -          | BaseSBO          | -        | 5         | easy           |
+| Bio          | Earthworm Optimisation Algorithm                | EOA        | OriginalEOA      | 2018     | 8         | medium         |
+| Bio          | Wildebeest Herd Optimization                    | WHO        | OriginalWHO      | 2019     | 12        | hard           |
+| Bio          | Slime Mould Algorithm                           | SMA        | OriginalSMA      | 2020     | 3         | easy           |
+| Bio          | -                                               | -          | BaseSMA          | -        | 3         | easy           |
+| Bio          | Barnacles Mating Optimizer                      | BMO        | OriginalBMO      | 2018     | 3         | easy           |
+| Bio          | Tunicate Swarm Algorithm                        | TSA        | OriginalTSA      | 2020     | 2         | easy           |
+| Bio          | Symbiotic Organisms Search                      | SOS        | OriginalSOS      | 2014     | 2         | medium         |
+| Bio          | Seagull Optimization Algorithm                  | SOA        | OriginalSOA      | 2019     | 3         | easy           |
+| Bio          | -                                               | -          | DevSOA           | -        | 3         | easy           |
+| -            | -                                               | -          | -                | -        | -         | -              |
+| System       | Germinal Center Optimization                    | GCO        | OriginalGCO      | 2018     | 4         | medium         |
+| System       | -                                               | -          | BaseGCO          | -        | 4         | medium         |
+| System       | Water Cycle Algorithm                           | WCA        | OriginalWCA      | 2012     | 5         | medium         |
+| System       | Artificial Ecosystem-based Optimization         | AEO        | OriginalAEO      | 2019     | 2         | easy           |
+| System       | -                                               | -          | EnhancedAEO      | 2020     | 2         | medium         |
+| System       | -                                               | -          | ModifiedAEO      | 2020     | 2         | medium         |
+| System       | -                                               | -          | ImprovedAEO      | 2021     | 2         | medium         |
+| System       | -                                               | -          | AugmentedAEO     | 2022     | 2         | medium         |
+| -            | -                                               | -          | -                | -        | -         | -              |
+| Math         | Hill Climbing                                   | HC         | OriginalHC       | 1993     | 3         | easy           |
+| Math         | -                                               | -          | SwarmHC          | -        | 3         | easy           |
+| Math         | Cross-Entropy Method                            | CEM        | OriginalCEM      | 1997     | 4         | easy           |
+| Math         | Sine Cosine Algorithm                           | SCA        | OriginalSCA      | 2016     | 2         | easy           |
+| Math         | -                                               | -          | BaseSCA          | -        | 2         | easy           |
+| Math         | Gradient-Based Optimizer                        | GBO        | OriginalGBO      | 2020     | 5         | medium         |
+| Math         | Arithmetic Optimization Algorithm               | AOA        | OrginalAOA       | 2021     | 6         | easy           |
+| Math         | Chaos Game Optimization                         | CGO        | OriginalCGO      | 2021     | 2         | easy           |
+| Math         | Pareto-like Sequential Sampling                 | PSS        | OriginalPSS      | 2021     | 4         | medium         |
+| Math         | weIghted meaN oF vectOrs                        | INFO       | OriginalINFO     | 2022     | 2         | medium         |
+| Math         | RUNge Kutta optimizer                           | RUN        | OriginalRUN      | 2021     | 2         | hard           |
+| Math         | Circle Search Algorithm                         | CircleSA   | OriginalCircleSA | 2022     | 3         | easy           |
+| -            | -                                               | -          | -                | -        | -         | -              |
+| Music        | Harmony Search                                  | HS         | OriginalHS       | 2001     | 4         | easy           |
+| Music        | -                                               | -          | BaseHS           | -        | 4         | easy           |
+
+
+
+
+
+### A
+
+* **ABC - Artificial Bee Colony**
+  * **OriginalABC**: Karaboga, D. (2005). An idea based on honey bee swarm for numerical optimization (Vol. 200, pp. 1-10). Technical report-tr06, Erciyes university, engineering faculty, computer engineering department.
+
+* **ACOR - Ant Colony Optimization**. 
+  * **OriginalACOR**: Socha, K., & Dorigo, M. (2008). Ant colony optimization for continuous domains. European journal of operational research, 185(3), 1155-1173.
+
+* **ALO - Ant Lion Optimizer** 
+  * **OriginalALO**: Mirjalili S (2015). âThe Ant Lion Optimizer.â Advances in Engineering Software, 83, 80-98. doi: [10.1016/j.advengsoft.2015.01.010](https://doi.org/10.1016/j.advengsoft.2015.01.010)
+  * **BaseALO**: The developed version
+
+* **AEO - Artificial Ecosystem-based Optimization** 
+  * **OriginalAEO**: Zhao, W., Wang, L., & Zhang, Z. (2019). Artificial ecosystem-based optimization: a novel nature-inspired meta-heuristic algorithm. Neural Computing and Applications, 1-43.
+  * **AugmentedAEO**: Van Thieu, N., Barma, S. D., Van Lam, T., Kisi, O., & Mahesha, A. (2022). Groundwater level modeling using Augmented Artificial Ecosystem Optimization. Journal of Hydrology, 129034.
+  * **ImprovedAEO**: Rizk-Allah, R. M., & El-Fergany, A. A. (2020). Artificial ecosystem optimizer for parameters identification of proton exchange membrane fuel cells model. International Journal of Hydrogen Energy.
+  * **EnhancedAEO**: Eid, A., Kamel, S., Korashy, A., & Khurshaid, T. (2020). An Enhanced Artificial Ecosystem-Based Optimization for Optimal Allocation of Multiple Distributed Generations. IEEE Access, 8, 178493-178513.
+  * **ModifiedAEO**: Menesy, A. S., Sultan, H. M., Korashy, A., Banakhr, F. A., Ashmawy, M. G., & Kamel, S. (2020). Effective parameter extraction of different polymer electrolyte membrane fuel cell stack models using a modified artificial ecosystem optimization algorithm. IEEE Access, 8, 31892-31909.
+  
+* **ASO - Atom Search Optimization**   
+  * **OriginalASO**: Zhao, W., Wang, L., & Zhang, Z. (2019). Atom search optimization and its application to solve a hydrogeologic parameter estimation problem. Knowledge-Based Systems, 163, 283-304.
+
+* **ArchOA - Archimedes Optimization Algorithm**
+  * **OriginalArchOA**: Hashim, F. A., Hussain, K., Houssein, E. H., Mabrouk, M. S., & Al-Atabany, W. (2021). Archimedes optimization algorithm: a new metaheuristic algorithm for solving optimization problems. Applied Intelligence, 51(3), 1531-1551.
+
+* **AOA - Arithmetic Optimization Algorithm**
+  * **OriginalAOA**: Abualigah, L., Diabat, A., Mirjalili, S., Abd Elaziz, M., & Gandomi, A. H. (2021). The arithmetic optimization algorithm. Computer methods in applied mechanics and engineering, 376, 113609.
+
+* **AO - Aquila Optimizer**
+  * **OriginalAO**: Abualigah, L., Yousri, D., Abd Elaziz, M., Ewees, A. A., Al-qaness, M. A., & Gandomi, A. H. (2021). Aquila Optimizer: A novel meta-heuristic optimization Algorithm. Computers & Industrial Engineering, 157, 107250.
+
+* **AVOA - African Vultures Optimization Algorithm**
+  * **OriginalAVOA**: Abdollahzadeh, B., Gharehchopogh, F. S., & Mirjalili, S. (2021). African vultures optimization algorithm: A new nature-inspired metaheuristic algorithm for global optimization problems. Computers & Industrial Engineering, 158, 107408.
+
+* **AGTO - Artificial Gorilla Troops Optimization**
+  * **OriginalAGTO**: Abdollahzadeh, B., Soleimanian Gharehchopogh, F., & Mirjalili, S. (2021). Artificial gorilla troops optimizer: a new natureâinspired metaheuristic algorithm for global optimization problems. International Journal of Intelligent Systems, 36(10), 5887-5958.
+
+* **ARO - Artificial Rabbits Optimization**:
+  * **OriginalARO**: Wang, L., Cao, Q., Zhang, Z., Mirjalili, S., & Zhao, W. (2022). Artificial rabbits optimization: A new bio-inspired meta-heuristic algorithm for solving engineering optimization problems. Engineering Applications of Artificial Intelligence, 114, 105082.
+
+
+
+### B
+
+
+* **BFO - Bacterial Foraging Optimization** 
+  * **OriginalBFO**: Passino, K. M. (2002). Biomimicry of bacterial foraging for distributed optimization and control. IEEE control systems magazine, 22(3), 52-67.
+  * **ABFO**: Nguyen, T., Nguyen, B. M., & Nguyen, G. (2019, April). Building resource auto-scaler with functional-link neural network and adaptive bacterial foraging optimization. In International Conference on Theory and Applications of Models of Computation (pp. 501-517). Springer, Cham.
+
+* **BeesA - Bees Algorithm** 
+  * **OriginalBeesA**: Pham, D. T., Ghanbarzadeh, A., Koc, E., Otri, S., Rahim, S., & Zaidi, M. (2005). The bees algorithm. Technical Note, Manufacturing Engineering Centre, Cardiff University, UK.
+  * **ProbBeesA**: The probabilitic version of: Pham, D. T., Ghanbarzadeh, A., KoÃ§, E., Otri, S., Rahim, S., & Zaidi, M. (2006). The bees algorithmâa novel tool for complex optimisation problems. In Intelligent production machines and systems (pp. 454-459). Elsevier Science Ltd.
+  
+* **BBO - Biogeography-Based Optimization** 
+  * **OriginalBBO**: Simon, D. (2008). Biogeography-based optimization. IEEE transactions on evolutionary computation, 12(6), 702-713.
+  * **BaseBBO**: The developed version
+  
+* **BA - Bat Algorithm** 
+  * **OriginalBA**: Yang, X. S. (2010). A new metaheuristic bat-inspired algorithm. In Nature inspired cooperative strategies for optimization (NICSO 2010) (pp. 65-74). Springer, Berlin, Heidelberg.
+  * **AdaptiveBA**: Wang, X., Wang, W. and Wang, Y., 2013, July. An adaptive bat algorithm. In International Conference on Intelligent Computing(pp. 216-223). Springer, Berlin, Heidelberg.
+  * **ModifiedBA**: Dong, H., Li, T., Ding, R. and Sun, J., 2018. A novel hybrid genetic algorithm with granular information for feature selection and optimization. Applied Soft Computing, 65, pp.33-46.
+
+* **BSO - Brain Storm Optimization** 
+  * **OriginalBSO**: . Shi, Y. (2011, June). Brain storm optimization algorithm. In International conference in swarm intelligence (pp. 303-309). Springer, Berlin, Heidelberg.
+  * **ImprovedBSO**: El-Abd, M., 2017. Global-best brain storm optimization algorithm. Swarm and evolutionary computation, 37, pp.27-44.
+
+* **BSA - Bird Swarm Algorithm** 
+  * **OriginalBSA**: Meng, X. B., Gao, X. Z., Lu, L., Liu, Y., & Zhang, H. (2016). A new bio-inspired optimisation algorithm:Bird Swarm Algorithm. Journal of Experimental & Theoretical Artificial Intelligence, 28(4), 673-687.
+
+* **BMO - Barnacles Mating Optimizer**:
+  * **OriginalBMO**: Sulaiman, M. H., Mustaffa, Z., Saari, M. M., Daniyal, H., Daud, M. R., Razali, S., & Mohamed, A. I. (2018, June). Barnacles mating optimizer: a bio-inspired algorithm for solving optimization problems. In 2018 19th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD) (pp. 265-270). IEEE.
+
+* **BES - Bald Eagle Search** 
+  * **OriginalBES**: Alsattar, H. A., Zaidan, A. A., & Zaidan, B. B. (2019). Novel meta-heuristic bald eagle search optimisation algorithm. Artificial Intelligence Review, 1-28.
+  
+* **BRO - Battle Royale Optimization**
+  * **OriginalBRO**: Rahkar Farshi, T. (2020). Battle royale optimization algorithm. Neural Computing and Applications, 1-19.
+  * **BaseBRO**: The developed version
+
+### C
+
+* **CA - Culture Algorithm** 
+  * **OriginalCA**: Reynolds, R.G., 1994, February. An introduction to cultural algorithms. In Proceedings of the third annual conference on evolutionary programming (Vol. 24, pp. 131-139). River Edge, NJ: World Scientific.
+
+* **CEM - Cross Entropy Method**
+  * **OriginalCEM**: Rubinstein, R. (1999). The cross-entropy method for combinatorial and continuous optimization. Methodology and computing in applied probability, 1(2), 127-190.
+  
+* **CSO - Cat Swarm Optimization** 
+  * **OriginalCSO**: Chu, S. C., Tsai, P. W., & Pan, J. S. (2006, August). Cat swarm optimization. In Pacific Rim international conference on artificial intelligence (pp. 854-858). Springer, Berlin, Heidelberg.
+
+* **CSA - Cuckoo Search Algorithm** 
+  * **OriginalCSA**: Yang, X. S., & Deb, S. (2009, December). Cuckoo search via LÃ©vy flights. In 2009 World congress on nature & biologically inspired computing (NaBIC) (pp. 210-214). Ieee.
+
+* **CRO - Coral Reefs Optimization** 
+  * **OriginalCRO**: Salcedo-Sanz, S., Del Ser, J., Landa-Torres, I., Gil-LÃ³pez, S., & Portilla-Figueras, J. A. (2014). The coral reefs optimization algorithm: a novel metaheuristic for efficiently solving optimization problems. The Scientific World Journal, 2014.
+  * **OCRO**: Nguyen, T., Nguyen, T., Nguyen, B. M., & Nguyen, G. (2019). Efficient time-series forecasting using neural network and opposition-based coral reefs optimization. International Journal of Computational Intelligence Systems, 12(2), 1144-1161.
+
+* **COA - Coyote Optimization Algorithm**
+  * **OriginalCOA**: Pierezan, J., & Coelho, L. D. S. (2018, July). Coyote optimization algorithm: a new metaheuristic for global optimization problems. In 2018 IEEE congress on evolutionary computation (CEC) (pp. 1-8). IEEE.
+
+* **CHIO - Coronavirus Herd Immunity Optimization**
+  * **OriginalCHIO**: Al-Betar, M. A., Alyasseri, Z. A. A., Awadallah, M. A., & Abu Doush, I. (2021). Coronavirus herd immunity optimizer (CHIO). Neural Computing and Applications, 33(10), 5011-5042.
+  * **BaseCHIO**: The developed version
+
+* **CGO - Chaos Game Optimization** 
+  * **OriginalCGO**: Talatahari, S., & Azizi, M. (2021). Chaos Game Optimization: a novel metaheuristic algorithm. Artificial Intelligence Review, 54(2), 917-1004.
+
+* **CSA - Circle Search Algorithm**
+  * **OriginalCSA**: Qais, M. H., Hasanien, H. M., Turky, R. A., Alghuwainem, S., Tostado-VÃ©liz, M., & Jurado, F. (2022). Circle Search Algorithm: A Geometry-Based Metaheuristic Optimization Algorithm. Mathematics, 10(10), 1626.
+
+### D
+
+* **DE - Differential Evolution** 
+  * **BaseDE**: Storn, R., & Price, K. (1997). Differential evolutionâa simple and efficient heuristic for global optimization over continuous spaces. Journal of global optimization, 11(4), 341-359.
+  * **JADE**: Zhang, J., & Sanderson, A. C. (2009). JADE: adaptive differential evolution with optional external archive. IEEE Transactions on evolutionary computation, 13(5), 945-958.
+  * **SADE**: Qin, A. K., & Suganthan, P. N. (2005, September). Self-adaptive differential evolution algorithm for numerical optimization. In 2005 IEEE congress on evolutionary computation (Vol. 2, pp. 1785-1791). IEEE.
+  * **SHADE**: Tanabe, R., & Fukunaga, A. (2013, June). Success-history based parameter adaptation for differential evolution. In 2013 IEEE congress on evolutionary computation (pp. 71-78). IEEE.
+  * **L_SHADE**: Tanabe, R., & Fukunaga, A. S. (2014, July). Improving the search performance of SHADE using linear population size reduction. In 2014 IEEE congress on evolutionary computation (CEC) (pp. 1658-1665). IEEE.
+  * **SAP_DE**: Teo, J. (2006). Exploring dynamic self-adaptive populations in differential evolution. Soft Computing, 10(8), 673-686.
+  
+* **DSA - Differential Search Algorithm (not done)** 
+  * **BaseDSA**: Civicioglu, P. (2012). Transforming geocentric cartesian coordinates to geodetic coordinates by using differential search algorithm. Computers & Geosciences, 46, 229-247.
+  
+* **DO - Dragonfly Optimization** 
+  * **OriginalDO**: Mirjalili, S. (2016). Dragonfly algorithm: a new meta-heuristic optimization technique for solving single-objective, discrete, and multi-objective problems. Neural Computing and Applications, 27(4), 1053-1073.
+
+* **DMOA - Dwarf Mongoose Optimization Algorithm**
+  * **OriginalDMOA**: Agushaka, J. O., Ezugwu, A. E., & Abualigah, L. (2022). Dwarf mongoose optimization algorithm. Computer methods in applied mechanics and engineering, 391, 114570.
+  * **DevDMOA**: The developed version
+
+### E
+
+* **ES - Evolution Strategies** . 
+  * **OriginalES**: Schwefel, H. P. (1984). Evolution strategies: A family of non-linear optimization techniques based on imitating some principles of organic evolution. Annals of Operations Research, 1(2), 165-167.
+  * **LevyES**: Zhang, S., & Salari, E. (2005). Competitive learning vector quantization with evolution strategies for image compression. Optical Engineering, 44(2), 027006.
+
+* **EP - Evolutionary programming** . 
+  * **OriginalEP**: Fogel, L. J. (1994). Evolutionary programming in perspective: The top-down view. Computational intelligence: Imitating life.
+  * **LevyEP**: Lee, C.Y. and Yao, X., 2001, May. Evolutionary algorithms with adaptive lÃ©vy mutations. In Proceedings of the 2001 congress on evolutionary computation (IEEE Cat. No. 01TH8546) (Vol. 1, pp. 568-575). IEEE.
+
+* **EHO - Elephant Herding Optimization** . 
+  * **OriginalEHO**: Wang, G. G., Deb, S., & Coelho, L. D. S. (2015, December). Elephant herding optimization. In 2015 3rd International Symposium on Computational and Business Intelligence (ISCBI) (pp. 1-5). IEEE.
+
+* **EFO - Electromagnetic Field Optimization** . 
+  * **OriginalEFO**:Abedinpourshotorban, H., Shamsuddin, S. M., Beheshti, Z., & Jawawi, D. N. (2016). Electromagnetic field optimization: A physics-inspired metaheuristic optimization algorithm. Swarm and Evolutionary Computation, 26, 8-22.
+  * **BaseEFO**: The developed version
+
+* **EOA - Earthworm Optimisation Algorithm** . 
+  * **OriginalEOA**: Wang, G. G., Deb, S., & dos Santos Coelho, L. (2018). Earthworm optimisation algorithm: a bio-inspired metaheuristic algorithm for global optimisation problems. IJBIC, 12(1), 1-22.
+
+* **EO - Equilibrium Optimizer** . 
+  * **OriginalEO**: Faramarzi, A., Heidarinejad, M., Stephens, B., & Mirjalili, S. (2019). Equilibrium optimizer: A novel optimization algorithm. Knowledge-Based Systems.
+  * **ModifiedEO**: Gupta, S., Deep, K., & Mirjalili, S. (2020). An efficient equilibrium optimizer with mutation strategy for numerical optimization. Applied Soft Computing, 96, 106542.
+  * **AdaptiveEO**: Wunnava, A., Naik, M. K., Panda, R., Jena, B., & Abraham, A. (2020). A novel interdependence based multilevel thresholding technique using adaptive equilibrium optimizer. Engineering Applications of Artificial Intelligence, 94, 103836.
+
+### F
+
+* **FFA - Firefly Algorithm** 
+  * **OriginalFFA**: Åukasik, S., & Å»ak, S. (2009, October). Firefly algorithm for continuous constrained optimization tasks. In International conference on computational collective intelligence (pp. 97-106). Springer, Berlin, Heidelberg.
+  
+* **FA - Fireworks algorithm** 
+  * **OriginalFA**: Tan, Y., & Zhu, Y. (2010, June). Fireworks algorithm for optimization. In International conference in swarm intelligence (pp. 355-364). Springer, Berlin, Heidelberg.
+
+* **FPA - Flower Pollination Algorithm** 
+  * **OriginalFPA**: Yang, X. S. (2012, September). Flower pollination algorithm for global optimization. In International conference on unconventional computing and natural computation (pp. 240-249). Springer, Berlin, Heidelberg.
+
+* **FOA - Fruit-fly Optimization Algorithm**
+  * **OriginalFOA**: Pan, W. T. (2012). A new fruit fly optimization algorithm: taking the financial distress model as an example. Knowledge-Based Systems, 26, 69-74.
+  * **BaseFOA**: The developed version
+  * **WhaleFOA**: Fan, Y., Wang, P., Heidari, A. A., Wang, M., Zhao, X., Chen, H., & Li, C. (2020). Boosted hunting-based fruit fly optimization and advances in real-world problems. Expert Systems with Applications, 159, 113502.
+
+* **FBIO - Forensic-Based Investigation Optimization** 
+  * **OriginalFBIO**: Chou, J.S. and Nguyen, N.M., 2020. FBI inspired meta-optimization. Applied Soft Computing, p.106339.
+  * **BaseFBIO**: Fathy, A., Rezk, H. and Alanazi, T.M., 2021. Recent approach of forensic-based investigation algorithm for optimizing fractional order PID-based MPPT with proton exchange membrane fuel cell.IEEE Access,9, pp.18974-18992.
+
+* **FHO - Fire Hawk Optimization**
+  * **OriginalFHO**: Azizi, M., Talatahari, S., & Gandomi, A. H. (2022). Fire Hawk Optimizer: a novel metaheuristic algorithm. Artificial Intelligence Review, 1-77.
+
+### G
+
+* **GA - Genetic Algorithm** 
+  * **BaseGA**: Holland, J. H. (1992). Genetic algorithms. Scientific american, 267(1), 66-73.
+  * **SingleGA**: De Falco, I., Della Cioppa, A. and Tarantino, E., 2002. Mutation-based genetic algorithm: performance evaluation.Â Applied Soft Computing,Â 1(4), pp.285-299.
+  * **MultiGA**: De Jong, K.A. and Spears, W.M., 1992. A formal analysis of the role of multi-point crossover in genetic algorithms.Â Annals of mathematics and Artificial intelligence,Â 5(1), pp.1-26.
+  * **EliteSingleGA**: Elite version of Single-point mutation GA
+  * **EliteMultiGA**: Elite version of Multiple-point mutation GA
+
+* **GWO - Grey Wolf Optimizer** 
+  * **OriginalGWO**: Mirjalili, S., Mirjalili, S. M., & Lewis, A. (2014). Grey wolf optimizer. Advances in engineering software, 69, 46-61.
+  * **RW_GWO**: Gupta, S., & Deep, K. (2019). A novel random walk grey wolf optimizer. Swarm and evolutionary computation, 44, 101-112.
+  * **GWO_WOA**: Obadina, O. O., Thaha, M. A., Althoefer, K., & Shaheed, M. H. (2022). Dynamic characterization of a masterâslave robotic manipulator using a hybrid grey wolfâwhale optimization algorithm. Journal of Vibration and Control, 28(15-16), 1992-2003.
+
+* **GOA - Grasshopper Optimisation Algorithm** 
+  * **OriginalGOA**: Saremi, S., Mirjalili, S., & Lewis, A. (2017). Grasshopper optimisation algorithm: theory and application. Advances in Engineering Software, 105, 30-47.
+
+* **GCO - Germinal Center Optimization** 
+  * **OriginalGCO**: VillaseÃ±or, C., Arana-Daniel, N., Alanis, A. Y., LÃ³pez-Franco, C., & Hernandez-Vargas, E. A. (2018). Germinal center optimization algorithm. International Journal of Computational Intelligence Systems, 12(1), 13-27.
+  * **BaseGCO**: The developed version
+
+* **GSKA - Gaining Sharing Knowledge-based Algorithm** 
+  * **OriginalGSKA**: Mohamed, A. W., Hadi, A. A., & Mohamed, A. K. (2019). Gaining-sharing knowledge based algorithm for solving optimization problems: a novel nature-inspired algorithm. International Journal of Machine Learning and Cybernetics, 1-29.
+  * **BaseGSKA**: Mohamed, A.W., Hadi, A.A., Mohamed, A.K. and Awad, N.H., 2020, July. Evaluating the performance of adaptive GainingSharing knowledge based algorithm on CEC 2020 benchmark problems. InÂ 2020 IEEE Congress on Evolutionary Computation (CEC)Â (pp. 1-8). IEEE.
+
+* **GBO - Gradient-Based Optimizer**
+  * **OriginalGBO**: Ahmadianfar, I., Bozorg-Haddad, O., & Chu, X. (2020). Gradient-based optimizer: A new metaheuristic optimization algorithm. Information Sciences, 540, 131-159.
+
+### H
+
+* **HC - Hill Climbing** . 
+  * **OriginalHC**: Talbi, E. G., & Muntean, T. (1993, January). Hill-climbing, simulated annealing and genetic algorithms: a comparative study and application to the mapping problem. In [1993] Proceedings of the Twenty-sixth Hawaii International Conference on System Sciences (Vol. 2, pp. 565-573). IEEE.
+  * **SwarmHC**: The developed version based on swarm-based idea (Original is single-solution based method)
+
+* **HS - Harmony Search** . 
+  * **OriginalHS**: Geem, Z. W., Kim, J. H., & Loganathan, G. V. (2001). A new heuristic optimization algorithm:harmony search. simulation, 76(2), 60-68.
+  * **BaseHS**: The developed version
+
+* **HHO - Harris Hawks Optimization** . 
+  * **OriginalHHO**: Heidari, A. A., Mirjalili, S., Faris, H., Aljarah, I., Mafarja, M., & Chen, H. (2019). Harris hawks optimization: Algorithm and applications. Future Generation Computer Systems, 97, 849-872.
+
+* **HGSO - Henry Gas Solubility Optimization** . 
+  * **OriginalHGSO**: Hashim, F. A., Houssein, E. H., Mabrouk, M. S., Al-Atabany, W., & Mirjalili, S. (2019). Henry gas solubility optimization: A novel physics-based algorithm. Future Generation Computer Systems, 101, 646-667.
+
+* **HGS - Hunger Games Search** . 
+  * **OriginalHGS**: Yang, Y., Chen, H., Heidari, A. A., & Gandomi, A. H. (2021). Hunger games search:Visions, conception, implementation, deep analysis, perspectives, and towards performance shifts. Expert Systems with Applications, 177, 114864.
+  
+* **HHOA - Horse Herd Optimization Algorithm (not done)** . 
+  * **BaseHHOA**: MiarNaeimi, F., Azizyan, G., & Rashki, M. (2021). Horse herd optimization algorithm: A nature-inspired algorithm for high-dimensional optimization problems. Knowledge-Based Systems, 213, 106711.
+  
+* **HBA - Honey Badger Algorithm**:
+  * **OriginalHBA**: Hashim, F. A., Houssein, E. H., Hussain, K., Mabrouk, M. S., & Al-Atabany, W. (2022). Honey Badger Algorithm: New metaheuristic algorithm for solving optimization problems. Mathematics and Computers in Simulation, 192, 84-110.
+
+
+### I
+
+* **IWO - Invasive Weed Optimization** . 
+  * **OriginalIWO**: Mehrabian, A. R., & Lucas, C. (2006). A novel numerical optimization algorithm inspired from weed colonization. Ecological informatics, 1(4), 355-366.
+
+* **ICA - Imperialist Competitive Algorithm** 
+  * **OriginalICA**: Atashpaz-Gargari, E., & Lucas, C. (2007, September). Imperialist competitive algorithm: an algorithm for optimization inspired by imperialistic competition. In 2007 IEEE congress on evolutionary computation (pp. 4661-4667). Ieee.
+
+* **INFO - weIghted meaN oF vectOrs**:
+  * **OriginalINFO**: Ahmadianfar, I., Heidari, A. A., Gandomi, A. H., Chu, X., & Chen, H. (2021). RUN beyond the metaphor: An efficient     optimization algorithm based on Runge Kutta method. Expert Systems with Applications, 181, 115079.
+
+### J
+
+* **JA - Jaya Algorithm** 
+  * **OriginalJA**: Rao, R. (2016). Jaya: A simple and new optimization algorithm for solving constrained and unconstrained optimization problems. International Journal of Industrial Engineering Computations, 7(1), 19-34.
+  * **BaseJA**: The developed version
+  * **LevyJA**: Iacca, G., dos Santos Junior, V. C., & de Melo, V. V. (2021). An improved Jaya optimization algorithm with Levy flight. Expert Systems with Applications, 165, 113902.
+
+### K
+
+### L
+
+* **LCO - Life Choice-based Optimization** 
+  * **OriginalLCO**: Khatri, A., Gaba, A., Rana, K. P. S., & Kumar, V. (2019). A novel life choice-based optimizer. Soft Computing, 1-21.
+  * **BaseLCO**: The developed version
+  * **ImprovedLCO**: The improved version using Gaussian distribution and Mutation Mechanism
+
+
+### M
+
+* **MA - Memetic Algorithm**
+  * **OriginalMA**: Moscato, P. (1989). On evolution, search, optimization, genetic algorithms and martial arts: Towards memetic algorithms. Caltech concurrent computation program, C3P Report, 826, 1989.
+
+* **MFO - Moth Flame Optimization** 
+  * **OriginalMFO**: Mirjalili, S. (2015). Moth-flame optimization algorithm: A novel nature-inspired heuristic paradigm. Knowledge-based systems, 89, 228-249.
+  * **BaseMFO**: The developed version
+
+* **MVO - Multi-Verse Optimizer** 
+  * **OriginalMVO**: Mirjalili, S., Mirjalili, S. M., & Hatamlou, A. (2016). Multi-verse optimizer: a nature-inspired algorithm for global optimization. Neural Computing and Applications, 27(2), 495-513.
+  * **BaseMVO**: The developed version
+
+* **MSA - Moth Search Algorithm** 
+  * **OriginalMSA**: Wang, G. G. (2018). Moth search algorithm: a bio-inspired metaheuristic algorithm for global optimization problems. Memetic Computing, 10(2), 151-164.
+  
+* **MRFO - Manta Ray Foraging Optimization** 
+  * **OriginalMRFO**: Zhao, W., Zhang, Z., & Wang, L. (2020). Manta ray foraging optimization: An effective bio-inspired optimizer for engineering applications. Engineering Applications of Artificial Intelligence, 87, 103300.
+
+* **MPA - Marine Predators Algorithm**:
+  * **OriginalMPA**: Faramarzi, A., Heidarinejad, M., Mirjalili, S., & Gandomi, A. H. (2020). Marine Predators Algorithm: A nature-inspired metaheuristic. Expert systems with applications, 152, 113377.
+
+
+### N
+
+
+* **NRO - Nuclear Reaction Optimization** 
+  * **OriginalNRO**: Wei, Z., Huang, C., Wang, X., Han, T., & Li, Y. (2019). Nuclear Reaction Optimization: A novel and powerful physics-based algorithm for global optimization. IEEE Access. 
+
+* **NMRA - Nake Mole-Rat Algorithm**
+  * **OriginalNMRA**: Salgotra, R., & Singh, U. (2019). The naked mole-rat algorithm. Neural Computing and Applications, 31(12), 8837-8857.
+  * **ImprovedNMRA**: Singh, P., Mittal, N., Singh, U. and Salgotra, R., 2021. Naked mole-rat algorithm with improved exploration and exploitation capabilities to determine 2D and 3D coordinates of sensor nodes in WSNs.Â Arabian Journal for Science and Engineering,Â 46(2), pp.1155-1178.
+
+
+### O
+
+### P
+
+* **PSO - Particle Swarm Optimization** 
+  * **OriginalPSO**: Eberhart, R., & Kennedy, J. (1995, October). A new optimizer using particle swarm theory. In MHS'95. Proceedings of the Sixth International Symposium on Micro Machine and Human Science (pp. 39-43). Ieee.
+  * **PPSO**: Ghasemi, M., Akbari, E., Rahimnejad, A., Razavi, S. E., Ghavidel, S., & Li, L. (2019). Phasor particle swarm optimization: a simple and efficient variant of PSO. Soft Computing, 23(19), 9701-9718.
+  * **HPSO_TVAC**: Ghasemi, M., Aghaei, J., & Hadipour, M. (2017). New self-organising hierarchical PSO with jumping time-varying acceleration coefficients. Electronics Letters, 53(20), 1360-1362.
+  * **C_PSO**: Liu, B., Wang, L., Jin, Y. H., Tang, F., & Huang, D. X. (2005). Improved particle swarm optimization combined with chaos. Chaos, Solitons & Fractals, 25(5), 1261-1271.
+  * **CL_PSO**: Liang, J. J., Qin, A. K., Suganthan, P. N., & Baskar, S. (2006). Comprehensive learning particle swarm optimizer for global optimization of multimodal functions. IEEE transactions on evolutionary computation, 10(3), 281-295.
+
+* **PFA - Pathfinder Algorithm** 
+  * **OriginalPFA**: Yapici, H., & Cetinkaya, N. (2019). A new meta-heuristic optimizer: Pathfinder algorithm. Applied Soft Computing, 78, 545-568.
+
+* **PSS - Pareto-like Sequential Sampling**
+  * **OriginalPSS**: Shaqfa, M., & Beyer, K. (2021). Pareto-like sequential sampling heuristic for global optimisation. Soft Computing, 25(14), 9077-9096.
+
+
+### Q
+
+* **QSA - Queuing Search Algorithm** 
+  * **OriginalQSA**: Zhang, J., Xiao, M., Gao, L., & Pan, Q. (2018). Queuing search algorithm: A novel metaheuristic algorithm for solving engineering optimization problems. Applied Mathematical Modelling, 63, 464-490.
+  * **BaseQSA**: The developed version
+  * **OppoQSA**: Zheng, X. and Nguyen, H., 2022. A novel artificial intelligent model for predicting water treatment efficiency of various biochar systems based on artificial neural network and queuing search algorithm. Chemosphere, 287, p.132251.
+  * **LevyQSA**: Abderazek, H., Hamza, F., Yildiz, A.R., Gao, L. and Sait, S.M., 2021. A comparative analysis of the queuing search algorithm, the sine-cosine algorithm, the ant lion algorithm to determine the optimal weight design problem of a spur gear drive system. Materials Testing, 63(5), pp.442-447.
+  * **ImprovedQSA**: Nguyen, B.M., Hoang, B., Nguyen, T. and Nguyen, G., 2021. nQSV-Net: a novel queuing search variant for global space search and workload modeling.Â Journal of Ambient Intelligence and Humanized Computing,Â 12(1), pp.27-46.
+
+### R
+
+* **RUN - RUNge Kutta optimizer**:
+  * **OriginalRUN**: Ahmadianfar, I., Heidari, A. A., Gandomi, A. H., Chu, X., & Chen, H. (2021). RUN beyond the metaphor: An efficient optimization algorithm based on Runge Kutta method. Expert Systems with Applications, 181, 115079.
+
+### S
+
+* **SA - Simulated Annealling** 
+  * **OriginalSA**: . Van Laarhoven, P. J., & Aarts, E. H. (1987). Simulated annealing. In Simulated annealing: Theory and applications (pp. 7-15). Springer, Dordrecht.
+
+* **SSpiderO - Social Spider Optimization** 
+  * **OriginalSSpiderO**: Cuevas, E., Cienfuegos, M., ZaldÃ­Var, D., & PÃ©rez-Cisneros, M. (2013). A swarm optimization algorithm inspired in the behavior of the social-spider. Expert Systems with Applications, 40(16), 6374-6384.
+
+* **SOS - Symbiotic Organisms Search**:
+  * **OriginalSOS**: Cheng, M. Y., & Prayogo, D. (2014). Symbiotic organisms search: a new metaheuristic optimization algorithm. Computers & Structures, 139, 98-112.
+
+* **SSpiderA - Social Spider Algorithm** 
+  * **OriginalSSpiderA**: James, J. Q., & Li, V. O. (2015). A social spider algorithm for global optimization. Applied Soft Computing, 30, 614-627.
+
+* **SCA - Sine Cosine Algorithm** 
+  * **OriginalSCA**: Mirjalili, S. (2016). SCA: a sine cosine algorithm for solving optimization problems. Knowledge-Based Systems, 96, 120-133.
+  * **BaseSCA**: Attia, A.F., El Sehiemy, R.A. and Hasanien, H.M., 2018. Optimal power flow solution in power systems using a novel Sine-Cosine algorithm.Â International Journal of Electrical Power & Energy Systems,Â 99, pp.331-343.
+
+* **SRSR - Swarm Robotics Search And Rescue** 
+  * **OriginalSRSR**: Bakhshipour, M., Ghadi, M. J., & Namdari, F. (2017). Swarm robotics search & rescue: A novel artificial intelligence-inspired optimization approach. Applied Soft Computing, 57, 708-726.
+
+* **SBO - Satin Bowerbird Optimizer** 
+  * **OriginalSBO**: Moosavi, S. H. S., & Bardsiri, V. K. (2017). Satin bowerbird optimizer: a new optimization algorithm to optimize ANFIS for software development effort estimation. Engineering Applications of Artificial Intelligence, 60, 1-15.
+  * **BaseSBO**: The developed version
+
+* **SHO - Spotted Hyena Optimizer**
+  * **OriginalSHO**: Dhiman, G., & Kumar, V. (2017). Spotted hyena optimizer: a novel bio-inspired based metaheuristic technique for engineering applications. Advances in Engineering Software, 114, 48-70.
+
+* **SSO - Salp Swarm Optimization**
+  * **OriginalSSO**: Mirjalili, S., Gandomi, A. H., Mirjalili, S. Z., Saremi, S., Faris, H., & Mirjalili, S. M. (2017). Salp Swarm Algorithm: A bio-inspired optimizer for engineering design problems. Advances in Engineering Software, 114, 163-191.
+
+* **SFO - Sailfish Optimizer** 
+  * **OriginalSFO**: Shadravan, S., Naji, H. R., & Bardsiri, V. K. (2019). The Sailfish Optimizer: A novel nature-inspired metaheuristic algorithm for solving constrained engineering optimization problems. Engineering Applications of Artificial Intelligence, 80, 20-34.
+  * **ImprovedSFO**: Li, L.L., Shen, Q., Tseng, M.L. and Luo, S., 2021. Power system hybrid dynamic economic emission dispatch with wind energy based on improved sailfish algorithm.Â Journal of Cleaner Production,Â 316, p.128318.
+
+* **SARO - Search And Rescue Optimization** 
+  * **OriginalSARO**: Shabani, A., Asgarian, B., Gharebaghi, S. A., Salido, M. A., & Giret, A. (2019). A New Optimization Algorithm Based on Search and Rescue Operations. Mathematical Problems in Engineering, 2019.
+  * **BaseSARO**: The developed version using Levy-flight
+
+* **SSDO - Social Ski-Driver Optimization** 
+  * **OriginalSSDO**: Tharwat, A., & Gabel, T. (2019). Parameters optimization of support vector machines for imbalanced data using social ski driver algorithm. Neural Computing and Applications, 1-14.
+
+* **SLO - Sea Lion Optimization**
+  * **OriginalSLO**: Masadeh, R., Mahafzah, B. A., & Sharieh, A. (2019). Sea Lion Optimization Algorithm. Sea, 10(5).
+  * **ImprovedSLO**: The developed version
+  * **ModifiedSLO**: Masadeh, R., Alsharman, N., Sharieh, A., Mahafzah, B.A. and Abdulrahman, A., 2021. Task scheduling on cloud computing based on sea lion optimization algorithm.Â International Journal of Web Information Systems.
+
+* **Seagull Optimization Algorithm**
+  * **OriginalSOA**: Dhiman, G., & Kumar, V. (2019). Seagull optimization algorithm: Theory and its applications for large-scale industrial engineering problems. Knowledge-based systems, 165, 169-196.
+  * **DevSOA**: The developed version
+
+* **SMA - Slime Mould Algorithm**
+  * **OriginalSMA**: Li, S., Chen, H., Wang, M., Heidari, A. A., & Mirjalili, S. (2020). Slime mould algorithm: A new method for stochastic optimization. Future Generation Computer Systems.
+  * **BaseSMA**: The developed version
+
+* **SSA - Sparrow Search Algorithm** 
+  * **OriginalSSA**: Jiankai Xue & Bo Shen (2020) A novel swarm intelligence optimization approach: sparrow search algorithm, Systems Science & Control Engineering, 8:1, 22-34, DOI: 10.1080/21642583.2019.1708830
+  * **BaseSSA**: The developed version
+
+* **SPBO - Student Psychology Based Optimization**
+  * **OriginalSPBO**: Das, B., Mukherjee, V., & Das, D. (2020). Student psychology based optimization algorithm: A new population based optimization algorithm for solving optimization problems. Advances in Engineering software, 146, 102804.
+  * **DevSPBO**: The developed version
+
+* **SCSO - Sand Cat Swarm Optimization**
+  * **OriginalSCSO**: Seyyedabbasi, A., & Kiani, F. (2022). Sand Cat swarm optimization: a nature-inspired algorithm to solve global optimization problems. Engineering with Computers, 1-25.
+
+### T
+
+* **TLO - Teaching Learning Optimization** 
+  * **OriginalTLO**: Rao, R. V., Savsani, V. J., & Vakharia, D. P. (2011). Teachingâlearning-based optimization: a novel method for constrained mechanical design optimization problems. Computer-Aided Design, 43(3), 303-315.
+  * **BaseTLO**: Rao, R., & Patel, V. (2012). An elitist teaching-learning-based optimization algorithm for solving complex constrained optimization problems. International Journal of Industrial Engineering Computations, 3(4), 535-560.
+  * **ImprovedTLO**: Rao, R. V., & Patel, V. (2013). An improved teaching-learning-based optimization algorithm for solving unconstrained optimization problems. Scientia Iranica, 20(3), 710-720.
+
+* **TWO - Tug of War Optimization** 
+  * **OriginalTWO**: Kaveh, A., & Zolghadr, A. (2016). A novel meta-heuristic algorithm: tug of war optimization. Iran University of Science & Technology, 6(4), 469-492.
+  * **OppoTWO**: Kaveh, A., Almasi, P. and Khodagholi, A., 2022. Optimum Design of Castellated Beams Using Four Recently Developed Meta-heuristic Algorithms.Â Iranian Journal of Science and Technology, Transactions of Civil Engineering, pp.1-13.
+  * **LevyTWO**: The developed version using Levy-flight
+  * **ImprovedTWO**: Nguyen, T., Hoang, B., Nguyen, G., & Nguyen, B. M. (2020). A new workload prediction model using extreme learning machine and enhanced tug of war optimization. Procedia Computer Science, 170, 362-369.
+
+* **TSA - Tunicate Swarm Algorithm**
+  * **OriginalTSA**: Kaur, S., Awasthi, L. K., Sangal, A. L., & Dhiman, G. (2020). Tunicate Swarm Algorithm: A new bio-inspired based metaheuristic paradigm for global optimization. Engineering Applications of Artificial Intelligence, 90, 103541.
+
+* **TSO - Tuna Swarm Optimization**
+  * **OriginalTSO**: Xie, L., Han, T., Zhou, H., Zhang, Z. R., Han, B., & Tang, A. (2021). Tuna swarm optimization: a novel swarm-based metaheuristic algorithm for global optimization. Computational intelligence and Neuroscience, 2021.
+
+
+### U
+
+### V
+
+* **VCS - Virus Colony Search** 
+  * **OriginalVCS**: Li, M. D., Zhao, H., Weng, X. W., & Han, T. (2016). A novel nature-inspired algorithm for optimization: Virus colony search. Advances in Engineering Software, 92, 65-88.
+  * **BaseVCS**: The developed version
+
+### W
+
+* **WCA - Water Cycle Algorithm** 
+  * **OriginalWCA**: Eskandar, H., Sadollah, A., Bahreininejad, A., & Hamdi, M. (2012). Water cycle algorithmâA novel metaheuristic optimization method for solving constrained engineering optimization problems. Computers & Structures, 110, 151-166.
+  
+* **WOA - Whale Optimization Algorithm** 
+  * **OriginalWOA**: Mirjalili, S., & Lewis, A. (2016). The whale optimization algorithm. Advances in engineering software, 95, 51-67.
+  * **HI_WOA**: Tang, C., Sun, W., Wu, W., & Xue, M. (2019, July). A hybrid improved whale optimization algorithm. In 2019 IEEE 15th International Conference on Control and Automation (ICCA) (pp. 362-367). IEEE.
+
+* **WHO - Wildebeest Herd Optimization** 
+  * **OriginalWHO**: Amali, D., & Dinakaran, M. (2019). Wildebeest herd optimization: A new global optimization algorithm inspired by wildebeest herding behaviour. Journal of Intelligent & Fuzzy Systems, (Preprint), 1-14.
+
+* **WDO - Wind Driven Optimization** 
+  * **OriginalWDO**: Bayraktar, Z., Komurcu, M., & Werner, D. H. (2010, July). Wind Driven Optimization (WDO): A novel nature-inspired optimization algorithm and its application to electromagnetics. In 2010 IEEE antennas and propagation society international symposium (pp. 1-4). IEEE.
+
+
+### X
+
+### Y
+
+### Z
```

### Comparing `mealpy-2.5.3/README.md` & `mealpy-2.5.3a1/README.md`

 * *Files 6% similar despite different names*

```diff
@@ -1,1104 +1,1093 @@
-
-<p align="center">
-<img style="height:400px;" 
-src="https://thieu1995.github.io/post/2022-04/19-mealpy-tutorials/mealpy5-nobg.png" 
-alt="MEALPY"/>
-</p>
-
----
-
-
-[![GitHub release](https://img.shields.io/badge/release-2.5.3-yellow.svg)](https://github.com/thieu1995/mealpy/releases)
-[![Wheel](https://img.shields.io/pypi/wheel/gensim.svg)](https://pypi.python.org/pypi/mealpy) 
-[![PyPI version](https://badge.fury.io/py/mealpy.svg)](https://badge.fury.io/py/mealpy)
-![PyPI - Python Version](https://img.shields.io/pypi/pyversions/mealpy.svg)
-![PyPI - Status](https://img.shields.io/pypi/status/mealpy.svg)
-![PyPI - Downloads](https://img.shields.io/pypi/dm/mealpy.svg)
-[![Downloads](https://pepy.tech/badge/mealpy)](https://pepy.tech/project/mealpy)
-[![Tests & Publishes to PyPI](https://github.com/thieu1995/mealpy/actions/workflows/publish-package.yaml/badge.svg)](https://github.com/thieu1995/mealpy/actions/workflows/publish-package.yaml)
-![GitHub Release Date](https://img.shields.io/github/release-date/thieu1995/mealpy.svg)
-[![Documentation Status](https://readthedocs.org/projects/mealpy/badge/?version=latest)](https://mealpy.readthedocs.io/en/latest/?badge=latest)
-[![Chat](https://img.shields.io/badge/Chat-on%20Telegram-blue)](https://t.me/+fRVCJGuGJg1mNDg1)
-[![Average time to resolve an issue](http://isitmaintained.com/badge/resolution/thieu1995/mealpy.svg)](http://isitmaintained.com/project/thieu1995/mealpy "Average time to resolve an issue")
-[![Percentage of issues still open](http://isitmaintained.com/badge/open/thieu1995/mealpy.svg)](http://isitmaintained.com/project/thieu1995/mealpy "Percentage of issues still open")
-![GitHub contributors](https://img.shields.io/github/contributors/thieu1995/mealpy.svg)
-[![GitTutorial](https://img.shields.io/badge/PR-Welcome-%23FF8300.svg?)](https://git-scm.com/book/en/v2/GitHub-Contributing-to-a-Project)
-[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3711948.svg)](https://doi.org/10.5281/zenodo.3711948)
-[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)
-
-
-MEALPY is the largest python library for most of the cutting-edge nature-inspired meta-heuristic algorithms (population-based). Population meta-heuristic algorithms (PMA) are the most popular algorithms in the field of 
-approximate optimization.
-
-* **Free software:** GNU General Public License (GPL) V3 license
-* **Total algorithms**: 174 (102 original, 45 official variants, 27 developed variants)
-* **Documentation:** https://mealpy.readthedocs.io/en/latest/
-* **Python versions:** 3.7.x, 3.8.x, 3.9.x, 3.10.x, 3.11.x
-* **Dependencies:** numpy, scipy, pandas, matplotlib
-
-
-# Goals
-
-Our goals are to implement all of the classical as well as the state-of-the-art nature-inspired algorithms, create a simple interface that helps researchers access optimization algorithms as quickly as possible, and share knowledge of the optimization field with everyone without a fee. What you can do with mealpy:
-
-- Analyse parameters of meta-heuristic algorithms.
-- Perform Qualitative and Quantitative Analysis of algorithms.
-- Analyse rate of convergence of algorithms.
-- Test and Analyse the scalability and the robustness of algorithms.
-- Save results in various formats (csv, json, pickle, png, pdf, jpeg)
-- Export and import models can also be done with Mealpy.
-
-
-
-# Installation
-
-### Install with pip
-Install the [current PyPI release](https://pypi.python.org/pypi/mealpy):
-```sh 
-$ pip install mealpy==2.5.3
-```
-
-### Install from source
-In case you want to install directly from the source code, use:
-```sh 
-$ git clone https://github.com/thieu1995/mealpy.git
-$ cd mealpy
-$ python setup.py install
-```
-
-
-# Usage
-
-After installation, you can import Mealpy as any other Python module:
-
-```sh
-$ python
->>> import mealpy
->>> mealpy.__version__
-```
-
-Let's go through a basic and advanced example.
-
-
-## Examples
-
-### Simple Benchmark Function
-
-```python 
-from mealpy.bio_based import SMA
-import numpy as np
-
-def fitness_function(solution):
-    return np.sum(solution**2)
-
-problem = {
-    "fit_func": fitness_function,
-    "lb": [-100, ] * 30,
-    "ub": [100, ] * 30,
-    "minmax": "min",
-    "log_to": None,
-    "save_population": False,
-}
-
-## Run the algorithm
-model = SMA.BaseSMA(epoch=100, pop_size=50, pr=0.03)
-best_position, best_fitness = model.solve(problem)
-print(f"Best solution: {best_position}, Best fitness: {best_fitness}")
-```
-
-### Constrained Benchmark Function
-* [The Constrained Benchmark Function](https://github.com/thieu1995/mealpy/tree/master/examples/applications/run_constraint_functions.py)
-
-
-### Multi-objective Benchmark Function
-* [Multi-objective benchmark functions](https://github.com/thieu1995/mealpy/tree/master/examples/applications/run_multi_objective_functions.py)
-
-
-### Custom Problem 
-
-For our custom problem, we can create a class and inherit from the Problem class, named the child class the  
-'Squared' class. In the initialization method of the 'Squared' class, we have to set the *lb*, *ub*, and *minmax*  
-of the problem (lb: a list of lower bound values, ub: a list of upper bound values, and minmax: a string specifying 
-whether the problem is a 'min' or 'max' problem). 
-
-Afterwards, we have to override the abstract method 'fit_func()', which takes a parameter 'solution' (the solution 
-to be evaluated) and returns the function value. The resulting code should look something like the code snippet 
-below. 'Name' is an additional parameter we want to include in this class, and you can include any other additional 
-parameters you need.
-
-
-```python 
-import numpy as np
-from mealpy.bio_based import BBO
-from mealpy.utils.problem import Problem
-
-# Our custom problem class
-class Squared(Problem):
-    def __init__(self, lb=(-5, -5, -5, -5, -5, -5), ub=(5, 5, 5, 5, 5, 5), minmax="min", name="Squared", **kwargs):
-        super().__init__(lb, ub, minmax, **kwargs)
-        self.name = name
-
-    def fit_func(self, solution):
-        return np.sum(solution ** 2)
-```
-
-Now, we define an algorithm, and pass an instance of our *Squared* class as the problem argument. 
-
-```python
-problem = Squared(lb=[-10] * 20, ub=[10] * 20, minmax="min")
-model = BBO.BaseBBO(epoch=10, pop_size=50)
-best_position, best_fitness = model.solve(problem)
-
-print(best_position)
-print(best_fitness)
-print(model.get_parameters())
-print(model.get_name())
-print(model.get_attributes()["solution"])
-print(model.problem.get_name())
-print(model.problem.n_dims)
-```
-
-
-### Tuner class (GridSearchCV/ParameterSearch, Hyper-parameter tuning)
-
-We build a dedicated class, Tuner, that can help you tune your algorithm's parameters.
-
-```python
-import numpy as np
-from mealpy.bio_based import BBO
-from mealpy.tuner import Tuner          # Remember this
-
-
-def fitness(solution):
-    return np.sum(solution**2)
-
-problem = {
-    "lb": [-100, ]*50,
-    "ub": [100, ]*50,
-    "minmax": "min",
-    "fit_func": fitness,
-    "name": "Squared Problem",
-    "log_to": None,
-}
-
-paras_bbo_grid = {
-    "epoch": [100],
-    "pop_size": [50],
-    "elites": [2, 3, 4, 5],
-    "p_m": [0.01, 0.02, 0.05, 0.1, 0.15, 0.2]
-}
-
-term = {
-  "max_fe": 10000
-}
-
-if __name__ == "__main__":
-    model = BBO.BaseBBO()
-
-    tuner = Tuner(model, paras_bbo_grid)
-    tuner.execute(problem=problem, termination=term, n_trials=5, n_jobs=5, mode="thread", n_workers=4, verbose=True)
-    ## Solve this problem 5 times (n_trials) using 5 processes (n_jobs), each process will handle 1 trial. 
-    ## The mode to run the solver is thread (mode), we will calculate the fitness of 4 solutions (n_workers) at the same time 
-
-    print(tuner.best_score)
-    print(tuner.best_params)
-    print(tuner.best_algorithm)
-    print(tuner.best_algorithm.get_name())
-    
-    ## Save results to csv file 
-    tuner.export_results(save_path="history/tuning", save_as="csv")
-    
-    ## Re-solve the best model on your problem 
-    best_position, best_fitness = tuner.resolve()
-
-    print(best_position, best_fitness)
-    print(tuner.problem.get_name())
-```
-
-
-### Multitask class (Multitask solving)
-
-We also build a dedicated class, Multitask, that can help you run several scenarios. For example:
-
-1. Run 1 algorithm with 1 problem, and multiple trials
-2. Run 1 algorithm with multiple problems, and multiple trials
-3. Run multiple algorithms with 1 problem, and multiple trials
-4. Run multiple algorithms with multiple problems, and multiple trials
-
-
-```python
-#### Using multiple algorithm to solve multiple problems with multiple trials
-
-## Import libraries
-## For example, we want to solve F5, F10, F29 problem in CEC-2017
-from opfunu.cec_based.cec2017 import F52017, F102017, F292017
-
-from mealpy.bio_based import BBO
-from mealpy.evolutionary_based import DE
-from mealpy.multitask import Multitask          # Remember this
-
-
-## You can define your own problems
-
-f1 = F52017(30, f_bias=0)
-f2 = F102017(30, f_bias=0)
-f3 = F292017(30, f_bias=0)
-
-p1 = {
-    "lb": f1.lb.tolist(),
-    "ub": f1.ub.tolist(),
-    "minmax": "min",
-    "fit_func": f1.evaluate,
-    "name": "F5-CEC2017",
-    "log_to": None,
-}
-
-p2 = {
-    "lb": f2.lb.tolist(),
-    "ub": f2.ub.tolist(),
-    "minmax": "min",
-    "fit_func": f2.evaluate,
-    "name": "F10-CEC2017",
-    "log_to": None,
-}
-
-p3 = {
-    "lb": f3.lb.tolist(),
-    "ub": f3.ub.tolist(),
-    "minmax": "min",
-    "fit_func": f3.evaluate,
-    "name": "F29-CEC2017",
-    "log_to": None,
-}
-
-## Define models
-
-model1 = BBO.BaseBBO(epoch=10, pop_size=50)
-model2 = BBO.OriginalBBO(epoch=10, pop_size=50)
-model3 = DE.BaseDE(epoch=10, pop_size=50)
-
-## Define termination if needed
-term = {
-    "max_fe": 10000
-}
-
-## Define and run Multitask
-if __name__ == "__main__":
-    multitask = Multitask(algorithms=(model1, model2, model3), problems=(p1, p2, p3), terminations=(term, ), modes=("thread", ))
-    # default modes = "single", default termination = epoch (as defined in problem dictionary)
-    multitask.execute(n_trials=5, n_jobs=5, save_path="history", save_as="csv", save_convergence=False, verbose=False)
-    
-    ## Check the directory: history/, you will see list of .csv result files
-```
-
-For more usage examples please look at [examples](/examples) folder.
-
-More advanced examples can also be found in the [Mealpy-examples repository](https://github.com/thieu1995/mealpy_examples).
-
-
-### Get Visualize Figures
-
-
-* [Tutorials](/examples/utils/visualize/all_charts.py)
-
-<p align="center"><img src="https://thieu1995.github.io/post/2022-04/19-mealpy-tutorials/mealpy2.png" alt="MEALPY"/>
-</p>
-
-
-## Mealpy Application
-
-### Mealpy + Neural Network (Replace the Gradient Descent Optimizer)
-
-* Time-series Problem:
-  * Traditional MLP
-    code: [Link](https://github.com/thieu1995/mealpy/tree/master/examples/applications/keras/traditional-mlp-time-series.py)
-  * Hybrid code (Mealpy +
-    MLP): [Link](https://github.com/thieu1995/mealpy/tree/master/examples/applications/keras/mha-hybrid-mlp-time-series.py)
-* Classification Problem:
-  * Traditional MLP
-    code: [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/keras/traditional-mlp-classification.py)
-  * Hybrid code (Mealpy +
-    MLP): [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/keras/mha-hybrid-mlp-classification.py)
-
-### Mealpy + Neural Network (Optimize Neural Network Hyper-parameter)
-
-Code: [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/keras/mha-hyper-parameter-mlp-time-series.py)
-
-### Other Applications
-
-* Solving Knapsack Problem (Discrete
-  problems): [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/discrete-problems/knapsack-problem.py)
-
-* Optimize SVM (SVC)
-  model: [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/sklearn/svm_classification.py)
-
-* Optimize Linear Regression
-  Model: [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/pytorch/linear_regression.py)
-
-* Travelling Salesman Problem: https://github.com/thieu1995/MHA-TSP 
-
-* Feature selection problem: https://github.com/thieu1995/MHA-FS
-
-
-
-## Tutorial Videos
-
-All tutorial videos: [Link](https://mealpy.readthedocs.io/en/latest/pages/general/video_tutorials.html)
-
-All code examples: [Link](https://github.com/thieu1995/mealpy/tree/master/examples)
-
-All visualization examples: [Link](https://mealpy.readthedocs.io/en/latest/pages/visualization.html)
-
-
-
-### Get helps (questions, problems)
-
-* Official source code repo: https://github.com/thieu1995/mealpy
-* Official document: https://mealpy.readthedocs.io/
-* Download releases: https://pypi.org/project/mealpy/
-* Issue tracker: https://github.com/thieu1995/mealpy/issues
-* Notable changes log: https://github.com/thieu1995/mealpy/blob/master/ChangeLog.md
-* Examples with different meapy version: https://github.com/thieu1995/mealpy/blob/master/EXAMPLES.md
-
-* This project also related to our another projects which are "meta-heuristics" and "neural-network", check it here
-    * https://github.com/thieu1995/opfunu
-    * https://github.com/thieu1995/metaheuristics
-    * https://github.com/aiir-team
-
-**Want to have an instant assistant? Join our telegram community at [link](https://t.me/+fRVCJGuGJg1mNDg1)**
-We share lots of information, questions, and answers there. You will get more support and knowledge there.
-
-### Cite Us
-
-If you are using mealpy in your project, we would appreciate citations:
-
-```bibtex 
-@article{van2023mealpy,
-  title={MEALPY: An open-source library for latest meta-heuristic algorithms in Python},
-  author={Van Thieu, Nguyen and Mirjalili, Seyedali},
-  journal={Journal of Systems Architecture},
-  year={2023},
-  publisher={Elsevier}
-}
-
-@article{van2023groundwater,
-  title={Groundwater level modeling using Augmented Artificial Ecosystem Optimization},
-  author={Van Thieu, Nguyen and Barma, Surajit Deb and Van Lam, To and Kisi, Ozgur and Mahesha, Amai},
-  journal={Journal of Hydrology},
-  volume={617},
-  pages={129034},
-  year={2023},
-  publisher={Elsevier}
-}
-```
-
-
-
-# List of papers used MEALPY
-
-- Min, J., Oh, M., Kim, W., Seo, H., & Paek, J. (2022, October). Evaluation of Metaheuristic Algorithms for TAS Scheduling in Time-Sensitive Networking. In 2022 13th International Conference on Information and Communication Technology Convergence (ICTC) (pp. 809-812). IEEE.
-- Khozeimeh, F., Sharifrazi, D., Izadi, N. H., Joloudari, J. H., Shoeibi, A., Alizadehsani, R., ... & Islam, S. M. S. (2021). Combining a convolutional neural network with autoencoders to predict the survival chance of COVID-19 patients. Scientific Reports, 11(1), 15343.
-- Rajesh, K., Jain, E., & Kotecha, P. (2022). A Multi-Objective approach to the Electric Vehicle Routing Problem. arXiv preprint arXiv:2208.12440.
-- SÃ¡nchez, A. J. H., & Upegui, F. R. (2022). Una herramienta para el diseÃ±o de redes MSMN de banda ancha en lÃ­neas de transmisiÃ³n basada en algoritmos heurÃ­sticos de optimizaciÃ³n comparados. Revista IngenierÃ­a UC, 29(2), 106-123.
-- Khanmohammadi, M., Armaghani, D. J., & Sabri Sabri, M. M. (2022). Prediction and Optimization of Pile Bearing Capacity Considering Effects of Time. Mathematics, 10(19), 3563.
-- Kudela, J. (2023). The Evolutionary Computation Methods No One Should Use. arXiv preprint arXiv:2301.01984.
-- Vieira, M., Faia, R., Pinto, T., & Vale, Z. (2022, September). Schedule Peer-to-Peer Transactions of an Energy Community Using Particle Swarm. In 2022 18th International Conference on the European Energy Market (EEM) (pp. 1-6). IEEE.
-- Bui, X. N., Nguyen, H., Le, Q. T., & Le, T. N. Forecasting PM. MINING SCIENCE ANDTECHNOLOGY (Russia), 111.
-- Bui, X. N., Nguyen, H., Le, Q. T., & Le, T. N. (2022). Forecasting PM 2.5 emissions in open-pit minesusing a functional link neural network optimized by various optimization algorithms. Gornye nauki i tekhnologii= Mining Science and Technology (Russia), 7(2), 111-125.
-- DoÄan, E., & YÃ¶rÃ¼keren, N. (2022). Enhancement of Transmission System Security with Archimedes Optimization Algorithm.
-- Ayub, N., Aurangzeb, K., Awais, M., & Ali, U. (2020, November). Electricity theft detection using CNN-GRU and manta ray foraging optimization algorithm. In 2020 IEEE 23Rd international multitopic conference (INMIC) (pp. 1-6). IEEE.
-- Pintilie, L., Nechita, M. T., Suditu, G. D., Dafinescu, V., & DrÄgoi, E. N. (2022). Photo-decolorization of Eriochrome Black T: process optimization with Differential Evolution algorithm. In PASEW-22, MESSH-22 & CABES-22 April 19â21, 2022 Paris (France). Eminent Association of Pioneers.
-- LaTorre, A., Molina, D., Osaba, E., Poyatos, J., Del Ser, J., & Herrera, F. (2021). A prescription of methodological guidelines for comparing bio-inspired optimization algorithms. Swarm and Evolutionary Computation, 67, 100973.
-- Gottam, S., Nanda, S. J., & Maddila, R. K. (2021, December). A CNN-LSTM Model Trained with Grey Wolf Optimizer for Prediction of Household Power Consumption. In 2021 IEEE International Symposium on Smart Electronic Systems (iSES)(Formerly iNiS) (pp. 355-360). IEEE.
-- Darius, P. S., Devadason, J., & Solomon, D. G. (2022, December). Prospects of Ant Colony Optimization (ACO) in Various Domains. In 2022 4th International Conference on Circuits, Control, Communication and Computing (I4C) (pp. 79-84). IEEE.
-- Ayub, N., Irfan, M., Awais, M., Ali, U., Ali, T., Hamdi, M., ... & Muhammad, F. (2020). Big data analytics for short and medium-term electricity load forecasting using an AI techniques ensembler. Energies, 13(19), 5193.
-- Biundini, I. Z., Melo, A. G., Coelho, F. O., HonÃ³rio, L. M., Marcato, A. L., & Pinto, M. F. (2022). Experimentation and Simulation with Autonomous Coverage Path Planning for UAVs. Journal of Intelligent & Robotic Systems, 105(2), 46.
-- Yousaf, I., Anwar, F., Imtiaz, S., Almadhor, A. S., Ishmanov, F., & Kim, S. W. (2022). An Optimized Hyperparameter of Convolutional Neural Network Algorithm for Bug Severity Prediction in Alzheimerâs-Based IoT System. Computational Intelligence and Neuroscience, 2022.
-- Xu, L., Yan, W., & Ji, J. (2023). The research of a novel WOG-YOLO algorithm for autonomous driving object detection. Scientific reports, 13(1), 3699.
-- Costache, R. D., Arabameri, A., Islam, A. R. M. T., Abba, S. I., Pandey, M., Ajin, R. S., & Pham, B. T. (2022). Flood susceptibility computation using state-of-the-art machine learning and optimization algorithms.
-- Del Ser, J., Osaba, E., Martinez, A. D., Bilbao, M. N., Poyatos, J., Molina, D., & Herrera, F. (2021, December). More is not always better: insights from a massive comparison of meta-heuristic algorithms over real-parameter optimization problems. In 2021 IEEE Symposium Series on Computational Intelligence (SSCI) (pp. 1-7). IEEE.
-- Rustam, F., Aslam, N., De La Torre DÃ­ez, I., Khan, Y. D., MazÃ³n, J. L. V., RodrÃ­guez, C. L., & Ashraf, I. (2022, November). White Blood Cell Classification Using Texture and RGB Features of Oversampled Microscopic Images. In Healthcare (Vol. 10, No. 11, p. 2230). MDPI.
-- Neupane, D., Kafle, S., Gurung, S., Neupane, S., & Bhattarai, N. (2021). Optimal sizing and financial analysis of a stand-alone SPV-micro-hydropower hybrid system considering generation uncertainty. International Journal of Low-Carbon Technologies, 16(4), 1479-1491.
-- Liang, R., Le-Hung, T., & Nguyen-Thoi, T. (2022). Energy consumption prediction of air-conditioning systems in eco-buildings using hunger games search optimization-based artificial neural network model. Journal of Building Engineering, 59, 105087.
-- He, Z., Nguyen, H., Vu, T. H., Zhou, J., Asteris, P. G., & Mammou, A. (2022). Novel integrated approaches for predicting the compressibility of clay using cascade forward neural networks optimized by swarm-and evolution-based algorithms. Acta Geotechnica, 1-16.
-- Xu, L., Yan, W., & Ji, J. (2022). The research of a novel WOG-YOLO algorithm forautonomous driving object detection.
-- Nasir Ayub, M. I., Awais, M., Ali, U., Ali, T., Hamdi, M., Alghamdi, A., & Muhammad, F. Big Data Analytics for Short and Medium Term Electricity Load Forecasting using AI Techniques Ensembler.
-- Xie, C., Nguyen, H., Choi, Y., & Armaghani, D. J. (2022). Optimized functional linked neural network for predicting diaphragm wall deflection induced by braced excavations in clays. Geoscience Frontiers, 13(2), 101313.
-- Hakemi, S., Houshmand, M., & Hosseini, S. A. (2022). A Dynamic Quantum-Inspired Genetic Algorithm with Lengthening Chromosome Size.
-- Kashifi, M. T. City-Wide Crash Risk Prediction and Interpretation Using Deep Learning Model with Multi-Source Big Data. Available at SSRN 4329686.
-- Nguyen, H., & Hoang, N. D. (2022). Computer vision-based classification of concrete spall severity using metaheuristic-optimized Extreme Gradient Boosting Machine and Deep Convolutional Neural Network. Automation in Construction, 140, 104371.
-- Zheng, J., Lu, Z., Wu, K., Ning, G. H., & Li, D. (2020). Coinage-metal-based cyclic trinuclear complexes with metalâmetal interactions: Theories to experiments and structures to functions. Chemical Reviews, 120(17), 9675-9742.
-- Van Thieu, N., Barma, S. D., Van Lam, T., Kisi, O., & Mahesha, A. (2023). Groundwater level modeling using Augmented Artificial Ecosystem Optimization. Journal of Hydrology, 617, 129034.
-- Mo, Z., Zhang, Z., Miao, Q., & Tsui, K. L. (2022). Intelligent Informative Frequency Band Searching Assisted by a Dynamic Bandit Tree Method for Machine Fault Diagnosis. IEEE/ASME Transactions on Mechatronics.
-- Dangi, D., Chandel, S. T., Dixit, D. K., Sharma, S., & Bhagat, A. (2023). An Efficient Model for Sentiment Analysis using Artificial Rabbits Optimized Vector Functional Link Network. Expert Systems with Applications, 119849.
-- Dey, S., Roychoudhury, R., Malakar, S., & Sarkar, R. (2022). An optimized fuzzy ensemble of convolutional neural networks for detecting tuberculosis from Chest X-ray images. Applied Soft Computing, 114, 108094.
-- Mousavirad, S. J., & Alexandre, L. A. (2022). Population-based JPEG Image Compression: Problem Re-Formulation. arXiv preprint arXiv:2212.06313.
-- Tsui, K. L. Intelligent Informative Frequency Band Searching Assisted by A Dynamic Bandit Tree Method for Machine Fault Diagnosis.
-- Neupane, D. (2020). Optimal Sizing and Performance Analysis of Solar PV-Micro hydropower Hybrid System in the Context of Rural Area of Nepal (Doctoral dissertation, Pulchowk Campus).
-- LaTorre, A., Molina, D., Osaba, E., Poyatos, J., Del Ser, J., & Herrera, F. Swarm and Evolutionary Computation.
-- Vieira, M. A. (2022). OtimizaÃ§Ã£o dos custos operacionais de uma comunidade energÃ©tica considerando transaÃ§Ãµes locais em âpeer-to-peerâ (Doctoral dissertation).
-- ToÄaÃ§ar, M. (2022). Using DarkNet models and metaheuristic optimization methods together to detect weeds growing along with seedlings. Ecological Informatics, 68, 101519.
-- ToÄaÃ§ar, M. (2021). Detection of segmented uterine cancer images by Hotspot Detection method using deep learning models, Pigeon-Inspired Optimization, types-based dominant activation selection approaches. Computers in Biology and Medicine, 136, 104659.
-- Khan, N. A Short Term Electricity Load and Price Forecasting Model Based on BAT Algorithm in Logistic Regression and CNN-GRU with WOA.
-- Yelisetti, S., Saini, V. K., Kumar, R., & Lamba, R. (2022, May). Energy Consumption Cost Benefits through Smart Home Energy Management in Residential Buildings: An Indian Case Study. In 2022 IEEE IAS Global Conference on Emerging Technologies (GlobConET) (pp. 930-935). IEEE.
-- Nguyen, H., Cao, M. T., Tran, X. L., Tran, T. H., & Hoang, N. D. (2022). A novel whale optimization algorithm optimized XGBoost regression for estimating bearing capacity of concrete piles. Neural Computing and Applications, 1-28.
-- Hirsching, C., de Jongh, S., Eser, D., Suriyah, M., & Leibfried, T. (2022). Meta-heuristic optimization of control structure and design for MMC-HVdc applications. Electric Power Systems Research, 213, 108371.
-- Amelin, V., Gatiyatullin, E., Romanov, N., Samarkhanov, R., Vasilyev, R., & Yanovich, Y. (2022). Black-Box for Blockchain Parameters Adjustment. IEEE Access, 10, 101795-101802.
-- Ngo, T. Q., Nguyen, L. Q., & Tran, V. Q. (2022). Novel hybrid machine learning models including support vector machine with meta-heuristic algorithms in predicting unconfined compressive strength of organic soils stabilised with cement and lime. International Journal of Pavement Engineering, 1-18.
-- Zhu, Y., & Iiduka, H. (2021). Unified Algorithm Framework for Nonconvex Stochastic Optimization in Deep Neural Networks. IEEE Access, 9, 143807-143823.
-- Hakemi, S., Houshmand, M., KheirKhah, E., & Hosseini, S. A. (2022). A review of recent advances in quantum-inspired metaheuristics. Evolutionary Intelligence, 1-16.
-- Das, A., Das, S. R., Panda, J. P., Dey, A., Gajrani, K. K., Somani, N., & Gupta, N. (2022). Machine learning based modelling and optimization in hard turning of AISI D6 steel with newly developed AlTiSiN coated carbide tool. arXiv preprint arXiv:2202.00596.
-- Yelisetti, S., Saini, V. K., Kumar, R., Lamba, R., & Saxena, A. (2022). Optimal energy management system for residential buildings considering the time of use price with swarm intelligence algorithms. Journal of Building Engineering, 59, 105062.
-- ValdÃ©s, G. T. (2022). Algoritmo para la detecciÃ³n de vehÃ­culos y peatones combinando CNNÂ´ sy tÃ©cnicas de bÃºsqueda.
-- Sallam, N. M., Saleh, A. I., Ali, H. A., & Abdelsalam, M. M. (2023). An efficient EGWO algorithm as feature selection for B-ALL diagnoses and its subtypes classification using peripheral blood smear images. Alexandria Engineering Journal, 68, 39-66.
-
-
-
-
-# Documents
-
-* Meta-heuristic Categories: (Based on this article: [link](https://doi.org/10.1016/j.procs.2020.09.075))
-    + Evolutionary-based: Idea from Darwin's law of natural selection, evolutionary computing 
-    + Swarm-based: Idea from movement, interaction of birds, organization of social ...
-    + Physics-based: Idea from physics law such as Newton's law of universal gravitation, black hole, multiverse 
-    + Human-based: Idea from human interaction such as queuing search, teaching learning, ... 
-    + Biology-based: Idea from biology creature (or microorganism),...
-    + System-based: Idea from eco-system, immune-system, network-system, ...
-    + Math-based: Idea from mathematical form or mathematical law such as sin-cosin 
-    + Music-based: Idea from music instrument
-
-* Difficulty - Difficulty Level (Personal Opinion): **Objective observation from author**. Depend on the number of 
-  parameters, number of equations, the original ideas, time spend for coding, source lines of code (SLOC).
-    + Easy: A few paras, few equations, SLOC very short
-    + Medium: more equations than Easy level, SLOC longer than Easy level
-    + Hard: Lots of equations, SLOC longer than Medium level, the paper hard to read.
-    + Hard* - Very hard: Lots of equations, SLOC too long, the paper is very hard to read.
-    
-** For newbie, we recommend to read the paper of algorithms which difficulty is "easy" or "medium" difficulty level.
-
-
-| **Group**    | **Name**                                        | **Module** | **Class**        | **Year** | **Paras** | **Difficulty** |
-|--------------|-------------------------------------------------|------------|------------------|----------|-----------|----------------|
-| Evolutionary | Evolutionary Programming                        | EP         | OriginalEP       | 1964     | 3         | easy           |
-| Evolutionary | -                                               | -          | LevyEP           | -        | 3         | easy           |
-| Evolutionary | Evolution Strategies                            | ES         | OriginalES       | 1971     | 3         | easy           |
-| Evolutionary | -                                               | -          | LevyES           | -        | 3         | easy           |
-| Evolutionary | Memetic Algorithm                               | MA         | OriginalMA       | 1989     | 7         | easy           |
-| Evolutionary | Genetic Algorithm                               | GA         | BaseGA           | 1992     | 4         | easy           |
-| Evolutionary | -                                               | -          | SingleGA         | -        | 7         | easy           |
-| Evolutionary | -                                               | -          | MultiGA          | -        | 7         | easy           |
-| Evolutionary | -                                               | -          | EliteSingleGA    | -        | 10        | easy           |
-| Evolutionary | -                                               | -          | EliteMultiGA     | -        | 10        | easy           |
-| Evolutionary | Differential Evolution                          | DE         | BaseDE           | 1997     | 5         | easy           |
-| Evolutionary | -                                               | -          | JADE             | 2009     | 6         | medium         |
-| Evolutionary | -                                               | -          | SADE             | 2005     | 2         | medium         |
-| Evolutionary | -                                               | -          | SHADE            | 2013     | 4         | medium         |
-| Evolutionary | -                                               | -          | L_SHADE          | 2014     | 4         | medium         |
-| Evolutionary | -                                               | -          | SAP_DE           | 2006     | 3         | medium         |
-| Evolutionary | Flower Pollination Algorithm                    | FPA        | OriginalFPA      | 2014     | 4         | medium         |
-| Evolutionary | Coral Reefs Optimization                        | CRO        | OriginalCRO      | 2014     | 11        | medium         |
-| Evolutionary | -                                               | -          | OCRO             | 2019     | 12        | medium         |
-| -            | -                                               | -          | -                | -        | -         | -              |
-| Swarm        | Particle Swarm Optimization                     | PSO        | OriginalPSO      | 1995     | 6         | easy           |
-| Swarm        | -                                               | -          | PPSO             | 2019     | 2         | medium         |
-| Swarm        | -                                               | -          | HPSO_TVAC        | 2017     | 4         | medium         |
-| Swarm        | -                                               | -          | C_PSO            | 2015     | 6         | medium         |
-| Swarm        | -                                               | -          | CL_PSO           | 2006     | 6         | medium         |
-| Swarm        | Bacterial Foraging Optimization                 | BFO        | OriginalBFO      | 2002     | 10        | hard           |
-| Swarm        | -                                               | -          | ABFO             | 2019     | 8         | medium         |
-| Swarm        | Bees Algorithm                                  | BeesA      | OriginalBeesA    | 2005     | 8         | medium         |
-| Swarm        | -                                               | -          | ProbBeesA        | 2015     | 5         | medium         |
-| Swarm        | Cat Swarm Optimization                          | CSO        | OriginalCSO      | 2006     | 11        | hard           |
-| Swarm        | Artificial Bee Colony                           | ABC        | OriginalABC      | 2007     | 8         | medium         |
-| Swarm        | Ant Colony Optimization                         | ACO-R      | OriginalACOR     | 2008     | 5         | easy           |
-| Swarm        | Cuckoo Search Algorithm                         | CSA        | OriginalCSA      | 2009     | 3         | medium         |
-| Swarm        | Firefly Algorithm                               | FFA        | OriginalFFA      | 2009     | 8         | easy           |
-| Swarm        | Fireworks Algorithm                             | FA         | OriginalFA       | 2010     | 7         | medium         |
-| Swarm        | Bat Algorithm                                   | BA         | OriginalBA       | 2010     | 6         | medium         |
-| Swarm        | -                                               | -          | AdaptiveBA       | -        | 8         | medium         |
-| Swarm        | -                                               | -          | ModifiedBA       | -        | 5         | medium         |
-| Swarm        | Fruit-fly Optimization Algorithm                | FOA        | OriginalFOA      | 2012     | 2         | easy           |
-| Swarm        | -                                               | -          | BaseFOA          | -        | 2         | easy           |
-| Swarm        | -                                               | -          | WhaleFOA         | 2020     | 2         | medium         |
-| Swarm        | Social Spider Optimization                      | SSpiderO   | OriginalSSpiderO | 2018     | 4         | hard*          |
-| Swarm        | Grey Wolf Optimizer                             | GWO        | OriginalGWO      | 2014     | 2         | easy           |
-| Swarm        | -                                               | -          | RW_GWO           | 2019     | 2         | easy           |
-| Swarm        | Social Spider Algorithm                         | SSpiderA   | OriginalSSpiderA | 2015     | 5         | medium         |
-| Swarm        | Ant Lion Optimizer                              | ALO        | OriginalALO      | 2015     | 2         | easy           |
-| Swarm        | -                                               | -          | BaseALO          | -        | 2         | easy           |
-| Swarm        | Moth Flame Optimization                         | MFO        | OriginalMFO      | 2015     | 2         | easy           |
-| Swarm        | -                                               | -          | BaseMFO          | -        | 2         | easy           |
-| Swarm        | Elephant Herding Optimization                   | EHO        | OriginalEHO      | 2015     | 5         | easy           |
-| Swarm        | Jaya Algorithm                                  | JA         | OriginalJA       | 2016     | 2         | easy           |
-| Swarm        | -                                               | -          | BaseJA           | -        | 2         | easy           |
-| Swarm        | -                                               | -          | LevyJA           | 2021     | 2         | easy           |
-| Swarm        | Whale Optimization Algorithm                    | WOA        | OriginalWOA      | 2016     | 2         | medium         |
-| Swarm        | -                                               | -          | HI_WOA           | 2019     | 3         | medium         |
-| Swarm        | Dragonfly Optimization                          | DO         | OriginalDO       | 2016     | 2         | medium         |
-| Swarm        | Bird Swarm Algorithm                            | BSA        | OriginalBSA      | 2016     | 9         | medium         |
-| Swarm        | Spotted Hyena Optimizer                         | SHO        | OriginalSHO      | 2017     | 4         | medium         |
-| Swarm        | Salp Swarm Optimization                         | SSO        | OriginalSSO      | 2017     | 2         | easy           |
-| Swarm        | Swarm Robotics Search And Rescue                | SRSR       | OriginalSRSR     | 2017     | 2         | hard*          |
-| Swarm        | Grasshopper Optimisation Algorithm              | GOA        | OriginalGOA      | 2017     | 4         | easy           |
-| Swarm        | Coyote Optimization Algorithm                   | COA        | OriginalCOA      | 2018     | 3         | medium         |
-| Swarm        | Moth Search Algorithm                           | MSA        | OriginalMSA      | 2018     | 5         | easy           |
-| Swarm        | Sea Lion Optimization                           | SLO        | OriginalSLO      | 2019     | 2         | medium         |
-| Swarm        | -                                               | -          | ModifiedSLO      | -        | 2         | medium         |
-| Swarm        | -                                               | -          | ImprovedSLO      | -        | 4         | medium         |
-| Swarm        | Nake Mole-Rat Algorithm                         | NMRA       | OriginalNMRA     | 2019     | 3         | easy           |
-| Swarm        | -                                               | -          | ImprovedNMRA     | -        | 4         | medium         |
-| Swarm        | Pathfinder Algorithm                            | PFA        | OriginalPFA      | 2019     | 2         | medium         |
-| Swarm        | Sailfish Optimizer                              | SFO        | OriginalSFO      | 2019     | 5         | easy           |
-| Swarm        | -                                               | -          | ImprovedSFO      | -        | 3         | medium         |
-| Swarm        | Harris Hawks Optimization                       | HHO        | OriginalHHO      | 2019     | 2         | medium         |
-| Swarm        | Manta Ray Foraging Optimization                 | MRFO       | OriginalMRFO     | 2020     | 3         | medium         |
-| Swarm        | Bald Eagle Search                               | BES        | OriginalBES      | 2020     | 7         | easy           |
-| Swarm        | Sparrow Search Algorithm                        | SSA        | OriginalSSA      | 2020     | 5         | medium         |
-| Swarm        | -                                               | -          | BaseSSA          | -        | 5         | medium         |
-| Swarm        | Hunger Games Search                             | HGS        | OriginalHGS      | 2021     | 4         | medium         |
-| Swarm        | Aquila Optimizer                                | AO         | OriginalAO       | 2021     | 2         | easy           |
-| Swarm        | Hybrid Grey Wolf - Whale Optimization Algorithm | GWO        | GWO_WOA          | 2022     | 2         | easy           |
-| Swarm        | Marine Predators Algorithm                      | MPA        | OriginalMPA      | 2020     | 2         | medium         |
-| Swarm        | Honey Badger Algorithm                          | HBA        | OriginalHBA      | 2022     | 2         | easy           |
-| Swarm        | Sand Cat Swarm Optimization                     | SCSO       | OriginalSCSO     | 2022     | 2         | easy           |
-| Swarm        | Tuna Swarm Optimization                         | TSO        | OriginalTSO      | 2021     | 2         | medium         |
-| Swarm        | African Vultures Optimization Algorithm         | AVOA       | OriginalAVOA     | 2022     | 7         | medium         |
-| Swarm        | Artificial Gorilla Troops Optimization          | AGTO       | OriginalAGTO     | 2021     | 5         | medium         |
-| Swarm        | Artificial Rabbits Optimization                 | ARO        | OriginalARO      | 2022     | 2         | easy           |
-| Swarm        | Dwarf Mongoose Optimization Algorithm           | DMOA       | OriginalDMOA     | 2022     | 4         | medium         |
-| Swarm        | -                                               | -          | DevDMOA          | -        | 3         | medium         |
-| -            | -                                               | -          | -                | -        | -         | -              |
-| Physics      | Simulated Annealling                            | SA         | OriginalSA       | 1987     | 9         | medium         |
-| Physics      | Wind Driven Optimization                        | WDO        | OriginalWDO      | 2013     | 7         | easy           |
-| Physics      | Multi-Verse Optimizer                           | MVO        | OriginalMVO      | 2016     | 4         | easy           |
-| Physics      | -                                               | -          | BaseMVO          | -        | 4         | easy           |
-| Physics      | Tug of War Optimization                         | TWO        | OriginalTWO      | 2016     | 2         | easy           |
-| Physics      | -                                               | -          | OppoTWO          | -        | 2         | medium         |
-| Physics      | -                                               | -          | LevyTWO          | -        | 2         | medium         |
-| Physics      | -                                               | -          | EnhancedTWO      | 2020     | 2         | medium         |
-| Physics      | Electromagnetic Field Optimization              | EFO        | OriginalEFO      | 2016     | 6         | easy           |
-| Physics      | -                                               | -          | BaseEFO          | -        | 6         | medium         |
-| Physics      | Nuclear Reaction Optimization                   | NRO        | OriginalNRO      | 2019     | 2         | hard*          |
-| Physics      | Henry Gas Solubility Optimization               | HGSO       | OriginalHGSO     | 2019     | 3         | medium         |
-| Physics      | Atom Search Optimization                        | ASO        | OriginalASO      | 2019     | 4         | medium         |
-| Physics      | Equilibrium Optimizer                           | EO         | OriginalEO       | 2019     | 2         | easy           |
-| Physics      | -                                               | -          | ModifiedEO       | 2020     | 2         | medium         |
-| Physics      | -                                               | -          | AdaptiveEO       | 2020     | 2         | medium         |
-| Physics      | Archimedes Optimization Algorithm               | ArchOA     | OriginalArchOA   | 2021     | 8         | medium         |
-| -            | -                                               | -          | -                | -        | -         | -              |
-| Human        | Culture Algorithm                               | CA         | OriginalCA       | 1994     | 3         | easy           |
-| Human        | Imperialist Competitive Algorithm               | ICA        | OriginalICA      | 2007     | 8         | hard*          |
-| Human        | Teaching Learning-based Optimization            | TLO        | OriginalTLO      | 2011     | 2         | easy           |
-| Human        | -                                               | -          | BaseTLO          | 2012     | 2         | easy           |
-| Human        | -                                               | -          | ITLO             | 2013     | 3         | medium         |
-| Human        | Brain Storm Optimization                        | BSO        | OriginalBSO      | 2011     | 8         | medium         |
-| Human        | -                                               | -          | ImprovedBSO      | 2017     | 7         | medium         |
-| Human        | Queuing Search Algorithm                        | QSA        | OriginalQSA      | 2019     | 2         | hard           |
-| Human        | -                                               | -          | BaseQSA          | -        | 2         | hard           |
-| Human        | -                                               | -          | OppoQSA          | -        | 2         | hard           |
-| Human        | -                                               | -          | LevyQSA          | -        | 2         | hard           |
-| Human        | -                                               | -          | ImprovedQSA      | 2021     | 2         | hard           |
-| Human        | Search And Rescue Optimization                  | SARO       | OriginalSARO     | 2019     | 4         | medium         |
-| Human        | -                                               | -          | BaseSARO         | -        | 4         | medium         |
-| Human        | Life Choice-Based Optimization                  | LCO        | OriginalLCO      | 2019     | 3         | easy           |
-| Human        | -                                               | -          | BaseLCO          | -        | 3         | easy           |
-| Human        | -                                               | -          | ImprovedLCO      | -        | 2         | easy           |
-| Human        | Social Ski-Driver Optimization                  | SSDO       | OriginalSSDO     | 2019     | 2         | easy           |
-| Human        | Gaining Sharing Knowledge-based Algorithm       | GSKA       | OriginalGSKA     | 2019     | 6         | medium         |
-| Human        | -                                               | -          | BaseGSKA         | -        | 4         | medium         |
-| Human        | Coronavirus Herd Immunity Optimization          | CHIO       | OriginalCHIO     | 2020     | 4         | medium         |
-| Human        | -                                               | -          | BaseCHIO         | -        | 4         | medium         |
-| Human        | Forensic-Based Investigation Optimization       | FBIO       | OriginalFBIO     | 2020     | 2         | medium         |
-| Human        | -                                               | -          | BaseFBIO         | -        | 2         | medium         |
-| Human        | Battle Royale Optimization                      | BRO        | OriginalBRO      | 2020     | 3         | medium         |
-| Human        | -                                               | -          | BaseBRO          | -        | 3         | medium         |
-| Human        | Student Psychology Based Optimization           | SPBO       | OriginalSPBO     | 2020     | 2         | medium         |
-| Human        | -                                               | -          | DevSPBO          |          | 2         | medium         |
-| -            | -                                               | -          | -                | -        | -         | -              |
-| Bio          | Invasive Weed Optimization                      | IWO        | OriginalIWO      | 2006     | 7         | easy           |
-| Bio          | Biogeography-Based Optimization                 | BBO        | OriginalBBO      | 2008     | 4         | easy           |
-| Bio          | -                                               | -          | BaseBBO          | -        | 4         | easy           |
-| Bio          | Virus Colony Search                             | VCS        | OriginalVCS      | 2016     | 4         | hard*          |
-| Bio          | -                                               | -          | BaseVCS          | -        | 4         | hard*          |
-| Bio          | Satin Bowerbird Optimizer                       | SBO        | OriginalSBO      | 2017     | 5         | easy           |
-| Bio          | -                                               | -          | BaseSBO          | -        | 5         | easy           |
-| Bio          | Earthworm Optimisation Algorithm                | EOA        | OriginalEOA      | 2018     | 8         | medium         |
-| Bio          | Wildebeest Herd Optimization                    | WHO        | OriginalWHO      | 2019     | 12        | hard           |
-| Bio          | Slime Mould Algorithm                           | SMA        | OriginalSMA      | 2020     | 3         | easy           |
-| Bio          | -                                               | -          | BaseSMA          | -        | 3         | easy           |
-| Bio          | Barnacles Mating Optimizer                      | BMO        | OriginalBMO      | 2018     | 3         | easy           |
-| Bio          | Tunicate Swarm Algorithm                        | TSA        | OriginalTSA      | 2020     | 2         | easy           |
-| Bio          | Symbiotic Organisms Search                      | SOS        | OriginalSOS      | 2014     | 2         | medium         |
-| Bio          | Seagull Optimization Algorithm                  | SOA        | OriginalSOA      | 2019     | 3         | easy           |
-| Bio          | -                                               | -          | DevSOA           | -        | 3         | easy           |
-| -            | -                                               | -          | -                | -        | -         | -              |
-| System       | Germinal Center Optimization                    | GCO        | OriginalGCO      | 2018     | 4         | medium         |
-| System       | -                                               | -          | BaseGCO          | -        | 4         | medium         |
-| System       | Water Cycle Algorithm                           | WCA        | OriginalWCA      | 2012     | 5         | medium         |
-| System       | Artificial Ecosystem-based Optimization         | AEO        | OriginalAEO      | 2019     | 2         | easy           |
-| System       | -                                               | -          | EnhancedAEO      | 2020     | 2         | medium         |
-| System       | -                                               | -          | ModifiedAEO      | 2020     | 2         | medium         |
-| System       | -                                               | -          | ImprovedAEO      | 2021     | 2         | medium         |
-| System       | -                                               | -          | AugmentedAEO     | 2022     | 2         | medium         |
-| -            | -                                               | -          | -                | -        | -         | -              |
-| Math         | Hill Climbing                                   | HC         | OriginalHC       | 1993     | 3         | easy           |
-| Math         | -                                               | -          | SwarmHC          | -        | 3         | easy           |
-| Math         | Cross-Entropy Method                            | CEM        | OriginalCEM      | 1997     | 4         | easy           |
-| Math         | Sine Cosine Algorithm                           | SCA        | OriginalSCA      | 2016     | 2         | easy           |
-| Math         | -                                               | -          | BaseSCA          | -        | 2         | easy           |
-| Math         | Gradient-Based Optimizer                        | GBO        | OriginalGBO      | 2020     | 5         | medium         |
-| Math         | Arithmetic Optimization Algorithm               | AOA        | OrginalAOA       | 2021     | 6         | easy           |
-| Math         | Chaos Game Optimization                         | CGO        | OriginalCGO      | 2021     | 2         | easy           |
-| Math         | Pareto-like Sequential Sampling                 | PSS        | OriginalPSS      | 2021     | 4         | medium         |
-| Math         | weIghted meaN oF vectOrs                        | INFO       | OriginalINFO     | 2022     | 2         | medium         |
-| Math         | RUNge Kutta optimizer                           | RUN        | OriginalRUN      | 2021     | 2         | hard           |
-| Math         | Circle Search Algorithm                         | CircleSA   | OriginalCircleSA | 2022     | 3         | easy           |
-| -            | -                                               | -          | -                | -        | -         | -              |
-| Music        | Harmony Search                                  | HS         | OriginalHS       | 2001     | 4         | easy           |
-| Music        | -                                               | -          | BaseHS           | -        | 4         | easy           |
-
-
-
-
-
-### A
-
-* **ABC - Artificial Bee Colony**
-  * **OriginalABC**: Karaboga, D. (2005). An idea based on honey bee swarm for numerical optimization (Vol. 200, pp. 1-10). Technical report-tr06, Erciyes university, engineering faculty, computer engineering department.
-
-* **ACOR - Ant Colony Optimization**. 
-  * **OriginalACOR**: Socha, K., & Dorigo, M. (2008). Ant colony optimization for continuous domains. European journal of operational research, 185(3), 1155-1173.
-
-* **ALO - Ant Lion Optimizer** 
-  * **OriginalALO**: Mirjalili S (2015). âThe Ant Lion Optimizer.â Advances in Engineering Software, 83, 80-98. doi: [10.1016/j.advengsoft.2015.01.010](https://doi.org/10.1016/j.advengsoft.2015.01.010)
-  * **BaseALO**: The developed version
-
-* **AEO - Artificial Ecosystem-based Optimization** 
-  * **OriginalAEO**: Zhao, W., Wang, L., & Zhang, Z. (2019). Artificial ecosystem-based optimization: a novel nature-inspired meta-heuristic algorithm. Neural Computing and Applications, 1-43.
-  * **AugmentedAEO**: Van Thieu, N., Barma, S. D., Van Lam, T., Kisi, O., & Mahesha, A. (2022). Groundwater level modeling using Augmented Artificial Ecosystem Optimization. Journal of Hydrology, 129034.
-  * **ImprovedAEO**: Rizk-Allah, R. M., & El-Fergany, A. A. (2020). Artificial ecosystem optimizer for parameters identification of proton exchange membrane fuel cells model. International Journal of Hydrogen Energy.
-  * **EnhancedAEO**: Eid, A., Kamel, S., Korashy, A., & Khurshaid, T. (2020). An Enhanced Artificial Ecosystem-Based Optimization for Optimal Allocation of Multiple Distributed Generations. IEEE Access, 8, 178493-178513.
-  * **ModifiedAEO**: Menesy, A. S., Sultan, H. M., Korashy, A., Banakhr, F. A., Ashmawy, M. G., & Kamel, S. (2020). Effective parameter extraction of different polymer electrolyte membrane fuel cell stack models using a modified artificial ecosystem optimization algorithm. IEEE Access, 8, 31892-31909.
-  
-* **ASO - Atom Search Optimization**   
-  * **OriginalASO**: Zhao, W., Wang, L., & Zhang, Z. (2019). Atom search optimization and its application to solve a hydrogeologic parameter estimation problem. Knowledge-Based Systems, 163, 283-304.
-
-* **ArchOA - Archimedes Optimization Algorithm**
-  * **OriginalArchOA**: Hashim, F. A., Hussain, K., Houssein, E. H., Mabrouk, M. S., & Al-Atabany, W. (2021). Archimedes optimization algorithm: a new metaheuristic algorithm for solving optimization problems. Applied Intelligence, 51(3), 1531-1551.
-
-* **AOA - Arithmetic Optimization Algorithm**
-  * **OriginalAOA**: Abualigah, L., Diabat, A., Mirjalili, S., Abd Elaziz, M., & Gandomi, A. H. (2021). The arithmetic optimization algorithm. Computer methods in applied mechanics and engineering, 376, 113609.
-
-* **AO - Aquila Optimizer**
-  * **OriginalAO**: Abualigah, L., Yousri, D., Abd Elaziz, M., Ewees, A. A., Al-qaness, M. A., & Gandomi, A. H. (2021). Aquila Optimizer: A novel meta-heuristic optimization Algorithm. Computers & Industrial Engineering, 157, 107250.
-
-* **AVOA - African Vultures Optimization Algorithm**
-  * **OriginalAVOA**: Abdollahzadeh, B., Gharehchopogh, F. S., & Mirjalili, S. (2021). African vultures optimization algorithm: A new nature-inspired metaheuristic algorithm for global optimization problems. Computers & Industrial Engineering, 158, 107408.
-
-* **AGTO - Artificial Gorilla Troops Optimization**
-  * **OriginalAGTO**: Abdollahzadeh, B., Soleimanian Gharehchopogh, F., & Mirjalili, S. (2021). Artificial gorilla troops optimizer: a new natureâinspired metaheuristic algorithm for global optimization problems. International Journal of Intelligent Systems, 36(10), 5887-5958.
-
-* **ARO - Artificial Rabbits Optimization**:
-  * **OriginalARO**: Wang, L., Cao, Q., Zhang, Z., Mirjalili, S., & Zhao, W. (2022). Artificial rabbits optimization: A new bio-inspired meta-heuristic algorithm for solving engineering optimization problems. Engineering Applications of Artificial Intelligence, 114, 105082.
-
-
-
-### B
-
-
-* **BFO - Bacterial Foraging Optimization** 
-  * **OriginalBFO**: Passino, K. M. (2002). Biomimicry of bacterial foraging for distributed optimization and control. IEEE control systems magazine, 22(3), 52-67.
-  * **ABFO**: Nguyen, T., Nguyen, B. M., & Nguyen, G. (2019, April). Building resource auto-scaler with functional-link neural network and adaptive bacterial foraging optimization. In International Conference on Theory and Applications of Models of Computation (pp. 501-517). Springer, Cham.
-
-* **BeesA - Bees Algorithm** 
-  * **OriginalBeesA**: Pham, D. T., Ghanbarzadeh, A., Koc, E., Otri, S., Rahim, S., & Zaidi, M. (2005). The bees algorithm. Technical Note, Manufacturing Engineering Centre, Cardiff University, UK.
-  * **ProbBeesA**: The probabilitic version of: Pham, D. T., Ghanbarzadeh, A., KoÃ§, E., Otri, S., Rahim, S., & Zaidi, M. (2006). The bees algorithmâa novel tool for complex optimisation problems. In Intelligent production machines and systems (pp. 454-459). Elsevier Science Ltd.
-  
-* **BBO - Biogeography-Based Optimization** 
-  * **OriginalBBO**: Simon, D. (2008). Biogeography-based optimization. IEEE transactions on evolutionary computation, 12(6), 702-713.
-  * **BaseBBO**: The developed version
-  
-* **BA - Bat Algorithm** 
-  * **OriginalBA**: Yang, X. S. (2010). A new metaheuristic bat-inspired algorithm. In Nature inspired cooperative strategies for optimization (NICSO 2010) (pp. 65-74). Springer, Berlin, Heidelberg.
-  * **AdaptiveBA**: Wang, X., Wang, W. and Wang, Y., 2013, July. An adaptive bat algorithm. In International Conference on Intelligent Computing(pp. 216-223). Springer, Berlin, Heidelberg.
-  * **ModifiedBA**: Dong, H., Li, T., Ding, R. and Sun, J., 2018. A novel hybrid genetic algorithm with granular information for feature selection and optimization. Applied Soft Computing, 65, pp.33-46.
-
-* **BSO - Brain Storm Optimization** 
-  * **OriginalBSO**: . Shi, Y. (2011, June). Brain storm optimization algorithm. In International conference in swarm intelligence (pp. 303-309). Springer, Berlin, Heidelberg.
-  * **ImprovedBSO**: El-Abd, M., 2017. Global-best brain storm optimization algorithm. Swarm and evolutionary computation, 37, pp.27-44.
-
-* **BSA - Bird Swarm Algorithm** 
-  * **OriginalBSA**: Meng, X. B., Gao, X. Z., Lu, L., Liu, Y., & Zhang, H. (2016). A new bio-inspired optimisation algorithm:Bird Swarm Algorithm. Journal of Experimental & Theoretical Artificial Intelligence, 28(4), 673-687.
-
-* **BMO - Barnacles Mating Optimizer**:
-  * **OriginalBMO**: Sulaiman, M. H., Mustaffa, Z., Saari, M. M., Daniyal, H., Daud, M. R., Razali, S., & Mohamed, A. I. (2018, June). Barnacles mating optimizer: a bio-inspired algorithm for solving optimization problems. In 2018 19th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD) (pp. 265-270). IEEE.
-
-* **BES - Bald Eagle Search** 
-  * **OriginalBES**: Alsattar, H. A., Zaidan, A. A., & Zaidan, B. B. (2019). Novel meta-heuristic bald eagle search optimisation algorithm. Artificial Intelligence Review, 1-28.
-  
-* **BRO - Battle Royale Optimization**
-  * **OriginalBRO**: Rahkar Farshi, T. (2020). Battle royale optimization algorithm. Neural Computing and Applications, 1-19.
-  * **BaseBRO**: The developed version
-
-### C
-
-* **CA - Culture Algorithm** 
-  * **OriginalCA**: Reynolds, R.G., 1994, February. An introduction to cultural algorithms. In Proceedings of the third annual conference on evolutionary programming (Vol. 24, pp. 131-139). River Edge, NJ: World Scientific.
-
-* **CEM - Cross Entropy Method**
-  * **OriginalCEM**: Rubinstein, R. (1999). The cross-entropy method for combinatorial and continuous optimization. Methodology and computing in applied probability, 1(2), 127-190.
-  
-* **CSO - Cat Swarm Optimization** 
-  * **OriginalCSO**: Chu, S. C., Tsai, P. W., & Pan, J. S. (2006, August). Cat swarm optimization. In Pacific Rim international conference on artificial intelligence (pp. 854-858). Springer, Berlin, Heidelberg.
-
-* **CSA - Cuckoo Search Algorithm** 
-  * **OriginalCSA**: Yang, X. S., & Deb, S. (2009, December). Cuckoo search via LÃ©vy flights. In 2009 World congress on nature & biologically inspired computing (NaBIC) (pp. 210-214). Ieee.
-
-* **CRO - Coral Reefs Optimization** 
-  * **OriginalCRO**: Salcedo-Sanz, S., Del Ser, J., Landa-Torres, I., Gil-LÃ³pez, S., & Portilla-Figueras, J. A. (2014). The coral reefs optimization algorithm: a novel metaheuristic for efficiently solving optimization problems. The Scientific World Journal, 2014.
-  * **OCRO**: Nguyen, T., Nguyen, T., Nguyen, B. M., & Nguyen, G. (2019). Efficient time-series forecasting using neural network and opposition-based coral reefs optimization. International Journal of Computational Intelligence Systems, 12(2), 1144-1161.
-
-* **COA - Coyote Optimization Algorithm**
-  * **OriginalCOA**: Pierezan, J., & Coelho, L. D. S. (2018, July). Coyote optimization algorithm: a new metaheuristic for global optimization problems. In 2018 IEEE congress on evolutionary computation (CEC) (pp. 1-8). IEEE.
-
-* **CHIO - Coronavirus Herd Immunity Optimization**
-  * **OriginalCHIO**: Al-Betar, M. A., Alyasseri, Z. A. A., Awadallah, M. A., & Abu Doush, I. (2021). Coronavirus herd immunity optimizer (CHIO). Neural Computing and Applications, 33(10), 5011-5042.
-  * **BaseCHIO**: The developed version
-
-* **CGO - Chaos Game Optimization** 
-  * **OriginalCGO**: Talatahari, S., & Azizi, M. (2021). Chaos Game Optimization: a novel metaheuristic algorithm. Artificial Intelligence Review, 54(2), 917-1004.
-
-* **CSA - Circle Search Algorithm**
-  * **OriginalCSA**: Qais, M. H., Hasanien, H. M., Turky, R. A., Alghuwainem, S., Tostado-VÃ©liz, M., & Jurado, F. (2022). Circle Search Algorithm: A Geometry-Based Metaheuristic Optimization Algorithm. Mathematics, 10(10), 1626.
-
-### D
-
-* **DE - Differential Evolution** 
-  * **BaseDE**: Storn, R., & Price, K. (1997). Differential evolutionâa simple and efficient heuristic for global optimization over continuous spaces. Journal of global optimization, 11(4), 341-359.
-  * **JADE**: Zhang, J., & Sanderson, A. C. (2009). JADE: adaptive differential evolution with optional external archive. IEEE Transactions on evolutionary computation, 13(5), 945-958.
-  * **SADE**: Qin, A. K., & Suganthan, P. N. (2005, September). Self-adaptive differential evolution algorithm for numerical optimization. In 2005 IEEE congress on evolutionary computation (Vol. 2, pp. 1785-1791). IEEE.
-  * **SHADE**: Tanabe, R., & Fukunaga, A. (2013, June). Success-history based parameter adaptation for differential evolution. In 2013 IEEE congress on evolutionary computation (pp. 71-78). IEEE.
-  * **L_SHADE**: Tanabe, R., & Fukunaga, A. S. (2014, July). Improving the search performance of SHADE using linear population size reduction. In 2014 IEEE congress on evolutionary computation (CEC) (pp. 1658-1665). IEEE.
-  * **SAP_DE**: Teo, J. (2006). Exploring dynamic self-adaptive populations in differential evolution. Soft Computing, 10(8), 673-686.
-  
-* **DSA - Differential Search Algorithm (not done)** 
-  * **BaseDSA**: Civicioglu, P. (2012). Transforming geocentric cartesian coordinates to geodetic coordinates by using differential search algorithm. Computers & Geosciences, 46, 229-247.
-  
-* **DO - Dragonfly Optimization** 
-  * **OriginalDO**: Mirjalili, S. (2016). Dragonfly algorithm: a new meta-heuristic optimization technique for solving single-objective, discrete, and multi-objective problems. Neural Computing and Applications, 27(4), 1053-1073.
-
-* **DMOA - Dwarf Mongoose Optimization Algorithm**
-  * **OriginalDMOA**: Agushaka, J. O., Ezugwu, A. E., & Abualigah, L. (2022). Dwarf mongoose optimization algorithm. Computer methods in applied mechanics and engineering, 391, 114570.
-  * **DevDMOA**: The developed version
-
-### E
-
-* **ES - Evolution Strategies** . 
-  * **OriginalES**: Schwefel, H. P. (1984). Evolution strategies: A family of non-linear optimization techniques based on imitating some principles of organic evolution. Annals of Operations Research, 1(2), 165-167.
-  * **LevyES**: Zhang, S., & Salari, E. (2005). Competitive learning vector quantization with evolution strategies for image compression. Optical Engineering, 44(2), 027006.
-
-* **EP - Evolutionary programming** . 
-  * **OriginalEP**: Fogel, L. J. (1994). Evolutionary programming in perspective: The top-down view. Computational intelligence: Imitating life.
-  * **LevyEP**: Lee, C.Y. and Yao, X., 2001, May. Evolutionary algorithms with adaptive lÃ©vy mutations. In Proceedings of the 2001 congress on evolutionary computation (IEEE Cat. No. 01TH8546) (Vol. 1, pp. 568-575). IEEE.
-
-* **EHO - Elephant Herding Optimization** . 
-  * **OriginalEHO**: Wang, G. G., Deb, S., & Coelho, L. D. S. (2015, December). Elephant herding optimization. In 2015 3rd International Symposium on Computational and Business Intelligence (ISCBI) (pp. 1-5). IEEE.
-
-* **EFO - Electromagnetic Field Optimization** . 
-  * **OriginalEFO**:Abedinpourshotorban, H., Shamsuddin, S. M., Beheshti, Z., & Jawawi, D. N. (2016). Electromagnetic field optimization: A physics-inspired metaheuristic optimization algorithm. Swarm and Evolutionary Computation, 26, 8-22.
-  * **BaseEFO**: The developed version
-
-* **EOA - Earthworm Optimisation Algorithm** . 
-  * **OriginalEOA**: Wang, G. G., Deb, S., & dos Santos Coelho, L. (2018). Earthworm optimisation algorithm: a bio-inspired metaheuristic algorithm for global optimisation problems. IJBIC, 12(1), 1-22.
-
-* **EO - Equilibrium Optimizer** . 
-  * **OriginalEO**: Faramarzi, A., Heidarinejad, M., Stephens, B., & Mirjalili, S. (2019). Equilibrium optimizer: A novel optimization algorithm. Knowledge-Based Systems.
-  * **ModifiedEO**: Gupta, S., Deep, K., & Mirjalili, S. (2020). An efficient equilibrium optimizer with mutation strategy for numerical optimization. Applied Soft Computing, 96, 106542.
-  * **AdaptiveEO**: Wunnava, A., Naik, M. K., Panda, R., Jena, B., & Abraham, A. (2020). A novel interdependence based multilevel thresholding technique using adaptive equilibrium optimizer. Engineering Applications of Artificial Intelligence, 94, 103836.
-
-### F
-
-* **FFA - Firefly Algorithm** 
-  * **OriginalFFA**: Åukasik, S., & Å»ak, S. (2009, October). Firefly algorithm for continuous constrained optimization tasks. In International conference on computational collective intelligence (pp. 97-106). Springer, Berlin, Heidelberg.
-  
-* **FA - Fireworks algorithm** 
-  * **OriginalFA**: Tan, Y., & Zhu, Y. (2010, June). Fireworks algorithm for optimization. In International conference in swarm intelligence (pp. 355-364). Springer, Berlin, Heidelberg.
-
-* **FPA - Flower Pollination Algorithm** 
-  * **OriginalFPA**: Yang, X. S. (2012, September). Flower pollination algorithm for global optimization. In International conference on unconventional computing and natural computation (pp. 240-249). Springer, Berlin, Heidelberg.
-
-* **FOA - Fruit-fly Optimization Algorithm**
-  * **OriginalFOA**: Pan, W. T. (2012). A new fruit fly optimization algorithm: taking the financial distress model as an example. Knowledge-Based Systems, 26, 69-74.
-  * **BaseFOA**: The developed version
-  * **WhaleFOA**: Fan, Y., Wang, P., Heidari, A. A., Wang, M., Zhao, X., Chen, H., & Li, C. (2020). Boosted hunting-based fruit fly optimization and advances in real-world problems. Expert Systems with Applications, 159, 113502.
-
-* **FBIO - Forensic-Based Investigation Optimization** 
-  * **OriginalFBIO**: Chou, J.S. and Nguyen, N.M., 2020. FBI inspired meta-optimization. Applied Soft Computing, p.106339.
-  * **BaseFBIO**: Fathy, A., Rezk, H. and Alanazi, T.M., 2021. Recent approach of forensic-based investigation algorithm for optimizing fractional order PID-based MPPT with proton exchange membrane fuel cell.IEEE Access,9, pp.18974-18992.
-
-* **FHO - Fire Hawk Optimization**
-  * **OriginalFHO**: Azizi, M., Talatahari, S., & Gandomi, A. H. (2022). Fire Hawk Optimizer: a novel metaheuristic algorithm. Artificial Intelligence Review, 1-77.
-
-### G
-
-* **GA - Genetic Algorithm** 
-  * **BaseGA**: Holland, J. H. (1992). Genetic algorithms. Scientific american, 267(1), 66-73.
-  * **SingleGA**: De Falco, I., Della Cioppa, A. and Tarantino, E., 2002. Mutation-based genetic algorithm: performance evaluation.Â Applied Soft Computing,Â 1(4), pp.285-299.
-  * **MultiGA**: De Jong, K.A. and Spears, W.M., 1992. A formal analysis of the role of multi-point crossover in genetic algorithms.Â Annals of mathematics and Artificial intelligence,Â 5(1), pp.1-26.
-  * **EliteSingleGA**: Elite version of Single-point mutation GA
-  * **EliteMultiGA**: Elite version of Multiple-point mutation GA
-
-* **GWO - Grey Wolf Optimizer** 
-  * **OriginalGWO**: Mirjalili, S., Mirjalili, S. M., & Lewis, A. (2014). Grey wolf optimizer. Advances in engineering software, 69, 46-61.
-  * **RW_GWO**: Gupta, S., & Deep, K. (2019). A novel random walk grey wolf optimizer. Swarm and evolutionary computation, 44, 101-112.
-  * **GWO_WOA**: Obadina, O. O., Thaha, M. A., Althoefer, K., & Shaheed, M. H. (2022). Dynamic characterization of a masterâslave robotic manipulator using a hybrid grey wolfâwhale optimization algorithm. Journal of Vibration and Control, 28(15-16), 1992-2003.
-
-* **GOA - Grasshopper Optimisation Algorithm** 
-  * **OriginalGOA**: Saremi, S., Mirjalili, S., & Lewis, A. (2017). Grasshopper optimisation algorithm: theory and application. Advances in Engineering Software, 105, 30-47.
-
-* **GCO - Germinal Center Optimization** 
-  * **OriginalGCO**: VillaseÃ±or, C., Arana-Daniel, N., Alanis, A. Y., LÃ³pez-Franco, C., & Hernandez-Vargas, E. A. (2018). Germinal center optimization algorithm. International Journal of Computational Intelligence Systems, 12(1), 13-27.
-  * **BaseGCO**: The developed version
-
-* **GSKA - Gaining Sharing Knowledge-based Algorithm** 
-  * **OriginalGSKA**: Mohamed, A. W., Hadi, A. A., & Mohamed, A. K. (2019). Gaining-sharing knowledge based algorithm for solving optimization problems: a novel nature-inspired algorithm. International Journal of Machine Learning and Cybernetics, 1-29.
-  * **BaseGSKA**: Mohamed, A.W., Hadi, A.A., Mohamed, A.K. and Awad, N.H., 2020, July. Evaluating the performance of adaptive GainingSharing knowledge based algorithm on CEC 2020 benchmark problems. InÂ 2020 IEEE Congress on Evolutionary Computation (CEC)Â (pp. 1-8). IEEE.
-
-* **GBO - Gradient-Based Optimizer**
-  * **OriginalGBO**: Ahmadianfar, I., Bozorg-Haddad, O., & Chu, X. (2020). Gradient-based optimizer: A new metaheuristic optimization algorithm. Information Sciences, 540, 131-159.
-
-### H
-
-* **HC - Hill Climbing** . 
-  * **OriginalHC**: Talbi, E. G., & Muntean, T. (1993, January). Hill-climbing, simulated annealing and genetic algorithms: a comparative study and application to the mapping problem. In [1993] Proceedings of the Twenty-sixth Hawaii International Conference on System Sciences (Vol. 2, pp. 565-573). IEEE.
-  * **SwarmHC**: The developed version based on swarm-based idea (Original is single-solution based method)
-
-* **HS - Harmony Search** . 
-  * **OriginalHS**: Geem, Z. W., Kim, J. H., & Loganathan, G. V. (2001). A new heuristic optimization algorithm:harmony search. simulation, 76(2), 60-68.
-  * **BaseHS**: The developed version
-
-* **HHO - Harris Hawks Optimization** . 
-  * **OriginalHHO**: Heidari, A. A., Mirjalili, S., Faris, H., Aljarah, I., Mafarja, M., & Chen, H. (2019). Harris hawks optimization: Algorithm and applications. Future Generation Computer Systems, 97, 849-872.
-
-* **HGSO - Henry Gas Solubility Optimization** . 
-  * **OriginalHGSO**: Hashim, F. A., Houssein, E. H., Mabrouk, M. S., Al-Atabany, W., & Mirjalili, S. (2019). Henry gas solubility optimization: A novel physics-based algorithm. Future Generation Computer Systems, 101, 646-667.
-
-* **HGS - Hunger Games Search** . 
-  * **OriginalHGS**: Yang, Y., Chen, H., Heidari, A. A., & Gandomi, A. H. (2021). Hunger games search:Visions, conception, implementation, deep analysis, perspectives, and towards performance shifts. Expert Systems with Applications, 177, 114864.
-  
-* **HHOA - Horse Herd Optimization Algorithm (not done)** . 
-  * **BaseHHOA**: MiarNaeimi, F., Azizyan, G., & Rashki, M. (2021). Horse herd optimization algorithm: A nature-inspired algorithm for high-dimensional optimization problems. Knowledge-Based Systems, 213, 106711.
-  
-* **HBA - Honey Badger Algorithm**:
-  * **OriginalHBA**: Hashim, F. A., Houssein, E. H., Hussain, K., Mabrouk, M. S., & Al-Atabany, W. (2022). Honey Badger Algorithm: New metaheuristic algorithm for solving optimization problems. Mathematics and Computers in Simulation, 192, 84-110.
-
-
-### I
-
-* **IWO - Invasive Weed Optimization** . 
-  * **OriginalIWO**: Mehrabian, A. R., & Lucas, C. (2006). A novel numerical optimization algorithm inspired from weed colonization. Ecological informatics, 1(4), 355-366.
-
-* **ICA - Imperialist Competitive Algorithm** 
-  * **OriginalICA**: Atashpaz-Gargari, E., & Lucas, C. (2007, September). Imperialist competitive algorithm: an algorithm for optimization inspired by imperialistic competition. In 2007 IEEE congress on evolutionary computation (pp. 4661-4667). Ieee.
-
-* **INFO - weIghted meaN oF vectOrs**:
-  * **OriginalINFO**: Ahmadianfar, I., Heidari, A. A., Gandomi, A. H., Chu, X., & Chen, H. (2021). RUN beyond the metaphor: An efficient     optimization algorithm based on Runge Kutta method. Expert Systems with Applications, 181, 115079.
-
-### J
-
-* **JA - Jaya Algorithm** 
-  * **OriginalJA**: Rao, R. (2016). Jaya: A simple and new optimization algorithm for solving constrained and unconstrained optimization problems. International Journal of Industrial Engineering Computations, 7(1), 19-34.
-  * **BaseJA**: The developed version
-  * **LevyJA**: Iacca, G., dos Santos Junior, V. C., & de Melo, V. V. (2021). An improved Jaya optimization algorithm with Levy flight. Expert Systems with Applications, 165, 113902.
-
-### K
-
-### L
-
-* **LCO - Life Choice-based Optimization** 
-  * **OriginalLCO**: Khatri, A., Gaba, A., Rana, K. P. S., & Kumar, V. (2019). A novel life choice-based optimizer. Soft Computing, 1-21.
-  * **BaseLCO**: The developed version
-  * **ImprovedLCO**: The improved version using Gaussian distribution and Mutation Mechanism
-
-
-### M
-
-* **MA - Memetic Algorithm**
-  * **OriginalMA**: Moscato, P. (1989). On evolution, search, optimization, genetic algorithms and martial arts: Towards memetic algorithms. Caltech concurrent computation program, C3P Report, 826, 1989.
-
-* **MFO - Moth Flame Optimization** 
-  * **OriginalMFO**: Mirjalili, S. (2015). Moth-flame optimization algorithm: A novel nature-inspired heuristic paradigm. Knowledge-based systems, 89, 228-249.
-  * **BaseMFO**: The developed version
-
-* **MVO - Multi-Verse Optimizer** 
-  * **OriginalMVO**: Mirjalili, S., Mirjalili, S. M., & Hatamlou, A. (2016). Multi-verse optimizer: a nature-inspired algorithm for global optimization. Neural Computing and Applications, 27(2), 495-513.
-  * **BaseMVO**: The developed version
-
-* **MSA - Moth Search Algorithm** 
-  * **OriginalMSA**: Wang, G. G. (2018). Moth search algorithm: a bio-inspired metaheuristic algorithm for global optimization problems. Memetic Computing, 10(2), 151-164.
-  
-* **MRFO - Manta Ray Foraging Optimization** 
-  * **OriginalMRFO**: Zhao, W., Zhang, Z., & Wang, L. (2020). Manta ray foraging optimization: An effective bio-inspired optimizer for engineering applications. Engineering Applications of Artificial Intelligence, 87, 103300.
-
-* **MPA - Marine Predators Algorithm**:
-  * **OriginalMPA**: Faramarzi, A., Heidarinejad, M., Mirjalili, S., & Gandomi, A. H. (2020). Marine Predators Algorithm: A nature-inspired metaheuristic. Expert systems with applications, 152, 113377.
-
-
-### N
-
-
-* **NRO - Nuclear Reaction Optimization** 
-  * **OriginalNRO**: Wei, Z., Huang, C., Wang, X., Han, T., & Li, Y. (2019). Nuclear Reaction Optimization: A novel and powerful physics-based algorithm for global optimization. IEEE Access. 
-
-* **NMRA - Nake Mole-Rat Algorithm**
-  * **OriginalNMRA**: Salgotra, R., & Singh, U. (2019). The naked mole-rat algorithm. Neural Computing and Applications, 31(12), 8837-8857.
-  * **ImprovedNMRA**: Singh, P., Mittal, N., Singh, U. and Salgotra, R., 2021. Naked mole-rat algorithm with improved exploration and exploitation capabilities to determine 2D and 3D coordinates of sensor nodes in WSNs.Â Arabian Journal for Science and Engineering,Â 46(2), pp.1155-1178.
-
-
-### O
-
-### P
-
-* **PSO - Particle Swarm Optimization** 
-  * **OriginalPSO**: Eberhart, R., & Kennedy, J. (1995, October). A new optimizer using particle swarm theory. In MHS'95. Proceedings of the Sixth International Symposium on Micro Machine and Human Science (pp. 39-43). Ieee.
-  * **PPSO**: Ghasemi, M., Akbari, E., Rahimnejad, A., Razavi, S. E., Ghavidel, S., & Li, L. (2019). Phasor particle swarm optimization: a simple and efficient variant of PSO. Soft Computing, 23(19), 9701-9718.
-  * **HPSO_TVAC**: Ghasemi, M., Aghaei, J., & Hadipour, M. (2017). New self-organising hierarchical PSO with jumping time-varying acceleration coefficients. Electronics Letters, 53(20), 1360-1362.
-  * **C_PSO**: Liu, B., Wang, L., Jin, Y. H., Tang, F., & Huang, D. X. (2005). Improved particle swarm optimization combined with chaos. Chaos, Solitons & Fractals, 25(5), 1261-1271.
-  * **CL_PSO**: Liang, J. J., Qin, A. K., Suganthan, P. N., & Baskar, S. (2006). Comprehensive learning particle swarm optimizer for global optimization of multimodal functions. IEEE transactions on evolutionary computation, 10(3), 281-295.
-
-* **PFA - Pathfinder Algorithm** 
-  * **OriginalPFA**: Yapici, H., & Cetinkaya, N. (2019). A new meta-heuristic optimizer: Pathfinder algorithm. Applied Soft Computing, 78, 545-568.
-
-* **PSS - Pareto-like Sequential Sampling**
-  * **OriginalPSS**: Shaqfa, M., & Beyer, K. (2021). Pareto-like sequential sampling heuristic for global optimisation. Soft Computing, 25(14), 9077-9096.
-
-
-### Q
-
-* **QSA - Queuing Search Algorithm** 
-  * **OriginalQSA**: Zhang, J., Xiao, M., Gao, L., & Pan, Q. (2018). Queuing search algorithm: A novel metaheuristic algorithm for solving engineering optimization problems. Applied Mathematical Modelling, 63, 464-490.
-  * **BaseQSA**: The developed version
-  * **OppoQSA**: Zheng, X. and Nguyen, H., 2022. A novel artificial intelligent model for predicting water treatment efficiency of various biochar systems based on artificial neural network and queuing search algorithm. Chemosphere, 287, p.132251.
-  * **LevyQSA**: Abderazek, H., Hamza, F., Yildiz, A.R., Gao, L. and Sait, S.M., 2021. A comparative analysis of the queuing search algorithm, the sine-cosine algorithm, the ant lion algorithm to determine the optimal weight design problem of a spur gear drive system. Materials Testing, 63(5), pp.442-447.
-  * **ImprovedQSA**: Nguyen, B.M., Hoang, B., Nguyen, T. and Nguyen, G., 2021. nQSV-Net: a novel queuing search variant for global space search and workload modeling.Â Journal of Ambient Intelligence and Humanized Computing,Â 12(1), pp.27-46.
-
-### R
-
-* **RUN - RUNge Kutta optimizer**:
-  * **OriginalRUN**: Ahmadianfar, I., Heidari, A. A., Gandomi, A. H., Chu, X., & Chen, H. (2021). RUN beyond the metaphor: An efficient optimization algorithm based on Runge Kutta method. Expert Systems with Applications, 181, 115079.
-
-### S
-
-* **SA - Simulated Annealling** 
-  * **OriginalSA**: . Van Laarhoven, P. J., & Aarts, E. H. (1987). Simulated annealing. In Simulated annealing: Theory and applications (pp. 7-15). Springer, Dordrecht.
-
-* **SSpiderO - Social Spider Optimization** 
-  * **OriginalSSpiderO**: Cuevas, E., Cienfuegos, M., ZaldÃ­Var, D., & PÃ©rez-Cisneros, M. (2013). A swarm optimization algorithm inspired in the behavior of the social-spider. Expert Systems with Applications, 40(16), 6374-6384.
-
-* **SOS - Symbiotic Organisms Search**:
-  * **OriginalSOS**: Cheng, M. Y., & Prayogo, D. (2014). Symbiotic organisms search: a new metaheuristic optimization algorithm. Computers & Structures, 139, 98-112.
-
-* **SSpiderA - Social Spider Algorithm** 
-  * **OriginalSSpiderA**: James, J. Q., & Li, V. O. (2015). A social spider algorithm for global optimization. Applied Soft Computing, 30, 614-627.
-
-* **SCA - Sine Cosine Algorithm** 
-  * **OriginalSCA**: Mirjalili, S. (2016). SCA: a sine cosine algorithm for solving optimization problems. Knowledge-Based Systems, 96, 120-133.
-  * **BaseSCA**: Attia, A.F., El Sehiemy, R.A. and Hasanien, H.M., 2018. Optimal power flow solution in power systems using a novel Sine-Cosine algorithm.Â International Journal of Electrical Power & Energy Systems,Â 99, pp.331-343.
-
-* **SRSR - Swarm Robotics Search And Rescue** 
-  * **OriginalSRSR**: Bakhshipour, M., Ghadi, M. J., & Namdari, F. (2017). Swarm robotics search & rescue: A novel artificial intelligence-inspired optimization approach. Applied Soft Computing, 57, 708-726.
-
-* **SBO - Satin Bowerbird Optimizer** 
-  * **OriginalSBO**: Moosavi, S. H. S., & Bardsiri, V. K. (2017). Satin bowerbird optimizer: a new optimization algorithm to optimize ANFIS for software development effort estimation. Engineering Applications of Artificial Intelligence, 60, 1-15.
-  * **BaseSBO**: The developed version
-
-* **SHO - Spotted Hyena Optimizer**
-  * **OriginalSHO**: Dhiman, G., & Kumar, V. (2017). Spotted hyena optimizer: a novel bio-inspired based metaheuristic technique for engineering applications. Advances in Engineering Software, 114, 48-70.
-
-* **SSO - Salp Swarm Optimization**
-  * **OriginalSSO**: Mirjalili, S., Gandomi, A. H., Mirjalili, S. Z., Saremi, S., Faris, H., & Mirjalili, S. M. (2017). Salp Swarm Algorithm: A bio-inspired optimizer for engineering design problems. Advances in Engineering Software, 114, 163-191.
-
-* **SFO - Sailfish Optimizer** 
-  * **OriginalSFO**: Shadravan, S., Naji, H. R., & Bardsiri, V. K. (2019). The Sailfish Optimizer: A novel nature-inspired metaheuristic algorithm for solving constrained engineering optimization problems. Engineering Applications of Artificial Intelligence, 80, 20-34.
-  * **ImprovedSFO**: Li, L.L., Shen, Q., Tseng, M.L. and Luo, S., 2021. Power system hybrid dynamic economic emission dispatch with wind energy based on improved sailfish algorithm.Â Journal of Cleaner Production,Â 316, p.128318.
-
-* **SARO - Search And Rescue Optimization** 
-  * **OriginalSARO**: Shabani, A., Asgarian, B., Gharebaghi, S. A., Salido, M. A., & Giret, A. (2019). A New Optimization Algorithm Based on Search and Rescue Operations. Mathematical Problems in Engineering, 2019.
-  * **BaseSARO**: The developed version using Levy-flight
-
-* **SSDO - Social Ski-Driver Optimization** 
-  * **OriginalSSDO**: Tharwat, A., & Gabel, T. (2019). Parameters optimization of support vector machines for imbalanced data using social ski driver algorithm. Neural Computing and Applications, 1-14.
-
-* **SLO - Sea Lion Optimization**
-  * **OriginalSLO**: Masadeh, R., Mahafzah, B. A., & Sharieh, A. (2019). Sea Lion Optimization Algorithm. Sea, 10(5).
-  * **ImprovedSLO**: The developed version
-  * **ModifiedSLO**: Masadeh, R., Alsharman, N., Sharieh, A., Mahafzah, B.A. and Abdulrahman, A., 2021. Task scheduling on cloud computing based on sea lion optimization algorithm.Â International Journal of Web Information Systems.
-
-* **Seagull Optimization Algorithm**
-  * **OriginalSOA**: Dhiman, G., & Kumar, V. (2019). Seagull optimization algorithm: Theory and its applications for large-scale industrial engineering problems. Knowledge-based systems, 165, 169-196.
-  * **DevSOA**: The developed version
-
-* **SMA - Slime Mould Algorithm**
-  * **OriginalSMA**: Li, S., Chen, H., Wang, M., Heidari, A. A., & Mirjalili, S. (2020). Slime mould algorithm: A new method for stochastic optimization. Future Generation Computer Systems.
-  * **BaseSMA**: The developed version
-
-* **SSA - Sparrow Search Algorithm** 
-  * **OriginalSSA**: Jiankai Xue & Bo Shen (2020) A novel swarm intelligence optimization approach: sparrow search algorithm, Systems Science & Control Engineering, 8:1, 22-34, DOI: 10.1080/21642583.2019.1708830
-  * **BaseSSA**: The developed version
-
-* **SPBO - Student Psychology Based Optimization**
-  * **OriginalSPBO**: Das, B., Mukherjee, V., & Das, D. (2020). Student psychology based optimization algorithm: A new population based optimization algorithm for solving optimization problems. Advances in Engineering software, 146, 102804.
-  * **DevSPBO**: The developed version
-
-* **SCSO - Sand Cat Swarm Optimization**
-  * **OriginalSCSO**: Seyyedabbasi, A., & Kiani, F. (2022). Sand Cat swarm optimization: a nature-inspired algorithm to solve global optimization problems. Engineering with Computers, 1-25.
-
-### T
-
-* **TLO - Teaching Learning Optimization** 
-  * **OriginalTLO**: Rao, R. V., Savsani, V. J., & Vakharia, D. P. (2011). Teachingâlearning-based optimization: a novel method for constrained mechanical design optimization problems. Computer-Aided Design, 43(3), 303-315.
-  * **BaseTLO**: Rao, R., & Patel, V. (2012). An elitist teaching-learning-based optimization algorithm for solving complex constrained optimization problems. International Journal of Industrial Engineering Computations, 3(4), 535-560.
-  * **ImprovedTLO**: Rao, R. V., & Patel, V. (2013). An improved teaching-learning-based optimization algorithm for solving unconstrained optimization problems. Scientia Iranica, 20(3), 710-720.
-
-* **TWO - Tug of War Optimization** 
-  * **OriginalTWO**: Kaveh, A., & Zolghadr, A. (2016). A novel meta-heuristic algorithm: tug of war optimization. Iran University of Science & Technology, 6(4), 469-492.
-  * **OppoTWO**: Kaveh, A., Almasi, P. and Khodagholi, A., 2022. Optimum Design of Castellated Beams Using Four Recently Developed Meta-heuristic Algorithms.Â Iranian Journal of Science and Technology, Transactions of Civil Engineering, pp.1-13.
-  * **LevyTWO**: The developed version using Levy-flight
-  * **ImprovedTWO**: Nguyen, T., Hoang, B., Nguyen, G., & Nguyen, B. M. (2020). A new workload prediction model using extreme learning machine and enhanced tug of war optimization. Procedia Computer Science, 170, 362-369.
-
-* **TSA - Tunicate Swarm Algorithm**
-  * **OriginalTSA**: Kaur, S., Awasthi, L. K., Sangal, A. L., & Dhiman, G. (2020). Tunicate Swarm Algorithm: A new bio-inspired based metaheuristic paradigm for global optimization. Engineering Applications of Artificial Intelligence, 90, 103541.
-
-* **TSO - Tuna Swarm Optimization**
-  * **OriginalTSO**: Xie, L., Han, T., Zhou, H., Zhang, Z. R., Han, B., & Tang, A. (2021). Tuna swarm optimization: a novel swarm-based metaheuristic algorithm for global optimization. Computational intelligence and Neuroscience, 2021.
-
-
-### U
-
-### V
-
-* **VCS - Virus Colony Search** 
-  * **OriginalVCS**: Li, M. D., Zhao, H., Weng, X. W., & Han, T. (2016). A novel nature-inspired algorithm for optimization: Virus colony search. Advances in Engineering Software, 92, 65-88.
-  * **BaseVCS**: The developed version
-
-### W
-
-* **WCA - Water Cycle Algorithm** 
-  * **OriginalWCA**: Eskandar, H., Sadollah, A., Bahreininejad, A., & Hamdi, M. (2012). Water cycle algorithmâA novel metaheuristic optimization method for solving constrained engineering optimization problems. Computers & Structures, 110, 151-166.
-  
-* **WOA - Whale Optimization Algorithm** 
-  * **OriginalWOA**: Mirjalili, S., & Lewis, A. (2016). The whale optimization algorithm. Advances in engineering software, 95, 51-67.
-  * **HI_WOA**: Tang, C., Sun, W., Wu, W., & Xue, M. (2019, July). A hybrid improved whale optimization algorithm. In 2019 IEEE 15th International Conference on Control and Automation (ICCA) (pp. 362-367). IEEE.
-
-* **WHO - Wildebeest Herd Optimization** 
-  * **OriginalWHO**: Amali, D., & Dinakaran, M. (2019). Wildebeest herd optimization: A new global optimization algorithm inspired by wildebeest herding behaviour. Journal of Intelligent & Fuzzy Systems, (Preprint), 1-14.
-
-* **WDO - Wind Driven Optimization** 
-  * **OriginalWDO**: Bayraktar, Z., Komurcu, M., Bossard, J.A. and Werner, D.H., 2013. The wind driven optimization technique and its application in electromagnetics. IEEE transactions on antennas and propagation, 61(5), pp.2745-2757.
-
-
-### X
-
-### Y
-
-### Z
+
+<p align="center"><img src="https://thieu1995.github.io/post/2022-04/19-mealpy-tutorials/mealpy1.png" alt="MEALPY"/></p>
+
+---
+
+
+[![GitHub release](https://img.shields.io/badge/release-2.5.2-yellow.svg)](https://github.com/thieu1995/mealpy/releases)
+[![Wheel](https://img.shields.io/pypi/wheel/gensim.svg)](https://pypi.python.org/pypi/mealpy) 
+[![PyPI version](https://badge.fury.io/py/mealpy.svg)](https://badge.fury.io/py/mealpy)
+![PyPI - Python Version](https://img.shields.io/pypi/pyversions/mealpy.svg)
+![PyPI - Status](https://img.shields.io/pypi/status/mealpy.svg)
+![PyPI - Downloads](https://img.shields.io/pypi/dm/mealpy.svg)
+[![Downloads](https://pepy.tech/badge/mealpy)](https://pepy.tech/project/mealpy)
+[![Tests & Publishes to PyPI](https://github.com/thieu1995/mealpy/actions/workflows/publish-package.yaml/badge.svg)](https://github.com/thieu1995/mealpy/actions/workflows/publish-package.yaml)
+![GitHub Release Date](https://img.shields.io/github/release-date/thieu1995/mealpy.svg)
+[![Documentation Status](https://readthedocs.org/projects/mealpy/badge/?version=latest)](https://mealpy.readthedocs.io/en/latest/?badge=latest)
+[![Chat](https://img.shields.io/badge/Chat-on%20Telegram-blue)](https://t.me/+fRVCJGuGJg1mNDg1)
+[![Average time to resolve an issue](http://isitmaintained.com/badge/resolution/thieu1995/mealpy.svg)](http://isitmaintained.com/project/thieu1995/mealpy "Average time to resolve an issue")
+[![Percentage of issues still open](http://isitmaintained.com/badge/open/thieu1995/mealpy.svg)](http://isitmaintained.com/project/thieu1995/mealpy "Percentage of issues still open")
+![GitHub contributors](https://img.shields.io/github/contributors/thieu1995/mealpy.svg)
+[![GitTutorial](https://img.shields.io/badge/PR-Welcome-%23FF8300.svg?)](https://git-scm.com/book/en/v2/GitHub-Contributing-to-a-Project)
+[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3711948.svg)](https://doi.org/10.5281/zenodo.3711948)
+[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)
+
+
+MEALPY is the largest python library for most of the cutting-edge nature-inspired meta-heuristic algorithms (population-based). Population meta-heuristic algorithms (PMA) are the most popular algorithms in the field of 
+approximate optimization.
+
+* **Free software:** GNU General Public License (GPL) V3 license
+* **Total algorithms**: 172 (102 original, 45 official variants, 25 developed variants)
+* **Documentation:** https://mealpy.readthedocs.io/en/latest/
+* **Python versions:** 3.7.x, 3.8.x, 3.9.x, 3.10.x, 3.11.x
+* **Dependencies:** numpy, scipy, pandas, matplotlib
+
+
+# Goals
+
+Our goals are to implement all of the classical as well as the state-of-the-art nature-inspired algorithms, create a simple interface that helps researchers access optimization algorithms as quickly as possible, and share knowledge of the optimization field with everyone without a fee. What you can do with mealpy:
+
+- Analyse parameters of meta-heuristic algorithms.
+- Perform Qualitative and Quantitative Analysis of algorithms.
+- Analyse rate of convergence of algorithms.
+- Test and Analyse the scalability and the robustness of algorithms.
+- Save results in various formats (csv, json, pickle, png, pdf, jpeg)
+- Export and import models can also be done with Mealpy.
+
+
+
+# Installation
+
+### Install with pip
+Install the [current PyPI release](https://pypi.python.org/pypi/mealpy):
+```sh 
+$ pip install mealpy==2.5.2
+```
+
+### Install from source
+In case you want to install directly from the source code, use:
+```sh 
+$ git clone https://github.com/thieu1995/mealpy.git
+$ cd mealpy
+$ python setup.py install
+```
+
+
+# Usage
+
+After installation, you can import Mealpy as any other Python module:
+
+```sh
+$ python
+>>> import mealpy
+>>> mealpy.__version__
+```
+
+Let's go through a basic and advanced example.
+
+
+## Examples
+
+### Simple Benchmark Function
+
+```python 
+from mealpy.bio_based import SMA
+import numpy as np
+
+def fitness_function(solution):
+    return np.sum(solution**2)
+
+problem = {
+    "fit_func": fitness_function,
+    "lb": [-100, ] * 30,
+    "ub": [100, ] * 30,
+    "minmax": "min",
+    "log_to": None,
+    "save_population": False,
+}
+
+## Run the algorithm
+model = SMA.BaseSMA(epoch=100, pop_size=50, pr=0.03)
+best_position, best_fitness = model.solve(problem)
+print(f"Best solution: {best_position}, Best fitness: {best_fitness}")
+```
+
+### Constrained Benchmark Function
+* [The Constrained Benchmark Function](https://github.com/thieu1995/mealpy/tree/master/examples/applications/run_constraint_functions.py)
+
+
+### Multi-objective Benchmark Function
+* [Multi-objective benchmark functions](https://github.com/thieu1995/mealpy/tree/master/examples/applications/run_multi_objective_functions.py)
+
+
+### Custom Problem 
+
+For our custom problem, we can create a class and inherit from the Problem class, named the child class the  
+'Squared' class. In the initialization method of the 'Squared' class, we have to set the *lb*, *ub*, and *minmax*  
+of the problem (lb: a list of lower bound values, ub: a list of upper bound values, and minmax: a string specifying 
+whether the problem is a 'min' or 'max' problem). 
+
+Afterwards, we have to override the abstract method 'fit_func()', which takes a parameter 'solution' (the solution 
+to be evaluated) and returns the function value. The resulting code should look something like the code snippet 
+below. 'Name' is an additional parameter we want to include in this class, and you can include any other additional 
+parameters you need.
+
+
+```python 
+import numpy as np
+from mealpy.bio_based import BBO
+from mealpy.utils.problem import Problem
+
+# Our custom problem class
+class Squared(Problem):
+    def __init__(self, lb=(-5, -5, -5, -5, -5, -5), ub=(5, 5, 5, 5, 5, 5), minmax="min", name="Squared", **kwargs):
+        super().__init__(lb, ub, minmax, **kwargs)
+        self.name = name
+
+    def fit_func(self, solution):
+        return np.sum(solution ** 2)
+```
+
+Now, we define an algorithm, and pass an instance of our *Squared* class as the problem argument. 
+
+```python
+problem = Squared(lb=[-10] * 20, ub=[10] * 20, minmax="min")
+model = BBO.BaseBBO(epoch=10, pop_size=50)
+best_position, best_fitness = model.solve(problem)
+
+print(best_position)
+print(best_fitness)
+print(model.get_parameters())
+print(model.get_name())
+print(model.get_attributes()["solution"])
+print(model.problem.get_name())
+print(model.problem.n_dims)
+```
+
+
+### Tuner class (GridSearchCV/ParameterSearch, Hyper-parameter tuning)
+
+We build a dedicated class, Tuner, that can help you tune your algorithm's parameters.
+
+```python
+import numpy as np
+from mealpy.bio_based import BBO
+from mealpy.tuner import Tuner          # Remember this
+
+
+def fitness(solution):
+    return np.sum(solution**2)
+
+problem = {
+    "lb": [-100, ]*50,
+    "ub": [100, ]*50,
+    "minmax": "min",
+    "fit_func": fitness,
+    "name": "Squared Problem",
+    "log_to": None,
+}
+
+paras_bbo_grid = {
+    "epoch": [100],
+    "pop_size": [50],
+    "elites": [2, 3, 4, 5],
+    "p_m": [0.01, 0.02, 0.05, 0.1, 0.15, 0.2]
+}
+
+if __name__ == "__main__":
+    model = BBO.BaseBBO()
+
+    tuner = Tuner(model, paras_bbo_grid)
+    tuner.execute(problem=problem, n_trials=10, mode="parallel", n_workers=4)
+
+    print(tuner.best_score)
+    print(tuner.best_params)
+    print(tuner.best_algorithm)
+    print(tuner.best_algorithm.get_name())
+    
+    ## Save results to csv file 
+    tuner.export_results(save_path="history/tuning", save_as="csv")
+    
+    ## Re-solve the best model on your problem 
+    best_position, best_fitness = tuner.resolve()
+
+    print(best_position, best_fitness)
+    print(tuner.problem.get_name())
+```
+
+
+### Multitask class (Multitask solving)
+
+We also build a dedicated class, Multitask, that can help you run several scenarios. For example:
+
+1. Run 1 algorithm with 1 problem, and multiple trials
+2. Run 1 algorithm with multiple problems, and multiple trials
+3. Run multiple algorithms with 1 problem, and multiple trials
+4. Run multiple algorithms with multiple problems, and multiple trials
+
+
+```python
+#### Using multiple algorithm to solve multiple problems with multiple trials
+
+## Import libraries
+## For example, we want to solve F5, F10, F29 problem in CEC-2017
+from opfunu.cec_based.cec2017 import F52017, F102017, F292017
+
+from mealpy.bio_based import BBO
+from mealpy.evolutionary_based import DE
+from mealpy.multitask import Multitask          # Remember this
+
+
+## You can define your own problems
+
+f1 = F52017(30, f_bias=0)
+f2 = F102017(30, f_bias=0)
+f3 = F292017(30, f_bias=0)
+
+p1 = {
+    "lb": f1.lb.tolist(),
+    "ub": f1.ub.tolist(),
+    "minmax": "min",
+    "fit_func": f1.evaluate,
+    "name": "F5-CEC2017",
+    "log_to": None,
+}
+
+p2 = {
+    "lb": f2.lb.tolist(),
+    "ub": f2.ub.tolist(),
+    "minmax": "min",
+    "fit_func": f2.evaluate,
+    "name": "F10-CEC2017",
+    "log_to": None,
+}
+
+p3 = {
+    "lb": f3.lb.tolist(),
+    "ub": f3.ub.tolist(),
+    "minmax": "min",
+    "fit_func": f3.evaluate,
+    "name": "F29-CEC2017",
+    "log_to": None,
+}
+
+## Define models
+
+model1 = BBO.BaseBBO(epoch=10, pop_size=50)
+model2 = BBO.OriginalBBO(epoch=10, pop_size=50)
+model3 = DE.BaseDE(epoch=10, pop_size=50)
+
+
+## Define and run Multitask
+
+if __name__ == "__main__":
+    multitask = Multitask(algorithms=(model1, model2, model3), problems=(p1, p2, p3))
+    multitask.execute(n_trials=3, mode="parallel", n_workers=6, save_path="history", save_as="csv", save_convergence=True, verbose=True)
+    
+    ## Check the directory: history/, you will see list of .csv result files
+```
+
+For more usage examples please look at [examples](/examples) folder.
+
+More advanced examples can also be found in the [Mealpy-examples repository](https://github.com/thieu1995/mealpy_examples).
+
+
+### Get Visualize Figures
+
+
+* [Tutorials](/examples/utils/visualize/all_charts.py)
+
+<p align="center"><img src="https://thieu1995.github.io/post/2022-04/19-mealpy-tutorials/mealpy2.png" alt="MEALPY"/>
+</p>
+
+
+## Mealpy Application
+
+### Mealpy + Neural Network (Replace the Gradient Descent Optimizer)
+
+* Time-series Problem:
+  * Traditional MLP
+    code: [Link](https://github.com/thieu1995/mealpy/tree/master/examples/applications/keras/traditional-mlp-time-series.py)
+  * Hybrid code (Mealpy +
+    MLP): [Link](https://github.com/thieu1995/mealpy/tree/master/examples/applications/keras/mha-hybrid-mlp-time-series.py)
+* Classification Problem:
+  * Traditional MLP
+    code: [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/keras/traditional-mlp-classification.py)
+  * Hybrid code (Mealpy +
+    MLP): [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/keras/mha-hybrid-mlp-classification.py)
+
+### Mealpy + Neural Network (Optimize Neural Network Hyper-parameter)
+
+Code: [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/keras/mha-hyper-parameter-mlp-time-series.py)
+
+### Other Applications
+
+* Solving Knapsack Problem (Discrete
+  problems): [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/discrete-problems/knapsack-problem.py)
+
+* Optimize SVM (SVC)
+  model: [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/sklearn/svm_classification.py)
+
+* Optimize Linear Regression
+  Model: [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/pytorch/linear_regression.py)
+
+* Travelling Salesman Problem: https://github.com/thieu1995/MHA-TSP 
+
+* Feature selection problem: https://github.com/thieu1995/MHA-FS
+
+
+
+## Tutorial Videos
+
+All tutorial videos: [Link](https://mealpy.readthedocs.io/en/latest/pages/general/video_tutorials.html)
+
+All code examples: [Link](https://github.com/thieu1995/mealpy/tree/master/examples)
+
+All visualization examples: [Link](https://mealpy.readthedocs.io/en/latest/pages/visualization.html)
+
+
+
+### Get helps (questions, problems)
+
+* Official source code repo: https://github.com/thieu1995/mealpy
+* Official document: https://mealpy.readthedocs.io/
+* Download releases: https://pypi.org/project/mealpy/
+* Issue tracker: https://github.com/thieu1995/mealpy/issues
+* Notable changes log: https://github.com/thieu1995/mealpy/blob/master/ChangeLog.md
+* Examples with different meapy version: https://github.com/thieu1995/mealpy/blob/master/EXAMPLES.md
+
+* This project also related to our another projects which are "meta-heuristics" and "neural-network", check it here
+    * https://github.com/thieu1995/opfunu
+    * https://github.com/thieu1995/metaheuristics
+    * https://github.com/aiir-team
+
+**Want to have an instant assistant? Join our telegram community at [link](https://t.me/+fRVCJGuGJg1mNDg1)**
+We share lots of information, questions, and answers there. You will get more support and knowledge there.
+
+### Cite Us
+
+If you are using mealpy in your project, we would appreciate citations:
+
+```bibtex 
+@software{nguyen_van_thieu_2022_6684223,
+  author       = {Nguyen Van Thieu and Seyedali Mirjalili},
+  title        = {{MEALPY: a Framework of The State-of-The-Art Meta-Heuristic Algorithms in Python}},
+  month        = jun,
+  year         = 2022,
+  publisher    = {Zenodo},
+  version      = {v2.4.2},
+  doi          = {10.5281/zenodo.6684223},
+  url          = {https://doi.org/10.5281/zenodo.6684223}
+}
+
+@article{van2023groundwater,
+  title={Groundwater level modeling using Augmented Artificial Ecosystem Optimization},
+  author={Van Thieu, Nguyen and Barma, Surajit Deb and Van Lam, To and Kisi, Ozgur and Mahesha, Amai},
+  journal={Journal of Hydrology},
+  volume={617},
+  pages={129034},
+  year={2023},
+  publisher={Elsevier}
+}
+```
+
+
+
+# List of papers used MEALPY
+
+- Min, J., Oh, M., Kim, W., Seo, H., & Paek, J. (2022, October). Evaluation of Metaheuristic Algorithms for TAS Scheduling in Time-Sensitive Networking. In 2022 13th International Conference on Information and Communication Technology Convergence (ICTC) (pp. 809-812). IEEE.
+- Khozeimeh, F., Sharifrazi, D., Izadi, N. H., Joloudari, J. H., Shoeibi, A., Alizadehsani, R., ... & Islam, S. M. S. (2021). Combining a convolutional neural network with autoencoders to predict the survival chance of COVID-19 patients. Scientific Reports, 11(1), 15343.
+- Rajesh, K., Jain, E., & Kotecha, P. (2022). A Multi-Objective approach to the Electric Vehicle Routing Problem. arXiv preprint arXiv:2208.12440.
+- SÃ¡nchez, A. J. H., & Upegui, F. R. (2022). Una herramienta para el diseÃ±o de redes MSMN de banda ancha en lÃ­neas de transmisiÃ³n basada en algoritmos heurÃ­sticos de optimizaciÃ³n comparados. Revista IngenierÃ­a UC, 29(2), 106-123.
+- Khanmohammadi, M., Armaghani, D. J., & Sabri Sabri, M. M. (2022). Prediction and Optimization of Pile Bearing Capacity Considering Effects of Time. Mathematics, 10(19), 3563.
+- Kudela, J. (2023). The Evolutionary Computation Methods No One Should Use. arXiv preprint arXiv:2301.01984.
+- Vieira, M., Faia, R., Pinto, T., & Vale, Z. (2022, September). Schedule Peer-to-Peer Transactions of an Energy Community Using Particle Swarm. In 2022 18th International Conference on the European Energy Market (EEM) (pp. 1-6). IEEE.
+- Bui, X. N., Nguyen, H., Le, Q. T., & Le, T. N. Forecasting PM. MINING SCIENCE ANDTECHNOLOGY (Russia), 111.
+- Bui, X. N., Nguyen, H., Le, Q. T., & Le, T. N. (2022). Forecasting PM 2.5 emissions in open-pit minesusing a functional link neural network optimized by various optimization algorithms. Gornye nauki i tekhnologii= Mining Science and Technology (Russia), 7(2), 111-125.
+- DoÄan, E., & YÃ¶rÃ¼keren, N. (2022). Enhancement of Transmission System Security with Archimedes Optimization Algorithm.
+- Ayub, N., Aurangzeb, K., Awais, M., & Ali, U. (2020, November). Electricity theft detection using CNN-GRU and manta ray foraging optimization algorithm. In 2020 IEEE 23Rd international multitopic conference (INMIC) (pp. 1-6). IEEE.
+- Pintilie, L., Nechita, M. T., Suditu, G. D., Dafinescu, V., & DrÄgoi, E. N. (2022). Photo-decolorization of Eriochrome Black T: process optimization with Differential Evolution algorithm. In PASEW-22, MESSH-22 & CABES-22 April 19â21, 2022 Paris (France). Eminent Association of Pioneers.
+- LaTorre, A., Molina, D., Osaba, E., Poyatos, J., Del Ser, J., & Herrera, F. (2021). A prescription of methodological guidelines for comparing bio-inspired optimization algorithms. Swarm and Evolutionary Computation, 67, 100973.
+- Gottam, S., Nanda, S. J., & Maddila, R. K. (2021, December). A CNN-LSTM Model Trained with Grey Wolf Optimizer for Prediction of Household Power Consumption. In 2021 IEEE International Symposium on Smart Electronic Systems (iSES)(Formerly iNiS) (pp. 355-360). IEEE.
+- Darius, P. S., Devadason, J., & Solomon, D. G. (2022, December). Prospects of Ant Colony Optimization (ACO) in Various Domains. In 2022 4th International Conference on Circuits, Control, Communication and Computing (I4C) (pp. 79-84). IEEE.
+- Ayub, N., Irfan, M., Awais, M., Ali, U., Ali, T., Hamdi, M., ... & Muhammad, F. (2020). Big data analytics for short and medium-term electricity load forecasting using an AI techniques ensembler. Energies, 13(19), 5193.
+- Biundini, I. Z., Melo, A. G., Coelho, F. O., HonÃ³rio, L. M., Marcato, A. L., & Pinto, M. F. (2022). Experimentation and Simulation with Autonomous Coverage Path Planning for UAVs. Journal of Intelligent & Robotic Systems, 105(2), 46.
+- Yousaf, I., Anwar, F., Imtiaz, S., Almadhor, A. S., Ishmanov, F., & Kim, S. W. (2022). An Optimized Hyperparameter of Convolutional Neural Network Algorithm for Bug Severity Prediction in Alzheimerâs-Based IoT System. Computational Intelligence and Neuroscience, 2022.
+- Xu, L., Yan, W., & Ji, J. (2023). The research of a novel WOG-YOLO algorithm for autonomous driving object detection. Scientific reports, 13(1), 3699.
+- Costache, R. D., Arabameri, A., Islam, A. R. M. T., Abba, S. I., Pandey, M., Ajin, R. S., & Pham, B. T. (2022). Flood susceptibility computation using state-of-the-art machine learning and optimization algorithms.
+- Del Ser, J., Osaba, E., Martinez, A. D., Bilbao, M. N., Poyatos, J., Molina, D., & Herrera, F. (2021, December). More is not always better: insights from a massive comparison of meta-heuristic algorithms over real-parameter optimization problems. In 2021 IEEE Symposium Series on Computational Intelligence (SSCI) (pp. 1-7). IEEE.
+- Rustam, F., Aslam, N., De La Torre DÃ­ez, I., Khan, Y. D., MazÃ³n, J. L. V., RodrÃ­guez, C. L., & Ashraf, I. (2022, November). White Blood Cell Classification Using Texture and RGB Features of Oversampled Microscopic Images. In Healthcare (Vol. 10, No. 11, p. 2230). MDPI.
+- Neupane, D., Kafle, S., Gurung, S., Neupane, S., & Bhattarai, N. (2021). Optimal sizing and financial analysis of a stand-alone SPV-micro-hydropower hybrid system considering generation uncertainty. International Journal of Low-Carbon Technologies, 16(4), 1479-1491.
+- Liang, R., Le-Hung, T., & Nguyen-Thoi, T. (2022). Energy consumption prediction of air-conditioning systems in eco-buildings using hunger games search optimization-based artificial neural network model. Journal of Building Engineering, 59, 105087.
+- He, Z., Nguyen, H., Vu, T. H., Zhou, J., Asteris, P. G., & Mammou, A. (2022). Novel integrated approaches for predicting the compressibility of clay using cascade forward neural networks optimized by swarm-and evolution-based algorithms. Acta Geotechnica, 1-16.
+- Xu, L., Yan, W., & Ji, J. (2022). The research of a novel WOG-YOLO algorithm forautonomous driving object detection.
+- Nasir Ayub, M. I., Awais, M., Ali, U., Ali, T., Hamdi, M., Alghamdi, A., & Muhammad, F. Big Data Analytics for Short and Medium Term Electricity Load Forecasting using AI Techniques Ensembler.
+- Xie, C., Nguyen, H., Choi, Y., & Armaghani, D. J. (2022). Optimized functional linked neural network for predicting diaphragm wall deflection induced by braced excavations in clays. Geoscience Frontiers, 13(2), 101313.
+- Hakemi, S., Houshmand, M., & Hosseini, S. A. (2022). A Dynamic Quantum-Inspired Genetic Algorithm with Lengthening Chromosome Size.
+- Kashifi, M. T. City-Wide Crash Risk Prediction and Interpretation Using Deep Learning Model with Multi-Source Big Data. Available at SSRN 4329686.
+- Nguyen, H., & Hoang, N. D. (2022). Computer vision-based classification of concrete spall severity using metaheuristic-optimized Extreme Gradient Boosting Machine and Deep Convolutional Neural Network. Automation in Construction, 140, 104371.
+- Zheng, J., Lu, Z., Wu, K., Ning, G. H., & Li, D. (2020). Coinage-metal-based cyclic trinuclear complexes with metalâmetal interactions: Theories to experiments and structures to functions. Chemical Reviews, 120(17), 9675-9742.
+- Van Thieu, N., Barma, S. D., Van Lam, T., Kisi, O., & Mahesha, A. (2023). Groundwater level modeling using Augmented Artificial Ecosystem Optimization. Journal of Hydrology, 617, 129034.
+- Mo, Z., Zhang, Z., Miao, Q., & Tsui, K. L. (2022). Intelligent Informative Frequency Band Searching Assisted by a Dynamic Bandit Tree Method for Machine Fault Diagnosis. IEEE/ASME Transactions on Mechatronics.
+- Dangi, D., Chandel, S. T., Dixit, D. K., Sharma, S., & Bhagat, A. (2023). An Efficient Model for Sentiment Analysis using Artificial Rabbits Optimized Vector Functional Link Network. Expert Systems with Applications, 119849.
+- Dey, S., Roychoudhury, R., Malakar, S., & Sarkar, R. (2022). An optimized fuzzy ensemble of convolutional neural networks for detecting tuberculosis from Chest X-ray images. Applied Soft Computing, 114, 108094.
+- Mousavirad, S. J., & Alexandre, L. A. (2022). Population-based JPEG Image Compression: Problem Re-Formulation. arXiv preprint arXiv:2212.06313.
+- Tsui, K. L. Intelligent Informative Frequency Band Searching Assisted by A Dynamic Bandit Tree Method for Machine Fault Diagnosis.
+- Neupane, D. (2020). Optimal Sizing and Performance Analysis of Solar PV-Micro hydropower Hybrid System in the Context of Rural Area of Nepal (Doctoral dissertation, Pulchowk Campus).
+- LaTorre, A., Molina, D., Osaba, E., Poyatos, J., Del Ser, J., & Herrera, F. Swarm and Evolutionary Computation.
+- Vieira, M. A. (2022). OtimizaÃ§Ã£o dos custos operacionais de uma comunidade energÃ©tica considerando transaÃ§Ãµes locais em âpeer-to-peerâ (Doctoral dissertation).
+- ToÄaÃ§ar, M. (2022). Using DarkNet models and metaheuristic optimization methods together to detect weeds growing along with seedlings. Ecological Informatics, 68, 101519.
+- ToÄaÃ§ar, M. (2021). Detection of segmented uterine cancer images by Hotspot Detection method using deep learning models, Pigeon-Inspired Optimization, types-based dominant activation selection approaches. Computers in Biology and Medicine, 136, 104659.
+- Khan, N. A Short Term Electricity Load and Price Forecasting Model Based on BAT Algorithm in Logistic Regression and CNN-GRU with WOA.
+- Yelisetti, S., Saini, V. K., Kumar, R., & Lamba, R. (2022, May). Energy Consumption Cost Benefits through Smart Home Energy Management in Residential Buildings: An Indian Case Study. In 2022 IEEE IAS Global Conference on Emerging Technologies (GlobConET) (pp. 930-935). IEEE.
+- Nguyen, H., Cao, M. T., Tran, X. L., Tran, T. H., & Hoang, N. D. (2022). A novel whale optimization algorithm optimized XGBoost regression for estimating bearing capacity of concrete piles. Neural Computing and Applications, 1-28.
+- Hirsching, C., de Jongh, S., Eser, D., Suriyah, M., & Leibfried, T. (2022). Meta-heuristic optimization of control structure and design for MMC-HVdc applications. Electric Power Systems Research, 213, 108371.
+- Amelin, V., Gatiyatullin, E., Romanov, N., Samarkhanov, R., Vasilyev, R., & Yanovich, Y. (2022). Black-Box for Blockchain Parameters Adjustment. IEEE Access, 10, 101795-101802.
+- Ngo, T. Q., Nguyen, L. Q., & Tran, V. Q. (2022). Novel hybrid machine learning models including support vector machine with meta-heuristic algorithms in predicting unconfined compressive strength of organic soils stabilised with cement and lime. International Journal of Pavement Engineering, 1-18.
+- Zhu, Y., & Iiduka, H. (2021). Unified Algorithm Framework for Nonconvex Stochastic Optimization in Deep Neural Networks. IEEE Access, 9, 143807-143823.
+- Hakemi, S., Houshmand, M., KheirKhah, E., & Hosseini, S. A. (2022). A review of recent advances in quantum-inspired metaheuristics. Evolutionary Intelligence, 1-16.
+- Das, A., Das, S. R., Panda, J. P., Dey, A., Gajrani, K. K., Somani, N., & Gupta, N. (2022). Machine learning based modelling and optimization in hard turning of AISI D6 steel with newly developed AlTiSiN coated carbide tool. arXiv preprint arXiv:2202.00596.
+- Yelisetti, S., Saini, V. K., Kumar, R., Lamba, R., & Saxena, A. (2022). Optimal energy management system for residential buildings considering the time of use price with swarm intelligence algorithms. Journal of Building Engineering, 59, 105062.
+- ValdÃ©s, G. T. (2022). Algoritmo para la detecciÃ³n de vehÃ­culos y peatones combinando CNNÂ´ sy tÃ©cnicas de bÃºsqueda.
+- Sallam, N. M., Saleh, A. I., Ali, H. A., & Abdelsalam, M. M. (2023). An efficient EGWO algorithm as feature selection for B-ALL diagnoses and its subtypes classification using peripheral blood smear images. Alexandria Engineering Journal, 68, 39-66.
+
+
+
+
+# Documents
+
+* Meta-heuristic Categories: (Based on this article: [link](https://doi.org/10.1016/j.procs.2020.09.075))
+    + Evolutionary-based: Idea from Darwin's law of natural selection, evolutionary computing 
+    + Swarm-based: Idea from movement, interaction of birds, organization of social ...
+    + Physics-based: Idea from physics law such as Newton's law of universal gravitation, black hole, multiverse 
+    + Human-based: Idea from human interaction such as queuing search, teaching learning, ... 
+    + Biology-based: Idea from biology creature (or microorganism),...
+    + System-based: Idea from eco-system, immune-system, network-system, ...
+    + Math-based: Idea from mathematical form or mathematical law such as sin-cosin 
+    + Music-based: Idea from music instrument
+
+* Difficulty - Difficulty Level (Personal Opinion): Objective observation from author. Depend on the number of 
+  parameters, number of equations, the original ideas, time spend for coding, source lines of code (SLOC).
+    + Easy: A few paras, few equations, SLOC very short
+    + Medium: more equations than Easy level, SLOC longer than Easy level
+    + Hard: Lots of equations, SLOC longer than Medium level, the paper hard to read.
+    + Hard* - Very hard: Lots of equations, SLOC too long, the paper is very hard to read.
+    
+** For newbie, we recommend to read the paper of algorithms which difficulty is "easy" or "medium" difficulty level.
+
+
+| **Group**    | **Name**                                        | **Module** | **Class**        | **Year** | **Paras** | **Difficulty** |
+|--------------|-------------------------------------------------|------------|------------------|----------|-----------|----------------|
+| Evolutionary | Evolutionary Programming                        | EP         | OriginalEP       | 1964     | 3         | easy           |
+| Evolutionary | -                                               | -          | LevyEP           | -        | 3         | easy           |
+| Evolutionary | Evolution Strategies                            | ES         | OriginalES       | 1971     | 3         | easy           |
+| Evolutionary | -                                               | -          | LevyES           | -        | 3         | easy           |
+| Evolutionary | Memetic Algorithm                               | MA         | OriginalMA       | 1989     | 7         | easy           |
+| Evolutionary | Genetic Algorithm                               | GA         | BaseGA           | 1992     | 4         | easy           |
+| Evolutionary | -                                               | -          | SingleGA         | -        | 7         | easy           |
+| Evolutionary | -                                               | -          | MultiGA          | -        | 7         | easy           |
+| Evolutionary | -                                               | -          | EliteSingleGA    | -        | 10        | easy           |
+| Evolutionary | -                                               | -          | EliteMultiGA     | -        | 10        | easy           |
+| Evolutionary | Differential Evolution                          | DE         | BaseDE           | 1997     | 5         | easy           |
+| Evolutionary | -                                               | -          | JADE             | 2009     | 6         | medium         |
+| Evolutionary | -                                               | -          | SADE             | 2005     | 2         | medium         |
+| Evolutionary | -                                               | -          | SHADE            | 2013     | 4         | medium         |
+| Evolutionary | -                                               | -          | L_SHADE          | 2014     | 4         | medium         |
+| Evolutionary | -                                               | -          | SAP_DE           | 2006     | 3         | medium         |
+| Evolutionary | Flower Pollination Algorithm                    | FPA        | OriginalFPA      | 2014     | 4         | medium         |
+| Evolutionary | Coral Reefs Optimization                        | CRO        | OriginalCRO      | 2014     | 11        | medium         |
+| Evolutionary | -                                               | -          | OCRO             | 2019     | 12        | medium         |
+| -            | -                                               | -          | -                | -        | -         | -              |
+| Swarm        | Particle Swarm Optimization                     | PSO        | OriginalPSO      | 1995     | 6         | easy           |
+| Swarm        | -                                               | -          | PPSO             | 2019     | 2         | medium         |
+| Swarm        | -                                               | -          | HPSO_TVAC        | 2017     | 4         | medium         |
+| Swarm        | -                                               | -          | C_PSO            | 2015     | 6         | medium         |
+| Swarm        | -                                               | -          | CL_PSO           | 2006     | 6         | medium         |
+| Swarm        | Bacterial Foraging Optimization                 | BFO        | OriginalBFO      | 2002     | 10        | hard           |
+| Swarm        | -                                               | -          | ABFO             | 2019     | 8         | medium         |
+| Swarm        | Bees Algorithm                                  | BeesA      | OriginalBeesA    | 2005     | 8         | medium         |
+| Swarm        | -                                               | -          | ProbBeesA        | 2015     | 5         | medium         |
+| Swarm        | Cat Swarm Optimization                          | CSO        | OriginalCSO      | 2006     | 11        | hard           |
+| Swarm        | Artificial Bee Colony                           | ABC        | OriginalABC      | 2007     | 8         | medium         |
+| Swarm        | Ant Colony Optimization                         | ACO-R      | OriginalACOR     | 2008     | 5         | easy           |
+| Swarm        | Cuckoo Search Algorithm                         | CSA        | OriginalCSA      | 2009     | 3         | medium         |
+| Swarm        | Firefly Algorithm                               | FFA        | OriginalFFA      | 2009     | 8         | easy           |
+| Swarm        | Fireworks Algorithm                             | FA         | OriginalFA       | 2010     | 7         | medium         |
+| Swarm        | Bat Algorithm                                   | BA         | OriginalBA       | 2010     | 6         | medium         |
+| Swarm        | -                                               | -          | AdaptiveBA       | -        | 8         | medium         |
+| Swarm        | -                                               | -          | ModifiedBA       | -        | 5         | medium         |
+| Swarm        | Fruit-fly Optimization Algorithm                | FOA        | OriginalFOA      | 2012     | 2         | easy           |
+| Swarm        | -                                               | -          | BaseFOA          | -        | 2         | easy           |
+| Swarm        | -                                               | -          | WhaleFOA         | 2020     | 2         | medium         |
+| Swarm        | Social Spider Optimization                      | SSpiderO   | OriginalSSpiderO | 2018     | 4         | hard*          |
+| Swarm        | Grey Wolf Optimizer                             | GWO        | OriginalGWO      | 2014     | 2         | easy           |
+| Swarm        | -                                               | -          | RW_GWO           | 2019     | 2         | easy           |
+| Swarm        | Social Spider Algorithm                         | SSpiderA   | OriginalSSpiderA | 2015     | 5         | medium         |
+| Swarm        | Ant Lion Optimizer                              | ALO        | OriginalALO      | 2015     | 2         | easy           |
+| Swarm        | -                                               | -          | BaseALO          | -        | 2         | easy           |
+| Swarm        | Moth Flame Optimization                         | MFO        | OriginalMFO      | 2015     | 2         | easy           |
+| Swarm        | -                                               | -          | BaseMFO          | -        | 2         | easy           |
+| Swarm        | Elephant Herding Optimization                   | EHO        | OriginalEHO      | 2015     | 5         | easy           |
+| Swarm        | Jaya Algorithm                                  | JA         | OriginalJA       | 2016     | 2         | easy           |
+| Swarm        | -                                               | -          | BaseJA           | -        | 2         | easy           |
+| Swarm        | -                                               | -          | LevyJA           | 2021     | 2         | easy           |
+| Swarm        | Whale Optimization Algorithm                    | WOA        | OriginalWOA      | 2016     | 2         | medium         |
+| Swarm        | -                                               | -          | HI_WOA           | 2019     | 3         | medium         |
+| Swarm        | Dragonfly Optimization                          | DO         | OriginalDO       | 2016     | 2         | medium         |
+| Swarm        | Bird Swarm Algorithm                            | BSA        | OriginalBSA      | 2016     | 9         | medium         |
+| Swarm        | Spotted Hyena Optimizer                         | SHO        | OriginalSHO      | 2017     | 4         | medium         |
+| Swarm        | Salp Swarm Optimization                         | SSO        | OriginalSSO      | 2017     | 2         | easy           |
+| Swarm        | Swarm Robotics Search And Rescue                | SRSR       | OriginalSRSR     | 2017     | 2         | hard*          |
+| Swarm        | Grasshopper Optimisation Algorithm              | GOA        | OriginalGOA      | 2017     | 4         | easy           |
+| Swarm        | Coyote Optimization Algorithm                   | COA        | OriginalCOA      | 2018     | 3         | medium         |
+| Swarm        | Moth Search Algorithm                           | MSA        | OriginalMSA      | 2018     | 5         | easy           |
+| Swarm        | Sea Lion Optimization                           | SLO        | OriginalSLO      | 2019     | 2         | medium         |
+| Swarm        | -                                               | -          | ModifiedSLO      | -        | 2         | medium         |
+| Swarm        | -                                               | -          | ImprovedSLO      | -        | 4         | medium         |
+| Swarm        | Nake Mole-Rat Algorithm                         | NMRA       | OriginalNMRA     | 2019     | 3         | easy           |
+| Swarm        | -                                               | -          | ImprovedNMRA     | -        | 4         | medium         |
+| Swarm        | Pathfinder Algorithm                            | PFA        | OriginalPFA      | 2019     | 2         | medium         |
+| Swarm        | Sailfish Optimizer                              | SFO        | OriginalSFO      | 2019     | 5         | easy           |
+| Swarm        | -                                               | -          | ImprovedSFO      | -        | 3         | medium         |
+| Swarm        | Harris Hawks Optimization                       | HHO        | OriginalHHO      | 2019     | 2         | medium         |
+| Swarm        | Manta Ray Foraging Optimization                 | MRFO       | OriginalMRFO     | 2020     | 3         | medium         |
+| Swarm        | Bald Eagle Search                               | BES        | OriginalBES      | 2020     | 7         | easy           |
+| Swarm        | Sparrow Search Algorithm                        | SSA        | OriginalSSA      | 2020     | 5         | medium         |
+| Swarm        | -                                               | -          | BaseSSA          | -        | 5         | medium         |
+| Swarm        | Hunger Games Search                             | HGS        | OriginalHGS      | 2021     | 4         | medium         |
+| Swarm        | Aquila Optimizer                                | AO         | OriginalAO       | 2021     | 2         | easy           |
+| Swarm        | Hybrid Grey Wolf - Whale Optimization Algorithm | GWO        | GWO_WOA          | 2022     | 2         | easy           |
+| Swarm        | Marine Predators Algorithm                      | MPA        | OriginalMPA      | 2020     | 2         | medium         |
+| Swarm        | Honey Badger Algorithm                          | HBA        | OriginalHBA      | 2022     | 2         | easy           |
+| Swarm        | Sand Cat Swarm Optimization                     | SCSO       | OriginalSCSO     | 2022     | 2         | easy           |
+| Swarm        | Tuna Swarm Optimization                         | TSO        | OriginalTSO      | 2021     | 2         | medium         |
+| Swarm        | African Vultures Optimization Algorithm         | AVOA       | OriginalAVOA     | 2022     | 7         | medium         |
+| Swarm        | Artificial Gorilla Troops Optimization          | AGTO       | OriginalAGTO     | 2021     | 5         | medium         |
+| Swarm        | Artificial Rabbits Optimization                 | ARO        | OriginalARO      | 2022     | 2         | easy           |
+| Swarm        | Dwarf Mongoose Optimization Algorithm           | DMOA       | OriginalDMOA     | 2022     | 4         | medium         |
+| Swarm        | -                                               | -          | DevDMOA          | -        | 3         | medium         |
+| -            | -                                               | -          | -                | -        | -         | -              |
+| Physics      | Simulated Annealling                            | SA         | OriginalSA       | 1987     | 9         | medium         |
+| Physics      | Wind Driven Optimization                        | WDO        | OriginalWDO      | 2013     | 7         | easy           |
+| Physics      | Multi-Verse Optimizer                           | MVO        | OriginalMVO      | 2016     | 4         | easy           |
+| Physics      | -                                               | -          | BaseMVO          | -        | 4         | easy           |
+| Physics      | Tug of War Optimization                         | TWO        | OriginalTWO      | 2016     | 2         | easy           |
+| Physics      | -                                               | -          | OppoTWO          | -        | 2         | medium         |
+| Physics      | -                                               | -          | LevyTWO          | -        | 2         | medium         |
+| Physics      | -                                               | -          | EnhancedTWO      | 2020     | 2         | medium         |
+| Physics      | Electromagnetic Field Optimization              | EFO        | OriginalEFO      | 2016     | 6         | easy           |
+| Physics      | -                                               | -          | BaseEFO          | -        | 6         | medium         |
+| Physics      | Nuclear Reaction Optimization                   | NRO        | OriginalNRO      | 2019     | 2         | hard*          |
+| Physics      | Henry Gas Solubility Optimization               | HGSO       | OriginalHGSO     | 2019     | 3         | medium         |
+| Physics      | Atom Search Optimization                        | ASO        | OriginalASO      | 2019     | 4         | medium         |
+| Physics      | Equilibrium Optimizer                           | EO         | OriginalEO       | 2019     | 2         | easy           |
+| Physics      | -                                               | -          | ModifiedEO       | 2020     | 2         | medium         |
+| Physics      | -                                               | -          | AdaptiveEO       | 2020     | 2         | medium         |
+| Physics      | Archimedes Optimization Algorithm               | ArchOA     | OriginalArchOA   | 2021     | 8         | medium         |
+| -            | -                                               | -          | -                | -        | -         | -              |
+| Human        | Culture Algorithm                               | CA         | OriginalCA       | 1994     | 3         | easy           |
+| Human        | Imperialist Competitive Algorithm               | ICA        | OriginalICA      | 2007     | 8         | hard*          |
+| Human        | Teaching Learning-based Optimization            | TLO        | OriginalTLO      | 2011     | 2         | easy           |
+| Human        | -                                               | -          | BaseTLO          | 2012     | 2         | easy           |
+| Human        | -                                               | -          | ITLO             | 2013     | 3         | medium         |
+| Human        | Brain Storm Optimization                        | BSO        | OriginalBSO      | 2011     | 8         | medium         |
+| Human        | -                                               | -          | ImprovedBSO      | 2017     | 7         | medium         |
+| Human        | Queuing Search Algorithm                        | QSA        | OriginalQSA      | 2019     | 2         | hard           |
+| Human        | -                                               | -          | BaseQSA          | -        | 2         | hard           |
+| Human        | -                                               | -          | OppoQSA          | -        | 2         | hard           |
+| Human        | -                                               | -          | LevyQSA          | -        | 2         | hard           |
+| Human        | -                                               | -          | ImprovedQSA      | 2021     | 2         | hard           |
+| Human        | Search And Rescue Optimization                  | SARO       | OriginalSARO     | 2019     | 4         | medium         |
+| Human        | -                                               | -          | BaseSARO         | -        | 4         | medium         |
+| Human        | Life Choice-Based Optimization                  | LCO        | OriginalLCO      | 2019     | 3         | easy           |
+| Human        | -                                               | -          | BaseLCO          | -        | 3         | easy           |
+| Human        | -                                               | -          | ImprovedLCO      | -        | 2         | easy           |
+| Human        | Social Ski-Driver Optimization                  | SSDO       | OriginalSSDO     | 2019     | 2         | easy           |
+| Human        | Gaining Sharing Knowledge-based Algorithm       | GSKA       | OriginalGSKA     | 2019     | 6         | medium         |
+| Human        | -                                               | -          | BaseGSKA         | -        | 4         | medium         |
+| Human        | Coronavirus Herd Immunity Optimization          | CHIO       | OriginalCHIO     | 2020     | 4         | medium         |
+| Human        | -                                               | -          | BaseCHIO         | -        | 4         | medium         |
+| Human        | Forensic-Based Investigation Optimization       | FBIO       | OriginalFBIO     | 2020     | 2         | medium         |
+| Human        | -                                               | -          | BaseFBIO         | -        | 2         | medium         |
+| Human        | Battle Royale Optimization                      | BRO        | OriginalBRO      | 2020     | 3         | medium         |
+| Human        | -                                               | -          | BaseBRO          | -        | 3         | medium         |
+| Human        | Student Psychology Based Optimization           | SPBO       | OriginalSPBO     | 2020     | 2         | medium         |
+| Human        | -                                               | -          | DevSPBO          |          | 2         | medium         |
+| -            | -                                               | -          | -                | -        | -         | -              |
+| Bio          | Invasive Weed Optimization                      | IWO        | OriginalIWO      | 2006     | 7         | easy           |
+| Bio          | Biogeography-Based Optimization                 | BBO        | OriginalBBO      | 2008     | 4         | easy           |
+| Bio          | -                                               | -          | BaseBBO          | -        | 4         | easy           |
+| Bio          | Virus Colony Search                             | VCS        | OriginalVCS      | 2016     | 4         | hard*          |
+| Bio          | -                                               | -          | BaseVCS          | -        | 4         | hard*          |
+| Bio          | Satin Bowerbird Optimizer                       | SBO        | OriginalSBO      | 2017     | 5         | easy           |
+| Bio          | -                                               | -          | BaseSBO          | -        | 5         | easy           |
+| Bio          | Earthworm Optimisation Algorithm                | EOA        | OriginalEOA      | 2018     | 8         | medium         |
+| Bio          | Wildebeest Herd Optimization                    | WHO        | OriginalWHO      | 2019     | 12        | hard           |
+| Bio          | Slime Mould Algorithm                           | SMA        | OriginalSMA      | 2020     | 3         | easy           |
+| Bio          | -                                               | -          | BaseSMA          | -        | 3         | easy           |
+| Bio          | Barnacles Mating Optimizer                      | BMO        | OriginalBMO      | 2018     | 3         | easy           |
+| Bio          | Tunicate Swarm Algorithm                        | TSA        | OriginalTSA      | 2020     | 2         | easy           |
+| Bio          | Symbiotic Organisms Search                      | SOS        | OriginalSOS      | 2014     | 2         | medium         |
+| Bio          | Seagull Optimization Algorithm                  | SOA        | OriginalSOA      | 2019     | 3         | easy           |
+| Bio          | -                                               | -          | DevSOA           | -        | 3         | easy           |
+| -            | -                                               | -          | -                | -        | -         | -              |
+| System       | Germinal Center Optimization                    | GCO        | OriginalGCO      | 2018     | 4         | medium         |
+| System       | -                                               | -          | BaseGCO          | -        | 4         | medium         |
+| System       | Water Cycle Algorithm                           | WCA        | OriginalWCA      | 2012     | 5         | medium         |
+| System       | Artificial Ecosystem-based Optimization         | AEO        | OriginalAEO      | 2019     | 2         | easy           |
+| System       | -                                               | -          | EnhancedAEO      | 2020     | 2         | medium         |
+| System       | -                                               | -          | ModifiedAEO      | 2020     | 2         | medium         |
+| System       | -                                               | -          | ImprovedAEO      | 2021     | 2         | medium         |
+| System       | -                                               | -          | AugmentedAEO     | 2022     | 2         | medium         |
+| -            | -                                               | -          | -                | -        | -         | -              |
+| Math         | Hill Climbing                                   | HC         | OriginalHC       | 1993     | 3         | easy           |
+| Math         | -                                               | -          | SwarmHC          | -        | 3         | easy           |
+| Math         | Cross-Entropy Method                            | CEM        | OriginalCEM      | 1997     | 4         | easy           |
+| Math         | Sine Cosine Algorithm                           | SCA        | OriginalSCA      | 2016     | 2         | easy           |
+| Math         | -                                               | -          | BaseSCA          | -        | 2         | easy           |
+| Math         | Gradient-Based Optimizer                        | GBO        | OriginalGBO      | 2020     | 5         | medium         |
+| Math         | Arithmetic Optimization Algorithm               | AOA        | OrginalAOA       | 2021     | 6         | easy           |
+| Math         | Chaos Game Optimization                         | CGO        | OriginalCGO      | 2021     | 2         | easy           |
+| Math         | Pareto-like Sequential Sampling                 | PSS        | OriginalPSS      | 2021     | 4         | medium         |
+| Math         | weIghted meaN oF vectOrs                        | INFO       | OriginalINFO     | 2022     | 2         | medium         |
+| Math         | RUNge Kutta optimizer                           | RUN        | OriginalRUN      | 2021     | 2         | hard           |
+| Math         | Circle Search Algorithm                         | CircleSA   | OriginalCircleSA | 2022     | 3         | easy           |
+| -            | -                                               | -          | -                | -        | -         | -              |
+| Music        | Harmony Search                                  | HS         | OriginalHS       | 2001     | 4         | easy           |
+| Music        | -                                               | -          | BaseHS           | -        | 4         | easy           |
+
+
+
+
+
+### A
+
+* **ABC - Artificial Bee Colony**
+  * **OriginalABC**: Karaboga, D. (2005). An idea based on honey bee swarm for numerical optimization (Vol. 200, pp. 1-10). Technical report-tr06, Erciyes university, engineering faculty, computer engineering department.
+
+* **ACOR - Ant Colony Optimization**. 
+  * **OriginalACOR**: Socha, K., & Dorigo, M. (2008). Ant colony optimization for continuous domains. European journal of operational research, 185(3), 1155-1173.
+
+* **ALO - Ant Lion Optimizer** 
+  * **OriginalALO**: Mirjalili S (2015). âThe Ant Lion Optimizer.â Advances in Engineering Software, 83, 80-98. doi: [10.1016/j.advengsoft.2015.01.010](https://doi.org/10.1016/j.advengsoft.2015.01.010)
+  * **BaseALO**: The developed version
+
+* **AEO - Artificial Ecosystem-based Optimization** 
+  * **OriginalAEO**: Zhao, W., Wang, L., & Zhang, Z. (2019). Artificial ecosystem-based optimization: a novel nature-inspired meta-heuristic algorithm. Neural Computing and Applications, 1-43.
+  * **AugmentedAEO**: Van Thieu, N., Barma, S. D., Van Lam, T., Kisi, O., & Mahesha, A. (2022). Groundwater level modeling using Augmented Artificial Ecosystem Optimization. Journal of Hydrology, 129034.
+  * **ImprovedAEO**: Rizk-Allah, R. M., & El-Fergany, A. A. (2020). Artificial ecosystem optimizer for parameters identification of proton exchange membrane fuel cells model. International Journal of Hydrogen Energy.
+  * **EnhancedAEO**: Eid, A., Kamel, S., Korashy, A., & Khurshaid, T. (2020). An Enhanced Artificial Ecosystem-Based Optimization for Optimal Allocation of Multiple Distributed Generations. IEEE Access, 8, 178493-178513.
+  * **ModifiedAEO**: Menesy, A. S., Sultan, H. M., Korashy, A., Banakhr, F. A., Ashmawy, M. G., & Kamel, S. (2020). Effective parameter extraction of different polymer electrolyte membrane fuel cell stack models using a modified artificial ecosystem optimization algorithm. IEEE Access, 8, 31892-31909.
+  
+* **ASO - Atom Search Optimization**   
+  * **OriginalASO**: Zhao, W., Wang, L., & Zhang, Z. (2019). Atom search optimization and its application to solve a hydrogeologic parameter estimation problem. Knowledge-Based Systems, 163, 283-304.
+
+* **ArchOA - Archimedes Optimization Algorithm**
+  * **OriginalArchOA**: Hashim, F. A., Hussain, K., Houssein, E. H., Mabrouk, M. S., & Al-Atabany, W. (2021). Archimedes optimization algorithm: a new metaheuristic algorithm for solving optimization problems. Applied Intelligence, 51(3), 1531-1551.
+
+* **AOA - Arithmetic Optimization Algorithm**
+  * **OriginalAOA**: Abualigah, L., Diabat, A., Mirjalili, S., Abd Elaziz, M., & Gandomi, A. H. (2021). The arithmetic optimization algorithm. Computer methods in applied mechanics and engineering, 376, 113609.
+
+* **AO - Aquila Optimizer**
+  * **OriginalAO**: Abualigah, L., Yousri, D., Abd Elaziz, M., Ewees, A. A., Al-qaness, M. A., & Gandomi, A. H. (2021). Aquila Optimizer: A novel meta-heuristic optimization Algorithm. Computers & Industrial Engineering, 157, 107250.
+
+* **AVOA - African Vultures Optimization Algorithm**
+  * **OriginalAVOA**: Abdollahzadeh, B., Gharehchopogh, F. S., & Mirjalili, S. (2021). African vultures optimization algorithm: A new nature-inspired metaheuristic algorithm for global optimization problems. Computers & Industrial Engineering, 158, 107408.
+
+* **AGTO - Artificial Gorilla Troops Optimization**
+  * **OriginalAGTO**: Abdollahzadeh, B., Soleimanian Gharehchopogh, F., & Mirjalili, S. (2021). Artificial gorilla troops optimizer: a new natureâinspired metaheuristic algorithm for global optimization problems. International Journal of Intelligent Systems, 36(10), 5887-5958.
+
+* **ARO - Artificial Rabbits Optimization**:
+  * **OriginalARO**: Wang, L., Cao, Q., Zhang, Z., Mirjalili, S., & Zhao, W. (2022). Artificial rabbits optimization: A new bio-inspired meta-heuristic algorithm for solving engineering optimization problems. Engineering Applications of Artificial Intelligence, 114, 105082.
+
+
+
+### B
+
+
+* **BFO - Bacterial Foraging Optimization** 
+  * **OriginalBFO**: Passino, K. M. (2002). Biomimicry of bacterial foraging for distributed optimization and control. IEEE control systems magazine, 22(3), 52-67.
+  * **ABFO**: Nguyen, T., Nguyen, B. M., & Nguyen, G. (2019, April). Building resource auto-scaler with functional-link neural network and adaptive bacterial foraging optimization. In International Conference on Theory and Applications of Models of Computation (pp. 501-517). Springer, Cham.
+
+* **BeesA - Bees Algorithm** 
+  * **OriginalBeesA**: Pham, D. T., Ghanbarzadeh, A., Koc, E., Otri, S., Rahim, S., & Zaidi, M. (2005). The bees algorithm. Technical Note, Manufacturing Engineering Centre, Cardiff University, UK.
+  * **ProbBeesA**: The probabilitic version of: Pham, D. T., Ghanbarzadeh, A., KoÃ§, E., Otri, S., Rahim, S., & Zaidi, M. (2006). The bees algorithmâa novel tool for complex optimisation problems. In Intelligent production machines and systems (pp. 454-459). Elsevier Science Ltd.
+  
+* **BBO - Biogeography-Based Optimization** 
+  * **OriginalBBO**: Simon, D. (2008). Biogeography-based optimization. IEEE transactions on evolutionary computation, 12(6), 702-713.
+  * **BaseBBO**: The developed version
+  
+* **BA - Bat Algorithm** 
+  * **OriginalBA**: Yang, X. S. (2010). A new metaheuristic bat-inspired algorithm. In Nature inspired cooperative strategies for optimization (NICSO 2010) (pp. 65-74). Springer, Berlin, Heidelberg.
+  * **AdaptiveBA**: Wang, X., Wang, W. and Wang, Y., 2013, July. An adaptive bat algorithm. In International Conference on Intelligent Computing(pp. 216-223). Springer, Berlin, Heidelberg.
+  * **ModifiedBA**: Dong, H., Li, T., Ding, R. and Sun, J., 2018. A novel hybrid genetic algorithm with granular information for feature selection and optimization. Applied Soft Computing, 65, pp.33-46.
+
+* **BSO - Brain Storm Optimization** 
+  * **OriginalBSO**: . Shi, Y. (2011, June). Brain storm optimization algorithm. In International conference in swarm intelligence (pp. 303-309). Springer, Berlin, Heidelberg.
+  * **ImprovedBSO**: El-Abd, M., 2017. Global-best brain storm optimization algorithm. Swarm and evolutionary computation, 37, pp.27-44.
+
+* **BSA - Bird Swarm Algorithm** 
+  * **OriginalBSA**: Meng, X. B., Gao, X. Z., Lu, L., Liu, Y., & Zhang, H. (2016). A new bio-inspired optimisation algorithm:Bird Swarm Algorithm. Journal of Experimental & Theoretical Artificial Intelligence, 28(4), 673-687.
+
+* **BMO - Barnacles Mating Optimizer**:
+  * **OriginalBMO**: Sulaiman, M. H., Mustaffa, Z., Saari, M. M., Daniyal, H., Daud, M. R., Razali, S., & Mohamed, A. I. (2018, June). Barnacles mating optimizer: a bio-inspired algorithm for solving optimization problems. In 2018 19th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD) (pp. 265-270). IEEE.
+
+* **BES - Bald Eagle Search** 
+  * **OriginalBES**: Alsattar, H. A., Zaidan, A. A., & Zaidan, B. B. (2019). Novel meta-heuristic bald eagle search optimisation algorithm. Artificial Intelligence Review, 1-28.
+  
+* **BRO - Battle Royale Optimization**
+  * **OriginalBRO**: Rahkar Farshi, T. (2020). Battle royale optimization algorithm. Neural Computing and Applications, 1-19.
+  * **BaseBRO**: The developed version
+
+### C
+
+* **CA - Culture Algorithm** 
+  * **OriginalCA**: Reynolds, R.G., 1994, February. An introduction to cultural algorithms. In Proceedings of the third annual conference on evolutionary programming (Vol. 24, pp. 131-139). River Edge, NJ: World Scientific.
+
+* **CEM - Cross Entropy Method**
+  * **OriginalCEM**: Rubinstein, R. (1999). The cross-entropy method for combinatorial and continuous optimization. Methodology and computing in applied probability, 1(2), 127-190.
+  
+* **CSO - Cat Swarm Optimization** 
+  * **OriginalCSO**: Chu, S. C., Tsai, P. W., & Pan, J. S. (2006, August). Cat swarm optimization. In Pacific Rim international conference on artificial intelligence (pp. 854-858). Springer, Berlin, Heidelberg.
+
+* **CSA - Cuckoo Search Algorithm** 
+  * **OriginalCSA**: Yang, X. S., & Deb, S. (2009, December). Cuckoo search via LÃ©vy flights. In 2009 World congress on nature & biologically inspired computing (NaBIC) (pp. 210-214). Ieee.
+
+* **CRO - Coral Reefs Optimization** 
+  * **OriginalCRO**: Salcedo-Sanz, S., Del Ser, J., Landa-Torres, I., Gil-LÃ³pez, S., & Portilla-Figueras, J. A. (2014). The coral reefs optimization algorithm: a novel metaheuristic for efficiently solving optimization problems. The Scientific World Journal, 2014.
+  * **OCRO**: Nguyen, T., Nguyen, T., Nguyen, B. M., & Nguyen, G. (2019). Efficient time-series forecasting using neural network and opposition-based coral reefs optimization. International Journal of Computational Intelligence Systems, 12(2), 1144-1161.
+
+* **COA - Coyote Optimization Algorithm**
+  * **OriginalCOA**: Pierezan, J., & Coelho, L. D. S. (2018, July). Coyote optimization algorithm: a new metaheuristic for global optimization problems. In 2018 IEEE congress on evolutionary computation (CEC) (pp. 1-8). IEEE.
+
+* **CHIO - Coronavirus Herd Immunity Optimization**
+  * **OriginalCHIO**: Al-Betar, M. A., Alyasseri, Z. A. A., Awadallah, M. A., & Abu Doush, I. (2021). Coronavirus herd immunity optimizer (CHIO). Neural Computing and Applications, 33(10), 5011-5042.
+  * **BaseCHIO**: The developed version
+
+* **CGO - Chaos Game Optimization** 
+  * **OriginalCGO**: Talatahari, S., & Azizi, M. (2021). Chaos Game Optimization: a novel metaheuristic algorithm. Artificial Intelligence Review, 54(2), 917-1004.
+
+* **CSA - Circle Search Algorithm**
+  * **OriginalCSA**: Qais, M. H., Hasanien, H. M., Turky, R. A., Alghuwainem, S., Tostado-VÃ©liz, M., & Jurado, F. (2022). Circle Search Algorithm: A Geometry-Based Metaheuristic Optimization Algorithm. Mathematics, 10(10), 1626.
+
+### D
+
+* **DE - Differential Evolution** 
+  * **BaseDE**: Storn, R., & Price, K. (1997). Differential evolutionâa simple and efficient heuristic for global optimization over continuous spaces. Journal of global optimization, 11(4), 341-359.
+  * **JADE**: Zhang, J., & Sanderson, A. C. (2009). JADE: adaptive differential evolution with optional external archive. IEEE Transactions on evolutionary computation, 13(5), 945-958.
+  * **SADE**: Qin, A. K., & Suganthan, P. N. (2005, September). Self-adaptive differential evolution algorithm for numerical optimization. In 2005 IEEE congress on evolutionary computation (Vol. 2, pp. 1785-1791). IEEE.
+  * **SHADE**: Tanabe, R., & Fukunaga, A. (2013, June). Success-history based parameter adaptation for differential evolution. In 2013 IEEE congress on evolutionary computation (pp. 71-78). IEEE.
+  * **L_SHADE**: Tanabe, R., & Fukunaga, A. S. (2014, July). Improving the search performance of SHADE using linear population size reduction. In 2014 IEEE congress on evolutionary computation (CEC) (pp. 1658-1665). IEEE.
+  * **SAP_DE**: Teo, J. (2006). Exploring dynamic self-adaptive populations in differential evolution. Soft Computing, 10(8), 673-686.
+  
+* **DSA - Differential Search Algorithm (not done)** 
+  * **BaseDSA**: Civicioglu, P. (2012). Transforming geocentric cartesian coordinates to geodetic coordinates by using differential search algorithm. Computers & Geosciences, 46, 229-247.
+  
+* **DO - Dragonfly Optimization** 
+  * **OriginalDO**: Mirjalili, S. (2016). Dragonfly algorithm: a new meta-heuristic optimization technique for solving single-objective, discrete, and multi-objective problems. Neural Computing and Applications, 27(4), 1053-1073.
+
+* **DMOA - Dwarf Mongoose Optimization Algorithm**
+  * **OriginalDMOA**: Agushaka, J. O., Ezugwu, A. E., & Abualigah, L. (2022). Dwarf mongoose optimization algorithm. Computer methods in applied mechanics and engineering, 391, 114570.
+  * **DevDMOA**: The developed version
+
+### E
+
+* **ES - Evolution Strategies** . 
+  * **OriginalES**: Schwefel, H. P. (1984). Evolution strategies: A family of non-linear optimization techniques based on imitating some principles of organic evolution. Annals of Operations Research, 1(2), 165-167.
+  * **LevyES**: Zhang, S., & Salari, E. (2005). Competitive learning vector quantization with evolution strategies for image compression. Optical Engineering, 44(2), 027006.
+
+* **EP - Evolutionary programming** . 
+  * **OriginalEP**: Fogel, L. J. (1994). Evolutionary programming in perspective: The top-down view. Computational intelligence: Imitating life.
+  * **LevyEP**: Lee, C.Y. and Yao, X., 2001, May. Evolutionary algorithms with adaptive lÃ©vy mutations. In Proceedings of the 2001 congress on evolutionary computation (IEEE Cat. No. 01TH8546) (Vol. 1, pp. 568-575). IEEE.
+
+* **EHO - Elephant Herding Optimization** . 
+  * **OriginalEHO**: Wang, G. G., Deb, S., & Coelho, L. D. S. (2015, December). Elephant herding optimization. In 2015 3rd International Symposium on Computational and Business Intelligence (ISCBI) (pp. 1-5). IEEE.
+
+* **EFO - Electromagnetic Field Optimization** . 
+  * **OriginalEFO**:Abedinpourshotorban, H., Shamsuddin, S. M., Beheshti, Z., & Jawawi, D. N. (2016). Electromagnetic field optimization: A physics-inspired metaheuristic optimization algorithm. Swarm and Evolutionary Computation, 26, 8-22.
+  * **BaseEFO**: The developed version
+
+* **EOA - Earthworm Optimisation Algorithm** . 
+  * **OriginalEOA**: Wang, G. G., Deb, S., & dos Santos Coelho, L. (2018). Earthworm optimisation algorithm: a bio-inspired metaheuristic algorithm for global optimisation problems. IJBIC, 12(1), 1-22.
+
+* **EO - Equilibrium Optimizer** . 
+  * **OriginalEO**: Faramarzi, A., Heidarinejad, M., Stephens, B., & Mirjalili, S. (2019). Equilibrium optimizer: A novel optimization algorithm. Knowledge-Based Systems.
+  * **ModifiedEO**: Gupta, S., Deep, K., & Mirjalili, S. (2020). An efficient equilibrium optimizer with mutation strategy for numerical optimization. Applied Soft Computing, 96, 106542.
+  * **AdaptiveEO**: Wunnava, A., Naik, M. K., Panda, R., Jena, B., & Abraham, A. (2020). A novel interdependence based multilevel thresholding technique using adaptive equilibrium optimizer. Engineering Applications of Artificial Intelligence, 94, 103836.
+
+### F
+
+* **FFA - Firefly Algorithm** 
+  * **OriginalFFA**: Åukasik, S., & Å»ak, S. (2009, October). Firefly algorithm for continuous constrained optimization tasks. In International conference on computational collective intelligence (pp. 97-106). Springer, Berlin, Heidelberg.
+  
+* **FA - Fireworks algorithm** 
+  * **OriginalFA**: Tan, Y., & Zhu, Y. (2010, June). Fireworks algorithm for optimization. In International conference in swarm intelligence (pp. 355-364). Springer, Berlin, Heidelberg.
+
+* **FPA - Flower Pollination Algorithm** 
+  * **OriginalFPA**: Yang, X. S. (2012, September). Flower pollination algorithm for global optimization. In International conference on unconventional computing and natural computation (pp. 240-249). Springer, Berlin, Heidelberg.
+
+* **FOA - Fruit-fly Optimization Algorithm**
+  * **OriginalFOA**: Pan, W. T. (2012). A new fruit fly optimization algorithm: taking the financial distress model as an example. Knowledge-Based Systems, 26, 69-74.
+  * **BaseFOA**: The developed version
+  * **WhaleFOA**: Fan, Y., Wang, P., Heidari, A. A., Wang, M., Zhao, X., Chen, H., & Li, C. (2020). Boosted hunting-based fruit fly optimization and advances in real-world problems. Expert Systems with Applications, 159, 113502.
+
+* **FBIO - Forensic-Based Investigation Optimization** 
+  * **OriginalFBIO**: Chou, J.S. and Nguyen, N.M., 2020. FBI inspired meta-optimization. Applied Soft Computing, p.106339.
+  * **BaseFBIO**: Fathy, A., Rezk, H. and Alanazi, T.M., 2021. Recent approach of forensic-based investigation algorithm for optimizing fractional order PID-based MPPT with proton exchange membrane fuel cell.IEEE Access,9, pp.18974-18992.
+
+* **FHO - Fire Hawk Optimization**
+  * **OriginalFHO**: Azizi, M., Talatahari, S., & Gandomi, A. H. (2022). Fire Hawk Optimizer: a novel metaheuristic algorithm. Artificial Intelligence Review, 1-77.
+
+### G
+
+* **GA - Genetic Algorithm** 
+  * **BaseGA**: Holland, J. H. (1992). Genetic algorithms. Scientific american, 267(1), 66-73.
+  * **SingleGA**: De Falco, I., Della Cioppa, A. and Tarantino, E., 2002. Mutation-based genetic algorithm: performance evaluation.Â Applied Soft Computing,Â 1(4), pp.285-299.
+  * **MultiGA**: De Jong, K.A. and Spears, W.M., 1992. A formal analysis of the role of multi-point crossover in genetic algorithms.Â Annals of mathematics and Artificial intelligence,Â 5(1), pp.1-26.
+  * **EliteSingleGA**: Elite version of Single-point mutation GA
+  * **EliteMultiGA**: Elite version of Multiple-point mutation GA
+
+* **GWO - Grey Wolf Optimizer** 
+  * **OriginalGWO**: Mirjalili, S., Mirjalili, S. M., & Lewis, A. (2014). Grey wolf optimizer. Advances in engineering software, 69, 46-61.
+  * **RW_GWO**: Gupta, S., & Deep, K. (2019). A novel random walk grey wolf optimizer. Swarm and evolutionary computation, 44, 101-112.
+  * **GWO_WOA**: Obadina, O. O., Thaha, M. A., Althoefer, K., & Shaheed, M. H. (2022). Dynamic characterization of a masterâslave robotic manipulator using a hybrid grey wolfâwhale optimization algorithm. Journal of Vibration and Control, 28(15-16), 1992-2003.
+
+* **GOA - Grasshopper Optimisation Algorithm** 
+  * **OriginalGOA**: Saremi, S., Mirjalili, S., & Lewis, A. (2017). Grasshopper optimisation algorithm: theory and application. Advances in Engineering Software, 105, 30-47.
+
+* **GCO - Germinal Center Optimization** 
+  * **OriginalGCO**: VillaseÃ±or, C., Arana-Daniel, N., Alanis, A. Y., LÃ³pez-Franco, C., & Hernandez-Vargas, E. A. (2018). Germinal center optimization algorithm. International Journal of Computational Intelligence Systems, 12(1), 13-27.
+  * **BaseGCO**: The developed version
+
+* **GSKA - Gaining Sharing Knowledge-based Algorithm** 
+  * **OriginalGSKA**: Mohamed, A. W., Hadi, A. A., & Mohamed, A. K. (2019). Gaining-sharing knowledge based algorithm for solving optimization problems: a novel nature-inspired algorithm. International Journal of Machine Learning and Cybernetics, 1-29.
+  * **BaseGSKA**: Mohamed, A.W., Hadi, A.A., Mohamed, A.K. and Awad, N.H., 2020, July. Evaluating the performance of adaptive GainingSharing knowledge based algorithm on CEC 2020 benchmark problems. InÂ 2020 IEEE Congress on Evolutionary Computation (CEC)Â (pp. 1-8). IEEE.
+
+* **GBO - Gradient-Based Optimizer**
+  * **OriginalGBO**: Ahmadianfar, I., Bozorg-Haddad, O., & Chu, X. (2020). Gradient-based optimizer: A new metaheuristic optimization algorithm. Information Sciences, 540, 131-159.
+
+### H
+
+* **HC - Hill Climbing** . 
+  * **OriginalHC**: Talbi, E. G., & Muntean, T. (1993, January). Hill-climbing, simulated annealing and genetic algorithms: a comparative study and application to the mapping problem. In [1993] Proceedings of the Twenty-sixth Hawaii International Conference on System Sciences (Vol. 2, pp. 565-573). IEEE.
+  * **SwarmHC**: The developed version based on swarm-based idea (Original is single-solution based method)
+
+* **HS - Harmony Search** . 
+  * **OriginalHS**: Geem, Z. W., Kim, J. H., & Loganathan, G. V. (2001). A new heuristic optimization algorithm:harmony search. simulation, 76(2), 60-68.
+  * **BaseHS**: The developed version
+
+* **HHO - Harris Hawks Optimization** . 
+  * **OriginalHHO**: Heidari, A. A., Mirjalili, S., Faris, H., Aljarah, I., Mafarja, M., & Chen, H. (2019). Harris hawks optimization: Algorithm and applications. Future Generation Computer Systems, 97, 849-872.
+
+* **HGSO - Henry Gas Solubility Optimization** . 
+  * **OriginalHGSO**: Hashim, F. A., Houssein, E. H., Mabrouk, M. S., Al-Atabany, W., & Mirjalili, S. (2019). Henry gas solubility optimization: A novel physics-based algorithm. Future Generation Computer Systems, 101, 646-667.
+
+* **HGS - Hunger Games Search** . 
+  * **OriginalHGS**: Yang, Y., Chen, H., Heidari, A. A., & Gandomi, A. H. (2021). Hunger games search:Visions, conception, implementation, deep analysis, perspectives, and towards performance shifts. Expert Systems with Applications, 177, 114864.
+  
+* **HHOA - Horse Herd Optimization Algorithm (not done)** . 
+  * **BaseHHOA**: MiarNaeimi, F., Azizyan, G., & Rashki, M. (2021). Horse herd optimization algorithm: A nature-inspired algorithm for high-dimensional optimization problems. Knowledge-Based Systems, 213, 106711.
+  
+* **HBA - Honey Badger Algorithm**:
+  * **OriginalHBA**: Hashim, F. A., Houssein, E. H., Hussain, K., Mabrouk, M. S., & Al-Atabany, W. (2022). Honey Badger Algorithm: New metaheuristic algorithm for solving optimization problems. Mathematics and Computers in Simulation, 192, 84-110.
+
+
+### I
+
+* **IWO - Invasive Weed Optimization** . 
+  * **OriginalIWO**: Mehrabian, A. R., & Lucas, C. (2006). A novel numerical optimization algorithm inspired from weed colonization. Ecological informatics, 1(4), 355-366.
+
+* **ICA - Imperialist Competitive Algorithm** 
+  * **OriginalICA**: Atashpaz-Gargari, E., & Lucas, C. (2007, September). Imperialist competitive algorithm: an algorithm for optimization inspired by imperialistic competition. In 2007 IEEE congress on evolutionary computation (pp. 4661-4667). Ieee.
+
+* **INFO - weIghted meaN oF vectOrs**:
+  * **OriginalINFO**: Ahmadianfar, I., Heidari, A. A., Gandomi, A. H., Chu, X., & Chen, H. (2021). RUN beyond the metaphor: An efficient     optimization algorithm based on Runge Kutta method. Expert Systems with Applications, 181, 115079.
+
+### J
+
+* **JA - Jaya Algorithm** 
+  * **OriginalJA**: Rao, R. (2016). Jaya: A simple and new optimization algorithm for solving constrained and unconstrained optimization problems. International Journal of Industrial Engineering Computations, 7(1), 19-34.
+  * **BaseJA**: The developed version
+  * **LevyJA**: Iacca, G., dos Santos Junior, V. C., & de Melo, V. V. (2021). An improved Jaya optimization algorithm with Levy flight. Expert Systems with Applications, 165, 113902.
+
+### K
+
+### L
+
+* **LCO - Life Choice-based Optimization** 
+  * **OriginalLCO**: Khatri, A., Gaba, A., Rana, K. P. S., & Kumar, V. (2019). A novel life choice-based optimizer. Soft Computing, 1-21.
+  * **BaseLCO**: The developed version
+  * **ImprovedLCO**: The improved version using Gaussian distribution and Mutation Mechanism
+
+
+### M
+
+* **MA - Memetic Algorithm**
+  * **OriginalMA**: Moscato, P. (1989). On evolution, search, optimization, genetic algorithms and martial arts: Towards memetic algorithms. Caltech concurrent computation program, C3P Report, 826, 1989.
+
+* **MFO - Moth Flame Optimization** 
+  * **OriginalMFO**: Mirjalili, S. (2015). Moth-flame optimization algorithm: A novel nature-inspired heuristic paradigm. Knowledge-based systems, 89, 228-249.
+  * **BaseMFO**: The developed version
+
+* **MVO - Multi-Verse Optimizer** 
+  * **OriginalMVO**: Mirjalili, S., Mirjalili, S. M., & Hatamlou, A. (2016). Multi-verse optimizer: a nature-inspired algorithm for global optimization. Neural Computing and Applications, 27(2), 495-513.
+  * **BaseMVO**: The developed version
+
+* **MSA - Moth Search Algorithm** 
+  * **OriginalMSA**: Wang, G. G. (2018). Moth search algorithm: a bio-inspired metaheuristic algorithm for global optimization problems. Memetic Computing, 10(2), 151-164.
+  
+* **MRFO - Manta Ray Foraging Optimization** 
+  * **OriginalMRFO**: Zhao, W., Zhang, Z., & Wang, L. (2020). Manta ray foraging optimization: An effective bio-inspired optimizer for engineering applications. Engineering Applications of Artificial Intelligence, 87, 103300.
+
+* **MPA - Marine Predators Algorithm**:
+  * **OriginalMPA**: Faramarzi, A., Heidarinejad, M., Mirjalili, S., & Gandomi, A. H. (2020). Marine Predators Algorithm: A nature-inspired metaheuristic. Expert systems with applications, 152, 113377.
+
+
+### N
+
+
+* **NRO - Nuclear Reaction Optimization** 
+  * **OriginalNRO**: Wei, Z., Huang, C., Wang, X., Han, T., & Li, Y. (2019). Nuclear Reaction Optimization: A novel and powerful physics-based algorithm for global optimization. IEEE Access. 
+
+* **NMRA - Nake Mole-Rat Algorithm**
+  * **OriginalNMRA**: Salgotra, R., & Singh, U. (2019). The naked mole-rat algorithm. Neural Computing and Applications, 31(12), 8837-8857.
+  * **ImprovedNMRA**: Singh, P., Mittal, N., Singh, U. and Salgotra, R., 2021. Naked mole-rat algorithm with improved exploration and exploitation capabilities to determine 2D and 3D coordinates of sensor nodes in WSNs.Â Arabian Journal for Science and Engineering,Â 46(2), pp.1155-1178.
+
+
+### O
+
+### P
+
+* **PSO - Particle Swarm Optimization** 
+  * **OriginalPSO**: Eberhart, R., & Kennedy, J. (1995, October). A new optimizer using particle swarm theory. In MHS'95. Proceedings of the Sixth International Symposium on Micro Machine and Human Science (pp. 39-43). Ieee.
+  * **PPSO**: Ghasemi, M., Akbari, E., Rahimnejad, A., Razavi, S. E., Ghavidel, S., & Li, L. (2019). Phasor particle swarm optimization: a simple and efficient variant of PSO. Soft Computing, 23(19), 9701-9718.
+  * **HPSO_TVAC**: Ghasemi, M., Aghaei, J., & Hadipour, M. (2017). New self-organising hierarchical PSO with jumping time-varying acceleration coefficients. Electronics Letters, 53(20), 1360-1362.
+  * **C_PSO**: Liu, B., Wang, L., Jin, Y. H., Tang, F., & Huang, D. X. (2005). Improved particle swarm optimization combined with chaos. Chaos, Solitons & Fractals, 25(5), 1261-1271.
+  * **CL_PSO**: Liang, J. J., Qin, A. K., Suganthan, P. N., & Baskar, S. (2006). Comprehensive learning particle swarm optimizer for global optimization of multimodal functions. IEEE transactions on evolutionary computation, 10(3), 281-295.
+
+* **PFA - Pathfinder Algorithm** 
+  * **OriginalPFA**: Yapici, H., & Cetinkaya, N. (2019). A new meta-heuristic optimizer: Pathfinder algorithm. Applied Soft Computing, 78, 545-568.
+
+* **PSS - Pareto-like Sequential Sampling**
+  * **OriginalPSS**: Shaqfa, M., & Beyer, K. (2021). Pareto-like sequential sampling heuristic for global optimisation. Soft Computing, 25(14), 9077-9096.
+
+
+### Q
+
+* **QSA - Queuing Search Algorithm** 
+  * **OriginalQSA**: Zhang, J., Xiao, M., Gao, L., & Pan, Q. (2018). Queuing search algorithm: A novel metaheuristic algorithm for solving engineering optimization problems. Applied Mathematical Modelling, 63, 464-490.
+  * **BaseQSA**: The developed version
+  * **OppoQSA**: Zheng, X. and Nguyen, H., 2022. A novel artificial intelligent model for predicting water treatment efficiency of various biochar systems based on artificial neural network and queuing search algorithm. Chemosphere, 287, p.132251.
+  * **LevyQSA**: Abderazek, H., Hamza, F., Yildiz, A.R., Gao, L. and Sait, S.M., 2021. A comparative analysis of the queuing search algorithm, the sine-cosine algorithm, the ant lion algorithm to determine the optimal weight design problem of a spur gear drive system. Materials Testing, 63(5), pp.442-447.
+  * **ImprovedQSA**: Nguyen, B.M., Hoang, B., Nguyen, T. and Nguyen, G., 2021. nQSV-Net: a novel queuing search variant for global space search and workload modeling.Â Journal of Ambient Intelligence and Humanized Computing,Â 12(1), pp.27-46.
+
+### R
+
+* **RUN - RUNge Kutta optimizer**:
+  * **OriginalRUN**: Ahmadianfar, I., Heidari, A. A., Gandomi, A. H., Chu, X., & Chen, H. (2021). RUN beyond the metaphor: An efficient optimization algorithm based on Runge Kutta method. Expert Systems with Applications, 181, 115079.
+
+### S
+
+* **SA - Simulated Annealling** 
+  * **OriginalSA**: . Van Laarhoven, P. J., & Aarts, E. H. (1987). Simulated annealing. In Simulated annealing: Theory and applications (pp. 7-15). Springer, Dordrecht.
+
+* **SSpiderO - Social Spider Optimization** 
+  * **OriginalSSpiderO**: Cuevas, E., Cienfuegos, M., ZaldÃ­Var, D., & PÃ©rez-Cisneros, M. (2013). A swarm optimization algorithm inspired in the behavior of the social-spider. Expert Systems with Applications, 40(16), 6374-6384.
+
+* **SOS - Symbiotic Organisms Search**:
+  * **OriginalSOS**: Cheng, M. Y., & Prayogo, D. (2014). Symbiotic organisms search: a new metaheuristic optimization algorithm. Computers & Structures, 139, 98-112.
+
+* **SSpiderA - Social Spider Algorithm** 
+  * **OriginalSSpiderA**: James, J. Q., & Li, V. O. (2015). A social spider algorithm for global optimization. Applied Soft Computing, 30, 614-627.
+
+* **SCA - Sine Cosine Algorithm** 
+  * **OriginalSCA**: Mirjalili, S. (2016). SCA: a sine cosine algorithm for solving optimization problems. Knowledge-Based Systems, 96, 120-133.
+  * **BaseSCA**: Attia, A.F., El Sehiemy, R.A. and Hasanien, H.M., 2018. Optimal power flow solution in power systems using a novel Sine-Cosine algorithm.Â International Journal of Electrical Power & Energy Systems,Â 99, pp.331-343.
+
+* **SRSR - Swarm Robotics Search And Rescue** 
+  * **OriginalSRSR**: Bakhshipour, M., Ghadi, M. J., & Namdari, F. (2017). Swarm robotics search & rescue: A novel artificial intelligence-inspired optimization approach. Applied Soft Computing, 57, 708-726.
+
+* **SBO - Satin Bowerbird Optimizer** 
+  * **OriginalSBO**: Moosavi, S. H. S., & Bardsiri, V. K. (2017). Satin bowerbird optimizer: a new optimization algorithm to optimize ANFIS for software development effort estimation. Engineering Applications of Artificial Intelligence, 60, 1-15.
+  * **BaseSBO**: The developed version
+
+* **SHO - Spotted Hyena Optimizer**
+  * **OriginalSHO**: Dhiman, G., & Kumar, V. (2017). Spotted hyena optimizer: a novel bio-inspired based metaheuristic technique for engineering applications. Advances in Engineering Software, 114, 48-70.
+
+* **SSO - Salp Swarm Optimization**
+  * **OriginalSSO**: Mirjalili, S., Gandomi, A. H., Mirjalili, S. Z., Saremi, S., Faris, H., & Mirjalili, S. M. (2017). Salp Swarm Algorithm: A bio-inspired optimizer for engineering design problems. Advances in Engineering Software, 114, 163-191.
+
+* **SFO - Sailfish Optimizer** 
+  * **OriginalSFO**: Shadravan, S., Naji, H. R., & Bardsiri, V. K. (2019). The Sailfish Optimizer: A novel nature-inspired metaheuristic algorithm for solving constrained engineering optimization problems. Engineering Applications of Artificial Intelligence, 80, 20-34.
+  * **ImprovedSFO**: Li, L.L., Shen, Q., Tseng, M.L. and Luo, S., 2021. Power system hybrid dynamic economic emission dispatch with wind energy based on improved sailfish algorithm.Â Journal of Cleaner Production,Â 316, p.128318.
+
+* **SARO - Search And Rescue Optimization** 
+  * **OriginalSARO**: Shabani, A., Asgarian, B., Gharebaghi, S. A., Salido, M. A., & Giret, A. (2019). A New Optimization Algorithm Based on Search and Rescue Operations. Mathematical Problems in Engineering, 2019.
+  * **BaseSARO**: The developed version using Levy-flight
+
+* **SSDO - Social Ski-Driver Optimization** 
+  * **OriginalSSDO**: Tharwat, A., & Gabel, T. (2019). Parameters optimization of support vector machines for imbalanced data using social ski driver algorithm. Neural Computing and Applications, 1-14.
+
+* **SLO - Sea Lion Optimization**
+  * **OriginalSLO**: Masadeh, R., Mahafzah, B. A., & Sharieh, A. (2019). Sea Lion Optimization Algorithm. Sea, 10(5).
+  * **ImprovedSLO**: The developed version
+  * **ModifiedSLO**: Masadeh, R., Alsharman, N., Sharieh, A., Mahafzah, B.A. and Abdulrahman, A., 2021. Task scheduling on cloud computing based on sea lion optimization algorithm.Â International Journal of Web Information Systems.
+
+* **Seagull Optimization Algorithm**
+  * **OriginalSOA**: Dhiman, G., & Kumar, V. (2019). Seagull optimization algorithm: Theory and its applications for large-scale industrial engineering problems. Knowledge-based systems, 165, 169-196.
+  * **DevSOA**: The developed version
+
+* **SMA - Slime Mould Algorithm**
+  * **OriginalSMA**: Li, S., Chen, H., Wang, M., Heidari, A. A., & Mirjalili, S. (2020). Slime mould algorithm: A new method for stochastic optimization. Future Generation Computer Systems.
+  * **BaseSMA**: The developed version
+
+* **SSA - Sparrow Search Algorithm** 
+  * **OriginalSSA**: Jiankai Xue & Bo Shen (2020) A novel swarm intelligence optimization approach: sparrow search algorithm, Systems Science & Control Engineering, 8:1, 22-34, DOI: 10.1080/21642583.2019.1708830
+  * **BaseSSA**: The developed version
+
+* **SPBO - Student Psychology Based Optimization**
+  * **OriginalSPBO**: Das, B., Mukherjee, V., & Das, D. (2020). Student psychology based optimization algorithm: A new population based optimization algorithm for solving optimization problems. Advances in Engineering software, 146, 102804.
+  * **DevSPBO**: The developed version
+
+* **SCSO - Sand Cat Swarm Optimization**
+  * **OriginalSCSO**: Seyyedabbasi, A., & Kiani, F. (2022). Sand Cat swarm optimization: a nature-inspired algorithm to solve global optimization problems. Engineering with Computers, 1-25.
+
+### T
+
+* **TLO - Teaching Learning Optimization** 
+  * **OriginalTLO**: Rao, R. V., Savsani, V. J., & Vakharia, D. P. (2011). Teachingâlearning-based optimization: a novel method for constrained mechanical design optimization problems. Computer-Aided Design, 43(3), 303-315.
+  * **BaseTLO**: Rao, R., & Patel, V. (2012). An elitist teaching-learning-based optimization algorithm for solving complex constrained optimization problems. International Journal of Industrial Engineering Computations, 3(4), 535-560.
+  * **ImprovedTLO**: Rao, R. V., & Patel, V. (2013). An improved teaching-learning-based optimization algorithm for solving unconstrained optimization problems. Scientia Iranica, 20(3), 710-720.
+
+* **TWO - Tug of War Optimization** 
+  * **OriginalTWO**: Kaveh, A., & Zolghadr, A. (2016). A novel meta-heuristic algorithm: tug of war optimization. Iran University of Science & Technology, 6(4), 469-492.
+  * **OppoTWO**: Kaveh, A., Almasi, P. and Khodagholi, A., 2022. Optimum Design of Castellated Beams Using Four Recently Developed Meta-heuristic Algorithms.Â Iranian Journal of Science and Technology, Transactions of Civil Engineering, pp.1-13.
+  * **LevyTWO**: The developed version using Levy-flight
+  * **ImprovedTWO**: Nguyen, T., Hoang, B., Nguyen, G., & Nguyen, B. M. (2020). A new workload prediction model using extreme learning machine and enhanced tug of war optimization. Procedia Computer Science, 170, 362-369.
+
+* **TSA - Tunicate Swarm Algorithm**
+  * **OriginalTSA**: Kaur, S., Awasthi, L. K., Sangal, A. L., & Dhiman, G. (2020). Tunicate Swarm Algorithm: A new bio-inspired based metaheuristic paradigm for global optimization. Engineering Applications of Artificial Intelligence, 90, 103541.
+
+* **TSO - Tuna Swarm Optimization**
+  * **OriginalTSO**: Xie, L., Han, T., Zhou, H., Zhang, Z. R., Han, B., & Tang, A. (2021). Tuna swarm optimization: a novel swarm-based metaheuristic algorithm for global optimization. Computational intelligence and Neuroscience, 2021.
+
+
+### U
+
+### V
+
+* **VCS - Virus Colony Search** 
+  * **OriginalVCS**: Li, M. D., Zhao, H., Weng, X. W., & Han, T. (2016). A novel nature-inspired algorithm for optimization: Virus colony search. Advances in Engineering Software, 92, 65-88.
+  * **BaseVCS**: The developed version
+
+### W
+
+* **WCA - Water Cycle Algorithm** 
+  * **OriginalWCA**: Eskandar, H., Sadollah, A., Bahreininejad, A., & Hamdi, M. (2012). Water cycle algorithmâA novel metaheuristic optimization method for solving constrained engineering optimization problems. Computers & Structures, 110, 151-166.
+  
+* **WOA - Whale Optimization Algorithm** 
+  * **OriginalWOA**: Mirjalili, S., & Lewis, A. (2016). The whale optimization algorithm. Advances in engineering software, 95, 51-67.
+  * **HI_WOA**: Tang, C., Sun, W., Wu, W., & Xue, M. (2019, July). A hybrid improved whale optimization algorithm. In 2019 IEEE 15th International Conference on Control and Automation (ICCA) (pp. 362-367). IEEE.
+
+* **WHO - Wildebeest Herd Optimization** 
+  * **OriginalWHO**: Amali, D., & Dinakaran, M. (2019). Wildebeest herd optimization: A new global optimization algorithm inspired by wildebeest herding behaviour. Journal of Intelligent & Fuzzy Systems, (Preprint), 1-14.
+
+* **WDO - Wind Driven Optimization** 
+  * **OriginalWDO**: Bayraktar, Z., Komurcu, M., & Werner, D. H. (2010, July). Wind Driven Optimization (WDO): A novel nature-inspired optimization algorithm and its application to electromagnetics. In 2010 IEEE antennas and propagation society international symposium (pp. 1-4). IEEE.
+
+
+### X
+
+### Y
+
+### Z
```

### Comparing `mealpy-2.5.3/mealpy/__init__.py` & `mealpy-2.5.3a1/mealpy/__init__.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,48 +1,48 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 16:19, 16/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-#
-# Examples:
-# >>>
-# >>> from mealpy.swarm_based import PSO
-# >>> import numpy as np
-# >>>
-# >>> def fitness_function(solution):
-# >>>     return np.sum(solution ** 2)
-# >>>
-# >>> problem = {
-# >>>    "fit_func": fitness_function,
-# >>>    "lb": [-100, ] * 30,
-# >>>    "ub": [100, ] * 30,
-# >>>    "minmax": "min",
-# >>>    "save_population": True,
-# >>>    "log_to": "file",
-# >>>    "log_file": "mealpy.log",
-# >>>    "name": Square",
-# >>> }
-# >>>
-# >>> ## Run the algorithm
-# >>> model = PSO.C_PSO(epoch=5, pop_size=50, name="C-PSO")
-# >>> best_position, best_fitness = model.solve(problem)
-# >>> print(f"Best solution: {best_position}, Best fitness: {best_fitness}")
-
-
-__version__ = "2.5.3"
-
-from .bio_based import (BBO, BBOA, BMO, EOA, IWO, SBO, SMA, SOA, SOS, TPO, TSA, VCS, WHO)
-from .evolutionary_based import (CRO, DE, EP, ES, FPA, GA, MA)
-from .human_based import (BRO, BSO, CA, CHIO, FBIO, GSKA, HBO, HCO, ICA, LCO, QSA, SARO, SPBO, SSDO, TLO, TOA, WarSO)
-from .math_based import (AOA, CEM, CGO, CircleSA, GBO, HC, INFO, PSS, RUN, SCA, SHIO)
-from .physics_based import (ArchOA, ASO, CDO, EFO, EO, EVO, FLA, HGSO, MVO, NRO, RIME, SA, TWO, WDO)
-from .swarm_based import (ABC, ACOR, AGTO, ALO, AO, ARO, AVOA, BA, BeesA, BES, BFO, BSA, COA, CoatiOA, CSA, CSO,
-                          DMOA, DO, EHO, ESOA, FA, FFA, FFO, FOA, FOX, GJO, GOA, GTO, GWO, HBA, HGS, HHO, JA,
-                          MFO, MGO, MPA, MRFO, MSA, NGO, NMRA, OOA, PFA, POA, PSO, SCSO, SeaHO, ServalOA, SFO,
-                          SHO, SLO, SRSR, SSA, SSO, SSpiderA, SSpiderO, STO, TDO, TSO, WaOA, WOA, ZOA)
-from .system_based import AEO, GCO, WCA
-from .music_based import HS
-from .utils.problem import Problem
-from .utils.termination import Termination
-from .tuner import Tuner
-from .multitask import Multitask
+#!/usr/bin/env python
+# Created by "Thieu" at 16:19, 16/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+#
+# Examples:
+# >>>
+# >>> from mealpy.swarm_based import PSO
+# >>> import numpy as np
+# >>>
+# >>> def fitness_function(solution):
+# >>>     return np.sum(solution ** 2)
+# >>>
+# >>> problem = {
+# >>>    "fit_func": fitness_function,
+# >>>    "lb": [-100, ] * 30,
+# >>>    "ub": [100, ] * 30,
+# >>>    "minmax": "min",
+# >>>    "save_population": True,
+# >>>    "log_to": "file",
+# >>>    "log_file": "mealpy.log",
+# >>>    "name": Square",
+# >>> }
+# >>>
+# >>> ## Run the algorithm
+# >>> model = PSO.C_PSO(epoch=5, pop_size=50, name="C-PSO")
+# >>> best_position, best_fitness = model.solve(problem)
+# >>> print(f"Best solution: {best_position}, Best fitness: {best_fitness}")
+
+
+__version__ = "2.5.3-alpha.1"
+
+from .bio_based import (BBO, BBOA, BMO, EOA, IWO, SBO, SMA, SOA, SOS, TPO, TSA, VCS, WHO)
+from .evolutionary_based import (CRO, DE, EP, ES, FPA, GA, MA)
+from .human_based import (BRO, BSO, CA, CHIO, FBIO, GSKA, HBO, HCO, ICA, LCO, QSA, SARO, SPBO, SSDO, TLO, TOA, WarSO)
+from .math_based import (AOA, CEM, CGO, CircleSA, GBO, HC, INFO, PSS, RUN, SCA, SHIO)
+from .physics_based import (ArchOA, ASO, CDO, EFO, EO, EVO, FLA, HGSO, MVO, NRO, RIME, SA, TWO, WDO)
+from .swarm_based import (ABC, ACOR, AGTO, ALO, AO, ARO, AVOA, BA, BeesA, BES, BFO, BSA, COA, CoatiOA, CSA, CSO,
+                          DMOA, DO, EHO, ESOA, FA, FFA, FFO, FOA, FOX, GJO, GOA, GTO, GWO, HBA, HGS, HHO, JA,
+                          MFO, MGO, MPA, MRFO, MSA, NGO, NMRA, OOA, PFA, POA, PSO, SCSO, SeaHO, ServalOA, SFO,
+                          SHO, SLO, SRSR, SSA, SSO, SSpiderA, SSpiderO, STO, TDO, TSO, WaOA, WOA, ZOA)
+from .system_based import AEO, GCO, WCA
+from .music_based import HS
+from .utils.problem import Problem
+from .utils.termination import Termination
+from .tuner import Tuner
+from .multitask import Multitask
```

### Comparing `mealpy-2.5.3/mealpy/bio_based/BBO.py` & `mealpy-2.5.3a1/mealpy/bio_based/BBO.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,183 +1,183 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 12:24, 18/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalBBO(Optimizer):
-    """
-    The original version of: Biogeography-Based Optimization (BBO)
-
-    Links:
-        1. https://ieeexplore.ieee.org/abstract/document/4475427
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + p_m (float): (0, 1) -> better [0.01, 0.2], Mutation probability
-        + elites (int): (2, pop_size/2) -> better [2, 5], Number of elites will be keep for next generation
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.bio_based.BBO import OriginalBBO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> p_m = 0.01
-    >>> elites = 2
-    >>> model = OriginalBBO(epoch, pop_size, p_m, elites)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Simon, D., 2008. Biogeography-based optimization. IEEE transactions on evolutionary computation, 12(6), pp.702-713.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, p_m=0.01, elites=2, **kwargs):
-        """
-        Initialize the algorithm components.
-
-        Args:
-            epoch (int): Maximum number of iterations, default = 10000
-            pop_size (int): Number of population size, default = 100
-            p_m (float): Mutation probability, default=0.01
-            elites (int): Number of elites will be keep for next generation, default=2
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.p_m = self.validator.check_float("p_m", p_m, (0, 1.0))
-        self.elites = self.validator.check_int("elites", elites, [2, int(self.pop_size / 2)])
-        self.set_parameters(["epoch", "pop_size", "p_m", "elites"])
-        self.sort_flag = False
-        self.mu = (self.pop_size + 1 - np.array(range(1, self.pop_size + 1))) / (self.pop_size + 1)
-        self.mr = 1 - self.mu
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        _, pop_elites, _ = self.get_special_solutions(self.pop, best=self.elites)
-        pop = []
-        for idx in range(0, self.pop_size):
-            # Probabilistic migration to the i-th position
-            pos_new = deepcopy(self.pop[idx][self.ID_POS])
-            for j in range(self.problem.n_dims):
-                if np.random.uniform() < self.mr[idx]:  # Should we immigrate?
-                    # Pick a position from which to emigrate (roulette wheel selection)
-                    random_number = np.random.uniform() * np.sum(self.mu)
-                    select = self.mu[0]
-                    select_index = 0
-                    while (random_number > select) and (select_index < self.pop_size - 1):
-                        select_index += 1
-                        select += self.mu[select_index]
-                    # this is the migration step
-                    pos_new[j] = self.pop[select_index][self.ID_POS][j]
-
-            noise = np.random.uniform(self.problem.lb, self.problem.ub)
-            condition = np.random.random(self.problem.n_dims) < self.p_m
-            pos_new = np.where(condition, noise, pos_new)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop = self.update_target_wrapper_population(pop)
-            self.pop = self.greedy_selection_population(self.pop, pop)
-        # replace the solutions with their new migrated and mutated versions then Merge Populations
-        self.pop = self.get_sorted_strim_population(self.pop + pop_elites, self.pop_size)
-
-
-class BaseBBO(OriginalBBO):
-    """
-    The developed version: Biogeography-Based Optimization (BBO)
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + p_m (float): (0, 1) -> better [0.01, 0.2], Mutation probability
-        + elites (int): (2, pop_size/2) -> better [2, 5], Number of elites will be keep for next generation
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.bio_based.BBO import BaseBBO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> p_m = 0.01
-    >>> elites = 2
-    >>> model = BaseBBO(epoch, pop_size, p_m, elites)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, p_m=0.01, elites=2, **kwargs):
-        """
-        Initialize the algorithm components.
-
-        Args:
-            epoch (int): Maximum number of iterations, default = 10000
-            pop_size (int): Number of population size, default = 100
-            p_m (float): Mutation probability, default=0.01
-            elites (int): Number of elites will be keep for next generation, default=2
-        """
-        super().__init__(epoch, pop_size, p_m, elites, **kwargs)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        _, pop_elites, _ = self.get_special_solutions(self.pop, best=self.elites)
-        list_fitness = [agent[self.ID_TAR][self.ID_FIT] for agent in self.pop]
-        pop = []
-        for idx in range(0, self.pop_size):
-            # Probabilistic migration to the i-th position
-            # Pick a position from which to emigrate (roulette wheel selection)
-            idx_selected = self.get_index_roulette_wheel_selection(list_fitness)
-            # this is the migration step
-            condition = np.random.random(self.problem.n_dims) < self.mr[idx]
-            pos_new = np.where(condition, self.pop[idx_selected][self.ID_POS], self.pop[idx][self.ID_POS])
-            # Mutation
-            mutated = np.random.uniform(self.problem.lb, self.problem.ub)
-            pos_new = np.where(np.random.random(self.problem.n_dims) < self.p_m, mutated, pos_new)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop = self.update_target_wrapper_population(pop)
-            self.pop = self.greedy_selection_population(self.pop, pop)
-        # Replace the solutions with their new migrated and mutated versions then merge populations
-        self.pop = self.get_sorted_strim_population(self.pop + pop_elites, self.pop_size)
+#!/usr/bin/env python
+# Created by "Thieu" at 12:24, 18/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalBBO(Optimizer):
+    """
+    The original version of: Biogeography-Based Optimization (BBO)
+
+    Links:
+        1. https://ieeexplore.ieee.org/abstract/document/4475427
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + p_m (float): (0, 1) -> better [0.01, 0.2], Mutation probability
+        + elites (int): (2, pop_size/2) -> better [2, 5], Number of elites will be keep for next generation
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.bio_based.BBO import OriginalBBO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> p_m = 0.01
+    >>> elites = 2
+    >>> model = OriginalBBO(epoch, pop_size, p_m, elites)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Simon, D., 2008. Biogeography-based optimization. IEEE transactions on evolutionary computation, 12(6), pp.702-713.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, p_m=0.01, elites=2, **kwargs):
+        """
+        Initialize the algorithm components.
+
+        Args:
+            epoch (int): Maximum number of iterations, default = 10000
+            pop_size (int): Number of population size, default = 100
+            p_m (float): Mutation probability, default=0.01
+            elites (int): Number of elites will be keep for next generation, default=2
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.p_m = self.validator.check_float("p_m", p_m, (0, 1.0))
+        self.elites = self.validator.check_int("elites", elites, [2, int(self.pop_size / 2)])
+        self.set_parameters(["epoch", "pop_size", "p_m", "elites"])
+        self.sort_flag = False
+        self.mu = (self.pop_size + 1 - np.array(range(1, self.pop_size + 1))) / (self.pop_size + 1)
+        self.mr = 1 - self.mu
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        _, pop_elites, _ = self.get_special_solutions(self.pop, best=self.elites)
+        pop = []
+        for idx in range(0, self.pop_size):
+            # Probabilistic migration to the i-th position
+            pos_new = deepcopy(self.pop[idx][self.ID_POS])
+            for j in range(self.problem.n_dims):
+                if np.random.uniform() < self.mr[idx]:  # Should we immigrate?
+                    # Pick a position from which to emigrate (roulette wheel selection)
+                    random_number = np.random.uniform() * np.sum(self.mu)
+                    select = self.mu[0]
+                    select_index = 0
+                    while (random_number > select) and (select_index < self.pop_size - 1):
+                        select_index += 1
+                        select += self.mu[select_index]
+                    # this is the migration step
+                    pos_new[j] = self.pop[select_index][self.ID_POS][j]
+
+            noise = np.random.uniform(self.problem.lb, self.problem.ub)
+            condition = np.random.random(self.problem.n_dims) < self.p_m
+            pos_new = np.where(condition, noise, pos_new)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop = self.update_target_wrapper_population(pop)
+            self.pop = self.greedy_selection_population(self.pop, pop)
+        # replace the solutions with their new migrated and mutated versions then Merge Populations
+        self.pop = self.get_sorted_strim_population(self.pop + pop_elites, self.pop_size)
+
+
+class BaseBBO(OriginalBBO):
+    """
+    The developed version: Biogeography-Based Optimization (BBO)
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + p_m (float): (0, 1) -> better [0.01, 0.2], Mutation probability
+        + elites (int): (2, pop_size/2) -> better [2, 5], Number of elites will be keep for next generation
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.bio_based.BBO import BaseBBO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> p_m = 0.01
+    >>> elites = 2
+    >>> model = BaseBBO(epoch, pop_size, p_m, elites)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, p_m=0.01, elites=2, **kwargs):
+        """
+        Initialize the algorithm components.
+
+        Args:
+            epoch (int): Maximum number of iterations, default = 10000
+            pop_size (int): Number of population size, default = 100
+            p_m (float): Mutation probability, default=0.01
+            elites (int): Number of elites will be keep for next generation, default=2
+        """
+        super().__init__(epoch, pop_size, p_m, elites, **kwargs)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        _, pop_elites, _ = self.get_special_solutions(self.pop, best=self.elites)
+        list_fitness = [agent[self.ID_TAR][self.ID_FIT] for agent in self.pop]
+        pop = []
+        for idx in range(0, self.pop_size):
+            # Probabilistic migration to the i-th position
+            # Pick a position from which to emigrate (roulette wheel selection)
+            idx_selected = self.get_index_roulette_wheel_selection(list_fitness)
+            # this is the migration step
+            condition = np.random.random(self.problem.n_dims) < self.mr[idx]
+            pos_new = np.where(condition, self.pop[idx_selected][self.ID_POS], self.pop[idx][self.ID_POS])
+            # Mutation
+            mutated = np.random.uniform(self.problem.lb, self.problem.ub)
+            pos_new = np.where(np.random.random(self.problem.n_dims) < self.p_m, mutated, pos_new)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop = self.update_target_wrapper_population(pop)
+            self.pop = self.greedy_selection_population(self.pop, pop)
+        # Replace the solutions with their new migrated and mutated versions then merge populations
+        self.pop = self.get_sorted_strim_population(self.pop + pop_elites, self.pop_size)
```

### Comparing `mealpy-2.5.3/mealpy/bio_based/BBOA.py` & `mealpy-2.5.3a1/mealpy/bio_based/BBOA.py`

 * *Ordering differences only*

 * *Files 9% similar despite different names*

```diff
@@ -1,101 +1,101 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 12:51, 18/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalBBOA(Optimizer):
-    """
-    The original version of: Brown-Bear Optimization Algorithm (BBOA)
-
-    Links:
-        1. https://www.mathworks.com/matlabcentral/fileexchange/125490-brown-bear-optimization-algorithm
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.bio_based.BBOA import OriginalBBOA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalBBOA(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Prakash, T., Singh, P. P., Singh, V. P., & Singh, S. N. (2023). A Novel Brown-bear Optimization
-    Algorithm for Solving Economic Dispatch Problem. In Advanced Control & Optimization Paradigms for
-    Energy System Operation and Management (pp. 137-164). River Publishers.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pp = (epoch+1) / self.epoch
-
-        ## Pedal marking behaviour
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            if pp <= (epoch+1)/3:           # Gait while walking
-                pos_new = self.pop[idx][self.ID_POS] + (-pp * np.random.rand(self.problem.n_dims) * self.pop[idx][self.ID_POS])
-            elif (epoch+1)/3 < pp <= 2*(epoch+1)/3:     # Careful Stepping
-                qq = pp * np.random.rand(self.problem.n_dims)
-                pos_new = self.pop[idx][self.ID_POS] + (qq * (self.g_best[self.ID_POS] - np.random.randint(1, 3) * self.g_worst[self.ID_POS]))
-            else:
-                ww = 2 * pp * np.pi * np.random.rand(self.problem.n_dims)
-                pos_new = self.pop[idx][self.ID_POS] + (ww*self.g_best[self.ID_POS] - np.abs(self.pop[idx][self.ID_POS])) - (ww*self.g_worst[self.ID_POS] - np.abs(self.pop[idx][self.ID_POS]))
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-        ## Sniffing of pedal marks
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            kk = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
-            if self.compare_agent(self.pop[idx], self.pop[kk]):
-                pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (self.pop[idx][self.ID_POS] - self.pop[kk][self.ID_POS])
-            else:
-                pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (self.pop[kk][self.ID_POS] - self.pop[idx][self.ID_POS])
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 12:51, 18/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalBBOA(Optimizer):
+    """
+    The original version of: Brown-Bear Optimization Algorithm (BBOA)
+
+    Links:
+        1. https://www.mathworks.com/matlabcentral/fileexchange/125490-brown-bear-optimization-algorithm
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.bio_based.BBOA import OriginalBBOA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalBBOA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Prakash, T., Singh, P. P., Singh, V. P., & Singh, S. N. (2023). A Novel Brown-bear Optimization
+    Algorithm for Solving Economic Dispatch Problem. In Advanced Control & Optimization Paradigms for
+    Energy System Operation and Management (pp. 137-164). River Publishers.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pp = (epoch+1) / self.epoch
+
+        ## Pedal marking behaviour
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            if pp <= (epoch+1)/3:           # Gait while walking
+                pos_new = self.pop[idx][self.ID_POS] + (-pp * np.random.rand(self.problem.n_dims) * self.pop[idx][self.ID_POS])
+            elif (epoch+1)/3 < pp <= 2*(epoch+1)/3:     # Careful Stepping
+                qq = pp * np.random.rand(self.problem.n_dims)
+                pos_new = self.pop[idx][self.ID_POS] + (qq * (self.g_best[self.ID_POS] - np.random.randint(1, 3) * self.g_worst[self.ID_POS]))
+            else:
+                ww = 2 * pp * np.pi * np.random.rand(self.problem.n_dims)
+                pos_new = self.pop[idx][self.ID_POS] + (ww*self.g_best[self.ID_POS] - np.abs(self.pop[idx][self.ID_POS])) - (ww*self.g_worst[self.ID_POS] - np.abs(self.pop[idx][self.ID_POS]))
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+        ## Sniffing of pedal marks
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            kk = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
+            if self.compare_agent(self.pop[idx], self.pop[kk]):
+                pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (self.pop[idx][self.ID_POS] - self.pop[kk][self.ID_POS])
+            else:
+                pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (self.pop[kk][self.ID_POS] - self.pop[idx][self.ID_POS])
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/bio_based/BMO.py` & `mealpy-2.5.3a1/mealpy/bio_based/BMO.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,78 +1,78 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 11:10, 15/10/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalBMO(Optimizer):
-    """
-    The original version: Barnacles Mating Optimizer (BMO)
-
-    Links:
-        1. https://ieeexplore.ieee.org/document/8441097
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + pl (int): [1, pop_size - 1], barnacleâs threshold
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.bio_based.BMO import OriginalBMO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> pl = 4
-    >>> model = OriginalBMO(epoch, pop_size, pl)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Wang, G.G., Deb, S. and Coelho, L.D.S., 2018. Earthworm optimisation algorithm: a bio-inspired metaheuristic algorithm
-    for global optimisation problems. International journal of bio-inspired computation, 12(1), pp.1-22.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, pl=5, **kwargs):
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.pl = self.validator.check_int("pl", pl, [1, self.pop_size-1])
-        self.set_parameters(["epoch", "pop_size", "pl"])
-        self.sort_flag = True
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        k1 = np.random.permutation(self.pop_size)
-        k2 = np.random.permutation(self.pop_size)
-        temp = np.abs(k1 - k2)
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            if temp[idx] <= self.pl:
-                p = np.random.uniform(0, 1)
-                pos_new = p * self.pop[k1[idx]][self.ID_POS] + (1 - p) * self.pop[k2[idx]][self.ID_POS]
-            else:
-                pos_new = np.random.uniform(0, 1) * self.pop[k2[idx]][self.ID_POS]
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        self.pop = self.update_target_wrapper_population(pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 11:10, 15/10/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalBMO(Optimizer):
+    """
+    The original version: Barnacles Mating Optimizer (BMO)
+
+    Links:
+        1. https://ieeexplore.ieee.org/document/8441097
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + pl (int): [1, pop_size - 1], barnacleâs threshold
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.bio_based.BMO import OriginalBMO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> pl = 4
+    >>> model = OriginalBMO(epoch, pop_size, pl)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Wang, G.G., Deb, S. and Coelho, L.D.S., 2018. Earthworm optimisation algorithm: a bio-inspired metaheuristic algorithm
+    for global optimisation problems. International journal of bio-inspired computation, 12(1), pp.1-22.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, pl=5, **kwargs):
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.pl = self.validator.check_int("pl", pl, [1, self.pop_size-1])
+        self.set_parameters(["epoch", "pop_size", "pl"])
+        self.sort_flag = True
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        k1 = np.random.permutation(self.pop_size)
+        k2 = np.random.permutation(self.pop_size)
+        temp = np.abs(k1 - k2)
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            if temp[idx] <= self.pl:
+                p = np.random.uniform(0, 1)
+                pos_new = p * self.pop[k1[idx]][self.ID_POS] + (1 - p) * self.pop[k2[idx]][self.ID_POS]
+            else:
+                pos_new = np.random.uniform(0, 1) * self.pop[k2[idx]][self.ID_POS]
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        self.pop = self.update_target_wrapper_population(pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/bio_based/EOA.py` & `mealpy-2.5.3a1/mealpy/bio_based/EOA.py`

 * *Ordering differences only*

 * *Files 9% similar despite different names*

```diff
@@ -1,160 +1,160 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 14:52, 17/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalEOA(Optimizer):
-    """
-    The developed version: Earthworm Optimisation Algorithm (EOA)
-
-    Links:
-        1. http://doi.org/10.1504/IJBIC.2015.10004283
-        2. https://www.mathworks.com/matlabcentral/fileexchange/53479-earthworm-optimization-algorithm-ewa
-
-    Notes
-    ~~~~~
-    The original version from matlab code above will not work well, even with small dimensions.
-    I change updating process, change cauchy process using x_mean, use global best solution
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + p_c (float): (0, 1) -> better [0.5, 0.95], crossover probability
-        + p_m (float): (0, 1) -> better [0.01, 0.2], initial mutation probability
-        + n_best (int): (2, pop_size/2) -> better [2, 5], how many of the best earthworm to keep from one generation to the next
-        + alpha (float): (0, 1) -> better [0.8, 0.99], similarity factor
-        + beta (float): (0, 1) -> better [0.8, 1.0], the initial proportional factor
-        + gamma (float): (0, 1) -> better [0.8, 0.99], a constant that is similar to cooling factor of a cooling schedule in the simulated annealing.
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.bio_based.EOA import OriginalEOA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> p_c = 0.9
-    >>> p_m = 0.01
-    >>> n_best = 2
-    >>> alpha = 0.98
-    >>> beta = 0.9
-    >>> gamma = 0.9
-    >>> model = OriginalEOA(epoch, pop_size, p_c, p_m, n_best, alpha, beta, gamma)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Wang, G.G., Deb, S. and Coelho, L.D.S., 2018. Earthworm optimisation algorithm: a bio-inspired metaheuristic algorithm
-    for global optimisation problems. International journal of bio-inspired computation, 12(1), pp.1-22.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, p_c=0.9, p_m=0.01, n_best=2, alpha=0.98, beta=0.9, gamma=0.9, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            p_c (float): default = 0.9, crossover probability
-            p_m (float): default = 0.01 initial mutation probability
-            n_best (int): default = 2, how many of the best earthworm to keep from one generation to the next
-            alpha (float): default = 0.98, similarity factor
-            beta (float): default = 0.9, the initial proportional factor
-            gamma (float): default = 0.9, a constant that is similar to cooling factor of a cooling schedule in the simulated annealing.
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.p_c = self.validator.check_float("p_c", p_c, (0, 1.0))
-        self.p_m = self.validator.check_float("p_m", p_m, (0, 1.0))
-        self.n_best = self.validator.check_int("n_best", n_best, [2, int(self.pop_size / 2)])
-        self.alpha = self.validator.check_float("alpha", alpha, (0, 1.0))
-        self.beta = self.validator.check_float("beta", beta, (0, 1.0))
-        self.gamma = self.validator.check_float("gamma", gamma, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "p_c", "p_m", "n_best", "alpha", "beta", "gamma"])
-        self.sort_flag = False
-
-    def initialize_variables(self):
-        self.dyn_beta = self.beta
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        ## Update the pop best
-        pop_elites, local_best = self.get_global_best_solution(self.pop)
-        pop = []
-        for idx in range(0, self.pop_size):
-            ### Reproduction 1: the first way of reproducing
-            x_t1 = self.problem.lb + self.problem.ub - self.alpha * self.pop[idx][self.ID_POS]
-
-            ### Reproduction 2: the second way of reproducing
-            if idx >= self.n_best:  ### Select two parents to mate and create two children
-                idx = int(self.pop_size * 0.2)
-                if np.random.uniform() < 0.5:  ## 80% parents selected from best population
-                    idx1, idx2 = np.random.choice(range(0, idx), 2, replace=False)
-                else:  ## 20% left parents selected from worst population (make more diversity)
-                    idx1, idx2 = np.random.choice(range(idx, self.pop_size), 2, replace=False)
-                r = np.random.uniform()
-                x_child = r * self.pop[idx2][self.ID_POS] + (1 - r) * self.pop[idx1][self.ID_POS]
-            else:
-                r1 = np.random.randint(0, self.pop_size)
-                x_child = self.pop[r1][self.ID_POS]
-            x_t1 = self.dyn_beta * x_t1 + (1.0 - self.dyn_beta) * x_child
-            pos_new = self.amend_position(x_t1, self.problem.lb, self.problem.ub)
-            pop.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop = self.update_target_wrapper_population(pop)
-            self.pop = self.greedy_selection_population(self.pop, pop)
-        self.dyn_beta = self.gamma * self.beta
-        self.pop = self.get_sorted_strim_population(self.pop, self.pop_size)
-
-        pos_list = np.array([item[self.ID_POS] for item in self.pop])
-        x_mean = np.mean(pos_list, axis=0)
-        ## Cauchy mutation (CM)
-        cauchy_w = deepcopy(self.g_best[self.ID_POS])
-        pop_new = []
-        for idx in range(self.n_best, self.pop_size):  # Don't allow the elites to be mutated
-            condition = np.random.random(self.problem.n_dims) < self.p_m
-            cauchy_w = np.where(condition, x_mean, cauchy_w)
-            x_t1 = (cauchy_w + self.g_best[self.ID_POS]) / 2
-            pos_new = self.amend_position(x_t1, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop[self.n_best:] = self.greedy_selection_population(pop_new, self.pop[self.n_best:])
-
-        ## Elitism Strategy: Replace the worst with the previous generation's elites.
-        self.pop, local_best = self.get_global_best_solution(self.pop)
-        for i in range(0, self.n_best):
-            self.pop[self.pop_size - i - 1] = deepcopy(pop_elites[i])
-
-        ## Make sure the population does not have duplicates.
-        new_set = set()
-        for idx, agent in enumerate(self.pop):
-            if tuple(agent[self.ID_POS].tolist()) in new_set:
-                self.pop[idx] = self.create_solution(self.problem.lb, self.problem.ub)
-            else:
-                new_set.add(tuple(agent[self.ID_POS].tolist()))
+#!/usr/bin/env python
+# Created by "Thieu" at 14:52, 17/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalEOA(Optimizer):
+    """
+    The developed version: Earthworm Optimisation Algorithm (EOA)
+
+    Links:
+        1. http://doi.org/10.1504/IJBIC.2015.10004283
+        2. https://www.mathworks.com/matlabcentral/fileexchange/53479-earthworm-optimization-algorithm-ewa
+
+    Notes
+    ~~~~~
+    The original version from matlab code above will not work well, even with small dimensions.
+    I change updating process, change cauchy process using x_mean, use global best solution
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + p_c (float): (0, 1) -> better [0.5, 0.95], crossover probability
+        + p_m (float): (0, 1) -> better [0.01, 0.2], initial mutation probability
+        + n_best (int): (2, pop_size/2) -> better [2, 5], how many of the best earthworm to keep from one generation to the next
+        + alpha (float): (0, 1) -> better [0.8, 0.99], similarity factor
+        + beta (float): (0, 1) -> better [0.8, 1.0], the initial proportional factor
+        + gamma (float): (0, 1) -> better [0.8, 0.99], a constant that is similar to cooling factor of a cooling schedule in the simulated annealing.
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.bio_based.EOA import OriginalEOA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> p_c = 0.9
+    >>> p_m = 0.01
+    >>> n_best = 2
+    >>> alpha = 0.98
+    >>> beta = 0.9
+    >>> gamma = 0.9
+    >>> model = OriginalEOA(epoch, pop_size, p_c, p_m, n_best, alpha, beta, gamma)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Wang, G.G., Deb, S. and Coelho, L.D.S., 2018. Earthworm optimisation algorithm: a bio-inspired metaheuristic algorithm
+    for global optimisation problems. International journal of bio-inspired computation, 12(1), pp.1-22.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, p_c=0.9, p_m=0.01, n_best=2, alpha=0.98, beta=0.9, gamma=0.9, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            p_c (float): default = 0.9, crossover probability
+            p_m (float): default = 0.01 initial mutation probability
+            n_best (int): default = 2, how many of the best earthworm to keep from one generation to the next
+            alpha (float): default = 0.98, similarity factor
+            beta (float): default = 0.9, the initial proportional factor
+            gamma (float): default = 0.9, a constant that is similar to cooling factor of a cooling schedule in the simulated annealing.
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.p_c = self.validator.check_float("p_c", p_c, (0, 1.0))
+        self.p_m = self.validator.check_float("p_m", p_m, (0, 1.0))
+        self.n_best = self.validator.check_int("n_best", n_best, [2, int(self.pop_size / 2)])
+        self.alpha = self.validator.check_float("alpha", alpha, (0, 1.0))
+        self.beta = self.validator.check_float("beta", beta, (0, 1.0))
+        self.gamma = self.validator.check_float("gamma", gamma, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "p_c", "p_m", "n_best", "alpha", "beta", "gamma"])
+        self.sort_flag = False
+
+    def initialize_variables(self):
+        self.dyn_beta = self.beta
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        ## Update the pop best
+        pop_elites, local_best = self.get_global_best_solution(self.pop)
+        pop = []
+        for idx in range(0, self.pop_size):
+            ### Reproduction 1: the first way of reproducing
+            x_t1 = self.problem.lb + self.problem.ub - self.alpha * self.pop[idx][self.ID_POS]
+
+            ### Reproduction 2: the second way of reproducing
+            if idx >= self.n_best:  ### Select two parents to mate and create two children
+                idx = int(self.pop_size * 0.2)
+                if np.random.uniform() < 0.5:  ## 80% parents selected from best population
+                    idx1, idx2 = np.random.choice(range(0, idx), 2, replace=False)
+                else:  ## 20% left parents selected from worst population (make more diversity)
+                    idx1, idx2 = np.random.choice(range(idx, self.pop_size), 2, replace=False)
+                r = np.random.uniform()
+                x_child = r * self.pop[idx2][self.ID_POS] + (1 - r) * self.pop[idx1][self.ID_POS]
+            else:
+                r1 = np.random.randint(0, self.pop_size)
+                x_child = self.pop[r1][self.ID_POS]
+            x_t1 = self.dyn_beta * x_t1 + (1.0 - self.dyn_beta) * x_child
+            pos_new = self.amend_position(x_t1, self.problem.lb, self.problem.ub)
+            pop.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop = self.update_target_wrapper_population(pop)
+            self.pop = self.greedy_selection_population(self.pop, pop)
+        self.dyn_beta = self.gamma * self.beta
+        self.pop = self.get_sorted_strim_population(self.pop, self.pop_size)
+
+        pos_list = np.array([item[self.ID_POS] for item in self.pop])
+        x_mean = np.mean(pos_list, axis=0)
+        ## Cauchy mutation (CM)
+        cauchy_w = deepcopy(self.g_best[self.ID_POS])
+        pop_new = []
+        for idx in range(self.n_best, self.pop_size):  # Don't allow the elites to be mutated
+            condition = np.random.random(self.problem.n_dims) < self.p_m
+            cauchy_w = np.where(condition, x_mean, cauchy_w)
+            x_t1 = (cauchy_w + self.g_best[self.ID_POS]) / 2
+            pos_new = self.amend_position(x_t1, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop[self.n_best:] = self.greedy_selection_population(pop_new, self.pop[self.n_best:])
+
+        ## Elitism Strategy: Replace the worst with the previous generation's elites.
+        self.pop, local_best = self.get_global_best_solution(self.pop)
+        for i in range(0, self.n_best):
+            self.pop[self.pop_size - i - 1] = deepcopy(pop_elites[i])
+
+        ## Make sure the population does not have duplicates.
+        new_set = set()
+        for idx, agent in enumerate(self.pop):
+            if tuple(agent[self.ID_POS].tolist()) in new_set:
+                self.pop[idx] = self.create_solution(self.problem.lb, self.problem.ub)
+            else:
+                new_set.add(tuple(agent[self.ID_POS].tolist()))
```

### Comparing `mealpy-2.5.3/mealpy/bio_based/IWO.py` & `mealpy-2.5.3a1/mealpy/bio_based/IWO.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,115 +1,115 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 12:17, 18/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalIWO(Optimizer):
-    """
-    The original version of: Invasive Weed Optimization (IWO)
-
-    Links:
-        1. https://pdfs.semanticscholar.org/734c/66e3757620d3d4016410057ee92f72a9853d.pdf
-
-    Notes
-    ~~~~~
-    Better to use normal distribution instead of uniform distribution, updating population by sorting
-    both parent population and child population
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + seed_min (int): [1, 3], Number of Seeds (min)
-        + seed_max (int): [4, pop_size/2], Number of Seeds (max)
-        + exponent (int): [2, 4], Variance Reduction Exponent
-        + sigma_start (float): [0.5, 5.0], The initial value of Standard Deviation
-        + sigma_end (float): (0, 0.5), The final value of Standard Deviation
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.bio_based.IWO import OriginalIWO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> seed_min = 3
-    >>> seed_max = 9
-    >>> exponent = 3
-    >>> sigma_start = 0.6
-    >>> sigma_end = 0.01
-    >>> model = OriginalIWO(epoch, pop_size, seed_min, seed_max, exponent, sigma_start, sigma_end)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Mehrabian, A.R. and Lucas, C., 2006. A novel numerical optimization algorithm inspired from weed colonization.
-    Ecological informatics, 1(4), pp.355-366.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, seed_min=2, seed_max=10, exponent=2, sigma_start=1.0, sigma_end=0.01, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            seed_min (int): Number of Seeds (min)
-            seed_max (int): Number of seeds (max)
-            exponent (int): Variance Reduction Exponent
-            sigma_start (float): The initial value of standard deviation
-            sigma_end (float): The final value of standard deviation
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.seed_min = self.validator.check_int("seed_min", seed_min, [1, 3])
-        self.seed_max = self.validator.check_int("seed_max", seed_max, [4, int(self.pop_size/2)])
-        self.exponent = self.validator.check_int("exponent", exponent, [2, 4])
-        self.sigma_start = self.validator.check_float("sigma_start", sigma_start, [0.5, 5.0])
-        self.sigma_end = self.validator.check_float("sigma_end", sigma_end, (0, 0.5))
-        self.set_parameters(["epoch", "pop_size", "seed_min", "seed_max", "exponent", "sigma_start", "sigma_end"])
-        self.sort_flag = True
-
-    def evolve(self, epoch=None):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # Update Standard Deviation
-        sigma = ((self.epoch - epoch) / (self.epoch - 1)) ** self.exponent * (self.sigma_start - self.sigma_end) + self.sigma_end
-        pop, best, worst = self.get_special_solutions(self.pop)
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            temp = best[0][self.ID_TAR][self.ID_FIT] - worst[0][self.ID_TAR][self.ID_FIT]
-            if temp == 0:
-                ratio = np.random.rand()
-            else:
-                ratio = (pop[idx][self.ID_TAR][self.ID_FIT] - worst[0][self.ID_TAR][self.ID_FIT]) / temp
-            s = int(np.ceil(self.seed_min + (self.seed_max - self.seed_min) * ratio))
-            if s > int(np.sqrt(self.pop_size)):
-                s = int(np.sqrt(self.pop_size))
-            pop_local = []
-            for j in range(s):
-                # Initialize Offspring and Generate Random Location
-                pos_new = pop[idx][self.ID_POS] + sigma * np.random.normal(0, 1, self.problem.n_dims)
-                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                pop_local.append([pos_new, None])
-                if self.mode not in self.AVAILABLE_MODES:
-                    pop_local[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-            if self.mode in self.AVAILABLE_MODES:
-                pop_local = self.update_target_wrapper_population(pop_local)
-            pop_new += pop_local
-        self.pop = self.get_sorted_strim_population(pop_new, self.pop_size)
+#!/usr/bin/env python
+# Created by "Thieu" at 12:17, 18/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalIWO(Optimizer):
+    """
+    The original version of: Invasive Weed Optimization (IWO)
+
+    Links:
+        1. https://pdfs.semanticscholar.org/734c/66e3757620d3d4016410057ee92f72a9853d.pdf
+
+    Notes
+    ~~~~~
+    Better to use normal distribution instead of uniform distribution, updating population by sorting
+    both parent population and child population
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + seed_min (int): [1, 3], Number of Seeds (min)
+        + seed_max (int): [4, pop_size/2], Number of Seeds (max)
+        + exponent (int): [2, 4], Variance Reduction Exponent
+        + sigma_start (float): [0.5, 5.0], The initial value of Standard Deviation
+        + sigma_end (float): (0, 0.5), The final value of Standard Deviation
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.bio_based.IWO import OriginalIWO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> seed_min = 3
+    >>> seed_max = 9
+    >>> exponent = 3
+    >>> sigma_start = 0.6
+    >>> sigma_end = 0.01
+    >>> model = OriginalIWO(epoch, pop_size, seed_min, seed_max, exponent, sigma_start, sigma_end)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Mehrabian, A.R. and Lucas, C., 2006. A novel numerical optimization algorithm inspired from weed colonization.
+    Ecological informatics, 1(4), pp.355-366.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, seed_min=2, seed_max=10, exponent=2, sigma_start=1.0, sigma_end=0.01, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            seed_min (int): Number of Seeds (min)
+            seed_max (int): Number of seeds (max)
+            exponent (int): Variance Reduction Exponent
+            sigma_start (float): The initial value of standard deviation
+            sigma_end (float): The final value of standard deviation
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.seed_min = self.validator.check_int("seed_min", seed_min, [1, 3])
+        self.seed_max = self.validator.check_int("seed_max", seed_max, [4, int(self.pop_size/2)])
+        self.exponent = self.validator.check_int("exponent", exponent, [2, 4])
+        self.sigma_start = self.validator.check_float("sigma_start", sigma_start, [0.5, 5.0])
+        self.sigma_end = self.validator.check_float("sigma_end", sigma_end, (0, 0.5))
+        self.set_parameters(["epoch", "pop_size", "seed_min", "seed_max", "exponent", "sigma_start", "sigma_end"])
+        self.sort_flag = True
+
+    def evolve(self, epoch=None):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # Update Standard Deviation
+        sigma = ((self.epoch - epoch) / (self.epoch - 1)) ** self.exponent * (self.sigma_start - self.sigma_end) + self.sigma_end
+        pop, best, worst = self.get_special_solutions(self.pop)
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            temp = best[0][self.ID_TAR][self.ID_FIT] - worst[0][self.ID_TAR][self.ID_FIT]
+            if temp == 0:
+                ratio = np.random.rand()
+            else:
+                ratio = (pop[idx][self.ID_TAR][self.ID_FIT] - worst[0][self.ID_TAR][self.ID_FIT]) / temp
+            s = int(np.ceil(self.seed_min + (self.seed_max - self.seed_min) * ratio))
+            if s > int(np.sqrt(self.pop_size)):
+                s = int(np.sqrt(self.pop_size))
+            pop_local = []
+            for j in range(s):
+                # Initialize Offspring and Generate Random Location
+                pos_new = pop[idx][self.ID_POS] + sigma * np.random.normal(0, 1, self.problem.n_dims)
+                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                pop_local.append([pos_new, None])
+                if self.mode not in self.AVAILABLE_MODES:
+                    pop_local[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+            if self.mode in self.AVAILABLE_MODES:
+                pop_local = self.update_target_wrapper_population(pop_local)
+            pop_new += pop_local
+        self.pop = self.get_sorted_strim_population(pop_new, self.pop_size)
```

### Comparing `mealpy-2.5.3/mealpy/bio_based/SBO.py` & `mealpy-2.5.3a1/mealpy/bio_based/SBO.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,213 +1,213 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 12:48, 18/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class BaseSBO(Optimizer):
-    """
-    The developed version: Satin Bowerbird Optimizer (SBO)
-
-    Links:
-        1. https://doi.org/10.1016/j.engappai.2017.01.006
-
-    Notes
-    ~~~~~
-    The original version is not good enough and can't handle negative fitness value.
-    I remove all third loop for faster training, remove equation (1, 2) in the paper, calculate probability by roulette-wheel.
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + alpha (float): [0.5, 3.0] -> better [0.5, 2.0], the greatest step size
-        + p_m (float): (0, 1.0) -> better [0.01, 0.2], mutation probability
-        + psw (float): (0, 1.0) -> better [0.01, 0.1], proportion of space width (z in the paper)
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.bio_based.SBO import BaseSBO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> alpha = 0.9
-    >>> p_m =0.05
-    >>> psw = 0.02
-    >>> model = BaseSBO(epoch, pop_size, alpha, p_m, psw)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, alpha=0.94, p_m=0.05, psw=0.02, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            alpha (float): the greatest step size, default=0.94
-            p_m (float): mutation probability, default=0.05
-            psw (float): proportion of space width (z in the paper), default=0.02
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.alpha = self.validator.check_float("alpha", alpha, [0.5, 3.0])
-        self.p_m = self.validator.check_float("p_m", p_m, (0, 1.0))
-        self.psw = self.validator.check_float("psw", psw, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "p_m", "psw"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # (percent of the difference between the upper and lower limit (Eq. 7))
-        self.sigma = self.psw * (self.problem.ub - self.problem.lb)
-
-        ## Calculate the probability of bowers using my equation
-        fit_list = np.array([item[self.ID_TAR][self.ID_FIT] for item in self.pop])
-        pop_new = []
-        for i in range(0, self.pop_size):
-            ### Select a bower using roulette wheel
-            idx = self.get_index_roulette_wheel_selection(fit_list)
-            ### Calculating Step Size
-            lamda = self.alpha * np.random.uniform()
-            pos_new = self.pop[i][self.ID_POS] + lamda * ((self.pop[idx][self.ID_POS] + self.g_best[self.ID_POS]) / 2 - self.pop[i][self.ID_POS])
-            ### Mutation
-            temp = self.pop[i][self.ID_POS] + np.random.normal(0, 1, self.problem.n_dims) * self.sigma
-            pos_new = np.where(np.random.random(self.problem.n_dims) < self.p_m, temp, pos_new)
-            ### In-bound position
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[i] = self.get_better_solution([pos_new, target], self.pop[i])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-
-class OriginalSBO(BaseSBO):
-    """
-    The original version of: Satin Bowerbird Optimizer (SBO)
-
-    Links:
-        1. https://doi.org/10.1016/j.engappai.2017.01.006
-        2. https://www.mathworks.com/matlabcentral/fileexchange/62009-satin-bowerbird-optimizer-sbo-2017
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + alpha (float): [0.5, 3.0] -> better [0.5, 0.99], the greatest step size
-        + p_m (float): (0, 1.0) -> better [0.01, 0.2], mutation probability
-        + psw (float): (0, 1.0) -> better [0.01, 0.1], proportion of space width (z in the paper)
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.bio_based.SBO import OriginalSBO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> alpha = 0.9
-    >>> p_m=0.05
-    >>> psw = 0.02
-    >>> model = OriginalSBO(epoch, pop_size, alpha, p_m, psw)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Moosavi, S.H.S. and Bardsiri, V.K., 2017. Satin bowerbird optimizer: A new optimization algorithm
-    to optimize ANFIS for software development effort estimation. Engineering Applications of Artificial Intelligence, 60, pp.1-15.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, alpha=0.94, p_m=0.05, psw=0.02, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            alpha (float): the greatest step size, default=0.94
-            p_m (float): mutation probability, default=0.05
-            psw (float): proportion of space width (z in the paper), default=0.02
-        """
-        super().__init__(epoch, pop_size, alpha, p_m, psw, **kwargs)
-
-    def roulette_wheel_selection__(self, fitness_list=None) -> int:
-        """
-        Roulette Wheel Selection in the original version, this version can't handle the negative fitness values
-
-        Args:
-            fitness_list (list): Fitness of population
-
-        Returns:
-            f (int): The index of selected solution
-        """
-        r = np.random.uniform()
-        c = np.cumsum(fitness_list)
-        f = np.where(r < c)[0][0]
-        return f
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # (percent of the difference between the upper and lower limit (Eq. 7))
-        self.sigma = self.psw * (self.problem.ub - self.problem.lb)
-
-        ## Calculate the probability of bowers using Eqs. (1) and (2)
-        fx_list = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in self.pop])
-        fit_list = deepcopy(fx_list)
-        for i in range(0, self.pop_size):
-            if fx_list[i] < 0:
-                fit_list[i] = 1.0 + np.abs(fx_list[i])
-            else:
-                fit_list[i] = 1.0 / (1.0 + np.abs(fx_list[i]))
-        fit_sum = np.sum(fit_list)
-        ## Calculating the probability of each bower
-        prob_list = fit_list / fit_sum
-        pop_new = []
-        for i in range(0, self.pop_size):
-            pos_new = deepcopy(self.pop[i][self.ID_POS])
-            for j in range(0, self.problem.n_dims):
-                ### Select a bower using roulette wheel
-                idx = self.roulette_wheel_selection__(prob_list)
-                ### Calculating Step Size
-                lamda = self.alpha / (1 + prob_list[idx])
-                pos_new[j] = self.pop[i][self.ID_POS][j] + lamda * \
-                             ((self.pop[idx][self.ID_POS][j] + self.g_best[self.ID_POS][j]) / 2 - self.pop[i][self.ID_POS][j])
-                ### Mutation
-                if np.random.uniform() < self.p_m:
-                    pos_new[j] = self.pop[i][self.ID_POS][j] + np.random.normal(0, 1) * self.sigma[j]
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                self.pop[i] = [pos_new, self.get_target_wrapper(pos_new)]
-        if self.mode in self.AVAILABLE_MODES:
-            self.pop = self.update_target_wrapper_population(pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 12:48, 18/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class BaseSBO(Optimizer):
+    """
+    The developed version: Satin Bowerbird Optimizer (SBO)
+
+    Links:
+        1. https://doi.org/10.1016/j.engappai.2017.01.006
+
+    Notes
+    ~~~~~
+    The original version is not good enough and can't handle negative fitness value.
+    I remove all third loop for faster training, remove equation (1, 2) in the paper, calculate probability by roulette-wheel.
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + alpha (float): [0.5, 3.0] -> better [0.5, 2.0], the greatest step size
+        + p_m (float): (0, 1.0) -> better [0.01, 0.2], mutation probability
+        + psw (float): (0, 1.0) -> better [0.01, 0.1], proportion of space width (z in the paper)
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.bio_based.SBO import BaseSBO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> alpha = 0.9
+    >>> p_m =0.05
+    >>> psw = 0.02
+    >>> model = BaseSBO(epoch, pop_size, alpha, p_m, psw)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, alpha=0.94, p_m=0.05, psw=0.02, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            alpha (float): the greatest step size, default=0.94
+            p_m (float): mutation probability, default=0.05
+            psw (float): proportion of space width (z in the paper), default=0.02
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.alpha = self.validator.check_float("alpha", alpha, [0.5, 3.0])
+        self.p_m = self.validator.check_float("p_m", p_m, (0, 1.0))
+        self.psw = self.validator.check_float("psw", psw, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "p_m", "psw"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # (percent of the difference between the upper and lower limit (Eq. 7))
+        self.sigma = self.psw * (self.problem.ub - self.problem.lb)
+
+        ## Calculate the probability of bowers using my equation
+        fit_list = np.array([item[self.ID_TAR][self.ID_FIT] for item in self.pop])
+        pop_new = []
+        for i in range(0, self.pop_size):
+            ### Select a bower using roulette wheel
+            idx = self.get_index_roulette_wheel_selection(fit_list)
+            ### Calculating Step Size
+            lamda = self.alpha * np.random.uniform()
+            pos_new = self.pop[i][self.ID_POS] + lamda * ((self.pop[idx][self.ID_POS] + self.g_best[self.ID_POS]) / 2 - self.pop[i][self.ID_POS])
+            ### Mutation
+            temp = self.pop[i][self.ID_POS] + np.random.normal(0, 1, self.problem.n_dims) * self.sigma
+            pos_new = np.where(np.random.random(self.problem.n_dims) < self.p_m, temp, pos_new)
+            ### In-bound position
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[i] = self.get_better_solution([pos_new, target], self.pop[i])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+
+class OriginalSBO(BaseSBO):
+    """
+    The original version of: Satin Bowerbird Optimizer (SBO)
+
+    Links:
+        1. https://doi.org/10.1016/j.engappai.2017.01.006
+        2. https://www.mathworks.com/matlabcentral/fileexchange/62009-satin-bowerbird-optimizer-sbo-2017
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + alpha (float): [0.5, 3.0] -> better [0.5, 0.99], the greatest step size
+        + p_m (float): (0, 1.0) -> better [0.01, 0.2], mutation probability
+        + psw (float): (0, 1.0) -> better [0.01, 0.1], proportion of space width (z in the paper)
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.bio_based.SBO import OriginalSBO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> alpha = 0.9
+    >>> p_m=0.05
+    >>> psw = 0.02
+    >>> model = OriginalSBO(epoch, pop_size, alpha, p_m, psw)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Moosavi, S.H.S. and Bardsiri, V.K., 2017. Satin bowerbird optimizer: A new optimization algorithm
+    to optimize ANFIS for software development effort estimation. Engineering Applications of Artificial Intelligence, 60, pp.1-15.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, alpha=0.94, p_m=0.05, psw=0.02, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            alpha (float): the greatest step size, default=0.94
+            p_m (float): mutation probability, default=0.05
+            psw (float): proportion of space width (z in the paper), default=0.02
+        """
+        super().__init__(epoch, pop_size, alpha, p_m, psw, **kwargs)
+
+    def roulette_wheel_selection__(self, fitness_list=None) -> int:
+        """
+        Roulette Wheel Selection in the original version, this version can't handle the negative fitness values
+
+        Args:
+            fitness_list (list): Fitness of population
+
+        Returns:
+            f (int): The index of selected solution
+        """
+        r = np.random.uniform()
+        c = np.cumsum(fitness_list)
+        f = np.where(r < c)[0][0]
+        return f
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # (percent of the difference between the upper and lower limit (Eq. 7))
+        self.sigma = self.psw * (self.problem.ub - self.problem.lb)
+
+        ## Calculate the probability of bowers using Eqs. (1) and (2)
+        fx_list = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in self.pop])
+        fit_list = deepcopy(fx_list)
+        for i in range(0, self.pop_size):
+            if fx_list[i] < 0:
+                fit_list[i] = 1.0 + np.abs(fx_list[i])
+            else:
+                fit_list[i] = 1.0 / (1.0 + np.abs(fx_list[i]))
+        fit_sum = np.sum(fit_list)
+        ## Calculating the probability of each bower
+        prob_list = fit_list / fit_sum
+        pop_new = []
+        for i in range(0, self.pop_size):
+            pos_new = deepcopy(self.pop[i][self.ID_POS])
+            for j in range(0, self.problem.n_dims):
+                ### Select a bower using roulette wheel
+                idx = self.roulette_wheel_selection__(prob_list)
+                ### Calculating Step Size
+                lamda = self.alpha / (1 + prob_list[idx])
+                pos_new[j] = self.pop[i][self.ID_POS][j] + lamda * \
+                             ((self.pop[idx][self.ID_POS][j] + self.g_best[self.ID_POS][j]) / 2 - self.pop[i][self.ID_POS][j])
+                ### Mutation
+                if np.random.uniform() < self.p_m:
+                    pos_new[j] = self.pop[i][self.ID_POS][j] + np.random.normal(0, 1) * self.sigma[j]
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                self.pop[i] = [pos_new, self.get_target_wrapper(pos_new)]
+        if self.mode in self.AVAILABLE_MODES:
+            self.pop = self.update_target_wrapper_population(pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/bio_based/SMA.py` & `mealpy-2.5.3a1/mealpy/bio_based/SMA.py`

 * *Ordering differences only*

 * *Files 9% similar despite different names*

```diff
@@ -1,225 +1,225 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 20:22, 12/06/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class BaseSMA(Optimizer):
-    """
-    The developed version: Slime Mould Algorithm (SMA)
-
-    Notes
-    ~~~~~
-    + Selected 2 unique and random solution to create new solution (not to create variable)
-    + Check bound and compare old position with new position to get the best one
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + p_t (float): (0, 1.0) -> better [0.01, 0.1], probability threshold (z in the paper)
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.bio_based.SMA import BaseSMA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> p_t = 0.03
-    >>> model = BaseSMA(epoch, pop_size, p_t)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    ID_WEI = 2
-
-    def __init__(self, epoch=10000, pop_size=100, p_t=0.03, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            p_t (float): probability threshold (z in the paper), default = 0.03
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.p_t = self.validator.check_float("p_t", p_t, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "p_t"])
-        self.sort_flag = True
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        """
-        Overriding method in Optimizer class
-
-        Returns:
-            list: [position, target, weight]
-        """
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        position = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(position)
-        weight = np.zeros(len(lb))
-        return [position, target, weight]
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # plus eps to avoid denominator zero
-        s = self.g_best[self.ID_TAR][self.ID_FIT] - self.pop[-1][self.ID_TAR][self.ID_FIT] + self.EPSILON
-
-        # calculate the fitness weight of each slime mold
-        for i in range(0, self.pop_size):
-            # Eq.(2.5)
-            if i <= int(self.pop_size / 2):
-                self.pop[i][self.ID_WEI] = 1 + np.random.uniform(0, 1, self.problem.n_dims) * \
-                    np.log10((self.g_best[self.ID_TAR][self.ID_FIT] - self.pop[i][self.ID_TAR][self.ID_FIT]) / s + 1)
-            else:
-                self.pop[i][self.ID_WEI] = 1 - np.random.uniform(0, 1, self.problem.n_dims) * \
-                    np.log10((self.g_best[self.ID_TAR][self.ID_FIT] - self.pop[i][self.ID_TAR][self.ID_FIT]) / s + 1)
-
-        a = np.arctanh(-((epoch + 1) / (self.epoch+1)) + 1)  # Eq.(2.4)
-        b = 1 - (epoch + 1) / (self.epoch+1)
-
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            # Update the Position of search agent
-            if np.random.uniform() < self.p_t:  # Eq.(2.7)
-                pos_new = self.generate_position(self.problem.lb, self.problem.ub)
-            else:
-                p = np.tanh(np.abs(self.pop[idx][self.ID_TAR][self.ID_FIT] - self.g_best[self.ID_TAR][self.ID_FIT]))  # Eq.(2.2)
-                vb = np.random.uniform(-a, a, self.problem.n_dims)  # Eq.(2.3)
-                vc = np.random.uniform(-b, b, self.problem.n_dims)
-
-                # two positions randomly selected from population, apply for the whole problem size instead of 1 variable
-                id_a, id_b = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 2, replace=False)
-
-                pos_1 = self.g_best[self.ID_POS] + vb * (self.pop[idx][self.ID_WEI] * self.pop[id_a][self.ID_POS] - self.pop[id_b][self.ID_POS])
-                pos_2 = vc * self.pop[idx][self.ID_POS]
-                condition = np.random.random(self.problem.n_dims) < p
-                pos_new = np.where(condition, pos_1, pos_2)
-            # Check bound and re-calculate fitness after each individual move
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None, np.zeros(self.problem.n_dims)])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target, np.zeros(self.problem.n_dims)], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-
-class OriginalSMA(BaseSMA):
-    """
-    The original version of: Slime Mould Algorithm (SMA)
-
-    Links:
-        1. https://doi.org/10.1016/j.future.2020.03.055
-        2. https://www.researchgate.net/publication/340431861_Slime_mould_algorithm_A_new_method_for_stochastic_optimization
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + p_t (float): (0, 1.0) -> better [0.01, 0.1], probability threshold (z in the paper)
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.bio_based.SMA import OriginalSMA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> p_t = 0.03
-    >>> model = OriginalSMA( epoch, pop_size, p_t)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Li, S., Chen, H., Wang, M., Heidari, A.A. and Mirjalili, S., 2020. Slime mould algorithm: A new method for
-    stochastic optimization. Future Generation Computer Systems, 111, pp.300-323.
-    """
-
-    ID_WEI = 2
-
-    def __init__(self, epoch=10000, pop_size=100, p_t=0.03, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 1000
-            pop_size (int): number of population size, default = 100
-            p_t (float): probability threshold (z in the paper), default = 0.03
-        """
-        super().__init__(epoch, pop_size, p_t, **kwargs)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-
-        # plus eps to avoid denominator zero
-        s = self.g_best[self.ID_TAR][self.ID_FIT] - self.pop[-1][self.ID_TAR][self.ID_FIT] + self.EPSILON
-
-        # calculate the fitness weight of each slime mold
-        for i in range(0, self.pop_size):
-            # Eq.(2.5)
-            if i <= int(self.pop_size / 2):
-                self.pop[i][self.ID_WEI] = 1 + np.random.uniform(0, 1, self.problem.n_dims) * \
-                    np.log10((self.g_best[self.ID_TAR][self.ID_FIT] - self.pop[i][self.ID_TAR][self.ID_FIT]) / s + 1)
-            else:
-                self.pop[i][self.ID_WEI] = 1 - np.random.uniform(0, 1, self.problem.n_dims) * \
-                    np.log10((self.g_best[self.ID_TAR][self.ID_FIT] - self.pop[i][self.ID_TAR][self.ID_FIT]) / s + 1)
-
-        a = np.arctanh(-((epoch + 1) / (self.epoch+1)) + 1)  # Eq.(2.4)
-        b = 1 - (epoch + 1) / (self.epoch+1)
-
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            # Update the Position of search agent
-            current_agent = deepcopy(self.pop[idx])
-            if np.random.uniform() < self.p_t:  # Eq.(2.7)
-                current_agent[self.ID_POS] = np.random.uniform(self.problem.lb, self.problem.ub)
-            else:
-                p = np.tanh(np.abs(current_agent[self.ID_TAR][self.ID_FIT] - self.g_best[self.ID_TAR][self.ID_FIT]))  # Eq.(2.2)
-                vb = np.random.uniform(-a, a, self.problem.n_dims)  # Eq.(2.3)
-                vc = np.random.uniform(-b, b, self.problem.n_dims)
-                for j in range(0, self.problem.n_dims):
-                    # two positions randomly selected from population
-                    id_a, id_b = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 2, replace=False)
-                    if np.random.uniform() < p:  # Eq.(2.1)
-                        current_agent[self.ID_POS][j] = self.g_best[self.ID_POS][j] + \
-                            vb[j] * (current_agent[self.ID_WEI][j] * self.pop[id_a][self.ID_POS][j] - self.pop[id_b][self.ID_POS][j])
-                    else:
-                        current_agent[self.ID_POS][j] = vc[j] * current_agent[self.ID_POS][j]
-            pos_new = self.amend_position(current_agent[self.ID_POS], self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None, np.zeros(self.problem.n_dims)])
-            if self.mode not in self.AVAILABLE_MODES:
-                self.pop[idx] = [pos_new, self.get_target_wrapper(pos_new), np.zeros(self.problem.n_dims)]
-        if self.mode in self.AVAILABLE_MODES:
-            self.pop = self.update_target_wrapper_population(pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 20:22, 12/06/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class BaseSMA(Optimizer):
+    """
+    The developed version: Slime Mould Algorithm (SMA)
+
+    Notes
+    ~~~~~
+    + Selected 2 unique and random solution to create new solution (not to create variable)
+    + Check bound and compare old position with new position to get the best one
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + p_t (float): (0, 1.0) -> better [0.01, 0.1], probability threshold (z in the paper)
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.bio_based.SMA import BaseSMA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> p_t = 0.03
+    >>> model = BaseSMA(epoch, pop_size, p_t)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    ID_WEI = 2
+
+    def __init__(self, epoch=10000, pop_size=100, p_t=0.03, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            p_t (float): probability threshold (z in the paper), default = 0.03
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.p_t = self.validator.check_float("p_t", p_t, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "p_t"])
+        self.sort_flag = True
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        """
+        Overriding method in Optimizer class
+
+        Returns:
+            list: [position, target, weight]
+        """
+        if pos is None:
+            pos = self.generate_position(lb, ub)
+        position = self.amend_position(pos, lb, ub)
+        target = self.get_target_wrapper(position)
+        weight = np.zeros(len(lb))
+        return [position, target, weight]
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # plus eps to avoid denominator zero
+        s = self.g_best[self.ID_TAR][self.ID_FIT] - self.pop[-1][self.ID_TAR][self.ID_FIT] + self.EPSILON
+
+        # calculate the fitness weight of each slime mold
+        for i in range(0, self.pop_size):
+            # Eq.(2.5)
+            if i <= int(self.pop_size / 2):
+                self.pop[i][self.ID_WEI] = 1 + np.random.uniform(0, 1, self.problem.n_dims) * \
+                    np.log10((self.g_best[self.ID_TAR][self.ID_FIT] - self.pop[i][self.ID_TAR][self.ID_FIT]) / s + 1)
+            else:
+                self.pop[i][self.ID_WEI] = 1 - np.random.uniform(0, 1, self.problem.n_dims) * \
+                    np.log10((self.g_best[self.ID_TAR][self.ID_FIT] - self.pop[i][self.ID_TAR][self.ID_FIT]) / s + 1)
+
+        a = np.arctanh(-((epoch + 1) / (self.epoch+1)) + 1)  # Eq.(2.4)
+        b = 1 - (epoch + 1) / (self.epoch+1)
+
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            # Update the Position of search agent
+            if np.random.uniform() < self.p_t:  # Eq.(2.7)
+                pos_new = self.generate_position(self.problem.lb, self.problem.ub)
+            else:
+                p = np.tanh(np.abs(self.pop[idx][self.ID_TAR][self.ID_FIT] - self.g_best[self.ID_TAR][self.ID_FIT]))  # Eq.(2.2)
+                vb = np.random.uniform(-a, a, self.problem.n_dims)  # Eq.(2.3)
+                vc = np.random.uniform(-b, b, self.problem.n_dims)
+
+                # two positions randomly selected from population, apply for the whole problem size instead of 1 variable
+                id_a, id_b = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 2, replace=False)
+
+                pos_1 = self.g_best[self.ID_POS] + vb * (self.pop[idx][self.ID_WEI] * self.pop[id_a][self.ID_POS] - self.pop[id_b][self.ID_POS])
+                pos_2 = vc * self.pop[idx][self.ID_POS]
+                condition = np.random.random(self.problem.n_dims) < p
+                pos_new = np.where(condition, pos_1, pos_2)
+            # Check bound and re-calculate fitness after each individual move
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None, np.zeros(self.problem.n_dims)])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target, np.zeros(self.problem.n_dims)], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+
+class OriginalSMA(BaseSMA):
+    """
+    The original version of: Slime Mould Algorithm (SMA)
+
+    Links:
+        1. https://doi.org/10.1016/j.future.2020.03.055
+        2. https://www.researchgate.net/publication/340431861_Slime_mould_algorithm_A_new_method_for_stochastic_optimization
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + p_t (float): (0, 1.0) -> better [0.01, 0.1], probability threshold (z in the paper)
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.bio_based.SMA import OriginalSMA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> p_t = 0.03
+    >>> model = OriginalSMA( epoch, pop_size, p_t)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Li, S., Chen, H., Wang, M., Heidari, A.A. and Mirjalili, S., 2020. Slime mould algorithm: A new method for
+    stochastic optimization. Future Generation Computer Systems, 111, pp.300-323.
+    """
+
+    ID_WEI = 2
+
+    def __init__(self, epoch=10000, pop_size=100, p_t=0.03, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 1000
+            pop_size (int): number of population size, default = 100
+            p_t (float): probability threshold (z in the paper), default = 0.03
+        """
+        super().__init__(epoch, pop_size, p_t, **kwargs)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+
+        # plus eps to avoid denominator zero
+        s = self.g_best[self.ID_TAR][self.ID_FIT] - self.pop[-1][self.ID_TAR][self.ID_FIT] + self.EPSILON
+
+        # calculate the fitness weight of each slime mold
+        for i in range(0, self.pop_size):
+            # Eq.(2.5)
+            if i <= int(self.pop_size / 2):
+                self.pop[i][self.ID_WEI] = 1 + np.random.uniform(0, 1, self.problem.n_dims) * \
+                    np.log10((self.g_best[self.ID_TAR][self.ID_FIT] - self.pop[i][self.ID_TAR][self.ID_FIT]) / s + 1)
+            else:
+                self.pop[i][self.ID_WEI] = 1 - np.random.uniform(0, 1, self.problem.n_dims) * \
+                    np.log10((self.g_best[self.ID_TAR][self.ID_FIT] - self.pop[i][self.ID_TAR][self.ID_FIT]) / s + 1)
+
+        a = np.arctanh(-((epoch + 1) / (self.epoch+1)) + 1)  # Eq.(2.4)
+        b = 1 - (epoch + 1) / (self.epoch+1)
+
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            # Update the Position of search agent
+            current_agent = deepcopy(self.pop[idx])
+            if np.random.uniform() < self.p_t:  # Eq.(2.7)
+                current_agent[self.ID_POS] = np.random.uniform(self.problem.lb, self.problem.ub)
+            else:
+                p = np.tanh(np.abs(current_agent[self.ID_TAR][self.ID_FIT] - self.g_best[self.ID_TAR][self.ID_FIT]))  # Eq.(2.2)
+                vb = np.random.uniform(-a, a, self.problem.n_dims)  # Eq.(2.3)
+                vc = np.random.uniform(-b, b, self.problem.n_dims)
+                for j in range(0, self.problem.n_dims):
+                    # two positions randomly selected from population
+                    id_a, id_b = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 2, replace=False)
+                    if np.random.uniform() < p:  # Eq.(2.1)
+                        current_agent[self.ID_POS][j] = self.g_best[self.ID_POS][j] + \
+                            vb[j] * (current_agent[self.ID_WEI][j] * self.pop[id_a][self.ID_POS][j] - self.pop[id_b][self.ID_POS][j])
+                    else:
+                        current_agent[self.ID_POS][j] = vc[j] * current_agent[self.ID_POS][j]
+            pos_new = self.amend_position(current_agent[self.ID_POS], self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None, np.zeros(self.problem.n_dims)])
+            if self.mode not in self.AVAILABLE_MODES:
+                self.pop[idx] = [pos_new, self.get_target_wrapper(pos_new), np.zeros(self.problem.n_dims)]
+        if self.mode in self.AVAILABLE_MODES:
+            self.pop = self.update_target_wrapper_population(pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/bio_based/SOA.py` & `mealpy-2.5.3a1/mealpy/bio_based/SOA.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,158 +1,158 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 17:21, 21/05/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class DevSOA(Optimizer):
-    """
-    The developed version: Seagull Optimization Algorithm (SOA)
-
-    Links:
-        1. https://www.sciencedirect.com/science/article/abs/pii/S0950705118305768
-
-    Notes:
-        1. The original one will not work because their operators always make the solution out of bound.
-        2. I added the normal random number in Eq. 14 to make its work
-        3. Besides, I will check keep the better one and remove the worst
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + fc (float): [1.0, 10.0] -> better [1, 5], freequency of employing variable A (A linear decreased from fc to 0), default = 2
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.bio_based.SOA import DevSOA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> fc = 2
-    >>> model = DevSOA(epoch, pop_size, fc)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, fc=2,  **kwargs):
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.fc = self.validator.check_float("fc", fc, [1.0, 10.])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        A = self.fc - (epoch+1)*self.fc / self.epoch    # Eq. 6
-        uu = vv = 1
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            B = 2 * A**2 * np.random.random()                                   # Eq. 8
-            M = B * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])     # Eq. 7
-            C = A * self.pop[idx][self.ID_POS]                                  # Eq. 5
-            D = np.abs(C + M)                                                   # Eq. 9
-            k = np.random.uniform(0, 2*np.pi)
-            r = uu * np.exp(k*vv)
-            xx = r * np.cos(k)
-            yy = r * np.sin(k)
-            zz = r * k
-            x_new = xx * yy * zz * D + np.random.normal(0, 1) * self.g_best[self.ID_POS]                 # Eq. 14
-            x_new = self.amend_position(x_new, self.problem.lb, self.problem.ub)
-            pop_new.append([x_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(x_new)
-                self.pop[idx] = self.get_better_solution([x_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-
-class OriginalSOA(Optimizer):
-    """
-    The original version: Seagull Optimization Algorithm (SOA)
-
-    Links:
-        1. https://www.sciencedirect.com/science/article/abs/pii/S0950705118305768
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + fc (float): [1.0, 10.0] -> better [1, 5], freequency of employing variable A (A linear decreased from fc to 0), default = 2
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.bio_based.SOA import OriginalSOA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalSOA(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Dhiman, G., & Kumar, V. (2019). Seagull optimization algorithm: Theory and its applications
-    for large-scale industrial engineering problems. Knowledge-based systems, 165, 169-196.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, fc=2,  **kwargs):
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.fc = self.validator.check_float("fc", fc, [1.0, 10.])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        A = self.fc - (epoch+1)*self.fc / self.epoch    # Eq. 6
-        uu = vv = 1
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            B = 2 * A**2 * np.random.random()                                   # Eq. 8
-            M = B * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])     # Eq. 7
-            C = A * self.pop[idx][self.ID_POS]                                  # Eq. 5
-            D = np.abs(C + M)                                                   # Eq. 9
-            k = np.random.uniform(0, 2*np.pi)
-            r = uu * np.exp(k*vv)
-            xx = r * np.cos(k)
-            yy = r * np.sin(k)
-            zz = r * k
-            x_new = xx * yy * zz * D + self.g_best[self.ID_POS]                 # Eq. 14
-            x_new = self.amend_position(x_new, self.problem.lb, self.problem.ub)
-            pop_new.append([x_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(x_new)
-        self.pop = self.update_target_wrapper_population(pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 17:21, 21/05/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class DevSOA(Optimizer):
+    """
+    The developed version: Seagull Optimization Algorithm (SOA)
+
+    Links:
+        1. https://www.sciencedirect.com/science/article/abs/pii/S0950705118305768
+
+    Notes:
+        1. The original one will not work because their operators always make the solution out of bound.
+        2. I added the normal random number in Eq. 14 to make its work
+        3. Besides, I will check keep the better one and remove the worst
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + fc (float): [1.0, 10.0] -> better [1, 5], freequency of employing variable A (A linear decreased from fc to 0), default = 2
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.bio_based.SOA import DevSOA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> fc = 2
+    >>> model = DevSOA(epoch, pop_size, fc)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, fc=2,  **kwargs):
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.fc = self.validator.check_float("fc", fc, [1.0, 10.])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        A = self.fc - (epoch+1)*self.fc / self.epoch    # Eq. 6
+        uu = vv = 1
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            B = 2 * A**2 * np.random.random()                                   # Eq. 8
+            M = B * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])     # Eq. 7
+            C = A * self.pop[idx][self.ID_POS]                                  # Eq. 5
+            D = np.abs(C + M)                                                   # Eq. 9
+            k = np.random.uniform(0, 2*np.pi)
+            r = uu * np.exp(k*vv)
+            xx = r * np.cos(k)
+            yy = r * np.sin(k)
+            zz = r * k
+            x_new = xx * yy * zz * D + np.random.normal(0, 1) * self.g_best[self.ID_POS]                 # Eq. 14
+            x_new = self.amend_position(x_new, self.problem.lb, self.problem.ub)
+            pop_new.append([x_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(x_new)
+                self.pop[idx] = self.get_better_solution([x_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+
+class OriginalSOA(Optimizer):
+    """
+    The original version: Seagull Optimization Algorithm (SOA)
+
+    Links:
+        1. https://www.sciencedirect.com/science/article/abs/pii/S0950705118305768
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + fc (float): [1.0, 10.0] -> better [1, 5], freequency of employing variable A (A linear decreased from fc to 0), default = 2
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.bio_based.SOA import OriginalSOA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalSOA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Dhiman, G., & Kumar, V. (2019). Seagull optimization algorithm: Theory and its applications
+    for large-scale industrial engineering problems. Knowledge-based systems, 165, 169-196.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, fc=2,  **kwargs):
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.fc = self.validator.check_float("fc", fc, [1.0, 10.])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        A = self.fc - (epoch+1)*self.fc / self.epoch    # Eq. 6
+        uu = vv = 1
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            B = 2 * A**2 * np.random.random()                                   # Eq. 8
+            M = B * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])     # Eq. 7
+            C = A * self.pop[idx][self.ID_POS]                                  # Eq. 5
+            D = np.abs(C + M)                                                   # Eq. 9
+            k = np.random.uniform(0, 2*np.pi)
+            r = uu * np.exp(k*vv)
+            xx = r * np.cos(k)
+            yy = r * np.sin(k)
+            zz = r * k
+            x_new = xx * yy * zz * D + self.g_best[self.ID_POS]                 # Eq. 14
+            x_new = self.amend_position(x_new, self.problem.lb, self.problem.ub)
+            pop_new.append([x_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(x_new)
+        self.pop = self.update_target_wrapper_population(pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/bio_based/SOS.py` & `mealpy-2.5.3a1/mealpy/bio_based/SOS.py`

 * *Ordering differences only*

 * *Files 16% similar despite different names*

```diff
@@ -1,91 +1,91 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 14:20, 15/10/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalSOS(Optimizer):
-    """
-    The original version: Symbiotic Organisms Search (SOS)
-
-    Links:
-        1. https://doi.org/10.1016/j.compstruc.2014.03.007
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.bio_based.SOS import OriginalSOS
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalSOS(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Cheng, M. Y., & Prayogo, D. (2014). Symbiotic organisms search: a new metaheuristic
-    optimization algorithm. Computers & Structures, 139, 98-112.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.support_parallel_modes = False
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        for idx in range(0, self.pop_size):
-            ## Mutualism Phase
-            jdx = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
-            mutual_vector = (self.pop[idx][self.ID_POS] + self.pop[jdx][self.ID_POS]) / 2
-            bf1, bf2 = np.random.randint(1, 3, 2)
-            xi_new = self.pop[idx][self.ID_POS] + np.random.rand() * (self.g_best[self.ID_POS] - bf1 * mutual_vector)
-            xj_new = self.pop[jdx][self.ID_POS] + np.random.rand() * (self.g_best[self.ID_POS] - bf2 * mutual_vector)
-            xi_new = self.amend_position(xi_new, self.problem.lb, self.problem.ub)
-            xj_new = self.amend_position(xj_new, self.problem.lb, self.problem.ub)
-            xi_tar = self.get_target_wrapper(xi_new)
-            xj_tar = self.get_target_wrapper(xj_new)
-            if self.compare_agent([xi_new, xi_tar], self.pop[idx]):
-                self.pop[idx] = [xi_new, xi_tar]
-            if self.compare_agent([xj_new, xj_tar], self.pop[jdx]):
-                self.pop[jdx] = [xj_new, xj_tar]
-
-            ## Commensalism phase
-            jdx = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
-            xi_new = self.pop[idx][self.ID_POS] + np.random.uniform(-1, 1) * (self.g_best[self.ID_POS] - self.pop[jdx][self.ID_POS])
-            xi_new = self.amend_position(xi_new, self.problem.lb, self.problem.ub)
-            xi_tar = self.get_target_wrapper(xi_new)
-            if self.compare_agent([xi_new, xi_tar], self.pop[idx]):
-                self.pop[idx] = [xi_new, xi_tar]
-
-            ## Parasitism phase
-            jdx = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
-            temp_idx = np.random.randint(0, self.problem.n_dims)
-            xi_new = self.pop[jdx][self.ID_POS].copy()
-            xi_new[temp_idx] = self.generate_position(self.problem.lb, self.problem.ub)[temp_idx]
-            xi_tar = self.get_target_wrapper(xi_new)
-            if self.compare_agent([xi_new, xi_tar], self.pop[idx]):
-                self.pop[idx] = [xi_new, xi_tar]
+#!/usr/bin/env python
+# Created by "Thieu" at 14:20, 15/10/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalSOS(Optimizer):
+    """
+    The original version: Symbiotic Organisms Search (SOS)
+
+    Links:
+        1. https://doi.org/10.1016/j.compstruc.2014.03.007
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.bio_based.SOS import OriginalSOS
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalSOS(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Cheng, M. Y., & Prayogo, D. (2014). Symbiotic organisms search: a new metaheuristic
+    optimization algorithm. Computers & Structures, 139, 98-112.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.support_parallel_modes = False
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        for idx in range(0, self.pop_size):
+            ## Mutualism Phase
+            jdx = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
+            mutual_vector = (self.pop[idx][self.ID_POS] + self.pop[jdx][self.ID_POS]) / 2
+            bf1, bf2 = np.random.randint(1, 3, 2)
+            xi_new = self.pop[idx][self.ID_POS] + np.random.rand() * (self.g_best[self.ID_POS] - bf1 * mutual_vector)
+            xj_new = self.pop[jdx][self.ID_POS] + np.random.rand() * (self.g_best[self.ID_POS] - bf2 * mutual_vector)
+            xi_new = self.amend_position(xi_new, self.problem.lb, self.problem.ub)
+            xj_new = self.amend_position(xj_new, self.problem.lb, self.problem.ub)
+            xi_tar = self.get_target_wrapper(xi_new)
+            xj_tar = self.get_target_wrapper(xj_new)
+            if self.compare_agent([xi_new, xi_tar], self.pop[idx]):
+                self.pop[idx] = [xi_new, xi_tar]
+            if self.compare_agent([xj_new, xj_tar], self.pop[jdx]):
+                self.pop[jdx] = [xj_new, xj_tar]
+
+            ## Commensalism phase
+            jdx = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
+            xi_new = self.pop[idx][self.ID_POS] + np.random.uniform(-1, 1) * (self.g_best[self.ID_POS] - self.pop[jdx][self.ID_POS])
+            xi_new = self.amend_position(xi_new, self.problem.lb, self.problem.ub)
+            xi_tar = self.get_target_wrapper(xi_new)
+            if self.compare_agent([xi_new, xi_tar], self.pop[idx]):
+                self.pop[idx] = [xi_new, xi_tar]
+
+            ## Parasitism phase
+            jdx = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
+            temp_idx = np.random.randint(0, self.problem.n_dims)
+            xi_new = self.pop[jdx][self.ID_POS].copy()
+            xi_new[temp_idx] = self.generate_position(self.problem.lb, self.problem.ub)[temp_idx]
+            xi_tar = self.get_target_wrapper(xi_new)
+            if self.compare_agent([xi_new, xi_tar], self.pop[idx]):
+                self.pop[idx] = [xi_new, xi_tar]
```

### Comparing `mealpy-2.5.3/mealpy/bio_based/TPO.py` & `mealpy-2.5.3a1/mealpy/bio_based/TPO.py`

 * *Ordering differences only*

 * *Files 11% similar despite different names*

```diff
@@ -1,123 +1,123 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 00:27, 18/03/2023 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalTPO(Optimizer):
-    """
-    The original version: Tree Physiology Optimization (TPO)
-
-    Links:
-        1. https://www.mathworks.com/matlabcentral/fileexchange/63982-tree-physiology-optimization-tpo-algorithm-for-stochastic-test-function-optimization
-
-    Notes:
-        1. The paper is difficult to read and understand, and the provided MATLAB code is also challenging to understand.
-        2. Based on my idea:
-            + pop_size = number of branhes, the population size should be equal to the number of branches.
-            + The number of leaves should be calculated as int(sqrt(pop_size) + 1), so we don't need to specify the n_leafs parameter, which will also reduce computation time.
-            + When using this algorithm, especially when setting stopping conditions, be careful and set it to the FE type.
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + alpha (float): [-10, 10.] -> better [0.2, 0.5], Absorption constant for tree root elongation, default = 0.5
-        + beta (float): [-100, 100.] -> better [10, 50], Diversification facor of tree shoot, default=50.
-        + theta (float): (0, 1.0] -> better [0.5, 0.9], Factor to reduce randomization, Theta = Power law to reduce randomization as iteration increases, default=0.9
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.bio_based.TPO import OriginalTPO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> alpha = 0.3
-    >>> beta = 50.
-    >>> theta = 0.9
-    >>> model = OriginalTPO(epoch, pop_size, alpha, beta, theta)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Halim, A. H., & Ismail, I. (2017). Tree physiology optimization in benchmark function and
-    traveling salesman problem. Journal of Intelligent Systems, 28(5), 849-871.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, alpha=0.3, beta=50.0, theta=0.9, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            alpha (float): Absorption constant for tree root elongation, default=0.3
-            beta (float): Diversification factor of tree shoot, default=50.
-            theta (float): Factor to reduce randomization, Theta = Power law to reduce randomization as iteration increases, default=0.9
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])     # Number of branches
-        self.alpha = self.validator.check_float("alpha", alpha, [-10.0, 10.])
-        self.beta = self.validator.check_float("beta", beta, [-100., 100])
-        self.theta = self.validator.check_float("theta", theta, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size"])
-        self.support_parallel_modes = False
-        self.sort_flag = False
-
-    def initialize_variables(self):
-        """
-        The idea is a tree has a pop_size of branches (n_branches), each branch will have several leafs.
-        """
-        self.n_leafs = int(np.sqrt(self.pop_size) + 1)  # Number of leafs
-        self._theta = self.theta
-        self.roots = np.random.uniform(0, 1, (self.n_leafs, self.problem.n_dims))
-
-    def initialization(self):
-        self.pop_total = []
-        self.pop = []                       # The best leaf in each branches
-        for idx in range(self.pop_size):
-            leafs = self.create_population(self.n_leafs)
-            _, best = self.get_global_best_solution(leafs)
-            self.pop.append(best)
-            self.pop_total.append(leafs)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        for idx in range(0, self.pop_size):
-            pos_list = np.array([agent[self.ID_POS] for agent in self.pop_total[idx]])
-            carbon_gain = self._theta * self.g_best[self.ID_POS] - pos_list
-            roots_old = np.copy(self.roots)
-            self.roots += self.alpha * carbon_gain * np.random.uniform(-0.5, 0.5, (self.n_leafs, self.problem.n_dims))
-            nutrient_value = self._theta * (self.roots - roots_old)
-            pos_list_new = self.g_best[self.ID_POS] + self.beta * nutrient_value
-            pop_new = []
-            for jdx in range(0, self.n_leafs):
-                pos_new = self.amend_position(pos_list_new[jdx], self.problem.lb, self.problem.ub)
-                pop_new.append([pos_new, None])
-                if self.mode not in self.AVAILABLE_MODES:
-                    target = self.get_target_wrapper(pos_new)
-                    self.pop_total[idx][jdx] = self.get_better_solution([pos_new, target], self.pop_total[idx][jdx])
-            if self.mode in self.AVAILABLE_MODES:
-                pop_new = self.update_target_wrapper_population(pop_new)
-                self.pop_total[idx] = self.greedy_selection_population(pop_new, self.pop_total[idx])
-        self._theta = self._theta * self.theta
-        for idx in range(0, self.pop_size):
-            _, best = self.get_global_best_solution(self.pop_total[idx])
-            self.pop[idx] = best
+#!/usr/bin/env python
+# Created by "Thieu" at 00:27, 18/03/2023 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalTPO(Optimizer):
+    """
+    The original version: Tree Physiology Optimization (TPO)
+
+    Links:
+        1. https://www.mathworks.com/matlabcentral/fileexchange/63982-tree-physiology-optimization-tpo-algorithm-for-stochastic-test-function-optimization
+
+    Notes:
+        1. The paper is difficult to read and understand, and the provided MATLAB code is also challenging to understand.
+        2. Based on my idea:
+            + pop_size = number of branhes, the population size should be equal to the number of branches.
+            + The number of leaves should be calculated as int(sqrt(pop_size) + 1), so we don't need to specify the n_leafs parameter, which will also reduce computation time.
+            + When using this algorithm, especially when setting stopping conditions, be careful and set it to the FE type.
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + alpha (float): [-10, 10.] -> better [0.2, 0.5], Absorption constant for tree root elongation, default = 0.5
+        + beta (float): [-100, 100.] -> better [10, 50], Diversification facor of tree shoot, default=50.
+        + theta (float): (0, 1.0] -> better [0.5, 0.9], Factor to reduce randomization, Theta = Power law to reduce randomization as iteration increases, default=0.9
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.bio_based.TPO import OriginalTPO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> alpha = 0.3
+    >>> beta = 50.
+    >>> theta = 0.9
+    >>> model = OriginalTPO(epoch, pop_size, alpha, beta, theta)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Halim, A. H., & Ismail, I. (2017). Tree physiology optimization in benchmark function and
+    traveling salesman problem. Journal of Intelligent Systems, 28(5), 849-871.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, alpha=0.3, beta=50.0, theta=0.9, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            alpha (float): Absorption constant for tree root elongation, default=0.3
+            beta (float): Diversification factor of tree shoot, default=50.
+            theta (float): Factor to reduce randomization, Theta = Power law to reduce randomization as iteration increases, default=0.9
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])     # Number of branches
+        self.alpha = self.validator.check_float("alpha", alpha, [-10.0, 10.])
+        self.beta = self.validator.check_float("beta", beta, [-100., 100])
+        self.theta = self.validator.check_float("theta", theta, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size"])
+        self.support_parallel_modes = False
+        self.sort_flag = False
+
+    def initialize_variables(self):
+        """
+        The idea is a tree has a pop_size of branches (n_branches), each branch will have several leafs.
+        """
+        self.n_leafs = int(np.sqrt(self.pop_size) + 1)  # Number of leafs
+        self._theta = self.theta
+        self.roots = np.random.uniform(0, 1, (self.n_leafs, self.problem.n_dims))
+
+    def initialization(self):
+        self.pop_total = []
+        self.pop = []                       # The best leaf in each branches
+        for idx in range(self.pop_size):
+            leafs = self.create_population(self.n_leafs)
+            _, best = self.get_global_best_solution(leafs)
+            self.pop.append(best)
+            self.pop_total.append(leafs)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        for idx in range(0, self.pop_size):
+            pos_list = np.array([agent[self.ID_POS] for agent in self.pop_total[idx]])
+            carbon_gain = self._theta * self.g_best[self.ID_POS] - pos_list
+            roots_old = np.copy(self.roots)
+            self.roots += self.alpha * carbon_gain * np.random.uniform(-0.5, 0.5, (self.n_leafs, self.problem.n_dims))
+            nutrient_value = self._theta * (self.roots - roots_old)
+            pos_list_new = self.g_best[self.ID_POS] + self.beta * nutrient_value
+            pop_new = []
+            for jdx in range(0, self.n_leafs):
+                pos_new = self.amend_position(pos_list_new[jdx], self.problem.lb, self.problem.ub)
+                pop_new.append([pos_new, None])
+                if self.mode not in self.AVAILABLE_MODES:
+                    target = self.get_target_wrapper(pos_new)
+                    self.pop_total[idx][jdx] = self.get_better_solution([pos_new, target], self.pop_total[idx][jdx])
+            if self.mode in self.AVAILABLE_MODES:
+                pop_new = self.update_target_wrapper_population(pop_new)
+                self.pop_total[idx] = self.greedy_selection_population(pop_new, self.pop_total[idx])
+        self._theta = self._theta * self.theta
+        for idx in range(0, self.pop_size):
+            _, best = self.get_global_best_solution(self.pop_total[idx])
+            self.pop[idx] = best
```

### Comparing `mealpy-2.5.3/mealpy/bio_based/TSA.py` & `mealpy-2.5.3a1/mealpy/bio_based/TSA.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,84 +1,84 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 17:23, 21/05/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalTSA(Optimizer):
-    """
-    The original version: Tunicate Swarm Algorithm (TSA)
-
-    Links:
-        1. https://www.sciencedirect.com/science/article/abs/pii/S0952197620300385?via%3Dihub
-        2. https://www.mathworks.com/matlabcentral/fileexchange/75182-tunicate-swarm-algorithm-tsa
-
-    Notes:
-        1. This algorithm has some limitations
-        2. The paper has several wrong equations in algorithm
-        3. The implementation in Matlab code has some difference to the paper
-        4. This algorithm shares some similarities with the Barnacles Mating Optimizer (BMO)
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.bio_based.TSA import OriginalTSA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalTSA(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Kaur, S., Awasthi, L. K., Sangal, A. L., & Dhiman, G. (2020). Tunicate Swarm Algorithm: A new bio-inspired
-    based metaheuristic paradigm for global optimization. Engineering Applications of Artificial Intelligence, 90, 103541.
-    """
-
-    ID_WEI = 2
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pmin, pmax = 1, 4
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            c3 = np.random.random(self.problem.n_dims)
-            c2 = np.random.random(self.problem.n_dims)
-            c1 = np.random.random(self.problem.n_dims)
-            M = np.fix(pmin + np.random.rand() * (pmax - pmin))
-            A = (c2 + c3 - 2 * c1) / M
-            t1 = self.g_best[self.ID_POS] + A * np.abs(self.g_best[self.ID_POS] - c2 * self.pop[idx][self.ID_POS])
-            t2 = self.g_best[self.ID_POS] - A * np.abs(self.g_best[self.ID_POS] - c2 * self.pop[idx][self.ID_POS])
-            new_pos = np.where(c3 >= 0.5, t1, t2)
-            if idx != 0:
-                new_pos = (new_pos + self.pop[idx-1][self.ID_POS]) / 2
-            new_pos = self.amend_position(new_pos, self.problem.lb, self.problem.ub)
-            pop_new.append([new_pos, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(new_pos)
-        self.pop = self.update_target_wrapper_population(pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 17:23, 21/05/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalTSA(Optimizer):
+    """
+    The original version: Tunicate Swarm Algorithm (TSA)
+
+    Links:
+        1. https://www.sciencedirect.com/science/article/abs/pii/S0952197620300385?via%3Dihub
+        2. https://www.mathworks.com/matlabcentral/fileexchange/75182-tunicate-swarm-algorithm-tsa
+
+    Notes:
+        1. Weakest algorithm in the list
+        2. The paper has so many wrong equations in algorithm
+        3. Matlab code different to the paper
+        4. This algorithm is typical similar to Barnacles Mating Optimizer (BMO)
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.bio_based.TSA import OriginalTSA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalTSA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Kaur, S., Awasthi, L. K., Sangal, A. L., & Dhiman, G. (2020). Tunicate Swarm Algorithm: A new bio-inspired
+    based metaheuristic paradigm for global optimization. Engineering Applications of Artificial Intelligence, 90, 103541.
+    """
+
+    ID_WEI = 2
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pmin, pmax = 1, 4
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            c3 = np.random.random(self.problem.n_dims)
+            c2 = np.random.random(self.problem.n_dims)
+            c1 = np.random.random(self.problem.n_dims)
+            M = np.fix(pmin + np.random.rand() * (pmax - pmin))
+            A = (c2 + c3 - 2 * c1) / M
+            t1 = self.g_best[self.ID_POS] + A * np.abs(self.g_best[self.ID_POS] - c2 * self.pop[idx][self.ID_POS])
+            t2 = self.g_best[self.ID_POS] - A * np.abs(self.g_best[self.ID_POS] - c2 * self.pop[idx][self.ID_POS])
+            new_pos = np.where(c3 >= 0.5, t1, t2)
+            if idx != 0:
+                new_pos = (new_pos + self.pop[idx-1][self.ID_POS]) / 2
+            new_pos = self.amend_position(new_pos, self.problem.lb, self.problem.ub)
+            pop_new.append([new_pos, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(new_pos)
+        self.pop = self.update_target_wrapper_population(pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/bio_based/VCS.py` & `mealpy-2.5.3a1/mealpy/bio_based/VCS.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,261 +1,261 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 22:07, 11/04/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class BaseVCS(Optimizer):
-    """
-    The developed version: Virus Colony Search (VCS)
-
-    Links:
-        1. https://doi.org/10.1016/j.advengsoft.2015.11.004
-
-    Notes
-    ~~~~~
-    + In Immune response process, updates the whole position instead of updating each variable in position
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + lamda (float): (0, 1.0) -> better [0.2, 0.5], Percentage of the number of the best will keep, default = 0.5
-        + sigma (float): (0, 5.0) -> better [0.1, 2.0], Weight factor
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.bio_based.VCS import BaseVCS
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> lamda = 0.5
-    >>> sigma = 0.3
-    >>> model = BaseVCS(epoch, pop_size, lamda, sigma)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, lamda=0.5, sigma=1.5, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            lamda (float): Percentage of the number of the best will keep, default = 0.5
-            sigma (float): Weight factor, default = 1.5
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.lamda = self.validator.check_float("lamda", lamda, (0, 1.0))
-        self.sigma = self.validator.check_float("sigma", sigma, (0, 5.0))
-        self.n_best = int(self.lamda * self.pop_size)
-        self.set_parameters(["epoch", "pop_size", "lamda", "sigma"])
-        self.sort_flag = True
-
-    def calculate_xmean__(self, pop):
-        """
-        Calculate the mean position of list of solutions (population)
-
-        Args:
-            pop (list): List of solutions (population)
-
-        Returns:
-            list: Mean position
-        """
-        ## Calculate the weighted mean of the Î» best individuals by
-        pop, local_best = self.get_global_best_solution(pop)
-        pos_list = [agent[self.ID_POS] for agent in pop[:self.n_best]]
-        factor_down = self.n_best * np.log1p(self.n_best + 1) - np.log1p(np.prod(range(1, self.n_best + 1)))
-        weight = np.log1p(self.n_best + 1) / factor_down
-        weight = weight / self.n_best
-        x_mean = weight * np.sum(pos_list, axis=0)
-        return x_mean
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        ## Viruses diffusion
-        pop = []
-        for idx in range(0, self.pop_size):
-            sigma = (np.log1p(epoch + 1) / self.epoch) * (self.pop[idx][self.ID_POS] - self.g_best[self.ID_POS])
-            gauss = np.random.normal(np.random.normal(self.g_best[self.ID_POS], np.abs(sigma)))
-            pos_new = gauss + np.random.uniform() * self.g_best[self.ID_POS] - np.random.uniform() * self.pop[idx][self.ID_POS]
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop = self.update_target_wrapper_population(pop)
-            self.pop = self.greedy_selection_population(pop, self.pop)
-
-        ## Host cells infection
-        x_mean = self.calculate_xmean__(self.pop)
-        sigma = self.sigma * (1 - (epoch + 1) / self.epoch)
-        pop = []
-        for idx in range(0, self.pop_size):
-            ## Basic / simple version, not the original version in the paper
-            pos_new = x_mean + sigma * np.random.normal(0, 1, self.problem.n_dims)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop = self.update_target_wrapper_population(pop)
-            self.pop = self.greedy_selection_population(pop, self.pop)
-
-        ## Calculate the weighted mean of the Î» best individuals by
-        self.pop, g_best = self.get_global_best_solution(self.pop)
-
-        ## Immune response
-        pop = []
-        for idx in range(0, self.pop_size):
-            pr = (self.problem.n_dims - idx + 1) / self.problem.n_dims
-            id1, id2 = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 2, replace=False)
-            temp = self.pop[id1][self.ID_POS] - (self.pop[id2][self.ID_POS] - self.pop[idx][self.ID_POS]) * np.random.uniform()
-            condition = np.random.random(self.problem.n_dims) < pr
-            pos_new = np.where(condition, self.pop[idx][self.ID_POS], temp)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop = self.update_target_wrapper_population(pop)
-            self.pop = self.greedy_selection_population(pop, self.pop)
-
-
-class OriginalVCS(BaseVCS):
-    """
-    The original version of: Virus Colony Search (VCS)
-
-    Links:
-        1. https://doi.org/10.1016/j.advengsoft.2015.11.004
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + lamda (float): (0, 1.0) -> better [0.2, 0.5], Percentage of the number of the best will keep, default = 0.5
-        + sigma (float): (0, 5.0) -> better [0.1, 2.0], Weight factor
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.bio_based.VCS import OriginalVCS
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> lamda = 0.5
-    >>> sigma = 0.3
-    >>> model = OriginalVCS(epoch, pop_size, lamda, sigma)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Li, M.D., Zhao, H., Weng, X.W. and Han, T., 2016. A novel nature-inspired algorithm
-    for optimization: Virus colony search. Advances in Engineering Software, 92, pp.65-88.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, lamda=0.5, sigma=1.5, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            lamda (float): Number of the best will keep, default = 0.5
-            sigma (float): Weight factor, default = 1.5
-        """
-        super().__init__(epoch, pop_size, lamda, sigma, **kwargs)
-
-    def amend_position(self, position=None, lb=None, ub=None):
-        """
-        Args:
-            position: vector position (location) of the solution.
-            lb: list of lower bound values
-            ub: list of upper bound values
-
-        Returns:
-            Amended position (make the position is in bound)
-        """
-        condition = np.logical_and(lb <= position, position <= ub)
-        random_pos = np.random.uniform(lb, ub)
-        return np.where(condition, position, random_pos)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        ## Viruses diffusion
-        pop = []
-        for idx in range(0, self.pop_size):
-            sigma = (np.log1p(epoch + 1) / self.epoch) * (self.pop[idx][self.ID_POS] - self.g_best[self.ID_POS])
-            gauss = np.array([np.random.normal(self.g_best[self.ID_POS][j], np.abs(sigma[j])) for j in range(0, self.problem.n_dims)])
-            pos_new = gauss + np.random.uniform() * self.g_best[self.ID_POS] - np.random.uniform() * self.pop[idx][self.ID_POS]
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop = self.update_target_wrapper_population(pop)
-            self.pop = self.greedy_selection_population(pop, self.pop)
-
-        ## Host cells infection
-        x_mean = self.calculate_xmean__(self.pop)
-        sigma = self.sigma * (1 - (epoch + 1) / self.epoch)
-        pop = []
-        for idx in range(0, self.pop_size):
-            ## Basic / simple version, not the original version in the paper
-            pos_new = x_mean + sigma * np.random.normal(0, 1, self.problem.n_dims)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop = self.update_target_wrapper_population(pop)
-            self.pop = self.greedy_selection_population(pop, self.pop)
-
-        ## Immune response
-        for idx in range(0, self.pop_size):
-            pr = (self.problem.n_dims - idx + 1) / self.problem.n_dims
-            pos_new = pop[idx][self.ID_POS]
-            for j in range(0, self.problem.n_dims):
-                if np.random.uniform() > pr:
-                    id1, id2 = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 2, replace=False)
-                    pos_new[j] = pop[id1][self.ID_POS][j] - (pop[id2][self.ID_POS][j] - pop[idx][self.ID_POS][j]) * np.random.uniform()
-            pop[idx][self.ID_POS] = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop = self.update_target_wrapper_population(pop)
-            self.pop = self.greedy_selection_population(pop, self.pop)
+#!/usr/bin/env python
+# Created by "Thieu" at 22:07, 11/04/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class BaseVCS(Optimizer):
+    """
+    The developed version: Virus Colony Search (VCS)
+
+    Links:
+        1. https://doi.org/10.1016/j.advengsoft.2015.11.004
+
+    Notes
+    ~~~~~
+    + In Immune response process, updates the whole position instead of updating each variable in position
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + lamda (float): (0, 1.0) -> better [0.2, 0.5], Percentage of the number of the best will keep, default = 0.5
+        + sigma (float): (0, 5.0) -> better [0.1, 2.0], Weight factor
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.bio_based.VCS import BaseVCS
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> lamda = 0.5
+    >>> sigma = 0.3
+    >>> model = BaseVCS(epoch, pop_size, lamda, sigma)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, lamda=0.5, sigma=1.5, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            lamda (float): Percentage of the number of the best will keep, default = 0.5
+            sigma (float): Weight factor, default = 1.5
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.lamda = self.validator.check_float("lamda", lamda, (0, 1.0))
+        self.sigma = self.validator.check_float("sigma", sigma, (0, 5.0))
+        self.n_best = int(self.lamda * self.pop_size)
+        self.set_parameters(["epoch", "pop_size", "lamda", "sigma"])
+        self.sort_flag = True
+
+    def calculate_xmean__(self, pop):
+        """
+        Calculate the mean position of list of solutions (population)
+
+        Args:
+            pop (list): List of solutions (population)
+
+        Returns:
+            list: Mean position
+        """
+        ## Calculate the weighted mean of the Î» best individuals by
+        pop, local_best = self.get_global_best_solution(pop)
+        pos_list = [agent[self.ID_POS] for agent in pop[:self.n_best]]
+        factor_down = self.n_best * np.log1p(self.n_best + 1) - np.log1p(np.prod(range(1, self.n_best + 1)))
+        weight = np.log1p(self.n_best + 1) / factor_down
+        weight = weight / self.n_best
+        x_mean = weight * np.sum(pos_list, axis=0)
+        return x_mean
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        ## Viruses diffusion
+        pop = []
+        for idx in range(0, self.pop_size):
+            sigma = (np.log1p(epoch + 1) / self.epoch) * (self.pop[idx][self.ID_POS] - self.g_best[self.ID_POS])
+            gauss = np.random.normal(np.random.normal(self.g_best[self.ID_POS], np.abs(sigma)))
+            pos_new = gauss + np.random.uniform() * self.g_best[self.ID_POS] - np.random.uniform() * self.pop[idx][self.ID_POS]
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop = self.update_target_wrapper_population(pop)
+            self.pop = self.greedy_selection_population(pop, self.pop)
+
+        ## Host cells infection
+        x_mean = self.calculate_xmean__(self.pop)
+        sigma = self.sigma * (1 - (epoch + 1) / self.epoch)
+        pop = []
+        for idx in range(0, self.pop_size):
+            ## Basic / simple version, not the original version in the paper
+            pos_new = x_mean + sigma * np.random.normal(0, 1, self.problem.n_dims)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop = self.update_target_wrapper_population(pop)
+            self.pop = self.greedy_selection_population(pop, self.pop)
+
+        ## Calculate the weighted mean of the Î» best individuals by
+        self.pop, g_best = self.get_global_best_solution(self.pop)
+
+        ## Immune response
+        pop = []
+        for idx in range(0, self.pop_size):
+            pr = (self.problem.n_dims - idx + 1) / self.problem.n_dims
+            id1, id2 = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 2, replace=False)
+            temp = self.pop[id1][self.ID_POS] - (self.pop[id2][self.ID_POS] - self.pop[idx][self.ID_POS]) * np.random.uniform()
+            condition = np.random.random(self.problem.n_dims) < pr
+            pos_new = np.where(condition, self.pop[idx][self.ID_POS], temp)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop = self.update_target_wrapper_population(pop)
+            self.pop = self.greedy_selection_population(pop, self.pop)
+
+
+class OriginalVCS(BaseVCS):
+    """
+    The original version of: Virus Colony Search (VCS)
+
+    Links:
+        1. https://doi.org/10.1016/j.advengsoft.2015.11.004
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + lamda (float): (0, 1.0) -> better [0.2, 0.5], Percentage of the number of the best will keep, default = 0.5
+        + sigma (float): (0, 5.0) -> better [0.1, 2.0], Weight factor
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.bio_based.VCS import OriginalVCS
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> lamda = 0.5
+    >>> sigma = 0.3
+    >>> model = OriginalVCS(epoch, pop_size, lamda, sigma)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Li, M.D., Zhao, H., Weng, X.W. and Han, T., 2016. A novel nature-inspired algorithm
+    for optimization: Virus colony search. Advances in Engineering Software, 92, pp.65-88.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, lamda=0.5, sigma=1.5, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            lamda (float): Number of the best will keep, default = 0.5
+            sigma (float): Weight factor, default = 1.5
+        """
+        super().__init__(epoch, pop_size, lamda, sigma, **kwargs)
+
+    def amend_position(self, position=None, lb=None, ub=None):
+        """
+        Args:
+            position: vector position (location) of the solution.
+            lb: list of lower bound values
+            ub: list of upper bound values
+
+        Returns:
+            Amended position (make the position is in bound)
+        """
+        condition = np.logical_and(lb <= position, position <= ub)
+        random_pos = np.random.uniform(lb, ub)
+        return np.where(condition, position, random_pos)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        ## Viruses diffusion
+        pop = []
+        for idx in range(0, self.pop_size):
+            sigma = (np.log1p(epoch + 1) / self.epoch) * (self.pop[idx][self.ID_POS] - self.g_best[self.ID_POS])
+            gauss = np.array([np.random.normal(self.g_best[self.ID_POS][j], np.abs(sigma[j])) for j in range(0, self.problem.n_dims)])
+            pos_new = gauss + np.random.uniform() * self.g_best[self.ID_POS] - np.random.uniform() * self.pop[idx][self.ID_POS]
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop = self.update_target_wrapper_population(pop)
+            self.pop = self.greedy_selection_population(pop, self.pop)
+
+        ## Host cells infection
+        x_mean = self.calculate_xmean__(self.pop)
+        sigma = self.sigma * (1 - (epoch + 1) / self.epoch)
+        pop = []
+        for idx in range(0, self.pop_size):
+            ## Basic / simple version, not the original version in the paper
+            pos_new = x_mean + sigma * np.random.normal(0, 1, self.problem.n_dims)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop = self.update_target_wrapper_population(pop)
+            self.pop = self.greedy_selection_population(pop, self.pop)
+
+        ## Immune response
+        for idx in range(0, self.pop_size):
+            pr = (self.problem.n_dims - idx + 1) / self.problem.n_dims
+            pos_new = pop[idx][self.ID_POS]
+            for j in range(0, self.problem.n_dims):
+                if np.random.uniform() > pr:
+                    id1, id2 = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 2, replace=False)
+                    pos_new[j] = pop[id1][self.ID_POS][j] - (pop[id2][self.ID_POS][j] - pop[idx][self.ID_POS][j]) * np.random.uniform()
+            pop[idx][self.ID_POS] = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop = self.update_target_wrapper_population(pop)
+            self.pop = self.greedy_selection_population(pop, self.pop)
```

### Comparing `mealpy-2.5.3/mealpy/bio_based/WHO.py` & `mealpy-2.5.3a1/mealpy/bio_based/WHO.py`

 * *Ordering differences only*

 * *Files 15% similar despite different names*

```diff
@@ -1,180 +1,180 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 12:51, 18/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalWHO(Optimizer):
-    """
-    The original version of: Wildebeest Herd Optimization (WHO)
-
-    Links:
-        1. https://doi.org/10.3233/JIFS-190495
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + n_explore_step (int): [2, 10] -> better [2, 4], number of exploration step
-        + n_exploit_step (int): [2, 10] -> better [2, 4], number of exploitation step
-        + eta (float): (0, 1.0) -> better [0.05, 0.5], learning rate
-        + p_hi (float): (0, 1.0) -> better [0.7, 0.95], the probability of wildebeest move to another position based on herd instinct
-        + local_alpha (float): (0, 3.0) -> better [0.5, 0.9], control local movement (alpha 1)
-        + local_beta (float): (0, 3.0) -> better [0.1, 0.5], control local movement (beta 1)
-        + global_alpha (float): (0, 3.0) -> better [0.1, 0.5], control global movement (alpha 2)
-        + global_beta (float): (0, 3.0), control global movement (beta 2)
-        + delta_w (float): (0.5, 5.0) -> better [1.0, 2.0], dist to worst
-        + delta_c (float): (0.5, 5.0) -> better [1.0, 2.0], dist to best
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.bio_based.WHO import OriginalWHO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> n_explore_step = 3
-    >>> n_exploit_step = 3
-    >>> eta = 0.15
-    >>> p_hi = 0.9
-    >>> local_alpha=0.9
-    >>> local_beta=0.3
-    >>> global_alpha=0.2
-    >>> global_beta=0.8
-    >>> delta_w=2.0
-    >>> delta_c=2.0
-    >>> model = OriginalWHO(epoch, pop_size, n_explore_step, n_exploit_step, eta, p_hi, local_alpha, local_beta,
-    >>>                     global_alpha, global_beta, delta_w, delta_c)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Amali, D. and Dinakaran, M., 2019. Wildebeest herd optimization: a new global optimization algorithm inspired
-    by wildebeest herding behaviour. Journal of Intelligent & Fuzzy Systems, 37(6), pp.8063-8076.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, n_explore_step=3, n_exploit_step=3, eta=0.15, p_hi=0.9,
-                 local_alpha=0.9, local_beta=0.3, global_alpha=0.2, global_beta=0.8, delta_w=2.0, delta_c=2.0, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            n_explore_step (int): default = 3, number of exploration step
-            n_exploit_step (int): default = 3, number of exploitation step
-            eta (float): default = 0.15, learning rate
-            p_hi (float): default = 0.9, the probability of wildebeest move to another position based on herd instinct
-            local_alpha (float): control local movement (alpha 1)
-            local_beta (float): control local movement (beta 1)
-            global_alpha (float): control global movement (alpha 2)
-            global_beta (float): control global movement (beta 2)
-            delta_w (float): dist to worst
-            delta_c (float): dist to best
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.n_explore_step = self.validator.check_int("n_explore_step", n_explore_step, [2, 10])
-        self.n_exploit_step = self.validator.check_int("n_exploit_step", n_exploit_step, [2, 10])
-        self.eta = self.validator.check_float("eta", eta, (0, 1.0))
-        self.p_hi = self.validator.check_float("p_hi", p_hi, (0, 1.0))
-        self.local_alpha = self.validator.check_float("local_alpha", local_alpha, (0, 3.0))
-        self.local_beta = self.validator.check_float("local_beta", local_beta, (0, 3.0))
-        self.global_alpha = self.validator.check_float("global_alpha", global_alpha, (0, 3.0))
-        self.global_beta = self.validator.check_float("global_beta", global_beta, (0, 3.0))
-        self.delta_w = self.validator.check_float("delta_w", delta_w, (0.5, 5.0))
-        self.delta_c = self.validator.check_float("delta_c", delta_c, (0.5, 5.0))
-        self.set_parameters(["epoch", "pop_size", "n_explore_step", "n_exploit_step",
-                             "eta", "p_hi", "local_alpha", "local_beta", "global_alpha", "global_beta", "delta_w", "delta_c"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        ## Begin the Wildebeest Herd Optimization process
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            ### 1. Local movement (Milling behaviour)
-            local_list = []
-            for j in range(0, self.n_explore_step):
-                temp = self.pop[idx][self.ID_POS] + self.eta * np.random.uniform() * np.random.uniform(self.problem.lb, self.problem.ub)
-                pos_new = self.amend_position(temp, self.problem.lb, self.problem.ub)
-                local_list.append([pos_new, None])
-                if self.mode not in self.AVAILABLE_MODES:
-                    local_list[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-            local_list = self.update_target_wrapper_population(local_list)
-            _, best_local = self.get_global_best_solution(local_list)
-            temp = self.local_alpha * best_local[self.ID_POS] + self.local_beta * (self.pop[idx][self.ID_POS] - best_local[self.ID_POS])
-            pos_new = self.amend_position(temp, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-        for idx in range(0, self.pop_size):
-            ### 2. Herd instinct
-            idr = np.random.choice(range(0, self.pop_size))
-            if self.compare_agent(self.pop[idr], self.pop[idx]) and np.random.rand() < self.p_hi:
-                temp = self.global_alpha * self.pop[idx][self.ID_POS] + self.global_beta * self.pop[idr][self.ID_POS]
-                pos_new = self.amend_position(temp, self.problem.lb, self.problem.ub)
-                target = self.get_target_wrapper(pos_new)
-                if self.compare_agent([pos_new, target], self.pop[idx]):
-                    self.pop[idx] = [pos_new, target]
-
-        _, best, worst = self.get_special_solutions(self.pop, best=1, worst=1)
-        g_best, g_worst = best[0], worst[0]
-
-        pop_child = []
-        for idx in range(0, self.pop_size):
-            dist_to_worst = np.linalg.norm(self.pop[idx][self.ID_POS] - g_worst[self.ID_POS])
-            dist_to_best = np.linalg.norm(self.pop[idx][self.ID_POS] - g_best[self.ID_POS])
-
-            ### 3. Starvation avoidance
-            if dist_to_worst < self.delta_w:
-                temp = self.pop[idx][self.ID_POS] + np.random.uniform() * (self.problem.ub - self.problem.lb) * \
-                       np.random.uniform(self.problem.lb, self.problem.ub)
-                pos_new = self.amend_position(temp, self.problem.lb, self.problem.ub)
-                pop_child.append([pos_new, None])
-                if self.mode not in self.AVAILABLE_MODES:
-                    target = self.get_target_wrapper(pos_new)
-                    self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-
-            ### 4. Population pressure
-            if 1.0 < dist_to_best and dist_to_best < self.delta_c:
-                temp = g_best[self.ID_POS] + self.eta * np.random.uniform(self.problem.lb, self.problem.ub)
-                pos_new = self.amend_position(temp, self.problem.lb, self.problem.ub)
-                pop_child.append([pos_new, None])
-                if self.mode not in self.AVAILABLE_MODES:
-                    target = self.get_target_wrapper(pos_new)
-                    self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-
-            ### 5. Herd social memory
-            for j in range(0, self.n_exploit_step):
-                temp = g_best[self.ID_POS] + 0.1 * np.random.uniform(self.problem.lb, self.problem.ub)
-                pos_new = self.amend_position(temp, self.problem.lb, self.problem.ub)
-                pop_child.append([pos_new, None])
-                if self.mode not in self.AVAILABLE_MODES:
-                    target = self.get_target_wrapper(pos_new)
-                    self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_child = self.update_target_wrapper_population(pop_child)
-            pop_child = self.get_sorted_strim_population(pop_child, self.pop_size)
-            self.pop = self.greedy_selection_population(pop_child, self.pop)
+#!/usr/bin/env python
+# Created by "Thieu" at 12:51, 18/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalWHO(Optimizer):
+    """
+    The original version of: Wildebeest Herd Optimization (WHO)
+
+    Links:
+        1. https://doi.org/10.3233/JIFS-190495
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + n_explore_step (int): [2, 10] -> better [2, 4], number of exploration step
+        + n_exploit_step (int): [2, 10] -> better [2, 4], number of exploitation step
+        + eta (float): (0, 1.0) -> better [0.05, 0.5], learning rate
+        + p_hi (float): (0, 1.0) -> better [0.7, 0.95], the probability of wildebeest move to another position based on herd instinct
+        + local_alpha (float): (0, 3.0) -> better [0.5, 0.9], control local movement (alpha 1)
+        + local_beta (float): (0, 3.0) -> better [0.1, 0.5], control local movement (beta 1)
+        + global_alpha (float): (0, 3.0) -> better [0.1, 0.5], control global movement (alpha 2)
+        + global_beta (float): (0, 3.0), control global movement (beta 2)
+        + delta_w (float): (0.5, 5.0) -> better [1.0, 2.0], dist to worst
+        + delta_c (float): (0.5, 5.0) -> better [1.0, 2.0], dist to best
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.bio_based.WHO import OriginalWHO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> n_explore_step = 3
+    >>> n_exploit_step = 3
+    >>> eta = 0.15
+    >>> p_hi = 0.9
+    >>> local_alpha=0.9
+    >>> local_beta=0.3
+    >>> global_alpha=0.2
+    >>> global_beta=0.8
+    >>> delta_w=2.0
+    >>> delta_c=2.0
+    >>> model = OriginalWHO(epoch, pop_size, n_explore_step, n_exploit_step, eta, p_hi, local_alpha, local_beta,
+    >>>                     global_alpha, global_beta, delta_w, delta_c)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Amali, D. and Dinakaran, M., 2019. Wildebeest herd optimization: a new global optimization algorithm inspired
+    by wildebeest herding behaviour. Journal of Intelligent & Fuzzy Systems, 37(6), pp.8063-8076.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, n_explore_step=3, n_exploit_step=3, eta=0.15, p_hi=0.9,
+                 local_alpha=0.9, local_beta=0.3, global_alpha=0.2, global_beta=0.8, delta_w=2.0, delta_c=2.0, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            n_explore_step (int): default = 3, number of exploration step
+            n_exploit_step (int): default = 3, number of exploitation step
+            eta (float): default = 0.15, learning rate
+            p_hi (float): default = 0.9, the probability of wildebeest move to another position based on herd instinct
+            local_alpha (float): control local movement (alpha 1)
+            local_beta (float): control local movement (beta 1)
+            global_alpha (float): control global movement (alpha 2)
+            global_beta (float): control global movement (beta 2)
+            delta_w (float): dist to worst
+            delta_c (float): dist to best
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.n_explore_step = self.validator.check_int("n_explore_step", n_explore_step, [2, 10])
+        self.n_exploit_step = self.validator.check_int("n_exploit_step", n_exploit_step, [2, 10])
+        self.eta = self.validator.check_float("eta", eta, (0, 1.0))
+        self.p_hi = self.validator.check_float("p_hi", p_hi, (0, 1.0))
+        self.local_alpha = self.validator.check_float("local_alpha", local_alpha, (0, 3.0))
+        self.local_beta = self.validator.check_float("local_beta", local_beta, (0, 3.0))
+        self.global_alpha = self.validator.check_float("global_alpha", global_alpha, (0, 3.0))
+        self.global_beta = self.validator.check_float("global_beta", global_beta, (0, 3.0))
+        self.delta_w = self.validator.check_float("delta_w", delta_w, (0.5, 5.0))
+        self.delta_c = self.validator.check_float("delta_c", delta_c, (0.5, 5.0))
+        self.set_parameters(["epoch", "pop_size", "n_explore_step", "n_exploit_step",
+                             "eta", "p_hi", "local_alpha", "local_beta", "global_alpha", "global_beta", "delta_w", "delta_c"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        ## Begin the Wildebeest Herd Optimization process
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            ### 1. Local movement (Milling behaviour)
+            local_list = []
+            for j in range(0, self.n_explore_step):
+                temp = self.pop[idx][self.ID_POS] + self.eta * np.random.uniform() * np.random.uniform(self.problem.lb, self.problem.ub)
+                pos_new = self.amend_position(temp, self.problem.lb, self.problem.ub)
+                local_list.append([pos_new, None])
+                if self.mode not in self.AVAILABLE_MODES:
+                    local_list[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+            local_list = self.update_target_wrapper_population(local_list)
+            _, best_local = self.get_global_best_solution(local_list)
+            temp = self.local_alpha * best_local[self.ID_POS] + self.local_beta * (self.pop[idx][self.ID_POS] - best_local[self.ID_POS])
+            pos_new = self.amend_position(temp, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+        for idx in range(0, self.pop_size):
+            ### 2. Herd instinct
+            idr = np.random.choice(range(0, self.pop_size))
+            if self.compare_agent(self.pop[idr], self.pop[idx]) and np.random.rand() < self.p_hi:
+                temp = self.global_alpha * self.pop[idx][self.ID_POS] + self.global_beta * self.pop[idr][self.ID_POS]
+                pos_new = self.amend_position(temp, self.problem.lb, self.problem.ub)
+                target = self.get_target_wrapper(pos_new)
+                if self.compare_agent([pos_new, target], self.pop[idx]):
+                    self.pop[idx] = [pos_new, target]
+
+        _, best, worst = self.get_special_solutions(self.pop, best=1, worst=1)
+        g_best, g_worst = best[0], worst[0]
+
+        pop_child = []
+        for idx in range(0, self.pop_size):
+            dist_to_worst = np.linalg.norm(self.pop[idx][self.ID_POS] - g_worst[self.ID_POS])
+            dist_to_best = np.linalg.norm(self.pop[idx][self.ID_POS] - g_best[self.ID_POS])
+
+            ### 3. Starvation avoidance
+            if dist_to_worst < self.delta_w:
+                temp = self.pop[idx][self.ID_POS] + np.random.uniform() * (self.problem.ub - self.problem.lb) * \
+                       np.random.uniform(self.problem.lb, self.problem.ub)
+                pos_new = self.amend_position(temp, self.problem.lb, self.problem.ub)
+                pop_child.append([pos_new, None])
+                if self.mode not in self.AVAILABLE_MODES:
+                    target = self.get_target_wrapper(pos_new)
+                    self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+
+            ### 4. Population pressure
+            if 1.0 < dist_to_best and dist_to_best < self.delta_c:
+                temp = g_best[self.ID_POS] + self.eta * np.random.uniform(self.problem.lb, self.problem.ub)
+                pos_new = self.amend_position(temp, self.problem.lb, self.problem.ub)
+                pop_child.append([pos_new, None])
+                if self.mode not in self.AVAILABLE_MODES:
+                    target = self.get_target_wrapper(pos_new)
+                    self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+
+            ### 5. Herd social memory
+            for j in range(0, self.n_exploit_step):
+                temp = g_best[self.ID_POS] + 0.1 * np.random.uniform(self.problem.lb, self.problem.ub)
+                pos_new = self.amend_position(temp, self.problem.lb, self.problem.ub)
+                pop_child.append([pos_new, None])
+                if self.mode not in self.AVAILABLE_MODES:
+                    target = self.get_target_wrapper(pos_new)
+                    self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_child = self.update_target_wrapper_population(pop_child)
+            pop_child = self.get_sorted_strim_population(pop_child, self.pop_size)
+            self.pop = self.greedy_selection_population(pop_child, self.pop)
```

### Comparing `mealpy-2.5.3/mealpy/evolutionary_based/CRO.py` & `mealpy-2.5.3a1/mealpy/evolutionary_based/CRO.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,337 +1,337 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 14:56, 19/11/2021 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalCRO(Optimizer):
-    """
-    The original version of: Coral Reefs Optimization (CRO)
-
-    Links:
-        1. https://downloads.hindawi.com/journals/tswj/2014/739768.pdf
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + po (float): [0.2, 0.5], the rate between free/occupied at the beginning
-        + Fb (float): [0.6, 0.9], BroadcastSpawner/ExistingCorals rate
-        + Fa (float): [0.05, 0.3], fraction of corals duplicates its self and tries to settle in a different part of the reef
-        + Fd (float): [0.05, 0.5], fraction of the worse health corals in reef will be applied depredation
-        + Pd (float): [0.1, 0.7], Probability of depredation
-        + GCR (float): [0.05, 0.2], probability for mutation process
-        + gamma_min (float): [0.01, 0.1] factor for mutation process
-        + gamma_max (float): [0.1, 0.5] factor for mutation process
-        + n_trials (int): [2, 10], number of attempts for a larvar to set in the reef.
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.evolutionary_based.CRO import OriginalCRO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> po = 0.4
-    >>> Fb = 0.9
-    >>> Fa = 0.1
-    >>> Fd = 0.1
-    >>> Pd = 0.5
-    >>> GCR = 0.1
-    >>> gamma_min = 0.02
-    >>> gamma_max = 0.2
-    >>> n_trials = 5
-    >>> model = OriginalCRO(epoch, pop_size, po, Fb, Fa, Fd, Pd, GCR, gamma_min, gamma_max, n_trials)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Salcedo-Sanz, S., Del Ser, J., Landa-Torres, I., Gil-LÃ³pez, S. and Portilla-Figueras, J.A., 2014.
-    The coral reefs optimization algorithm: a novel metaheuristic for efficiently solving optimization problems. The Scientific World Journal, 2014.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100,po=0.4, Fb=0.9, Fa=0.1, Fd=0.1, Pd=0.5, GCR=0.1,
-                 gamma_min=0.02, gamma_max=0.2, n_trials=3, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            po (float): the rate between free/occupied at the beginning
-            Fb (float): BroadcastSpawner/ExistingCorals rate
-            Fa (float): fraction of corals duplicates its self and tries to settle in a different part of the reef
-            Fd (float): fraction of the worse health corals in reef will be applied depredation
-            Pd (float): the maximum of probability of depredation
-            GCR (float): probability for mutation process
-            gamma_min (float): factor for mutation process
-            gamma_max (float): factor for mutation process
-            n_trials (int): number of attempts for a larva to set in the reef.
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])  # ~ number of space
-        self.po = self.validator.check_float("po", po, (0, 1.0))
-        self.Fb = self.validator.check_float("Fb", Fb, (0, 1.0))
-        self.Fa = self.validator.check_float("Fa", Fa, (0, 1.0))
-        self.Fd = self.validator.check_float("Fd", Fd, (0, 1.0))
-        self.Pd = self.validator.check_float("Pd", Pd, (0, 1.0))
-        self.GCR = self.validator.check_float("GCR", GCR, (0, 1.0))
-        self.gamma_min = self.validator.check_float("gamma_min", gamma_min, (0, 0.15))
-        self.gamma_max = self.validator.check_float("gamma_max", gamma_max, (0.15, 1.0))
-        self.n_trials = self.validator.check_int("n_trials", n_trials, [2, int(self.pop_size / 2)])
-        self.set_parameters(["epoch", "pop_size", "po", "Fb", "Fa", "Fd", "Pd", "GCR", "gamma_min", "gamma_max", "n_trials"])
-        self.sort_flag = False
-
-    def initialization(self):
-        if self.pop is None:
-            self.pop = self.create_population(self.pop_size)
-        self.reef = np.array([])
-        self.occupied_position = []  # after a gen, you should update the occupied_position
-        self.G1 = self.gamma_max
-        self.alpha = 10 * self.Pd / self.epoch
-        self.gama = 10 * (self.gamma_max - self.gamma_min) / self.epoch
-        self.num_occupied = int(self.pop_size / (1 + self.po))
-        self.dyn_Pd = 0
-        self.occupied_list = np.zeros(self.pop_size)
-        self.occupied_idx_list = np.random.choice(list(range(self.pop_size)), self.num_occupied, replace=False)
-        self.occupied_list[self.occupied_idx_list] = 1
-
-    def gaussian_mutation__(self, position):
-        random_pos = position + self.G1 * (self.problem.ub - self.problem.lb) * np.random.normal(0, 1, self.problem.n_dims)
-        condition = np.random.random(self.problem.n_dims) < self.GCR
-        pos_new = np.where(condition, random_pos, position)
-        return self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-
-    ### Crossover
-    def multi_point_cross__(self, pos1, pos2):
-        p1, p2 = np.random.choice(list(range(len(pos1))), 2, replace=False)
-        start, end = min(p1, p2), max(p1, p2)
-        return np.concatenate((pos1[:start], pos2[start:end], pos1[end:]), axis=0)
-
-    def larvae_setting__(self, larvae):
-        # Trial to land on a square of reefs
-        for larva in larvae:
-            for i in range(self.n_trials):
-                p = np.random.randint(0, self.pop_size - 1)
-                if self.occupied_list[p] == 0:
-                    self.pop[p] = larva
-                    self.occupied_idx_list = np.append(self.occupied_idx_list, p)  # Update occupied id
-                    self.occupied_list[p] = 1  # Update occupied list
-                    break
-                else:
-                    if self.compare_agent(larva, self.pop[p]):
-                        self.pop[p] = larva
-                        break
-
-    def sort_occupied_reef__(self):
-        def reef_fitness(idx):
-            return self.pop[idx][self.ID_TAR][self.ID_FIT]
-        idx_list_sorted = sorted(self.occupied_idx_list, key=reef_fitness)
-        return idx_list_sorted
-
-    def broadcast_spawning_brooding__(self):
-        # Step 1a
-        larvae = []
-        selected_corals = np.random.choice(self.occupied_idx_list, int(len(self.occupied_idx_list) * self.Fb), replace=False)
-        for i in self.occupied_idx_list:
-            if i not in selected_corals:
-                pos_new = self.gaussian_mutation__(self.pop[i][self.ID_POS])
-                larvae.append([pos_new, None])
-                if self.mode not in self.AVAILABLE_MODES:
-                    larvae[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        # Step 1b
-        while len(selected_corals) >= 2:
-            id1, id2 = np.random.choice(range(len(selected_corals)), 2, replace=False)
-            pos_new = self.multi_point_cross__(self.pop[selected_corals[id1]][self.ID_POS], self.pop[selected_corals[id2]][self.ID_POS])
-            larvae.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                larvae[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-            selected_corals = np.delete(selected_corals, [id1, id2])
-        return self.update_target_wrapper_population(larvae)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        ## Broadcast Spawning Brooding
-        larvae = self.broadcast_spawning_brooding__()
-        self.larvae_setting__(larvae)
-
-        ## Asexual Reproduction
-        num_duplicate = int(len(self.occupied_idx_list) * self.Fa)
-        pop_best = [self.pop[idx] for idx in self.occupied_idx_list]
-        pop_best = self.get_sorted_strim_population(pop_best, num_duplicate)
-        self.larvae_setting__(pop_best)
-
-        ## Depredation
-        if np.random.random() < self.dyn_Pd:
-            num__depredation__ = int(len(self.occupied_idx_list) * self.Fd)
-            idx_list_sorted = self.sort_occupied_reef__()
-            selected_depredator = idx_list_sorted[-num__depredation__:]
-            self.occupied_idx_list = np.setdiff1d(self.occupied_idx_list, selected_depredator)
-            for idx in selected_depredator:
-                self.occupied_list[idx] = 0
-        if self.dyn_Pd <= self.Pd:
-            self.dyn_Pd += self.alpha
-        if self.G1 >= self.gamma_min:
-            self.G1 -= self.gama
-
-
-class OCRO(OriginalCRO):
-    """
-    The original version of: Opposition-based Coral Reefs Optimization (OCRO)
-
-    Links:
-        1. https://dx.doi.org/10.2991/ijcis.d.190930.003
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + po (float): [0.2, 0.5], the rate between free/occupied at the beginning
-        + Fb (float): [0.6, 0.9], BroadcastSpawner/ExistingCorals rate
-        + Fa (float): [0.05, 0.3], fraction of corals duplicates its self and tries to settle in a different part of the reef
-        + Fd (float): [0.05, 0.5], fraction of the worse health corals in reef will be applied depredation
-        + Pd (float): [0.1, 0.7], the maximum of probability of depredation
-        + GCR (float): [0.05, 0.2], probability for mutation process
-        + gamma_min (float): [0.01, 0.1] factor for mutation process
-        + gamma_max (float): [0.1, 0.5] factor for mutation process
-        + n_trials (int): [2, 10], number of attempts for a larvar to set in the reef
-        + restart_count (int): [10, 100], reset the whole population after global best solution is not improved after restart_count times
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.evolutionary_based.CRO import OCRO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> po = 0.4
-    >>> Fb = 0.9
-    >>> Fa = 0.1
-    >>> Fd = 0.1
-    >>> Pd = 0.5
-    >>> GCR = 0.1
-    >>> gamma_min = 0.02
-    >>> gamma_max = 0.2
-    >>> n_trials = 5
-    >>> restart_count = 50
-    >>> model = OCRO(epoch, pop_size, po, Fb, Fa, Fd, Pd, GCR, gamma_min, gamma_max, n_trials, restart_count)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Nguyen, T., Nguyen, T., Nguyen, B.M. and Nguyen, G., 2019. Efficient time-series forecasting using
-    neural network and opposition-based coral reefs optimization. International Journal of Computational
-    Intelligence Systems, 12(2), p.1144.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, po=0.4, Fb=0.9, Fa=0.1, Fd=0.1, Pd=0.5,
-                 GCR=0.1, gamma_min=0.02, gamma_max=0.2, n_trials=3, restart_count=20, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            po (float): the rate between free/occupied at the beginning
-            Fb (float): BroadcastSpawner/ExistingCorals rate
-            Fa (float): fraction of corals duplicates its self and tries to settle in a different part of the reef
-            Fd (float): fraction of the worse health corals in reef will be applied depredation
-            Pd (float): Probability of depredation
-            GCR (float): probability for mutation process
-            gamma_min (float): [0.01, 0.1] factor for mutation process
-            gamma_max (float): [0.1, 0.5] factor for mutation process
-            n_trials (int): number of attempts for a larva to set in the reef.
-            restart_count (int): reset the whole population after global best solution is not improved after restart_count times
-        """
-        super().__init__(epoch, pop_size, po, Fb, Fa, Fd, Pd, GCR, gamma_min, gamma_max, n_trials, **kwargs)
-        self.restart_count = self.validator.check_int("restart_count", restart_count, [2, int(epoch / 2)])
-        self.set_parameters(["epoch", "pop_size", "po", "Fb", "Fa", "Fd", "Pd", "GCR", "gamma_min", "gamma_max", "n_trials", "restart_count"])
-        self.sort_flag = False
-
-    def initialize_variables(self):
-        self.reset_count = 0
-
-    def local_search__(self, pop=None):
-        pop_new = []
-        for idx in range(0, len(pop)):
-            random_pos = np.random.uniform(self.problem.lb, self.problem.ub)
-            condition = np.random.random(self.problem.n_dims) < 0.5
-            pos_new = np.where(condition, self.g_best[self.ID_POS], random_pos)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        return self.update_target_wrapper_population(pop_new)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        ## Broadcast Spawning Brooding
-        larvae = self.broadcast_spawning_brooding__()
-        self.larvae_setting__(larvae)
-
-        ## Asexual Reproduction
-        num_duplicate = int(len(self.occupied_idx_list) * self.Fa)
-        pop_best = [self.pop[idx] for idx in self.occupied_idx_list]
-        pop_best = self.get_sorted_strim_population(pop_best, num_duplicate)
-        pop_local_search = self.local_search__(pop_best)
-        self.larvae_setting__(pop_local_search)
-
-        ## Depredation
-        if np.random.random() < self.dyn_Pd:
-            num__depredation__ = int(len(self.occupied_idx_list) * self.Fd)
-            idx_list_sorted = self.sort_occupied_reef__()
-            selected_depredator = idx_list_sorted[-num__depredation__:]
-            for idx in selected_depredator:
-                ### Using opposition-based leanring
-                oppo_pos = self.create_opposition_position(self.pop[idx], self.g_best)
-                oppo_pos = self.amend_position(oppo_pos, self.problem.lb, self.problem.ub)
-                oppo_reef = [oppo_pos, self.get_target_wrapper(oppo_pos)]
-                if self.compare_agent(oppo_reef, self.pop[idx]):
-                    self.pop[idx] = oppo_reef
-                else:
-                    self.occupied_idx_list = self.occupied_idx_list[~np.isin(self.occupied_idx_list, [idx])]
-                    self.occupied_list[idx] = 0
-
-        if self.dyn_Pd <= self.Pd:
-            self.dyn_Pd += self.alpha
-        if self.G1 >= self.gamma_min:
-            self.G1 -= self.gama
-
-        self.reset_count += 1
-        _, local_best = self.get_global_best_solution(self.pop)
-        if self.compare_agent(local_best, self.g_best):
-            self.reset_count = 0
-
-        if self.reset_count == self.restart_count:
-            self.pop = self.create_population(self.pop_size)
-            self.occupied_list = np.zeros(self.pop_size)
-            self.occupied_idx_list = np.random.choice(range(self.pop_size), self.num_occupied, replace=False)
-            self.occupied_list[self.occupied_idx_list] = 1
-            self.reset_count = 0
+#!/usr/bin/env python
+# Created by "Thieu" at 14:56, 19/11/2021 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalCRO(Optimizer):
+    """
+    The original version of: Coral Reefs Optimization (CRO)
+
+    Links:
+        1. https://downloads.hindawi.com/journals/tswj/2014/739768.pdf
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + po (float): [0.2, 0.5], the rate between free/occupied at the beginning
+        + Fb (float): [0.6, 0.9], BroadcastSpawner/ExistingCorals rate
+        + Fa (float): [0.05, 0.3], fraction of corals duplicates its self and tries to settle in a different part of the reef
+        + Fd (float): [0.05, 0.5], fraction of the worse health corals in reef will be applied depredation
+        + Pd (float): [0.1, 0.7], Probability of depredation
+        + GCR (float): [0.05, 0.2], probability for mutation process
+        + gamma_min (float): [0.01, 0.1] factor for mutation process
+        + gamma_max (float): [0.1, 0.5] factor for mutation process
+        + n_trials (int): [2, 10], number of attempts for a larvar to set in the reef.
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.evolutionary_based.CRO import OriginalCRO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> po = 0.4
+    >>> Fb = 0.9
+    >>> Fa = 0.1
+    >>> Fd = 0.1
+    >>> Pd = 0.5
+    >>> GCR = 0.1
+    >>> gamma_min = 0.02
+    >>> gamma_max = 0.2
+    >>> n_trials = 5
+    >>> model = OriginalCRO(epoch, pop_size, po, Fb, Fa, Fd, Pd, GCR, gamma_min, gamma_max, n_trials)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Salcedo-Sanz, S., Del Ser, J., Landa-Torres, I., Gil-LÃ³pez, S. and Portilla-Figueras, J.A., 2014.
+    The coral reefs optimization algorithm: a novel metaheuristic for efficiently solving optimization problems. The Scientific World Journal, 2014.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100,po=0.4, Fb=0.9, Fa=0.1, Fd=0.1, Pd=0.5, GCR=0.1,
+                 gamma_min=0.02, gamma_max=0.2, n_trials=3, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            po (float): the rate between free/occupied at the beginning
+            Fb (float): BroadcastSpawner/ExistingCorals rate
+            Fa (float): fraction of corals duplicates its self and tries to settle in a different part of the reef
+            Fd (float): fraction of the worse health corals in reef will be applied depredation
+            Pd (float): the maximum of probability of depredation
+            GCR (float): probability for mutation process
+            gamma_min (float): factor for mutation process
+            gamma_max (float): factor for mutation process
+            n_trials (int): number of attempts for a larva to set in the reef.
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])  # ~ number of space
+        self.po = self.validator.check_float("po", po, (0, 1.0))
+        self.Fb = self.validator.check_float("Fb", Fb, (0, 1.0))
+        self.Fa = self.validator.check_float("Fa", Fa, (0, 1.0))
+        self.Fd = self.validator.check_float("Fd", Fd, (0, 1.0))
+        self.Pd = self.validator.check_float("Pd", Pd, (0, 1.0))
+        self.GCR = self.validator.check_float("GCR", GCR, (0, 1.0))
+        self.gamma_min = self.validator.check_float("gamma_min", gamma_min, (0, 0.15))
+        self.gamma_max = self.validator.check_float("gamma_max", gamma_max, (0.15, 1.0))
+        self.n_trials = self.validator.check_int("n_trials", n_trials, [2, int(self.pop_size / 2)])
+        self.set_parameters(["epoch", "pop_size", "po", "Fb", "Fa", "Fd", "Pd", "GCR", "gamma_min", "gamma_max", "n_trials"])
+        self.sort_flag = False
+
+    def initialization(self):
+        if self.pop is None:
+            self.pop = self.create_population(self.pop_size)
+        self.reef = np.array([])
+        self.occupied_position = []  # after a gen, you should update the occupied_position
+        self.G1 = self.gamma_max
+        self.alpha = 10 * self.Pd / self.epoch
+        self.gama = 10 * (self.gamma_max - self.gamma_min) / self.epoch
+        self.num_occupied = int(self.pop_size / (1 + self.po))
+        self.dyn_Pd = 0
+        self.occupied_list = np.zeros(self.pop_size)
+        self.occupied_idx_list = np.random.choice(list(range(self.pop_size)), self.num_occupied, replace=False)
+        self.occupied_list[self.occupied_idx_list] = 1
+
+    def gaussian_mutation__(self, position):
+        random_pos = position + self.G1 * (self.problem.ub - self.problem.lb) * np.random.normal(0, 1, self.problem.n_dims)
+        condition = np.random.random(self.problem.n_dims) < self.GCR
+        pos_new = np.where(condition, random_pos, position)
+        return self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+
+    ### Crossover
+    def multi_point_cross__(self, pos1, pos2):
+        p1, p2 = np.random.choice(list(range(len(pos1))), 2, replace=False)
+        start, end = min(p1, p2), max(p1, p2)
+        return np.concatenate((pos1[:start], pos2[start:end], pos1[end:]), axis=0)
+
+    def larvae_setting__(self, larvae):
+        # Trial to land on a square of reefs
+        for larva in larvae:
+            for i in range(self.n_trials):
+                p = np.random.randint(0, self.pop_size - 1)
+                if self.occupied_list[p] == 0:
+                    self.pop[p] = larva
+                    self.occupied_idx_list = np.append(self.occupied_idx_list, p)  # Update occupied id
+                    self.occupied_list[p] = 1  # Update occupied list
+                    break
+                else:
+                    if self.compare_agent(larva, self.pop[p]):
+                        self.pop[p] = larva
+                        break
+
+    def sort_occupied_reef__(self):
+        def reef_fitness(idx):
+            return self.pop[idx][self.ID_TAR][self.ID_FIT]
+        idx_list_sorted = sorted(self.occupied_idx_list, key=reef_fitness)
+        return idx_list_sorted
+
+    def broadcast_spawning_brooding__(self):
+        # Step 1a
+        larvae = []
+        selected_corals = np.random.choice(self.occupied_idx_list, int(len(self.occupied_idx_list) * self.Fb), replace=False)
+        for i in self.occupied_idx_list:
+            if i not in selected_corals:
+                pos_new = self.gaussian_mutation__(self.pop[i][self.ID_POS])
+                larvae.append([pos_new, None])
+                if self.mode not in self.AVAILABLE_MODES:
+                    larvae[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        # Step 1b
+        while len(selected_corals) >= 2:
+            id1, id2 = np.random.choice(range(len(selected_corals)), 2, replace=False)
+            pos_new = self.multi_point_cross__(self.pop[selected_corals[id1]][self.ID_POS], self.pop[selected_corals[id2]][self.ID_POS])
+            larvae.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                larvae[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+            selected_corals = np.delete(selected_corals, [id1, id2])
+        return self.update_target_wrapper_population(larvae)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        ## Broadcast Spawning Brooding
+        larvae = self.broadcast_spawning_brooding__()
+        self.larvae_setting__(larvae)
+
+        ## Asexual Reproduction
+        num_duplicate = int(len(self.occupied_idx_list) * self.Fa)
+        pop_best = [self.pop[idx] for idx in self.occupied_idx_list]
+        pop_best = self.get_sorted_strim_population(pop_best, num_duplicate)
+        self.larvae_setting__(pop_best)
+
+        ## Depredation
+        if np.random.random() < self.dyn_Pd:
+            num__depredation__ = int(len(self.occupied_idx_list) * self.Fd)
+            idx_list_sorted = self.sort_occupied_reef__()
+            selected_depredator = idx_list_sorted[-num__depredation__:]
+            self.occupied_idx_list = np.setdiff1d(self.occupied_idx_list, selected_depredator)
+            for idx in selected_depredator:
+                self.occupied_list[idx] = 0
+        if self.dyn_Pd <= self.Pd:
+            self.dyn_Pd += self.alpha
+        if self.G1 >= self.gamma_min:
+            self.G1 -= self.gama
+
+
+class OCRO(OriginalCRO):
+    """
+    The original version of: Opposition-based Coral Reefs Optimization (OCRO)
+
+    Links:
+        1. https://dx.doi.org/10.2991/ijcis.d.190930.003
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + po (float): [0.2, 0.5], the rate between free/occupied at the beginning
+        + Fb (float): [0.6, 0.9], BroadcastSpawner/ExistingCorals rate
+        + Fa (float): [0.05, 0.3], fraction of corals duplicates its self and tries to settle in a different part of the reef
+        + Fd (float): [0.05, 0.5], fraction of the worse health corals in reef will be applied depredation
+        + Pd (float): [0.1, 0.7], the maximum of probability of depredation
+        + GCR (float): [0.05, 0.2], probability for mutation process
+        + gamma_min (float): [0.01, 0.1] factor for mutation process
+        + gamma_max (float): [0.1, 0.5] factor for mutation process
+        + n_trials (int): [2, 10], number of attempts for a larvar to set in the reef
+        + restart_count (int): [10, 100], reset the whole population after global best solution is not improved after restart_count times
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.evolutionary_based.CRO import OCRO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> po = 0.4
+    >>> Fb = 0.9
+    >>> Fa = 0.1
+    >>> Fd = 0.1
+    >>> Pd = 0.5
+    >>> GCR = 0.1
+    >>> gamma_min = 0.02
+    >>> gamma_max = 0.2
+    >>> n_trials = 5
+    >>> restart_count = 50
+    >>> model = OCRO(epoch, pop_size, po, Fb, Fa, Fd, Pd, GCR, gamma_min, gamma_max, n_trials, restart_count)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Nguyen, T., Nguyen, T., Nguyen, B.M. and Nguyen, G., 2019. Efficient time-series forecasting using
+    neural network and opposition-based coral reefs optimization. International Journal of Computational
+    Intelligence Systems, 12(2), p.1144.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, po=0.4, Fb=0.9, Fa=0.1, Fd=0.1, Pd=0.5,
+                 GCR=0.1, gamma_min=0.02, gamma_max=0.2, n_trials=3, restart_count=20, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            po (float): the rate between free/occupied at the beginning
+            Fb (float): BroadcastSpawner/ExistingCorals rate
+            Fa (float): fraction of corals duplicates its self and tries to settle in a different part of the reef
+            Fd (float): fraction of the worse health corals in reef will be applied depredation
+            Pd (float): Probability of depredation
+            GCR (float): probability for mutation process
+            gamma_min (float): [0.01, 0.1] factor for mutation process
+            gamma_max (float): [0.1, 0.5] factor for mutation process
+            n_trials (int): number of attempts for a larva to set in the reef.
+            restart_count (int): reset the whole population after global best solution is not improved after restart_count times
+        """
+        super().__init__(epoch, pop_size, po, Fb, Fa, Fd, Pd, GCR, gamma_min, gamma_max, n_trials, **kwargs)
+        self.restart_count = self.validator.check_int("restart_count", restart_count, [2, int(epoch / 2)])
+        self.set_parameters(["epoch", "pop_size", "po", "Fb", "Fa", "Fd", "Pd", "GCR", "gamma_min", "gamma_max", "n_trials", "restart_count"])
+        self.sort_flag = False
+
+    def initialize_variables(self):
+        self.reset_count = 0
+
+    def local_search__(self, pop=None):
+        pop_new = []
+        for idx in range(0, len(pop)):
+            random_pos = np.random.uniform(self.problem.lb, self.problem.ub)
+            condition = np.random.random(self.problem.n_dims) < 0.5
+            pos_new = np.where(condition, self.g_best[self.ID_POS], random_pos)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        return self.update_target_wrapper_population(pop_new)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        ## Broadcast Spawning Brooding
+        larvae = self.broadcast_spawning_brooding__()
+        self.larvae_setting__(larvae)
+
+        ## Asexual Reproduction
+        num_duplicate = int(len(self.occupied_idx_list) * self.Fa)
+        pop_best = [self.pop[idx] for idx in self.occupied_idx_list]
+        pop_best = self.get_sorted_strim_population(pop_best, num_duplicate)
+        pop_local_search = self.local_search__(pop_best)
+        self.larvae_setting__(pop_local_search)
+
+        ## Depredation
+        if np.random.random() < self.dyn_Pd:
+            num__depredation__ = int(len(self.occupied_idx_list) * self.Fd)
+            idx_list_sorted = self.sort_occupied_reef__()
+            selected_depredator = idx_list_sorted[-num__depredation__:]
+            for idx in selected_depredator:
+                ### Using opposition-based leanring
+                oppo_pos = self.create_opposition_position(self.pop[idx], self.g_best)
+                oppo_pos = self.amend_position(oppo_pos, self.problem.lb, self.problem.ub)
+                oppo_reef = [oppo_pos, self.get_target_wrapper(oppo_pos)]
+                if self.compare_agent(oppo_reef, self.pop[idx]):
+                    self.pop[idx] = oppo_reef
+                else:
+                    self.occupied_idx_list = self.occupied_idx_list[~np.isin(self.occupied_idx_list, [idx])]
+                    self.occupied_list[idx] = 0
+
+        if self.dyn_Pd <= self.Pd:
+            self.dyn_Pd += self.alpha
+        if self.G1 >= self.gamma_min:
+            self.G1 -= self.gama
+
+        self.reset_count += 1
+        _, local_best = self.get_global_best_solution(self.pop)
+        if self.compare_agent(local_best, self.g_best):
+            self.reset_count = 0
+
+        if self.reset_count == self.restart_count:
+            self.pop = self.create_population(self.pop_size)
+            self.occupied_list = np.zeros(self.pop_size)
+            self.occupied_idx_list = np.random.choice(range(self.pop_size), self.num_occupied, replace=False)
+            self.occupied_list[self.occupied_idx_list] = 1
+            self.reset_count = 0
```

### Comparing `mealpy-2.5.3/mealpy/evolutionary_based/DE.py` & `mealpy-2.5.3a1/mealpy/evolutionary_based/DE.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,903 +1,903 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 09:48, 16/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-from scipy.stats import cauchy
-from copy import deepcopy
-
-
-class BaseDE(Optimizer):
-    """
-    The original version of: Differential Evolution (DE)
-
-    Links:
-        1. https://doi.org/10.1016/j.swevo.2018.10.006
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + wf (float): [0.5, 0.95], weighting factor, default = 0.8
-        + cr (float): [0.5, 0.95], crossover rate, default = 0.9
-        + strategy (int): [0, 5], there are lots of variant version of DE algorithm,
-            + 0: DE/current-to-rand/1/bin
-            + 1: DE/best/1/bin
-            + 2: DE/best/2/bin
-            + 3: DE/rand/2/bin
-            + 4: DE/current-to-best/1/bin
-            + 5: DE/current-to-rand/1/bin
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.evolutionary_based.DE import BaseDE
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> wf = 0.7
-    >>> cr = 0.9
-    >>> strategy = 0
-    >>> model = BaseDE(epoch, pop_size, wf, cr, strategy)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Mohamed, A.W., Hadi, A.A. and Jambi, K.M., 2019. Novel mutation strategy for enhancing SHADE and
-    LSHADE algorithms for global numerical optimization. Swarm and Evolutionary Computation, 50, p.100455.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, wf=1.0, cr=0.9, strategy=0, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            wf (float): weighting factor, default = 1.5
-            cr (float): crossover rate, default = 0.9
-            strategy (int): Different variants of DE, default = 0
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.wf = self.validator.check_float("wf", wf, (0, 3.0))
-        self.cr = self.validator.check_float("cr", cr, (0, 1.0))
-        self.strategy = self.validator.check_int("strategy", strategy, [0, 5])
-        self.set_parameters(["epoch", "pop_size", "wf", "cr", "strategy"])
-        self.sort_flag = False
-
-    def mutation__(self, current_pos, new_pos):
-        condition = np.random.random(self.problem.n_dims) < self.cr
-        pos_new = np.where(condition, new_pos, current_pos)
-        return self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop = []
-        if self.strategy == 0:
-            # Choose 3 random element and different to i
-            for idx in range(0, self.pop_size):
-                idx_list = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 3, replace=False)
-                pos_new = self.pop[idx_list[0]][self.ID_POS] + self.wf * \
-                          (self.pop[idx_list[1]][self.ID_POS] - self.pop[idx_list[2]][self.ID_POS])
-                pos_new = self.mutation__(self.pop[idx][self.ID_POS], pos_new)
-                pop.append([pos_new, None])
-                if self.mode not in self.AVAILABLE_MODES:
-                    target = self.get_target_wrapper(pos_new)
-                    self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        elif self.strategy == 1:
-            for idx in range(0, self.pop_size):
-                idx_list = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 2, replace=False)
-                pos_new = self.g_best[self.ID_POS] + self.wf * (self.pop[idx_list[0]][self.ID_POS] - self.pop[idx_list[1]][self.ID_POS])
-                pos_new = self.mutation__(self.pop[idx][self.ID_POS], pos_new)
-                pop.append([pos_new, None])
-                if self.mode not in self.AVAILABLE_MODES:
-                    target = self.get_target_wrapper(pos_new)
-                    self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        elif self.strategy == 2:
-            for idx in range(0, self.pop_size):
-                idx_list = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 4, replace=False)
-                pos_new = self.g_best[self.ID_POS] + self.wf * (self.pop[idx_list[0]][self.ID_POS] - self.pop[idx_list[1]][self.ID_POS]) + \
-                          self.wf * (self.pop[idx_list[2]][self.ID_POS] - self.pop[idx_list[3]][self.ID_POS])
-                pos_new = self.mutation__(self.pop[idx][self.ID_POS], pos_new)
-                pop.append([pos_new, None])
-                if self.mode not in self.AVAILABLE_MODES:
-                    target = self.get_target_wrapper(pos_new)
-                    self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        elif self.strategy == 3:
-            for idx in range(0, self.pop_size):
-                idx_list = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 5, replace=False)
-                pos_new = self.pop[idx_list[0]][self.ID_POS] + self.wf * \
-                          (self.pop[idx_list[1]][self.ID_POS] - self.pop[idx_list[2]][self.ID_POS]) + \
-                          self.wf * (self.pop[idx_list[3]][self.ID_POS] - self.pop[idx_list[4]][self.ID_POS])
-                pos_new = self.mutation__(self.pop[idx][self.ID_POS], pos_new)
-                pop.append([pos_new, None])
-                if self.mode not in self.AVAILABLE_MODES:
-                    target = self.get_target_wrapper(pos_new)
-                    self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        elif self.strategy == 4:
-            for idx in range(0, self.pop_size):
-                idx_list = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 2, replace=False)
-                pos_new = self.pop[idx][self.ID_POS] + self.wf * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) + \
-                          self.wf * (self.pop[idx_list[0]][self.ID_POS] - self.pop[idx_list[1]][self.ID_POS])
-                pos_new = self.mutation__(self.pop[idx][self.ID_POS], pos_new)
-                pop.append([pos_new, None])
-                if self.mode not in self.AVAILABLE_MODES:
-                    target = self.get_target_wrapper(pos_new)
-                    self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        else:
-            for idx in range(0, self.pop_size):
-                idx_list = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 3, replace=False)
-                pos_new = self.pop[idx][self.ID_POS] + self.wf * (self.pop[idx_list[0]][self.ID_POS] - self.pop[idx][self.ID_POS]) + \
-                          self.wf * (self.pop[idx_list[1]][self.ID_POS] - self.pop[idx_list[2]][self.ID_POS])
-                pos_new = self.mutation__(self.pop[idx][self.ID_POS], pos_new)
-                pop.append([pos_new, None])
-                if self.mode not in self.AVAILABLE_MODES:
-                    target = self.get_target_wrapper(pos_new)
-                    self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop = self.update_target_wrapper_population(pop)
-            self.pop = self.greedy_selection_population(self.pop, pop)
-
-
-class JADE(Optimizer):
-    """
-    The original version of: Differential Evolution (JADE)
-
-    Links:
-        1. https://doi.org/10.1109/TEVC.2009.2014613
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + miu_f (float): [0.4, 0.6], initial adaptive f, default = 0.5
-        + miu_cr (float): [0.4, 0.6], initial adaptive cr, default = 0.5
-        + pt (float): [0.05, 0.2], The percent of top best agents (p in the paper), default = 0.1
-        + ap (float): [0.05, 0.2], The Adaptation Parameter control value of f and cr (c in the paper), default=0.1
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.evolutionary_based.DE import JADE
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> miu_f = 0.5
-    >>> miu_cr = 0.5
-    >>> pt = 0.1
-    >>> ap = 0.1
-    >>> model = JADE(epoch, pop_size, miu_f, miu_cr, pt, ap)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Zhang, J. and Sanderson, A.C., 2009. JADE: adaptive differential evolution with optional
-    external archive. IEEE Transactions on evolutionary computation, 13(5), pp.945-958.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, miu_f=0.5, miu_cr=0.5, pt=0.1, ap=0.1, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            miu_f (float): initial adaptive f, default = 0.5
-            miu_cr (float): initial adaptive cr, default = 0.5
-            pt (float): The percent of top best agents (p in the paper), default = 0.1
-            ap (float): The Adaptation Parameter control value of f and cr (c in the paper), default=0.1
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.miu_f = self.validator.check_float("miu_f", miu_f, (0, 1.0))
-        self.miu_cr = self.validator.check_float("miu_cr", miu_cr, (0, 1.0))
-        # np.random.uniform(0.05, 0.2) # the x_best is select from the top 100p % solutions
-        self.pt = self.validator.check_float("pt", pt, (0, 1.0))
-        # np.random.uniform(1/20, 1/5) # the adaptation parameter control value of f and cr
-        self.ap = self.validator.check_float("ap", ap, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "miu_f", "miu_cr", "pt", "ap"])
-        self.sort_flag = False
-
-    def initialize_variables(self):
-        self.dyn_miu_cr = self.miu_cr
-        self.dyn_miu_f = self.miu_f
-        self.dyn_pop_archive = list()
-
-    ### Survivor Selection
-    def lehmer_mean(self, list_objects):
-        temp = sum(list_objects)
-        return 0 if temp == 0 else sum(list_objects ** 2) / temp
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        list_f = list()
-        list_cr = list()
-        temp_f = list()
-        temp_cr = list()
-
-        pop_sorted = self.get_sorted_strim_population(self.pop)
-        pop = []
-        for idx in range(0, self.pop_size):
-            ## Calculate adaptive parameter cr and f
-            cr = np.random.normal(self.dyn_miu_cr, 0.1)
-            cr = np.clip(cr, 0, 1)
-            while True:
-                f = cauchy.rvs(self.dyn_miu_f, 0.1)
-                if f < 0:
-                    continue
-                elif f > 1:
-                    f = 1
-                break
-            temp_f.append(f)
-            temp_cr.append(cr)
-            top = int(self.pop_size * self.pt)
-            x_best = pop_sorted[np.random.randint(0, top)]
-            x_r1 = self.pop[np.random.choice(list(set(range(0, self.pop_size)) - {idx}))]
-            new_pop = self.pop + self.dyn_pop_archive
-            while True:
-                x_r2 = new_pop[np.random.randint(0, len(new_pop))]
-                if np.any(x_r2[self.ID_POS] - x_r1[self.ID_POS]) and np.any(x_r2[self.ID_POS] - self.pop[idx][self.ID_POS]):
-                    break
-            x_new = self.pop[idx][self.ID_POS] + f * (x_best[self.ID_POS] - self.pop[idx][self.ID_POS]) + f * (x_r1[self.ID_POS] - x_r2[self.ID_POS])
-            pos_new = np.where(np.random.random(self.problem.n_dims) < cr, x_new, self.pop[idx][self.ID_POS])
-            j_rand = np.random.randint(0, self.problem.n_dims)
-            pos_new[j_rand] = x_new[j_rand]
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop = self.update_target_wrapper_population(pop)
-        for idx in range(0, self.pop_size):
-            if self.compare_agent(pop[idx], self.pop[idx]):
-                self.dyn_pop_archive.append(deepcopy(self.pop[idx]))
-                list_cr.append(temp_cr[idx])
-                list_f.append(temp_f[idx])
-                self.pop[idx] = deepcopy(pop[idx])
-
-        # Randomly remove solution
-        temp = len(self.dyn_pop_archive) - self.pop_size
-        if temp > 0:
-            idx_list = np.random.choice(range(0, len(self.dyn_pop_archive)), temp, replace=False)
-            archive_pop_new = []
-            for idx, solution in enumerate(self.dyn_pop_archive):
-                if idx not in idx_list:
-                    archive_pop_new.append(solution)
-            self.dyn_pop_archive = deepcopy(archive_pop_new)
-
-        # Update miu_cr and miu_f
-        if len(list_cr) == 0:
-            self.dyn_miu_cr = (1 - self.ap) * self.dyn_miu_cr + self.ap * 0.5
-        else:
-            self.dyn_miu_cr = (1 - self.ap) * self.dyn_miu_cr + self.ap * np.mean(np.array(list_cr))
-        if len(list_f) == 0:
-            self.dyn_miu_f = (1 - self.ap) * self.dyn_miu_f + self.ap * 0.5
-        else:
-            self.dyn_miu_f = (1 - self.ap) * self.dyn_miu_f + self.ap * self.lehmer_mean(np.array(list_f))
-
-
-class SADE(Optimizer):
-    """
-    The original version of: Self-Adaptive Differential Evolution (SADE)
-
-    Links:
-        1. https://doi.org/10.1109/CEC.2005.1554904
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.evolutionary_based.DE import SADE
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = SADE(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Qin, A.K. and Suganthan, P.N., 2005, September. Self-adaptive differential evolution algorithm for
-    numerical optimization. In 2005 IEEE congress on evolutionary computation (Vol. 2, pp. 1785-1791). IEEE.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def initialize_variables(self):
-        self.loop_probability = 50
-        self.loop_cr = 5
-        self.ns1 = self.ns2 = self.nf1 = self.nf2 = 0
-        self.crm = 0.5
-        self.p1 = 0.5
-        self.dyn_list_cr = list()
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop = []
-        list_probability = []
-        list_cr = []
-        for idx in range(0, self.pop_size):
-            ## Calculate adaptive parameter cr and f
-            cr = np.random.normal(self.crm, 0.1)
-            cr = np.clip(cr, 0, 1)
-            list_cr.append(cr)
-            while True:
-                f = np.random.normal(0.5, 0.3)
-                if f < 0:
-                    continue
-                elif f > 1:
-                    f = 1
-                break
-
-            id1, id2, id3 = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 3, replace=False)
-            if np.random.rand() < self.p1:
-                x_new = self.pop[id1][self.ID_POS] + f * (self.pop[id2][self.ID_POS] - self.pop[id3][self.ID_POS])
-                pos_new = np.where(np.random.random(self.problem.n_dims) < cr, x_new, self.pop[idx][self.ID_POS])
-                j_rand = np.random.randint(0, self.problem.n_dims)
-                pos_new[j_rand] = x_new[j_rand]
-                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                list_probability.append(True)
-            else:
-                x_new = self.pop[idx][self.ID_POS] + f * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) + \
-                        f * (self.pop[id1][self.ID_POS] - self.pop[id2][self.ID_POS])
-                pos_new = np.where(np.random.random(self.problem.n_dims) < cr, x_new, self.pop[idx][self.ID_POS])
-                j_rand = np.random.randint(0, self.problem.n_dims)
-                pos_new[j_rand] = x_new[j_rand]
-                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                list_probability.append(False)
-            pop.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop = self.update_target_wrapper_population(pop)
-
-        for idx in range(0, self.pop_size):
-            if list_probability[idx]:
-                if self.compare_agent(pop[idx], self.pop[idx]):
-                    self.ns1 += 1
-                    self.pop[idx] = deepcopy(pop[idx])
-                else:
-                    self.nf1 += 1
-            else:
-                if self.compare_agent(pop[idx], self.pop[idx]):
-                    self.ns2 += 1
-                    self.dyn_list_cr.append(list_cr[idx])
-                    self.pop[idx] = deepcopy(pop[idx])
-                else:
-                    self.nf2 += 1
-
-        # Update cr and p1
-        if (epoch + 1) / self.loop_cr == 0:
-            self.crm = np.mean(self.dyn_list_cr)
-            self.dyn_list_cr = list()
-
-        if (epoch + 1) / self.loop_probability == 0:
-            self.p1 = self.ns1 * (self.ns2 + self.nf2) / (self.ns2 * (self.ns1 + self.nf1) + self.ns1 * (self.ns2 + self.nf2))
-            self.ns1 = self.ns2 = self.nf1 = self.nf2 = 0
-
-
-class SHADE(Optimizer):
-    """
-    The original version of: Success-History Adaptation Differential Evolution (SHADE)
-
-    Links:
-        1. https://doi.org/10.1109/CEC.2013.6557555
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + miu_f (float): [0.4, 0.6], initial weighting factor, default = 0.5
-        + miu_cr (float): [0.4, 0.6], initial cross-over probability, default = 0.5
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.evolutionary_based.DE import SHADE
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> miu_f = 0.5
-    >>> miu_cr = 0.5
-    >>> model = SHADE( epoch, pop_size, miu_f, miu_cr)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Tanabe, R. and Fukunaga, A., 2013, June. Success-history based parameter adaptation for
-    differential evolution. In 2013 IEEE congress on evolutionary computation (pp. 71-78). IEEE.
-    """
-
-    def __init__(self, epoch=750, pop_size=100, miu_f=0.5, miu_cr=0.5, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            miu_f (float): initial weighting factor, default = 0.5
-            miu_cr (float): initial cross-over probability, default = 0.5
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        # the initial f, location is changed then that f is good
-        self.miu_f = self.validator.check_float("miu_f", miu_f, (0, 1.0))
-        # the initial cr,
-        self.miu_cr = self.validator.check_float("miu_cr", miu_cr, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "miu_f", "miu_cr"])
-        self.sort_flag = False
-
-    def initialize_variables(self):
-        self.dyn_miu_f = self.miu_f * np.ones(self.pop_size)  # list the initial f,
-        self.dyn_miu_cr = self.miu_cr * np.ones(self.pop_size)  # list the initial cr,
-        self.dyn_pop_archive = list()
-        self.k_counter = 0
-
-    ### Survivor Selection
-    def weighted_lehmer_mean__(self, list_objects, list_weights):
-        up = list_weights * list_objects ** 2
-        down = list_weights * list_objects
-        return np.sum(up) / np.sum(down)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        list_f = list()
-        list_cr = list()
-        list_f_index = list()
-        list_cr_index = list()
-
-        list_f_new = np.ones(self.pop_size)
-        list_cr_new = np.ones(self.pop_size)
-        pop_old = deepcopy(self.pop)
-        pop_sorted = self.get_sorted_strim_population(self.pop)
-
-        pop = []
-        for idx in range(0, self.pop_size):
-            ## Calculate adaptive parameter cr and f
-            idx_rand = np.random.randint(0, self.pop_size)
-            cr = np.random.normal(self.dyn_miu_cr[idx_rand], 0.1)
-            cr = np.clip(cr, 0, 1)
-            while True:
-                f = cauchy.rvs(self.dyn_miu_f[idx_rand], 0.1)
-                if f < 0:
-                    continue
-                elif f > 1:
-                    f = 1
-                break
-            list_cr_new[idx] = cr
-            list_f_new[idx] = f
-            p = np.random.uniform(2 / self.pop_size, 0.2)
-            top = int(self.pop_size * p)
-            x_best = pop_sorted[np.random.randint(0, top)]
-            x_r1 = self.pop[np.random.choice(list(set(range(0, self.pop_size)) - {idx}))]
-            new_pop = self.pop + self.dyn_pop_archive
-            while True:
-                x_r2 = new_pop[np.random.randint(0, len(new_pop))]
-                if np.any(x_r2[self.ID_POS] - x_r1[self.ID_POS]) and np.any(x_r2[self.ID_POS] - self.pop[idx][self.ID_POS]):
-                    break
-            x_new = self.pop[idx][self.ID_POS] + f * (x_best[self.ID_POS] - self.pop[idx][self.ID_POS]) + f * (x_r1[self.ID_POS] - x_r2[self.ID_POS])
-            condition = np.random.random(self.problem.n_dims) < cr
-            pos_new = np.where(condition, x_new, self.pop[idx][self.ID_POS])
-            j_rand = np.random.randint(0, self.problem.n_dims)
-            pos_new[j_rand] = x_new[j_rand]
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop = self.update_target_wrapper_population(pop)
-
-        for i in range(0, self.pop_size):
-            if self.compare_agent(pop[i], self.pop[i]):
-                list_cr.append(list_cr_new[i])
-                list_f.append(list_f_new[i])
-                list_f_index.append(i)
-                list_cr_index.append(i)
-                self.pop[i] = deepcopy(pop[i])
-                self.dyn_pop_archive.append(deepcopy(pop[i]))
-
-        # Randomly remove solution
-        temp = len(self.dyn_pop_archive) - self.pop_size
-        if temp > 0:
-            idx_list = np.random.choice(range(0, len(self.dyn_pop_archive)), temp, replace=False)
-            archive_pop_new = []
-            for idx, solution in enumerate(self.dyn_pop_archive):
-                if idx not in idx_list:
-                    archive_pop_new.append(solution)
-            self.dyn_pop_archive = deepcopy(archive_pop_new)
-
-        # Update miu_cr and miu_f
-        if len(list_f) != 0 and len(list_cr) != 0:
-            # Eq.13, 14, 10
-            list_fit_old = np.ones(len(list_cr_index))
-            list_fit_new = np.ones(len(list_cr_index))
-            idx_increase = 0
-            for i in range(0, self.pop_size):
-                if i in list_cr_index:
-                    list_fit_old[idx_increase] = pop_old[i][self.ID_TAR][self.ID_FIT]
-                    list_fit_new[idx_increase] = self.pop[i][self.ID_TAR][self.ID_FIT]
-                    idx_increase += 1
-            temp = np.sum(np.abs(list_fit_new - list_fit_old))
-            if temp == 0:
-                list_weights = 1.0 / len(list_fit_new) * np.ones(len(list_fit_new))
-            else:
-                list_weights = np.abs(list_fit_new - list_fit_old) / temp
-            self.dyn_miu_cr[self.k_counter] = np.sum(list_weights * np.array(list_cr))
-            self.dyn_miu_f[self.k_counter] = self.weighted_lehmer_mean__(np.array(list_f), list_weights)
-            self.k_counter += 1
-            if self.k_counter >= self.pop_size:
-                self.k_counter = 0
-
-
-class L_SHADE(Optimizer):
-    """
-    The original version of: Linear Population Size Reduction Success-History Adaptation Differential Evolution (LSHADE)
-
-    Links:
-        1. https://metahack.org/CEC2014-Tanabe-Fukunaga.pdf
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + miu_f (float): [0.4, 0.6], initial weighting factor, default = 0.5
-        + miu_cr (float): [0.4, 0.6], initial cross-over probability, default = 0.5
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.evolutionary_based.DE import L_SHADE
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> miu_f = 0.5
-    >>> miu_cr = 0.5
-    >>> model = L_SHADE(epoch, pop_size, miu_f, miu_cr)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Tanabe, R. and Fukunaga, A.S., 2014, July. Improving the search performance of SHADE using
-    linear population size reduction. In 2014 IEEE congress on evolutionary computation (CEC) (pp. 1658-1665). IEEE.
-    """
-
-    def __init__(self, epoch=750, pop_size=100, miu_f=0.5, miu_cr=0.5, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            miu_f (float): initial weighting factor, default = 0.5
-            miu_cr (float): initial cross-over probability, default = 0.5
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.miu_f = self.validator.check_float("miu_f", miu_f, (0, 1.0))
-        self.miu_cr = self.validator.check_float("miu_cr", miu_cr, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "miu_f", "miu_cr"])
-        self.sort_flag = False
-
-    def initialize_variables(self):
-        # Dynamic variable
-        self.dyn_miu_f = self.miu_f * np.ones(self.pop_size)  # list the initial f,
-        self.dyn_miu_cr = self.miu_cr * np.ones(self.pop_size)  # list the initial cr,
-        self.dyn_pop_archive = list()
-        self.dyn_pop_size = self.pop_size
-        self.k_counter = 0
-        self.n_min = int(self.pop_size / 5)
-
-    ### Survivor Selection
-    def weighted_lehmer_mean__(self, list_objects, list_weights):
-        up = np.sum(list_weights * list_objects ** 2)
-        down = np.sum(list_weights * list_objects)
-        return up / down if down != 0 else 0.5
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        list_f = list()
-        list_cr = list()
-        list_f_index = list()
-        list_cr_index = list()
-
-        list_f_new = np.ones(self.pop_size)
-        list_cr_new = np.ones(self.pop_size)
-        pop_old = deepcopy(self.pop)
-        pop_sorted = self.get_sorted_strim_population(self.pop)
-
-        pop = []
-        for idx in range(0, self.pop_size):
-            ## Calculate adaptive parameter cr and f
-            idx_rand = np.random.randint(0, self.pop_size)
-            cr = np.random.normal(self.dyn_miu_cr[idx_rand], 0.1)
-            cr = np.clip(cr, 0, 1)
-            while True:
-                f = cauchy.rvs(self.dyn_miu_f[idx_rand], 0.1)
-                if f < 0:
-                    continue
-                elif f > 1:
-                    f = 1
-                break
-            list_cr_new[idx] = cr
-            list_f_new[idx] = f
-            p = np.random.uniform(0.15, 0.2)
-            top = int(self.dyn_pop_size * p)
-            x_best = pop_sorted[np.random.randint(0, top)]
-            x_r1 = self.pop[np.random.choice(list(set(range(0, self.dyn_pop_size)) - {idx}))]
-            new_pop = self.pop + self.dyn_pop_archive
-            while True:
-                x_r2 = new_pop[np.random.randint(0, len(new_pop))]
-                if np.any(x_r2[self.ID_POS] - x_r1[self.ID_POS]) and np.any(x_r2[self.ID_POS] - self.pop[idx][self.ID_POS]):
-                    break
-            x_new = self.pop[idx][self.ID_POS] + f * (x_best[self.ID_POS] - self.pop[idx][self.ID_POS]) + f * (x_r1[self.ID_POS] - x_r2[self.ID_POS])
-            pos_new = np.where(np.random.random(self.problem.n_dims) < cr, x_new, self.pop[idx][self.ID_POS])
-            j_rand = np.random.randint(0, self.problem.n_dims)
-            pos_new[j_rand] = x_new[j_rand]
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop = self.update_target_wrapper_population(pop)
-
-        for i in range(0, self.pop_size):
-            if self.compare_agent(pop[i], self.pop[i]):
-                list_cr.append(list_cr_new[i])
-                list_f.append(list_f_new[i])
-                list_f_index.append(i)
-                list_cr_index.append(i)
-                self.pop[i] = deepcopy(pop[i])
-                self.dyn_pop_archive.append(deepcopy(self.pop[i]))
-
-        # Randomly remove solution
-        temp = len(self.dyn_pop_archive) - self.pop_size
-        if temp > 0:
-            idx_list = np.random.choice(range(0, len(self.dyn_pop_archive)), temp, replace=False)
-            archive_pop_new = []
-            for idx, solution in enumerate(self.dyn_pop_archive):
-                if idx not in idx_list:
-                    archive_pop_new.append(solution)
-            self.dyn_pop_archive = deepcopy(archive_pop_new)
-
-        # Update miu_cr and miu_f
-        if len(list_f) != 0 and len(list_cr) != 0:
-            # Eq.13, 14, 10
-            list_fit_old = np.ones(len(list_cr_index))
-            list_fit_new = np.ones(len(list_cr_index))
-            idx_increase = 0
-            for i in range(0, self.dyn_pop_size):
-                if i in list_cr_index:
-                    list_fit_old[idx_increase] = pop_old[i][self.ID_TAR][self.ID_FIT]
-                    list_fit_new[idx_increase] = self.pop[i][self.ID_TAR][self.ID_FIT]
-                    idx_increase += 1
-            total_fit = np.sum(np.abs(list_fit_new - list_fit_old))
-            list_weights = 0 if total_fit == 0 else np.abs(list_fit_new - list_fit_old) / total_fit
-            self.dyn_miu_cr[self.k_counter] = np.sum(list_weights * np.array(list_cr))
-            self.dyn_miu_f[self.k_counter] = self.weighted_lehmer_mean__(np.array(list_f), list_weights)
-            self.k_counter += 1
-            if self.k_counter >= self.dyn_pop_size:
-                self.k_counter = 0
-
-        # Linear Population Size Reduction
-        self.dyn_pop_size = round(self.pop_size + epoch * ((self.n_min - self.pop_size) / self.epoch))
-
-
-class SAP_DE(Optimizer):
-    """
-    The original version of: Differential Evolution with Self-Adaptive Populations (SAP_DE)
-
-    Links:
-        1. https://doi.org/10.1007/s00500-005-0537-1
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + branch (str): ["ABS" or "REL"], gaussian (absolute) or uniform (relative) method
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.evolutionary_based.DE import SAP_DE
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> branch = "ABS"
-    >>> model = SAP_DE(epoch, pop_size, branch)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Teo, J., 2006. Exploring dynamic self-adaptive populations in differential evolution. Soft Computing, 10(8), pp.673-686.
-    """
-
-    ID_CR = 2
-    ID_MR = 3
-    ID_PS = 4
-
-    def __init__(self, epoch=750, pop_size=100, branch="ABS", **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            branch (str): gaussian (absolute) or uniform (relative) method
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.branch = self.validator.check_str("branch", branch, ["ABS", "REL"])
-        self.set_parameters(["epoch", "pop_size", "branch"])
-        self.fixed_pop_size = self.pop_size
-        self.sort_flag = False
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        """
-        Overriding method in Optimizer class
-
-        Returns:
-            list: solution with format [position, target, crossover_rate, mutation_rate, pop_size]
-        """
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        position = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(position)
-        crossover_rate = np.random.uniform(0, 1)
-        mutation_rate = np.random.uniform(0, 1)
-        if self.branch == "ABS":
-            pop_size = int(10 * self.problem.n_dims + np.random.normal(0, 1))
-        else:  # elif self.branch == "REL":
-            pop_size = int(10 * self.problem.n_dims + np.random.uniform(-0.5, 0.5))
-        return [position, target, crossover_rate, mutation_rate, pop_size]
-
-    def edit_to_range(self, var=None, lower=0, upper=1, func_value=None):
-        while var <= lower or var >= upper:
-            if var <= lower:
-                var += func_value()
-            if var >= upper:
-                var -= func_value()
-        return var
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop = []
-        for idx in range(0, self.pop_size):
-            # Choose 3 random element and different to idx
-            idxs = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 3, replace=False)
-            j = np.random.randint(0, self.pop_size)
-            self.F = np.random.normal(0, 1)
-
-            ## Crossover
-            if np.random.uniform(0, 1) < self.pop[idx][self.ID_CR] or idx == j:
-                pos_new = self.pop[idxs[0]][self.ID_POS] + self.F * (self.pop[idxs[1]][self.ID_POS] - self.pop[idxs[2]][self.ID_POS])
-                cr_new = self.pop[idxs[0]][self.ID_CR] + self.F * (self.pop[idxs[1]][self.ID_CR] - self.pop[idxs[2]][self.ID_CR])
-                mr_new = self.pop[idxs[0]][self.ID_MR] + self.F * (self.pop[idxs[1]][self.ID_MR] - self.pop[idxs[2]][self.ID_MR])
-                if self.branch == "ABS":
-                    ps_new = self.pop[idxs[0]][self.ID_PS] + int(self.F * (self.pop[idxs[1]][self.ID_PS] - self.pop[idxs[2]][self.ID_PS]))
-                else:  # elif self.branch == "REL":
-                    ps_new = self.pop[idxs[0]][self.ID_PS] + self.F * (self.pop[idxs[1]][self.ID_PS] - self.pop[idxs[2]][self.ID_PS])
-                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                cr_new = self.edit_to_range(cr_new, 0, 1, np.random.random)
-                mr_new = self.edit_to_range(mr_new, 0, 1, np.random.random)
-                pop.append([pos_new, None, cr_new, mr_new, ps_new])
-                if self.mode not in self.AVAILABLE_MODES:
-                    pop[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-            else:
-                pop.append(deepcopy(self.pop[idx]))
-            ## Mutation
-            if np.random.uniform(0, 1) < self.pop[idxs[0]][self.ID_MR]:
-                pos_new = self.pop[idx][self.ID_POS] + np.random.normal(0, self.pop[idxs[0]][self.ID_MR])
-                cr_new = np.random.normal(0, 1)
-                mr_new = np.random.normal(0, 1)
-                if self.branch == "ABS":
-                    ps_new = self.pop[idx][self.ID_PS] + int(np.random.normal(0.5, 1))
-                else:  # elif self.branch == "REL":
-                    ps_new = self.pop[idx][self.ID_PS] + np.random.normal(0, self.pop[idxs[0]][self.ID_MR])
-                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                pop.append([pos_new, None, cr_new, mr_new, ps_new])
-                if self.mode not in self.AVAILABLE_MODES:
-                    pop[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop = self.update_target_wrapper_population(pop)
-
-        # Calculate new population size
-        total = sum([pop[i][self.ID_PS] for i in range(0, self.pop_size)])
-        if self.branch == "ABS":
-            m_new = int(total / self.pop_size)
-        else:  # elif self.branch == "REL":
-            m_new = int(self.pop_size + total)
-        if m_new <= 4:
-            m_new = self.fixed_pop_size + int(np.random.uniform(0, 4))
-        elif m_new > 4 * self.fixed_pop_size:
-            m_new = self.fixed_pop_size - int(np.random.uniform(0, 4))
-
-        ## Change population by population size
-        if m_new <= self.pop_size:
-            self.pop = pop[:m_new]
-        else:
-            pop_sorted = self.get_sorted_strim_population(pop)
-            self.pop = pop + pop_sorted[:m_new - self.pop_size]
-        self.pop_size = len(self.pop)
+#!/usr/bin/env python
+# Created by "Thieu" at 09:48, 16/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+from scipy.stats import cauchy
+from copy import deepcopy
+
+
+class BaseDE(Optimizer):
+    """
+    The original version of: Differential Evolution (DE)
+
+    Links:
+        1. https://doi.org/10.1016/j.swevo.2018.10.006
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + wf (float): [0.5, 0.95], weighting factor, default = 0.8
+        + cr (float): [0.5, 0.95], crossover rate, default = 0.9
+        + strategy (int): [0, 5], there are lots of variant version of DE algorithm,
+            + 0: DE/current-to-rand/1/bin
+            + 1: DE/best/1/bin
+            + 2: DE/best/2/bin
+            + 3: DE/rand/2/bin
+            + 4: DE/current-to-best/1/bin
+            + 5: DE/current-to-rand/1/bin
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.evolutionary_based.DE import BaseDE
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> wf = 0.7
+    >>> cr = 0.9
+    >>> strategy = 0
+    >>> model = BaseDE(epoch, pop_size, wf, cr, strategy)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Mohamed, A.W., Hadi, A.A. and Jambi, K.M., 2019. Novel mutation strategy for enhancing SHADE and
+    LSHADE algorithms for global numerical optimization. Swarm and Evolutionary Computation, 50, p.100455.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, wf=1.0, cr=0.9, strategy=0, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            wf (float): weighting factor, default = 1.5
+            cr (float): crossover rate, default = 0.9
+            strategy (int): Different variants of DE, default = 0
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.wf = self.validator.check_float("wf", wf, (0, 3.0))
+        self.cr = self.validator.check_float("cr", cr, (0, 1.0))
+        self.strategy = self.validator.check_int("strategy", strategy, [0, 5])
+        self.set_parameters(["epoch", "pop_size", "wf", "cr", "strategy"])
+        self.sort_flag = False
+
+    def mutation__(self, current_pos, new_pos):
+        condition = np.random.random(self.problem.n_dims) < self.cr
+        pos_new = np.where(condition, new_pos, current_pos)
+        return self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop = []
+        if self.strategy == 0:
+            # Choose 3 random element and different to i
+            for idx in range(0, self.pop_size):
+                idx_list = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 3, replace=False)
+                pos_new = self.pop[idx_list[0]][self.ID_POS] + self.wf * \
+                          (self.pop[idx_list[1]][self.ID_POS] - self.pop[idx_list[2]][self.ID_POS])
+                pos_new = self.mutation__(self.pop[idx][self.ID_POS], pos_new)
+                pop.append([pos_new, None])
+                if self.mode not in self.AVAILABLE_MODES:
+                    target = self.get_target_wrapper(pos_new)
+                    self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        elif self.strategy == 1:
+            for idx in range(0, self.pop_size):
+                idx_list = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 2, replace=False)
+                pos_new = self.g_best[self.ID_POS] + self.wf * (self.pop[idx_list[0]][self.ID_POS] - self.pop[idx_list[1]][self.ID_POS])
+                pos_new = self.mutation__(self.pop[idx][self.ID_POS], pos_new)
+                pop.append([pos_new, None])
+                if self.mode not in self.AVAILABLE_MODES:
+                    target = self.get_target_wrapper(pos_new)
+                    self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        elif self.strategy == 2:
+            for idx in range(0, self.pop_size):
+                idx_list = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 4, replace=False)
+                pos_new = self.g_best[self.ID_POS] + self.wf * (self.pop[idx_list[0]][self.ID_POS] - self.pop[idx_list[1]][self.ID_POS]) + \
+                          self.wf * (self.pop[idx_list[2]][self.ID_POS] - self.pop[idx_list[3]][self.ID_POS])
+                pos_new = self.mutation__(self.pop[idx][self.ID_POS], pos_new)
+                pop.append([pos_new, None])
+                if self.mode not in self.AVAILABLE_MODES:
+                    target = self.get_target_wrapper(pos_new)
+                    self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        elif self.strategy == 3:
+            for idx in range(0, self.pop_size):
+                idx_list = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 5, replace=False)
+                pos_new = self.pop[idx_list[0]][self.ID_POS] + self.wf * \
+                          (self.pop[idx_list[1]][self.ID_POS] - self.pop[idx_list[2]][self.ID_POS]) + \
+                          self.wf * (self.pop[idx_list[3]][self.ID_POS] - self.pop[idx_list[4]][self.ID_POS])
+                pos_new = self.mutation__(self.pop[idx][self.ID_POS], pos_new)
+                pop.append([pos_new, None])
+                if self.mode not in self.AVAILABLE_MODES:
+                    target = self.get_target_wrapper(pos_new)
+                    self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        elif self.strategy == 4:
+            for idx in range(0, self.pop_size):
+                idx_list = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 2, replace=False)
+                pos_new = self.pop[idx][self.ID_POS] + self.wf * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) + \
+                          self.wf * (self.pop[idx_list[0]][self.ID_POS] - self.pop[idx_list[1]][self.ID_POS])
+                pos_new = self.mutation__(self.pop[idx][self.ID_POS], pos_new)
+                pop.append([pos_new, None])
+                if self.mode not in self.AVAILABLE_MODES:
+                    target = self.get_target_wrapper(pos_new)
+                    self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        else:
+            for idx in range(0, self.pop_size):
+                idx_list = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 3, replace=False)
+                pos_new = self.pop[idx][self.ID_POS] + self.wf * (self.pop[idx_list[0]][self.ID_POS] - self.pop[idx][self.ID_POS]) + \
+                          self.wf * (self.pop[idx_list[1]][self.ID_POS] - self.pop[idx_list[2]][self.ID_POS])
+                pos_new = self.mutation__(self.pop[idx][self.ID_POS], pos_new)
+                pop.append([pos_new, None])
+                if self.mode not in self.AVAILABLE_MODES:
+                    target = self.get_target_wrapper(pos_new)
+                    self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop = self.update_target_wrapper_population(pop)
+            self.pop = self.greedy_selection_population(self.pop, pop)
+
+
+class JADE(Optimizer):
+    """
+    The original version of: Differential Evolution (JADE)
+
+    Links:
+        1. https://doi.org/10.1109/TEVC.2009.2014613
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + miu_f (float): [0.4, 0.6], initial adaptive f, default = 0.5
+        + miu_cr (float): [0.4, 0.6], initial adaptive cr, default = 0.5
+        + pt (float): [0.05, 0.2], The percent of top best agents (p in the paper), default = 0.1
+        + ap (float): [0.05, 0.2], The Adaptation Parameter control value of f and cr (c in the paper), default=0.1
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.evolutionary_based.DE import JADE
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> miu_f = 0.5
+    >>> miu_cr = 0.5
+    >>> pt = 0.1
+    >>> ap = 0.1
+    >>> model = JADE(epoch, pop_size, miu_f, miu_cr, pt, ap)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Zhang, J. and Sanderson, A.C., 2009. JADE: adaptive differential evolution with optional
+    external archive. IEEE Transactions on evolutionary computation, 13(5), pp.945-958.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, miu_f=0.5, miu_cr=0.5, pt=0.1, ap=0.1, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            miu_f (float): initial adaptive f, default = 0.5
+            miu_cr (float): initial adaptive cr, default = 0.5
+            pt (float): The percent of top best agents (p in the paper), default = 0.1
+            ap (float): The Adaptation Parameter control value of f and cr (c in the paper), default=0.1
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.miu_f = self.validator.check_float("miu_f", miu_f, (0, 1.0))
+        self.miu_cr = self.validator.check_float("miu_cr", miu_cr, (0, 1.0))
+        # np.random.uniform(0.05, 0.2) # the x_best is select from the top 100p % solutions
+        self.pt = self.validator.check_float("pt", pt, (0, 1.0))
+        # np.random.uniform(1/20, 1/5) # the adaptation parameter control value of f and cr
+        self.ap = self.validator.check_float("ap", ap, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "miu_f", "miu_cr", "pt", "ap"])
+        self.sort_flag = False
+
+    def initialize_variables(self):
+        self.dyn_miu_cr = self.miu_cr
+        self.dyn_miu_f = self.miu_f
+        self.dyn_pop_archive = list()
+
+    ### Survivor Selection
+    def lehmer_mean(self, list_objects):
+        temp = sum(list_objects)
+        return 0 if temp == 0 else sum(list_objects ** 2) / temp
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        list_f = list()
+        list_cr = list()
+        temp_f = list()
+        temp_cr = list()
+
+        pop_sorted = self.get_sorted_strim_population(self.pop)
+        pop = []
+        for idx in range(0, self.pop_size):
+            ## Calculate adaptive parameter cr and f
+            cr = np.random.normal(self.dyn_miu_cr, 0.1)
+            cr = np.clip(cr, 0, 1)
+            while True:
+                f = cauchy.rvs(self.dyn_miu_f, 0.1)
+                if f < 0:
+                    continue
+                elif f > 1:
+                    f = 1
+                break
+            temp_f.append(f)
+            temp_cr.append(cr)
+            top = int(self.pop_size * self.pt)
+            x_best = pop_sorted[np.random.randint(0, top)]
+            x_r1 = self.pop[np.random.choice(list(set(range(0, self.pop_size)) - {idx}))]
+            new_pop = self.pop + self.dyn_pop_archive
+            while True:
+                x_r2 = new_pop[np.random.randint(0, len(new_pop))]
+                if np.any(x_r2[self.ID_POS] - x_r1[self.ID_POS]) and np.any(x_r2[self.ID_POS] - self.pop[idx][self.ID_POS]):
+                    break
+            x_new = self.pop[idx][self.ID_POS] + f * (x_best[self.ID_POS] - self.pop[idx][self.ID_POS]) + f * (x_r1[self.ID_POS] - x_r2[self.ID_POS])
+            pos_new = np.where(np.random.random(self.problem.n_dims) < cr, x_new, self.pop[idx][self.ID_POS])
+            j_rand = np.random.randint(0, self.problem.n_dims)
+            pos_new[j_rand] = x_new[j_rand]
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop = self.update_target_wrapper_population(pop)
+        for idx in range(0, self.pop_size):
+            if self.compare_agent(pop[idx], self.pop[idx]):
+                self.dyn_pop_archive.append(deepcopy(self.pop[idx]))
+                list_cr.append(temp_cr[idx])
+                list_f.append(temp_f[idx])
+                self.pop[idx] = deepcopy(pop[idx])
+
+        # Randomly remove solution
+        temp = len(self.dyn_pop_archive) - self.pop_size
+        if temp > 0:
+            idx_list = np.random.choice(range(0, len(self.dyn_pop_archive)), temp, replace=False)
+            archive_pop_new = []
+            for idx, solution in enumerate(self.dyn_pop_archive):
+                if idx not in idx_list:
+                    archive_pop_new.append(solution)
+            self.dyn_pop_archive = deepcopy(archive_pop_new)
+
+        # Update miu_cr and miu_f
+        if len(list_cr) == 0:
+            self.dyn_miu_cr = (1 - self.ap) * self.dyn_miu_cr + self.ap * 0.5
+        else:
+            self.dyn_miu_cr = (1 - self.ap) * self.dyn_miu_cr + self.ap * np.mean(np.array(list_cr))
+        if len(list_f) == 0:
+            self.dyn_miu_f = (1 - self.ap) * self.dyn_miu_f + self.ap * 0.5
+        else:
+            self.dyn_miu_f = (1 - self.ap) * self.dyn_miu_f + self.ap * self.lehmer_mean(np.array(list_f))
+
+
+class SADE(Optimizer):
+    """
+    The original version of: Self-Adaptive Differential Evolution (SADE)
+
+    Links:
+        1. https://doi.org/10.1109/CEC.2005.1554904
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.evolutionary_based.DE import SADE
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = SADE(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Qin, A.K. and Suganthan, P.N., 2005, September. Self-adaptive differential evolution algorithm for
+    numerical optimization. In 2005 IEEE congress on evolutionary computation (Vol. 2, pp. 1785-1791). IEEE.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def initialize_variables(self):
+        self.loop_probability = 50
+        self.loop_cr = 5
+        self.ns1 = self.ns2 = self.nf1 = self.nf2 = 0
+        self.crm = 0.5
+        self.p1 = 0.5
+        self.dyn_list_cr = list()
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop = []
+        list_probability = []
+        list_cr = []
+        for idx in range(0, self.pop_size):
+            ## Calculate adaptive parameter cr and f
+            cr = np.random.normal(self.crm, 0.1)
+            cr = np.clip(cr, 0, 1)
+            list_cr.append(cr)
+            while True:
+                f = np.random.normal(0.5, 0.3)
+                if f < 0:
+                    continue
+                elif f > 1:
+                    f = 1
+                break
+
+            id1, id2, id3 = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 3, replace=False)
+            if np.random.rand() < self.p1:
+                x_new = self.pop[id1][self.ID_POS] + f * (self.pop[id2][self.ID_POS] - self.pop[id3][self.ID_POS])
+                pos_new = np.where(np.random.random(self.problem.n_dims) < cr, x_new, self.pop[idx][self.ID_POS])
+                j_rand = np.random.randint(0, self.problem.n_dims)
+                pos_new[j_rand] = x_new[j_rand]
+                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                list_probability.append(True)
+            else:
+                x_new = self.pop[idx][self.ID_POS] + f * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) + \
+                        f * (self.pop[id1][self.ID_POS] - self.pop[id2][self.ID_POS])
+                pos_new = np.where(np.random.random(self.problem.n_dims) < cr, x_new, self.pop[idx][self.ID_POS])
+                j_rand = np.random.randint(0, self.problem.n_dims)
+                pos_new[j_rand] = x_new[j_rand]
+                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                list_probability.append(False)
+            pop.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop = self.update_target_wrapper_population(pop)
+
+        for idx in range(0, self.pop_size):
+            if list_probability[idx]:
+                if self.compare_agent(pop[idx], self.pop[idx]):
+                    self.ns1 += 1
+                    self.pop[idx] = deepcopy(pop[idx])
+                else:
+                    self.nf1 += 1
+            else:
+                if self.compare_agent(pop[idx], self.pop[idx]):
+                    self.ns2 += 1
+                    self.dyn_list_cr.append(list_cr[idx])
+                    self.pop[idx] = deepcopy(pop[idx])
+                else:
+                    self.nf2 += 1
+
+        # Update cr and p1
+        if (epoch + 1) / self.loop_cr == 0:
+            self.crm = np.mean(self.dyn_list_cr)
+            self.dyn_list_cr = list()
+
+        if (epoch + 1) / self.loop_probability == 0:
+            self.p1 = self.ns1 * (self.ns2 + self.nf2) / (self.ns2 * (self.ns1 + self.nf1) + self.ns1 * (self.ns2 + self.nf2))
+            self.ns1 = self.ns2 = self.nf1 = self.nf2 = 0
+
+
+class SHADE(Optimizer):
+    """
+    The original version of: Success-History Adaptation Differential Evolution (SHADE)
+
+    Links:
+        1. https://doi.org/10.1109/CEC.2013.6557555
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + miu_f (float): [0.4, 0.6], initial weighting factor, default = 0.5
+        + miu_cr (float): [0.4, 0.6], initial cross-over probability, default = 0.5
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.evolutionary_based.DE import SHADE
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> miu_f = 0.5
+    >>> miu_cr = 0.5
+    >>> model = SHADE( epoch, pop_size, miu_f, miu_cr)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Tanabe, R. and Fukunaga, A., 2013, June. Success-history based parameter adaptation for
+    differential evolution. In 2013 IEEE congress on evolutionary computation (pp. 71-78). IEEE.
+    """
+
+    def __init__(self, epoch=750, pop_size=100, miu_f=0.5, miu_cr=0.5, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            miu_f (float): initial weighting factor, default = 0.5
+            miu_cr (float): initial cross-over probability, default = 0.5
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        # the initial f, location is changed then that f is good
+        self.miu_f = self.validator.check_float("miu_f", miu_f, (0, 1.0))
+        # the initial cr,
+        self.miu_cr = self.validator.check_float("miu_cr", miu_cr, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "miu_f", "miu_cr"])
+        self.sort_flag = False
+
+    def initialize_variables(self):
+        self.dyn_miu_f = self.miu_f * np.ones(self.pop_size)  # list the initial f,
+        self.dyn_miu_cr = self.miu_cr * np.ones(self.pop_size)  # list the initial cr,
+        self.dyn_pop_archive = list()
+        self.k_counter = 0
+
+    ### Survivor Selection
+    def weighted_lehmer_mean__(self, list_objects, list_weights):
+        up = list_weights * list_objects ** 2
+        down = list_weights * list_objects
+        return np.sum(up) / np.sum(down)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        list_f = list()
+        list_cr = list()
+        list_f_index = list()
+        list_cr_index = list()
+
+        list_f_new = np.ones(self.pop_size)
+        list_cr_new = np.ones(self.pop_size)
+        pop_old = deepcopy(self.pop)
+        pop_sorted = self.get_sorted_strim_population(self.pop)
+
+        pop = []
+        for idx in range(0, self.pop_size):
+            ## Calculate adaptive parameter cr and f
+            idx_rand = np.random.randint(0, self.pop_size)
+            cr = np.random.normal(self.dyn_miu_cr[idx_rand], 0.1)
+            cr = np.clip(cr, 0, 1)
+            while True:
+                f = cauchy.rvs(self.dyn_miu_f[idx_rand], 0.1)
+                if f < 0:
+                    continue
+                elif f > 1:
+                    f = 1
+                break
+            list_cr_new[idx] = cr
+            list_f_new[idx] = f
+            p = np.random.uniform(2 / self.pop_size, 0.2)
+            top = int(self.pop_size * p)
+            x_best = pop_sorted[np.random.randint(0, top)]
+            x_r1 = self.pop[np.random.choice(list(set(range(0, self.pop_size)) - {idx}))]
+            new_pop = self.pop + self.dyn_pop_archive
+            while True:
+                x_r2 = new_pop[np.random.randint(0, len(new_pop))]
+                if np.any(x_r2[self.ID_POS] - x_r1[self.ID_POS]) and np.any(x_r2[self.ID_POS] - self.pop[idx][self.ID_POS]):
+                    break
+            x_new = self.pop[idx][self.ID_POS] + f * (x_best[self.ID_POS] - self.pop[idx][self.ID_POS]) + f * (x_r1[self.ID_POS] - x_r2[self.ID_POS])
+            condition = np.random.random(self.problem.n_dims) < cr
+            pos_new = np.where(condition, x_new, self.pop[idx][self.ID_POS])
+            j_rand = np.random.randint(0, self.problem.n_dims)
+            pos_new[j_rand] = x_new[j_rand]
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop = self.update_target_wrapper_population(pop)
+
+        for i in range(0, self.pop_size):
+            if self.compare_agent(pop[i], self.pop[i]):
+                list_cr.append(list_cr_new[i])
+                list_f.append(list_f_new[i])
+                list_f_index.append(i)
+                list_cr_index.append(i)
+                self.pop[i] = deepcopy(pop[i])
+                self.dyn_pop_archive.append(deepcopy(pop[i]))
+
+        # Randomly remove solution
+        temp = len(self.dyn_pop_archive) - self.pop_size
+        if temp > 0:
+            idx_list = np.random.choice(range(0, len(self.dyn_pop_archive)), temp, replace=False)
+            archive_pop_new = []
+            for idx, solution in enumerate(self.dyn_pop_archive):
+                if idx not in idx_list:
+                    archive_pop_new.append(solution)
+            self.dyn_pop_archive = deepcopy(archive_pop_new)
+
+        # Update miu_cr and miu_f
+        if len(list_f) != 0 and len(list_cr) != 0:
+            # Eq.13, 14, 10
+            list_fit_old = np.ones(len(list_cr_index))
+            list_fit_new = np.ones(len(list_cr_index))
+            idx_increase = 0
+            for i in range(0, self.pop_size):
+                if i in list_cr_index:
+                    list_fit_old[idx_increase] = pop_old[i][self.ID_TAR][self.ID_FIT]
+                    list_fit_new[idx_increase] = self.pop[i][self.ID_TAR][self.ID_FIT]
+                    idx_increase += 1
+            temp = np.sum(np.abs(list_fit_new - list_fit_old))
+            if temp == 0:
+                list_weights = 1.0 / len(list_fit_new) * np.ones(len(list_fit_new))
+            else:
+                list_weights = np.abs(list_fit_new - list_fit_old) / temp
+            self.dyn_miu_cr[self.k_counter] = np.sum(list_weights * np.array(list_cr))
+            self.dyn_miu_f[self.k_counter] = self.weighted_lehmer_mean__(np.array(list_f), list_weights)
+            self.k_counter += 1
+            if self.k_counter >= self.pop_size:
+                self.k_counter = 0
+
+
+class L_SHADE(Optimizer):
+    """
+    The original version of: Linear Population Size Reduction Success-History Adaptation Differential Evolution (LSHADE)
+
+    Links:
+        1. https://metahack.org/CEC2014-Tanabe-Fukunaga.pdf
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + miu_f (float): [0.4, 0.6], initial weighting factor, default = 0.5
+        + miu_cr (float): [0.4, 0.6], initial cross-over probability, default = 0.5
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.evolutionary_based.DE import L_SHADE
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> miu_f = 0.5
+    >>> miu_cr = 0.5
+    >>> model = L_SHADE(epoch, pop_size, miu_f, miu_cr)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Tanabe, R. and Fukunaga, A.S., 2014, July. Improving the search performance of SHADE using
+    linear population size reduction. In 2014 IEEE congress on evolutionary computation (CEC) (pp. 1658-1665). IEEE.
+    """
+
+    def __init__(self, epoch=750, pop_size=100, miu_f=0.5, miu_cr=0.5, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            miu_f (float): initial weighting factor, default = 0.5
+            miu_cr (float): initial cross-over probability, default = 0.5
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.miu_f = self.validator.check_float("miu_f", miu_f, (0, 1.0))
+        self.miu_cr = self.validator.check_float("miu_cr", miu_cr, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "miu_f", "miu_cr"])
+        self.sort_flag = False
+
+    def initialize_variables(self):
+        # Dynamic variable
+        self.dyn_miu_f = self.miu_f * np.ones(self.pop_size)  # list the initial f,
+        self.dyn_miu_cr = self.miu_cr * np.ones(self.pop_size)  # list the initial cr,
+        self.dyn_pop_archive = list()
+        self.dyn_pop_size = self.pop_size
+        self.k_counter = 0
+        self.n_min = int(self.pop_size / 5)
+
+    ### Survivor Selection
+    def weighted_lehmer_mean__(self, list_objects, list_weights):
+        up = np.sum(list_weights * list_objects ** 2)
+        down = np.sum(list_weights * list_objects)
+        return up / down if down != 0 else 0.5
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        list_f = list()
+        list_cr = list()
+        list_f_index = list()
+        list_cr_index = list()
+
+        list_f_new = np.ones(self.pop_size)
+        list_cr_new = np.ones(self.pop_size)
+        pop_old = deepcopy(self.pop)
+        pop_sorted = self.get_sorted_strim_population(self.pop)
+
+        pop = []
+        for idx in range(0, self.pop_size):
+            ## Calculate adaptive parameter cr and f
+            idx_rand = np.random.randint(0, self.pop_size)
+            cr = np.random.normal(self.dyn_miu_cr[idx_rand], 0.1)
+            cr = np.clip(cr, 0, 1)
+            while True:
+                f = cauchy.rvs(self.dyn_miu_f[idx_rand], 0.1)
+                if f < 0:
+                    continue
+                elif f > 1:
+                    f = 1
+                break
+            list_cr_new[idx] = cr
+            list_f_new[idx] = f
+            p = np.random.uniform(0.15, 0.2)
+            top = int(self.dyn_pop_size * p)
+            x_best = pop_sorted[np.random.randint(0, top)]
+            x_r1 = self.pop[np.random.choice(list(set(range(0, self.dyn_pop_size)) - {idx}))]
+            new_pop = self.pop + self.dyn_pop_archive
+            while True:
+                x_r2 = new_pop[np.random.randint(0, len(new_pop))]
+                if np.any(x_r2[self.ID_POS] - x_r1[self.ID_POS]) and np.any(x_r2[self.ID_POS] - self.pop[idx][self.ID_POS]):
+                    break
+            x_new = self.pop[idx][self.ID_POS] + f * (x_best[self.ID_POS] - self.pop[idx][self.ID_POS]) + f * (x_r1[self.ID_POS] - x_r2[self.ID_POS])
+            pos_new = np.where(np.random.random(self.problem.n_dims) < cr, x_new, self.pop[idx][self.ID_POS])
+            j_rand = np.random.randint(0, self.problem.n_dims)
+            pos_new[j_rand] = x_new[j_rand]
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop = self.update_target_wrapper_population(pop)
+
+        for i in range(0, self.pop_size):
+            if self.compare_agent(pop[i], self.pop[i]):
+                list_cr.append(list_cr_new[i])
+                list_f.append(list_f_new[i])
+                list_f_index.append(i)
+                list_cr_index.append(i)
+                self.pop[i] = deepcopy(pop[i])
+                self.dyn_pop_archive.append(deepcopy(self.pop[i]))
+
+        # Randomly remove solution
+        temp = len(self.dyn_pop_archive) - self.pop_size
+        if temp > 0:
+            idx_list = np.random.choice(range(0, len(self.dyn_pop_archive)), temp, replace=False)
+            archive_pop_new = []
+            for idx, solution in enumerate(self.dyn_pop_archive):
+                if idx not in idx_list:
+                    archive_pop_new.append(solution)
+            self.dyn_pop_archive = deepcopy(archive_pop_new)
+
+        # Update miu_cr and miu_f
+        if len(list_f) != 0 and len(list_cr) != 0:
+            # Eq.13, 14, 10
+            list_fit_old = np.ones(len(list_cr_index))
+            list_fit_new = np.ones(len(list_cr_index))
+            idx_increase = 0
+            for i in range(0, self.dyn_pop_size):
+                if i in list_cr_index:
+                    list_fit_old[idx_increase] = pop_old[i][self.ID_TAR][self.ID_FIT]
+                    list_fit_new[idx_increase] = self.pop[i][self.ID_TAR][self.ID_FIT]
+                    idx_increase += 1
+            total_fit = np.sum(np.abs(list_fit_new - list_fit_old))
+            list_weights = 0 if total_fit == 0 else np.abs(list_fit_new - list_fit_old) / total_fit
+            self.dyn_miu_cr[self.k_counter] = np.sum(list_weights * np.array(list_cr))
+            self.dyn_miu_f[self.k_counter] = self.weighted_lehmer_mean__(np.array(list_f), list_weights)
+            self.k_counter += 1
+            if self.k_counter >= self.dyn_pop_size:
+                self.k_counter = 0
+
+        # Linear Population Size Reduction
+        self.dyn_pop_size = round(self.pop_size + epoch * ((self.n_min - self.pop_size) / self.epoch))
+
+
+class SAP_DE(Optimizer):
+    """
+    The original version of: Differential Evolution with Self-Adaptive Populations (SAP_DE)
+
+    Links:
+        1. https://doi.org/10.1007/s00500-005-0537-1
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + branch (str): ["ABS" or "REL"], gaussian (absolute) or uniform (relative) method
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.evolutionary_based.DE import SAP_DE
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> branch = "ABS"
+    >>> model = SAP_DE(epoch, pop_size, branch)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Teo, J., 2006. Exploring dynamic self-adaptive populations in differential evolution. Soft Computing, 10(8), pp.673-686.
+    """
+
+    ID_CR = 2
+    ID_MR = 3
+    ID_PS = 4
+
+    def __init__(self, epoch=750, pop_size=100, branch="ABS", **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            branch (str): gaussian (absolute) or uniform (relative) method
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.branch = self.validator.check_str("branch", branch, ["ABS", "REL"])
+        self.set_parameters(["epoch", "pop_size", "branch"])
+        self.fixed_pop_size = self.pop_size
+        self.sort_flag = False
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        """
+        Overriding method in Optimizer class
+
+        Returns:
+            list: solution with format [position, target, crossover_rate, mutation_rate, pop_size]
+        """
+        if pos is None:
+            pos = self.generate_position(lb, ub)
+        position = self.amend_position(pos, lb, ub)
+        target = self.get_target_wrapper(position)
+        crossover_rate = np.random.uniform(0, 1)
+        mutation_rate = np.random.uniform(0, 1)
+        if self.branch == "ABS":
+            pop_size = int(10 * self.problem.n_dims + np.random.normal(0, 1))
+        else:  # elif self.branch == "REL":
+            pop_size = int(10 * self.problem.n_dims + np.random.uniform(-0.5, 0.5))
+        return [position, target, crossover_rate, mutation_rate, pop_size]
+
+    def edit_to_range(self, var=None, lower=0, upper=1, func_value=None):
+        while var <= lower or var >= upper:
+            if var <= lower:
+                var += func_value()
+            if var >= upper:
+                var -= func_value()
+        return var
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop = []
+        for idx in range(0, self.pop_size):
+            # Choose 3 random element and different to idx
+            idxs = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 3, replace=False)
+            j = np.random.randint(0, self.pop_size)
+            self.F = np.random.normal(0, 1)
+
+            ## Crossover
+            if np.random.uniform(0, 1) < self.pop[idx][self.ID_CR] or idx == j:
+                pos_new = self.pop[idxs[0]][self.ID_POS] + self.F * (self.pop[idxs[1]][self.ID_POS] - self.pop[idxs[2]][self.ID_POS])
+                cr_new = self.pop[idxs[0]][self.ID_CR] + self.F * (self.pop[idxs[1]][self.ID_CR] - self.pop[idxs[2]][self.ID_CR])
+                mr_new = self.pop[idxs[0]][self.ID_MR] + self.F * (self.pop[idxs[1]][self.ID_MR] - self.pop[idxs[2]][self.ID_MR])
+                if self.branch == "ABS":
+                    ps_new = self.pop[idxs[0]][self.ID_PS] + int(self.F * (self.pop[idxs[1]][self.ID_PS] - self.pop[idxs[2]][self.ID_PS]))
+                else:  # elif self.branch == "REL":
+                    ps_new = self.pop[idxs[0]][self.ID_PS] + self.F * (self.pop[idxs[1]][self.ID_PS] - self.pop[idxs[2]][self.ID_PS])
+                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                cr_new = self.edit_to_range(cr_new, 0, 1, np.random.random)
+                mr_new = self.edit_to_range(mr_new, 0, 1, np.random.random)
+                pop.append([pos_new, None, cr_new, mr_new, ps_new])
+                if self.mode not in self.AVAILABLE_MODES:
+                    pop[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+            else:
+                pop.append(deepcopy(self.pop[idx]))
+            ## Mutation
+            if np.random.uniform(0, 1) < self.pop[idxs[0]][self.ID_MR]:
+                pos_new = self.pop[idx][self.ID_POS] + np.random.normal(0, self.pop[idxs[0]][self.ID_MR])
+                cr_new = np.random.normal(0, 1)
+                mr_new = np.random.normal(0, 1)
+                if self.branch == "ABS":
+                    ps_new = self.pop[idx][self.ID_PS] + int(np.random.normal(0.5, 1))
+                else:  # elif self.branch == "REL":
+                    ps_new = self.pop[idx][self.ID_PS] + np.random.normal(0, self.pop[idxs[0]][self.ID_MR])
+                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                pop.append([pos_new, None, cr_new, mr_new, ps_new])
+                if self.mode not in self.AVAILABLE_MODES:
+                    pop[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop = self.update_target_wrapper_population(pop)
+
+        # Calculate new population size
+        total = sum([pop[i][self.ID_PS] for i in range(0, self.pop_size)])
+        if self.branch == "ABS":
+            m_new = int(total / self.pop_size)
+        else:  # elif self.branch == "REL":
+            m_new = int(self.pop_size + total)
+        if m_new <= 4:
+            m_new = self.fixed_pop_size + int(np.random.uniform(0, 4))
+        elif m_new > 4 * self.fixed_pop_size:
+            m_new = self.fixed_pop_size - int(np.random.uniform(0, 4))
+
+        ## Change population by population size
+        if m_new <= self.pop_size:
+            self.pop = pop[:m_new]
+        else:
+            pop_sorted = self.get_sorted_strim_population(pop)
+            self.pop = pop + pop_sorted[:m_new - self.pop_size]
+        self.pop_size = len(self.pop)
```

### Comparing `mealpy-2.5.3/mealpy/evolutionary_based/EP.py` & `mealpy-2.5.3a1/mealpy/evolutionary_based/EP.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,215 +1,215 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 19:27, 10/04/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalEP(Optimizer):
-    """
-    The original version of: Evolutionary Programming (EP)
-
-    Links:
-        1. https://www.cleveralgorithms.com/nature-inspired/evolution/evolutionary_programming.html
-        2. https://github.com/clever-algorithms/CleverAlgorithms
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + bout_size (float): [0.05, 0.2], percentage of child agents implement tournament selection
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.evolutionary_based.EP import OriginalEP
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> bout_size = 0.05
-    >>> model = OriginalEP(epoch, pop_size, bout_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Yao, X., Liu, Y. and Lin, G., 1999. Evolutionary programming made faster.
-    IEEE Transactions on Evolutionary computation, 3(2), pp.82-102.
-    """
-
-    ID_POS = 0
-    ID_TAR = 1
-    ID_STR = 2  # strategy
-    ID_WIN = 3
-
-    def __init__(self, epoch=10000, pop_size=100, bout_size=0.05, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size (miu in the paper), default = 100
-            bout_size (float): percentage of child agents implement tournament selection
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.bout_size = self.validator.check_float("bout_size", bout_size, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "bout_size"])
-        self.sort_flag = True
-
-    def initialize_variables(self):
-        self.n_bout_size = int(self.bout_size * self.pop_size)
-        self.distance = 0.05 * (self.problem.ub - self.problem.lb)
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        """
-        Overriding method in Optimizer class
-
-        Returns:
-            list: wrapper of solution with format [position, target, strategy, times_win]
-        """
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        position = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(position)
-        strategy = np.random.uniform(0, self.distance, len(lb))
-        times_win = 0
-        return [position, target, strategy, times_win]
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        child = []
-        for idx in range(0, self.pop_size):
-            pos_new = self.pop[idx][self.ID_POS] + self.pop[idx][self.ID_STR] * np.random.normal(0, 1.0, self.problem.n_dims)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            s_old = self.pop[idx][self.ID_STR] + np.random.normal(0, 1.0, self.problem.n_dims) * np.abs(self.pop[idx][self.ID_STR]) ** 0.5
-            child.append([pos_new, None, s_old, 0])
-            if self.mode not in self.AVAILABLE_MODES:
-                child[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        child = self.update_target_wrapper_population(child)
-
-        # Update the global best
-        children, self.g_best = self.update_global_best_solution(child, save=False)
-        pop = children + self.pop
-        for i in range(0, len(pop)):
-            ## Tournament winner (Tried with bout_size times)
-            for idx in range(0, self.n_bout_size):
-                rand_idx = np.random.randint(0, len(pop))
-                if self.compare_agent(pop[i], pop[rand_idx]):
-                    pop[i][self.ID_WIN] += 1
-                else:
-                    pop[rand_idx][self.ID_WIN] += 1
-        pop = sorted(pop, key=lambda item: item[self.ID_WIN], reverse=True)
-        self.pop = pop[:self.pop_size]
-
-
-class LevyEP(OriginalEP):
-    """
-    The developed Levy-flight version: Evolutionary Programming (LevyEP)
-
-    Notes
-    ~~~~~
-    Levy-flight is applied to EP, flow and some equations is changed.
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + bout_size (float): [0.05, 0.2], percentage of child agents implement tournament selection
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.evolutionary_based.EP import LevyEP
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> bout_size = 0.05
-    >>> model = LevyEP(epoch, pop_size, bout_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    ID_POS = 0
-    ID_TAR = 1
-    ID_STR = 2  # strategy
-    ID_WIN = 3
-
-    def __init__(self, epoch=10000, pop_size=100, bout_size=0.05, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size (miu in the paper), default = 100
-            bout_size (float): percentage of child agents implement tournament selection
-        """
-        super().__init__(epoch, pop_size, bout_size, **kwargs)
-        self.sort_flag = True
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        child = []
-        for idx in range(0, self.pop_size):
-            pos_new = self.pop[idx][self.ID_POS] + self.pop[idx][self.ID_STR] * np.random.normal(0, 1.0, self.problem.n_dims)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            s_old = self.pop[idx][self.ID_STR] + np.random.normal(0, 1.0, self.problem.n_dims) * np.abs(self.pop[idx][self.ID_STR]) ** 0.5
-            child.append([pos_new, None, s_old, 0])
-            if self.mode not in self.AVAILABLE_MODES:
-                child[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        child = self.update_target_wrapper_population(child)
-
-        # Update the global best
-        children, self.g_best = self.update_global_best_solution(child, save=False)
-        pop = children + self.pop
-        for i in range(0, len(pop)):
-            ## Tournament winner (Tried with bout_size times)
-            for idx in range(0, self.n_bout_size):
-                rand_idx = np.random.randint(0, len(pop))
-                if self.compare_agent(pop[i], pop[rand_idx]):
-                    pop[i][self.ID_WIN] += 1
-                else:
-                    pop[rand_idx][self.ID_WIN] += 1
-
-        ## Keep the top population, but 50% of left population will make a comeback an take the good position
-        pop = sorted(pop, key=lambda agent: agent[self.ID_WIN], reverse=True)
-        pop_new = deepcopy(pop[:self.pop_size])
-        pop_left = deepcopy(pop[self.pop_size:])
-
-        ## Choice random 50% of population left
-        pop_comeback = []
-        idx_list = np.random.choice(range(0, len(pop_left)), int(0.5 * len(pop_left)), replace=False)
-        for idx in idx_list:
-            pos_new = pop_left[idx][self.ID_POS] + self.get_levy_flight_step(multiplier=0.01, size=self.problem.n_dims, case=-1)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            strategy = self.distance = 0.05 * (self.problem.ub - self.problem.lb)
-            pop_comeback.append([pos_new, None, strategy, 0])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_comeback[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop_comeback = self.update_target_wrapper_population(pop_comeback)
-        self.pop = self.get_sorted_strim_population(pop_new + pop_comeback, self.pop_size)
+#!/usr/bin/env python
+# Created by "Thieu" at 19:27, 10/04/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalEP(Optimizer):
+    """
+    The original version of: Evolutionary Programming (EP)
+
+    Links:
+        1. https://www.cleveralgorithms.com/nature-inspired/evolution/evolutionary_programming.html
+        2. https://github.com/clever-algorithms/CleverAlgorithms
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + bout_size (float): [0.05, 0.2], percentage of child agents implement tournament selection
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.evolutionary_based.EP import OriginalEP
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> bout_size = 0.05
+    >>> model = OriginalEP(epoch, pop_size, bout_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Yao, X., Liu, Y. and Lin, G., 1999. Evolutionary programming made faster.
+    IEEE Transactions on Evolutionary computation, 3(2), pp.82-102.
+    """
+
+    ID_POS = 0
+    ID_TAR = 1
+    ID_STR = 2  # strategy
+    ID_WIN = 3
+
+    def __init__(self, epoch=10000, pop_size=100, bout_size=0.05, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size (miu in the paper), default = 100
+            bout_size (float): percentage of child agents implement tournament selection
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.bout_size = self.validator.check_float("bout_size", bout_size, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "bout_size"])
+        self.sort_flag = True
+
+    def initialize_variables(self):
+        self.n_bout_size = int(self.bout_size * self.pop_size)
+        self.distance = 0.05 * (self.problem.ub - self.problem.lb)
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        """
+        Overriding method in Optimizer class
+
+        Returns:
+            list: wrapper of solution with format [position, target, strategy, times_win]
+        """
+        if pos is None:
+            pos = self.generate_position(lb, ub)
+        position = self.amend_position(pos, lb, ub)
+        target = self.get_target_wrapper(position)
+        strategy = np.random.uniform(0, self.distance, len(lb))
+        times_win = 0
+        return [position, target, strategy, times_win]
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        child = []
+        for idx in range(0, self.pop_size):
+            pos_new = self.pop[idx][self.ID_POS] + self.pop[idx][self.ID_STR] * np.random.normal(0, 1.0, self.problem.n_dims)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            s_old = self.pop[idx][self.ID_STR] + np.random.normal(0, 1.0, self.problem.n_dims) * np.abs(self.pop[idx][self.ID_STR]) ** 0.5
+            child.append([pos_new, None, s_old, 0])
+            if self.mode not in self.AVAILABLE_MODES:
+                child[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        child = self.update_target_wrapper_population(child)
+
+        # Update the global best
+        children, self.g_best = self.update_global_best_solution(child, save=False)
+        pop = children + self.pop
+        for i in range(0, len(pop)):
+            ## Tournament winner (Tried with bout_size times)
+            for idx in range(0, self.n_bout_size):
+                rand_idx = np.random.randint(0, len(pop))
+                if self.compare_agent(pop[i], pop[rand_idx]):
+                    pop[i][self.ID_WIN] += 1
+                else:
+                    pop[rand_idx][self.ID_WIN] += 1
+        pop = sorted(pop, key=lambda item: item[self.ID_WIN], reverse=True)
+        self.pop = pop[:self.pop_size]
+
+
+class LevyEP(OriginalEP):
+    """
+    The developed Levy-flight version: Evolutionary Programming (LevyEP)
+
+    Notes
+    ~~~~~
+    Levy-flight is applied to EP, flow and some equations is changed.
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + bout_size (float): [0.05, 0.2], percentage of child agents implement tournament selection
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.evolutionary_based.EP import LevyEP
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> bout_size = 0.05
+    >>> model = LevyEP(epoch, pop_size, bout_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    ID_POS = 0
+    ID_TAR = 1
+    ID_STR = 2  # strategy
+    ID_WIN = 3
+
+    def __init__(self, epoch=10000, pop_size=100, bout_size=0.05, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size (miu in the paper), default = 100
+            bout_size (float): percentage of child agents implement tournament selection
+        """
+        super().__init__(epoch, pop_size, bout_size, **kwargs)
+        self.sort_flag = True
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        child = []
+        for idx in range(0, self.pop_size):
+            pos_new = self.pop[idx][self.ID_POS] + self.pop[idx][self.ID_STR] * np.random.normal(0, 1.0, self.problem.n_dims)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            s_old = self.pop[idx][self.ID_STR] + np.random.normal(0, 1.0, self.problem.n_dims) * np.abs(self.pop[idx][self.ID_STR]) ** 0.5
+            child.append([pos_new, None, s_old, 0])
+            if self.mode not in self.AVAILABLE_MODES:
+                child[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        child = self.update_target_wrapper_population(child)
+
+        # Update the global best
+        children, self.g_best = self.update_global_best_solution(child, save=False)
+        pop = children + self.pop
+        for i in range(0, len(pop)):
+            ## Tournament winner (Tried with bout_size times)
+            for idx in range(0, self.n_bout_size):
+                rand_idx = np.random.randint(0, len(pop))
+                if self.compare_agent(pop[i], pop[rand_idx]):
+                    pop[i][self.ID_WIN] += 1
+                else:
+                    pop[rand_idx][self.ID_WIN] += 1
+
+        ## Keep the top population, but 50% of left population will make a comeback an take the good position
+        pop = sorted(pop, key=lambda agent: agent[self.ID_WIN], reverse=True)
+        pop_new = deepcopy(pop[:self.pop_size])
+        pop_left = deepcopy(pop[self.pop_size:])
+
+        ## Choice random 50% of population left
+        pop_comeback = []
+        idx_list = np.random.choice(range(0, len(pop_left)), int(0.5 * len(pop_left)), replace=False)
+        for idx in idx_list:
+            pos_new = pop_left[idx][self.ID_POS] + self.get_levy_flight_step(multiplier=0.01, size=self.problem.n_dims, case=-1)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            strategy = self.distance = 0.05 * (self.problem.ub - self.problem.lb)
+            pop_comeback.append([pos_new, None, strategy, 0])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_comeback[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop_comeback = self.update_target_wrapper_population(pop_comeback)
+        self.pop = self.get_sorted_strim_population(pop_new + pop_comeback, self.pop_size)
```

### Comparing `mealpy-2.5.3/mealpy/evolutionary_based/ES.py` & `mealpy-2.5.3a1/mealpy/evolutionary_based/ES.py`

 * *Ordering differences only*

 * *Files 19% similar despite different names*

```diff
@@ -1,410 +1,410 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 18:14, 10/04/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalES(Optimizer):
-    """
-    The original version of: Evolution Strategies (ES)
-
-    Links:
-        1. https://www.cleveralgorithms.com/nature-inspired/evolution/evolution_strategies.html
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + lamda (float): [0.5, 1.0], Percentage of child agents evolving in the next generation
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.evolutionary_based.ES import OriginalES
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> lamda = 0.75
-    >>> model = OriginalES(epoch, pop_size, lamda)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Beyer, H.G. and Schwefel, H.P., 2002. Evolution strategiesâa comprehensive introduction. Natural computing, 1(1), pp.3-52.
-    """
-
-    ID_POS = 0
-    ID_TAR = 1
-    ID_STR = 2  # strategy
-
-    def __init__(self, epoch=10000, pop_size=100, lamda=0.75, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size (miu in the paper), default = 100
-            lamda (float): Percentage of child agents evolving in the next generation, default=0.75
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.lamda = self.validator.check_float("lamda", lamda, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "lamda"])
-        self.n_child = int(self.lamda * self.pop_size)
-        self.sort_flag = True
-    
-    def initialize_variables(self):
-        self.distance = 0.05 * (self.problem.ub - self.problem.lb)
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        """
-        Overriding method in Optimizer class
-
-        Returns:
-            list: solution with format [position, target, strategy]
-        """
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        position = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(position)
-        strategy = np.random.uniform(0, self.distance)
-        return [position, target, strategy]
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        child = []
-        for idx in range(0, self.n_child):
-            pos_new = self.pop[idx][self.ID_POS] + self.pop[idx][self.ID_STR] * np.random.normal(0, 1.0, self.problem.n_dims)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            tau = np.sqrt(2.0 * self.problem.n_dims) ** -1.0
-            tau_p = np.sqrt(2.0 * np.sqrt(self.problem.n_dims)) ** -1.0
-            strategy = np.exp(tau_p * np.random.normal(0, 1.0, self.problem.n_dims) + tau * np.random.normal(0, 1.0, self.problem.n_dims))
-            child.append([pos_new, None, strategy])
-            if self.mode not in self.AVAILABLE_MODES:
-                child[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        child = self.update_target_wrapper_population(child)
-        self.pop = self.get_sorted_strim_population(child + self.pop, self.pop_size)
-
-
-class LevyES(OriginalES):
-    """
-    The developed Levy-flight version: Evolution Strategies (ES)
-
-    Links:
-        1. https://www.cleveralgorithms.com/nature-inspired/evolution/evolution_strategies.html
-
-    Notes
-    ~~~~~
-    The Levy-flight is applied, the flow and equations is changed
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + lamda (float): [0.5, 1.0], Percentage of child agents evolving in the next generation
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.evolutionary_based.ES import OriginalES
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> lamda = 0.75
-    >>> model = OriginalES(epoch, pop_size, lamda)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Beyer, H.G. and Schwefel, H.P., 2002. Evolution strategiesâa comprehensive introduction. Natural computing, 1(1), pp.3-52.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, lamda=0.75, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size (miu in the paper), default = 100
-            lamda (float): Percentage of child agents evolving in the next generation, default=0.75
-        """
-        super().__init__(epoch, pop_size, lamda, **kwargs)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        child = []
-        for idx in range(0, self.n_child):
-            pos_new = self.pop[idx][self.ID_POS] + self.pop[idx][self.ID_STR] * np.random.normal(0, 1.0, self.problem.n_dims)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            tau = np.sqrt(2.0 * self.problem.n_dims) ** -1.0
-            tau_p = np.sqrt(2.0 * np.sqrt(self.problem.n_dims)) ** -1.0
-            strategy = np.exp(tau_p * np.random.normal(0, 1.0, self.problem.n_dims) + tau * np.random.normal(0, 1.0, self.problem.n_dims))
-            child.append([pos_new, None, strategy])
-            if self.mode not in self.AVAILABLE_MODES:
-                child[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        child = self.update_target_wrapper_population(child)
-
-        child_levy = []
-        for idx in range(0, self.n_child):
-            pos_new = self.pop[idx][self.ID_POS] + self.get_levy_flight_step(multiplier=0.001, size=self.problem.n_dims, case=-1)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            tau = np.sqrt(2.0 * self.problem.n_dims) ** -1.0
-            tau_p = np.sqrt(2.0 * np.sqrt(self.problem.n_dims)) ** -1.0
-            stdevs = np.array([np.exp(tau_p * np.random.normal(0, 1.0) + tau * np.random.normal(0, 1.0)) for _ in range(self.problem.n_dims)])
-            child_levy.append([pos_new, None, stdevs])
-            if self.mode not in self.AVAILABLE_MODES:
-                child_levy[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        child_levy = self.update_target_wrapper_population(child_levy)
-        self.pop = self.get_sorted_strim_population(child + child_levy + self.pop, self.pop_size)
-
-
-class CMA_ES(Optimizer):
-    """
-    The original version of: Covariance Matrix Adaptation Evolution Strategy (CMA-ES)
-
-    Links:
-        1. https://en.wikipedia.org/wiki/CMA-ES
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.evolutionary_based.ES import CMA_ES
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = CMA_ES(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Hansen, N., & Ostermeier, A. (2001). Completely derandomized self-adaptation in evolution strategies. Evolutionary computation, 9(2), 159-195.
-    """
-
-    ID_POS = 0
-    ID_TAR = 1
-    ID_STEP = 2
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size (miu in the paper), default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = True
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        """
-        Overriding method in Optimizer class
-
-        Returns:
-            list: solution with format [position, target, strategy]
-        """
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        position = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(position)
-        step = np.random.multivariate_normal(np.zeros(self.problem.n_dims), np.eye(self.problem.n_dims))
-        return [position, target, step]
-
-    def before_main_loop(self):
-        self.mu = int(np.round(self.pop_size / 2))
-
-        self.ps = np.zeros(self.problem.n_dims)
-        self.C = np.eye(self.problem.n_dims)
-        self.pc = np.zeros(self.problem.n_dims)
-
-        self.w = np.log(self.pop_size + 0.5) - np.log(np.arange(1, self.pop_size+1))
-        self.w = self.w / np.sum(self.w)
-        self.mu_eff = 1. / np.sum(self.w**2)      # Number of effective solutions
-
-        # Step Size Control Parameters (c_sigma and d_sigma);
-        sigma0 = 0.1 * (self.problem.ub - self.problem.lb)
-        self.cs = (self.mu_eff + 2) / (self.problem.n_dims + self.mu_eff + 5)
-        self.ds = 1 + self.cs + 2*np.max(np.sqrt((self.mu_eff - 1.)/(self.problem.n_dims + 1)) - 1, 0)
-        self.ENN = np.sqrt(self.problem.n_dims) * (1 - 1.0/(4*self.problem.n_dims) + 1.0/(21*self.problem.n_dims**2))
-
-        ## Covariance Update Parameters
-        self.cc = (4+self.mu_eff/self.problem.n_dims) / (4 + self.problem.n_dims + 2 *self.mu_eff/self.problem.n_dims)
-        self.c1 = 2. / ((self.problem.n_dims + 1.3)**2 + self.mu_eff)
-        alpha_mu = 2
-        self.cmu = min(1-self.c1, alpha_mu*(self.mu_eff-2+1/self.mu_eff)/((self.problem.n_dims+2)**2+alpha_mu*self.mu_eff/2))
-        self.hth = (1.4 + 2 / (self.problem.n_dims + 1)) * self.ENN
-        self.sigma = sigma0
-        self.x_mean = np.mean([agent[self.ID_POS] for agent in self.pop[:self.mu]], axis=0)
-
-    def update_step__(self, pop, C):
-        for idx in range(0, self.pop_size):
-            pop[idx][self.ID_STEP] = np.random.multivariate_normal(np.zeros(self.problem.n_dims), C)
-        return pop
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            pos_new = self.x_mean + self.sigma * self.pop[idx][self.ID_STEP]
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            # print(pos_new)
-            pop_new.append([pos_new, None, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop_new = self.update_target_wrapper_population(pop_new)
-        self.pop, self.g_best = self.get_global_best_solution(pop_new)
-
-        # Update MEan
-        self.pop = self.update_step__(self.pop, self.C)
-        self.x_step = np.zeros(self.problem.n_dims)
-        for idx in range(0, self.mu):
-            self.x_step += self.w[idx] * self.pop[idx][self.ID_STEP]
-        self.x_mean = self.x_mean + self.sigma * self.x_step
-
-        # Update Step Size
-        t11 = np.dot(self.x_step, np.linalg.inv(np.linalg.cholesky(self.C).T))
-        self.ps = (1 - self.cs)*self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mu_eff) * t11
-        self.sigma = self.sigma * np.exp(self.cs / self.ds * (np.linalg.norm(self.ps)/self.ENN - 1))**0.3
-
-        # Update Covariance Matrix
-        if np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (epoch+1))) < self.hth:
-            hs = 1
-        else:
-            hs = 0
-        delta = (1 - hs) * self.cc * (2 - self.cc)
-        self.pc = (1 - self.cc)*self.pc + hs*np.sqrt(self.cc * (2 - self.cc)*self.mu_eff) * self.x_step
-        self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (np.outer(self.pc, self.pc)) + delta * self.C
-        for idx in range(0, self.mu):
-            self.C = self.C + self.cmu * self.w[idx] * np.outer(self.pop[idx][self.ID_STEP], self.pop[idx][self.ID_STEP])
-
-        # If Covariance Matrix is not Positive Defenite or Near Singular
-        E, V = np.linalg.eig(self.C)
-        E = np.diag(E)
-        if np.any(np.diag(E) < 0):
-            E[E < 0] = 0
-            self.C = V * E / V
-
-
-class Simple_CMA_ES(Optimizer):
-    """
-    The simple version of: Covariance Matrix Adaptation Evolution Strategy (Simple-CMA-ES)
-
-    Links:
-        1. Inspired from this version: https://github.com/jenkspt/CMA-ES
-        2. https://ieeexplore.ieee.org/abstract/document/6790628/
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.evolutionary_based.ES import Simple_CMA_ES
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = Simple_CMA_ES(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Hansen, N., & Ostermeier, A. (2001). Completely derandomized self-adaptation in evolution strategies. Evolutionary computation, 9(2), 159-195.
-    """
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size (miu in the paper), default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def before_main_loop(self):
-        self.mu = int(np.round(self.pop_size / 2))
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pos_list = np.array([agent[self.ID_POS] for agent in self.pop]).T
-        pop_sorted, _ = self.get_global_best_solution(self.pop)
-        pos_topk = np.array([agent[self.ID_POS] for agent in pop_sorted[:self.mu]]).T
-        # Covariance of topk but using mean of entire population
-        centered = pos_list - pos_topk.mean(1, keepdims=True)
-        C = (centered @ centered.T) / (self.mu - 1)
-        # Eigenvalue decomposition
-        w, E = np.linalg.eigh(C)
-        if np.any(np.diag(w) < 0):
-            w[w < 0] = 0
-        # Generate new population
-        # Sample from multivariate gaussian with mean of topk
-        N = np.random.normal(size=(self.problem.n_dims, self.pop_size))
-        X = pos_topk.mean(1, keepdims=True) + (E @ np.diag(np.sqrt(w)) @ N)
-        X = X.T
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            pos_new = self.amend_position(X[idx], self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution(pop_new[-1], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 18:14, 10/04/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalES(Optimizer):
+    """
+    The original version of: Evolution Strategies (ES)
+
+    Links:
+        1. https://www.cleveralgorithms.com/nature-inspired/evolution/evolution_strategies.html
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + lamda (float): [0.5, 1.0], Percentage of child agents evolving in the next generation
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.evolutionary_based.ES import OriginalES
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> lamda = 0.75
+    >>> model = OriginalES(epoch, pop_size, lamda)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Beyer, H.G. and Schwefel, H.P., 2002. Evolution strategiesâa comprehensive introduction. Natural computing, 1(1), pp.3-52.
+    """
+
+    ID_POS = 0
+    ID_TAR = 1
+    ID_STR = 2  # strategy
+
+    def __init__(self, epoch=10000, pop_size=100, lamda=0.75, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size (miu in the paper), default = 100
+            lamda (float): Percentage of child agents evolving in the next generation, default=0.75
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.lamda = self.validator.check_float("lamda", lamda, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "lamda"])
+        self.n_child = int(self.lamda * self.pop_size)
+        self.sort_flag = True
+    
+    def initialize_variables(self):
+        self.distance = 0.05 * (self.problem.ub - self.problem.lb)
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        """
+        Overriding method in Optimizer class
+
+        Returns:
+            list: solution with format [position, target, strategy]
+        """
+        if pos is None:
+            pos = self.generate_position(lb, ub)
+        position = self.amend_position(pos, lb, ub)
+        target = self.get_target_wrapper(position)
+        strategy = np.random.uniform(0, self.distance)
+        return [position, target, strategy]
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        child = []
+        for idx in range(0, self.n_child):
+            pos_new = self.pop[idx][self.ID_POS] + self.pop[idx][self.ID_STR] * np.random.normal(0, 1.0, self.problem.n_dims)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            tau = np.sqrt(2.0 * self.problem.n_dims) ** -1.0
+            tau_p = np.sqrt(2.0 * np.sqrt(self.problem.n_dims)) ** -1.0
+            strategy = np.exp(tau_p * np.random.normal(0, 1.0, self.problem.n_dims) + tau * np.random.normal(0, 1.0, self.problem.n_dims))
+            child.append([pos_new, None, strategy])
+            if self.mode not in self.AVAILABLE_MODES:
+                child[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        child = self.update_target_wrapper_population(child)
+        self.pop = self.get_sorted_strim_population(child + self.pop, self.pop_size)
+
+
+class LevyES(OriginalES):
+    """
+    The developed Levy-flight version: Evolution Strategies (ES)
+
+    Links:
+        1. https://www.cleveralgorithms.com/nature-inspired/evolution/evolution_strategies.html
+
+    Notes
+    ~~~~~
+    The Levy-flight is applied, the flow and equations is changed
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + lamda (float): [0.5, 1.0], Percentage of child agents evolving in the next generation
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.evolutionary_based.ES import OriginalES
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> lamda = 0.75
+    >>> model = OriginalES(epoch, pop_size, lamda)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Beyer, H.G. and Schwefel, H.P., 2002. Evolution strategiesâa comprehensive introduction. Natural computing, 1(1), pp.3-52.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, lamda=0.75, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size (miu in the paper), default = 100
+            lamda (float): Percentage of child agents evolving in the next generation, default=0.75
+        """
+        super().__init__(epoch, pop_size, lamda, **kwargs)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        child = []
+        for idx in range(0, self.n_child):
+            pos_new = self.pop[idx][self.ID_POS] + self.pop[idx][self.ID_STR] * np.random.normal(0, 1.0, self.problem.n_dims)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            tau = np.sqrt(2.0 * self.problem.n_dims) ** -1.0
+            tau_p = np.sqrt(2.0 * np.sqrt(self.problem.n_dims)) ** -1.0
+            strategy = np.exp(tau_p * np.random.normal(0, 1.0, self.problem.n_dims) + tau * np.random.normal(0, 1.0, self.problem.n_dims))
+            child.append([pos_new, None, strategy])
+            if self.mode not in self.AVAILABLE_MODES:
+                child[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        child = self.update_target_wrapper_population(child)
+
+        child_levy = []
+        for idx in range(0, self.n_child):
+            pos_new = self.pop[idx][self.ID_POS] + self.get_levy_flight_step(multiplier=0.001, size=self.problem.n_dims, case=-1)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            tau = np.sqrt(2.0 * self.problem.n_dims) ** -1.0
+            tau_p = np.sqrt(2.0 * np.sqrt(self.problem.n_dims)) ** -1.0
+            stdevs = np.array([np.exp(tau_p * np.random.normal(0, 1.0) + tau * np.random.normal(0, 1.0)) for _ in range(self.problem.n_dims)])
+            child_levy.append([pos_new, None, stdevs])
+            if self.mode not in self.AVAILABLE_MODES:
+                child_levy[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        child_levy = self.update_target_wrapper_population(child_levy)
+        self.pop = self.get_sorted_strim_population(child + child_levy + self.pop, self.pop_size)
+
+
+class CMA_ES(Optimizer):
+    """
+    The original version of: Covariance Matrix Adaptation Evolution Strategy (CMA-ES)
+
+    Links:
+        1. https://en.wikipedia.org/wiki/CMA-ES
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.evolutionary_based.ES import CMA_ES
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = CMA_ES(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Hansen, N., & Ostermeier, A. (2001). Completely derandomized self-adaptation in evolution strategies. Evolutionary computation, 9(2), 159-195.
+    """
+
+    ID_POS = 0
+    ID_TAR = 1
+    ID_STEP = 2
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size (miu in the paper), default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = True
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        """
+        Overriding method in Optimizer class
+
+        Returns:
+            list: solution with format [position, target, strategy]
+        """
+        if pos is None:
+            pos = self.generate_position(lb, ub)
+        position = self.amend_position(pos, lb, ub)
+        target = self.get_target_wrapper(position)
+        step = np.random.multivariate_normal(np.zeros(self.problem.n_dims), np.eye(self.problem.n_dims))
+        return [position, target, step]
+
+    def before_main_loop(self):
+        self.mu = int(np.round(self.pop_size / 2))
+
+        self.ps = np.zeros(self.problem.n_dims)
+        self.C = np.eye(self.problem.n_dims)
+        self.pc = np.zeros(self.problem.n_dims)
+
+        self.w = np.log(self.pop_size + 0.5) - np.log(np.arange(1, self.pop_size+1))
+        self.w = self.w / np.sum(self.w)
+        self.mu_eff = 1. / np.sum(self.w**2)      # Number of effective solutions
+
+        # Step Size Control Parameters (c_sigma and d_sigma);
+        sigma0 = 0.1 * (self.problem.ub - self.problem.lb)
+        self.cs = (self.mu_eff + 2) / (self.problem.n_dims + self.mu_eff + 5)
+        self.ds = 1 + self.cs + 2*np.max(np.sqrt((self.mu_eff - 1.)/(self.problem.n_dims + 1)) - 1, 0)
+        self.ENN = np.sqrt(self.problem.n_dims) * (1 - 1.0/(4*self.problem.n_dims) + 1.0/(21*self.problem.n_dims**2))
+
+        ## Covariance Update Parameters
+        self.cc = (4+self.mu_eff/self.problem.n_dims) / (4 + self.problem.n_dims + 2 *self.mu_eff/self.problem.n_dims)
+        self.c1 = 2. / ((self.problem.n_dims + 1.3)**2 + self.mu_eff)
+        alpha_mu = 2
+        self.cmu = min(1-self.c1, alpha_mu*(self.mu_eff-2+1/self.mu_eff)/((self.problem.n_dims+2)**2+alpha_mu*self.mu_eff/2))
+        self.hth = (1.4 + 2 / (self.problem.n_dims + 1)) * self.ENN
+        self.sigma = sigma0
+        self.x_mean = np.mean([agent[self.ID_POS] for agent in self.pop[:self.mu]], axis=0)
+
+    def update_step__(self, pop, C):
+        for idx in range(0, self.pop_size):
+            pop[idx][self.ID_STEP] = np.random.multivariate_normal(np.zeros(self.problem.n_dims), C)
+        return pop
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            pos_new = self.x_mean + self.sigma * self.pop[idx][self.ID_STEP]
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            # print(pos_new)
+            pop_new.append([pos_new, None, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop_new = self.update_target_wrapper_population(pop_new)
+        self.pop, self.g_best = self.get_global_best_solution(pop_new)
+
+        # Update MEan
+        self.pop = self.update_step__(self.pop, self.C)
+        self.x_step = np.zeros(self.problem.n_dims)
+        for idx in range(0, self.mu):
+            self.x_step += self.w[idx] * self.pop[idx][self.ID_STEP]
+        self.x_mean = self.x_mean + self.sigma * self.x_step
+
+        # Update Step Size
+        t11 = np.dot(self.x_step, np.linalg.inv(np.linalg.cholesky(self.C).T))
+        self.ps = (1 - self.cs)*self.ps + np.sqrt(self.cs * (2 - self.cs) * self.mu_eff) * t11
+        self.sigma = self.sigma * np.exp(self.cs / self.ds * (np.linalg.norm(self.ps)/self.ENN - 1))**0.3
+
+        # Update Covariance Matrix
+        if np.linalg.norm(self.ps) / np.sqrt(1 - (1 - self.cs)**(2 * (epoch+1))) < self.hth:
+            hs = 1
+        else:
+            hs = 0
+        delta = (1 - hs) * self.cc * (2 - self.cc)
+        self.pc = (1 - self.cc)*self.pc + hs*np.sqrt(self.cc * (2 - self.cc)*self.mu_eff) * self.x_step
+        self.C = (1 - self.c1 - self.cmu) * self.C + self.c1 * (np.outer(self.pc, self.pc)) + delta * self.C
+        for idx in range(0, self.mu):
+            self.C = self.C + self.cmu * self.w[idx] * np.outer(self.pop[idx][self.ID_STEP], self.pop[idx][self.ID_STEP])
+
+        # If Covariance Matrix is not Positive Defenite or Near Singular
+        E, V = np.linalg.eig(self.C)
+        E = np.diag(E)
+        if np.any(np.diag(E) < 0):
+            E[E < 0] = 0
+            self.C = V * E / V
+
+
+class Simple_CMA_ES(Optimizer):
+    """
+    The simple version of: Covariance Matrix Adaptation Evolution Strategy (Simple-CMA-ES)
+
+    Links:
+        1. Inspired from this version: https://github.com/jenkspt/CMA-ES
+        2. https://ieeexplore.ieee.org/abstract/document/6790628/
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.evolutionary_based.ES import Simple_CMA_ES
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = Simple_CMA_ES(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Hansen, N., & Ostermeier, A. (2001). Completely derandomized self-adaptation in evolution strategies. Evolutionary computation, 9(2), 159-195.
+    """
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size (miu in the paper), default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def before_main_loop(self):
+        self.mu = int(np.round(self.pop_size / 2))
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pos_list = np.array([agent[self.ID_POS] for agent in self.pop]).T
+        pop_sorted, _ = self.get_global_best_solution(self.pop)
+        pos_topk = np.array([agent[self.ID_POS] for agent in pop_sorted[:self.mu]]).T
+        # Covariance of topk but using mean of entire population
+        centered = pos_list - pos_topk.mean(1, keepdims=True)
+        C = (centered @ centered.T) / (self.mu - 1)
+        # Eigenvalue decomposition
+        w, E = np.linalg.eigh(C)
+        if np.any(np.diag(w) < 0):
+            w[w < 0] = 0
+        # Generate new population
+        # Sample from multivariate gaussian with mean of topk
+        N = np.random.normal(size=(self.problem.n_dims, self.pop_size))
+        X = pos_topk.mean(1, keepdims=True) + (E @ np.diag(np.sqrt(w)) @ N)
+        X = X.T
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            pos_new = self.amend_position(X[idx], self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution(pop_new[-1], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/evolutionary_based/FPA.py` & `mealpy-2.5.3a1/mealpy/evolutionary_based/FPA.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,104 +1,104 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 19:34, 08/04/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalFPA(Optimizer):
-    """
-    The original version of: Flower Pollination Algorithm (FPA)
-
-    Links:
-        1. https://doi.org/10.1007/978-3-642-32894-7_27
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + p_s (float): [0.5, 0.95], switch probability, default = 0.8
-        + levy_multiplier: [0.0001, 1000], mutiplier factor of Levy-flight trajectory, depends on the problem
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.evolutionary_based.FPA import OriginalFPA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> p_s = 0.8
-    >>> levy_multiplier = 0.2
-    >>> model = OriginalFPA(epoch, pop_size, p_s, levy_multiplier)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Yang, X.S., 2012, September. Flower pollination algorithm for global optimization. In International
-    conference on unconventional computing and natural computation (pp. 240-249). Springer, Berlin, Heidelberg.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, p_s=0.8, levy_multiplier=0.1, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            p_s (float): switch probability, default = 0.8
-            levy_multiplier (float): multiplier factor of Levy-flight trajectory, default = 0.2
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.p_s = self.validator.check_float("p_s", p_s, (0, 1.0))
-        self.levy_multiplier = self.validator.check_float("levy_multiplier", levy_multiplier, (-10000, 10000))
-        self.set_parameters(["epoch", "pop_size", "p_s", "levy_multiplier"])
-        self.sort_flag = False
-
-    def amend_position(self, position=None, lb=None, ub=None):
-        """
-        Args:
-            position: vector position (location) of the solution.
-            lb: list of lower bound values
-            ub: list of upper bound values
-
-        Returns:
-            Amended position (make the position is in bound)
-        """
-        condition = np.logical_and(lb <= position, position <= ub)
-        random_pos = np.random.uniform(lb, ub)
-        return np.where(condition, position, random_pos)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop = []
-        for idx in range(0, self.pop_size):
-            if np.random.uniform() < self.p_s:
-                levy = self.get_levy_flight_step(multiplier=self.levy_multiplier, size=self.problem.n_dims, case=-1)
-                pos_new = self.pop[idx][self.ID_POS] + 1.0 / np.sqrt(epoch + 1) * \
-                          levy * (self.pop[idx][self.ID_POS] - self.g_best[self.ID_POS])
-            else:
-                id1, id2 = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 2, replace=False)
-                pos_new = self.pop[idx][self.ID_POS] + np.random.uniform() * (self.pop[id1][self.ID_POS] - self.pop[id2][self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop = self.update_target_wrapper_population(pop)
-            self.pop = self.greedy_selection_population(self.pop, pop)
+#!/usr/bin/env python
+# Created by "Thieu" at 19:34, 08/04/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalFPA(Optimizer):
+    """
+    The original version of: Flower Pollination Algorithm (FPA)
+
+    Links:
+        1. https://doi.org/10.1007/978-3-642-32894-7_27
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + p_s (float): [0.5, 0.95], switch probability, default = 0.8
+        + levy_multiplier: [0.0001, 1000], mutiplier factor of Levy-flight trajectory, depends on the problem
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.evolutionary_based.FPA import OriginalFPA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> p_s = 0.8
+    >>> levy_multiplier = 0.2
+    >>> model = OriginalFPA(epoch, pop_size, p_s, levy_multiplier)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Yang, X.S., 2012, September. Flower pollination algorithm for global optimization. In International
+    conference on unconventional computing and natural computation (pp. 240-249). Springer, Berlin, Heidelberg.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, p_s=0.8, levy_multiplier=0.1, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            p_s (float): switch probability, default = 0.8
+            levy_multiplier (float): multiplier factor of Levy-flight trajectory, default = 0.2
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.p_s = self.validator.check_float("p_s", p_s, (0, 1.0))
+        self.levy_multiplier = self.validator.check_float("levy_multiplier", levy_multiplier, (-10000, 10000))
+        self.set_parameters(["epoch", "pop_size", "p_s", "levy_multiplier"])
+        self.sort_flag = False
+
+    def amend_position(self, position=None, lb=None, ub=None):
+        """
+        Args:
+            position: vector position (location) of the solution.
+            lb: list of lower bound values
+            ub: list of upper bound values
+
+        Returns:
+            Amended position (make the position is in bound)
+        """
+        condition = np.logical_and(lb <= position, position <= ub)
+        random_pos = np.random.uniform(lb, ub)
+        return np.where(condition, position, random_pos)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop = []
+        for idx in range(0, self.pop_size):
+            if np.random.uniform() < self.p_s:
+                levy = self.get_levy_flight_step(multiplier=self.levy_multiplier, size=self.problem.n_dims, case=-1)
+                pos_new = self.pop[idx][self.ID_POS] + 1.0 / np.sqrt(epoch + 1) * \
+                          levy * (self.pop[idx][self.ID_POS] - self.g_best[self.ID_POS])
+            else:
+                id1, id2 = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 2, replace=False)
+                pos_new = self.pop[idx][self.ID_POS] + np.random.uniform() * (self.pop[id1][self.ID_POS] - self.pop[id2][self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop = self.update_target_wrapper_population(pop)
+            self.pop = self.greedy_selection_population(self.pop, pop)
```

### Comparing `mealpy-2.5.3/mealpy/evolutionary_based/GA.py` & `mealpy-2.5.3a1/mealpy/evolutionary_based/GA.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,787 +1,787 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 09:33, 16/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-import copy as cp
-
-
-class BaseGA(Optimizer):
-    """
-    The original version of: Genetic Algorithm (GA)
-
-    Links:
-        1. https://blog.sicara.com/getting-started-genetic-algorithms-python-tutorial-81ffa1dd72f9
-        2. https://www.tutorialspoint.com/genetic_algorithms/genetic_algorithms_quick_guide.htm
-        3. https://www.analyticsvidhya.com/blog/2017/07/introduction-to-genetic-algorithm/
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + pc (float): [0.7, 0.95], cross-over probability, default = 0.95
-        + pm (float): [0.01, 0.2], mutation probability, default = 0.025
-        + selection (str): Optional, can be ["roulette", "tournament", "random"], default = "tournament"
-        + k_way (float): Optional, set it when use "tournament" selection, default = 0.2
-        + crossover (str): Optional, can be ["one_point", "multi_points", "uniform", "arithmetic"], default = "uniform"
-        + mutation_multipoints (bool): Optional, True or False, effect on mutation process, default = True
-        + mutation (str): Optional, can be ["flip", "swap"] for multipoints and can be ["flip", "swap", "scramble", "inversion"] for one-point
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.evolutionary_based.GA import BaseGA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> pc = 0.9
-    >>> pm = 0.05
-    >>> model1 = BaseGA(epoch, pop_size, pc, pm)
-    >>> best_position, best_fitness = model1.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    >>>
-    >>> model2 = BaseGA(epoch, pop_size, pc, pm, selection="tournament", k_way=0.4, crossover="multi_points")
-    >>>
-    >>> model3 = BaseGA(epoch, pop_size, pc, pm, crossover="one_point", mutation="scramble")
-    >>>
-    >>> model4 = BaseGA(epoch, pop_size, pc, pm, crossover="arithmetic", mutation_multipoints=True, mutation="swap")
-    >>>
-    >>> model5 = BaseGA(epoch, pop_size, pc, pm, selection="roulette", crossover="multi_points")
-    >>>
-    >>> model6 = BaseGA(epoch, pop_size, pc, pm, selection="random", mutation="inversion")
-    >>>
-    >>> model7 = BaseGA(epoch, pop_size, pc, pm, crossover="arithmetic", mutation="flip")
-
-    References
-    ~~~~~~~~~~
-    [1] Whitley, D., 1994. A genetic algorithm tutorial. Statistics and computing, 4(2), pp.65-85.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, pc=0.95, pm=0.025, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            pc (float): cross-over probability, default = 0.95
-            pm (float): mutation probability, default = 0.025
-            selection (str): Optional, can be ["roulette", "tournament", "random"], default = "tournament"
-            k_way (float): Optional, set it when use "tournament" selection, default = 0.2
-            crossover (str): Optional, can be ["one_point", "multi_points", "uniform", "arithmetic"], default = "uniform"
-            mutation_multipoints (bool): Optional, True or False, effect on mutation process, default = False
-            mutation (str): Optional, can be ["flip", "swap"] for multipoints and can be ["flip", "swap", "scramble", "inversion"] for one-point, default="flip"
-        """
-        super().__init__(**kwargs)
-
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.pc = self.validator.check_float("pc", pc, (0, 1.0))
-        self.pm = self.validator.check_float("pm", pm, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "pc", "pm"])
-        self.sort_flag = False
-        self.selection = "tournament"
-        self.k_way = 0.2
-        self.crossover = "uniform"
-        self.mutation = "flip"
-        self.mutation_multipoints = True
-
-        if "selection" in kwargs:
-            self.selection = self.validator.check_str("selection", kwargs["selection"], ["tournament", "random", "roulette"])
-        if "k_way" in kwargs:
-            self.k_way = self.validator.check_float("k_way", kwargs["k_way"], (0, 1.0))
-        if "crossover" in kwargs:
-            self.crossover = self.validator.check_str("crossover", kwargs["crossover"], ["one_point", "multi_points", "uniform", "arithmetic"])
-        if "mutation_multipoints" in kwargs:
-            self.mutation_multipoints = self.validator.check_bool("mutation_multipoints", kwargs["mutation_multipoints"])
-        if self.mutation_multipoints:
-            if "mutation" in kwargs:
-                self.mutation = self.validator.check_str("mutation", kwargs["mutation"], ["flip", "swap"])
-        else:
-            if "mutation" in kwargs:
-                self.mutation = self.validator.check_str("mutation", kwargs["mutation"], ["flip", "swap", "scramble", "inversion"])
-
-    def selection_process__(self, list_fitness):
-        """
-        Notes
-        ~~~~~
-        + https://www.tutorialspoint.com/genetic_algorithms/genetic_algorithms_parent_selection.htm
-        + Default selection strategy is Tournament with k% = 0.2.
-        + Other strategy like "roulette" and "random" can be selected via Optional parameter "selection"
-
-        Args:
-            list_fitness (np.array): list of fitness values.
-
-        Returns:
-            list: The position of dad and mom
-        """
-        if self.selection == "roulette":
-            id_c1 = self.get_index_roulette_wheel_selection(list_fitness)
-            id_c2 = self.get_index_roulette_wheel_selection(list_fitness)
-        elif self.selection == "random":
-            id_c1, id_c2 = np.random.choice(range(self.pop_size), 2, replace=False)
-        else:   ## tournament
-            id_c1, id_c2 = self.get_index_kway_tournament_selection(self.pop, k_way=self.k_way, output=2)
-        return self.pop[id_c1][self.ID_POS], self.pop[id_c2][self.ID_POS]
-
-    def selection_process_00__(self, pop_selected):
-        """
-        Notes
-        ~~~~~
-        + https://www.tutorialspoint.com/genetic_algorithms/genetic_algorithms_parent_selection.htm
-        + Default selection strategy is Tournament with k% = 0.2.
-        + Other strategy like "roulette" and "random" can be selected via Optional parameter "selection"
-
-        Args:
-            pop_selected (np.array): a population that will be selected
-
-        Returns:
-            list: The position of dad and mom
-        """
-        if self.selection == "roulette":
-            list_fitness = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in pop_selected])
-            id_c1 = self.get_index_roulette_wheel_selection(list_fitness)
-            id_c2 = self.get_index_roulette_wheel_selection(list_fitness)
-        elif self.selection == "random":
-            id_c1, id_c2 = np.random.choice(range(len(pop_selected)), 2, replace=False)
-        else:   ## tournament
-            id_c1, id_c2 = self.get_index_kway_tournament_selection(pop_selected, k_way=self.k_way, output=2)
-        return pop_selected[id_c1][self.ID_POS], pop_selected[id_c2][self.ID_POS]
-
-    def selection_process_01__(self, pop_dad, pop_mom):
-        """
-        Notes
-        ~~~~~
-        + https://www.tutorialspoint.com/genetic_algorithms/genetic_algorithms_parent_selection.htm
-        + Default selection strategy is Tournament with k% = 0.2.
-        + Other strategy like "roulette" and "random" can be selected via Optional parameter "selection"
-
-        Returns:
-            list: The position of dad and mom
-        """
-        if self.selection == "roulette":
-            list_fit_dad = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in pop_dad])
-            list_fit_mom = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in pop_mom])
-            id_c1 = self.get_index_roulette_wheel_selection(list_fit_dad)
-            id_c2 = self.get_index_roulette_wheel_selection(list_fit_mom)
-        elif self.selection == "random":
-            id_c1 = np.random.choice(range(len(pop_dad)))
-            id_c2 = np.random.choice(range(len(pop_mom)))
-        else:   ## tournament
-            id_c1 = self.get_index_kway_tournament_selection(pop_dad, k_way=self.k_way, output=1)[0]
-            id_c2 = self.get_index_kway_tournament_selection(pop_mom, k_way=self.k_way, output=1)[0]
-        return pop_dad[id_c1][self.ID_POS], pop_mom[id_c2][self.ID_POS]
-
-    def crossover_process__(self, dad, mom):
-        """
-        Notes
-        ~~~~~
-        + https://www.tutorialspoint.com/genetic_algorithms/genetic_algorithms_crossover.htm
-        + Default crossover strategy is "uniform"
-        + Other strategy like "arithmetic", "one_point", "multi_points" can be selected via parameter: crossover
-
-        Args:
-            dad (np.array): The position of dad
-            mom (np.array): The position of mom
-
-        Returns:
-            list: The position of child 1 and child 2
-        """
-        if self.crossover == "arithmetic":
-            w1, w2 = self.crossover_arithmetic(dad, mom)
-        elif self.crossover == "one_point":
-            cut = np.random.randint(1, self.problem.n_dims-1)
-            w1 = np.concatenate([ dad[:cut], mom[cut:] ])
-            w2 = np.concatenate([ mom[:cut], dad[cut:] ])
-        elif self.crossover == "multi_points":
-            idxs = np.random.choice(range(1, self.problem.n_dims-1), 2, replace=False)
-            cut1, cut2 = np.min(idxs), np.max(idxs)
-            w1 = np.concatenate([ dad[:cut1], mom[cut1:cut2], dad[cut2:] ])
-            w2 = np.concatenate([ mom[:cut1], dad[cut1:cut2], mom[cut2:] ])
-        else:           # uniform
-            flip = np.random.randint(0, 2, self.problem.n_dims)
-            w1 = dad * flip + mom * (1 - flip)
-            w2 = mom * flip + dad * (1 - flip)
-        return w1, w2
-
-    def mutation_process__(self, child):
-        """
-        Notes
-        ~~~~~
-        + https://www.tutorialspoint.com/genetic_algorithms/genetic_algorithms_mutation.htm
-        + There are 2 strategies that effects by the mutation probability: Mutated on single point or the whole vector.
-            + Multiple points (whole vector) has 2 strategies selected via parameter: mutation
-                + flip --> (default in this case) should set the pm small such as: [0.01 -> 0.2]
-                + swap --> should set the pm small such as: [0.01 -> 0.2]
-            + Single point has 4 strategies:
-                + flip --> should set the pm large such as: [0.5 -> 0.9]
-                + swap --> same as flip: pm in range [0.5 -> 0.9]
-                + scramble --> should set the pm small enough such as: [0.4 -> 0.6]
-                + inversion --> like scramble [0.4 -> 0.6]
-
-        Args:
-            child (np.array): The position of the child
-
-        Returns:
-            np.array: The mutated vector of the child
-        """
-
-        if self.mutation_multipoints:
-            if self.mutation == "swap":
-                for idx in range(self.problem.n_dims):
-                    idx_swap = np.random.choice(list(set(range(0, self.problem.n_dims)) - {idx}))
-                    child[idx], child[idx_swap] = child[idx_swap], child[idx]
-                    return child
-            else:       # "flip"
-                mutation_child = self.generate_position(self.problem.lb, self.problem.ub)
-                flag_child = np.random.uniform(0, 1, self.problem.n_dims) < self.pm
-                return np.where(flag_child, mutation_child, child)
-        else:
-            if self.mutation == "swap":
-                idx1, idx2 = np.random.choice(range(0, self.problem.n_dims), 2, replace=False)
-                child[idx1], child[idx2] = child[idx2], child[idx1]
-                return child
-            elif self.mutation == "inversion":
-                cut1, cut2 = np.random.choice(range(0, self.problem.n_dims), 2, replace=False)
-                temp = child[cut1:cut2]
-                temp = temp[::-1]
-                child[cut1:cut2] = temp
-                return child
-            elif self.mutation == "scramble":
-                cut1, cut2 = np.random.choice(range(0, self.problem.n_dims), 2, replace=False)
-                temp = child[cut1:cut2]
-                np.random.shuffle(temp)
-                child[cut1:cut2] = temp
-                return child
-            else:   # "flip"
-                idx = np.random.randint(0, self.problem.n_dims)
-                child[idx] = np.random.uniform(self.problem.lb[idx], self.problem.ub[idx])
-                return child
-
-    def survivor_process__(self, pop, pop_child):
-        """
-        The current survivor process is select the worst solution out of k-way solutions (tournament selection) and
-        compare with child solutions. The better solution will be kept for the next generation.
-
-        Args:
-            pop: The old population
-            pop_child: The new population
-
-        Returns:
-            The new population
-        """
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            id_child = self.get_index_kway_tournament_selection(pop, k_way=0.1, output=1, reverse=True)[0]
-            pop_new.append(self.get_better_solution(pop_child[idx], pop[id_child]))
-        return pop_new
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        list_fitness = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in self.pop])
-        pop_new = []
-        for i in range(0, int(self.pop_size/2)):
-            ### Selection
-            child1, child2 = self.selection_process__(list_fitness)
-
-            ### Crossover
-            if np.random.uniform() < self.pc:
-                child1, child2 = self.crossover_process__(child1, child2)
-
-            ### Mutation
-            child1 = self.mutation_process__(child1)
-            child2 = self.mutation_process__(child2)
-
-            pop_new.append([self.amend_position(child1, self.problem.lb, self.problem.ub), None])
-            pop_new.append([self.amend_position(child2, self.problem.lb, self.problem.ub), None])
-
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-2][self.ID_TAR] = self.get_target_wrapper(child1)
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(child2)
-        ### Survivor Selection
-        pop_new = self.update_target_wrapper_population(pop_new)
-        self.pop = self.survivor_process__(self.pop, pop_new)
-
-
-class SingleGA(BaseGA):
-    """
-    The developed single-point mutation of: Genetic Algorithm (GA)
-
-    Links:
-        1. https://blog.sicara.com/getting-started-genetic-algorithms-python-tutorial-81ffa1dd72f9
-        2. https://www.tutorialspoint.com/genetic_algorithms/genetic_algorithms_quick_guide.htm
-        3. https://www.analyticsvidhya.com/blog/2017/07/introduction-to-genetic-algorithm/
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + pc (float): [0.7, 0.95], cross-over probability, default = 0.95
-        + pm (float): [0.01, 0.2], mutation probability, default = 0.025
-        + selection (str): Optional, can be ["roulette", "tournament", "random"], default = "tournament"
-        + crossover (str): Optional, can be ["one_point", "multi_points", "uniform", "arithmetic"], default = "uniform"
-        + mutation (str): Optional, can be ["flip", "swap", "scramble", "inversion"] for one-point
-        + k_way (float): Optional, set it when use "tournament" selection, default = 0.2
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.evolutionary_based.GA import SingleGA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> pc = 0.9
-    >>> pm = 0.8
-    >>> selection = "roulette"
-    >>> crossover = "uniform"
-    >>> mutation = "swap"
-    >>> model1 = SingleGA(epoch, pop_size, pc, pm, selection, crossover, mutation)
-    >>> best_position, best_fitness = model1.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    >>>
-    >>> model2 = SingleGA(epoch, pop_size, pc, pm, selection="tournament", k_way=0.4, crossover="multi_points")
-    >>>
-    >>> model3 = SingleGA(epoch, pop_size, pc, pm, crossover="one_point", mutation="scramble")
-    >>>
-    >>> model4 = SingleGA(epoch, pop_size, pc, pm, crossover="arithmetic", mutation="swap")
-    >>>
-    >>> model5 = SingleGA(epoch, pop_size, pc, pm, selection="roulette", crossover="multi_points")
-    >>>
-    >>> model6 = SingleGA(epoch, pop_size, pc, pm, selection="random", mutation="inversion")
-    >>>
-    >>> model7 = SingleGA(epoch, pop_size, pc, pm, crossover="arithmetic", mutation="flip")
-
-    References
-    ~~~~~~~~~~
-    [1] Whitley, D., 1994. A genetic algorithm tutorial. Statistics and computing, 4(2), pp.65-85.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, pc=0.95, pm=0.8, selection="roulette",
-                 crossover="uniform", mutation="swap", k_way=0.2, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            pc (float): cross-over probability, default = 0.95
-            pm (float): mutation probability, default = 0.8
-            selection (str): Optional, can be ["roulette", "tournament", "random"], default = "tournament"
-            crossover (str): Optional, can be ["one_point", "multi_points", "uniform", "arithmetic"], default = "uniform"
-            mutation (str): Optional, can be ["flip", "swap", "scramble", "inversion"], default="flip"
-            k_way (float): Optional, set it when use "tournament" selection, default = 0.2
-        """
-        super().__init__(epoch, pop_size, pc, pm, **kwargs)
-        self.selection = self.validator.check_str("selection", selection, ["tournament", "random", "roulette"])
-        self.crossover = self.validator.check_str("crossover", crossover, ["one_point", "multi_points", "uniform", "arithmetic"])
-        self.mutation = self.validator.check_str("mutation", mutation, ["flip", "swap", "scramble", "inversion"])
-        self.k_way = self.validator.check_float("k_way", k_way, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "pc", "pm", "selection", "crossover", "mutation", "k_way"])
-        self.sort_flag = False
-
-    def mutation_process__(self, child):
-        """
-        + https://www.tutorialspoint.com/genetic_algorithms/genetic_algorithms_mutation.htm
-        + The mutation process is effected by parameter: pm
-            + flip --> should set the pm large such as: [0.5 -> 0.9]
-            + swap --> same as flip: pm in range [0.5 -> 0.9]
-            + scramble --> should set the pm small enough such as: [0.4 -> 0.6]
-            + inversion --> like scramble [0.4 -> 0.6]
-
-        Args:
-            child (np.array): The position of the child
-
-        Returns:
-            np.array: The mutated vector of the child
-        """
-        if self.mutation == "swap":
-            idx1, idx2 = np.random.choice(range(0, self.problem.n_dims), 2, replace=False)
-            child[idx1], child[idx2] = child[idx2], child[idx1]
-            return child
-        elif self.mutation == "inversion":
-            cut1, cut2 = np.random.choice(range(0, self.problem.n_dims), 2, replace=False)
-            temp = child[cut1:cut2]
-            temp = temp[::-1]
-            child[cut1:cut2] = temp
-            return child
-        elif self.mutation == "scramble":
-            cut1, cut2 = np.random.choice(range(0, self.problem.n_dims), 2, replace=False)
-            temp = child[cut1:cut2]
-            np.random.shuffle(temp)
-            child[cut1:cut2] = temp
-            return child
-        else:   # "flip"
-            idx = np.random.randint(0, self.problem.n_dims)
-            child[idx] = np.random.uniform(self.problem.lb[idx], self.problem.ub[idx])
-            return child
-
-
-class EliteSingleGA(SingleGA):
-    """
-    The developed elite single-point mutation of: Genetic Algorithm (GA)
-
-    Links:
-        1. https://www.baeldung.com/cs/elitism-in-evolutionary-algorithms
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + pc (float): [0.7, 0.95], cross-over probability, default = 0.95
-        + pm (float): [0.01, 0.2], mutation probability, default = 0.025
-        + selection (str): Optional, can be ["roulette", "tournament", "random"], default = "tournament"
-        + crossover (str): Optional, can be ["one_point", "multi_points", "uniform", "arithmetic"], default = "uniform"
-        + mutation (str): Optional, can be ["flip", "swap", "scramble", "inversion"] for one-point
-        + k_way (float): Optional, set it when use "tournament" selection, default = 0.2
-        + elite_best (float/int): Optional, can be float (percentage of the best in elite group), or int (the number of best elite), default = 0.1
-        + elite_worst (float/int): Opttional, can be float (percentage of the worst in elite group), or int (the number of worst elite), default = 0.3
-        + strategy (int): Optional, can be 0 or 1. If = 0, the selection is select parents from (elite_worst + non_elite_group).
-            Else, the selection will select dad from elite_worst and mom from non_elite_group.
-        + pop_size = elite_group (elite_best + elite_worst) + non_elite_group
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.evolutionary_based.GA import EliteSingleGA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> pc = 0.9
-    >>> pm = 0.8
-    >>> selection = "roulette"
-    >>> crossover = "uniform"
-    >>> mutation = "swap"
-    >>> elite_best = 0.1
-    >>> elite_worst = 0.3
-    >>> strategy = 0
-    >>> model1 = EliteSingleGA(epoch, pop_size, pc, pm, selection, crossover, mutation, elite_best, elite_worst, strategy)
-    >>> best_position, best_fitness = model1.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    >>>
-    >>> model2 = EliteSingleGA(epoch, pop_size, pc, pm, selection="tournament", k_way=0.4, crossover="multi_points")
-    >>>
-    >>> model3 = EliteSingleGA(epoch, pop_size, pc, pm, crossover="one_point", mutation="scramble")
-    >>>
-    >>> model4 = EliteSingleGA(epoch, pop_size, pc, pm, crossover="arithmetic", mutation="swap")
-    >>>
-    >>> model5 = EliteSingleGA(epoch, pop_size, pc, pm, selection="roulette", crossover="multi_points")
-    >>>
-    >>> model6 = EliteSingleGA(epoch, pop_size, pc, pm, selection="random", mutation="inversion")
-    >>>
-    >>> model7 = EliteSingleGA(epoch, pop_size, pc, pm, crossover="arithmetic", mutation="flip")
-
-    References
-    ~~~~~~~~~~
-    [1] Whitley, D., 1994. A genetic algorithm tutorial. Statistics and computing, 4(2), pp.65-85.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, pc=0.95, pm=0.8, selection="roulette",
-                 crossover="uniform", mutation="swap", k_way=0.2,
-                 elite_best=0.1, elite_worst=0.3, strategy=0, **kwargs):
-        super().__init__(epoch, pop_size, pc, pm, selection, crossover, mutation, k_way, **kwargs)
-        self.elite_best = self.validator.check_is_int_and_float("elite_best", elite_best, [1, int(self.pop_size / 2)-1], (0, 0.5))
-        self.n_elite_best = int(self.elite_best * self.pop_size) if self.elite_best < 1 else self.elite_best
-        if self.n_elite_best < 1:
-            self.n_elite_best = 1
-
-        self.elite_worst = self.validator.check_is_int_and_float("elite_worst", elite_worst, [1, int(self.pop_size / 2)-1], (0, 0.5))
-        self.n_elite_worst = int(self.elite_worst * self.pop_size) if self.elite_worst < 1 else self.elite_worst
-        if self.n_elite_worst < 1:
-            self.n_elite_worst = 1
-
-        self.strategy = self.validator.check_int("strategy", strategy, [0, 1])
-        self.set_parameters(["epoch", "pop_size", "pc", "pm", "selection", "crossover", "mutation", "k_way",
-                             "elite_best", "elite_worst", "strategy"])
-        self.sort_flag = True
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = cp.deepcopy(self.pop[:self.n_elite_best])
-
-        if self.strategy == 0:
-            pop_old = cp.deepcopy(self.pop[self.n_elite_best:])
-            for idx in range(self.n_elite_best, self.pop_size):
-                ### Selection
-                child1, child2 = self.selection_process_00__(pop_old)
-                ### Crossover
-                if np.random.uniform() < self.pc:
-                    child1, child2 = self.crossover_process__(child1, child2)
-                child = child1 if np.random.random() <= 0.5 else child2
-                ### Mutation
-                child = self.mutation_process__(child)
-                ### Survivor Selection
-                pos_new = self.amend_position(child, self.problem.lb, self.problem.ub)
-                pop_new.append([pos_new, None])
-                if self.mode not in self.AVAILABLE_MODES:
-                    pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-            self.pop = self.update_target_wrapper_population(pop_new)
-        else:
-            pop_dad = cp.deepcopy(self.pop[self.n_elite_best:self.n_elite_best+self.n_elite_worst])
-            pop_mom = cp.deepcopy(self.pop[self.n_elite_best+self.n_elite_worst:])
-            for idx in range(self.n_elite_best, self.pop_size):
-                ### Selection
-                child1, child2 = self.selection_process_01__(pop_dad, pop_mom)
-                ### Crossover
-                if np.random.uniform() < self.pc:
-                    child1, child2 = self.crossover_process__(child1, child2)
-                child = child1 if np.random.random() <= 0.5 else child2
-                ### Mutation
-                child = self.mutation_process__(child)
-                ### Survivor Selection
-                pos_new = self.amend_position(child, self.problem.lb, self.problem.ub)
-                pop_new.append([pos_new, None])
-                if self.mode not in self.AVAILABLE_MODES:
-                    pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-            self.pop = self.update_target_wrapper_population(pop_new)
-
-
-class MultiGA(BaseGA):
-    """
-    The developed multipoints-mutation version of: Genetic Algorithm (GA)
-
-    Links:
-        1. https://blog.sicara.com/getting-started-genetic-algorithms-python-tutorial-81ffa1dd72f9
-        2. https://www.tutorialspoint.com/genetic_algorithms/genetic_algorithms_quick_guide.htm
-        3. https://www.analyticsvidhya.com/blog/2017/07/introduction-to-genetic-algorithm/
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + pc (float): [0.7, 0.95], cross-over probability, default = 0.95
-        + pm (float): [0.01, 0.2], mutation probability, default = 0.025
-        + selection (str): Optional, can be ["roulette", "tournament", "random"], default = "tournament"
-        + k_way (float): Optional, set it when use "tournament" selection, default = 0.2
-        + crossover (str): Optional, can be ["one_point", "multi_points", "uniform", "arithmetic"], default = "uniform"
-        + mutation (str): Optional, can be ["flip", "swap"] for multipoints
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.evolutionary_based.GA import MultiGA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> pc = 0.9
-    >>> pm = 0.05
-    >>> selection = "roulette"
-    >>> crossover = "uniform"
-    >>> mutation = "swap"
-    >>> model1 = MultiGA(epoch, pop_size, pc, pm, selection, crossover, mutation)
-    >>> best_position, best_fitness = model1.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    >>>
-    >>> model2 = MultiGA(epoch, pop_size, pc, pm, selection="tournament", k_way=0.4, crossover="multi_points")
-    >>>
-    >>> model3 = MultiGA(epoch, pop_size, pc, pm, crossover="one_point", mutation="flip")
-    >>>
-    >>> model4 = MultiGA(epoch, pop_size, pc, pm, crossover="arithmetic", mutation_multipoints=True, mutation="swap")
-    >>>
-    >>> model5 = MultiGA(epoch, pop_size, pc, pm, selection="roulette", crossover="multi_points")
-    >>>
-    >>> model6 = MultiGA(epoch, pop_size, pc, pm, selection="random", mutation="swap")
-    >>>
-    >>> model7 = MultiGA(epoch, pop_size, pc, pm, crossover="arithmetic", mutation="flip")
-
-    References
-    ~~~~~~~~~~
-    [1] Whitley, D., 1994. A genetic algorithm tutorial. Statistics and computing, 4(2), pp.65-85.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, pc=0.95, pm=0.025,
-                 selection="roulette", crossover="arithmetic", mutation="flip", k_way=0.2, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            pc (float): cross-over probability, default = 0.95
-            pm (float): mutation probability, default = 0.025
-            selection (str): Optional, can be ["roulette", "tournament", "random"], default = "tournament"
-            crossover (str): Optional, can be ["one_point", "multi_points", "uniform", "arithmetic"], default = "uniform"
-            mutation (str): Optional, can be ["flip", "swap"] for multipoints
-            k_way (float): Optional, set it when use "tournament" selection, default = 0.2
-        """
-        super().__init__(epoch, pop_size, pc, pm, **kwargs)
-        self.selection = self.validator.check_str("selection", selection, ["tournament", "random", "roulette"])
-        self.crossover = self.validator.check_str("crossover", crossover, ["one_point", "multi_points", "uniform", "arithmetic"])
-        self.mutation = self.validator.check_str("mutation", mutation, ["flip", "swap"])
-        self.k_way = self.validator.check_float("k_way", k_way, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "pc", "pm", "selection", "crossover", "mutation", "k_way"])
-
-    def mutation_process__(self, child):
-        """
-        + https://www.tutorialspoint.com/genetic_algorithms/genetic_algorithms_mutation.htm
-        + Mutated on the whole vector is effected by parameter: pm
-            + flip --> (default in this case) should set the pm small such as: [0.01 -> 0.2]
-            + swap --> should set the pm small such as: [0.01 -> 0.2]
-
-        Args:
-            child (np.array): The position of the child
-
-        Returns:
-            np.array: The mutated vector of the child
-        """
-        if self.mutation == "swap":
-            for idx in range(self.problem.n_dims):
-                idx_swap = np.random.choice(list(set(range(0, self.problem.n_dims)) - {idx}))
-                child[idx], child[idx_swap] = child[idx_swap], child[idx]
-                return child
-        else:       # "flip"
-            mutation_child = self.generate_position(self.problem.lb, self.problem.ub)
-            flag_child = np.random.uniform(0, 1, self.problem.n_dims) < self.pm
-            return np.where(flag_child, mutation_child, child)
-
-
-class EliteMultiGA(MultiGA):
-    """
-    The developed elite multipoints-mutation version of: Genetic Algorithm (GA)
-
-    Links:
-        1. https://www.baeldung.com/cs/elitism-in-evolutionary-algorithms
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + pc (float): [0.7, 0.95], cross-over probability, default = 0.95
-        + pm (float): [0.01, 0.2], mutation probability, default = 0.025
-        + selection (str): Optional, can be ["roulette", "tournament", "random"], default = "tournament"
-        + k_way (float): Optional, set it when use "tournament" selection, default = 0.2
-        + crossover (str): Optional, can be ["one_point", "multi_points", "uniform", "arithmetic"], default = "uniform"
-        + mutation (str): Optional, can be ["flip", "swap"] for multipoints
-        + elite_best (float/int): Optional, can be float (percentage of the best in elite group), or int (the number of best elite), default = 0.1
-        + elite_worst (float/int): Opttional, can be float (percentage of the worst in elite group), or int (the number of worst elite), default = 0.3
-        + strategy (int): Optional, can be 0 or 1. If = 0, the selection is select parents from (elite_worst + non_elite_group).
-            Else, the selection will select dad from elite_worst and mom from non_elite_group.
-        + pop_size = elite_group (elite_best + elite_worst) + non_elite_group
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.evolutionary_based.GA import MultiGA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> pc = 0.9
-    >>> pm = 0.05
-    >>> selection = "roulette"
-    >>> crossover = "uniform"
-    >>> mutation = "swap"
-    >>> model1 = MultiGA(epoch, pop_size, pc, pm, selection, crossover, mutation)
-    >>> best_position, best_fitness = model1.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    >>>
-    >>> model2 = MultiGA(epoch, pop_size, pc, pm, selection="tournament", k_way=0.4, crossover="multi_points")
-
-    References
-    ~~~~~~~~~~
-    [1] Whitley, D., 1994. A genetic algorithm tutorial. Statistics and computing, 4(2), pp.65-85.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, pc=0.95, pm=0.8, selection="roulette",
-                 crossover="uniform", mutation="swap", k_way=0.2,
-                 elite_best=0.1, elite_worst=0.3, strategy=0, **kwargs):
-        super().__init__(epoch, pop_size, pc, pm, selection, crossover, mutation, k_way, **kwargs)
-        self.elite_best = self.validator.check_is_int_and_float("elite_best", elite_best, [1, int(self.pop_size / 2) - 1], (0, 0.5))
-        self.n_elite_best = int(self.elite_best * self.pop_size) if self.elite_best < 1 else self.elite_best
-        if self.n_elite_best < 1:
-            self.n_elite_best = 1
-
-        self.elite_worst = self.validator.check_is_int_and_float("elite_worst", elite_worst, [1, int(self.pop_size / 2) - 1], (0, 0.5))
-        self.n_elite_worst = int(self.elite_worst * self.pop_size) if self.elite_worst < 1 else self.elite_worst
-        if self.n_elite_worst < 1:
-            self.n_elite_worst = 1
-
-        self.strategy = self.validator.check_int("strategy", strategy, [0, 1])
-        self.set_parameters(["epoch", "pop_size", "pc", "pm", "selection", "crossover", "mutation", "k_way",
-                             "elite_best", "elite_worst", "strategy"])
-        self.sort_flag = True
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = cp.deepcopy(self.pop[:self.n_elite_best])
-
-        if self.strategy == 0:
-            pop_old = cp.deepcopy(self.pop[self.n_elite_best:])
-            for idx in range(self.n_elite_best, self.pop_size):
-                ### Selection
-                child1, child2 = self.selection_process_00__(pop_old)
-                ### Crossover
-                if np.random.uniform() < self.pc:
-                    child1, child2 = self.crossover_process__(child1, child2)
-                child = child1 if np.random.random() <= 0.5 else child2
-                ### Mutation
-                child = self.mutation_process__(child)
-                ### Survivor Selection
-                pos_new = self.amend_position(child, self.problem.lb, self.problem.ub)
-                pop_new.append([pos_new, None])
-                if self.mode not in self.AVAILABLE_MODES:
-                    pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-            self.pop = self.update_target_wrapper_population(pop_new)
-        else:
-            pop_dad = cp.deepcopy(self.pop[self.n_elite_best:self.n_elite_best+self.n_elite_worst])
-            pop_mom = cp.deepcopy(self.pop[self.n_elite_best+self.n_elite_worst:])
-            for idx in range(self.n_elite_best, self.pop_size):
-                ### Selection
-                child1, child2 = self.selection_process_01__(pop_dad, pop_mom)
-                ### Crossover
-                if np.random.uniform() < self.pc:
-                    child1, child2 = self.crossover_process__(child1, child2)
-                child = child1 if np.random.random() <= 0.5 else child2
-                ### Mutation
-                child = self.mutation_process__(child)
-                ### Survivor Selection
-                pos_new = self.amend_position(child, self.problem.lb, self.problem.ub)
-                pop_new.append([pos_new, None])
-                if self.mode not in self.AVAILABLE_MODES:
-                    pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-            self.pop = self.update_target_wrapper_population(pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 09:33, 16/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+import copy as cp
+
+
+class BaseGA(Optimizer):
+    """
+    The original version of: Genetic Algorithm (GA)
+
+    Links:
+        1. https://blog.sicara.com/getting-started-genetic-algorithms-python-tutorial-81ffa1dd72f9
+        2. https://www.tutorialspoint.com/genetic_algorithms/genetic_algorithms_quick_guide.htm
+        3. https://www.analyticsvidhya.com/blog/2017/07/introduction-to-genetic-algorithm/
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + pc (float): [0.7, 0.95], cross-over probability, default = 0.95
+        + pm (float): [0.01, 0.2], mutation probability, default = 0.025
+        + selection (str): Optional, can be ["roulette", "tournament", "random"], default = "tournament"
+        + k_way (float): Optional, set it when use "tournament" selection, default = 0.2
+        + crossover (str): Optional, can be ["one_point", "multi_points", "uniform", "arithmetic"], default = "uniform"
+        + mutation_multipoints (bool): Optional, True or False, effect on mutation process, default = True
+        + mutation (str): Optional, can be ["flip", "swap"] for multipoints and can be ["flip", "swap", "scramble", "inversion"] for one-point
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.evolutionary_based.GA import BaseGA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> pc = 0.9
+    >>> pm = 0.05
+    >>> model1 = BaseGA(epoch, pop_size, pc, pm)
+    >>> best_position, best_fitness = model1.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    >>>
+    >>> model2 = BaseGA(epoch, pop_size, pc, pm, selection="tournament", k_way=0.4, crossover="multi_points")
+    >>>
+    >>> model3 = BaseGA(epoch, pop_size, pc, pm, crossover="one_point", mutation="scramble")
+    >>>
+    >>> model4 = BaseGA(epoch, pop_size, pc, pm, crossover="arithmetic", mutation_multipoints=True, mutation="swap")
+    >>>
+    >>> model5 = BaseGA(epoch, pop_size, pc, pm, selection="roulette", crossover="multi_points")
+    >>>
+    >>> model6 = BaseGA(epoch, pop_size, pc, pm, selection="random", mutation="inversion")
+    >>>
+    >>> model7 = BaseGA(epoch, pop_size, pc, pm, crossover="arithmetic", mutation="flip")
+
+    References
+    ~~~~~~~~~~
+    [1] Whitley, D., 1994. A genetic algorithm tutorial. Statistics and computing, 4(2), pp.65-85.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, pc=0.95, pm=0.025, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            pc (float): cross-over probability, default = 0.95
+            pm (float): mutation probability, default = 0.025
+            selection (str): Optional, can be ["roulette", "tournament", "random"], default = "tournament"
+            k_way (float): Optional, set it when use "tournament" selection, default = 0.2
+            crossover (str): Optional, can be ["one_point", "multi_points", "uniform", "arithmetic"], default = "uniform"
+            mutation_multipoints (bool): Optional, True or False, effect on mutation process, default = False
+            mutation (str): Optional, can be ["flip", "swap"] for multipoints and can be ["flip", "swap", "scramble", "inversion"] for one-point, default="flip"
+        """
+        super().__init__(**kwargs)
+
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.pc = self.validator.check_float("pc", pc, (0, 1.0))
+        self.pm = self.validator.check_float("pm", pm, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "pc", "pm"])
+        self.sort_flag = False
+        self.selection = "tournament"
+        self.k_way = 0.2
+        self.crossover = "uniform"
+        self.mutation = "flip"
+        self.mutation_multipoints = True
+
+        if "selection" in kwargs:
+            self.selection = self.validator.check_str("selection", kwargs["selection"], ["tournament", "random", "roulette"])
+        if "k_way" in kwargs:
+            self.k_way = self.validator.check_float("k_way", kwargs["k_way"], (0, 1.0))
+        if "crossover" in kwargs:
+            self.crossover = self.validator.check_str("crossover", kwargs["crossover"], ["one_point", "multi_points", "uniform", "arithmetic"])
+        if "mutation_multipoints" in kwargs:
+            self.mutation_multipoints = self.validator.check_bool("mutation_multipoints", kwargs["mutation_multipoints"])
+        if self.mutation_multipoints:
+            if "mutation" in kwargs:
+                self.mutation = self.validator.check_str("mutation", kwargs["mutation"], ["flip", "swap"])
+        else:
+            if "mutation" in kwargs:
+                self.mutation = self.validator.check_str("mutation", kwargs["mutation"], ["flip", "swap", "scramble", "inversion"])
+
+    def selection_process__(self, list_fitness):
+        """
+        Notes
+        ~~~~~
+        + https://www.tutorialspoint.com/genetic_algorithms/genetic_algorithms_parent_selection.htm
+        + Default selection strategy is Tournament with k% = 0.2.
+        + Other strategy like "roulette" and "random" can be selected via Optional parameter "selection"
+
+        Args:
+            list_fitness (np.array): list of fitness values.
+
+        Returns:
+            list: The position of dad and mom
+        """
+        if self.selection == "roulette":
+            id_c1 = self.get_index_roulette_wheel_selection(list_fitness)
+            id_c2 = self.get_index_roulette_wheel_selection(list_fitness)
+        elif self.selection == "random":
+            id_c1, id_c2 = np.random.choice(range(self.pop_size), 2, replace=False)
+        else:   ## tournament
+            id_c1, id_c2 = self.get_index_kway_tournament_selection(self.pop, k_way=self.k_way, output=2)
+        return self.pop[id_c1][self.ID_POS], self.pop[id_c2][self.ID_POS]
+
+    def selection_process_00__(self, pop_selected):
+        """
+        Notes
+        ~~~~~
+        + https://www.tutorialspoint.com/genetic_algorithms/genetic_algorithms_parent_selection.htm
+        + Default selection strategy is Tournament with k% = 0.2.
+        + Other strategy like "roulette" and "random" can be selected via Optional parameter "selection"
+
+        Args:
+            pop_selected (np.array): a population that will be selected
+
+        Returns:
+            list: The position of dad and mom
+        """
+        if self.selection == "roulette":
+            list_fitness = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in pop_selected])
+            id_c1 = self.get_index_roulette_wheel_selection(list_fitness)
+            id_c2 = self.get_index_roulette_wheel_selection(list_fitness)
+        elif self.selection == "random":
+            id_c1, id_c2 = np.random.choice(range(len(pop_selected)), 2, replace=False)
+        else:   ## tournament
+            id_c1, id_c2 = self.get_index_kway_tournament_selection(pop_selected, k_way=self.k_way, output=2)
+        return pop_selected[id_c1][self.ID_POS], pop_selected[id_c2][self.ID_POS]
+
+    def selection_process_01__(self, pop_dad, pop_mom):
+        """
+        Notes
+        ~~~~~
+        + https://www.tutorialspoint.com/genetic_algorithms/genetic_algorithms_parent_selection.htm
+        + Default selection strategy is Tournament with k% = 0.2.
+        + Other strategy like "roulette" and "random" can be selected via Optional parameter "selection"
+
+        Returns:
+            list: The position of dad and mom
+        """
+        if self.selection == "roulette":
+            list_fit_dad = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in pop_dad])
+            list_fit_mom = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in pop_mom])
+            id_c1 = self.get_index_roulette_wheel_selection(list_fit_dad)
+            id_c2 = self.get_index_roulette_wheel_selection(list_fit_mom)
+        elif self.selection == "random":
+            id_c1 = np.random.choice(range(len(pop_dad)))
+            id_c2 = np.random.choice(range(len(pop_mom)))
+        else:   ## tournament
+            id_c1 = self.get_index_kway_tournament_selection(pop_dad, k_way=self.k_way, output=1)[0]
+            id_c2 = self.get_index_kway_tournament_selection(pop_mom, k_way=self.k_way, output=1)[0]
+        return pop_dad[id_c1][self.ID_POS], pop_mom[id_c2][self.ID_POS]
+
+    def crossover_process__(self, dad, mom):
+        """
+        Notes
+        ~~~~~
+        + https://www.tutorialspoint.com/genetic_algorithms/genetic_algorithms_crossover.htm
+        + Default crossover strategy is "uniform"
+        + Other strategy like "arithmetic", "one_point", "multi_points" can be selected via parameter: crossover
+
+        Args:
+            dad (np.array): The position of dad
+            mom (np.array): The position of mom
+
+        Returns:
+            list: The position of child 1 and child 2
+        """
+        if self.crossover == "arithmetic":
+            w1, w2 = self.crossover_arithmetic(dad, mom)
+        elif self.crossover == "one_point":
+            cut = np.random.randint(1, self.problem.n_dims-1)
+            w1 = np.concatenate([ dad[:cut], mom[cut:] ])
+            w2 = np.concatenate([ mom[:cut], dad[cut:] ])
+        elif self.crossover == "multi_points":
+            idxs = np.random.choice(range(1, self.problem.n_dims-1), 2, replace=False)
+            cut1, cut2 = np.min(idxs), np.max(idxs)
+            w1 = np.concatenate([ dad[:cut1], mom[cut1:cut2], dad[cut2:] ])
+            w2 = np.concatenate([ mom[:cut1], dad[cut1:cut2], mom[cut2:] ])
+        else:           # uniform
+            flip = np.random.randint(0, 2, self.problem.n_dims)
+            w1 = dad * flip + mom * (1 - flip)
+            w2 = mom * flip + dad * (1 - flip)
+        return w1, w2
+
+    def mutation_process__(self, child):
+        """
+        Notes
+        ~~~~~
+        + https://www.tutorialspoint.com/genetic_algorithms/genetic_algorithms_mutation.htm
+        + There are 2 strategies that effects by the mutation probability: Mutated on single point or the whole vector.
+            + Multiple points (whole vector) has 2 strategies selected via parameter: mutation
+                + flip --> (default in this case) should set the pm small such as: [0.01 -> 0.2]
+                + swap --> should set the pm small such as: [0.01 -> 0.2]
+            + Single point has 4 strategies:
+                + flip --> should set the pm large such as: [0.5 -> 0.9]
+                + swap --> same as flip: pm in range [0.5 -> 0.9]
+                + scramble --> should set the pm small enough such as: [0.4 -> 0.6]
+                + inversion --> like scramble [0.4 -> 0.6]
+
+        Args:
+            child (np.array): The position of the child
+
+        Returns:
+            np.array: The mutated vector of the child
+        """
+
+        if self.mutation_multipoints:
+            if self.mutation == "swap":
+                for idx in range(self.problem.n_dims):
+                    idx_swap = np.random.choice(list(set(range(0, self.problem.n_dims)) - {idx}))
+                    child[idx], child[idx_swap] = child[idx_swap], child[idx]
+                    return child
+            else:       # "flip"
+                mutation_child = self.generate_position(self.problem.lb, self.problem.ub)
+                flag_child = np.random.uniform(0, 1, self.problem.n_dims) < self.pm
+                return np.where(flag_child, mutation_child, child)
+        else:
+            if self.mutation == "swap":
+                idx1, idx2 = np.random.choice(range(0, self.problem.n_dims), 2, replace=False)
+                child[idx1], child[idx2] = child[idx2], child[idx1]
+                return child
+            elif self.mutation == "inversion":
+                cut1, cut2 = np.random.choice(range(0, self.problem.n_dims), 2, replace=False)
+                temp = child[cut1:cut2]
+                temp = temp[::-1]
+                child[cut1:cut2] = temp
+                return child
+            elif self.mutation == "scramble":
+                cut1, cut2 = np.random.choice(range(0, self.problem.n_dims), 2, replace=False)
+                temp = child[cut1:cut2]
+                np.random.shuffle(temp)
+                child[cut1:cut2] = temp
+                return child
+            else:   # "flip"
+                idx = np.random.randint(0, self.problem.n_dims)
+                child[idx] = np.random.uniform(self.problem.lb[idx], self.problem.ub[idx])
+                return child
+
+    def survivor_process__(self, pop, pop_child):
+        """
+        The current survivor process is select the worst solution out of k-way solutions (tournament selection) and
+        compare with child solutions. The better solution will be kept for the next generation.
+
+        Args:
+            pop: The old population
+            pop_child: The new population
+
+        Returns:
+            The new population
+        """
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            id_child = self.get_index_kway_tournament_selection(pop, k_way=0.1, output=1, reverse=True)[0]
+            pop_new.append(self.get_better_solution(pop_child[idx], pop[id_child]))
+        return pop_new
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        list_fitness = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in self.pop])
+        pop_new = []
+        for i in range(0, int(self.pop_size/2)):
+            ### Selection
+            child1, child2 = self.selection_process__(list_fitness)
+
+            ### Crossover
+            if np.random.uniform() < self.pc:
+                child1, child2 = self.crossover_process__(child1, child2)
+
+            ### Mutation
+            child1 = self.mutation_process__(child1)
+            child2 = self.mutation_process__(child2)
+
+            pop_new.append([self.amend_position(child1, self.problem.lb, self.problem.ub), None])
+            pop_new.append([self.amend_position(child2, self.problem.lb, self.problem.ub), None])
+
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-2][self.ID_TAR] = self.get_target_wrapper(child1)
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(child2)
+        ### Survivor Selection
+        pop_new = self.update_target_wrapper_population(pop_new)
+        self.pop = self.survivor_process__(self.pop, pop_new)
+
+
+class SingleGA(BaseGA):
+    """
+    The developed single-point mutation of: Genetic Algorithm (GA)
+
+    Links:
+        1. https://blog.sicara.com/getting-started-genetic-algorithms-python-tutorial-81ffa1dd72f9
+        2. https://www.tutorialspoint.com/genetic_algorithms/genetic_algorithms_quick_guide.htm
+        3. https://www.analyticsvidhya.com/blog/2017/07/introduction-to-genetic-algorithm/
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + pc (float): [0.7, 0.95], cross-over probability, default = 0.95
+        + pm (float): [0.01, 0.2], mutation probability, default = 0.025
+        + selection (str): Optional, can be ["roulette", "tournament", "random"], default = "tournament"
+        + crossover (str): Optional, can be ["one_point", "multi_points", "uniform", "arithmetic"], default = "uniform"
+        + mutation (str): Optional, can be ["flip", "swap", "scramble", "inversion"] for one-point
+        + k_way (float): Optional, set it when use "tournament" selection, default = 0.2
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.evolutionary_based.GA import SingleGA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> pc = 0.9
+    >>> pm = 0.8
+    >>> selection = "roulette"
+    >>> crossover = "uniform"
+    >>> mutation = "swap"
+    >>> model1 = SingleGA(epoch, pop_size, pc, pm, selection, crossover, mutation)
+    >>> best_position, best_fitness = model1.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    >>>
+    >>> model2 = SingleGA(epoch, pop_size, pc, pm, selection="tournament", k_way=0.4, crossover="multi_points")
+    >>>
+    >>> model3 = SingleGA(epoch, pop_size, pc, pm, crossover="one_point", mutation="scramble")
+    >>>
+    >>> model4 = SingleGA(epoch, pop_size, pc, pm, crossover="arithmetic", mutation="swap")
+    >>>
+    >>> model5 = SingleGA(epoch, pop_size, pc, pm, selection="roulette", crossover="multi_points")
+    >>>
+    >>> model6 = SingleGA(epoch, pop_size, pc, pm, selection="random", mutation="inversion")
+    >>>
+    >>> model7 = SingleGA(epoch, pop_size, pc, pm, crossover="arithmetic", mutation="flip")
+
+    References
+    ~~~~~~~~~~
+    [1] Whitley, D., 1994. A genetic algorithm tutorial. Statistics and computing, 4(2), pp.65-85.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, pc=0.95, pm=0.8, selection="roulette",
+                 crossover="uniform", mutation="swap", k_way=0.2, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            pc (float): cross-over probability, default = 0.95
+            pm (float): mutation probability, default = 0.8
+            selection (str): Optional, can be ["roulette", "tournament", "random"], default = "tournament"
+            crossover (str): Optional, can be ["one_point", "multi_points", "uniform", "arithmetic"], default = "uniform"
+            mutation (str): Optional, can be ["flip", "swap", "scramble", "inversion"], default="flip"
+            k_way (float): Optional, set it when use "tournament" selection, default = 0.2
+        """
+        super().__init__(epoch, pop_size, pc, pm, **kwargs)
+        self.selection = self.validator.check_str("selection", selection, ["tournament", "random", "roulette"])
+        self.crossover = self.validator.check_str("crossover", crossover, ["one_point", "multi_points", "uniform", "arithmetic"])
+        self.mutation = self.validator.check_str("mutation", mutation, ["flip", "swap", "scramble", "inversion"])
+        self.k_way = self.validator.check_float("k_way", k_way, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "pc", "pm", "selection", "crossover", "mutation", "k_way"])
+        self.sort_flag = False
+
+    def mutation_process__(self, child):
+        """
+        + https://www.tutorialspoint.com/genetic_algorithms/genetic_algorithms_mutation.htm
+        + The mutation process is effected by parameter: pm
+            + flip --> should set the pm large such as: [0.5 -> 0.9]
+            + swap --> same as flip: pm in range [0.5 -> 0.9]
+            + scramble --> should set the pm small enough such as: [0.4 -> 0.6]
+            + inversion --> like scramble [0.4 -> 0.6]
+
+        Args:
+            child (np.array): The position of the child
+
+        Returns:
+            np.array: The mutated vector of the child
+        """
+        if self.mutation == "swap":
+            idx1, idx2 = np.random.choice(range(0, self.problem.n_dims), 2, replace=False)
+            child[idx1], child[idx2] = child[idx2], child[idx1]
+            return child
+        elif self.mutation == "inversion":
+            cut1, cut2 = np.random.choice(range(0, self.problem.n_dims), 2, replace=False)
+            temp = child[cut1:cut2]
+            temp = temp[::-1]
+            child[cut1:cut2] = temp
+            return child
+        elif self.mutation == "scramble":
+            cut1, cut2 = np.random.choice(range(0, self.problem.n_dims), 2, replace=False)
+            temp = child[cut1:cut2]
+            np.random.shuffle(temp)
+            child[cut1:cut2] = temp
+            return child
+        else:   # "flip"
+            idx = np.random.randint(0, self.problem.n_dims)
+            child[idx] = np.random.uniform(self.problem.lb[idx], self.problem.ub[idx])
+            return child
+
+
+class EliteSingleGA(SingleGA):
+    """
+    The developed elite single-point mutation of: Genetic Algorithm (GA)
+
+    Links:
+        1. https://www.baeldung.com/cs/elitism-in-evolutionary-algorithms
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + pc (float): [0.7, 0.95], cross-over probability, default = 0.95
+        + pm (float): [0.01, 0.2], mutation probability, default = 0.025
+        + selection (str): Optional, can be ["roulette", "tournament", "random"], default = "tournament"
+        + crossover (str): Optional, can be ["one_point", "multi_points", "uniform", "arithmetic"], default = "uniform"
+        + mutation (str): Optional, can be ["flip", "swap", "scramble", "inversion"] for one-point
+        + k_way (float): Optional, set it when use "tournament" selection, default = 0.2
+        + elite_best (float/int): Optional, can be float (percentage of the best in elite group), or int (the number of best elite), default = 0.1
+        + elite_worst (float/int): Opttional, can be float (percentage of the worst in elite group), or int (the number of worst elite), default = 0.3
+        + strategy (int): Optional, can be 0 or 1. If = 0, the selection is select parents from (elite_worst + non_elite_group).
+            Else, the selection will select dad from elite_worst and mom from non_elite_group.
+        + pop_size = elite_group (elite_best + elite_worst) + non_elite_group
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.evolutionary_based.GA import EliteSingleGA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> pc = 0.9
+    >>> pm = 0.8
+    >>> selection = "roulette"
+    >>> crossover = "uniform"
+    >>> mutation = "swap"
+    >>> elite_best = 0.1
+    >>> elite_worst = 0.3
+    >>> strategy = 0
+    >>> model1 = EliteSingleGA(epoch, pop_size, pc, pm, selection, crossover, mutation, elite_best, elite_worst, strategy)
+    >>> best_position, best_fitness = model1.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    >>>
+    >>> model2 = EliteSingleGA(epoch, pop_size, pc, pm, selection="tournament", k_way=0.4, crossover="multi_points")
+    >>>
+    >>> model3 = EliteSingleGA(epoch, pop_size, pc, pm, crossover="one_point", mutation="scramble")
+    >>>
+    >>> model4 = EliteSingleGA(epoch, pop_size, pc, pm, crossover="arithmetic", mutation="swap")
+    >>>
+    >>> model5 = EliteSingleGA(epoch, pop_size, pc, pm, selection="roulette", crossover="multi_points")
+    >>>
+    >>> model6 = EliteSingleGA(epoch, pop_size, pc, pm, selection="random", mutation="inversion")
+    >>>
+    >>> model7 = EliteSingleGA(epoch, pop_size, pc, pm, crossover="arithmetic", mutation="flip")
+
+    References
+    ~~~~~~~~~~
+    [1] Whitley, D., 1994. A genetic algorithm tutorial. Statistics and computing, 4(2), pp.65-85.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, pc=0.95, pm=0.8, selection="roulette",
+                 crossover="uniform", mutation="swap", k_way=0.2,
+                 elite_best=0.1, elite_worst=0.3, strategy=0, **kwargs):
+        super().__init__(epoch, pop_size, pc, pm, selection, crossover, mutation, k_way, **kwargs)
+        self.elite_best = self.validator.check_is_int_and_float("elite_best", elite_best, [1, int(self.pop_size / 2)-1], (0, 0.5))
+        self.n_elite_best = int(self.elite_best * self.pop_size) if self.elite_best < 1 else self.elite_best
+        if self.n_elite_best < 1:
+            self.n_elite_best = 1
+
+        self.elite_worst = self.validator.check_is_int_and_float("elite_worst", elite_worst, [1, int(self.pop_size / 2)-1], (0, 0.5))
+        self.n_elite_worst = int(self.elite_worst * self.pop_size) if self.elite_worst < 1 else self.elite_worst
+        if self.n_elite_worst < 1:
+            self.n_elite_worst = 1
+
+        self.strategy = self.validator.check_int("strategy", strategy, [0, 1])
+        self.set_parameters(["epoch", "pop_size", "pc", "pm", "selection", "crossover", "mutation", "k_way",
+                             "elite_best", "elite_worst", "strategy"])
+        self.sort_flag = True
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = cp.deepcopy(self.pop[:self.n_elite_best])
+
+        if self.strategy == 0:
+            pop_old = cp.deepcopy(self.pop[self.n_elite_best:])
+            for idx in range(self.n_elite_best, self.pop_size):
+                ### Selection
+                child1, child2 = self.selection_process_00__(pop_old)
+                ### Crossover
+                if np.random.uniform() < self.pc:
+                    child1, child2 = self.crossover_process__(child1, child2)
+                child = child1 if np.random.random() <= 0.5 else child2
+                ### Mutation
+                child = self.mutation_process__(child)
+                ### Survivor Selection
+                pos_new = self.amend_position(child, self.problem.lb, self.problem.ub)
+                pop_new.append([pos_new, None])
+                if self.mode not in self.AVAILABLE_MODES:
+                    pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+            self.pop = self.update_target_wrapper_population(pop_new)
+        else:
+            pop_dad = cp.deepcopy(self.pop[self.n_elite_best:self.n_elite_best+self.n_elite_worst])
+            pop_mom = cp.deepcopy(self.pop[self.n_elite_best+self.n_elite_worst:])
+            for idx in range(self.n_elite_best, self.pop_size):
+                ### Selection
+                child1, child2 = self.selection_process_01__(pop_dad, pop_mom)
+                ### Crossover
+                if np.random.uniform() < self.pc:
+                    child1, child2 = self.crossover_process__(child1, child2)
+                child = child1 if np.random.random() <= 0.5 else child2
+                ### Mutation
+                child = self.mutation_process__(child)
+                ### Survivor Selection
+                pos_new = self.amend_position(child, self.problem.lb, self.problem.ub)
+                pop_new.append([pos_new, None])
+                if self.mode not in self.AVAILABLE_MODES:
+                    pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+            self.pop = self.update_target_wrapper_population(pop_new)
+
+
+class MultiGA(BaseGA):
+    """
+    The developed multipoints-mutation version of: Genetic Algorithm (GA)
+
+    Links:
+        1. https://blog.sicara.com/getting-started-genetic-algorithms-python-tutorial-81ffa1dd72f9
+        2. https://www.tutorialspoint.com/genetic_algorithms/genetic_algorithms_quick_guide.htm
+        3. https://www.analyticsvidhya.com/blog/2017/07/introduction-to-genetic-algorithm/
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + pc (float): [0.7, 0.95], cross-over probability, default = 0.95
+        + pm (float): [0.01, 0.2], mutation probability, default = 0.025
+        + selection (str): Optional, can be ["roulette", "tournament", "random"], default = "tournament"
+        + k_way (float): Optional, set it when use "tournament" selection, default = 0.2
+        + crossover (str): Optional, can be ["one_point", "multi_points", "uniform", "arithmetic"], default = "uniform"
+        + mutation (str): Optional, can be ["flip", "swap"] for multipoints
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.evolutionary_based.GA import MultiGA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> pc = 0.9
+    >>> pm = 0.05
+    >>> selection = "roulette"
+    >>> crossover = "uniform"
+    >>> mutation = "swap"
+    >>> model1 = MultiGA(epoch, pop_size, pc, pm, selection, crossover, mutation)
+    >>> best_position, best_fitness = model1.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    >>>
+    >>> model2 = MultiGA(epoch, pop_size, pc, pm, selection="tournament", k_way=0.4, crossover="multi_points")
+    >>>
+    >>> model3 = MultiGA(epoch, pop_size, pc, pm, crossover="one_point", mutation="flip")
+    >>>
+    >>> model4 = MultiGA(epoch, pop_size, pc, pm, crossover="arithmetic", mutation_multipoints=True, mutation="swap")
+    >>>
+    >>> model5 = MultiGA(epoch, pop_size, pc, pm, selection="roulette", crossover="multi_points")
+    >>>
+    >>> model6 = MultiGA(epoch, pop_size, pc, pm, selection="random", mutation="swap")
+    >>>
+    >>> model7 = MultiGA(epoch, pop_size, pc, pm, crossover="arithmetic", mutation="flip")
+
+    References
+    ~~~~~~~~~~
+    [1] Whitley, D., 1994. A genetic algorithm tutorial. Statistics and computing, 4(2), pp.65-85.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, pc=0.95, pm=0.025,
+                 selection="roulette", crossover="arithmetic", mutation="flip", k_way=0.2, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            pc (float): cross-over probability, default = 0.95
+            pm (float): mutation probability, default = 0.025
+            selection (str): Optional, can be ["roulette", "tournament", "random"], default = "tournament"
+            crossover (str): Optional, can be ["one_point", "multi_points", "uniform", "arithmetic"], default = "uniform"
+            mutation (str): Optional, can be ["flip", "swap"] for multipoints
+            k_way (float): Optional, set it when use "tournament" selection, default = 0.2
+        """
+        super().__init__(epoch, pop_size, pc, pm, **kwargs)
+        self.selection = self.validator.check_str("selection", selection, ["tournament", "random", "roulette"])
+        self.crossover = self.validator.check_str("crossover", crossover, ["one_point", "multi_points", "uniform", "arithmetic"])
+        self.mutation = self.validator.check_str("mutation", mutation, ["flip", "swap"])
+        self.k_way = self.validator.check_float("k_way", k_way, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "pc", "pm", "selection", "crossover", "mutation", "k_way"])
+
+    def mutation_process__(self, child):
+        """
+        + https://www.tutorialspoint.com/genetic_algorithms/genetic_algorithms_mutation.htm
+        + Mutated on the whole vector is effected by parameter: pm
+            + flip --> (default in this case) should set the pm small such as: [0.01 -> 0.2]
+            + swap --> should set the pm small such as: [0.01 -> 0.2]
+
+        Args:
+            child (np.array): The position of the child
+
+        Returns:
+            np.array: The mutated vector of the child
+        """
+        if self.mutation == "swap":
+            for idx in range(self.problem.n_dims):
+                idx_swap = np.random.choice(list(set(range(0, self.problem.n_dims)) - {idx}))
+                child[idx], child[idx_swap] = child[idx_swap], child[idx]
+                return child
+        else:       # "flip"
+            mutation_child = self.generate_position(self.problem.lb, self.problem.ub)
+            flag_child = np.random.uniform(0, 1, self.problem.n_dims) < self.pm
+            return np.where(flag_child, mutation_child, child)
+
+
+class EliteMultiGA(MultiGA):
+    """
+    The developed elite multipoints-mutation version of: Genetic Algorithm (GA)
+
+    Links:
+        1. https://www.baeldung.com/cs/elitism-in-evolutionary-algorithms
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + pc (float): [0.7, 0.95], cross-over probability, default = 0.95
+        + pm (float): [0.01, 0.2], mutation probability, default = 0.025
+        + selection (str): Optional, can be ["roulette", "tournament", "random"], default = "tournament"
+        + k_way (float): Optional, set it when use "tournament" selection, default = 0.2
+        + crossover (str): Optional, can be ["one_point", "multi_points", "uniform", "arithmetic"], default = "uniform"
+        + mutation (str): Optional, can be ["flip", "swap"] for multipoints
+        + elite_best (float/int): Optional, can be float (percentage of the best in elite group), or int (the number of best elite), default = 0.1
+        + elite_worst (float/int): Opttional, can be float (percentage of the worst in elite group), or int (the number of worst elite), default = 0.3
+        + strategy (int): Optional, can be 0 or 1. If = 0, the selection is select parents from (elite_worst + non_elite_group).
+            Else, the selection will select dad from elite_worst and mom from non_elite_group.
+        + pop_size = elite_group (elite_best + elite_worst) + non_elite_group
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.evolutionary_based.GA import MultiGA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> pc = 0.9
+    >>> pm = 0.05
+    >>> selection = "roulette"
+    >>> crossover = "uniform"
+    >>> mutation = "swap"
+    >>> model1 = MultiGA(epoch, pop_size, pc, pm, selection, crossover, mutation)
+    >>> best_position, best_fitness = model1.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    >>>
+    >>> model2 = MultiGA(epoch, pop_size, pc, pm, selection="tournament", k_way=0.4, crossover="multi_points")
+
+    References
+    ~~~~~~~~~~
+    [1] Whitley, D., 1994. A genetic algorithm tutorial. Statistics and computing, 4(2), pp.65-85.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, pc=0.95, pm=0.8, selection="roulette",
+                 crossover="uniform", mutation="swap", k_way=0.2,
+                 elite_best=0.1, elite_worst=0.3, strategy=0, **kwargs):
+        super().__init__(epoch, pop_size, pc, pm, selection, crossover, mutation, k_way, **kwargs)
+        self.elite_best = self.validator.check_is_int_and_float("elite_best", elite_best, [1, int(self.pop_size / 2) - 1], (0, 0.5))
+        self.n_elite_best = int(self.elite_best * self.pop_size) if self.elite_best < 1 else self.elite_best
+        if self.n_elite_best < 1:
+            self.n_elite_best = 1
+
+        self.elite_worst = self.validator.check_is_int_and_float("elite_worst", elite_worst, [1, int(self.pop_size / 2) - 1], (0, 0.5))
+        self.n_elite_worst = int(self.elite_worst * self.pop_size) if self.elite_worst < 1 else self.elite_worst
+        if self.n_elite_worst < 1:
+            self.n_elite_worst = 1
+
+        self.strategy = self.validator.check_int("strategy", strategy, [0, 1])
+        self.set_parameters(["epoch", "pop_size", "pc", "pm", "selection", "crossover", "mutation", "k_way",
+                             "elite_best", "elite_worst", "strategy"])
+        self.sort_flag = True
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = cp.deepcopy(self.pop[:self.n_elite_best])
+
+        if self.strategy == 0:
+            pop_old = cp.deepcopy(self.pop[self.n_elite_best:])
+            for idx in range(self.n_elite_best, self.pop_size):
+                ### Selection
+                child1, child2 = self.selection_process_00__(pop_old)
+                ### Crossover
+                if np.random.uniform() < self.pc:
+                    child1, child2 = self.crossover_process__(child1, child2)
+                child = child1 if np.random.random() <= 0.5 else child2
+                ### Mutation
+                child = self.mutation_process__(child)
+                ### Survivor Selection
+                pos_new = self.amend_position(child, self.problem.lb, self.problem.ub)
+                pop_new.append([pos_new, None])
+                if self.mode not in self.AVAILABLE_MODES:
+                    pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+            self.pop = self.update_target_wrapper_population(pop_new)
+        else:
+            pop_dad = cp.deepcopy(self.pop[self.n_elite_best:self.n_elite_best+self.n_elite_worst])
+            pop_mom = cp.deepcopy(self.pop[self.n_elite_best+self.n_elite_worst:])
+            for idx in range(self.n_elite_best, self.pop_size):
+                ### Selection
+                child1, child2 = self.selection_process_01__(pop_dad, pop_mom)
+                ### Crossover
+                if np.random.uniform() < self.pc:
+                    child1, child2 = self.crossover_process__(child1, child2)
+                child = child1 if np.random.random() <= 0.5 else child2
+                ### Mutation
+                child = self.mutation_process__(child)
+                ### Survivor Selection
+                pos_new = self.amend_position(child, self.problem.lb, self.problem.ub)
+                pop_new.append([pos_new, None])
+                if self.mode not in self.AVAILABLE_MODES:
+                    pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+            self.pop = self.update_target_wrapper_population(pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/evolutionary_based/MA.py` & `mealpy-2.5.3a1/mealpy/evolutionary_based/MA.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,195 +1,195 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 14:22, 11/04/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalMA(Optimizer):
-    """
-    The original version of: Memetic Algorithm (MA)
-
-    Links:
-        1. https://www.cleveralgorithms.com/nature-inspired/physical/memetic_algorithm.html
-        2. https://github.com/clever-algorithms/CleverAlgorithms
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + pc (float): [0.7, 0.95], cross-over probability, default = 0.85
-        + pm (float): [0.05, 0.3], mutation probability, default = 0.15
-        + p_local (float): [0.3, 0.7], Probability of local search for each agent, default=0.5
-        + max_local_gens (int): [5, 25], number of local search agent will be created during local search mechanism, default=10
-        + bits_per_param (int): [2, 4, 8, 16], number of bits to decode a real number to 0-1 bitstring, default=4
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.evolutionary_based.MA import OriginalMA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> pc = 0.85
-    >>> pm = 0.15
-    >>> p_local = 0.5
-    >>> max_local_gens = 10
-    >>> bits_per_param = 4
-    >>> model = OriginalMA(epoch, pop_size, pc, pm, p_local, max_local_gens, bits_per_param)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Moscato, P., 1989. On evolution, search, optimization, genetic algorithms and martial arts:
-    Towards memetic algorithms. Caltech concurrent computation program, C3P Report, 826, p.1989.
-    """
-
-    ID_BIT = 2
-
-    def __init__(self, epoch=10000, pop_size=100, pc=0.85, pm=0.15,
-                 p_local=0.5, max_local_gens=10, bits_per_param=4, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            pc (float): cross-over probability, default = 0.85
-            pm (float): mutation probability, default = 0.15
-            p_local (float): Probability of local search for each agent, default=0.5
-            max_local_gens (int): Number of local search agent will be created during local search mechanism, default=10
-            bits_per_param (int): Number of bits to decode a real number to 0-1 bitstring, default=4
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.pc = self.validator.check_float("pc", pc, (0, 1.0))
-        self.pm = self.validator.check_float("pm", pm, (0, 1.0))
-        self.p_local = self.validator.check_float("p_local", p_local, (0, 1.0))
-        self.max_local_gens = self.validator.check_int("max_local_gens", max_local_gens, [2, int(pop_size/2)])
-        self.bits_per_param = self.validator.check_int("bits_per_param", bits_per_param, [2, 32])
-        self.set_parameters(["epoch", "pop_size", "pc", "pm", "p_local", "max_local_gens", "bits_per_param"])
-        self.sort_flag = True
-
-    def initialize_variables(self):
-        self.bits_total = self.problem.n_dims * self.bits_per_param
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        """
-        Overriding method in Optimizer class
-
-        Returns:
-            list: wrapper of solution with format [position, target, bitstring]
-        """
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        position = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(position)
-        bitstring = ''.join(["1" if np.random.uniform() < 0.5 else "0" for _ in range(0, self.bits_total)])
-        return [position, target, bitstring]
-
-    def decode_(self, bitstring=None):
-        """
-        Decode the random bitstring into real number
-
-        Args:
-            bitstring (str): "11000000100101000101010" - bits_per_param = 16, 32 bit for 2 variable. eg. x1 and x2
-
-        Returns:
-            list: list of real number (vector)
-        """
-        vector = np.ones(self.problem.n_dims)
-        for idx in range(0, self.problem.n_dims):
-            param = bitstring[idx * self.bits_per_param: (idx + 1) * self.bits_per_param]  # Select 16 bit every time
-            vector[idx] = self.problem.lb[idx] + ((self.problem.ub[idx] - self.problem.lb[idx]) / ((2.0 ** self.bits_per_param) - 1)) * int(param, 2)
-        return vector
-
-    def crossover__(self, dad=None, mom=None):
-        if np.random.uniform() >= self.pc:
-            temp = deepcopy([dad])
-            return temp[0]
-        else:
-            child = ""
-            for idx in range(0, self.bits_total):
-                if np.random.uniform() < 0.5:
-                    child += dad[idx]
-                else:
-                    child += mom[idx]
-            return child
-
-    def point_mutation__(self, bitstring=None):
-        child = ""
-        for bit in bitstring:
-            if np.random.uniform() < self.pc:
-                child += "0" if bit == "1" else "1"
-            else:
-                child += bit
-        return child
-
-    def bits_climber__(self, child=None):
-        current = deepcopy(child)
-        list_local = []
-        for idx in range(0, self.max_local_gens):
-            child = deepcopy(current)
-            bitstring_new = self.point_mutation__(child[self.ID_BIT])
-            pos_new = self.decode_(bitstring_new)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            list_local.append([pos_new, None, bitstring_new])
-            if self.mode not in self.AVAILABLE_MODES:
-                list_local[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        list_local = self.update_target_wrapper_population(list_local)
-        list_local.append(child)
-        _, best = self.get_global_best_solution(list_local)
-        return best
-
-    def create_child__(self, idx, pop_copy):
-        ancient = pop_copy[idx + 1] if idx % 2 == 0 else pop_copy[idx - 1]
-        if idx == self.pop_size - 1:
-            ancient = pop_copy[0]
-        bitstring_new = self.crossover__(pop_copy[idx][self.ID_BIT], ancient[self.ID_BIT])
-        bitstring_new = self.point_mutation__(bitstring_new)
-        pos_new = self.decode_(bitstring_new)
-        pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-        target = self.get_target_wrapper(pos_new)
-        return [pos_new, target, bitstring_new]
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        ## Binary tournament
-        children = []
-        for idx in range(0, self.pop_size):
-            idx_offspring = self.get_index_kway_tournament_selection(self.pop, k_way=2, output=1)[0]
-            children.append(deepcopy(self.pop[idx_offspring]))
-        pop = []
-        for idx in range(0, self.pop_size):
-            ancient = children[idx + 1] if idx % 2 == 0 else children[idx - 1]
-            if idx == self.pop_size - 1:
-                ancient = children[0]
-            bitstring_new = self.crossover__(children[idx][self.ID_BIT], ancient[self.ID_BIT])
-            bitstring_new = self.point_mutation__(bitstring_new)
-            pos_new = self.decode_(bitstring_new)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop.append([pos_new, None, bitstring_new])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        self.pop = self.update_target_wrapper_population(pop)
-
-        # Searching in local
-        for i in range(0, self.pop_size):
-            if np.random.rand() < self.p_local:
-                self.pop[i] = self.bits_climber__(pop[i])
+#!/usr/bin/env python
+# Created by "Thieu" at 14:22, 11/04/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalMA(Optimizer):
+    """
+    The original version of: Memetic Algorithm (MA)
+
+    Links:
+        1. https://www.cleveralgorithms.com/nature-inspired/physical/memetic_algorithm.html
+        2. https://github.com/clever-algorithms/CleverAlgorithms
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + pc (float): [0.7, 0.95], cross-over probability, default = 0.85
+        + pm (float): [0.05, 0.3], mutation probability, default = 0.15
+        + p_local (float): [0.3, 0.7], Probability of local search for each agent, default=0.5
+        + max_local_gens (int): [5, 25], number of local search agent will be created during local search mechanism, default=10
+        + bits_per_param (int): [2, 4, 8, 16], number of bits to decode a real number to 0-1 bitstring, default=4
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.evolutionary_based.MA import OriginalMA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> pc = 0.85
+    >>> pm = 0.15
+    >>> p_local = 0.5
+    >>> max_local_gens = 10
+    >>> bits_per_param = 4
+    >>> model = OriginalMA(epoch, pop_size, pc, pm, p_local, max_local_gens, bits_per_param)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Moscato, P., 1989. On evolution, search, optimization, genetic algorithms and martial arts:
+    Towards memetic algorithms. Caltech concurrent computation program, C3P Report, 826, p.1989.
+    """
+
+    ID_BIT = 2
+
+    def __init__(self, epoch=10000, pop_size=100, pc=0.85, pm=0.15,
+                 p_local=0.5, max_local_gens=10, bits_per_param=4, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            pc (float): cross-over probability, default = 0.85
+            pm (float): mutation probability, default = 0.15
+            p_local (float): Probability of local search for each agent, default=0.5
+            max_local_gens (int): Number of local search agent will be created during local search mechanism, default=10
+            bits_per_param (int): Number of bits to decode a real number to 0-1 bitstring, default=4
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.pc = self.validator.check_float("pc", pc, (0, 1.0))
+        self.pm = self.validator.check_float("pm", pm, (0, 1.0))
+        self.p_local = self.validator.check_float("p_local", p_local, (0, 1.0))
+        self.max_local_gens = self.validator.check_int("max_local_gens", max_local_gens, [2, int(pop_size/2)])
+        self.bits_per_param = self.validator.check_int("bits_per_param", bits_per_param, [2, 32])
+        self.set_parameters(["epoch", "pop_size", "pc", "pm", "p_local", "max_local_gens", "bits_per_param"])
+        self.sort_flag = True
+
+    def initialize_variables(self):
+        self.bits_total = self.problem.n_dims * self.bits_per_param
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        """
+        Overriding method in Optimizer class
+
+        Returns:
+            list: wrapper of solution with format [position, target, bitstring]
+        """
+        if pos is None:
+            pos = self.generate_position(lb, ub)
+        position = self.amend_position(pos, lb, ub)
+        target = self.get_target_wrapper(position)
+        bitstring = ''.join(["1" if np.random.uniform() < 0.5 else "0" for _ in range(0, self.bits_total)])
+        return [position, target, bitstring]
+
+    def decode_(self, bitstring=None):
+        """
+        Decode the random bitstring into real number
+
+        Args:
+            bitstring (str): "11000000100101000101010" - bits_per_param = 16, 32 bit for 2 variable. eg. x1 and x2
+
+        Returns:
+            list: list of real number (vector)
+        """
+        vector = np.ones(self.problem.n_dims)
+        for idx in range(0, self.problem.n_dims):
+            param = bitstring[idx * self.bits_per_param: (idx + 1) * self.bits_per_param]  # Select 16 bit every time
+            vector[idx] = self.problem.lb[idx] + ((self.problem.ub[idx] - self.problem.lb[idx]) / ((2.0 ** self.bits_per_param) - 1)) * int(param, 2)
+        return vector
+
+    def crossover__(self, dad=None, mom=None):
+        if np.random.uniform() >= self.pc:
+            temp = deepcopy([dad])
+            return temp[0]
+        else:
+            child = ""
+            for idx in range(0, self.bits_total):
+                if np.random.uniform() < 0.5:
+                    child += dad[idx]
+                else:
+                    child += mom[idx]
+            return child
+
+    def point_mutation__(self, bitstring=None):
+        child = ""
+        for bit in bitstring:
+            if np.random.uniform() < self.pc:
+                child += "0" if bit == "1" else "1"
+            else:
+                child += bit
+        return child
+
+    def bits_climber__(self, child=None):
+        current = deepcopy(child)
+        list_local = []
+        for idx in range(0, self.max_local_gens):
+            child = deepcopy(current)
+            bitstring_new = self.point_mutation__(child[self.ID_BIT])
+            pos_new = self.decode_(bitstring_new)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            list_local.append([pos_new, None, bitstring_new])
+            if self.mode not in self.AVAILABLE_MODES:
+                list_local[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        list_local = self.update_target_wrapper_population(list_local)
+        list_local.append(child)
+        _, best = self.get_global_best_solution(list_local)
+        return best
+
+    def create_child__(self, idx, pop_copy):
+        ancient = pop_copy[idx + 1] if idx % 2 == 0 else pop_copy[idx - 1]
+        if idx == self.pop_size - 1:
+            ancient = pop_copy[0]
+        bitstring_new = self.crossover__(pop_copy[idx][self.ID_BIT], ancient[self.ID_BIT])
+        bitstring_new = self.point_mutation__(bitstring_new)
+        pos_new = self.decode_(bitstring_new)
+        pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+        target = self.get_target_wrapper(pos_new)
+        return [pos_new, target, bitstring_new]
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        ## Binary tournament
+        children = []
+        for idx in range(0, self.pop_size):
+            idx_offspring = self.get_index_kway_tournament_selection(self.pop, k_way=2, output=1)[0]
+            children.append(deepcopy(self.pop[idx_offspring]))
+        pop = []
+        for idx in range(0, self.pop_size):
+            ancient = children[idx + 1] if idx % 2 == 0 else children[idx - 1]
+            if idx == self.pop_size - 1:
+                ancient = children[0]
+            bitstring_new = self.crossover__(children[idx][self.ID_BIT], ancient[self.ID_BIT])
+            bitstring_new = self.point_mutation__(bitstring_new)
+            pos_new = self.decode_(bitstring_new)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop.append([pos_new, None, bitstring_new])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        self.pop = self.update_target_wrapper_population(pop)
+
+        # Searching in local
+        for i in range(0, self.pop_size):
+            if np.random.rand() < self.p_local:
+                self.pop[i] = self.bits_climber__(pop[i])
```

### Comparing `mealpy-2.5.3/mealpy/human_based/BRO.py` & `mealpy-2.5.3a1/mealpy/human_based/BRO.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,231 +1,231 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 09:17, 09/11/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from scipy.spatial.distance import cdist
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class BaseBRO(Optimizer):
-    """
-    The developed version: Battle Royale Optimization (BRO)
-
-    Notes
-    ~~~~~
-    The flow of algorithm is changed. Thrid loop is removed
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + threshold (int): [2, 5], dead threshold, default=3
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.BRO import BaseBRO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> threshold = 3
-    >>> model = BaseBRO(epoch, pop_size, threshold)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    ID_DAM = 2
-
-    def __init__(self, epoch=10000, pop_size=100, threshold=3, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            threshold (int): dead threshold, default=3
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.threshold = self.validator.check_float("threshold", threshold, [1, 10])
-        self.set_parameters(["epoch", "pop_size", "threshold"])
-        self.support_parallel_modes = False
-        self.sort_flag = False
-
-    def initialize_variables(self):
-        shrink = np.ceil(np.log10(self.epoch))
-        self.dyn_delta = np.round(self.epoch / shrink)
-        self.problem.lb_updated = deepcopy(self.problem.lb)
-        self.problem.ub_updated = deepcopy(self.problem.ub)
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        """
-        Overriding method in Optimizer class
-
-        Returns:
-            list: wrapper of solution with format [position, target, damage]
-        """
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        position = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(position)
-        damage = 0
-        return [position, target, damage]
-
-    def get_idx_min__(self, data):
-        k_zero = np.count_nonzero(data == 0)
-        if k_zero == len(data):
-            return np.random.choice(range(0, k_zero))
-        ## 1st: Partition sorting, not good solution here.
-        # return np.argpartition(data, k_zero)[k_zero]
-        ## 2nd: Faster
-        return np.where(data == np.min(data[data != 0]))[0][0]
-
-    def find_idx_min_distance__(self, target_pos=None, pop=None):
-        list_pos = np.array([pop[idx][self.ID_POS] for idx in range(0, self.pop_size)])
-        target_pos = np.reshape(target_pos, (1, -1))
-        dist_list = cdist(list_pos, target_pos, 'euclidean')
-        dist_list = np.reshape(dist_list, (-1))
-        return self.get_idx_min__(dist_list)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        for i in range(self.pop_size):
-            # Compare ith soldier with nearest one (jth)
-            j = self.find_idx_min_distance__(self.pop[i][self.ID_POS], self.pop)
-            if self.compare_agent(self.pop[i], self.pop[j]):
-                ## Update Winner based on global best solution
-                pos_new = self.pop[i][self.ID_POS] + np.random.normal(0, 1) * \
-                          np.mean(np.array([self.pop[i][self.ID_POS], self.g_best[self.ID_POS]]), axis=0)
-                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                target = self.get_target_wrapper(pos_new)
-                dam_new = self.pop[i][self.ID_DAM] - 1  ## Substract damaged hurt -1 to go next battle
-                self.pop[i] = [pos_new, target, dam_new]
-                ## Update Loser
-                if self.pop[j][self.ID_DAM] < self.threshold:  ## If loser not dead yet, move it based on general
-                    pos_new = np.random.uniform() * (np.maximum(self.pop[j][self.ID_POS], self.g_best[self.ID_POS]) -
-                                                     np.minimum(self.pop[j][self.ID_POS], self.g_best[self.ID_POS])) + \
-                              np.maximum(self.pop[j][self.ID_POS], self.g_best[self.ID_POS])
-                    dam_new = self.pop[j][self.ID_DAM] + 1
-
-                    self.pop[j][self.ID_TAR] = self.get_target_wrapper(self.pop[j][self.ID_POS])
-                else:  ## Loser dead and respawn again
-                    pos_new = self.generate_position(self.problem.lb_updated, self.problem.ub_updated)
-                    dam_new = 0
-                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                target = self.get_target_wrapper(pos_new)
-                self.pop[j] = [pos_new, target, dam_new]
-            else:
-                ## Update Loser by following position of Winner
-                self.pop[i] = deepcopy(self.pop[j])
-                ## Update Winner by following position of General to protect the King and General
-                pos_new = self.pop[j][self.ID_POS] + np.random.uniform() * (self.g_best[self.ID_POS] - self.pop[j][self.ID_POS])
-                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                target = self.get_target_wrapper(pos_new)
-                dam_new = 0
-                self.pop[j] = [pos_new, target, dam_new]
-        if epoch >= self.dyn_delta:  # max_epoch = 1000 -> delta = 300, 450, >500,....
-            pos_list = np.array([self.pop[idx][self.ID_POS] for idx in range(0, self.pop_size)])
-            pos_std = np.std(pos_list, axis=0)
-            lb = self.g_best[self.ID_POS] - pos_std
-            ub = self.g_best[self.ID_POS] + pos_std
-            self.problem.lb_updated = np.clip(lb, self.problem.lb_updated, self.problem.ub_updated)
-            self.problem.ub_updated = np.clip(ub, self.problem.lb_updated, self.problem.ub_updated)
-            self.dyn_delta += np.round(self.dyn_delta / 2)
-
-
-class OriginalBRO(BaseBRO):
-    """
-    The original version of: Battle Royale Optimization (BRO)
-
-    Links:
-        1. https://doi.org/10.1007/s00521-020-05004-4
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + threshold (int): [2, 5], dead threshold, default=3
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.BRO import BaseBRO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> threshold = 3
-    >>> model = BaseBRO(epoch, pop_size, threshold)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Rahkar Farshi, T., 2021. Battle royale optimization algorithm. Neural Computing and Applications, 33(4), pp.1139-1157.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, threshold=3, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            threshold (int): dead threshold, default=3
-        """
-        super().__init__(epoch, pop_size, threshold, **kwargs)
-        self.support_parallel_modes = False
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        for i in range(self.pop_size):
-            # Compare ith soldier with nearest one (jth)
-            j = self.find_idx_min_distance__(self.pop[i][self.ID_POS], self.pop)
-            dam, vic = i, j  ## This error in the algorithm's flow in the paper, But in the matlab code, he changed.
-            if self.compare_agent(self.pop[i], self.pop[j]):
-                dam, vic = j, i  ## The mistake also here in the paper.
-            if self.pop[dam][self.ID_DAM] < self.threshold:
-                pos_new = np.random.uniform(0, 1, self.problem.n_dims) * \
-                          (np.maximum(self.pop[dam][self.ID_POS], self.g_best[self.ID_POS]) -
-                           np.minimum(self.pop[dam][self.ID_POS], self.g_best[self.ID_POS])) + \
-                          np.maximum(self.pop[dam][self.ID_POS], self.g_best[self.ID_POS])
-                self.pop[dam][self.ID_POS] = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                self.pop[dam][self.ID_TAR] = self.get_target_wrapper(self.pop[dam][self.ID_POS])
-                self.pop[dam][self.ID_DAM] += 1
-                self.pop[vic][self.ID_DAM] = 0
-            else:
-                self.pop[dam] = self.create_solution(self.problem.lb_updated, self.problem.ub_updated)
-        if epoch >= self.dyn_delta:
-            pos_list = np.array([self.pop[idx][self.ID_POS] for idx in range(0, self.pop_size)])
-            pos_std = np.std(pos_list, axis=0)
-            lb = self.g_best[self.ID_POS] - pos_std
-            ub = self.g_best[self.ID_POS] + pos_std
-
-            self.problem.lb_updated = np.clip(lb, self.problem.lb_updated, self.problem.ub_updated)
-            self.problem.ub_updated = np.clip(ub, self.problem.lb_updated, self.problem.ub_updated)
-            self.dyn_delta += round(self.dyn_delta / 2)
+#!/usr/bin/env python
+# Created by "Thieu" at 09:17, 09/11/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from scipy.spatial.distance import cdist
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class BaseBRO(Optimizer):
+    """
+    The developed version: Battle Royale Optimization (BRO)
+
+    Notes
+    ~~~~~
+    The flow of algorithm is changed. Thrid loop is removed
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + threshold (int): [2, 5], dead threshold, default=3
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.BRO import BaseBRO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> threshold = 3
+    >>> model = BaseBRO(epoch, pop_size, threshold)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    ID_DAM = 2
+
+    def __init__(self, epoch=10000, pop_size=100, threshold=3, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            threshold (int): dead threshold, default=3
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.threshold = self.validator.check_float("threshold", threshold, [1, 10])
+        self.set_parameters(["epoch", "pop_size", "threshold"])
+        self.support_parallel_modes = False
+        self.sort_flag = False
+
+    def initialize_variables(self):
+        shrink = np.ceil(np.log10(self.epoch))
+        self.dyn_delta = np.round(self.epoch / shrink)
+        self.problem.lb_updated = deepcopy(self.problem.lb)
+        self.problem.ub_updated = deepcopy(self.problem.ub)
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        """
+        Overriding method in Optimizer class
+
+        Returns:
+            list: wrapper of solution with format [position, target, damage]
+        """
+        if pos is None:
+            pos = self.generate_position(lb, ub)
+        position = self.amend_position(pos, lb, ub)
+        target = self.get_target_wrapper(position)
+        damage = 0
+        return [position, target, damage]
+
+    def get_idx_min__(self, data):
+        k_zero = np.count_nonzero(data == 0)
+        if k_zero == len(data):
+            return np.random.choice(range(0, k_zero))
+        ## 1st: Partition sorting, not good solution here.
+        # return np.argpartition(data, k_zero)[k_zero]
+        ## 2nd: Faster
+        return np.where(data == np.min(data[data != 0]))[0][0]
+
+    def find_idx_min_distance__(self, target_pos=None, pop=None):
+        list_pos = np.array([pop[idx][self.ID_POS] for idx in range(0, self.pop_size)])
+        target_pos = np.reshape(target_pos, (1, -1))
+        dist_list = cdist(list_pos, target_pos, 'euclidean')
+        dist_list = np.reshape(dist_list, (-1))
+        return self.get_idx_min__(dist_list)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        for i in range(self.pop_size):
+            # Compare ith soldier with nearest one (jth)
+            j = self.find_idx_min_distance__(self.pop[i][self.ID_POS], self.pop)
+            if self.compare_agent(self.pop[i], self.pop[j]):
+                ## Update Winner based on global best solution
+                pos_new = self.pop[i][self.ID_POS] + np.random.normal(0, 1) * \
+                          np.mean(np.array([self.pop[i][self.ID_POS], self.g_best[self.ID_POS]]), axis=0)
+                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                target = self.get_target_wrapper(pos_new)
+                dam_new = self.pop[i][self.ID_DAM] - 1  ## Substract damaged hurt -1 to go next battle
+                self.pop[i] = [pos_new, target, dam_new]
+                ## Update Loser
+                if self.pop[j][self.ID_DAM] < self.threshold:  ## If loser not dead yet, move it based on general
+                    pos_new = np.random.uniform() * (np.maximum(self.pop[j][self.ID_POS], self.g_best[self.ID_POS]) -
+                                                     np.minimum(self.pop[j][self.ID_POS], self.g_best[self.ID_POS])) + \
+                              np.maximum(self.pop[j][self.ID_POS], self.g_best[self.ID_POS])
+                    dam_new = self.pop[j][self.ID_DAM] + 1
+
+                    self.pop[j][self.ID_TAR] = self.get_target_wrapper(self.pop[j][self.ID_POS])
+                else:  ## Loser dead and respawn again
+                    pos_new = self.generate_position(self.problem.lb_updated, self.problem.ub_updated)
+                    dam_new = 0
+                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                target = self.get_target_wrapper(pos_new)
+                self.pop[j] = [pos_new, target, dam_new]
+            else:
+                ## Update Loser by following position of Winner
+                self.pop[i] = deepcopy(self.pop[j])
+                ## Update Winner by following position of General to protect the King and General
+                pos_new = self.pop[j][self.ID_POS] + np.random.uniform() * (self.g_best[self.ID_POS] - self.pop[j][self.ID_POS])
+                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                target = self.get_target_wrapper(pos_new)
+                dam_new = 0
+                self.pop[j] = [pos_new, target, dam_new]
+        if epoch >= self.dyn_delta:  # max_epoch = 1000 -> delta = 300, 450, >500,....
+            pos_list = np.array([self.pop[idx][self.ID_POS] for idx in range(0, self.pop_size)])
+            pos_std = np.std(pos_list, axis=0)
+            lb = self.g_best[self.ID_POS] - pos_std
+            ub = self.g_best[self.ID_POS] + pos_std
+            self.problem.lb_updated = np.clip(lb, self.problem.lb_updated, self.problem.ub_updated)
+            self.problem.ub_updated = np.clip(ub, self.problem.lb_updated, self.problem.ub_updated)
+            self.dyn_delta += np.round(self.dyn_delta / 2)
+
+
+class OriginalBRO(BaseBRO):
+    """
+    The original version of: Battle Royale Optimization (BRO)
+
+    Links:
+        1. https://doi.org/10.1007/s00521-020-05004-4
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + threshold (int): [2, 5], dead threshold, default=3
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.BRO import BaseBRO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> threshold = 3
+    >>> model = BaseBRO(epoch, pop_size, threshold)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Rahkar Farshi, T., 2021. Battle royale optimization algorithm. Neural Computing and Applications, 33(4), pp.1139-1157.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, threshold=3, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            threshold (int): dead threshold, default=3
+        """
+        super().__init__(epoch, pop_size, threshold, **kwargs)
+        self.support_parallel_modes = False
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        for i in range(self.pop_size):
+            # Compare ith soldier with nearest one (jth)
+            j = self.find_idx_min_distance__(self.pop[i][self.ID_POS], self.pop)
+            dam, vic = i, j  ## This error in the algorithm's flow in the paper, But in the matlab code, he changed.
+            if self.compare_agent(self.pop[i], self.pop[j]):
+                dam, vic = j, i  ## The mistake also here in the paper.
+            if self.pop[dam][self.ID_DAM] < self.threshold:
+                pos_new = np.random.uniform(0, 1, self.problem.n_dims) * \
+                          (np.maximum(self.pop[dam][self.ID_POS], self.g_best[self.ID_POS]) -
+                           np.minimum(self.pop[dam][self.ID_POS], self.g_best[self.ID_POS])) + \
+                          np.maximum(self.pop[dam][self.ID_POS], self.g_best[self.ID_POS])
+                self.pop[dam][self.ID_POS] = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                self.pop[dam][self.ID_TAR] = self.get_target_wrapper(self.pop[dam][self.ID_POS])
+                self.pop[dam][self.ID_DAM] += 1
+                self.pop[vic][self.ID_DAM] = 0
+            else:
+                self.pop[dam] = self.create_solution(self.problem.lb_updated, self.problem.ub_updated)
+        if epoch >= self.dyn_delta:
+            pos_list = np.array([self.pop[idx][self.ID_POS] for idx in range(0, self.pop_size)])
+            pos_std = np.std(pos_list, axis=0)
+            lb = self.g_best[self.ID_POS] - pos_std
+            ub = self.g_best[self.ID_POS] + pos_std
+
+            self.problem.lb_updated = np.clip(lb, self.problem.lb_updated, self.problem.ub_updated)
+            self.problem.ub_updated = np.clip(ub, self.problem.lb_updated, self.problem.ub_updated)
+            self.dyn_delta += round(self.dyn_delta / 2)
```

### Comparing `mealpy-2.5.3/mealpy/human_based/BSO.py` & `mealpy-2.5.3a1/mealpy/human_based/BSO.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,275 +1,275 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 07:44, 08/04/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class ImprovedBSO(Optimizer):
-    """
-    The improved version: Brain Storm Optimization (BSO)
-
-    Notes
-    ~~~~~
-    + Remove some probability parameters, and some unnecessary equations.
-    + The Levy-flight technique is employed to enhance the algorithm's robustness and resilience in challenging environments.
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + m_clusters (int): [3, 10], number of clusters (m in the paper)
-        + p1 (float): 25% percent
-        + p2 (float): 50% percent changed by its own (local search), 50% percent changed by outside (global search)
-        + p3 (float): 75% percent develop the old idea, 25% invented new idea based on levy-flight
-        + p4 (float): [0.4, 0.6], Need more weights on the centers instead of the random position
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.BSO import ImprovedBSO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> m_clusters = 5
-    >>> p1 = 0.25
-    >>> p2 = 0.5
-    >>> p3 = 0.75
-    >>> p4 = 0.6
-    >>> model = ImprovedBSO(epoch, pop_size, m_clusters, p1, p2, p3, p4)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    def __init__(self, epoch=10000, pop_size=100,
-                 m_clusters=5, p1=0.25, p2=0.5, p3=0.75, p4=0.5, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            m_clusters (int): number of clusters (m in the paper)
-            p1 (float): 25% percent
-            p2 (float): 50% percent changed by its own (local search), 50% percent changed by outside (global search)
-            p3 (float): 75% percent develop the old idea, 25% invented new idea based on levy-flight
-            p4 (float): Need more weights on the centers instead of the random position
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.m_clusters = self.validator.check_int("m_clusters", m_clusters, [2, int(self.pop_size/5)])
-        self.p1 = self.validator.check_float("p1", p1, (0, 1.0))
-        self.p2 = self.validator.check_float("p2", p2, (0, 1.0))
-        self.p3 = self.validator.check_float("p3", p3, (0, 1.0))
-        self.p4 = self.validator.check_float("p4", p4, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "m_clusters", "p1", "p2", "p3", "p4"])
-        self.sort_flag = False
-        self.m_solution = int(self.pop_size / self.m_clusters)
-        self.pop_group, self.centers = None, None
-
-    def find_cluster__(self, pop_group):
-        centers = []
-        for i in range(0, self.m_clusters):
-            _, local_best = self.get_global_best_solution(pop_group[i])
-            centers.append(deepcopy(local_best))
-        return centers
-
-    def initialization(self):
-        if self.pop is None:
-            self.pop = self.create_population(self.pop_size)
-        self.pop_group = self.create_pop_group(self.pop, self.m_clusters, self.m_solution)
-        self.centers = self.find_cluster__(self.pop_group)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        epxilon = 1 - 1 * (epoch + 1) / self.epoch  # 1. Changed here, no need: k
-
-        if np.random.uniform() < self.p1:  # p_5a
-            idx = np.random.randint(0, self.m_clusters)
-            solution_new = self.create_solution(self.problem.lb, self.problem.ub)
-            self.centers[idx] = solution_new
-
-        pop_group = deepcopy(self.pop_group)
-        for i in range(0, self.pop_size):  # Generate new individuals
-            cluster_id = int(i / self.m_solution)
-            location_id = int(i % self.m_solution)
-
-            if np.random.uniform() < self.p2:  # p_6b
-                if np.random.uniform() < self.p3:
-                    pos_new = self.centers[cluster_id][self.ID_POS] + epxilon * np.random.normal(0, 1, self.problem.n_dims)
-                else:  # 2. Using levy flight here
-                    levy_step = self.get_levy_flight_step(beta=1.0, multiplier=0.001, size=self.problem.n_dims, case=-1)
-                    pos_new = self.pop_group[cluster_id][location_id][self.ID_POS] + levy_step
-            else:
-                id1, id2 = np.random.choice(range(0, self.m_clusters), 2, replace=False)
-                if np.random.uniform() < self.p4:
-                    pos_new = 0.5 * (self.centers[id1][self.ID_POS] + self.centers[id2][self.ID_POS]) + \
-                              epxilon * np.random.normal(0, 1, self.problem.n_dims)
-                else:
-                    rand_id1 = np.random.randint(0, self.m_solution)
-                    rand_id2 = np.random.randint(0, self.m_solution)
-                    pos_new = 0.5 * (self.pop_group[id1][rand_id1][self.ID_POS] + self.pop_group[id2][rand_id2][self.ID_POS]) + \
-                              epxilon * np.random.normal(0, 1, self.problem.n_dims)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_group[cluster_id][location_id] = [pos_new, None]
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                pop_group[cluster_id][location_id] = self.get_better_solution([pos_new, target], self.pop_group[cluster_id][location_id])
-        if self.mode in self.AVAILABLE_MODES:
-            for idx in range(0, self.m_clusters):
-                pop_group[idx] = self.update_target_wrapper_population(pop_group[idx])
-                pop_group[idx] = self.greedy_selection_population(self.pop_group[idx], pop_group[idx])
-
-        # Needed to update the centers and population
-        self.centers = self.find_cluster__(pop_group)
-        self.pop = []
-        for idx in range(0, self.m_clusters):
-            self.pop += pop_group[idx]
-
-
-class OriginalBSO(ImprovedBSO):
-    """
-    The original version of: Brain Storm Optimization (BSO)
-
-    Links:
-        1. https://doi.org/10.1007/978-3-642-21515-5_36
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + m_clusters (int): [3, 10], number of clusters (m in the paper)
-        + p1 (float): [0.1, 0.5], probability
-        + p2 (float): [0.5, 0.95], probability
-        + p3 (float): [0.2, 0.8], probability
-        + p4 (float): [0.2, 0.8], probability
-        + slope (int): [10, 15, 20, 25], changing logsig() function's slope (k: in the paper)
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.BSO import OriginalBSO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> m_clusters = 5
-    >>> p1 = 0.2
-    >>> p2 = 0.8
-    >>> p3 = 0.4
-    >>> p4 = 0.5
-    >>> slope = 20
-    >>> model = OriginalBSO(epoch, pop_size, m_clusters, p1, p2, p3, p4, slope)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Shi, Y., 2011, June. Brain storm optimization algorithm. In International
-    conference in swarm intelligence (pp. 303-309). Springer, Berlin, Heidelberg.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, m_clusters=5, p1=0.2, p2=0.8, p3=0.4, p4=0.5, slope=20, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            m_clusters (int): number of clusters (m in the paper)
-            p1 (float): probability
-            p2 (float): probability
-            p3 (float): probability
-            p4 (float): probability
-            slope (int): changing logsig() function's slope (k: in the paper)
-        """
-        super().__init__(epoch, pop_size, m_clusters, p1, p2, p3, p4, **kwargs)
-        self.slope = self.validator.check_int("slope", slope, [10, 50])
-        self.set_parameters(["epoch", "pop_size", "m_clusters", "p1", "p2", "p3", "p4", "slope"])
-
-    def amend_position(self, position=None, lb=None, ub=None):
-        """
-        Args:
-            position: vector position (location) of the solution.
-            lb: list of lower bound values
-            ub: list of upper bound values
-
-        Returns:
-            Amended position (make the position is in bound)
-        """
-        rand_pos = np.random.uniform(lb, ub)
-        condition = np.logical_and(lb <= position, position <= ub)
-        return np.where(condition, position, rand_pos)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        x = (0.5 * self.epoch - (epoch + 1)) / self.slope
-        epxilon = np.random.uniform() * (1 / (1 + np.exp(-x)))
-
-        if np.random.rand() < self.p1:  # p_5a
-            idx = np.random.randint(0, self.m_clusters)
-            solution_new = self.create_solution(self.problem.lb, self.problem.ub)
-            self.centers[idx] = solution_new
-
-        pop_group = deepcopy(self.pop_group)
-        for i in range(0, self.pop_size):  # Generate new individuals
-            cluster_id = int(i / self.m_solution)
-            location_id = int(i % self.m_solution)
-
-            if np.random.uniform() < self.p2:  # p_6b
-                if np.random.uniform() < self.p3:  # p_6i
-                    cluster_id = np.random.randint(0, self.m_clusters)
-                if np.random.uniform() < self.p3:
-                    pos_new = self.centers[cluster_id][self.ID_POS] + epxilon * np.random.normal(0, 1, self.problem.n_dims)
-                else:
-                    rand_idx = np.random.randint(0, self.m_solution)
-                    pos_new = self.pop_group[cluster_id][rand_idx][self.ID_POS] + np.random.normal(0, 1, self.problem.n_dims)
-            else:
-                id1, id2 = np.random.choice(range(0, self.m_clusters), 2, replace=False)
-                if np.random.uniform() < self.p4:
-                    pos_new = 0.5 * (self.centers[id1][self.ID_POS] + self.centers[id2][self.ID_POS]) + \
-                              epxilon * np.random.normal(0, 1, self.problem.n_dims)
-                else:
-                    rand_id1 = np.random.randint(0, self.m_solution)
-                    rand_id2 = np.random.randint(0, self.m_solution)
-                    pos_new = 0.5 * (self.pop_group[id1][rand_id1][self.ID_POS] + self.pop_group[id2][rand_id2][self.ID_POS]) + \
-                              epxilon * np.random.normal(0, 1, self.problem.n_dims)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_group[cluster_id][location_id] = [pos_new, None]
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                pop_group[cluster_id][location_id] = self.get_better_solution([pos_new, target], self.pop_group[cluster_id][location_id])
-        if self.mode in self.AVAILABLE_MODES:
-            for idx in range(0, self.m_clusters):
-                pop_group[idx] = self.update_target_wrapper_population(pop_group[idx])
-                pop_group[idx] = self.greedy_selection_population(self.pop_group[idx], pop_group[idx])
-
-        # Needed to update the centers and population
-        self.centers = self.find_cluster__(pop_group)
-        self.pop = []
-        for idx in range(0, self.m_clusters):
-            self.pop += pop_group[idx]
+#!/usr/bin/env python
+# Created by "Thieu" at 07:44, 08/04/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class ImprovedBSO(Optimizer):
+    """
+    The improved version: Brain Storm Optimization (BSO)
+
+    Notes
+    ~~~~~
+    + Remove some probability parameters, and some useless equations.
+    + Levy-flight technique is used for robustness
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + m_clusters (int): [3, 10], number of clusters (m in the paper)
+        + p1 (float): 25% percent
+        + p2 (float): 50% percent changed by its own (local search), 50% percent changed by outside (global search)
+        + p3 (float): 75% percent develop the old idea, 25% invented new idea based on levy-flight
+        + p4 (float): [0.4, 0.6], Need more weights on the centers instead of the random position
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.BSO import ImprovedBSO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> m_clusters = 5
+    >>> p1 = 0.25
+    >>> p2 = 0.5
+    >>> p3 = 0.75
+    >>> p4 = 0.6
+    >>> model = ImprovedBSO(epoch, pop_size, m_clusters, p1, p2, p3, p4)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    def __init__(self, epoch=10000, pop_size=100,
+                 m_clusters=5, p1=0.25, p2=0.5, p3=0.75, p4=0.5, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            m_clusters (int): number of clusters (m in the paper)
+            p1 (float): 25% percent
+            p2 (float): 50% percent changed by its own (local search), 50% percent changed by outside (global search)
+            p3 (float): 75% percent develop the old idea, 25% invented new idea based on levy-flight
+            p4 (float): Need more weights on the centers instead of the random position
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.m_clusters = self.validator.check_int("m_clusters", m_clusters, [2, int(self.pop_size/5)])
+        self.p1 = self.validator.check_float("p1", p1, (0, 1.0))
+        self.p2 = self.validator.check_float("p2", p2, (0, 1.0))
+        self.p3 = self.validator.check_float("p3", p3, (0, 1.0))
+        self.p4 = self.validator.check_float("p4", p4, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "m_clusters", "p1", "p2", "p3", "p4"])
+        self.sort_flag = False
+        self.m_solution = int(self.pop_size / self.m_clusters)
+        self.pop_group, self.centers = None, None
+
+    def find_cluster__(self, pop_group):
+        centers = []
+        for i in range(0, self.m_clusters):
+            _, local_best = self.get_global_best_solution(pop_group[i])
+            centers.append(deepcopy(local_best))
+        return centers
+
+    def initialization(self):
+        if self.pop is None:
+            self.pop = self.create_population(self.pop_size)
+        self.pop_group = self.create_pop_group(self.pop, self.m_clusters, self.m_solution)
+        self.centers = self.find_cluster__(self.pop_group)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        epxilon = 1 - 1 * (epoch + 1) / self.epoch  # 1. Changed here, no need: k
+
+        if np.random.uniform() < self.p1:  # p_5a
+            idx = np.random.randint(0, self.m_clusters)
+            solution_new = self.create_solution(self.problem.lb, self.problem.ub)
+            self.centers[idx] = solution_new
+
+        pop_group = deepcopy(self.pop_group)
+        for i in range(0, self.pop_size):  # Generate new individuals
+            cluster_id = int(i / self.m_solution)
+            location_id = int(i % self.m_solution)
+
+            if np.random.uniform() < self.p2:  # p_6b
+                if np.random.uniform() < self.p3:
+                    pos_new = self.centers[cluster_id][self.ID_POS] + epxilon * np.random.normal(0, 1, self.problem.n_dims)
+                else:  # 2. Using levy flight here
+                    levy_step = self.get_levy_flight_step(beta=1.0, multiplier=0.001, size=self.problem.n_dims, case=-1)
+                    pos_new = self.pop_group[cluster_id][location_id][self.ID_POS] + levy_step
+            else:
+                id1, id2 = np.random.choice(range(0, self.m_clusters), 2, replace=False)
+                if np.random.uniform() < self.p4:
+                    pos_new = 0.5 * (self.centers[id1][self.ID_POS] + self.centers[id2][self.ID_POS]) + \
+                              epxilon * np.random.normal(0, 1, self.problem.n_dims)
+                else:
+                    rand_id1 = np.random.randint(0, self.m_solution)
+                    rand_id2 = np.random.randint(0, self.m_solution)
+                    pos_new = 0.5 * (self.pop_group[id1][rand_id1][self.ID_POS] + self.pop_group[id2][rand_id2][self.ID_POS]) + \
+                              epxilon * np.random.normal(0, 1, self.problem.n_dims)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_group[cluster_id][location_id] = [pos_new, None]
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                pop_group[cluster_id][location_id] = self.get_better_solution([pos_new, target], self.pop_group[cluster_id][location_id])
+        if self.mode in self.AVAILABLE_MODES:
+            for idx in range(0, self.m_clusters):
+                pop_group[idx] = self.update_target_wrapper_population(pop_group[idx])
+                pop_group[idx] = self.greedy_selection_population(self.pop_group[idx], pop_group[idx])
+
+        # Needed to update the centers and population
+        self.centers = self.find_cluster__(pop_group)
+        self.pop = []
+        for idx in range(0, self.m_clusters):
+            self.pop += pop_group[idx]
+
+
+class OriginalBSO(ImprovedBSO):
+    """
+    The original version of: Brain Storm Optimization (BSO)
+
+    Links:
+        1. https://doi.org/10.1007/978-3-642-21515-5_36
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + m_clusters (int): [3, 10], number of clusters (m in the paper)
+        + p1 (float): [0.1, 0.5], probability
+        + p2 (float): [0.5, 0.95], probability
+        + p3 (float): [0.2, 0.8], probability
+        + p4 (float): [0.2, 0.8], probability
+        + slope (int): [10, 15, 20, 25], changing logsig() function's slope (k: in the paper)
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.BSO import OriginalBSO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> m_clusters = 5
+    >>> p1 = 0.2
+    >>> p2 = 0.8
+    >>> p3 = 0.4
+    >>> p4 = 0.5
+    >>> slope = 20
+    >>> model = OriginalBSO(epoch, pop_size, m_clusters, p1, p2, p3, p4, slope)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Shi, Y., 2011, June. Brain storm optimization algorithm. In International
+    conference in swarm intelligence (pp. 303-309). Springer, Berlin, Heidelberg.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, m_clusters=5, p1=0.2, p2=0.8, p3=0.4, p4=0.5, slope=20, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            m_clusters (int): number of clusters (m in the paper)
+            p1 (float): probability
+            p2 (float): probability
+            p3 (float): probability
+            p4 (float): probability
+            slope (int): changing logsig() function's slope (k: in the paper)
+        """
+        super().__init__(epoch, pop_size, m_clusters, p1, p2, p3, p4, **kwargs)
+        self.slope = self.validator.check_int("slope", slope, [10, 50])
+        self.set_parameters(["epoch", "pop_size", "m_clusters", "p1", "p2", "p3", "p4", "slope"])
+
+    def amend_position(self, position=None, lb=None, ub=None):
+        """
+        Args:
+            position: vector position (location) of the solution.
+            lb: list of lower bound values
+            ub: list of upper bound values
+
+        Returns:
+            Amended position (make the position is in bound)
+        """
+        rand_pos = np.random.uniform(lb, ub)
+        condition = np.logical_and(lb <= position, position <= ub)
+        return np.where(condition, position, rand_pos)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        x = (0.5 * self.epoch - (epoch + 1)) / self.slope
+        epxilon = np.random.uniform() * (1 / (1 + np.exp(-x)))
+
+        if np.random.rand() < self.p1:  # p_5a
+            idx = np.random.randint(0, self.m_clusters)
+            solution_new = self.create_solution(self.problem.lb, self.problem.ub)
+            self.centers[idx] = solution_new
+
+        pop_group = deepcopy(self.pop_group)
+        for i in range(0, self.pop_size):  # Generate new individuals
+            cluster_id = int(i / self.m_solution)
+            location_id = int(i % self.m_solution)
+
+            if np.random.uniform() < self.p2:  # p_6b
+                if np.random.uniform() < self.p3:  # p_6i
+                    cluster_id = np.random.randint(0, self.m_clusters)
+                if np.random.uniform() < self.p3:
+                    pos_new = self.centers[cluster_id][self.ID_POS] + epxilon * np.random.normal(0, 1, self.problem.n_dims)
+                else:
+                    rand_idx = np.random.randint(0, self.m_solution)
+                    pos_new = self.pop_group[cluster_id][rand_idx][self.ID_POS] + np.random.normal(0, 1, self.problem.n_dims)
+            else:
+                id1, id2 = np.random.choice(range(0, self.m_clusters), 2, replace=False)
+                if np.random.uniform() < self.p4:
+                    pos_new = 0.5 * (self.centers[id1][self.ID_POS] + self.centers[id2][self.ID_POS]) + \
+                              epxilon * np.random.normal(0, 1, self.problem.n_dims)
+                else:
+                    rand_id1 = np.random.randint(0, self.m_solution)
+                    rand_id2 = np.random.randint(0, self.m_solution)
+                    pos_new = 0.5 * (self.pop_group[id1][rand_id1][self.ID_POS] + self.pop_group[id2][rand_id2][self.ID_POS]) + \
+                              epxilon * np.random.normal(0, 1, self.problem.n_dims)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_group[cluster_id][location_id] = [pos_new, None]
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                pop_group[cluster_id][location_id] = self.get_better_solution([pos_new, target], self.pop_group[cluster_id][location_id])
+        if self.mode in self.AVAILABLE_MODES:
+            for idx in range(0, self.m_clusters):
+                pop_group[idx] = self.update_target_wrapper_population(pop_group[idx])
+                pop_group[idx] = self.greedy_selection_population(self.pop_group[idx], pop_group[idx])
+
+        # Needed to update the centers and population
+        self.centers = self.find_cluster__(pop_group)
+        self.pop = []
+        for idx in range(0, self.m_clusters):
+            self.pop += pop_group[idx]
```

### Comparing `mealpy-2.5.3/mealpy/human_based/CA.py` & `mealpy-2.5.3a1/mealpy/human_based/CA.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,109 +1,109 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 12:09, 02/03/2021 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalCA(Optimizer):
-    """
-    The original version of: Culture Algorithm (CA)
-
-    Links:
-        1. https://github.com/clever-algorithms/CleverAlgorithms
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + accepted_rate (float): [0.1, 0.5], probability of accepted rate, default: 0.15
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.CA import OriginalCA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> accepted_rate = 0.15
-    >>> model = OriginalCA(epoch, pop_size, accepted_rate)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Chen, B., Zhao, L. and Lu, J.H., 2009, April. Wind power forecast using RBF network and culture algorithm.
-    In 2009 International Conference on Sustainable Power Generation and Supply (pp. 1-6). IEEE.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, accepted_rate=0.15, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            accepted_rate (float): probability of accepted rate, default: 0.15
-        """
-        super().__init__(**kwargs)
-
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.accepted_rate = self.validator.check_float("accepted_rate", accepted_rate, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "accepted_rate"])
-        self.support_parallel_modes = False
-        self.sort_flag = True
-
-    def initialize_variables(self):
-        ## Dynamic variables
-        self.dyn_belief_space = {
-            "lb": self.problem.lb,
-            "ub": self.problem.ub,
-        }
-        self.dyn_accepted_num = int(self.accepted_rate * self.pop_size)
-        # update situational knowledge (g_best here is a element inside belief space)
-
-    def create_faithful__(self, lb, ub):
-        position = self.generate_position(lb, ub)
-        position = self.amend_position(position, lb, ub)
-        target = self.get_target_wrapper(position)
-        return [position, target]
-
-    def update_belief_space__(self, belief_space, pop_accepted):
-        pos_list = np.array([solution[self.ID_POS] for solution in pop_accepted])
-        belief_space["lb"] = np.min(pos_list, axis=0)
-        belief_space["ub"] = np.max(pos_list, axis=0)
-        return belief_space
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # create next generation
-        pop_child = [self.create_faithful__(self.dyn_belief_space["lb"], self.dyn_belief_space["ub"]) for _ in range(0, self.pop_size)]
-
-        # select next generation
-        pop_new = []
-        pop_full = self.pop + pop_child
-        size_new = len(pop_full)
-        for _ in range(0, self.pop_size):
-            id1, id2 = np.random.choice(list(range(0, size_new)), 2, replace=False)
-            pop_new.append(self.get_better_solution(pop_full[id1], pop_full[id2]))
-        self.pop = self.get_sorted_strim_population(pop_new)
-
-        # Get accepted faithful
-        accepted = self.pop[:self.dyn_accepted_num]
-
-        # Update belief_space
-        self.dyn_belief_space = self.update_belief_space__(self.dyn_belief_space, accepted)
+#!/usr/bin/env python
+# Created by "Thieu" at 12:09, 02/03/2021 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalCA(Optimizer):
+    """
+    The original version of: Culture Algorithm (CA)
+
+    Links:
+        1. https://github.com/clever-algorithms/CleverAlgorithms
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + accepted_rate (float): [0.1, 0.5], probability of accepted rate, default: 0.15
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.CA import OriginalCA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> accepted_rate = 0.15
+    >>> model = OriginalCA(epoch, pop_size, accepted_rate)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Chen, B., Zhao, L. and Lu, J.H., 2009, April. Wind power forecast using RBF network and culture algorithm.
+    In 2009 International Conference on Sustainable Power Generation and Supply (pp. 1-6). IEEE.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, accepted_rate=0.15, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            accepted_rate (float): probability of accepted rate, default: 0.15
+        """
+        super().__init__(**kwargs)
+
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.accepted_rate = self.validator.check_float("accepted_rate", accepted_rate, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "accepted_rate"])
+        self.support_parallel_modes = False
+        self.sort_flag = True
+
+    def initialize_variables(self):
+        ## Dynamic variables
+        self.dyn_belief_space = {
+            "lb": self.problem.lb,
+            "ub": self.problem.ub,
+        }
+        self.dyn_accepted_num = int(self.accepted_rate * self.pop_size)
+        # update situational knowledge (g_best here is a element inside belief space)
+
+    def create_faithful__(self, lb, ub):
+        position = self.generate_position(lb, ub)
+        position = self.amend_position(position, lb, ub)
+        target = self.get_target_wrapper(position)
+        return [position, target]
+
+    def update_belief_space__(self, belief_space, pop_accepted):
+        pos_list = np.array([solution[self.ID_POS] for solution in pop_accepted])
+        belief_space["lb"] = np.min(pos_list, axis=0)
+        belief_space["ub"] = np.max(pos_list, axis=0)
+        return belief_space
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # create next generation
+        pop_child = [self.create_faithful__(self.dyn_belief_space["lb"], self.dyn_belief_space["ub"]) for _ in range(0, self.pop_size)]
+
+        # select next generation
+        pop_new = []
+        pop_full = self.pop + pop_child
+        size_new = len(pop_full)
+        for _ in range(0, self.pop_size):
+            id1, id2 = np.random.choice(list(range(0, size_new)), 2, replace=False)
+            pop_new.append(self.get_better_solution(pop_full[id1], pop_full[id2]))
+        self.pop = self.get_sorted_strim_population(pop_new)
+
+        # Get accepted faithful
+        accepted = self.pop[:self.dyn_accepted_num]
+
+        # Update belief_space
+        self.dyn_belief_space = self.update_belief_space__(self.dyn_belief_space, accepted)
```

### Comparing `mealpy-2.5.3/mealpy/human_based/CHIO.py` & `mealpy-2.5.3a1/mealpy/human_based/CHIO.py`

 * *Ordering differences only*

 * *Files 13% similar despite different names*

```diff
@@ -1,248 +1,248 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 19:24, 09/05/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalCHIO(Optimizer):
-    """
-    The original version of: Coronavirus Herd Immunity Optimization (CHIO)
-
-    Links:
-        1. https://link.springer.com/article/10.1007/s00521-020-05296-6
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + brr (float): [0.05, 0.2], Basic reproduction rate, default=0.15
-        + max_age (int): [5, 20], Maximum infected cases age, default=10
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.CHIO import OriginalCHIO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> brr = 0.15
-    >>> max_age = 10
-    >>> model = OriginalCHIO(epoch, pop_size, brr, max_age)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Al-Betar, M.A., Alyasseri, Z.A.A., Awadallah, M.A. et al. Coronavirus herd immunity optimizer (CHIO).
-    Neural Comput & Applic 33, 5011â5042 (2021). https://doi.org/10.1007/s00521-020-05296-6
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, brr=0.15, max_age=10, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            brr (float): Basic reproduction rate, default=0.15
-            max_age (int): Maximum infected cases age, default=10
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.brr = self.validator.check_float("brr", brr, (0, 1.0))
-        self.max_age = self.validator.check_int("max_age", max_age, [1, 1+int(epoch/5)])
-        self.set_parameters(["epoch", "pop_size", "brr", "max_age"])
-
-    def initialize_variables(self):
-        self.immunity_type_list = np.random.randint(0, 3, self.pop_size)  # Randint [0, 1, 2]
-        self.age_list = np.zeros(self.pop_size)  # Control the age of each position
-        self.finished = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = []
-        is_corona_list = [False, ] * self.pop_size
-        for i in range(0, self.pop_size):
-            pos_new = deepcopy(self.pop[i][self.ID_POS])
-            for j in range(0, self.problem.n_dims):
-                rand = np.random.uniform()
-                if rand < (1.0 / 3) * self.brr:
-                    idx_candidates = np.where(self.immunity_type_list == 1)  # Infected list
-                    if idx_candidates[0].size == 0:
-                        self.finished = True
-                        # print("Epoch: {}, i: {}, immunity_list: {}".format(epoch, i, self.immunity_type_list))
-                        break
-                    idx_selected = np.random.choice(idx_candidates[0])
-                    pos_new[j] = self.pop[i][self.ID_POS][j] + np.random.uniform() * \
-                                 (self.pop[i][self.ID_POS][j] - self.pop[idx_selected][self.ID_POS][j])
-                    is_corona_list[i] = True
-                elif (1.0 / 3) * self.brr <= rand < (2.0 / 3) * self.brr:
-                    idx_candidates = np.where(self.immunity_type_list == 0)  # Susceptible list
-                    idx_selected = np.random.choice(idx_candidates[0])
-                    pos_new[j] = self.pop[i][self.ID_POS][j] + np.random.uniform() * \
-                                 (self.pop[i][self.ID_POS][j] - self.pop[idx_selected][self.ID_POS][j])
-                elif (2.0 / 3) * self.brr <= rand < self.brr:
-                    idx_candidates = np.where(self.immunity_type_list == 2)  # Immunity list
-                    fit_list = np.array([self.pop[item][self.ID_TAR][self.ID_FIT] for item in idx_candidates[0]])
-                    idx_selected = idx_candidates[0][np.argmin(fit_list)]  # Found the index of best fitness
-                    pos_new[j] = self.pop[i][self.ID_POS][j] + np.random.uniform() * \
-                                 (self.pop[i][self.ID_POS][j] - self.pop[idx_selected][self.ID_POS][j])
-            if self.finished:
-                break
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop_new = self.update_target_wrapper_population(pop_new)
-        if len(pop_new) != self.pop_size:
-            pop_child = self.create_population(self.pop_size - len(pop_new))
-            pop_new = pop_new + pop_child
-
-        for idx in range(0, self.pop_size):
-            # Step 4: Update herd immunity population
-            if self.compare_agent(pop_new[idx], self.pop[idx]):
-                self.pop[idx] = deepcopy(pop_new[idx])
-            else:
-                self.age_list[idx] += 1
-
-            ## Calculate immunity mean of population
-            fit_list = np.array([item[self.ID_TAR][self.ID_FIT] for item in self.pop])
-            delta_fx = np.mean(fit_list)
-            if (self.compare_agent(pop_new[idx], [None, [delta_fx, None]])) and (self.immunity_type_list[idx] == 0) and is_corona_list[idx]:
-                self.immunity_type_list[idx] = 1
-                self.age_list[idx] = 1
-            if (self.compare_agent([None, [delta_fx, None]], pop_new[idx])) and (self.immunity_type_list[idx] == 1):
-                self.immunity_type_list[idx] = 2
-                self.age_list[idx] = 0
-            # Step 5: Fatality condition
-            if (self.age_list[idx] >= self.max_age) and (self.immunity_type_list[idx] == 1):
-                self.pop[idx] = self.create_solution(self.problem.lb, self.problem.ub)
-                self.immunity_type_list[idx] = 0
-                self.age_list[idx] = 0
-
-
-class BaseCHIO(OriginalCHIO):
-    """
-    The developed version of: Coronavirus Herd Immunity Optimization (CHIO)
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + brr (float): [0.05, 0.2], Basic reproduction rate, default=0.15
-        + max_age (int): [5, 20], Maximum infected cases age, default=10
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.CHIO import BaseCHIO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> brr = 0.15
-    >>> max_age = 10
-    >>> model = BaseCHIO(epoch, pop_size, brr, max_age)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, brr=0.15, max_age=10, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            brr (float): Basic reproduction rate, default=0.15
-            max_age (int): Maximum infected cases age, default=10
-        """
-        super().__init__(epoch, pop_size, brr, max_age, **kwargs)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = []
-        is_corona_list = [False, ] * self.pop_size
-        for i in range(0, self.pop_size):
-            pos_new = deepcopy(self.pop[i][self.ID_POS])
-            for j in range(0, self.problem.n_dims):
-                rand = np.random.uniform()
-                if rand < (1.0 / 3) * self.brr:
-                    idx_candidates = np.where(self.immunity_type_list == 1)  # Infected list
-                    if idx_candidates[0].size == 0:
-                        rand_choice = np.random.choice(range(0, self.pop_size), int(0.33 * self.pop_size), replace=False)
-                        self.immunity_type_list[rand_choice] = 1
-                        idx_candidates = np.where(self.immunity_type_list == 1)
-                    idx_selected = np.random.choice(idx_candidates[0])
-                    pos_new[j] = self.pop[i][self.ID_POS][j] + np.random.uniform() * \
-                                 (self.pop[i][self.ID_POS][j] - self.pop[idx_selected][self.ID_POS][j])
-                    is_corona_list[i] = True
-                elif (1.0 / 3) * self.brr <= rand < (2.0 / 3) * self.brr:
-                    idx_candidates = np.where(self.immunity_type_list == 0)  # Susceptible list
-                    if idx_candidates[0].size == 0:
-                        rand_choice = np.random.choice(range(0, self.pop_size), int(0.33 * self.pop_size), replace=False)
-                        self.immunity_type_list[rand_choice] = 0
-                        idx_candidates = np.where(self.immunity_type_list == 0)
-                    idx_selected = np.random.choice(idx_candidates[0])
-                    pos_new[j] = self.pop[i][self.ID_POS][j] + np.random.uniform() * \
-                                 (self.pop[i][self.ID_POS][j] - self.pop[idx_selected][self.ID_POS][j])
-                elif (2.0 / 3) * self.brr <= rand < self.brr:
-                    idx_candidates = np.where(self.immunity_type_list == 2)  # Immunity list
-                    fit_list = np.array([self.pop[item][self.ID_TAR][self.ID_FIT] for item in idx_candidates[0]])
-                    idx_selected = idx_candidates[0][np.argmin(fit_list)]  # Found the index of best fitness
-                    pos_new[j] = self.pop[i][self.ID_POS][j] + np.random.uniform() * \
-                                 (self.pop[i][self.ID_POS][j] - self.pop[idx_selected][self.ID_POS][j])
-            if self.finished:
-                break
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop_new = self.update_target_wrapper_population(pop_new)
-
-        for idx in range(0, self.pop_size):
-            # Step 4: Update herd immunity population
-            if self.compare_agent(pop_new[idx], self.pop[idx]):
-                self.pop[idx] = deepcopy(pop_new[idx])
-            else:
-                self.age_list[idx] += 1
-
-            ## Calculate immunity mean of population
-            fit_list = np.array([item[self.ID_TAR][self.ID_FIT] for item in self.pop])
-            delta_fx = np.mean(fit_list)
-            if (self.compare_agent(pop_new[idx], [None, [delta_fx, None]])) and (self.immunity_type_list[idx] == 0) and is_corona_list[idx]:
-                self.immunity_type_list[idx] = 1
-                self.age_list[idx] = 1
-            if (self.compare_agent([None, [delta_fx, None]], pop_new[idx])) and (self.immunity_type_list[idx] == 1):
-                self.immunity_type_list[idx] = 2
-                self.age_list[idx] = 0
-            # Step 5: Fatality condition
-            if (self.age_list[idx] >= self.max_age) and (self.immunity_type_list[idx] == 1):
-                self.pop[idx] = self.create_solution(self.problem.lb, self.problem.ub)
-                self.immunity_type_list[idx] = 0
-                self.age_list[idx] = 0
+#!/usr/bin/env python
+# Created by "Thieu" at 19:24, 09/05/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalCHIO(Optimizer):
+    """
+    The original version of: Coronavirus Herd Immunity Optimization (CHIO)
+
+    Links:
+        1. https://link.springer.com/article/10.1007/s00521-020-05296-6
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + brr (float): [0.05, 0.2], Basic reproduction rate, default=0.15
+        + max_age (int): [5, 20], Maximum infected cases age, default=10
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.CHIO import OriginalCHIO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> brr = 0.15
+    >>> max_age = 10
+    >>> model = OriginalCHIO(epoch, pop_size, brr, max_age)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Al-Betar, M.A., Alyasseri, Z.A.A., Awadallah, M.A. et al. Coronavirus herd immunity optimizer (CHIO).
+    Neural Comput & Applic 33, 5011â5042 (2021). https://doi.org/10.1007/s00521-020-05296-6
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, brr=0.15, max_age=10, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            brr (float): Basic reproduction rate, default=0.15
+            max_age (int): Maximum infected cases age, default=10
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.brr = self.validator.check_float("brr", brr, (0, 1.0))
+        self.max_age = self.validator.check_int("max_age", max_age, [1, 1+int(epoch/5)])
+        self.set_parameters(["epoch", "pop_size", "brr", "max_age"])
+
+    def initialize_variables(self):
+        self.immunity_type_list = np.random.randint(0, 3, self.pop_size)  # Randint [0, 1, 2]
+        self.age_list = np.zeros(self.pop_size)  # Control the age of each position
+        self.finished = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = []
+        is_corona_list = [False, ] * self.pop_size
+        for i in range(0, self.pop_size):
+            pos_new = deepcopy(self.pop[i][self.ID_POS])
+            for j in range(0, self.problem.n_dims):
+                rand = np.random.uniform()
+                if rand < (1.0 / 3) * self.brr:
+                    idx_candidates = np.where(self.immunity_type_list == 1)  # Infected list
+                    if idx_candidates[0].size == 0:
+                        self.finished = True
+                        # print("Epoch: {}, i: {}, immunity_list: {}".format(epoch, i, self.immunity_type_list))
+                        break
+                    idx_selected = np.random.choice(idx_candidates[0])
+                    pos_new[j] = self.pop[i][self.ID_POS][j] + np.random.uniform() * \
+                                 (self.pop[i][self.ID_POS][j] - self.pop[idx_selected][self.ID_POS][j])
+                    is_corona_list[i] = True
+                elif (1.0 / 3) * self.brr <= rand < (2.0 / 3) * self.brr:
+                    idx_candidates = np.where(self.immunity_type_list == 0)  # Susceptible list
+                    idx_selected = np.random.choice(idx_candidates[0])
+                    pos_new[j] = self.pop[i][self.ID_POS][j] + np.random.uniform() * \
+                                 (self.pop[i][self.ID_POS][j] - self.pop[idx_selected][self.ID_POS][j])
+                elif (2.0 / 3) * self.brr <= rand < self.brr:
+                    idx_candidates = np.where(self.immunity_type_list == 2)  # Immunity list
+                    fit_list = np.array([self.pop[item][self.ID_TAR][self.ID_FIT] for item in idx_candidates[0]])
+                    idx_selected = idx_candidates[0][np.argmin(fit_list)]  # Found the index of best fitness
+                    pos_new[j] = self.pop[i][self.ID_POS][j] + np.random.uniform() * \
+                                 (self.pop[i][self.ID_POS][j] - self.pop[idx_selected][self.ID_POS][j])
+            if self.finished:
+                break
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop_new = self.update_target_wrapper_population(pop_new)
+        if len(pop_new) != self.pop_size:
+            pop_child = self.create_population(self.pop_size - len(pop_new))
+            pop_new = pop_new + pop_child
+
+        for idx in range(0, self.pop_size):
+            # Step 4: Update herd immunity population
+            if self.compare_agent(pop_new[idx], self.pop[idx]):
+                self.pop[idx] = deepcopy(pop_new[idx])
+            else:
+                self.age_list[idx] += 1
+
+            ## Calculate immunity mean of population
+            fit_list = np.array([item[self.ID_TAR][self.ID_FIT] for item in self.pop])
+            delta_fx = np.mean(fit_list)
+            if (self.compare_agent(pop_new[idx], [None, [delta_fx, None]])) and (self.immunity_type_list[idx] == 0) and is_corona_list[idx]:
+                self.immunity_type_list[idx] = 1
+                self.age_list[idx] = 1
+            if (self.compare_agent([None, [delta_fx, None]], pop_new[idx])) and (self.immunity_type_list[idx] == 1):
+                self.immunity_type_list[idx] = 2
+                self.age_list[idx] = 0
+            # Step 5: Fatality condition
+            if (self.age_list[idx] >= self.max_age) and (self.immunity_type_list[idx] == 1):
+                self.pop[idx] = self.create_solution(self.problem.lb, self.problem.ub)
+                self.immunity_type_list[idx] = 0
+                self.age_list[idx] = 0
+
+
+class BaseCHIO(OriginalCHIO):
+    """
+    The developed version of: Coronavirus Herd Immunity Optimization (CHIO)
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + brr (float): [0.05, 0.2], Basic reproduction rate, default=0.15
+        + max_age (int): [5, 20], Maximum infected cases age, default=10
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.CHIO import BaseCHIO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> brr = 0.15
+    >>> max_age = 10
+    >>> model = BaseCHIO(epoch, pop_size, brr, max_age)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, brr=0.15, max_age=10, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            brr (float): Basic reproduction rate, default=0.15
+            max_age (int): Maximum infected cases age, default=10
+        """
+        super().__init__(epoch, pop_size, brr, max_age, **kwargs)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = []
+        is_corona_list = [False, ] * self.pop_size
+        for i in range(0, self.pop_size):
+            pos_new = deepcopy(self.pop[i][self.ID_POS])
+            for j in range(0, self.problem.n_dims):
+                rand = np.random.uniform()
+                if rand < (1.0 / 3) * self.brr:
+                    idx_candidates = np.where(self.immunity_type_list == 1)  # Infected list
+                    if idx_candidates[0].size == 0:
+                        rand_choice = np.random.choice(range(0, self.pop_size), int(0.33 * self.pop_size), replace=False)
+                        self.immunity_type_list[rand_choice] = 1
+                        idx_candidates = np.where(self.immunity_type_list == 1)
+                    idx_selected = np.random.choice(idx_candidates[0])
+                    pos_new[j] = self.pop[i][self.ID_POS][j] + np.random.uniform() * \
+                                 (self.pop[i][self.ID_POS][j] - self.pop[idx_selected][self.ID_POS][j])
+                    is_corona_list[i] = True
+                elif (1.0 / 3) * self.brr <= rand < (2.0 / 3) * self.brr:
+                    idx_candidates = np.where(self.immunity_type_list == 0)  # Susceptible list
+                    if idx_candidates[0].size == 0:
+                        rand_choice = np.random.choice(range(0, self.pop_size), int(0.33 * self.pop_size), replace=False)
+                        self.immunity_type_list[rand_choice] = 0
+                        idx_candidates = np.where(self.immunity_type_list == 0)
+                    idx_selected = np.random.choice(idx_candidates[0])
+                    pos_new[j] = self.pop[i][self.ID_POS][j] + np.random.uniform() * \
+                                 (self.pop[i][self.ID_POS][j] - self.pop[idx_selected][self.ID_POS][j])
+                elif (2.0 / 3) * self.brr <= rand < self.brr:
+                    idx_candidates = np.where(self.immunity_type_list == 2)  # Immunity list
+                    fit_list = np.array([self.pop[item][self.ID_TAR][self.ID_FIT] for item in idx_candidates[0]])
+                    idx_selected = idx_candidates[0][np.argmin(fit_list)]  # Found the index of best fitness
+                    pos_new[j] = self.pop[i][self.ID_POS][j] + np.random.uniform() * \
+                                 (self.pop[i][self.ID_POS][j] - self.pop[idx_selected][self.ID_POS][j])
+            if self.finished:
+                break
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop_new = self.update_target_wrapper_population(pop_new)
+
+        for idx in range(0, self.pop_size):
+            # Step 4: Update herd immunity population
+            if self.compare_agent(pop_new[idx], self.pop[idx]):
+                self.pop[idx] = deepcopy(pop_new[idx])
+            else:
+                self.age_list[idx] += 1
+
+            ## Calculate immunity mean of population
+            fit_list = np.array([item[self.ID_TAR][self.ID_FIT] for item in self.pop])
+            delta_fx = np.mean(fit_list)
+            if (self.compare_agent(pop_new[idx], [None, [delta_fx, None]])) and (self.immunity_type_list[idx] == 0) and is_corona_list[idx]:
+                self.immunity_type_list[idx] = 1
+                self.age_list[idx] = 1
+            if (self.compare_agent([None, [delta_fx, None]], pop_new[idx])) and (self.immunity_type_list[idx] == 1):
+                self.immunity_type_list[idx] = 2
+                self.age_list[idx] = 0
+            # Step 5: Fatality condition
+            if (self.age_list[idx] >= self.max_age) and (self.immunity_type_list[idx] == 1):
+                self.pop[idx] = self.create_solution(self.problem.lb, self.problem.ub)
+                self.immunity_type_list[idx] = 0
+                self.age_list[idx] = 0
```

### Comparing `mealpy-2.5.3/mealpy/human_based/FBIO.py` & `mealpy-2.5.3a1/mealpy/human_based/FBIO.py`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,300 +1,300 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 08:57, 14/06/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class BaseFBIO(Optimizer):
-    """
-    The developed : Forensic-Based Investigation Optimization (FBIO)
-
-    Notes
-    ~~~~~
-    Third loop is removed, the flowand a few equations is improved
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.FBIO import BaseFBIO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = BaseFBIO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def probability__(self, list_fitness=None):  # Eq.(3) in FBI Inspired Meta-Optimization
-        max1 = np.max(list_fitness)
-        min1 = np.min(list_fitness)
-        return (max1 - list_fitness) / (max1 - min1 + self.EPSILON)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # Investigation team - team A
-        # Step A1
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            n_change = np.random.randint(0, self.problem.n_dims)
-            nb1, nb2 = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 2, replace=False)
-            # Eq.(2) in FBI Inspired Meta - Optimization
-            pos_a = deepcopy(self.pop[idx][self.ID_POS])
-            pos_a[n_change] = self.pop[idx][self.ID_POS][n_change] + np.random.normal() * \
-                (self.pop[idx][self.ID_POS][n_change] - (self.pop[nb1][self.ID_POS][n_change] + self.pop[nb2][self.ID_POS][n_change]) / 2)
-            pos_a = self.amend_position(pos_a, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_a, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_a)
-                self.pop[idx] = self.get_better_solution([pos_a, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-        list_fitness = np.array([item[self.ID_TAR][self.ID_FIT] for item in self.pop])
-        prob = self.probability__(list_fitness)
-
-        # Step A2
-        pop_child = []
-        for idx in range(0, self.pop_size):
-            if np.random.rand() > prob[idx]:
-                r1, r2, r3 = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 3, replace=False)
-                ## Remove third loop here, the condition also not good, need to remove also. No need Rnd variable
-                temp = self.g_best[self.ID_POS] + self.pop[r1][self.ID_POS] + np.random.uniform() * (self.pop[r2][self.ID_POS] - self.pop[r3][self.ID_POS])
-                condition = np.random.random(self.problem.n_dims) < 0.5
-                pos_new = np.where(condition, temp, self.pop[idx][self.ID_POS])
-            else:
-                pos_new = np.random.uniform(self.problem.lb, self.problem.ub)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_child.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_child = self.update_target_wrapper_population(pop_child)
-            self.pop = self.greedy_selection_population(pop_child, self.pop)
-
-        ## Persuing team - team B
-        ## Step B1
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            ### Remove third loop here also
-            ### Eq.(6) in FBI Inspired Meta-Optimization
-            pos_b = np.random.uniform(0, 1, self.problem.n_dims) * self.pop[idx][self.ID_POS] + \
-                    np.random.uniform(0, 1, self.problem.n_dims) * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-            pos_b = self.amend_position(pos_b, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_b, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_b)
-                self.pop[idx] = self.get_better_solution([pos_b, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-        ## Step B2
-        pop_child = []
-        for idx in range(0, self.pop_size):
-            rr = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
-            if self.compare_agent(self.pop[idx], self.pop[rr]):
-                ## Eq.(7) in FBI Inspired Meta-Optimization
-                pos_b = self.pop[idx][self.ID_POS] + np.random.uniform(0, 1, self.problem.n_dims) * \
-                        (self.pop[rr][self.ID_POS] - self.pop[idx][self.ID_POS]) + np.random.uniform() * (self.g_best[self.ID_POS] - self.pop[rr][self.ID_POS])
-            else:
-                ## Eq.(8) in FBI Inspired Meta-Optimization
-                pos_b = self.pop[idx][self.ID_POS] + np.random.uniform(0, 1, self.problem.n_dims) * \
-                        (self.pop[idx][self.ID_POS] - self.pop[rr][self.ID_POS]) + np.random.uniform() * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-            pos_b = self.amend_position(pos_b, self.problem.lb, self.problem.ub)
-            pop_child.append([pos_b, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_b)
-                self.pop[idx] = self.get_better_solution([pos_b, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_child = self.update_target_wrapper_population(pop_child)
-            self.pop = self.greedy_selection_population(pop_child, self.pop)
-
-
-class OriginalFBIO(BaseFBIO):
-    """
-    The original version of: Forensic-Based Investigation Optimization (FBIO)
-
-    Links:
-        1. https://doi.org/10.1016/j.asoc.2020.106339
-        2. https://ww2.mathworks.cn/matlabcentral/fileexchange/76299-forensic-based-investigation-algorithm-fbi
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.FBIO import OriginalFBIO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalFBIO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Chou, J.S. and Nguyen, N.M., 2020. FBI inspired meta-optimization. Applied Soft Computing, 93, p.106339.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(epoch, pop_size, **kwargs)
-
-    def amend_position(self, position=None, lb=None, ub=None):
-        """
-        Depend on what kind of problem are we trying to solve, there will be an different amend_position
-        function to rebound the position of agent into the valid range.
-
-        Args:
-            position: vector position (location) of the solution.
-            lb: list of lower bound values
-            ub: list of upper bound values
-
-        Returns:
-            Amended position (make the position is in bound)
-        """
-        rand_pos = np.random.uniform(lb, ub)
-        condition = np.logical_and(lb <= position, position <= ub)
-        return np.where(condition, position, rand_pos)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # Investigation team - team A
-        # Step A1
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            n_change = np.random.randint(0, self.problem.n_dims)
-            nb1, nb2 = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 2, replace=False)
-            # Eq.(2) in FBI Inspired Meta - Optimization
-            pos_a = deepcopy(self.pop[idx][self.ID_POS])
-            pos_a[n_change] = self.pop[idx][self.ID_POS][n_change] + (np.random.uniform() - 0.5) * 2 * \
-                (self.pop[idx][self.ID_POS][n_change] - (self.pop[nb1][self.ID_POS][n_change] + self.pop[nb2][self.ID_POS][n_change]) / 2)
-            ## Not good move here, change only 1 variable but check bound of all variable in solution
-            pos_a = self.amend_position(pos_a, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_a, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_a)
-                self.pop[idx] = self.get_better_solution([pos_a, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-        # Step A2
-        list_fitness = np.array([item[self.ID_TAR][self.ID_FIT] for item in self.pop])
-        prob = self.probability__(list_fitness)
-        pop_child = []
-        for idx in range(0, self.pop_size):
-            if np.random.uniform() > prob[idx]:
-                r1, r2, r3 = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 3, replace=False)
-                pos_a = deepcopy(self.pop[idx][self.ID_POS])
-                Rnd = np.floor(np.random.uniform() * self.problem.n_dims) + 1
-
-                for j in range(0, self.problem.n_dims):
-                    if (np.random.uniform() < np.random.uniform() or Rnd == j):
-                        pos_a[j] = self.g_best[self.ID_POS][j] + self.pop[r1][self.ID_POS][j] + \
-                                   np.random.uniform() * (self.pop[r2][self.ID_POS][j] - self.pop[r3][self.ID_POS][j])
-                    ## In the original matlab code they do the else condition here, not good again because no need else here
-                ## Same here, they do check the bound of all variable in solution
-                ## pos_a = self.amend_position(pos_a, self.problem.lb, self.problem.ub)
-            else:
-                pos_a = np.random.uniform(self.problem.lb, self.problem.ub)
-            pos_a = self.amend_position(pos_a, self.problem.lb, self.problem.ub)
-            pop_child.append([pos_a, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_a)
-                self.pop[idx] = self.get_better_solution([pos_a, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_child = self.update_target_wrapper_population(pop_child)
-            self.pop = self.greedy_selection_population(pop_child, self.pop)
-
-        ## Persuing team - team B
-        ## Step B1
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            pos_b = deepcopy(self.pop[idx][self.ID_POS])
-            for j in range(0, self.problem.n_dims):
-                ### Eq.(6) in FBI Inspired Meta-Optimization
-                pos_b[j] = np.random.uniform() * self.pop[idx][self.ID_POS][j] + \
-                           np.random.uniform() * (self.g_best[self.ID_POS][j] - self.pop[idx][self.ID_POS][j])
-            pos_b = self.amend_position(pos_b, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_b, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_b)
-                self.pop[idx] = self.get_better_solution([pos_b, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-        ## Step B2
-        pop_child = []
-        for idx in range(0, self.pop_size):
-            ### Not good move here again
-            rr = np.random.randint(0, self.pop_size)
-            while rr == idx:
-                rr = np.random.randint(0, self.pop_size)
-            if self.compare_agent(self.pop[idx], self.pop[rr]):
-                ## Eq.(7) in FBI Inspired Meta-Optimization
-                pos_b = self.pop[idx][self.ID_POS] + np.random.uniform(0, 1, self.problem.n_dims) * (self.pop[rr][self.ID_POS] - self.pop[idx][self.ID_POS]) + \
-                        np.random.uniform() * (self.g_best[self.ID_POS] - self.pop[rr][self.ID_POS])
-            else:
-                ## Eq.(8) in FBI Inspired Meta-Optimization
-                pos_b = self.pop[idx][self.ID_POS] + np.random.uniform(0, 1, self.problem.n_dims) * (self.pop[idx][self.ID_POS] - self.pop[rr][self.ID_POS]) + \
-                        np.random.uniform() * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-            pos_b = self.amend_position(pos_b, self.problem.lb, self.problem.ub)
-            pop_child.append([pos_b, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_b)
-                self.pop[idx] = self.get_better_solution([pos_b, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_child = self.update_target_wrapper_population(pop_child)
-            self.pop = self.greedy_selection_population(pop_child, self.pop)
+#!/usr/bin/env python
+# Created by "Thieu" at 08:57, 14/06/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class BaseFBIO(Optimizer):
+    """
+    The developed : Forensic-Based Investigation Optimization (FBIO)
+
+    Notes
+    ~~~~~
+    Third loop is removed, the flowand a few equations is improved
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.FBIO import BaseFBIO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = BaseFBIO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def probability__(self, list_fitness=None):  # Eq.(3) in FBI Inspired Meta-Optimization
+        max1 = np.max(list_fitness)
+        min1 = np.min(list_fitness)
+        return (max1 - list_fitness) / (max1 - min1 + self.EPSILON)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # Investigation team - team A
+        # Step A1
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            n_change = np.random.randint(0, self.problem.n_dims)
+            nb1, nb2 = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 2, replace=False)
+            # Eq.(2) in FBI Inspired Meta - Optimization
+            pos_a = deepcopy(self.pop[idx][self.ID_POS])
+            pos_a[n_change] = self.pop[idx][self.ID_POS][n_change] + np.random.normal() * \
+                (self.pop[idx][self.ID_POS][n_change] - (self.pop[nb1][self.ID_POS][n_change] + self.pop[nb2][self.ID_POS][n_change]) / 2)
+            pos_a = self.amend_position(pos_a, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_a, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_a)
+                self.pop[idx] = self.get_better_solution([pos_a, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+        list_fitness = np.array([item[self.ID_TAR][self.ID_FIT] for item in self.pop])
+        prob = self.probability__(list_fitness)
+
+        # Step A2
+        pop_child = []
+        for idx in range(0, self.pop_size):
+            if np.random.rand() > prob[idx]:
+                r1, r2, r3 = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 3, replace=False)
+                ## Remove third loop here, the condition also not good, need to remove also. No need Rnd variable
+                temp = self.g_best[self.ID_POS] + self.pop[r1][self.ID_POS] + np.random.uniform() * (self.pop[r2][self.ID_POS] - self.pop[r3][self.ID_POS])
+                condition = np.random.random(self.problem.n_dims) < 0.5
+                pos_new = np.where(condition, temp, self.pop[idx][self.ID_POS])
+            else:
+                pos_new = np.random.uniform(self.problem.lb, self.problem.ub)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_child.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_child = self.update_target_wrapper_population(pop_child)
+            self.pop = self.greedy_selection_population(pop_child, self.pop)
+
+        ## Persuing team - team B
+        ## Step B1
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            ### Remove third loop here also
+            ### Eq.(6) in FBI Inspired Meta-Optimization
+            pos_b = np.random.uniform(0, 1, self.problem.n_dims) * self.pop[idx][self.ID_POS] + \
+                    np.random.uniform(0, 1, self.problem.n_dims) * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+            pos_b = self.amend_position(pos_b, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_b, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_b)
+                self.pop[idx] = self.get_better_solution([pos_b, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+        ## Step B2
+        pop_child = []
+        for idx in range(0, self.pop_size):
+            rr = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
+            if self.compare_agent(self.pop[idx], self.pop[rr]):
+                ## Eq.(7) in FBI Inspired Meta-Optimization
+                pos_b = self.pop[idx][self.ID_POS] + np.random.uniform(0, 1, self.problem.n_dims) * \
+                        (self.pop[rr][self.ID_POS] - self.pop[idx][self.ID_POS]) + np.random.uniform() * (self.g_best[self.ID_POS] - self.pop[rr][self.ID_POS])
+            else:
+                ## Eq.(8) in FBI Inspired Meta-Optimization
+                pos_b = self.pop[idx][self.ID_POS] + np.random.uniform(0, 1, self.problem.n_dims) * \
+                        (self.pop[idx][self.ID_POS] - self.pop[rr][self.ID_POS]) + np.random.uniform() * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+            pos_b = self.amend_position(pos_b, self.problem.lb, self.problem.ub)
+            pop_child.append([pos_b, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_b)
+                self.pop[idx] = self.get_better_solution([pos_b, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_child = self.update_target_wrapper_population(pop_child)
+            self.pop = self.greedy_selection_population(pop_child, self.pop)
+
+
+class OriginalFBIO(BaseFBIO):
+    """
+    The original version of: Forensic-Based Investigation Optimization (FBIO)
+
+    Links:
+        1. https://doi.org/10.1016/j.asoc.2020.106339
+        2. https://ww2.mathworks.cn/matlabcentral/fileexchange/76299-forensic-based-investigation-algorithm-fbi
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.FBIO import OriginalFBIO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalFBIO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Chou, J.S. and Nguyen, N.M., 2020. FBI inspired meta-optimization. Applied Soft Computing, 93, p.106339.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(epoch, pop_size, **kwargs)
+
+    def amend_position(self, position=None, lb=None, ub=None):
+        """
+        Depend on what kind of problem are we trying to solve, there will be an different amend_position
+        function to rebound the position of agent into the valid range.
+
+        Args:
+            position: vector position (location) of the solution.
+            lb: list of lower bound values
+            ub: list of upper bound values
+
+        Returns:
+            Amended position (make the position is in bound)
+        """
+        rand_pos = np.random.uniform(lb, ub)
+        condition = np.logical_and(lb <= position, position <= ub)
+        return np.where(condition, position, rand_pos)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # Investigation team - team A
+        # Step A1
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            n_change = np.random.randint(0, self.problem.n_dims)
+            nb1, nb2 = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 2, replace=False)
+            # Eq.(2) in FBI Inspired Meta - Optimization
+            pos_a = deepcopy(self.pop[idx][self.ID_POS])
+            pos_a[n_change] = self.pop[idx][self.ID_POS][n_change] + (np.random.uniform() - 0.5) * 2 * \
+                (self.pop[idx][self.ID_POS][n_change] - (self.pop[nb1][self.ID_POS][n_change] + self.pop[nb2][self.ID_POS][n_change]) / 2)
+            ## Not good move here, change only 1 variable but check bound of all variable in solution
+            pos_a = self.amend_position(pos_a, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_a, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_a)
+                self.pop[idx] = self.get_better_solution([pos_a, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+        # Step A2
+        list_fitness = np.array([item[self.ID_TAR][self.ID_FIT] for item in self.pop])
+        prob = self.probability__(list_fitness)
+        pop_child = []
+        for idx in range(0, self.pop_size):
+            if np.random.uniform() > prob[idx]:
+                r1, r2, r3 = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 3, replace=False)
+                pos_a = deepcopy(self.pop[idx][self.ID_POS])
+                Rnd = np.floor(np.random.uniform() * self.problem.n_dims) + 1
+
+                for j in range(0, self.problem.n_dims):
+                    if (np.random.uniform() < np.random.uniform() or Rnd == j):
+                        pos_a[j] = self.g_best[self.ID_POS][j] + self.pop[r1][self.ID_POS][j] + \
+                                   np.random.uniform() * (self.pop[r2][self.ID_POS][j] - self.pop[r3][self.ID_POS][j])
+                    ## In the original matlab code they do the else condition here, not good again because no need else here
+                ## Same here, they do check the bound of all variable in solution
+                ## pos_a = self.amend_position(pos_a, self.problem.lb, self.problem.ub)
+            else:
+                pos_a = np.random.uniform(self.problem.lb, self.problem.ub)
+            pos_a = self.amend_position(pos_a, self.problem.lb, self.problem.ub)
+            pop_child.append([pos_a, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_a)
+                self.pop[idx] = self.get_better_solution([pos_a, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_child = self.update_target_wrapper_population(pop_child)
+            self.pop = self.greedy_selection_population(pop_child, self.pop)
+
+        ## Persuing team - team B
+        ## Step B1
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            pos_b = deepcopy(self.pop[idx][self.ID_POS])
+            for j in range(0, self.problem.n_dims):
+                ### Eq.(6) in FBI Inspired Meta-Optimization
+                pos_b[j] = np.random.uniform() * self.pop[idx][self.ID_POS][j] + \
+                           np.random.uniform() * (self.g_best[self.ID_POS][j] - self.pop[idx][self.ID_POS][j])
+            pos_b = self.amend_position(pos_b, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_b, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_b)
+                self.pop[idx] = self.get_better_solution([pos_b, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+        ## Step B2
+        pop_child = []
+        for idx in range(0, self.pop_size):
+            ### Not good move here again
+            rr = np.random.randint(0, self.pop_size)
+            while rr == idx:
+                rr = np.random.randint(0, self.pop_size)
+            if self.compare_agent(self.pop[idx], self.pop[rr]):
+                ## Eq.(7) in FBI Inspired Meta-Optimization
+                pos_b = self.pop[idx][self.ID_POS] + np.random.uniform(0, 1, self.problem.n_dims) * (self.pop[rr][self.ID_POS] - self.pop[idx][self.ID_POS]) + \
+                        np.random.uniform() * (self.g_best[self.ID_POS] - self.pop[rr][self.ID_POS])
+            else:
+                ## Eq.(8) in FBI Inspired Meta-Optimization
+                pos_b = self.pop[idx][self.ID_POS] + np.random.uniform(0, 1, self.problem.n_dims) * (self.pop[idx][self.ID_POS] - self.pop[rr][self.ID_POS]) + \
+                        np.random.uniform() * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+            pos_b = self.amend_position(pos_b, self.problem.lb, self.problem.ub)
+            pop_child.append([pos_b, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_b)
+                self.pop[idx] = self.get_better_solution([pos_b, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_child = self.update_target_wrapper_population(pop_child)
+            self.pop = self.greedy_selection_population(pop_child, self.pop)
```

### Comparing `mealpy-2.5.3/mealpy/human_based/GSKA.py` & `mealpy-2.5.3a1/mealpy/human_based/GSKA.py`

 * *Ordering differences only*

 * *Files 16% similar despite different names*

```diff
@@ -1,248 +1,248 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 16:58, 08/04/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class BaseGSKA(Optimizer):
-    """
-    The developed version: Gaining Sharing Knowledge-based Algorithm (GSKA)
-
-    Notes
-    ~~~~~
-    + Third loop is removed, 2 parameters is removed
-    + Solution represent junior or senior instead of dimension of solution
-    + Equations is based vector, can handle large-scale problem
-    + Apply the ideas of levy-flight and global best
-    + Keep the better one after updating process
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + pb (float): [0.1, 0.5], percent of the best (p in the paper), default = 0.1
-        + kr (float): [0.5, 0.9], knowledge ratio, default = 0.7
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.GSKA import BaseGSKA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> pb = 0.1
-    >>> kr = 0.9
-    >>> model = BaseGSKA(epoch, pop_size, pb, kr)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, pb=0.1, kr=0.7, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100, n: pop_size, m: clusters
-            pb (float): percent of the best 0.1%, 0.8%, 0.1% (p in the paper), default = 0.1
-            kr (float): knowledge ratio, default = 0.7
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.pb = self.validator.check_float("pb", pb, (0, 1.0))
-        self.kr = self.validator.check_float("kr", kr, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "pb", "kr"])
-        self.sort_flag = True
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        D = int(np.ceil(self.pop_size * (1 - (epoch + 1) / self.epoch)))
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            # If it is the best it chooses best+2, best+1
-            if idx == 0:
-                previ, nexti = idx + 2, idx + 1
-            # If it is the worse it chooses worst-2, worst-1
-            elif idx == self.pop_size - 1:
-                previ, nexti = idx - 2, idx - 1
-            # Other case it chooses i-1, i+1
-            else:
-                previ, nexti = idx - 1, idx + 1
-
-            if idx < D:  # senior gaining and sharing
-                if np.random.uniform() <= self.kr:
-                    rand_idx = np.random.choice(list(set(range(0, self.pop_size)) - {previ, idx, nexti}))
-                    if self.compare_agent(self.pop[rand_idx], self.pop[idx]):
-                        pos_new = self.pop[idx][self.ID_POS] + np.random.uniform(0, 1, self.problem.n_dims) * \
-                                  (self.pop[previ][self.ID_POS] - self.pop[nexti][self.ID_POS] +
-                                   self.pop[rand_idx][self.ID_POS] - self.pop[idx][self.ID_POS])
-                    else:
-                        pos_new = self.g_best[self.ID_POS] + np.random.uniform(0, 1, self.problem.n_dims) * \
-                                  (self.pop[rand_idx][self.ID_POS] - self.pop[idx][self.ID_POS])
-                else:
-                    pos_new = np.random.uniform(self.problem.lb, self.problem.ub)
-            else:  # junior gaining and sharing
-                if np.random.uniform() <= self.kr:
-                    id1 = int(self.pb * self.pop_size)
-                    id2 = id1 + int(self.pop_size - 2 * 100 * self.pb)
-                    rand_best = np.random.choice(list(set(range(0, id1)) - {idx}))
-                    rand_worst = np.random.choice(list(set(range(id2, self.pop_size)) - {idx}))
-                    rand_mid = np.random.choice(list(set(range(id1, id2)) - {idx}))
-                    if self.compare_agent(self.pop[rand_mid], self.pop[idx]):
-                        pos_new = self.pop[idx][self.ID_POS] + np.random.uniform(0, 1, self.problem.n_dims) * \
-                                  (self.pop[rand_best][self.ID_POS] - self.pop[rand_worst][self.ID_POS] +
-                                   self.pop[rand_mid][self.ID_POS] - self.pop[idx][self.ID_POS])
-                    else:
-                        pos_new = self.g_best[self.ID_POS] + np.random.uniform(0, 1, self.problem.n_dims) * \
-                                  (self.pop[rand_mid][self.ID_POS] - self.pop[idx][self.ID_POS])
-                else:
-                    pos_new = np.random.uniform(self.problem.lb, self.problem.ub)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(pop_new, self.pop)
-
-
-class OriginalGSKA(Optimizer):
-    """
-    The original version of: Gaining Sharing Knowledge-based Algorithm (GSKA)
-
-    Links:
-        1. https://doi.org/10.1007/s13042-019-01053-x
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + pb (float): [0.1, 0.5], percent of the best (p in the paper), default = 0.1
-        + kf (float): [0.3, 0.8], knowledge factor that controls the total amount of gained and shared knowledge added from others to the current individual during generations, default = 0.5
-        + kr (float): [0.5, 0.95], knowledge ratio, default = 0.9
-        + kg (int): [3, 20], number of generations effect to D-dimension, default = 5
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.GSKA import OriginalGSKA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> pb = 0.1
-    >>> kf = 0.5
-    >>> kr = 0.9
-    >>> kg = 5
-    >>> model = OriginalGSKA(epoch, pop_size, pb, kf, kr, kg)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Mohamed, A.W., Hadi, A.A. and Mohamed, A.K., 2020. Gaining-sharing knowledge based algorithm for solving
-    optimization problems: a novel nature-inspired algorithm. International Journal of Machine Learning and Cybernetics, 11(7), pp.1501-1529.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, pb=0.1, kf=0.5, kr=0.9, kg=5, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100, n: pop_size, m: clusters
-            pb (float): percent of the best   0.1%, 0.8%, 0.1% (p in the paper), default = 0.1
-            kf (float): knowledge factor that controls the total amount of gained and shared knowledge added
-                        from others to the current individual during generations, default = 0.5
-            kr (float): knowledge ratio, default = 0.9
-            kg (int): Number of generations effect to D-dimension, default = 5
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.pb = self.validator.check_float("pb", pb, (0, 1.0))
-        self.kf = self.validator.check_float("kf", kf, (0, 1.0))
-        self.kr = self.validator.check_float("kr", kr, (0, 1.0))
-        self.kg = self.validator.check_int("kg", kg, [1, 1 + int(epoch / 2)])
-        self.set_parameters(["epoch", "pop_size", "pb", "kf", "kr", "kg"])
-        self.sort_flag = True
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        D = int(self.problem.n_dims * (1 - (epoch + 1) / self.epoch) ** self.kg)
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            # If it is the best it chooses best+2, best+1
-            if idx == 0:
-                previ, nexti = idx + 2, idx + 1
-            # If it is the worse it chooses worst-2, worst-1
-            elif idx == self.pop_size - 1:
-                previ, nexti = idx - 2, idx - 1
-            # Other case it chooses i-1, i+1
-            else:
-                previ, nexti = idx - 1, idx + 1
-
-            # The random individual is for all dimension values
-            rand_idx = np.random.choice(list(set(range(0, self.pop_size)) - {previ, idx, nexti}))
-            pos_new = deepcopy(self.pop[idx][self.ID_POS])
-
-            for j in range(0, self.problem.n_dims):
-                if j < D:  # junior gaining and sharing
-                    if np.random.uniform() <= self.kr:
-                        if self.compare_agent(self.pop[rand_idx], self.pop[idx]):
-                            pos_new[j] = self.pop[idx][self.ID_POS][j] + self.kf * \
-                                         (self.pop[previ][self.ID_POS][j] - self.pop[nexti][self.ID_POS][j] +
-                                          self.pop[rand_idx][self.ID_POS][j] - self.pop[idx][self.ID_POS][j])
-                        else:
-                            pos_new[j] = self.pop[idx][self.ID_POS][j] + self.kf * \
-                                         (self.pop[previ][self.ID_POS][j] - self.pop[nexti][self.ID_POS][j] +
-                                          self.pop[idx][self.ID_POS][j] - self.pop[rand_idx][self.ID_POS][j])
-                else:  # senior gaining and sharing
-                    if np.random.uniform() <= self.kr:
-                        id1 = int(self.pb * self.pop_size)
-                        id2 = id1 + int(self.pop_size - 2 * 100 * self.pb)
-                        rand_best = np.random.choice(list(set(range(0, id1)) - {idx}))
-                        rand_worst = np.random.choice(list(set(range(id2, self.pop_size)) - {idx}))
-                        rand_mid = np.random.choice(list(set(range(id1, id2)) - {idx}))
-                        if self.compare_agent(self.pop[rand_mid], self.pop[idx]):
-                            pos_new[j] = self.pop[idx][self.ID_POS][j] + self.kf * \
-                                         (self.pop[rand_best][self.ID_POS][j] - self.pop[rand_worst][self.ID_POS][j] +
-                                          self.pop[rand_mid][self.ID_POS][j] - self.pop[idx][self.ID_POS][j])
-                        else:
-                            pos_new[j] = self.pop[idx][self.ID_POS][j] + self.kf * \
-                                         (self.pop[rand_best][self.ID_POS][j] - self.pop[rand_worst][self.ID_POS][j] +
-                                          self.pop[idx][self.ID_POS][j] - self.pop[rand_mid][self.ID_POS][j])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(pop_new, self.pop)
+#!/usr/bin/env python
+# Created by "Thieu" at 16:58, 08/04/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class BaseGSKA(Optimizer):
+    """
+    The developed version: Gaining Sharing Knowledge-based Algorithm (GSKA)
+
+    Notes
+    ~~~~~
+    + Third loop is removed, 2 parameters is removed
+    + Solution represent junior or senior instead of dimension of solution
+    + Equations is based vector, can handle large-scale problem
+    + Apply the ideas of levy-flight and global best
+    + Keep the better one after updating process
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + pb (float): [0.1, 0.5], percent of the best (p in the paper), default = 0.1
+        + kr (float): [0.5, 0.9], knowledge ratio, default = 0.7
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.GSKA import BaseGSKA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> pb = 0.1
+    >>> kr = 0.9
+    >>> model = BaseGSKA(epoch, pop_size, pb, kr)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, pb=0.1, kr=0.7, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100, n: pop_size, m: clusters
+            pb (float): percent of the best 0.1%, 0.8%, 0.1% (p in the paper), default = 0.1
+            kr (float): knowledge ratio, default = 0.7
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.pb = self.validator.check_float("pb", pb, (0, 1.0))
+        self.kr = self.validator.check_float("kr", kr, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "pb", "kr"])
+        self.sort_flag = True
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        D = int(np.ceil(self.pop_size * (1 - (epoch + 1) / self.epoch)))
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            # If it is the best it chooses best+2, best+1
+            if idx == 0:
+                previ, nexti = idx + 2, idx + 1
+            # If it is the worse it chooses worst-2, worst-1
+            elif idx == self.pop_size - 1:
+                previ, nexti = idx - 2, idx - 1
+            # Other case it chooses i-1, i+1
+            else:
+                previ, nexti = idx - 1, idx + 1
+
+            if idx < D:  # senior gaining and sharing
+                if np.random.uniform() <= self.kr:
+                    rand_idx = np.random.choice(list(set(range(0, self.pop_size)) - {previ, idx, nexti}))
+                    if self.compare_agent(self.pop[rand_idx], self.pop[idx]):
+                        pos_new = self.pop[idx][self.ID_POS] + np.random.uniform(0, 1, self.problem.n_dims) * \
+                                  (self.pop[previ][self.ID_POS] - self.pop[nexti][self.ID_POS] +
+                                   self.pop[rand_idx][self.ID_POS] - self.pop[idx][self.ID_POS])
+                    else:
+                        pos_new = self.g_best[self.ID_POS] + np.random.uniform(0, 1, self.problem.n_dims) * \
+                                  (self.pop[rand_idx][self.ID_POS] - self.pop[idx][self.ID_POS])
+                else:
+                    pos_new = np.random.uniform(self.problem.lb, self.problem.ub)
+            else:  # junior gaining and sharing
+                if np.random.uniform() <= self.kr:
+                    id1 = int(self.pb * self.pop_size)
+                    id2 = id1 + int(self.pop_size - 2 * 100 * self.pb)
+                    rand_best = np.random.choice(list(set(range(0, id1)) - {idx}))
+                    rand_worst = np.random.choice(list(set(range(id2, self.pop_size)) - {idx}))
+                    rand_mid = np.random.choice(list(set(range(id1, id2)) - {idx}))
+                    if self.compare_agent(self.pop[rand_mid], self.pop[idx]):
+                        pos_new = self.pop[idx][self.ID_POS] + np.random.uniform(0, 1, self.problem.n_dims) * \
+                                  (self.pop[rand_best][self.ID_POS] - self.pop[rand_worst][self.ID_POS] +
+                                   self.pop[rand_mid][self.ID_POS] - self.pop[idx][self.ID_POS])
+                    else:
+                        pos_new = self.g_best[self.ID_POS] + np.random.uniform(0, 1, self.problem.n_dims) * \
+                                  (self.pop[rand_mid][self.ID_POS] - self.pop[idx][self.ID_POS])
+                else:
+                    pos_new = np.random.uniform(self.problem.lb, self.problem.ub)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(pop_new, self.pop)
+
+
+class OriginalGSKA(Optimizer):
+    """
+    The original version of: Gaining Sharing Knowledge-based Algorithm (GSKA)
+
+    Links:
+        1. https://doi.org/10.1007/s13042-019-01053-x
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + pb (float): [0.1, 0.5], percent of the best (p in the paper), default = 0.1
+        + kf (float): [0.3, 0.8], knowledge factor that controls the total amount of gained and shared knowledge added from others to the current individual during generations, default = 0.5
+        + kr (float): [0.5, 0.95], knowledge ratio, default = 0.9
+        + kg (int): [3, 20], number of generations effect to D-dimension, default = 5
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.GSKA import OriginalGSKA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> pb = 0.1
+    >>> kf = 0.5
+    >>> kr = 0.9
+    >>> kg = 5
+    >>> model = OriginalGSKA(epoch, pop_size, pb, kf, kr, kg)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Mohamed, A.W., Hadi, A.A. and Mohamed, A.K., 2020. Gaining-sharing knowledge based algorithm for solving
+    optimization problems: a novel nature-inspired algorithm. International Journal of Machine Learning and Cybernetics, 11(7), pp.1501-1529.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, pb=0.1, kf=0.5, kr=0.9, kg=5, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100, n: pop_size, m: clusters
+            pb (float): percent of the best   0.1%, 0.8%, 0.1% (p in the paper), default = 0.1
+            kf (float): knowledge factor that controls the total amount of gained and shared knowledge added
+                        from others to the current individual during generations, default = 0.5
+            kr (float): knowledge ratio, default = 0.9
+            kg (int): Number of generations effect to D-dimension, default = 5
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.pb = self.validator.check_float("pb", pb, (0, 1.0))
+        self.kf = self.validator.check_float("kf", kf, (0, 1.0))
+        self.kr = self.validator.check_float("kr", kr, (0, 1.0))
+        self.kg = self.validator.check_int("kg", kg, [1, 1 + int(epoch / 2)])
+        self.set_parameters(["epoch", "pop_size", "pb", "kf", "kr", "kg"])
+        self.sort_flag = True
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        D = int(self.problem.n_dims * (1 - (epoch + 1) / self.epoch) ** self.kg)
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            # If it is the best it chooses best+2, best+1
+            if idx == 0:
+                previ, nexti = idx + 2, idx + 1
+            # If it is the worse it chooses worst-2, worst-1
+            elif idx == self.pop_size - 1:
+                previ, nexti = idx - 2, idx - 1
+            # Other case it chooses i-1, i+1
+            else:
+                previ, nexti = idx - 1, idx + 1
+
+            # The random individual is for all dimension values
+            rand_idx = np.random.choice(list(set(range(0, self.pop_size)) - {previ, idx, nexti}))
+            pos_new = deepcopy(self.pop[idx][self.ID_POS])
+
+            for j in range(0, self.problem.n_dims):
+                if j < D:  # junior gaining and sharing
+                    if np.random.uniform() <= self.kr:
+                        if self.compare_agent(self.pop[rand_idx], self.pop[idx]):
+                            pos_new[j] = self.pop[idx][self.ID_POS][j] + self.kf * \
+                                         (self.pop[previ][self.ID_POS][j] - self.pop[nexti][self.ID_POS][j] +
+                                          self.pop[rand_idx][self.ID_POS][j] - self.pop[idx][self.ID_POS][j])
+                        else:
+                            pos_new[j] = self.pop[idx][self.ID_POS][j] + self.kf * \
+                                         (self.pop[previ][self.ID_POS][j] - self.pop[nexti][self.ID_POS][j] +
+                                          self.pop[idx][self.ID_POS][j] - self.pop[rand_idx][self.ID_POS][j])
+                else:  # senior gaining and sharing
+                    if np.random.uniform() <= self.kr:
+                        id1 = int(self.pb * self.pop_size)
+                        id2 = id1 + int(self.pop_size - 2 * 100 * self.pb)
+                        rand_best = np.random.choice(list(set(range(0, id1)) - {idx}))
+                        rand_worst = np.random.choice(list(set(range(id2, self.pop_size)) - {idx}))
+                        rand_mid = np.random.choice(list(set(range(id1, id2)) - {idx}))
+                        if self.compare_agent(self.pop[rand_mid], self.pop[idx]):
+                            pos_new[j] = self.pop[idx][self.ID_POS][j] + self.kf * \
+                                         (self.pop[rand_best][self.ID_POS][j] - self.pop[rand_worst][self.ID_POS][j] +
+                                          self.pop[rand_mid][self.ID_POS][j] - self.pop[idx][self.ID_POS][j])
+                        else:
+                            pos_new[j] = self.pop[idx][self.ID_POS][j] + self.kf * \
+                                         (self.pop[rand_best][self.ID_POS][j] - self.pop[rand_worst][self.ID_POS][j] +
+                                          self.pop[idx][self.ID_POS][j] - self.pop[rand_mid][self.ID_POS][j])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(pop_new, self.pop)
```

### Comparing `mealpy-2.5.3/mealpy/human_based/HBO.py` & `mealpy-2.5.3a1/mealpy/human_based/HBO.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,159 +1,159 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 00:47, 16/10/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalHBO(Optimizer):
-    """
-    The original version of: Heap-based optimizer (HBO)
-
-    Links:
-        1. https://www.sciencedirect.com/science/article/abs/pii/S0957417420305261#!
-        2. https://github.com/qamar-askari/HBO/blob/master/HBO.m
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + degree (int): [2, 4], the degree level in Corporate Rank Hierarchy (CRH), default=2
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.HBO import OriginalHBO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> degree = 3
-    >>> model = OriginalHBO(epoch, pop_size, degree)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Askari, Q., Saeed, M., & Younas, I. (2020). Heap-based optimizer inspired by corporate rank hierarchy
-    for global optimization. Expert Systems with Applications, 161, 113702.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, degree=2, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            degree (int): the degree level in Corporate Rank Hierarchy (CRH), default=2
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.degree = self.validator.check_int("degree", degree, [2, 10])
-        self.set_parameters(["epoch", "pop_size", "degree"])
-        self.support_parallel_modes = False
-        self.sort_flag = False
-
-    def initialize_variables(self):
-        self.cycles = np.floor(self.epoch / 25)
-        self.it_per_cycle = self.epoch / self.cycles
-        self.qtr_cycle = self.it_per_cycle / 4
-
-    def colleagues_limits_generator__(self, pop_size, degree=3):
-        friend_limits = np.zeros((pop_size, 2))
-        for c in range(pop_size - 1, -1, -1):
-            hi = int(np.ceil((np.log10(c * degree - c + 1) / np.log10(degree)))) - 1
-            lowerLim = ((degree * degree ** (hi - 1) - 1) / (degree - 1) + 1)
-            upperLim = (degree * degree ** hi - 1) / (degree - 1)
-            friend_limits[c, 0] = lowerLim if lowerLim <= pop_size else pop_size
-            friend_limits[c, 1] = upperLim if upperLim <= pop_size else pop_size
-        return friend_limits.astype(int)
-
-    def heapifying__(self, pop, degree=3):
-        pop_size = len(pop)
-        heap = []
-        for c in range(pop_size):
-            heap.append([pop[c][self.ID_TAR], c])
-            # Heapifying
-            t = c
-            while t > 0:
-                parent_id = int(np.floor((t + 1)/degree) - 1)
-                if self.compare_agent(pop[parent_id], pop[t]):
-                    break
-                else:
-                    heap[t], heap[parent_id] = heap[parent_id], heap[t]
-                t = parent_id
-        return heap
-
-    def before_main_loop(self):
-        self.heap = self.heapifying__(self.pop, self.degree)
-        self.friend_limits = self.colleagues_limits_generator__(self.pop_size, self.degree)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        gama = (np.mod(epoch+1, self.it_per_cycle) +1) / self.qtr_cycle
-        gama = np.abs(2 - gama)
-        p1 = 1 - (epoch+1) / self.epoch
-        p2 = p1 + (1 - p1) / 2
-        for c in range(self.pop_size-1, 0, -1):
-
-            if c == 0: # Dealing with root
-                continue
-            else:
-                parent_id = int(np.floor((c+1)/self.degree) - 1)
-                cur_agent = deepcopy(self.pop[self.heap[c][1]])         #Sol to be updated
-                par_agent = self.pop[self.heap[parent_id][1]]           #Sol to be updated with reference to
-
-                # Sol to be updated with reference to
-                if self.friend_limits[c, 0] < self.friend_limits[c, 1]+1:
-                    friend_idx = self.friend_limits[c, 0]
-                else:
-                    friend_idx = np.random.choice(list(set(range(self.friend_limits[c, 0], self.friend_limits[c, 1])) - {c}))
-                fri_agent = self.pop[self.heap[friend_idx][1]]
-
-                #Position Updating
-                rr = np.random.rand(self.problem.n_dims)
-                rn = (2 * np.random.rand(self.problem.n_dims) - 1)
-
-                for jdx in range(self.problem.n_dims):
-                    if rr[jdx] < p1:
-                        continue
-                    elif rr[jdx] < p2:
-                        cur_agent[self.ID_POS][jdx] = par_agent[self.ID_POS][jdx] + rn[jdx] * gama * \
-                                                      np.abs(par_agent[self.ID_POS][jdx] - cur_agent[self.ID_POS][jdx])
-                    else:
-                        if self.compare_agent([None, self.heap[friend_idx][0]], [None, self.heap[c][0]]):
-                            cur_agent[self.ID_POS][jdx] = fri_agent[self.ID_POS][jdx] + rn[jdx] * \
-                                                          gama * np.abs(fri_agent[self.ID_POS][jdx] - cur_agent[self.ID_POS][jdx])
-                        else:
-                            cur_agent[self.ID_POS][jdx] += rn[jdx] * gama * np.abs(fri_agent[self.ID_POS][jdx] - cur_agent[self.ID_POS][jdx])
-                cur_agent[self.ID_POS] = self.amend_position(cur_agent[self.ID_POS], self.problem.lb, self.problem.ub)
-                cur_agent[self.ID_TAR] = self.get_target_wrapper(cur_agent[self.ID_POS])
-
-                if self.compare_agent(cur_agent, [None, self.heap[c][0]]):
-                    self.pop[self.heap[c][1]] = cur_agent
-                    self.heap[c][0] = deepcopy(cur_agent[self.ID_TAR])
-
-            # Heapifying
-            t = c
-            while t > 1:
-                parent_id = int((t + 1) / self.degree)
-                if self.compare_agent([None, self.heap[parent_id][0]], [None, self.heap[t][0]]):
-                    break
-                else:
-                    self.heap[t], self.heap[parent_id] = self.heap[parent_id], self.heap[t]
-                t = parent_id
+#!/usr/bin/env python
+# Created by "Thieu" at 00:47, 16/10/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalHBO(Optimizer):
+    """
+    The original version of: Heap-based optimizer (HBO)
+
+    Links:
+        1. https://www.sciencedirect.com/science/article/abs/pii/S0957417420305261#!
+        2. https://github.com/qamar-askari/HBO/blob/master/HBO.m
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+            + degree (int): [2, 4], the degree level in Corporate Rank Hierarchy (CRH), default=2
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.HBO import OriginalHBO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> degree = 3
+    >>> model = OriginalHBO(epoch, pop_size, degree)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Askari, Q., Saeed, M., & Younas, I. (2020). Heap-based optimizer inspired by corporate rank hierarchy
+    for global optimization. Expert Systems with Applications, 161, 113702.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, degree=2, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            degree (int): the degree level in Corporate Rank Hierarchy (CRH), default=2
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.degree = self.validator.check_int("degree", degree, [2, 10])
+        self.set_parameters(["epoch", "pop_size", "degree"])
+        self.support_parallel_modes = False
+        self.sort_flag = False
+
+    def initialize_variables(self):
+        self.cycles = np.floor(self.epoch / 25)
+        self.it_per_cycle = self.epoch / self.cycles
+        self.qtr_cycle = self.it_per_cycle / 4
+
+    def colleagues_limits_generator__(self, pop_size, degree=3):
+        friend_limits = np.zeros((pop_size, 2))
+        for c in range(pop_size - 1, -1, -1):
+            hi = int(np.ceil((np.log10(c * degree - c + 1) / np.log10(degree)))) - 1
+            lowerLim = ((degree * degree ** (hi - 1) - 1) / (degree - 1) + 1)
+            upperLim = (degree * degree ** hi - 1) / (degree - 1)
+            friend_limits[c, 0] = lowerLim if lowerLim <= pop_size else pop_size
+            friend_limits[c, 1] = upperLim if upperLim <= pop_size else pop_size
+        return friend_limits.astype(int)
+
+    def heapifying__(self, pop, degree=3):
+        pop_size = len(pop)
+        heap = []
+        for c in range(pop_size):
+            heap.append([pop[c][self.ID_TAR], c])
+            # Heapifying
+            t = c
+            while t > 0:
+                parent_id = int(np.floor((t + 1)/degree) - 1)
+                if self.compare_agent(pop[parent_id], pop[t]):
+                    break
+                else:
+                    heap[t], heap[parent_id] = heap[parent_id], heap[t]
+                t = parent_id
+        return heap
+
+    def before_main_loop(self):
+        self.heap = self.heapifying__(self.pop, self.degree)
+        self.friend_limits = self.colleagues_limits_generator__(self.pop_size, self.degree)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        gama = (np.mod(epoch+1, self.it_per_cycle) +1) / self.qtr_cycle
+        gama = np.abs(2 - gama)
+        p1 = 1 - (epoch+1) / self.epoch
+        p2 = p1 + (1 - p1) / 2
+        for c in range(self.pop_size-1, 0, -1):
+
+            if c == 0: # Dealing with root
+                continue
+            else:
+                parent_id = int(np.floor((c+1)/self.degree) - 1)
+                cur_agent = deepcopy(self.pop[self.heap[c][1]])         #Sol to be updated
+                par_agent = self.pop[self.heap[parent_id][1]]           #Sol to be updated with reference to
+
+                # Sol to be updated with reference to
+                if self.friend_limits[c, 0] < self.friend_limits[c, 1]+1:
+                    friend_idx = self.friend_limits[c, 0]
+                else:
+                    friend_idx = np.random.choice(list(set(range(self.friend_limits[c, 0], self.friend_limits[c, 1])) - {c}))
+                fri_agent = self.pop[self.heap[friend_idx][1]]
+
+                #Position Updating
+                rr = np.random.rand(self.problem.n_dims)
+                rn = (2 * np.random.rand(self.problem.n_dims) - 1)
+
+                for jdx in range(self.problem.n_dims):
+                    if rr[jdx] < p1:
+                        continue
+                    elif rr[jdx] < p2:
+                        cur_agent[self.ID_POS][jdx] = par_agent[self.ID_POS][jdx] + rn[jdx] * gama * \
+                                                      np.abs(par_agent[self.ID_POS][jdx] - cur_agent[self.ID_POS][jdx])
+                    else:
+                        if self.compare_agent([None, self.heap[friend_idx][0]], [None, self.heap[c][0]]):
+                            cur_agent[self.ID_POS][jdx] = fri_agent[self.ID_POS][jdx] + rn[jdx] * \
+                                                          gama * np.abs(fri_agent[self.ID_POS][jdx] - cur_agent[self.ID_POS][jdx])
+                        else:
+                            cur_agent[self.ID_POS][jdx] += rn[jdx] * gama * np.abs(fri_agent[self.ID_POS][jdx] - cur_agent[self.ID_POS][jdx])
+                cur_agent[self.ID_POS] = self.amend_position(cur_agent[self.ID_POS], self.problem.lb, self.problem.ub)
+                cur_agent[self.ID_TAR] = self.get_target_wrapper(cur_agent[self.ID_POS])
+
+                if self.compare_agent(cur_agent, [None, self.heap[c][0]]):
+                    self.pop[self.heap[c][1]] = cur_agent
+                    self.heap[c][0] = deepcopy(cur_agent[self.ID_TAR])
+
+            # Heapifying
+            t = c
+            while t > 1:
+                parent_id = int((t + 1) / self.degree)
+                if self.compare_agent([None, self.heap[parent_id][0]], [None, self.heap[t][0]]):
+                    break
+                else:
+                    self.heap[t], self.heap[parent_id] = self.heap[parent_id], self.heap[t]
+                t = parent_id
```

### Comparing `mealpy-2.5.3/mealpy/human_based/HCO.py` & `mealpy-2.5.3a1/mealpy/swarm_based/MSA.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,134 +1,128 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 08:57, 12/03/2023 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalHCO(Optimizer):
-    """
-    The original version of: Human Conception Optimizer (HCO)
-
-    Links:
-        1. https://www.mathworks.com/matlabcentral/fileexchange/124200-human-conception-optimizer-hco
-        2. https://www.nature.com/articles/s41598-022-25031-6
-
-    Notes:
-        1. This algorithm shares some similarities with the PSO algorithm (equations)
-        2. The implementation of Matlab code is kinda different to the paper
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + w (float): (0, 1.) - weight factor for probability of fitness selection, default=0.65
-        + w1 (float): (0, 1.0) - weight factor for velocity update stage, default=0.05
-        + c1 (float): (0., 3.0) - acceleration coefficient, same as PSO, default=1.4
-        + c2 (float): (0., 3.0) - acceleration coefficient, same as PSO, default=1.4
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.HCO import OriginalHCO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalHCO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Acharya, D., & Das, D. K. (2022). A novel Human Conception Optimizer for solving optimization problems. Scientific Reports, 12(1), 21631.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, w=0.65, w1=0.05, c1=1.4, c2=1.4, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            w (float): weight factor for probability of fitness selection, default=0.65
-            w1 (float): weight factor for velocity update stage, default=0.05
-            c1 (float): acceleration coefficient, same as PSO, default=1.4
-            c2 (float): acceleration coefficient, same as PSO, default=1.4
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.w = self.validator.check_float("w", w, [0, 1.0])
-        self.w1 = self.validator.check_float("w1", w1, [0, 1.0])
-        self.c1 = self.validator.check_float("c1", c1, [0., 100.])
-        self.c2 = self.validator.check_float("c2", c2, [1., 100.])
-        self.set_parameters(["epoch", "pop_size", "w", "w1", "c1", "c2"])
-        self.sort_flag = False
-
-    def initialization(self):
-        if self.pop is None:
-            self.pop = self.create_population(self.pop_size)
-        pop_op = []
-        for idx in range(0, self.pop_size):
-            pos_new = self.problem.ub + self.problem.lb - self.pop[idx][self.ID_POS]
-            pop_op.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_op = self.update_target_wrapper_population(pop_op)
-            self.pop = self.greedy_selection_population(self.pop, pop_op)
-        _, (best,), (worst,) = self.get_special_solutions(self.pop, best=1, worst=1)
-        pfit = (worst[self.ID_TAR][self.ID_FIT] - best[self.ID_TAR][self.ID_FIT]) * self.w + best[self.ID_TAR][self.ID_FIT]
-        for idx in range(0, self.pop_size):
-            if self.compare_agent([None, [pfit, None]], self.pop[idx]):
-                while True:
-                    sol = self.create_solution(self.problem.lb, self.problem.ub)
-                    if self.compare_agent(sol, [None, [pfit, None]]):
-                        self.pop[idx] = sol
-                        break
-        self.vec = np.random.rand(self.pop_size, self.problem.n_dims)
-        self.pop_p = deepcopy(self.pop)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        lamda = np.random.rand()
-        neu = 2
-        fits = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in self.pop])
-        fit_mean = np.mean(fits)
-        RR = (self.g_best[self.ID_TAR][self.ID_FIT] - fits) ** 2
-        rr = (fit_mean - fits) ** 2
-        ll = RR - rr
-        LL = (self.g_best[self.ID_TAR][self.ID_FIT] - fit_mean)
-        VV = lamda * (ll / (4 * neu * LL))
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            a1 = self.pop_p[idx][self.ID_POS] - self.pop[idx][self.ID_POS]
-            a2 = self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]
-            self.vec[idx] = self.w1 * (VV[idx] + self.vec[idx]) + self.c1 * a1*np.sin(2*np.pi*(epoch+1)/self.epoch) + self.c2*a2*np.sin(2*np.pi*(epoch+1)/self.epoch)
-            pos_new = self.pop[idx][self.ID_POS] + self.vec[idx]
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-
-        for idx in range(0, self.pop_size):
-            if self.compare_agent(pop_new[idx], self.pop[idx]):
-                self.pop[idx] = pop_new[idx]
-                if self.compare_agent(pop_new[idx], self.pop_p[idx]):
-                    self.pop_p[idx] = deepcopy(pop_new[idx])
+#!/usr/bin/env python
+# Created by "Thieu" at 14:52, 17/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from math import gamma
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalMSA(Optimizer):
+    """
+    The original version: Moth Search Algorithm (MSA)
+
+    Links:
+        1. https://www.mathworks.com/matlabcentral/fileexchange/59010-moth-search-ms-algorithm
+        2. https://doi.org/10.1007/s12293-016-0212-3
+
+    Notes
+    ~~~~~
+    + The matlab version of original paper is not good (especially convergence chart)
+    + The random number (gaussian distribution) is added in each updating equation
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + n_best (int): [3, 10], how many of the best moths to keep from one generation to the next, default=5
+        + partition (float): [0.3, 0.8], The proportional of first partition, default=0.5
+        + max_step_size (float): [0.5, 2.0], Max step size used in Levy-flight technique, default=1.0
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.MSA import OriginalMSA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> n_best = 5
+    >>> partition = 0.5
+    >>> max_step_size = 1.0
+    >>> model = OriginalMSA(epoch, pop_size, n_best, partition, max_step_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Wang, G.G., 2018. Moth search algorithm: a bio-inspired metaheuristic algorithm for
+    global optimization problems. Memetic Computing, 10(2), pp.151-164.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, n_best=5, partition=0.5, max_step_size=1.0, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            n_best (int): how many of the best moths to keep from one generation to the next, default=5
+            partition (float): The proportional of first partition, default=0.5
+            max_step_size (float): Max step size used in Levy-flight technique, default=1.0
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.n_best = self.validator.check_int("n_best", n_best, [2, int(self.pop_size/2)])
+        self.partition = self.validator.check_float("partition", partition, (0, 1.0))
+        self.max_step_size = self.validator.check_float("max_step_size", max_step_size, (0, 5.0))
+        self.set_parameters(["epoch", "pop_size", "n_best", "partition", "max_step_size"])
+        self.sort_flag = True
+        # np1 in paper
+        self.n_moth1 = int(np.ceil(self.partition * self.pop_size))
+        # np2 in paper, we actually don't need this variable
+        self.n_moth2 = self.pop_size - self.n_moth1
+        # you can change this ratio so as to get much better performance
+        self.golden_ratio = (np.sqrt(5) - 1) / 2.0
+
+    def _levy_walk(self, iteration):
+        beta = 1.5  # Eq. 2.23
+        sigma = (gamma(1 + beta) * np.sin(np.pi * (beta - 1) / 2) / (gamma(beta / 2) * (beta - 1) * 2 ** ((beta - 2) / 2))) ** (1 / (beta - 1))
+        u = np.random.uniform(self.problem.lb, self.problem.ub) * sigma
+        v = np.random.uniform(self.problem.lb, self.problem.ub)
+        step = u / np.abs(v) ** (1.0 / (beta - 1))  # Eq. 2.21
+        scale = self.max_step_size / (iteration + 1)
+        delta_x = scale * step
+        return delta_x
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_best = deepcopy(self.pop[:self.n_best])
+
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            # Migration operator
+            if idx < self.n_moth1:
+                # scale = self.max_step_size / (epoch+1)       # Smaller step for local walk
+                pos_new = self.pop[idx][self.ID_POS] + np.random.normal() * self._levy_walk(epoch)
+            else:
+                # Flying in a straight line
+                temp_case1 = self.pop[idx][self.ID_POS] + np.random.normal() * \
+                             self.golden_ratio * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+                temp_case2 = self.pop[idx][self.ID_POS] + np.random.normal() * \
+                             (1.0 / self.golden_ratio) * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+                pos_new = np.where(np.random.uniform(self.problem.n_dims) < 0.5, temp_case2, temp_case1)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+        self.pop, _ = self.get_global_best_solution(self.pop)
+        # Replace the worst with the previous generation's elites.
+        for i in range(0, self.n_best):
+            self.pop[-1 - i] = deepcopy(pop_best[i])
```

### Comparing `mealpy-2.5.3/mealpy/human_based/ICA.py` & `mealpy-2.5.3a1/mealpy/human_based/ICA.py`

 * *Ordering differences only*

 * *Files 6% similar despite different names*

```diff
@@ -1,193 +1,193 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 14:07, 02/03/2021 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalICA(Optimizer):
-    """
-    The original version of: Imperialist Competitive Algorithm (ICA)
-
-    Links:
-        1. https://ieeexplore.ieee.org/document/4425083
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + empire_count (int): [3, 10], Number of Empires (also Imperialists)
-        + assimilation_coeff (float): [1.0, 3.0], Assimilation Coefficient (beta in the paper)
-        + revolution_prob (float): [0.01, 0.1], Revolution Probability
-        + revolution_rate (float): [0.05, 0.2], Revolution Rate       (mu)
-        + revolution_step_size (float): [0.05, 0.2], Revolution Step Size  (sigma)
-        + zeta (float): [0.05, 0.2], Colonies Coefficient in Total Objective Value of Empires
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.ICA import OriginalICA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> empire_count = 5
-    >>> assimilation_coeff = 1.5
-    >>> revolution_prob = 0.05
-    >>> revolution_rate = 0.1
-    >>> revolution_step_size = 0.1
-    >>> zeta = 0.1
-    >>> model = OriginalICA(epoch, pop_size, empire_count, assimilation_coeff, revolution_prob, revolution_rate, revolution_step_size, zeta)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Atashpaz-Gargari, E. and Lucas, C., 2007, September. Imperialist competitive algorithm: an algorithm for
-    optimization inspired by imperialistic competition. In 2007 IEEE congress on evolutionary computation (pp. 4661-4667). Ieee.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, empire_count=5, assimilation_coeff=1.5,
-                 revolution_prob=0.05, revolution_rate=0.1, revolution_step_size=0.1, zeta=0.1, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size (n: pop_size, m: clusters), default = 100
-            empire_count (int): Number of Empires (also Imperialists)
-            assimilation_coeff (float): Assimilation Coefficient (beta in the paper)
-            revolution_prob (float): Revolution Probability
-            revolution_rate (float): Revolution Rate       (mu)
-            revolution_step_size (float): Revolution Step Size  (sigma)
-            zeta (float): Colonies Coefficient in Total Objective Value of Empires
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.empire_count = self.validator.check_int("empire_count", empire_count, [2, 2 + int(self.pop_size / 5)])
-        self.assimilation_coeff = self.validator.check_float("assimilation_coeff", assimilation_coeff, [1.0, 3.0])
-        self.revolution_prob = self.validator.check_float("revolution_prob", revolution_prob, (0, 1.0))
-        self.revolution_rate = self.validator.check_float("revolution_rate", revolution_rate, (0, 1.0))
-        self.revolution_step_size = self.validator.check_float("revolution_step_size", revolution_step_size, (0, 1.0))
-        self.zeta = self.validator.check_float("zeta", zeta, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "empire_count", "assimilation_coeff", "revolution_prob",
-                             "revolution_rate", "revolution_step_size", "zeta"])
-        self.sort_flag = True
-
-    def revolution_country__(self, position, n_revoluted):
-        pos_new = position + self.revolution_step_size * np.random.normal(0, 1, self.problem.n_dims)
-        idx_list = np.random.choice(range(0, self.problem.n_dims), n_revoluted, replace=False)
-        if len(idx_list) == 0:
-            idx_list = np.append(idx_list, np.random.randint(0, self.problem.n_dims))
-        position[idx_list] = pos_new[idx_list]  # Change only those selected index
-        return position
-
-    def initialization(self):
-        if self.pop is None:
-            self.pop = self.create_population(self.pop_size)
-        self.pop, self.g_best = self.get_global_best_solution(self.pop)
-        # Initialization
-        self.n_revoluted_variables = int(round(self.revolution_rate * self.problem.n_dims))
-
-        # pop = Empires
-        colony_count = self.pop_size - self.empire_count
-        self.pop_empires = deepcopy(self.pop[:self.empire_count])
-        self.pop_colonies = deepcopy(self.pop[self.empire_count:])
-
-        cost_empires_list = np.array([solution[self.ID_TAR][self.ID_FIT] for solution in self.pop_empires])
-        cost_empires_list_normalized = cost_empires_list - (np.max(cost_empires_list) + np.min(cost_empires_list))
-        prob_empires_list = np.abs(cost_empires_list_normalized / np.sum(cost_empires_list_normalized))
-        # Randomly choose colonies to empires
-        self.empires = {}
-        idx_already_selected = []
-        for i in range(0, self.empire_count - 1):
-            self.empires[i] = []
-            n_colonies = int(round(prob_empires_list[i] * colony_count))
-            idx_list = np.random.choice(list(set(range(0, colony_count)) - set(idx_already_selected)), n_colonies, replace=False).tolist()
-            idx_already_selected += idx_list
-            for idx in idx_list:
-                self.empires[i].append(self.pop_colonies[idx])
-        idx_last = list(set(range(0, colony_count)) - set(idx_already_selected))
-        self.empires[self.empire_count - 1] = []
-        for idx in idx_last:
-            self.empires[self.empire_count - 1].append(self.pop_colonies[idx])
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # Assimilation
-        for idx, colonies in self.empires.items():
-            for idx_colony, colony in enumerate(colonies):
-                pos_new = colony[self.ID_POS] + self.assimilation_coeff * \
-                          np.random.uniform(0, 1, self.problem.n_dims) * (self.pop_empires[idx][self.ID_POS] - colony[self.ID_POS])
-                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                self.empires[idx][idx_colony][self.ID_POS] = pos_new
-                if self.mode not in self.AVAILABLE_MODES:
-                    self.empires[idx][idx_colony][self.ID_TAR] = self.get_target_wrapper(pos_new)
-            self.empires[idx] = self.update_target_wrapper_population(self.empires[idx])
-
-        # Revolution
-        for idx, colonies in self.empires.items():
-            # Apply revolution to Imperialist
-            pos_new_em = self.revolution_country__(self.pop_empires[idx][self.ID_POS], self.n_revoluted_variables)
-            pos_new_em = self.amend_position(pos_new_em, self.problem.lb, self.problem.ub)
-            self.pop_empires[idx][self.ID_POS] = pos_new_em
-            if self.mode not in self.AVAILABLE_MODES:
-                self.pop_empires[idx][self.ID_TAR] = self.get_target_wrapper(pos_new_em)
-
-            # Apply revolution to Colonies
-            for idx_colony, colony in enumerate(colonies):
-                if np.random.rand() < self.revolution_prob:
-                    pos_new = self.revolution_country__(colony[self.ID_POS], self.n_revoluted_variables)
-                    pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                    self.empires[idx][idx_colony][self.ID_POS] = pos_new
-                    if self.mode not in self.AVAILABLE_MODES:
-                        self.empires[idx][idx_colony][self.ID_TAR] = self.get_target_wrapper(pos_new)
-            self.empires[idx] = self.update_target_wrapper_population(self.empires[idx])
-        self.pop_empires = self.update_target_wrapper_population(self.pop_empires)
-        self.update_global_best_solution(self.pop_empires, save=False)
-
-        # Intra-Empire Competition
-        for idx, colonies in self.empires.items():
-            for idx_colony, colony in enumerate(colonies):
-                if self.compare_agent(colony, self.pop_empires[idx]):
-                    self.empires[idx][idx_colony], self.pop_empires[idx] = deepcopy(self.pop_empires[idx]), deepcopy(colony)
-
-        # Update Total Objective Values of Empires
-        cost_empires_list = []
-        for idx, colonies in self.empires.items():
-            fit_list = np.array([solution[self.ID_TAR][self.ID_FIT] for solution in colonies])
-            fit_empire = self.pop_empires[idx][self.ID_TAR][self.ID_FIT] + self.zeta * np.mean(fit_list)
-            cost_empires_list.append(fit_empire)
-        cost_empires_list = np.array(cost_empires_list)
-
-        # Find possession probability of each empire based on its total power
-        cost_empires_list_normalized = cost_empires_list - (np.max(cost_empires_list) + np.min(cost_empires_list))
-        prob_empires_list = np.abs(cost_empires_list_normalized / np.sum(cost_empires_list_normalized))  # Vector P
-
-        uniform_list = np.random.uniform(0, 1, len(prob_empires_list))  # Vector R
-        vector_D = prob_empires_list - uniform_list
-        idx_empire = np.argmax(vector_D)
-
-        # Find the weakest empire and weakest colony inside it
-        idx_weakest_empire = np.argmax(cost_empires_list)
-        if len(self.empires[idx_weakest_empire]) > 0:
-            colonies_sorted, best, worst = self.get_special_solutions(self.empires[idx_weakest_empire])
-            self.empires[idx_empire].append(colonies_sorted.pop(-1))
-        else:
-            self.empires[idx_empire].append(self.pop_empires.pop(idx_weakest_empire))
-
-        self.pop = self.pop_empires + self.pop_colonies
+#!/usr/bin/env python
+# Created by "Thieu" at 14:07, 02/03/2021 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalICA(Optimizer):
+    """
+    The original version of: Imperialist Competitive Algorithm (ICA)
+
+    Links:
+        1. https://ieeexplore.ieee.org/document/4425083
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + empire_count (int): [3, 10], Number of Empires (also Imperialists)
+        + assimilation_coeff (float): [1.0, 3.0], Assimilation Coefficient (beta in the paper)
+        + revolution_prob (float): [0.01, 0.1], Revolution Probability
+        + revolution_rate (float): [0.05, 0.2], Revolution Rate       (mu)
+        + revolution_step_size (float): [0.05, 0.2], Revolution Step Size  (sigma)
+        + zeta (float): [0.05, 0.2], Colonies Coefficient in Total Objective Value of Empires
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.ICA import OriginalICA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> empire_count = 5
+    >>> assimilation_coeff = 1.5
+    >>> revolution_prob = 0.05
+    >>> revolution_rate = 0.1
+    >>> revolution_step_size = 0.1
+    >>> zeta = 0.1
+    >>> model = OriginalICA(epoch, pop_size, empire_count, assimilation_coeff, revolution_prob, revolution_rate, revolution_step_size, zeta)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Atashpaz-Gargari, E. and Lucas, C., 2007, September. Imperialist competitive algorithm: an algorithm for
+    optimization inspired by imperialistic competition. In 2007 IEEE congress on evolutionary computation (pp. 4661-4667). Ieee.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, empire_count=5, assimilation_coeff=1.5,
+                 revolution_prob=0.05, revolution_rate=0.1, revolution_step_size=0.1, zeta=0.1, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size (n: pop_size, m: clusters), default = 100
+            empire_count (int): Number of Empires (also Imperialists)
+            assimilation_coeff (float): Assimilation Coefficient (beta in the paper)
+            revolution_prob (float): Revolution Probability
+            revolution_rate (float): Revolution Rate       (mu)
+            revolution_step_size (float): Revolution Step Size  (sigma)
+            zeta (float): Colonies Coefficient in Total Objective Value of Empires
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.empire_count = self.validator.check_int("empire_count", empire_count, [2, 2 + int(self.pop_size / 5)])
+        self.assimilation_coeff = self.validator.check_float("assimilation_coeff", assimilation_coeff, [1.0, 3.0])
+        self.revolution_prob = self.validator.check_float("revolution_prob", revolution_prob, (0, 1.0))
+        self.revolution_rate = self.validator.check_float("revolution_rate", revolution_rate, (0, 1.0))
+        self.revolution_step_size = self.validator.check_float("revolution_step_size", revolution_step_size, (0, 1.0))
+        self.zeta = self.validator.check_float("zeta", zeta, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "empire_count", "assimilation_coeff", "revolution_prob",
+                             "revolution_rate", "revolution_step_size", "zeta"])
+        self.sort_flag = True
+
+    def revolution_country__(self, position, n_revoluted):
+        pos_new = position + self.revolution_step_size * np.random.normal(0, 1, self.problem.n_dims)
+        idx_list = np.random.choice(range(0, self.problem.n_dims), n_revoluted, replace=False)
+        if len(idx_list) == 0:
+            idx_list = np.append(idx_list, np.random.randint(0, self.problem.n_dims))
+        position[idx_list] = pos_new[idx_list]  # Change only those selected index
+        return position
+
+    def initialization(self):
+        if self.pop is None:
+            self.pop = self.create_population(self.pop_size)
+        self.pop, self.g_best = self.get_global_best_solution(self.pop)
+        # Initialization
+        self.n_revoluted_variables = int(round(self.revolution_rate * self.problem.n_dims))
+
+        # pop = Empires
+        colony_count = self.pop_size - self.empire_count
+        self.pop_empires = deepcopy(self.pop[:self.empire_count])
+        self.pop_colonies = deepcopy(self.pop[self.empire_count:])
+
+        cost_empires_list = np.array([solution[self.ID_TAR][self.ID_FIT] for solution in self.pop_empires])
+        cost_empires_list_normalized = cost_empires_list - (np.max(cost_empires_list) + np.min(cost_empires_list))
+        prob_empires_list = np.abs(cost_empires_list_normalized / np.sum(cost_empires_list_normalized))
+        # Randomly choose colonies to empires
+        self.empires = {}
+        idx_already_selected = []
+        for i in range(0, self.empire_count - 1):
+            self.empires[i] = []
+            n_colonies = int(round(prob_empires_list[i] * colony_count))
+            idx_list = np.random.choice(list(set(range(0, colony_count)) - set(idx_already_selected)), n_colonies, replace=False).tolist()
+            idx_already_selected += idx_list
+            for idx in idx_list:
+                self.empires[i].append(self.pop_colonies[idx])
+        idx_last = list(set(range(0, colony_count)) - set(idx_already_selected))
+        self.empires[self.empire_count - 1] = []
+        for idx in idx_last:
+            self.empires[self.empire_count - 1].append(self.pop_colonies[idx])
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # Assimilation
+        for idx, colonies in self.empires.items():
+            for idx_colony, colony in enumerate(colonies):
+                pos_new = colony[self.ID_POS] + self.assimilation_coeff * \
+                          np.random.uniform(0, 1, self.problem.n_dims) * (self.pop_empires[idx][self.ID_POS] - colony[self.ID_POS])
+                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                self.empires[idx][idx_colony][self.ID_POS] = pos_new
+                if self.mode not in self.AVAILABLE_MODES:
+                    self.empires[idx][idx_colony][self.ID_TAR] = self.get_target_wrapper(pos_new)
+            self.empires[idx] = self.update_target_wrapper_population(self.empires[idx])
+
+        # Revolution
+        for idx, colonies in self.empires.items():
+            # Apply revolution to Imperialist
+            pos_new_em = self.revolution_country__(self.pop_empires[idx][self.ID_POS], self.n_revoluted_variables)
+            pos_new_em = self.amend_position(pos_new_em, self.problem.lb, self.problem.ub)
+            self.pop_empires[idx][self.ID_POS] = pos_new_em
+            if self.mode not in self.AVAILABLE_MODES:
+                self.pop_empires[idx][self.ID_TAR] = self.get_target_wrapper(pos_new_em)
+
+            # Apply revolution to Colonies
+            for idx_colony, colony in enumerate(colonies):
+                if np.random.rand() < self.revolution_prob:
+                    pos_new = self.revolution_country__(colony[self.ID_POS], self.n_revoluted_variables)
+                    pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                    self.empires[idx][idx_colony][self.ID_POS] = pos_new
+                    if self.mode not in self.AVAILABLE_MODES:
+                        self.empires[idx][idx_colony][self.ID_TAR] = self.get_target_wrapper(pos_new)
+            self.empires[idx] = self.update_target_wrapper_population(self.empires[idx])
+        self.pop_empires = self.update_target_wrapper_population(self.pop_empires)
+        self.update_global_best_solution(self.pop_empires, save=False)
+
+        # Intra-Empire Competition
+        for idx, colonies in self.empires.items():
+            for idx_colony, colony in enumerate(colonies):
+                if self.compare_agent(colony, self.pop_empires[idx]):
+                    self.empires[idx][idx_colony], self.pop_empires[idx] = deepcopy(self.pop_empires[idx]), deepcopy(colony)
+
+        # Update Total Objective Values of Empires
+        cost_empires_list = []
+        for idx, colonies in self.empires.items():
+            fit_list = np.array([solution[self.ID_TAR][self.ID_FIT] for solution in colonies])
+            fit_empire = self.pop_empires[idx][self.ID_TAR][self.ID_FIT] + self.zeta * np.mean(fit_list)
+            cost_empires_list.append(fit_empire)
+        cost_empires_list = np.array(cost_empires_list)
+
+        # Find possession probability of each empire based on its total power
+        cost_empires_list_normalized = cost_empires_list - (np.max(cost_empires_list) + np.min(cost_empires_list))
+        prob_empires_list = np.abs(cost_empires_list_normalized / np.sum(cost_empires_list_normalized))  # Vector P
+
+        uniform_list = np.random.uniform(0, 1, len(prob_empires_list))  # Vector R
+        vector_D = prob_empires_list - uniform_list
+        idx_empire = np.argmax(vector_D)
+
+        # Find the weakest empire and weakest colony inside it
+        idx_weakest_empire = np.argmax(cost_empires_list)
+        if len(self.empires[idx_weakest_empire]) > 0:
+            colonies_sorted, best, worst = self.get_special_solutions(self.empires[idx_weakest_empire])
+            self.empires[idx_empire].append(colonies_sorted.pop(-1))
+        else:
+            self.empires[idx_empire].append(self.pop_empires.pop(idx_weakest_empire))
+
+        self.pop = self.pop_empires + self.pop_colonies
```

### Comparing `mealpy-2.5.3/mealpy/human_based/LCO.py` & `mealpy-2.5.3a1/mealpy/human_based/SARO.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,284 +1,265 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 11:16, 18/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalLCO(Optimizer):
-    """
-    The original version of: Life Choice-based Optimization (LCO)
-
-    Links:
-        1. https://doi.org/10.1007/s00500-019-04443-z
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + r1 (float): [1.5, 4], coefficient factor, default = 2.35
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.LCO import OriginalLCO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> r1 = 2.35
-    >>> model = OriginalLCO(epoch, pop_size, r1)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Khatri, A., Gaba, A., Rana, K.P.S. and Kumar, V., 2020. A novel life choice-based optimizer. Soft Computing, 24(12), pp.9121-9141.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, r1=2.35, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            r1 (float): coefficient factor
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.r1 = self.validator.check_float("r1", r1, [1.0, 3.0])
-        self.set_parameters(["epoch", "pop_size", "r1"])
-        self.n_agents = int(np.ceil(np.sqrt(self.pop_size)))
-        self.sort_flag = True
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            prob = np.random.rand()
-            if prob > 0.875:  # Update using Eq. 1, update from n best position
-                temp = np.array([np.random.rand() * self.pop[j][self.ID_POS] for j in range(0, self.n_agents)])
-                temp = np.mean(temp, axis=0)
-            elif prob < 0.7:  # Update using Eq. 2-6
-                f1 = 1 - epoch / self.epoch
-                f2 = 1 - f1
-                prev_pos = self.g_best[self.ID_POS] if idx == 0 else self.pop[idx-1][self.ID_POS]
-                best_diff = f1 * self.r1 * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-                better_diff = f2 * self.r1 * (prev_pos - self.pop[idx][self.ID_POS])
-                temp = self.pop[idx][self.ID_POS] + np.random.rand() * better_diff + np.random.rand() * best_diff
-            else:
-                temp = self.problem.ub - (self.pop[idx][self.ID_POS] - self.problem.lb) * np.random.rand()
-            pos_new = self.amend_position(temp, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(pop_new, self.pop)
-
-
-class BaseLCO(OriginalLCO):
-    """
-    The developed version: Life Choice-based Optimization (LCO)
-
-    Notes
-    ~~~~~
-    The flow is changed with if else statement.
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + r1 (float): [1.5, 4], coefficient factor, default = 2.35
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.LCO import BaseLCO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> r1 = 2.35
-    >>> model = BaseLCO(epoch, pop_size, r1)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, r1=2.35, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            r1 (float): coefficient factor
-        """
-        super().__init__(epoch, pop_size, r1, **kwargs)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # epoch: current chance, self.epoch: number of chances
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            prob = np.random.rand()
-            if prob > 0.875:  # Update using Eq. 1, update from n best position
-                temp = np.array([np.random.rand() * self.pop[j][self.ID_POS] for j in range(0, self.n_agents)])
-                temp = np.mean(temp, axis=0)
-            elif prob < 0.7:  # Update using Eq. 2-6
-                f = (epoch + 1) / self.epoch
-                if idx != 0:
-                    better_diff = f * self.r1 * (self.pop[idx - 1][self.ID_POS] - self.pop[idx][self.ID_POS])
-                else:
-                    better_diff = f * self.r1 * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-                best_diff = (1 - f) * self.r1 * (self.pop[0][self.ID_POS] - self.pop[idx][self.ID_POS])
-                temp = self.pop[idx][self.ID_POS] + np.random.rand() * better_diff + np.random.rand() * best_diff
-            else:
-                temp = self.generate_position(self.problem.lb, self.problem.ub)
-            pos_new = self.amend_position(temp, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(pop_new, self.pop)
-
-
-class ImprovedLCO(Optimizer):
-    """
-    The improved version: Life Choice-based Optimization (ILCO)
-
-    Notes
-    ~~~~~
-    + The flow of the original LCO is kept.
-    + Gaussian distribution and mutation mechanism are added
-    + R1 parameter is removed
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.LCO import BaseLCO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = BaseLCO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.pop_len = int(self.pop_size / 2)
-        self.sort_flag = True
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # epoch: current chance, self.epoch: number of chances
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            rand = np.random.random()
-            if rand > 0.875:  # Update using Eq. 1, update from n best position
-                n = int(np.ceil(np.sqrt(self.pop_size)))
-                pos_new = np.array([np.random.rand() * self.pop[j][self.ID_POS] for j in range(0, n)])
-                pos_new = np.mean(pos_new, axis=0)
-            elif rand < 0.7:  # Update using Eq. 2-6
-                f = (epoch + 1) / self.epoch
-                if idx != 0:
-                    better_diff = f * np.random.rand() * (self.pop[idx - 1][self.ID_POS] - self.pop[idx][self.ID_POS])
-                else:
-                    better_diff = f * np.random.rand() * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-                best_diff = (1 - f) * np.random.rand() * (self.pop[0][self.ID_POS] - self.pop[idx][self.ID_POS])
-                pos_new = self.pop[idx][self.ID_POS] + better_diff + best_diff
-            else:
-                pos_new = self.problem.ub - (self.pop[idx][self.ID_POS] - self.problem.lb) * np.random.rand()
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(pop_new, self.pop)
-
-        ## Sort the updated population based on fitness
-        pop, local_best = self.get_global_best_solution(self.pop)
-        pop_s1, pop_s2 = pop[:self.pop_len], pop[self.pop_len:]
-
-        ## Mutation scheme
-        pop_child1 = []
-        for idx in range(0, self.pop_len):
-            pos_new = pop_s1[idx][self.ID_POS] + np.random.normal(0, 1, self.problem.n_dims) * pop_s1[idx][self.ID_POS]
-            # np.random.rand() * ((epoch+1) / self.epoch) * np.random.normal(0, 1, self.problem.n_dims)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_child1.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                pop_s1[idx] = self.get_better_solution([pos_new, target], pop_s1[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_child1 = self.update_target_wrapper_population(pop_child1)
-            pop_s1 = self.greedy_selection_population(pop_s1, pop_child1)
-
-        ## Search Mechanism
-        pos_s1_list = [item[self.ID_POS] for item in pop_s1]
-        pos_s1_mean = np.mean(pos_s1_list, axis=0)
-        pop_child2 = []
-        for idx in range(0, self.pop_len):
-            pos_new = local_best[self.ID_POS] + np.random.uniform(0, 1) * pos_s1_mean * ((epoch+1) / self.epoch)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_child2.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                pop_s2[idx] = self.get_better_solution(pop_s2[idx], [pos_new, target])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_child2 = self.update_target_wrapper_population(pop_s2)
-            pop_s2 = self.greedy_selection_population(pop_s2, pop_child2)
-        ## Construct a new population
-        self.pop = pop_s1 + pop_s2
+#!/usr/bin/env python
+# Created by "Thieu" at 11:16, 18/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class BaseSARO(Optimizer):
+    """
+    The developed version: Search And Rescue Optimization (SARO)
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + se (float): [0.3, 0.8], social effect, default = 0.5
+        + mu (int): maximum unsuccessful search number, belongs to range: [2, 2+int(self.pop_size/2)], default = 15
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.SARO import BaseSARO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> se = 0.5
+    >>> mu = 50
+    >>> model = BaseSARO(epoch, pop_size, se, mu)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, se=0.5, mu=15, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            se (float): social effect, default = 0.5
+            mu (int): maximum unsuccessful search number, default = 15
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.se = self.validator.check_float("se", se, (0, 1.0))
+        self.mu = self.validator.check_int("mu", mu, [2, 2+int(self.pop_size/2)])
+        self.set_parameters(["epoch", "pop_size", "se", "mu"])
+        self.sort_flag = True
+
+    def initialize_variables(self):
+        self.dyn_USN = np.zeros(self.pop_size)
+
+    def initialization(self):
+        if self.pop is None:
+            self.pop = self.create_population(2 * self.pop_size)
+        else:
+            self.pop = self.pop + self.create_population(self.pop_size)
+
+    def amend_position(self, position=None, lb=None, ub=None):
+        """
+        Depend on what kind of problem are we trying to solve, there will be an different amend_position
+        function to rebound the position of agent into the valid range.
+
+        Args:
+            position: vector position (location) of the solution.
+            lb: list of lower bound values
+            ub: list of upper bound values
+
+        Returns:
+            Amended position (make the position is in bound)
+        """
+        condition = np.logical_and(lb <= position, position <= ub)
+        rand_pos = np.random.uniform(lb, ub)
+        return np.where(condition, position, rand_pos)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_x = deepcopy(self.pop[:self.pop_size])
+        pop_m = deepcopy(self.pop[self.pop_size:])
+
+        pop_new = []
+        for idx in range(self.pop_size):
+            ## Social Phase
+            k = np.random.choice(list(set(range(0, 2 * self.pop_size)) - {idx}))
+            sd = pop_x[idx][self.ID_POS] - self.pop[k][self.ID_POS]
+
+            #### Remove third loop here, also using random flight back when out of bound
+            pos_new_1 = self.pop[k][self.ID_POS] + np.random.uniform() * sd
+            pos_new_2 = pop_x[idx][self.ID_POS] + np.random.uniform() * sd
+            pos_new = np.where(np.logical_and(np.random.uniform(0, 1, self.problem.n_dims) < self.se,
+                                              self.pop[k][self.ID_TAR] < pop_x[idx][self.ID_TAR]), pos_new_1, pos_new_2)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop_new = self.update_target_wrapper_population(pop_new)
+        for idx in range(self.pop_size):
+            if self.compare_agent(pop_new[idx], pop_x[idx]):
+                pop_m[np.random.randint(0, self.pop_size)] = deepcopy(pop_x[idx])
+                pop_x[idx] = deepcopy(pop_new[idx])
+                self.dyn_USN[idx] = 0
+            else:
+                self.dyn_USN[idx] += 1
+
+        pop = deepcopy(pop_x) + deepcopy(pop_m)
+        pop_new = []
+        for idx in range(self.pop_size):
+            ## Individual phase
+            k1, k2 = np.random.choice(list(set(range(0, 2 * self.pop_size)) - {idx}), 2, replace=False)
+            #### Remove third loop here, and flight back strategy now be a random
+            pos_new = self.g_best[self.ID_POS] + np.random.uniform() * (pop[k1][self.ID_POS] - pop[k2][self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop_new = self.update_target_wrapper_population(pop_new)
+        for idx in range(0, self.pop_size):
+            if self.compare_agent(pop_new[idx], pop_x[idx]):
+                pop_m[np.random.randint(0, self.pop_size)] = deepcopy(pop_x[idx])
+                pop_x[idx] = deepcopy(pop_new[idx])
+                self.dyn_USN[idx] = 0
+            else:
+                self.dyn_USN[idx] += 1
+
+            if self.dyn_USN[idx] > self.mu:
+                pop_x[idx] = self.create_solution(self.problem.lb, self.problem.ub)
+                self.dyn_USN[idx] = 0
+        self.pop = pop_x + pop_m
+
+
+class OriginalSARO(BaseSARO):
+    """
+    The original version of: Search And Rescue Optimization (SARO)
+
+    Links:
+       1. https://doi.org/10.1155/2019/2482543
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + se (float): [0.3, 0.8], social effect, default = 0.5
+        + mu (int): [10, 20], maximum unsuccessful search number, default = 15
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.SARO import OriginalSARO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> se = 0.5
+    >>> mu = 50
+    >>> model = OriginalSARO(epoch, pop_size, se, mu)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Shabani, A., Asgarian, B., Gharebaghi, S.A., Salido, M.A. and Giret, A., 2019. A new optimization
+    algorithm based on search and rescue operations. Mathematical Problems in Engineering, 2019.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, se=0.5, mu=15, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            se (float): social effect, default = 0.5
+            mu (int): maximum unsuccessful search number, default = 15
+        """
+        super().__init__(epoch, pop_size, se, mu, **kwargs)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_x = deepcopy(self.pop[:self.pop_size])
+        pop_m = deepcopy(self.pop[self.pop_size:])
+
+        pop_new = []
+        for idx in range(self.pop_size):
+            ## Social Phase
+            k = np.random.choice(list(set(range(0, 2 * self.pop_size)) - {idx}))
+            sd = pop_x[idx][self.ID_POS] - self.pop[k][self.ID_POS]
+            j_rand = np.random.randint(0, self.problem.n_dims)
+            r1 = np.random.uniform(-1, 1)
+
+            pos_new = deepcopy(pop_x[idx][self.ID_POS])
+            for j in range(0, self.problem.n_dims):
+                if np.random.uniform() < self.se or j == j_rand:
+                    if self.compare_agent(self.pop[k], pop_x[idx]):
+                        pos_new[j] = self.pop[k][self.ID_POS][j] + r1 * sd[j]
+                    else:
+                        pos_new[j] = pop_x[idx][self.ID_POS][j] + r1 * sd[j]
+                if pos_new[j] < self.problem.lb[j]:
+                    pos_new[j] = (pop_x[idx][self.ID_POS][j] + self.problem.lb[j]) / 2
+                if pos_new[j] > self.problem.ub[j]:
+                    pos_new[j] = (pop_x[idx][self.ID_POS][j] + self.problem.ub[j]) / 2
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop_new = self.update_target_wrapper_population(pop_new)
+        for idx in range(0, self.pop_size):
+            if self.compare_agent(pop_new[idx], pop_x[idx]):
+                pop_m[np.random.randint(0, self.pop_size)] = deepcopy(pop_x[idx])
+                pop_x[idx] = deepcopy(pop_new[idx])
+                self.dyn_USN[idx] = 0
+            else:
+                self.dyn_USN[idx] += 1
+
+        ## Individual phase
+        pop = deepcopy(pop_x) + deepcopy(pop_m)
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            k, m = np.random.choice(list(set(range(0, 2 * self.pop_size)) - {idx}), 2, replace=False)
+            pos_new = pop_x[idx][self.ID_POS] + np.random.uniform() * (pop[k][self.ID_POS] - pop[m][self.ID_POS])
+            for j in range(0, self.problem.n_dims):
+                if pos_new[j] < self.problem.lb[j]:
+                    pos_new[j] = (pop_x[idx][self.ID_POS][j] + self.problem.lb[j]) / 2
+                if pos_new[j] > self.problem.ub[j]:
+                    pos_new[j] = (pop_x[idx][self.ID_POS][j] + self.problem.ub[j]) / 2
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop_new = self.update_target_wrapper_population(pop_new)
+        for idx in range(0, self.pop_size):
+            if self.compare_agent(pop_new[idx], pop_x[idx]):
+                pop_m[np.random.randint(0, self.pop_size)] = pop_x[idx]
+                pop_x[idx] = deepcopy(pop_new[idx])
+                self.dyn_USN[idx] = 0
+            else:
+                self.dyn_USN[idx] += 1
+
+            if self.dyn_USN[idx] > self.mu:
+                pop_x[idx] = self.create_solution(self.problem.lb, self.problem.ub)
+                self.dyn_USN[idx] = 0
+        self.pop = pop_x + pop_m
```

### Comparing `mealpy-2.5.3/mealpy/human_based/QSA.py` & `mealpy-2.5.3a1/mealpy/human_based/QSA.py`

 * *Ordering differences only*

 * *Files 26% similar despite different names*

```diff
@@ -1,457 +1,457 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 10:21, 18/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class BaseQSA(Optimizer):
-    """
-    The developed version: Queuing Search Algorithm (QSA)
-
-    Notes
-    ~~~~~
-    + The third loops are removed
-    + Global best solution is used in business 3-th instead of random solution
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.QSA import BaseQSA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = BaseQSA(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = True
-
-    def calculate_queue_length__(self, t1, t2, t3):
-        """
-        Calculate length of each queue based on  t1, t2,t3
-            + t1 = t1 * 1.0e+100
-            + t2 = t2 * 1.0e+100
-            + t3 = t3 * 1.0e+100
-        """
-        if t1 > 1.0e-6:
-            n1 = (1 / t1) / ((1 / t1) + (1 / t2) + (1 / t3))
-            n2 = (1 / t2) / ((1 / t1) + (1 / t2) + (1 / t3))
-        else:
-            n1 = 1.0 / 3
-            n2 = 1.0 / 3
-        q1 = int(n1 * self.pop_size)
-        q2 = int(n2 * self.pop_size)
-        q3 = self.pop_size - q1 - q2
-        return q1, q2, q3
-
-    def update_business_1__(self, pop=None, current_epoch=None):
-        A1, A2, A3 = pop[0][self.ID_POS], pop[1][self.ID_POS], pop[2][self.ID_POS]
-        t1, t2, t3 = pop[0][self.ID_TAR][self.ID_FIT], pop[1][self.ID_TAR][self.ID_FIT], pop[2][self.ID_TAR][self.ID_FIT]
-        q1, q2, q3 = self.calculate_queue_length__(t1, t2, t3)
-        case = None
-        for i in range(self.pop_size):
-            if i < q1:
-                if i == 0:
-                    case = 1
-                A = deepcopy(A1)
-            elif q1 <= i < q1 + q2:
-                if i == q1:
-                    case = 1
-                A = deepcopy(A2)
-            else:
-                if i == q1 + q2:
-                    case = 1
-                A = deepcopy(A3)
-            beta = np.power(current_epoch, np.power(current_epoch / self.epoch, 0.5))
-            alpha = np.random.uniform(-1, 1)
-            E = np.random.exponential(0.5, self.problem.n_dims)
-            F1 = beta * alpha * (E * np.abs(A - pop[i][self.ID_POS])) + np.random.exponential(0.5) * (A - pop[i][self.ID_POS])
-            F2 = beta * alpha * (E * np.abs(A - pop[i][self.ID_POS]))
-            if case == 1:
-                pos_new = A + F1
-                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                target = self.get_target_wrapper(pos_new)
-                if self.compare_agent([pos_new, target], pop[i]):
-                    pop[i] = [pos_new, target]
-                else:
-                    case = 2
-            else:
-                pos_new = pop[i][self.ID_POS] + F2
-                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                target = self.get_target_wrapper(pos_new)
-                if self.compare_agent([pos_new, target], pop[i]):
-                    pop[i] = [pos_new, target]
-                else:
-                    case = 1
-        pop, _ = self.get_global_best_solution(pop)
-        return pop
-
-    def update_business_2__(self, pop=None):
-        A1, A2, A3 = pop[0][self.ID_POS], pop[1][self.ID_POS], pop[2][self.ID_POS]
-        t1, t2, t3 = pop[0][self.ID_TAR][self.ID_FIT], pop[1][self.ID_TAR][self.ID_FIT], pop[2][self.ID_TAR][self.ID_FIT]
-        q1, q2, q3 = self.calculate_queue_length__(t1, t2, t3)
-        pr = [i / self.pop_size for i in range(1, self.pop_size + 1)]
-        if t1 > 1.0e-005:
-            cv = t1 / (t2 + t3)
-        else:
-            cv = 1.0 / 2
-        pop_new = []
-        for i in range(self.pop_size):
-            if i < q1:
-                A = deepcopy(A1)
-            elif q1 <= i < q1 + q2:
-                A = deepcopy(A2)
-            else:
-                A = deepcopy(A3)
-            if np.random.random() < pr[i]:
-                i1, i2 = np.random.choice(self.pop_size, 2, replace=False)
-                if np.random.random() < cv:
-                    X_new = pop[i][self.ID_POS] + np.random.exponential(0.5) * (pop[i1][self.ID_POS] - pop[i2][self.ID_POS])
-                else:
-                    X_new = pop[i][self.ID_POS] + np.random.exponential(0.5) * (A - pop[i1][self.ID_POS])
-            else:
-                X_new = self.generate_position(self.problem.lb, self.problem.ub)
-            pos_new = self.amend_position(X_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                pop_new[-1] = self.get_better_solution([pos_new, target], pop[i])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            pop_new = self.greedy_selection_population(pop, pop_new)
-        return self.get_sorted_strim_population(pop_new, self.pop_size)
-
-    def update_business_3__(self, pop, g_best):
-        pr = np.array([i / self.pop_size for i in range(1, self.pop_size + 1)])
-        pop_new = []
-        for i in range(self.pop_size):
-            X_new = deepcopy(pop[i][self.ID_POS])
-            id1 = np.random.choice(self.pop_size)
-            temp = g_best[self.ID_POS] + np.random.exponential(0.5, self.problem.n_dims) * (pop[id1][self.ID_POS] - pop[i][self.ID_POS])
-            X_new = np.where(np.random.random(self.problem.n_dims) > pr[i], temp, X_new)
-            pos_new = self.amend_position(X_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                pop_new[-1] = self.get_better_solution([pos_new, target], pop[i])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            pop_new = self.greedy_selection_population(pop, pop_new)
-        return pop_new
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop = self.update_business_1__(self.pop, epoch + 1)
-        pop = self.update_business_2__(pop)
-        self.pop = self.update_business_3__(pop, self.g_best)
-
-
-class OppoQSA(BaseQSA):
-    """
-    The opposition-based learning version: Queuing Search Algorithm (OQSA)
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.QSA import OppoQSA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OppoQSA(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(epoch, pop_size, **kwargs)
-        self.sort_flag = True
-
-    def opposition_based__(self, pop=None, g_best=None):
-        pop, _ = self.get_global_best_solution(pop)
-        pop_new = []
-        for i in range(0, self.pop_size):
-            X_new = self.create_opposition_position(pop[i], g_best)
-            pos_new = self.amend_position(X_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                pop_new[-1] = self.get_better_solution([pos_new, target], pop[i])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            pop_new = self.greedy_selection_population(pop, pop_new)
-        return pop_new
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop = self.update_business_1__(self.pop, epoch + 1)
-        pop = self.update_business_2__(pop)
-        pop = self.update_business_3__(pop, self.g_best)
-        self.pop = self.opposition_based__(pop, self.g_best)
-
-
-class LevyQSA(BaseQSA):
-    """
-    The Levy-flight version: Queuing Search Algorithm (LQSA)
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.QSA import LevyQSA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = LevyQSA(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(epoch, pop_size, **kwargs)
-        self.sort_flag = True
-
-    def update_business_2__(self, pop=None, current_epoch=None):
-        A1, A2, A3 = pop[0][self.ID_POS], pop[1][self.ID_POS], pop[2][self.ID_POS]
-        t1, t2, t3 = pop[0][self.ID_TAR][self.ID_FIT], pop[1][self.ID_TAR][self.ID_FIT], pop[2][self.ID_TAR][self.ID_FIT]
-        q1, q2, q3 = self.calculate_queue_length__(t1, t2, t3)
-        pr = [i / self.pop_size for i in range(1, self.pop_size + 1)]
-        if t1 > 1.0e-6:
-            cv = t1 / (t2 + t3)
-        else:
-            cv = 1 / 2
-        pop_new = []
-        for i in range(self.pop_size):
-            if i < q1:
-                A = deepcopy(A1)
-            elif q1 <= i < q1 + q2:
-                A = deepcopy(A2)
-            else:
-                A = deepcopy(A3)
-            if np.random.random() < pr[i]:
-                id1 = np.random.choice(self.pop_size)
-                if np.random.random() < cv:
-                    levy_step = self.get_levy_flight_step(beta=1.0, multiplier=0.001, case=-1)
-                    X_new = pop[i][self.ID_POS] + np.random.normal(0, 1, self.problem.n_dims) * levy_step
-                else:
-                    X_new = pop[i][self.ID_POS] + np.random.exponential(0.5) * (A - pop[id1][self.ID_POS])
-                pos_new = self.amend_position(X_new, self.problem.lb, self.problem.ub)
-            else:
-                pos_new = self.generate_position(self.problem.lb, self.problem.ub)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                pop_new[-1] = self.get_better_solution([pos_new, target], pop[i])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            pop_new = self.greedy_selection_population(pop, pop_new)
-        return self.get_sorted_strim_population(pop_new, self.pop_size)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop = self.update_business_1__(self.pop, epoch + 1)
-        pop = self.update_business_2__(pop, epoch + 1)
-        self.pop = self.update_business_3__(pop, self.g_best)
-
-
-class ImprovedQSA(OppoQSA, LevyQSA):
-    """
-    The original version of: Improved Queuing Search Algorithm (QSA)
-
-    Links:
-       1. https://doi.org/10.1007/s12652-020-02849-4
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.QSA import ImprovedQSA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = ImprovedQSA(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Nguyen, B.M., Hoang, B., Nguyen, T. and Nguyen, G., 2021. nQSV-Net: a novel queuing search variant for
-    global space search and workload modeling. Journal of Ambient Intelligence and Humanized Computing, 12(1), pp.27-46.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(epoch, pop_size, **kwargs)
-        self.sort_flag = True
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop = self.update_business_1__(self.pop, epoch + 1)
-        pop = self.update_business_2__(pop, epoch + 1)
-        pop = self.update_business_3__(pop, self.g_best)
-        self.pop = self.opposition_based__(pop, self.g_best)
-
-
-class OriginalQSA(BaseQSA):
-    """
-    The original version of: Queuing Search Algorithm (QSA)
-
-    Links:
-       1. https://www.sciencedirect.com/science/article/abs/pii/S0307904X18302890
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.QSA import OriginalQSA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalQSA(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Zhang, J., Xiao, M., Gao, L. and Pan, Q., 2018. Queuing search algorithm: A novel metaheuristic algorithm
-    for solving engineering optimization problems. Applied Mathematical Modelling, 63, pp.464-490.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(epoch, pop_size, **kwargs)
-        self.sort_flag = True
-
-    def update_business_3__(self, pop, g_best):
-        pr = [i / self.pop_size for i in range(1, self.pop_size + 1)]
-        pop_new = []
-        for i in range(self.pop_size):
-            pos_new = deepcopy(pop[i][self.ID_POS])
-            for j in range(self.problem.n_dims):
-                if np.random.random() > pr[i]:
-                    i1, i2 = np.random.choice(self.pop_size, 2, replace=False)
-                    e = np.random.exponential(0.5)
-                    X1 = pop[i1][self.ID_POS]
-                    X2 = pop[i2][self.ID_POS]
-                    pos_new[j] = X1[j] + e * (X2[j] - pop[i][self.ID_POS][j])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                pop_new[-1] = self.get_better_solution([pos_new, target], pop[i])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            pop_new = self.greedy_selection_population(pop, pop_new)
-        return pop_new
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop = self.update_business_1__(self.pop, epoch)
-        pop = self.update_business_2__(pop)
-        self.pop = self.update_business_3__(pop, self.g_best)
+#!/usr/bin/env python
+# Created by "Thieu" at 10:21, 18/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class BaseQSA(Optimizer):
+    """
+    The developed version: Queuing Search Algorithm (QSA)
+
+    Notes
+    ~~~~~
+    + The third loops are removed
+    + Global best solution is used in business 3-th instead of random solution
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.QSA import BaseQSA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = BaseQSA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = True
+
+    def calculate_queue_length__(self, t1, t2, t3):
+        """
+        Calculate length of each queue based on  t1, t2,t3
+            + t1 = t1 * 1.0e+100
+            + t2 = t2 * 1.0e+100
+            + t3 = t3 * 1.0e+100
+        """
+        if t1 > 1.0e-6:
+            n1 = (1 / t1) / ((1 / t1) + (1 / t2) + (1 / t3))
+            n2 = (1 / t2) / ((1 / t1) + (1 / t2) + (1 / t3))
+        else:
+            n1 = 1.0 / 3
+            n2 = 1.0 / 3
+        q1 = int(n1 * self.pop_size)
+        q2 = int(n2 * self.pop_size)
+        q3 = self.pop_size - q1 - q2
+        return q1, q2, q3
+
+    def update_business_1__(self, pop=None, current_epoch=None):
+        A1, A2, A3 = pop[0][self.ID_POS], pop[1][self.ID_POS], pop[2][self.ID_POS]
+        t1, t2, t3 = pop[0][self.ID_TAR][self.ID_FIT], pop[1][self.ID_TAR][self.ID_FIT], pop[2][self.ID_TAR][self.ID_FIT]
+        q1, q2, q3 = self.calculate_queue_length__(t1, t2, t3)
+        case = None
+        for i in range(self.pop_size):
+            if i < q1:
+                if i == 0:
+                    case = 1
+                A = deepcopy(A1)
+            elif q1 <= i < q1 + q2:
+                if i == q1:
+                    case = 1
+                A = deepcopy(A2)
+            else:
+                if i == q1 + q2:
+                    case = 1
+                A = deepcopy(A3)
+            beta = np.power(current_epoch, np.power(current_epoch / self.epoch, 0.5))
+            alpha = np.random.uniform(-1, 1)
+            E = np.random.exponential(0.5, self.problem.n_dims)
+            F1 = beta * alpha * (E * np.abs(A - pop[i][self.ID_POS])) + np.random.exponential(0.5) * (A - pop[i][self.ID_POS])
+            F2 = beta * alpha * (E * np.abs(A - pop[i][self.ID_POS]))
+            if case == 1:
+                pos_new = A + F1
+                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                target = self.get_target_wrapper(pos_new)
+                if self.compare_agent([pos_new, target], pop[i]):
+                    pop[i] = [pos_new, target]
+                else:
+                    case = 2
+            else:
+                pos_new = pop[i][self.ID_POS] + F2
+                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                target = self.get_target_wrapper(pos_new)
+                if self.compare_agent([pos_new, target], pop[i]):
+                    pop[i] = [pos_new, target]
+                else:
+                    case = 1
+        pop, _ = self.get_global_best_solution(pop)
+        return pop
+
+    def update_business_2__(self, pop=None):
+        A1, A2, A3 = pop[0][self.ID_POS], pop[1][self.ID_POS], pop[2][self.ID_POS]
+        t1, t2, t3 = pop[0][self.ID_TAR][self.ID_FIT], pop[1][self.ID_TAR][self.ID_FIT], pop[2][self.ID_TAR][self.ID_FIT]
+        q1, q2, q3 = self.calculate_queue_length__(t1, t2, t3)
+        pr = [i / self.pop_size for i in range(1, self.pop_size + 1)]
+        if t1 > 1.0e-005:
+            cv = t1 / (t2 + t3)
+        else:
+            cv = 1.0 / 2
+        pop_new = []
+        for i in range(self.pop_size):
+            if i < q1:
+                A = deepcopy(A1)
+            elif q1 <= i < q1 + q2:
+                A = deepcopy(A2)
+            else:
+                A = deepcopy(A3)
+            if np.random.random() < pr[i]:
+                i1, i2 = np.random.choice(self.pop_size, 2, replace=False)
+                if np.random.random() < cv:
+                    X_new = pop[i][self.ID_POS] + np.random.exponential(0.5) * (pop[i1][self.ID_POS] - pop[i2][self.ID_POS])
+                else:
+                    X_new = pop[i][self.ID_POS] + np.random.exponential(0.5) * (A - pop[i1][self.ID_POS])
+            else:
+                X_new = self.generate_position(self.problem.lb, self.problem.ub)
+            pos_new = self.amend_position(X_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                pop_new[-1] = self.get_better_solution([pos_new, target], pop[i])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            pop_new = self.greedy_selection_population(pop, pop_new)
+        return self.get_sorted_strim_population(pop_new, self.pop_size)
+
+    def update_business_3__(self, pop, g_best):
+        pr = np.array([i / self.pop_size for i in range(1, self.pop_size + 1)])
+        pop_new = []
+        for i in range(self.pop_size):
+            X_new = deepcopy(pop[i][self.ID_POS])
+            id1 = np.random.choice(self.pop_size)
+            temp = g_best[self.ID_POS] + np.random.exponential(0.5, self.problem.n_dims) * (pop[id1][self.ID_POS] - pop[i][self.ID_POS])
+            X_new = np.where(np.random.random(self.problem.n_dims) > pr[i], temp, X_new)
+            pos_new = self.amend_position(X_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                pop_new[-1] = self.get_better_solution([pos_new, target], pop[i])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            pop_new = self.greedy_selection_population(pop, pop_new)
+        return pop_new
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop = self.update_business_1__(self.pop, epoch + 1)
+        pop = self.update_business_2__(pop)
+        self.pop = self.update_business_3__(pop, self.g_best)
+
+
+class OppoQSA(BaseQSA):
+    """
+    The opposition-based learning version: Queuing Search Algorithm (OQSA)
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.QSA import OppoQSA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OppoQSA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(epoch, pop_size, **kwargs)
+        self.sort_flag = True
+
+    def opposition_based__(self, pop=None, g_best=None):
+        pop, _ = self.get_global_best_solution(pop)
+        pop_new = []
+        for i in range(0, self.pop_size):
+            X_new = self.create_opposition_position(pop[i], g_best)
+            pos_new = self.amend_position(X_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                pop_new[-1] = self.get_better_solution([pos_new, target], pop[i])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            pop_new = self.greedy_selection_population(pop, pop_new)
+        return pop_new
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop = self.update_business_1__(self.pop, epoch + 1)
+        pop = self.update_business_2__(pop)
+        pop = self.update_business_3__(pop, self.g_best)
+        self.pop = self.opposition_based__(pop, self.g_best)
+
+
+class LevyQSA(BaseQSA):
+    """
+    The Levy-flight version: Queuing Search Algorithm (LQSA)
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.QSA import LevyQSA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = LevyQSA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(epoch, pop_size, **kwargs)
+        self.sort_flag = True
+
+    def update_business_2__(self, pop=None, current_epoch=None):
+        A1, A2, A3 = pop[0][self.ID_POS], pop[1][self.ID_POS], pop[2][self.ID_POS]
+        t1, t2, t3 = pop[0][self.ID_TAR][self.ID_FIT], pop[1][self.ID_TAR][self.ID_FIT], pop[2][self.ID_TAR][self.ID_FIT]
+        q1, q2, q3 = self.calculate_queue_length__(t1, t2, t3)
+        pr = [i / self.pop_size for i in range(1, self.pop_size + 1)]
+        if t1 > 1.0e-6:
+            cv = t1 / (t2 + t3)
+        else:
+            cv = 1 / 2
+        pop_new = []
+        for i in range(self.pop_size):
+            if i < q1:
+                A = deepcopy(A1)
+            elif q1 <= i < q1 + q2:
+                A = deepcopy(A2)
+            else:
+                A = deepcopy(A3)
+            if np.random.random() < pr[i]:
+                id1 = np.random.choice(self.pop_size)
+                if np.random.random() < cv:
+                    levy_step = self.get_levy_flight_step(beta=1.0, multiplier=0.001, case=-1)
+                    X_new = pop[i][self.ID_POS] + np.random.normal(0, 1, self.problem.n_dims) * levy_step
+                else:
+                    X_new = pop[i][self.ID_POS] + np.random.exponential(0.5) * (A - pop[id1][self.ID_POS])
+                pos_new = self.amend_position(X_new, self.problem.lb, self.problem.ub)
+            else:
+                pos_new = self.generate_position(self.problem.lb, self.problem.ub)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                pop_new[-1] = self.get_better_solution([pos_new, target], pop[i])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            pop_new = self.greedy_selection_population(pop, pop_new)
+        return self.get_sorted_strim_population(pop_new, self.pop_size)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop = self.update_business_1__(self.pop, epoch + 1)
+        pop = self.update_business_2__(pop, epoch + 1)
+        self.pop = self.update_business_3__(pop, self.g_best)
+
+
+class ImprovedQSA(OppoQSA, LevyQSA):
+    """
+    The original version of: Improved Queuing Search Algorithm (QSA)
+
+    Links:
+       1. https://doi.org/10.1007/s12652-020-02849-4
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.QSA import ImprovedQSA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = ImprovedQSA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Nguyen, B.M., Hoang, B., Nguyen, T. and Nguyen, G., 2021. nQSV-Net: a novel queuing search variant for
+    global space search and workload modeling. Journal of Ambient Intelligence and Humanized Computing, 12(1), pp.27-46.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(epoch, pop_size, **kwargs)
+        self.sort_flag = True
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop = self.update_business_1__(self.pop, epoch + 1)
+        pop = self.update_business_2__(pop, epoch + 1)
+        pop = self.update_business_3__(pop, self.g_best)
+        self.pop = self.opposition_based__(pop, self.g_best)
+
+
+class OriginalQSA(BaseQSA):
+    """
+    The original version of: Queuing Search Algorithm (QSA)
+
+    Links:
+       1. https://www.sciencedirect.com/science/article/abs/pii/S0307904X18302890
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.QSA import OriginalQSA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalQSA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Zhang, J., Xiao, M., Gao, L. and Pan, Q., 2018. Queuing search algorithm: A novel metaheuristic algorithm
+    for solving engineering optimization problems. Applied Mathematical Modelling, 63, pp.464-490.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(epoch, pop_size, **kwargs)
+        self.sort_flag = True
+
+    def update_business_3__(self, pop, g_best):
+        pr = [i / self.pop_size for i in range(1, self.pop_size + 1)]
+        pop_new = []
+        for i in range(self.pop_size):
+            pos_new = deepcopy(pop[i][self.ID_POS])
+            for j in range(self.problem.n_dims):
+                if np.random.random() > pr[i]:
+                    i1, i2 = np.random.choice(self.pop_size, 2, replace=False)
+                    e = np.random.exponential(0.5)
+                    X1 = pop[i1][self.ID_POS]
+                    X2 = pop[i2][self.ID_POS]
+                    pos_new[j] = X1[j] + e * (X2[j] - pop[i][self.ID_POS][j])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                pop_new[-1] = self.get_better_solution([pos_new, target], pop[i])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            pop_new = self.greedy_selection_population(pop, pop_new)
+        return pop_new
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop = self.update_business_1__(self.pop, epoch)
+        pop = self.update_business_2__(pop)
+        self.pop = self.update_business_3__(pop, self.g_best)
```

### Comparing `mealpy-2.5.3/mealpy/human_based/SARO.py` & `mealpy-2.5.3a1/mealpy/swarm_based/SFO.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,265 +1,262 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 11:16, 18/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class BaseSARO(Optimizer):
-    """
-    The developed version: Search And Rescue Optimization (SARO)
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + se (float): [0.3, 0.8], social effect, default = 0.5
-        + mu (int): maximum unsuccessful search number, belongs to range: [2, 2+int(self.pop_size/2)], default = 15
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.SARO import BaseSARO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> se = 0.5
-    >>> mu = 50
-    >>> model = BaseSARO(epoch, pop_size, se, mu)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, se=0.5, mu=15, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            se (float): social effect, default = 0.5
-            mu (int): maximum unsuccessful search number, default = 15
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.se = self.validator.check_float("se", se, (0, 1.0))
-        self.mu = self.validator.check_int("mu", mu, [2, 2+int(self.pop_size/2)])
-        self.set_parameters(["epoch", "pop_size", "se", "mu"])
-        self.sort_flag = True
-
-    def initialize_variables(self):
-        self.dyn_USN = np.zeros(self.pop_size)
-
-    def initialization(self):
-        if self.pop is None:
-            self.pop = self.create_population(2 * self.pop_size)
-        else:
-            self.pop = self.pop + self.create_population(self.pop_size)
-
-    def amend_position(self, position=None, lb=None, ub=None):
-        """
-        Depend on what kind of problem are we trying to solve, there will be an different amend_position
-        function to rebound the position of agent into the valid range.
-
-        Args:
-            position: vector position (location) of the solution.
-            lb: list of lower bound values
-            ub: list of upper bound values
-
-        Returns:
-            Amended position (make the position is in bound)
-        """
-        condition = np.logical_and(lb <= position, position <= ub)
-        rand_pos = np.random.uniform(lb, ub)
-        return np.where(condition, position, rand_pos)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_x = deepcopy(self.pop[:self.pop_size])
-        pop_m = deepcopy(self.pop[self.pop_size:])
-
-        pop_new = []
-        for idx in range(self.pop_size):
-            ## Social Phase
-            k = np.random.choice(list(set(range(0, 2 * self.pop_size)) - {idx}))
-            sd = pop_x[idx][self.ID_POS] - self.pop[k][self.ID_POS]
-
-            #### Remove third loop here, also using random flight back when out of bound
-            pos_new_1 = self.pop[k][self.ID_POS] + np.random.uniform() * sd
-            pos_new_2 = pop_x[idx][self.ID_POS] + np.random.uniform() * sd
-            pos_new = np.where(np.logical_and(np.random.uniform(0, 1, self.problem.n_dims) < self.se,
-                                              self.pop[k][self.ID_TAR] < pop_x[idx][self.ID_TAR]), pos_new_1, pos_new_2)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop_new = self.update_target_wrapper_population(pop_new)
-        for idx in range(self.pop_size):
-            if self.compare_agent(pop_new[idx], pop_x[idx]):
-                pop_m[np.random.randint(0, self.pop_size)] = deepcopy(pop_x[idx])
-                pop_x[idx] = deepcopy(pop_new[idx])
-                self.dyn_USN[idx] = 0
-            else:
-                self.dyn_USN[idx] += 1
-
-        pop = deepcopy(pop_x) + deepcopy(pop_m)
-        pop_new = []
-        for idx in range(self.pop_size):
-            ## Individual phase
-            k1, k2 = np.random.choice(list(set(range(0, 2 * self.pop_size)) - {idx}), 2, replace=False)
-            #### Remove third loop here, and flight back strategy now be a random
-            pos_new = self.g_best[self.ID_POS] + np.random.uniform() * (pop[k1][self.ID_POS] - pop[k2][self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop_new = self.update_target_wrapper_population(pop_new)
-        for idx in range(0, self.pop_size):
-            if self.compare_agent(pop_new[idx], pop_x[idx]):
-                pop_m[np.random.randint(0, self.pop_size)] = deepcopy(pop_x[idx])
-                pop_x[idx] = deepcopy(pop_new[idx])
-                self.dyn_USN[idx] = 0
-            else:
-                self.dyn_USN[idx] += 1
-
-            if self.dyn_USN[idx] > self.mu:
-                pop_x[idx] = self.create_solution(self.problem.lb, self.problem.ub)
-                self.dyn_USN[idx] = 0
-        self.pop = pop_x + pop_m
-
-
-class OriginalSARO(BaseSARO):
-    """
-    The original version of: Search And Rescue Optimization (SARO)
-
-    Links:
-       1. https://doi.org/10.1155/2019/2482543
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + se (float): [0.3, 0.8], social effect, default = 0.5
-        + mu (int): [10, 20], maximum unsuccessful search number, default = 15
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.SARO import OriginalSARO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> se = 0.5
-    >>> mu = 50
-    >>> model = OriginalSARO(epoch, pop_size, se, mu)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Shabani, A., Asgarian, B., Gharebaghi, S.A., Salido, M.A. and Giret, A., 2019. A new optimization
-    algorithm based on search and rescue operations. Mathematical Problems in Engineering, 2019.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, se=0.5, mu=15, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            se (float): social effect, default = 0.5
-            mu (int): maximum unsuccessful search number, default = 15
-        """
-        super().__init__(epoch, pop_size, se, mu, **kwargs)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_x = deepcopy(self.pop[:self.pop_size])
-        pop_m = deepcopy(self.pop[self.pop_size:])
-
-        pop_new = []
-        for idx in range(self.pop_size):
-            ## Social Phase
-            k = np.random.choice(list(set(range(0, 2 * self.pop_size)) - {idx}))
-            sd = pop_x[idx][self.ID_POS] - self.pop[k][self.ID_POS]
-            j_rand = np.random.randint(0, self.problem.n_dims)
-            r1 = np.random.uniform(-1, 1)
-
-            pos_new = deepcopy(pop_x[idx][self.ID_POS])
-            for j in range(0, self.problem.n_dims):
-                if np.random.uniform() < self.se or j == j_rand:
-                    if self.compare_agent(self.pop[k], pop_x[idx]):
-                        pos_new[j] = self.pop[k][self.ID_POS][j] + r1 * sd[j]
-                    else:
-                        pos_new[j] = pop_x[idx][self.ID_POS][j] + r1 * sd[j]
-                if pos_new[j] < self.problem.lb[j]:
-                    pos_new[j] = (pop_x[idx][self.ID_POS][j] + self.problem.lb[j]) / 2
-                if pos_new[j] > self.problem.ub[j]:
-                    pos_new[j] = (pop_x[idx][self.ID_POS][j] + self.problem.ub[j]) / 2
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop_new = self.update_target_wrapper_population(pop_new)
-        for idx in range(0, self.pop_size):
-            if self.compare_agent(pop_new[idx], pop_x[idx]):
-                pop_m[np.random.randint(0, self.pop_size)] = deepcopy(pop_x[idx])
-                pop_x[idx] = deepcopy(pop_new[idx])
-                self.dyn_USN[idx] = 0
-            else:
-                self.dyn_USN[idx] += 1
-
-        ## Individual phase
-        pop = deepcopy(pop_x) + deepcopy(pop_m)
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            k, m = np.random.choice(list(set(range(0, 2 * self.pop_size)) - {idx}), 2, replace=False)
-            pos_new = pop_x[idx][self.ID_POS] + np.random.uniform() * (pop[k][self.ID_POS] - pop[m][self.ID_POS])
-            for j in range(0, self.problem.n_dims):
-                if pos_new[j] < self.problem.lb[j]:
-                    pos_new[j] = (pop_x[idx][self.ID_POS][j] + self.problem.lb[j]) / 2
-                if pos_new[j] > self.problem.ub[j]:
-                    pos_new[j] = (pop_x[idx][self.ID_POS][j] + self.problem.ub[j]) / 2
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop_new = self.update_target_wrapper_population(pop_new)
-        for idx in range(0, self.pop_size):
-            if self.compare_agent(pop_new[idx], pop_x[idx]):
-                pop_m[np.random.randint(0, self.pop_size)] = pop_x[idx]
-                pop_x[idx] = deepcopy(pop_new[idx])
-                self.dyn_USN[idx] = 0
-            else:
-                self.dyn_USN[idx] += 1
-
-            if self.dyn_USN[idx] > self.mu:
-                pop_x[idx] = self.create_solution(self.problem.lb, self.problem.ub)
-                self.dyn_USN[idx] = 0
-        self.pop = pop_x + pop_m
+#!/usr/bin/env python
+# Created by "Thieu" at 14:51, 17/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalSFO(Optimizer):
+    """
+    The original version of: SailFish Optimizer (SFO)
+
+    Links:
+        1. https://doi.org/10.1016/j.engappai.2019.01.001
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + pp (float): the rate between SailFish and Sardines (N_sf = N_s * pp) = 0.25, 0.2, 0.1
+        + AP (float): coefficient for decreasing the value of Attack Power linearly from AP to 0
+        + epsilon (float): should be 0.0001, 0.001
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.SFO import OriginalSFO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> pp = 0.1
+    >>> AP = 4.0
+    >>> epsilon = 0.0001
+    >>> model = OriginalSFO(epoch, pop_size, pp, AP, epsilon)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Shadravan, S., Naji, H.R. and Bardsiri, V.K., 2019. The Sailfish Optimizer: A novel
+    nature-inspired metaheuristic algorithm for solving constrained engineering optimization
+    problems. Engineering Applications of Artificial Intelligence, 80, pp.20-34.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, pp=0.1, AP=4.0, epsilon=0.0001, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100, SailFish pop size
+            pp (float): the rate between SailFish and Sardines (N_sf = N_s * pp) = 0.25, 0.2, 0.1
+            AP (float): coefficient for decreasing the value of Power Attack linearly from AP to 0
+            epsilon (float): should be 0.0001, 0.001
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.pp = self.validator.check_float("pp", pp, (0, 1.0))
+        self.AP = self.validator.check_float("AP", AP, (0, 100))
+        self.epsilon = self.validator.check_float("epsilon", epsilon, (0, 0.1))
+        self.set_parameters(["epoch", "pop_size", "pp", "AP", "epsilon"])
+        self.sort_flag = True
+        self.s_size = int(self.pop_size / self.pp)
+
+    def initialization(self):
+        if self.pop is None:
+            self.pop = self.create_population(self.pop_size)    # pop = sailfish
+        self.s_pop = self.create_population(self.s_size)
+        _, self.s_gbest = self.get_global_best_solution(self.s_pop)  # s_pop = sardines
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        ## Calculate lamda_i using Eq.(7)
+        ## Update the position of sailfish using Eq.(6)
+        pop_new = []
+        PD = 1 - self.pop_size / (self.pop_size + self.s_size)
+        for idx in range(0, self.pop_size):
+            lamda_i = 2 * np.random.uniform() * PD - PD
+            pos_new = self.s_gbest[self.ID_POS] - lamda_i * \
+                (np.random.uniform() * (self.pop[idx][self.ID_POS] + self.s_gbest[self.ID_POS]) / 2 - self.pop[idx][self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+        ## Calculate AttackPower using Eq.(10)
+        AP = self.AP * (1 - 2 * (epoch + 1) * self.epsilon)
+        if AP < 0.5:
+            alpha = int(self.s_size * np.abs(AP))
+            beta = int(self.problem.n_dims * np.abs(AP))
+            ### Random np.random.choice number of sardines which will be updated their position
+            list1 = np.random.choice(range(0, self.s_size), alpha)
+            for i in range(0, self.s_size):
+                if i in list1:
+                    #### Random np.random.choice number of dimensions in sardines updated, remove third loop by numpy vector computation
+                    pos_new = deepcopy(self.s_pop[i][self.ID_POS])
+                    list2 = np.random.choice(range(0, self.problem.n_dims), beta, replace=False)
+                    pos_new[list2] = (np.random.uniform(0, 1, self.problem.n_dims) *
+                                      (self.pop[self.ID_POS] - self.s_pop[i][self.ID_POS] + AP))[list2]
+                    pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                    self.s_pop[i] = [pos_new, None]
+        else:
+            ### Update the position of all sardine using Eq.(9)
+            for i in range(0, self.s_size):
+                pos_new = np.random.uniform() * (self.g_best[self.ID_POS] - self.s_pop[i][self.ID_POS] + AP)
+                self.s_pop[i][self.ID_POS] = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+        ## Recalculate the fitness of all sardine
+        self.s_pop = self.update_target_wrapper_population(self.s_pop)
+
+        ## Sort the population of sailfish and sardine (for reducing computational cost)
+        self.pop, g_best = self.get_global_best_solution(self.pop)
+        self.s_pop, s_gbest = self.get_global_best_solution(self.s_pop)
+        for i in range(0, self.pop_size):
+            for j in range(0, self.s_size):
+                ### If there is a better position in sardine population.
+                if self.compare_agent(self.s_pop[j], self.pop[i]):
+                    self.pop[i] = deepcopy(self.s_pop[j])
+                    del self.s_pop[j]
+                break  #### This simple keyword helped reducing ton of comparing operation.
+                #### Especially when sardine pop size >> sailfish pop size
+        temp = self.s_size - len(self.s_pop)
+        if temp == 1:
+            self.s_pop = self.s_pop + [self.create_solution(self.problem.lb, self.problem.ub)]
+        else:
+            self.s_pop = self.s_pop + self.create_population(self.s_size - len(self.s_pop))
+        _, self.s_gbest = self.get_global_best_solution(self.s_pop)
+
+
+class ImprovedSFO(Optimizer):
+    """
+    The original version: Improved Sailfish Optimizer (I-SFO)
+
+    Notes
+    ~~~~~
+    + Energy equation is reformed
+    + AP (A) and epsilon parameters are removed
+    + Opposition-based learning technique is used
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + pp (float): the rate between SailFish and Sardines (N_sf = N_s * pp) = 0.25, 0.2, 0.1
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.SFO import ImprovedSFO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> pp = 0.1
+    >>> model = ImprovedSFO(epoch, pop_size, pp)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Socha, K. and Dorigo, M., 2008. Ant colony optimization for continuous domains.
+    European journal of operational research, 185(3), pp.1155-1173.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, pp=0.1, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100, SailFish pop size
+            pp (float): the rate between SailFish and Sardines (N_sf = N_s * pp) = 0.25, 0.2, 0.1
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.pp = self.validator.check_float("pp", pp, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "pp"])
+        self.sort_flag = True
+        self.s_size = int(self.pop_size / self.pp)
+
+    def initialization(self):
+        if self.pop is None:
+            self.pop = self.create_population(self.pop_size)
+        self.s_pop = self.create_population(self.s_size)
+        _, self.s_gbest = self.get_global_best_solution(self.s_pop)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        ## Calculate lamda_i using Eq.(7)
+        ## Update the position of sailfish using Eq.(6)
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            PD = 1 - len(self.pop) / (len(self.pop) + len(self.s_pop))
+            lamda_i = 2 * np.random.uniform() * PD - PD
+            pos_new = self.s_gbest[self.ID_POS] - \
+                lamda_i * (np.random.uniform() * (self.g_best[self.ID_POS] + self.s_gbest[self.ID_POS]) / 2 - self.pop[idx][self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+        ## ## Calculate AttackPower using my Eq.thieu
+        #### This is our proposed, simple but effective, no need A and epsilon parameters
+        AP = 1 - epoch * 1.0 / self.epoch
+        if AP < 0.5:
+            for i in range(0, len(self.s_pop)):
+                temp = (self.g_best[self.ID_POS] + AP) / 2
+                pos_new = self.problem.lb + self.problem.ub - temp + np.random.uniform() * (temp - self.s_pop[i][self.ID_POS])
+                self.s_pop[i][self.ID_POS] = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+        else:
+            ### Update the position of all sardine using Eq.(9)
+            for i in range(0, len(self.s_pop)):
+                pos_new = np.random.uniform() * (self.g_best[self.ID_POS] - self.s_pop[i][self.ID_POS] + AP)
+                self.s_pop[i][self.ID_POS] = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+        ## Recalculate the fitness of all sardine
+        self.s_pop = self.update_target_wrapper_population(self.s_pop)
+
+        ## Sort the population of sailfish and sardine (for reducing computational cost)
+        self.pop = self.get_sorted_strim_population(self.pop, self.pop_size)
+        self.s_pop = self.get_sorted_strim_population(self.s_pop, len(self.s_pop))
+        for i in range(0, self.pop_size):
+            for j in range(0, len(self.s_pop)):
+                ### If there is a better position in sardine population.
+                if self.compare_agent(self.s_pop[j], self.pop[i]):
+                    self.pop[i] = deepcopy(self.s_pop[j])
+                    del self.s_pop[j]
+                break  #### This simple keyword helped reducing ton of comparing operation.
+                #### Especially when sardine pop size >> sailfish pop size
+
+        self.s_pop = self.s_pop + self.create_population(self.s_size - len(self.s_pop))
+        _, self.s_gbest = self.get_global_best_solution(self.s_pop)
```

### Comparing `mealpy-2.5.3/mealpy/human_based/SPBO.py` & `mealpy-2.5.3a1/mealpy/human_based/SPBO.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,162 +1,162 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 17:19, 21/05/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalSPBO(Optimizer):
-    """
-    The original version of: Student Psychology Based Optimization (SPBO)
-
-    Notes:
-        1. This algorithm is a weak algorithm in solving several problems
-        2. It also consumes too much time because of ndim * pop_size updating times.
-
-    Links:
-       1. https://www.sciencedirect.com/science/article/abs/pii/S0965997820301484
-       2. https://www.mathworks.com/matlabcentral/fileexchange/80991-student-psycology-based-optimization-spbo-algorithm
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.SPBO import OriginalSPBO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalSPBO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Das, B., Mukherjee, V., & Das, D. (2020). Student psychology based optimization algorithm: A new population based
-    optimization algorithm for solving optimization problems. Advances in Engineering software, 146, 102804.
-    """
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        for jdx in range(0, self.problem.n_dims):
-            idx_best = self.get_index_best(self.pop)
-            mid = np.random.randint(1, self.pop_size-1)
-            x_mean = np.mean([agent[self.ID_POS] for agent in self.pop], axis=0)
-            pop_new = []
-            for idx in range(0, self.pop_size):
-                if idx == idx_best:
-                    k = np.random.choice([1, 2])
-                    j = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
-                    new_pos = self.g_best[self.ID_POS] + (-1)**k * np.random.rand() * (self.g_best[self.ID_POS] - self.pop[j][self.ID_POS])
-                elif idx < mid:
-                    ## Good Student
-                    if np.random.rand() > np.random.rand():
-                        new_pos = self.g_best[self.ID_POS] + np.random.rand() * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-                    else:
-                        new_pos = self.pop[idx][self.ID_POS] + np.random.rand() * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) + \
-                            np.random.rand() * (self.pop[idx][self.ID_POS] - x_mean)
-                else:
-                    ## Average Student
-                    if np.random.rand() > np.random.rand():
-                        new_pos = self.pop[idx][self.ID_POS] + np.random.rand() * (x_mean - self.pop[idx][self.ID_POS])
-                    else:
-                        new_pos = self.generate_position(self.problem.lb, self.problem.ub)
-                new_pos = self.amend_position(new_pos, self.problem.lb, self.problem.ub)
-                pop_new.append([new_pos, None])
-                if self.mode not in self.AVAILABLE_MODES:
-                    new_tar = self.get_target_wrapper(new_pos)
-                    self.pop[idx] = self.get_better_solution([new_pos, new_tar], self.pop[idx])
-            if self.mode in self.AVAILABLE_MODES:
-                pop_new = self.update_target_wrapper_population(pop_new)
-                self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-
-class DevSPBO(OriginalSPBO):
-    """
-    The developed version of: Student Psychology Based Optimization (SPBO)
-
-    Notes:
-        1. Replace random number by normal random number
-        2. Sort the population and select 1/3 pop size for each category
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.SPBO import DevSPBO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = DevSPBO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        super().__init__(epoch, pop_size, **kwargs)
-        self.sort_flag = True
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        good = int(self.pop_size / 3)
-        average = 2 * int(self.pop_size / 3)
-        x_mean = np.mean([agent[self.ID_POS] for agent in self.pop], axis=0)
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            if idx == 0:
-                j = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
-                new_pos = self.g_best[self.ID_POS] + np.random.random(self.problem.n_dims) * (self.g_best[self.ID_POS] - self.pop[j][self.ID_POS])
-            elif idx < good:    ## Good Student
-                if np.random.rand() > np.random.rand():
-                    new_pos = self.g_best[self.ID_POS] + np.random.normal(0, 1) * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-                else:
-                    ra = np.random.rand()
-                    new_pos = self.pop[idx][self.ID_POS] + ra * \
-                              (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) + (1 - ra) * (self.pop[idx][self.ID_POS] - x_mean)
-            elif idx < average:  ## Average Student
-                new_pos = self.pop[idx][self.ID_POS] + np.random.normal(0, 1) * (x_mean - self.pop[idx][self.ID_POS])
-            else:
-                new_pos = self.generate_position(self.problem.lb, self.problem.ub)
-            new_pos = self.amend_position(new_pos, self.problem.lb, self.problem.ub)
-            pop_new.append([new_pos, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                new_tar = self.get_target_wrapper(new_pos)
-                self.pop[idx] = self.get_better_solution([new_pos, new_tar], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 17:19, 21/05/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalSPBO(Optimizer):
+    """
+    The original version of: Student Psychology Based Optimization (SPBO)
+
+    Notes:
+        1. Weak algorithm
+        2. Consume too much time because of ndim * pop_size updating times.
+
+    Links:
+       1. https://www.sciencedirect.com/science/article/abs/pii/S0965997820301484
+       2. https://www.mathworks.com/matlabcentral/fileexchange/80991-student-psycology-based-optimization-spbo-algorithm
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.SPBO import OriginalSPBO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalSPBO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Das, B., Mukherjee, V., & Das, D. (2020). Student psychology based optimization algorithm: A new population based
+    optimization algorithm for solving optimization problems. Advances in Engineering software, 146, 102804.
+    """
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        for jdx in range(0, self.problem.n_dims):
+            idx_best = self.get_index_best(self.pop)
+            mid = np.random.randint(1, self.pop_size-1)
+            x_mean = np.mean([agent[self.ID_POS] for agent in self.pop], axis=0)
+            pop_new = []
+            for idx in range(0, self.pop_size):
+                if idx == idx_best:
+                    k = np.random.choice([1, 2])
+                    j = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
+                    new_pos = self.g_best[self.ID_POS] + (-1)**k * np.random.rand() * (self.g_best[self.ID_POS] - self.pop[j][self.ID_POS])
+                elif idx < mid:
+                    ## Good Student
+                    if np.random.rand() > np.random.rand():
+                        new_pos = self.g_best[self.ID_POS] + np.random.rand() * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+                    else:
+                        new_pos = self.pop[idx][self.ID_POS] + np.random.rand() * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) + \
+                            np.random.rand() * (self.pop[idx][self.ID_POS] - x_mean)
+                else:
+                    ## Average Student
+                    if np.random.rand() > np.random.rand():
+                        new_pos = self.pop[idx][self.ID_POS] + np.random.rand() * (x_mean - self.pop[idx][self.ID_POS])
+                    else:
+                        new_pos = self.generate_position(self.problem.lb, self.problem.ub)
+                new_pos = self.amend_position(new_pos, self.problem.lb, self.problem.ub)
+                pop_new.append([new_pos, None])
+                if self.mode not in self.AVAILABLE_MODES:
+                    new_tar = self.get_target_wrapper(new_pos)
+                    self.pop[idx] = self.get_better_solution([new_pos, new_tar], self.pop[idx])
+            if self.mode in self.AVAILABLE_MODES:
+                pop_new = self.update_target_wrapper_population(pop_new)
+                self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+
+class DevSPBO(OriginalSPBO):
+    """
+    The developed version of: Student Psychology Based Optimization (SPBO)
+
+    Notes:
+        1. Replace random number by normal random number
+        2. Sort the population and select 1/3 pop size for each category
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.SPBO import DevSPBO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = DevSPBO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        super().__init__(epoch, pop_size, **kwargs)
+        self.sort_flag = True
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        good = int(self.pop_size / 3)
+        average = 2 * int(self.pop_size / 3)
+        x_mean = np.mean([agent[self.ID_POS] for agent in self.pop], axis=0)
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            if idx == 0:
+                j = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
+                new_pos = self.g_best[self.ID_POS] + np.random.random(self.problem.n_dims) * (self.g_best[self.ID_POS] - self.pop[j][self.ID_POS])
+            elif idx < good:    ## Good Student
+                if np.random.rand() > np.random.rand():
+                    new_pos = self.g_best[self.ID_POS] + np.random.normal(0, 1) * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+                else:
+                    ra = np.random.rand()
+                    new_pos = self.pop[idx][self.ID_POS] + ra * \
+                              (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) + (1 - ra) * (self.pop[idx][self.ID_POS] - x_mean)
+            elif idx < average:  ## Average Student
+                new_pos = self.pop[idx][self.ID_POS] + np.random.normal(0, 1) * (x_mean - self.pop[idx][self.ID_POS])
+            else:
+                new_pos = self.generate_position(self.problem.lb, self.problem.ub)
+            new_pos = self.amend_position(new_pos, self.problem.lb, self.problem.ub)
+            pop_new.append([new_pos, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                new_tar = self.get_target_wrapper(new_pos)
+                self.pop[idx] = self.get_better_solution([new_pos, new_tar], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/human_based/SSDO.py` & `mealpy-2.5.3a1/mealpy/human_based/SSDO.py`

 * *Ordering differences only*

 * *Files 9% similar despite different names*

```diff
@@ -1,113 +1,113 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 11:17, 18/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalSSDO(Optimizer):
-    """
-    The original version of: Social Ski-Driver Optimization (SSDO)
-
-    Links:
-       1. https://doi.org/10.1007/s00521-019-04159-z
-       2. https://www.mathworks.com/matlabcentral/fileexchange/71210-social-ski-driver-ssd-optimization-algorithm-2019
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.SSDO import OriginalSSDO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalSSDO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Tharwat, A. and Gabel, T., 2020. Parameters optimization of support vector machines for imbalanced
-    data using social ski driver algorithm. Neural Computing and Applications, 32(11), pp.6925-6938.
-    """
-
-    ID_VEL = 2
-    ID_LOC = 3
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        """
-        Overriding method in Optimizer class
-
-        Returns:
-            list: wrapper of solution with format [position, target, velocity, best_local_position]
-        """
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        position = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(position)
-        velocity = np.random.uniform(lb, ub)
-        pos_local = deepcopy(position)
-        return [position, target, velocity, pos_local]
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        c = 2 - epoch * (2.0 / self.epoch)  # a decreases linearly from 2 to 0
-
-        ## Calculate the mean of the best three solutions in each dimension. Eq 9
-        _, pop_best3, _ = self.get_special_solutions(self.pop, best=3)
-        pos_mean = np.mean(np.array([item[self.ID_POS] for item in pop_best3]))
-
-        pop_new = deepcopy(self.pop)
-        # Updating velocity vectors
-        r1 = np.random.uniform()  # r1, r2 is a random number in [0,1]
-        r2 = np.random.uniform()
-        for i in range(0, self.pop_size):
-            if r2 <= 0.5:  ## Use Sine function to move
-                vel_new = c * np.sin(r1) * (self.pop[i][self.ID_LOC] - self.pop[i][self.ID_POS]) + (2-c)*np.sin(r1) * (pos_mean - self.pop[i][self.ID_POS])
-            else:  ## Use Cosine function to move
-                vel_new = c * np.cos(r1) * (self.pop[i][self.ID_LOC] - self.pop[i][self.ID_POS]) + (2-c)*np.cos(r1) * (pos_mean - self.pop[i][self.ID_POS])
-            pop_new[i][self.ID_VEL] = vel_new
-
-        ## Reproduction
-        for idx in range(0, self.pop_size):
-            pos_new = np.random.normal(0, 1, self.problem.n_dims) * pop_new[idx][self.ID_POS] + np.random.rand() * pop_new[idx][self.ID_VEL]
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new[idx][self.ID_LOC] = self.pop[idx][self.ID_POS]
-            pop_new[idx][self.ID_POS] = pos_new
-            if self.mode not in self.AVAILABLE_MODES:
-                old = deepcopy(pop_new[idx])
-                old[self.ID_TAR] = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution(pop_new[idx], old)
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 11:17, 18/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalSSDO(Optimizer):
+    """
+    The original version of: Social Ski-Driver Optimization (SSDO)
+
+    Links:
+       1. https://doi.org/10.1007/s00521-019-04159-z
+       2. https://www.mathworks.com/matlabcentral/fileexchange/71210-social-ski-driver-ssd-optimization-algorithm-2019
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.SSDO import OriginalSSDO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalSSDO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Tharwat, A. and Gabel, T., 2020. Parameters optimization of support vector machines for imbalanced
+    data using social ski driver algorithm. Neural Computing and Applications, 32(11), pp.6925-6938.
+    """
+
+    ID_VEL = 2
+    ID_LOC = 3
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        """
+        Overriding method in Optimizer class
+
+        Returns:
+            list: wrapper of solution with format [position, target, velocity, best_local_position]
+        """
+        if pos is None:
+            pos = self.generate_position(lb, ub)
+        position = self.amend_position(pos, lb, ub)
+        target = self.get_target_wrapper(position)
+        velocity = np.random.uniform(lb, ub)
+        pos_local = deepcopy(position)
+        return [position, target, velocity, pos_local]
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        c = 2 - epoch * (2.0 / self.epoch)  # a decreases linearly from 2 to 0
+
+        ## Calculate the mean of the best three solutions in each dimension. Eq 9
+        _, pop_best3, _ = self.get_special_solutions(self.pop, best=3)
+        pos_mean = np.mean(np.array([item[self.ID_POS] for item in pop_best3]))
+
+        pop_new = deepcopy(self.pop)
+        # Updating velocity vectors
+        r1 = np.random.uniform()  # r1, r2 is a random number in [0,1]
+        r2 = np.random.uniform()
+        for i in range(0, self.pop_size):
+            if r2 <= 0.5:  ## Use Sine function to move
+                vel_new = c * np.sin(r1) * (self.pop[i][self.ID_LOC] - self.pop[i][self.ID_POS]) + (2-c)*np.sin(r1) * (pos_mean - self.pop[i][self.ID_POS])
+            else:  ## Use Cosine function to move
+                vel_new = c * np.cos(r1) * (self.pop[i][self.ID_LOC] - self.pop[i][self.ID_POS]) + (2-c)*np.cos(r1) * (pos_mean - self.pop[i][self.ID_POS])
+            pop_new[i][self.ID_VEL] = vel_new
+
+        ## Reproduction
+        for idx in range(0, self.pop_size):
+            pos_new = np.random.normal(0, 1, self.problem.n_dims) * pop_new[idx][self.ID_POS] + np.random.rand() * pop_new[idx][self.ID_VEL]
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new[idx][self.ID_LOC] = self.pop[idx][self.ID_POS]
+            pop_new[idx][self.ID_POS] = pos_new
+            if self.mode not in self.AVAILABLE_MODES:
+                old = deepcopy(pop_new[idx])
+                old[self.ID_TAR] = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution(pop_new[idx], old)
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/human_based/TLO.py` & `mealpy-2.5.3a1/mealpy/human_based/TLO.py`

 * *Ordering differences only*

 * *Files 11% similar despite different names*

```diff
@@ -1,319 +1,319 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 10:14, 18/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from functools import reduce
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class BaseTLO(Optimizer):
-    """
-    The developed version: Teaching Learning-based Optimization (TLO)
-
-    Links:
-       1. https://doi.org/10.5267/j.ijiec.2012.03.007
-
-    Notes
-    ~~~~~
-    + Use numpy np.array to make operations faster
-    + The global best solution is used
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.TLO import BaseTLO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = BaseTLO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Rao, R. and Patel, V., 2012. An elitist teaching-learning-based optimization algorithm for solving
-    complex constrained optimization problems. international journal of industrial engineering computations, 3(4), pp.535-560.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            ## Teaching Phrase
-            TF = np.random.randint(1, 3)  # 1 or 2 (never 3)
-            list_pos = np.array([item[self.ID_POS] for item in self.pop])
-            DIFF_MEAN = np.random.rand(self.problem.n_dims) * (self.g_best[self.ID_POS] - TF * np.mean(list_pos, axis=0))
-            temp = self.pop[idx][self.ID_POS] + DIFF_MEAN
-            pos_new = self.amend_position(temp, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-        pop_child = []
-        for idx in range(0, self.pop_size):
-            ## Learning Phrase
-            temp = deepcopy(self.pop[idx][self.ID_POS]).astype(float)
-            id_partner = np.random.choice(np.setxor1d(np.array(range(self.pop_size)), np.array([idx])))
-            if self.compare_agent(self.pop[idx], self.pop[id_partner]):
-                temp += np.random.rand(self.problem.n_dims) * (self.pop[idx][self.ID_POS] - self.pop[id_partner][self.ID_POS])
-            else:
-                temp += np.random.rand(self.problem.n_dims) * (self.pop[id_partner][self.ID_POS] - self.pop[idx][self.ID_POS])
-            pos_new = self.amend_position(temp, self.problem.lb, self.problem.ub)
-            pop_child.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_child = self.update_target_wrapper_population(pop_child)
-            self.pop = self.greedy_selection_population(pop_child, self.pop)
-
-
-class OriginalTLO(BaseTLO):
-    """
-    The original version of: Teaching Learning-based Optimization (TLO)
-
-    Links:
-       1. https://github.com/andaviaco/tblo
-
-    Notes
-    ~~~~~
-    + Third loops are removed
-    + This version is inspired from above link
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.TLO import OriginalTLO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalTLO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Rao, R.V., Savsani, V.J. and Vakharia, D.P., 2011. Teachingâlearning-based optimization: a novel method
-    for constrained mechanical design optimization problems. Computer-aided design, 43(3), pp.303-315.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(epoch, pop_size, **kwargs)
-        self.support_parallel_modes = False
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        for idx in range(0, self.pop_size):
-            ## Teaching Phrase
-            TF = np.random.randint(1, 3)  # 1 or 2 (never 3)
-            #### Remove third loop here
-            list_pos = np.array([item[self.ID_POS] for item in self.pop])
-            pos_new = self.pop[idx][self.ID_POS] + np.random.uniform(0, 1, self.problem.n_dims) * \
-                      (self.g_best[self.ID_POS] - TF * np.mean(list_pos, axis=0))
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            target = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, target], self.pop[idx]):
-                self.pop[idx] = [pos_new, target]
-
-            ## Learning Phrase
-            id_partner = np.random.choice(np.setxor1d(np.array(range(self.pop_size)), np.array([idx])))
-
-            #### Remove third loop here
-            if self.compare_agent(self.pop[idx], self.pop[id_partner]):
-                diff = self.pop[idx][self.ID_POS] - self.pop[id_partner][self.ID_POS]
-            else:
-                diff = self.pop[id_partner][self.ID_POS] - self.pop[idx][self.ID_POS]
-            pos_new = self.pop[idx][self.ID_POS] + np.random.uniform(0, 1, self.problem.n_dims) * diff
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            target = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, target], self.pop[idx]):
-                self.pop[idx] = [pos_new, target]
-
-
-class ImprovedTLO(BaseTLO):
-    """
-    The original version of: Improved Teaching-Learning-based Optimization (ImprovedTLO)
-
-    Links:
-       1. https://doi.org/10.1016/j.scient.2012.12.005
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + n_teachers (int): [3, 10], number of teachers in class, default=5
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.TLO import ImprovedTLO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> n_teachers = 5
-    >>> model = ImprovedTLO(epoch, pop_size, n_teachers)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Rao, R.V. and Patel, V., 2013. An improved teaching-learning-based optimization algorithm
-    for solving unconstrained optimization problems. Scientia Iranica, 20(3), pp.710-720.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, n_teachers=5, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            n_teachers (int): number of teachers in class
-        """
-        super().__init__(epoch, pop_size, **kwargs)
-        self.n_teachers = self.validator.check_int("n_teachers", n_teachers, [2, int(np.sqrt(self.pop_size)-1)])
-        self.set_parameters(["epoch", "pop_size", "n_teachers"])
-
-        self.n_students = self.pop_size - self.n_teachers
-        self.n_students_in_team = int(self.n_students / self.n_teachers)
-        self.sort_flag = False
-
-    def initialization(self):
-        if self.pop is None:
-            self.pop = self.create_population(self.pop_size)
-        sorted_pop, self.g_best = self.get_global_best_solution(self.pop)
-        self.teachers = deepcopy(sorted_pop[:self.n_teachers])
-        sorted_pop = sorted_pop[self.n_teachers:]
-        idx_list = np.random.permutation(range(0, self.n_students))
-        self.teams = []
-        for id_teacher in range(0, self.n_teachers):
-            group = []
-            for idx in range(0, self.n_students_in_team):
-                start_index = id_teacher * self.n_students_in_team + idx
-                group.append(sorted_pop[idx_list[start_index]])
-            self.teams.append(group)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        for id_teach, teacher in enumerate(self.teachers):
-            team = self.teams[id_teach]
-            list_pos = np.array([student[self.ID_POS] for student in self.teams[id_teach]])  # Step 7
-            mean_team = np.mean(list_pos, axis=0)
-            pop_new = []
-            for id_stud, student in enumerate(team):
-                if teacher[self.ID_TAR][self.ID_FIT] == 0:
-                    TF = 1
-                else:
-                    TF = student[self.ID_TAR][self.ID_FIT] / teacher[self.ID_TAR][self.ID_FIT]
-                diff_mean = np.random.rand() * (teacher[self.ID_POS] - TF * mean_team)  # Step 8
-
-                id2 = np.random.choice(list(set(range(0, self.n_teachers)) - {id_teach}))
-                if self.compare_agent(teacher, team[id2]):
-                    pos_new = (student[self.ID_POS] + diff_mean) + np.random.rand() * (team[id2][self.ID_POS] - student[self.ID_POS])
-                else:
-                    pos_new = (student[self.ID_POS] + diff_mean) + np.random.rand() * (student[self.ID_POS] - team[id2][self.ID_POS])
-                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                pop_new.append([pos_new, None])
-                if self.mode not in self.AVAILABLE_MODES:
-                    target = self.get_target_wrapper(pos_new)
-                    pop_new[-1] = self.get_better_solution([pos_new, target], student)
-            if self.mode in self.AVAILABLE_MODES:
-                pop_new = self.update_target_wrapper_population(pop_new)
-                pop_new = self.greedy_selection_population(team, pop_new)
-            self.teams[id_teach] = pop_new
-
-        for id_teach, teacher in enumerate(self.teachers):
-            ef = round(1 + np.random.rand())
-            team = self.teams[id_teach]
-            pop_new = []
-            for id_stud, student in enumerate(team):
-                id2 = np.random.choice(list(set(range(0, self.n_students_in_team)) - {id_stud}))
-                if self.compare_agent(student, team[id2]):
-                    pos_new = student[self.ID_POS] + np.random.rand() * (student[self.ID_POS] - team[id2][self.ID_POS]) + \
-                              np.random.rand() * (teacher[self.ID_POS] - ef * team[id2][self.ID_POS])
-                else:
-                    pos_new = student[self.ID_POS] + np.random.rand() * (team[id2][self.ID_POS] - student[self.ID_POS]) + \
-                              np.random.rand() * (teacher[self.ID_POS] - ef * student[self.ID_POS])
-                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                pop_new.append([pos_new, None])
-                if self.mode not in self.AVAILABLE_MODES:
-                    target = self.get_target_wrapper(pos_new)
-                    pop_new[-1] = self.get_better_solution([pos_new, target], student)
-            if self.mode in self.AVAILABLE_MODES:
-                pop_new = self.update_target_wrapper_population(pop_new)
-                pop_new = self.greedy_selection_population(team, pop_new)
-            self.teams[id_teach] = pop_new
-
-        for id_teach, teacher in enumerate(self.teachers):
-            team = self.teams[id_teach] + [teacher]
-            team, local_best = self.get_global_best_solution(team)
-            self.teachers[id_teach] = local_best
-            self.teams[id_teach] = team[1:]
-
-        self.pop = self.teachers + reduce(lambda x, y: x + y, self.teams)
+#!/usr/bin/env python
+# Created by "Thieu" at 10:14, 18/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from functools import reduce
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class BaseTLO(Optimizer):
+    """
+    The developed version: Teaching Learning-based Optimization (TLO)
+
+    Links:
+       1. https://doi.org/10.5267/j.ijiec.2012.03.007
+
+    Notes
+    ~~~~~
+    + Use numpy np.array to make operations faster
+    + The global best solution is used
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.TLO import BaseTLO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = BaseTLO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Rao, R. and Patel, V., 2012. An elitist teaching-learning-based optimization algorithm for solving
+    complex constrained optimization problems. international journal of industrial engineering computations, 3(4), pp.535-560.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            ## Teaching Phrase
+            TF = np.random.randint(1, 3)  # 1 or 2 (never 3)
+            list_pos = np.array([item[self.ID_POS] for item in self.pop])
+            DIFF_MEAN = np.random.rand(self.problem.n_dims) * (self.g_best[self.ID_POS] - TF * np.mean(list_pos, axis=0))
+            temp = self.pop[idx][self.ID_POS] + DIFF_MEAN
+            pos_new = self.amend_position(temp, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+        pop_child = []
+        for idx in range(0, self.pop_size):
+            ## Learning Phrase
+            temp = deepcopy(self.pop[idx][self.ID_POS]).astype(float)
+            id_partner = np.random.choice(np.setxor1d(np.array(range(self.pop_size)), np.array([idx])))
+            if self.compare_agent(self.pop[idx], self.pop[id_partner]):
+                temp += np.random.rand(self.problem.n_dims) * (self.pop[idx][self.ID_POS] - self.pop[id_partner][self.ID_POS])
+            else:
+                temp += np.random.rand(self.problem.n_dims) * (self.pop[id_partner][self.ID_POS] - self.pop[idx][self.ID_POS])
+            pos_new = self.amend_position(temp, self.problem.lb, self.problem.ub)
+            pop_child.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_child = self.update_target_wrapper_population(pop_child)
+            self.pop = self.greedy_selection_population(pop_child, self.pop)
+
+
+class OriginalTLO(BaseTLO):
+    """
+    The original version of: Teaching Learning-based Optimization (TLO)
+
+    Links:
+       1. https://github.com/andaviaco/tblo
+
+    Notes
+    ~~~~~
+    + Third loops are removed
+    + This version is inspired from above link
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.TLO import OriginalTLO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalTLO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Rao, R.V., Savsani, V.J. and Vakharia, D.P., 2011. Teachingâlearning-based optimization: a novel method
+    for constrained mechanical design optimization problems. Computer-aided design, 43(3), pp.303-315.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(epoch, pop_size, **kwargs)
+        self.support_parallel_modes = False
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        for idx in range(0, self.pop_size):
+            ## Teaching Phrase
+            TF = np.random.randint(1, 3)  # 1 or 2 (never 3)
+            #### Remove third loop here
+            list_pos = np.array([item[self.ID_POS] for item in self.pop])
+            pos_new = self.pop[idx][self.ID_POS] + np.random.uniform(0, 1, self.problem.n_dims) * \
+                      (self.g_best[self.ID_POS] - TF * np.mean(list_pos, axis=0))
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            target = self.get_target_wrapper(pos_new)
+            if self.compare_agent([pos_new, target], self.pop[idx]):
+                self.pop[idx] = [pos_new, target]
+
+            ## Learning Phrase
+            id_partner = np.random.choice(np.setxor1d(np.array(range(self.pop_size)), np.array([idx])))
+
+            #### Remove third loop here
+            if self.compare_agent(self.pop[idx], self.pop[id_partner]):
+                diff = self.pop[idx][self.ID_POS] - self.pop[id_partner][self.ID_POS]
+            else:
+                diff = self.pop[id_partner][self.ID_POS] - self.pop[idx][self.ID_POS]
+            pos_new = self.pop[idx][self.ID_POS] + np.random.uniform(0, 1, self.problem.n_dims) * diff
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            target = self.get_target_wrapper(pos_new)
+            if self.compare_agent([pos_new, target], self.pop[idx]):
+                self.pop[idx] = [pos_new, target]
+
+
+class ImprovedTLO(BaseTLO):
+    """
+    The original version of: Improved Teaching-Learning-based Optimization (ImprovedTLO)
+
+    Links:
+       1. https://doi.org/10.1016/j.scient.2012.12.005
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + n_teachers (int): [3, 10], number of teachers in class, default=5
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.TLO import ImprovedTLO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> n_teachers = 5
+    >>> model = ImprovedTLO(epoch, pop_size, n_teachers)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Rao, R.V. and Patel, V., 2013. An improved teaching-learning-based optimization algorithm
+    for solving unconstrained optimization problems. Scientia Iranica, 20(3), pp.710-720.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, n_teachers=5, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            n_teachers (int): number of teachers in class
+        """
+        super().__init__(epoch, pop_size, **kwargs)
+        self.n_teachers = self.validator.check_int("n_teachers", n_teachers, [2, int(np.sqrt(self.pop_size)-1)])
+        self.set_parameters(["epoch", "pop_size", "n_teachers"])
+
+        self.n_students = self.pop_size - self.n_teachers
+        self.n_students_in_team = int(self.n_students / self.n_teachers)
+        self.sort_flag = False
+
+    def initialization(self):
+        if self.pop is None:
+            self.pop = self.create_population(self.pop_size)
+        sorted_pop, self.g_best = self.get_global_best_solution(self.pop)
+        self.teachers = deepcopy(sorted_pop[:self.n_teachers])
+        sorted_pop = sorted_pop[self.n_teachers:]
+        idx_list = np.random.permutation(range(0, self.n_students))
+        self.teams = []
+        for id_teacher in range(0, self.n_teachers):
+            group = []
+            for idx in range(0, self.n_students_in_team):
+                start_index = id_teacher * self.n_students_in_team + idx
+                group.append(sorted_pop[idx_list[start_index]])
+            self.teams.append(group)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        for id_teach, teacher in enumerate(self.teachers):
+            team = self.teams[id_teach]
+            list_pos = np.array([student[self.ID_POS] for student in self.teams[id_teach]])  # Step 7
+            mean_team = np.mean(list_pos, axis=0)
+            pop_new = []
+            for id_stud, student in enumerate(team):
+                if teacher[self.ID_TAR][self.ID_FIT] == 0:
+                    TF = 1
+                else:
+                    TF = student[self.ID_TAR][self.ID_FIT] / teacher[self.ID_TAR][self.ID_FIT]
+                diff_mean = np.random.rand() * (teacher[self.ID_POS] - TF * mean_team)  # Step 8
+
+                id2 = np.random.choice(list(set(range(0, self.n_teachers)) - {id_teach}))
+                if self.compare_agent(teacher, team[id2]):
+                    pos_new = (student[self.ID_POS] + diff_mean) + np.random.rand() * (team[id2][self.ID_POS] - student[self.ID_POS])
+                else:
+                    pos_new = (student[self.ID_POS] + diff_mean) + np.random.rand() * (student[self.ID_POS] - team[id2][self.ID_POS])
+                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                pop_new.append([pos_new, None])
+                if self.mode not in self.AVAILABLE_MODES:
+                    target = self.get_target_wrapper(pos_new)
+                    pop_new[-1] = self.get_better_solution([pos_new, target], student)
+            if self.mode in self.AVAILABLE_MODES:
+                pop_new = self.update_target_wrapper_population(pop_new)
+                pop_new = self.greedy_selection_population(team, pop_new)
+            self.teams[id_teach] = pop_new
+
+        for id_teach, teacher in enumerate(self.teachers):
+            ef = round(1 + np.random.rand())
+            team = self.teams[id_teach]
+            pop_new = []
+            for id_stud, student in enumerate(team):
+                id2 = np.random.choice(list(set(range(0, self.n_students_in_team)) - {id_stud}))
+                if self.compare_agent(student, team[id2]):
+                    pos_new = student[self.ID_POS] + np.random.rand() * (student[self.ID_POS] - team[id2][self.ID_POS]) + \
+                              np.random.rand() * (teacher[self.ID_POS] - ef * team[id2][self.ID_POS])
+                else:
+                    pos_new = student[self.ID_POS] + np.random.rand() * (team[id2][self.ID_POS] - student[self.ID_POS]) + \
+                              np.random.rand() * (teacher[self.ID_POS] - ef * student[self.ID_POS])
+                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                pop_new.append([pos_new, None])
+                if self.mode not in self.AVAILABLE_MODES:
+                    target = self.get_target_wrapper(pos_new)
+                    pop_new[-1] = self.get_better_solution([pos_new, target], student)
+            if self.mode in self.AVAILABLE_MODES:
+                pop_new = self.update_target_wrapper_population(pop_new)
+                pop_new = self.greedy_selection_population(team, pop_new)
+            self.teams[id_teach] = pop_new
+
+        for id_teach, teacher in enumerate(self.teachers):
+            team = self.teams[id_teach] + [teacher]
+            team, local_best = self.get_global_best_solution(team)
+            self.teachers[id_teach] = local_best
+            self.teams[id_teach] = team[1:]
+
+        self.pop = self.teachers + reduce(lambda x, y: x + y, self.teams)
```

### Comparing `mealpy-2.5.3/mealpy/human_based/TOA.py` & `mealpy-2.5.3a1/mealpy/human_based/TOA.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,114 +1,110 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 18:22, 11/03/2023 ----------%
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalTOA(Optimizer):
-    """
-    The original version of: Teamwork Optimization Algorithm (TOA)
-
-    Links:
-        1. https://www.mdpi.com/1424-8220/21/13/4567
-
-    Notes:
-        1. Algorithm design is similar to Zebra Optimization Algorithm (ZOA), Osprey Optimization Algorithm (OOA), Coati Optimization Algorithm (CoatiOA),
-        Siberian Tiger Optimization (STO), Language Education Optimization (LEO), Serval Optimization Algorithm (SOA), Walrus Optimization Algorithm (WOA),
-        Fennec Fox Optimization (FFO), Three-periods optimization algorithm (TPOA), Pelican Optimization Algorithm (POA), Northern goshawk optimization (NGO),
-        Tasmanian devil optimization (TDO), Archery algorithm (AA), Cat and mouse based optimizer (CMBO)
-
-        2. It may be useful to compare the Matlab code of this algorithm with those of the similar algorithms to ensure its accuracy and completeness.
-
-        3. While this article may share some similarities with previous work by the same authors, it is important to recognize the potential value in exploring
-        different meta-metaphors and concepts to drive innovation and progress in optimization research.
-
-        4. Further investigation may be warranted to verify the benchmark results reported in the papers and ensure their reliability and accuracy.
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.TOA import OriginalTOA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalTOA(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Dehghani, M., & TrojovskÃ½, P. (2021). Teamwork optimization algorithm: A new optimization
-    approach for function minimization/maximization. Sensors, 21(13), 4567.
-    """
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.support_parallel_modes = False
-        self.sort_flag = False
-
-    def get_indexes_better__(self, pop, idx):
-        fits = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in self.pop])
-        if self.problem.minmax == "min":
-            idxs = np.where(fits < pop[idx][self.ID_TAR][self.ID_FIT])
-        else:
-            idxs = np.where(fits > pop[idx][self.ID_TAR][self.ID_FIT])
-        return idxs[0]
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        for idx in range(0, self.pop_size):
-            # Stage 1: Supervisor guidance
-            pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (self.g_best[self.ID_POS] - np.random.randint(1, 3) * self.pop[idx][self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            tar_new = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
-                self.pop[idx] = [pos_new, tar_new]
-
-            # Stage 2: Information sharing
-            idxs = self.get_indexes_better__(self.pop, idx)
-            if len(idxs) == 0:
-                sf = self.g_best
-            else:
-                sf_pos = np.array([self.pop[jdx][self.ID_POS] for jdx in idxs])
-                sf_pos = self.amend_position(np.mean(sf_pos, axis=0), self.problem.lb, self.problem.ub)
-                sf_tar = self.get_target_wrapper(sf_pos)
-                sf = [sf_pos, sf_tar]
-            pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (sf[self.ID_POS] - np.random.randint(1, 3) * self.pop[idx][self.ID_POS]) * \
-                        np.sign(self.pop[idx][self.ID_TAR][self.ID_FIT] - sf[self.ID_TAR][self.ID_FIT])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            tar_new = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
-                self.pop[idx] = [pos_new, tar_new]
-
-            # Stage 3: Individual activity
-            pos_new = self.pop[idx][self.ID_POS] + (-0.01 + np.random.rand() * 0.02) * self.pop[idx][self.ID_POS]
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            tar_new = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
-                self.pop[idx] = [pos_new, tar_new]
+#!/usr/bin/env python
+# Created by "Thieu" at 18:22, 11/03/2023 ----------%
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalTOA(Optimizer):
+    """
+    The original version of: Teamwork Optimization Algorithm (TOA)
+
+    Links:
+        1. https://www.mdpi.com/1424-8220/21/13/4567
+
+    Notes (Plagiarism):
+        1. Algorithm design is very similar to Zebra Optimization Algorithm (ZOA), Osprey Optimization Algorithm (OOA), Coati Optimization Algorithm (CoatiOA),
+        Siberian Tiger Optimization (STO), Language Education Optimization (LEO), Serval Optimization Algorithm (SOA), Walrus Optimization Algorithm (WOA),
+        Fennec Fox Optimization (FFO), Three-periods optimization algorithm (TPOA), Pelican Optimization Algorithm (POA), Northern goshawk optimization (NGO),
+        Tasmanian devil optimization (TDO), Archery algorithm (AA), Cat and mouse based optimizer (CMBO)
+        2. Check the matlab code of all above algorithms
+        2. Same authors, self-plagiarized article with kinda same algorithm with different meta-metaphors
+        4. Check the results of benchmark functions in the papers, they are mostly make up results
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.TOA import OriginalTOA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalTOA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Dehghani, M., & TrojovskÃ½, P. (2021). Teamwork optimization algorithm: A new optimization
+    approach for function minimization/maximization. Sensors, 21(13), 4567.
+    """
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.support_parallel_modes = False
+        self.sort_flag = False
+
+    def get_indexes_better__(self, pop, idx):
+        fits = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in self.pop])
+        if self.problem.minmax == "min":
+            idxs = np.where(fits < pop[idx][self.ID_TAR][self.ID_FIT])
+        else:
+            idxs = np.where(fits > pop[idx][self.ID_TAR][self.ID_FIT])
+        return idxs[0]
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        for idx in range(0, self.pop_size):
+            # Stage 1: Supervisor guidance
+            pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (self.g_best[self.ID_POS] - np.random.randint(1, 3) * self.pop[idx][self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            tar_new = self.get_target_wrapper(pos_new)
+            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
+                self.pop[idx] = [pos_new, tar_new]
+
+            # Stage 2: Information sharing
+            idxs = self.get_indexes_better__(self.pop, idx)
+            if len(idxs) == 0:
+                sf = self.g_best
+            else:
+                sf_pos = np.array([self.pop[jdx][self.ID_POS] for jdx in idxs])
+                sf_pos = self.amend_position(np.mean(sf_pos, axis=0), self.problem.lb, self.problem.ub)
+                sf_tar = self.get_target_wrapper(sf_pos)
+                sf = [sf_pos, sf_tar]
+            pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (sf[self.ID_POS] - np.random.randint(1, 3) * self.pop[idx][self.ID_POS]) * \
+                        np.sign(self.pop[idx][self.ID_TAR][self.ID_FIT] - sf[self.ID_TAR][self.ID_FIT])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            tar_new = self.get_target_wrapper(pos_new)
+            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
+                self.pop[idx] = [pos_new, tar_new]
+
+            # Stage 3: Individual activity
+            pos_new = self.pop[idx][self.ID_POS] + (-0.01 + np.random.rand() * 0.02) * self.pop[idx][self.ID_POS]
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            tar_new = self.get_target_wrapper(pos_new)
+            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
+                self.pop[idx] = [pos_new, tar_new]
```

### Comparing `mealpy-2.5.3/mealpy/human_based/WarSO.py` & `mealpy-2.5.3a1/mealpy/human_based/WarSO.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,89 +1,89 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 17:41, 21/05/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalWarSO(Optimizer):
-    """
-    The original version of: War Strategy Optimization (WarSO) algorithm
-
-    Links:
-       1. https://www.researchgate.net/publication/358806739_War_Strategy_Optimization_Algorithm_A_New_Effective_Metaheuristic_Algorithm_for_Global_Optimization
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + rr (float): [0.1, 0.9], the probability of switching position updating, default=0.1
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.human_based.WarSO import OriginalWarSO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalWarSO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Ayyarao, Tummala SLV, and Polamarasetty P. Kumar. "Parameter estimation of solar PV models with a new proposed
-    war strategy optimization algorithm." International Journal of Energy Research (2022).
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, rr=0.1, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            rr (float): the probability of switching position updating, default=0.1
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.rr = self.validator.check_float("rr", rr, (0.0, 1.0))
-        self.set_parameters(["epoch", "pop_size"])
-        self.support_parallel_modes = False
-        self.sort_flag = False
-
-    def initialize_variables(self):
-        self.wl = 2 * np.ones(self.pop_size)
-        self.wg = np.zeros(self.pop_size)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_sorted, _ = self.get_global_best_solution(self.pop)
-        com = np.random.permutation(self.pop_size)
-        for idx in range(0, self.pop_size):
-            r1 = np.random.rand()
-            if r1 < self.rr:
-                pos_new = 2*r1*(self.g_best[self.ID_POS] - self.pop[com[idx]][self.ID_POS]) + \
-                          self.wl[idx]*np.random.rand()*(pop_sorted[idx][self.ID_POS] - self.pop[idx][self.ID_POS])
-            else:
-                pos_new = 2*r1*(pop_sorted[idx][self.ID_POS] - self.g_best[self.ID_POS]) + \
-                          np.random.rand() * (self.wl[idx] * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            tar_new = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
-                self.pop[idx] = [pos_new, tar_new]
-                self.wg[idx] += 1
-                self.wl[idx] = 1 * self.wl[idx] * (1 - self.wg[idx] / self.epoch)**2
+#!/usr/bin/env python
+# Created by "Thieu" at 17:41, 21/05/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalWarSO(Optimizer):
+    """
+    The original version of: War Strategy Optimization (WarSO) algorithm
+
+    Links:
+       1. https://www.researchgate.net/publication/358806739_War_Strategy_Optimization_Algorithm_A_New_Effective_Metaheuristic_Algorithm_for_Global_Optimization
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + rr (float): [0.1, 0.9], the probability of switching position updating, default=0.1
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.WarSO import OriginalWarSO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalWarSO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Ayyarao, Tummala SLV, and Polamarasetty P. Kumar. "Parameter estimation of solar PV models with a new proposed
+    war strategy optimization algorithm." International Journal of Energy Research (2022).
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, rr=0.1, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            rr (float): the probability of switching position updating, default=0.1
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.rr = self.validator.check_float("rr", rr, (0.0, 1.0))
+        self.set_parameters(["epoch", "pop_size"])
+        self.support_parallel_modes = False
+        self.sort_flag = False
+
+    def initialize_variables(self):
+        self.wl = 2 * np.ones(self.pop_size)
+        self.wg = np.zeros(self.pop_size)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_sorted, _ = self.get_global_best_solution(self.pop)
+        com = np.random.permutation(self.pop_size)
+        for idx in range(0, self.pop_size):
+            r1 = np.random.rand()
+            if r1 < self.rr:
+                pos_new = 2*r1*(self.g_best[self.ID_POS] - self.pop[com[idx]][self.ID_POS]) + \
+                          self.wl[idx]*np.random.rand()*(pop_sorted[idx][self.ID_POS] - self.pop[idx][self.ID_POS])
+            else:
+                pos_new = 2*r1*(pop_sorted[idx][self.ID_POS] - self.g_best[self.ID_POS]) + \
+                          np.random.rand() * (self.wl[idx] * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            tar_new = self.get_target_wrapper(pos_new)
+            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
+                self.pop[idx] = [pos_new, tar_new]
+                self.wg[idx] += 1
+                self.wl[idx] = 1 * self.wl[idx] * (1 - self.wg[idx] / self.epoch)**2
```

### Comparing `mealpy-2.5.3/mealpy/math_based/AOA.py` & `mealpy-2.5.3a1/mealpy/math_based/AOA.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,109 +1,109 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 09:56, 07/07/2021 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalAOA(Optimizer):
-    """
-    The original version of: Arithmetic Optimization Algorithm (AOA)
-
-    Links:
-        1. https://doi.org/10.1016/j.cma.2020.113609
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + alpha (int): [3, 8], fixed parameter, sensitive exploitation parameter, Default: 5,
-        + miu (float): [0.3, 1.0], fixed parameter , control parameter to adjust the search process, Default: 0.5,
-        + moa_min (float): [0.1, 0.4], range min of Math Optimizer Accelerated, Default: 0.2,
-        + moa_max (float): [0.5, 1.0], range max of Math Optimizer Accelerated, Default: 0.9,
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.math_based.AOA import OriginalAOA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> alpha = 5
-    >>> miu = 0.5
-    >>> moa_min = 0.2
-    >>> moa_max = 0.9
-    >>> model = OriginalAOA(epoch, pop_size, alpha, miu, moa_min, moa_max)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Abualigah, L., Diabat, A., Mirjalili, S., Abd Elaziz, M. and Gandomi, A.H., 2021. The arithmetic
-    optimization algorithm. Computer methods in applied mechanics and engineering, 376, p.113609.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, alpha=5, miu=0.5, moa_min=0.2, moa_max=0.9, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            alpha (int): fixed parameter, sensitive exploitation parameter, Default: 5,
-            miu (float): fixed parameter, control parameter to adjust the search process, Default: 0.5,
-            moa_min (float): range min of Math Optimizer Accelerated, Default: 0.2,
-            moa_max (float): range max of Math Optimizer Accelerated, Default: 0.9,
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.alpha = self.validator.check_int("alpha", alpha, [2, 10])
-        self.miu = self.validator.check_float("miu", miu, [0.1, 2.0])
-        self.moa_min = self.validator.check_float("moa_min", moa_min, (0, 0.41))
-        self.moa_max = self.validator.check_float("moa_max", moa_max, (0.41, 1.0))
-        self.set_parameters(["epoch", "pop_size", "alpha", "miu", "moa_min", "moa_max"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        moa = self.moa_min + (epoch+1) * ((self.moa_max - self.moa_min) / self.epoch)  # Eq. 2
-        mop = 1 - ((epoch+1) ** (1.0 / self.alpha)) / (self.epoch ** (1.0 / self.alpha))  # Eq. 4
-
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            pos_new = deepcopy(self.pop[idx][self.ID_POS])
-            for j in range(0, self.problem.n_dims):
-                r1, r2, r3 = np.random.rand(3)
-                if r1 > moa:  # Exploration phase
-                    if r2 < 0.5:
-                        pos_new[j] = self.g_best[self.ID_POS][j] / (mop + self.EPSILON) * \
-                                     ((self.problem.ub[j] - self.problem.lb[j]) * self.miu + self.problem.lb[j])
-                    else:
-                        pos_new[j] = self.g_best[self.ID_POS][j] * mop * ((self.problem.ub[j] - self.problem.lb[j]) * self.miu + self.problem.lb[j])
-                else:  # Exploitation phase
-                    if r3 < 0.5:
-                        pos_new[j] = self.g_best[self.ID_POS][j] - mop * ((self.problem.ub[j] - self.problem.lb[j]) * self.miu + self.problem.lb[j])
-                    else:
-                        pos_new[j] = self.g_best[self.ID_POS][j] + mop * ((self.problem.ub[j] - self.problem.lb[j]) * self.miu + self.problem.lb[j])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 09:56, 07/07/2021 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalAOA(Optimizer):
+    """
+    The original version of: Arithmetic Optimization Algorithm (AOA)
+
+    Links:
+        1. https://doi.org/10.1016/j.cma.2020.113609
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + alpha (int): [3, 8], fixed parameter, sensitive exploitation parameter, Default: 5,
+        + miu (float): [0.3, 1.0], fixed parameter , control parameter to adjust the search process, Default: 0.5,
+        + moa_min (float): [0.1, 0.4], range min of Math Optimizer Accelerated, Default: 0.2,
+        + moa_max (float): [0.5, 1.0], range max of Math Optimizer Accelerated, Default: 0.9,
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.math_based.AOA import OriginalAOA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> alpha = 5
+    >>> miu = 0.5
+    >>> moa_min = 0.2
+    >>> moa_max = 0.9
+    >>> model = OriginalAOA(epoch, pop_size, alpha, miu, moa_min, moa_max)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Abualigah, L., Diabat, A., Mirjalili, S., Abd Elaziz, M. and Gandomi, A.H., 2021. The arithmetic
+    optimization algorithm. Computer methods in applied mechanics and engineering, 376, p.113609.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, alpha=5, miu=0.5, moa_min=0.2, moa_max=0.9, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            alpha (int): fixed parameter, sensitive exploitation parameter, Default: 5,
+            miu (float): fixed parameter, control parameter to adjust the search process, Default: 0.5,
+            moa_min (float): range min of Math Optimizer Accelerated, Default: 0.2,
+            moa_max (float): range max of Math Optimizer Accelerated, Default: 0.9,
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.alpha = self.validator.check_int("alpha", alpha, [2, 10])
+        self.miu = self.validator.check_float("miu", miu, [0.1, 2.0])
+        self.moa_min = self.validator.check_float("moa_min", moa_min, (0, 0.41))
+        self.moa_max = self.validator.check_float("moa_max", moa_max, (0.41, 1.0))
+        self.set_parameters(["epoch", "pop_size", "alpha", "miu", "moa_min", "moa_max"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        moa = self.moa_min + (epoch+1) * ((self.moa_max - self.moa_min) / self.epoch)  # Eq. 2
+        mop = 1 - ((epoch+1) ** (1.0 / self.alpha)) / (self.epoch ** (1.0 / self.alpha))  # Eq. 4
+
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            pos_new = deepcopy(self.pop[idx][self.ID_POS])
+            for j in range(0, self.problem.n_dims):
+                r1, r2, r3 = np.random.rand(3)
+                if r1 > moa:  # Exploration phase
+                    if r2 < 0.5:
+                        pos_new[j] = self.g_best[self.ID_POS][j] / (mop + self.EPSILON) * \
+                                     ((self.problem.ub[j] - self.problem.lb[j]) * self.miu + self.problem.lb[j])
+                    else:
+                        pos_new[j] = self.g_best[self.ID_POS][j] * mop * ((self.problem.ub[j] - self.problem.lb[j]) * self.miu + self.problem.lb[j])
+                else:  # Exploitation phase
+                    if r3 < 0.5:
+                        pos_new[j] = self.g_best[self.ID_POS][j] - mop * ((self.problem.ub[j] - self.problem.lb[j]) * self.miu + self.problem.lb[j])
+                    else:
+                        pos_new[j] = self.g_best[self.ID_POS][j] + mop * ((self.problem.ub[j] - self.problem.lb[j]) * self.miu + self.problem.lb[j])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/math_based/CEM.py` & `mealpy-2.5.3a1/mealpy/swarm_based/SHO.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,100 +1,110 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 18:08, 19/04/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalCEM(Optimizer):
-    """
-    The original version of: Cross-Entropy Method (CEM)
-
-    Links:
-        1. https://github.com/clever-algorithms/CleverAlgorithms
-        2. https://doi.org/10.1007/s10479-005-5724-z
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + n_best (int): N selected solutions as a samples for next evolution
-        + alpha (float): weight factor for means and stdevs (normal distribution)
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.math_based.CEM import OriginalCEM
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> n_best = 20
-    >>> alpha = 0.7
-    >>> model = OriginalCEM(epoch, pop_size, n_best, alpha)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] De Boer, P.T., Kroese, D.P., Mannor, S. and Rubinstein, R.Y., 2005. A tutorial on the
-    cross-entropy method. Annals of operations research, 134(1), pp.19-67.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, n_best=20, alpha=0.7, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            n_best (int): N selected solutions as a samples for next evolution
-            alpha (float): weight factor for means and stdevs (normal distribution)
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.n_best = self.validator.check_int("n_best", n_best, [2, int(self.pop_size/2)])
-        self.alpha = self.validator.check_float("alpha", alpha, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "n_best", "alpha"])
-        self.sort_flag = True
-
-    def initialize_variables(self):
-        self.means = np.random.uniform(self.problem.lb, self.problem.ub)
-        self.stdevs = np.abs(self.problem.ub - self.problem.lb)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        ## Selected the best samples and update means and stdevs
-        pop_best = self.pop[:self.n_best]
-        pos_list = np.array([item[self.ID_POS] for item in pop_best])
-
-        means_new = np.mean(pos_list, axis=0)
-        means_new_repeat = np.repeat(means_new.reshape((1, -1)), self.n_best, axis=0)
-        stdevs_new = np.mean((pos_list - means_new_repeat) ** 2, axis=0)
-        self.means = self.alpha * self.means + (1.0 - self.alpha) * means_new
-        self.stdevs = np.abs(self.alpha * self.stdevs + (1.0 - self.alpha) * stdevs_new)
-
-        ## Create new population for next generation
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            pos_new = np.random.normal(self.means, self.stdevs)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 10:55, 02/12/2019 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalSHO(Optimizer):
+    """
+    The original version of: Spotted Hyena Optimizer (SHO)
+
+    Links:
+        1. https://doi.org/10.1016/j.advengsoft.2017.05.014
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + h_factor (float): default = 5, coefficient linearly decreased from 5 to 0
+        + N_tried (int): default = 10
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.SHO import OriginalSHO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> h_factor = 5.0
+    >>> N_tried = 10
+    >>> model = OriginalSHO(epoch, pop_size, h_factor, N_tried)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Dhiman, G. and Kumar, V., 2017. Spotted hyena optimizer: a novel bio-inspired based metaheuristic
+    technique for engineering applications. Advances in Engineering Software, 114, pp.48-70.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, h_factor=5., N_tried=10, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            h_factor (float): default = 5, coefficient linearly decreased from 5.0 to 0
+            N_tried (int): default = 10,
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.h_factor = self.validator.check_float("h_factor", h_factor, (0.5, 10.0))
+        self.N_tried = self.validator.check_int("N_tried", N_tried, (1, float("inf")))
+        self.set_parameters(["epoch", "pop_size", "h_factor", "N_tried"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            h = self.h_factor - (epoch + 1.0) * (self.h_factor / self.epoch)
+            rd1 = np.random.uniform(0, 1, self.problem.n_dims)
+            rd2 = np.random.uniform(0, 1, self.problem.n_dims)
+            B = 2 * rd1
+            E = 2 * h * rd2 - h
+
+            if np.random.rand() < 0.5:
+                D_h = np.abs(np.dot(B, self.g_best[self.ID_POS]) - self.pop[idx][self.ID_POS])
+                pos_new = self.g_best[self.ID_POS] - np.dot(E, D_h)
+            else:
+                N = 1
+                for i in range(0, self.N_tried):
+                    pos_temp = self.g_best[self.ID_POS] + np.random.normal(0, 1, self.problem.n_dims) * \
+                              np.random.uniform(self.problem.lb, self.problem.ub)
+                    pos_temp = self.amend_position(pos_temp, self.problem.lb, self.problem.ub)
+                    target = self.get_target_wrapper(pos_temp)
+                    if self.compare_agent([pos_temp, target], self.g_best):
+                        N += 1
+                        break
+                    N += 1
+                circle_list = []
+                idx_list = np.random.choice(range(0, self.pop_size), N, replace=False)
+                for j in range(0, N):
+                    D_h = np.abs(np.dot(B, self.g_best[self.ID_POS]) - self.pop[idx_list[j]][self.ID_POS])
+                    p_k = self.g_best[self.ID_POS] - np.dot(E, D_h)
+                    circle_list.append(p_k)
+                pos_new = np.mean(np.array(circle_list), axis=0)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/math_based/CGO.py` & `mealpy-2.5.3a1/mealpy/math_based/CGO.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,114 +1,114 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 22:24, 02/03/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalCGO(Optimizer):
-    """
-    The original version of: Chaos Game Optimization (CGO)
-
-    Links:
-        1. https://doi.org/10.1007/s10462-020-09867-w
-
-    Notes
-    ~~~~~
-    + 4th seed is mutation process, but it is not clear mutation on multiple variables or 1 variable
-    + There is no usage of the variable alpha 4th in the paper
-    + The replacement of the worst solutions by generated seed are not clear (Lots of grammar errors in this section)
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.math_based.CGO import OriginalCGO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalCGO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Talatahari, S. and Azizi, M., 2021. Chaos Game Optimization: a novel metaheuristic algorithm.
-    Artificial Intelligence Review, 54(2), pp.917-1004.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            s1, s2, s3 = np.random.choice(range(0, self.pop_size), 3, replace=False)
-            MG = (self.pop[s1][self.ID_POS] + self.pop[s2][self.ID_POS] + self.pop[s3][self.ID_POS]) / 3
-
-            ## Calculating alpha based on Eq. 7
-            alpha1 = np.random.rand()
-            alpha2 = 2 * np.random.rand()
-            alpha3 = 1 + np.random.random() * np.random.rand()
-            esp = np.random.random()
-            # There is no usage of this variable in the paper
-            alpha4 = esp + esp * np.random.rand()
-
-            beta = np.random.randint(0, 2, 3)
-            gama = np.random.randint(0, 2, 3)
-            ## The seed4 is mutation process, but not sure k is multiple variables or 1 variable.
-            ## In the text said, multiple variables, but the defination of k is 1 variable. So confused
-            k = np.random.randint(0, self.problem.n_dims)
-            k_idx = np.random.choice(range(0, self.problem.n_dims), k, replace=False)
-
-            seed1 = self.pop[idx][self.ID_POS] + alpha1 * (beta[0] * self.g_best[self.ID_POS] - gama[0] * MG)  # Eq. 3
-            seed2 = self.g_best[self.ID_POS] + alpha2 * (beta[1] * self.pop[idx][self.ID_POS] - gama[1] * MG)  # Eq. 4
-            seed3 = MG + alpha3 * (beta[2] * self.pop[idx][self.ID_POS] - gama[2] * self.g_best[self.ID_POS])  # Eq. 5
-            seed4 = deepcopy(self.pop[idx][self.ID_POS]).astype(float)
-            seed4[k_idx] += np.random.uniform(0, 1, k)
-
-            # Check if solutions go outside the search space and bring them back
-            seed1 = self.amend_position(seed1, self.problem.lb, self.problem.ub)
-            seed2 = self.amend_position(seed2, self.problem.lb, self.problem.ub)
-            seed3 = self.amend_position(seed3, self.problem.lb, self.problem.ub)
-            seed4 = self.amend_position(seed4, self.problem.lb, self.problem.ub)
-
-            sol1 = [seed1, self.get_target_wrapper(seed1)]
-            sol2 = [seed2, self.get_target_wrapper(seed2)]
-            sol3 = [seed3, self.get_target_wrapper(seed3)]
-            sol4 = [seed4, self.get_target_wrapper(seed4)]
-
-            ## Lots of grammar errors in this section, so confused to understand which strategy they are using
-            _, best_seed = self.get_global_best_solution([sol1, sol2, sol3, sol4])
-            pop_new.append(best_seed)
-            if self.mode not in self.AVAILABLE_MODES:
-                self.pop[idx] = self.get_better_solution(best_seed, self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 22:24, 02/03/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalCGO(Optimizer):
+    """
+    The original version of: Chaos Game Optimization (CGO)
+
+    Links:
+        1. https://doi.org/10.1007/s10462-020-09867-w
+
+    Notes
+    ~~~~~
+    + 4th seed is mutation process, but it is not clear mutation on multiple variables or 1 variable
+    + There is no usage of the variable alpha 4th in the paper
+    + The replacement of the worst solutions by generated seed are not clear (Lots of grammar errors in this section)
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.math_based.CGO import OriginalCGO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalCGO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Talatahari, S. and Azizi, M., 2021. Chaos Game Optimization: a novel metaheuristic algorithm.
+    Artificial Intelligence Review, 54(2), pp.917-1004.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            s1, s2, s3 = np.random.choice(range(0, self.pop_size), 3, replace=False)
+            MG = (self.pop[s1][self.ID_POS] + self.pop[s2][self.ID_POS] + self.pop[s3][self.ID_POS]) / 3
+
+            ## Calculating alpha based on Eq. 7
+            alpha1 = np.random.rand()
+            alpha2 = 2 * np.random.rand()
+            alpha3 = 1 + np.random.random() * np.random.rand()
+            esp = np.random.random()
+            # There is no usage of this variable in the paper
+            alpha4 = esp + esp * np.random.rand()
+
+            beta = np.random.randint(0, 2, 3)
+            gama = np.random.randint(0, 2, 3)
+            ## The seed4 is mutation process, but not sure k is multiple variables or 1 variable.
+            ## In the text said, multiple variables, but the defination of k is 1 variable. So confused
+            k = np.random.randint(0, self.problem.n_dims)
+            k_idx = np.random.choice(range(0, self.problem.n_dims), k, replace=False)
+
+            seed1 = self.pop[idx][self.ID_POS] + alpha1 * (beta[0] * self.g_best[self.ID_POS] - gama[0] * MG)  # Eq. 3
+            seed2 = self.g_best[self.ID_POS] + alpha2 * (beta[1] * self.pop[idx][self.ID_POS] - gama[1] * MG)  # Eq. 4
+            seed3 = MG + alpha3 * (beta[2] * self.pop[idx][self.ID_POS] - gama[2] * self.g_best[self.ID_POS])  # Eq. 5
+            seed4 = deepcopy(self.pop[idx][self.ID_POS]).astype(float)
+            seed4[k_idx] += np.random.uniform(0, 1, k)
+
+            # Check if solutions go outside the search space and bring them back
+            seed1 = self.amend_position(seed1, self.problem.lb, self.problem.ub)
+            seed2 = self.amend_position(seed2, self.problem.lb, self.problem.ub)
+            seed3 = self.amend_position(seed3, self.problem.lb, self.problem.ub)
+            seed4 = self.amend_position(seed4, self.problem.lb, self.problem.ub)
+
+            sol1 = [seed1, self.get_target_wrapper(seed1)]
+            sol2 = [seed2, self.get_target_wrapper(seed2)]
+            sol3 = [seed3, self.get_target_wrapper(seed3)]
+            sol4 = [seed4, self.get_target_wrapper(seed4)]
+
+            ## Lots of grammar errors in this section, so confused to understand which strategy they are using
+            _, best_seed = self.get_global_best_solution([sol1, sol2, sol3, sol4])
+            pop_new.append(best_seed)
+            if self.mode not in self.AVAILABLE_MODES:
+                self.pop[idx] = self.get_better_solution(best_seed, self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/math_based/CircleSA.py` & `mealpy-2.5.3a1/mealpy/math_based/CircleSA.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,75 +1,75 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 17:38, 21/05/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalCircleSA(Optimizer):
-    """
-    The original version of: Circle Search Algorithm (CircleSA)
-
-    Links:
-        1. https://doi.org/10.3390/math10101626
-        2. https://www.mdpi.com/2227-7390/10/10/1626
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.math_based.CircleSA import OriginalCircleSA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalCircleSA(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Qais, M. H., Hasanien, H. M., Turky, R. A., Alghuwainem, S., Tostado-VÃ©liz, M., & Jurado, F. (2022).
-    Circle Search Algorithm: A Geometry-Based Metaheuristic Optimization Algorithm. Mathematics, 10(10), 1626.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, c_factor=0.8, **kwargs):
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.c_factor = self.validator.check_float("c_factor", c_factor, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "c_factor"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        a = np.pi - np.pi * ((epoch+1)/self.epoch)**2       # Eq. 8
-        p = 1 - 0.9 * ((epoch + 1) / self.epoch) ** 0.5
-        threshold = self.c_factor * self.epoch
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            w = a * np.random.rand() - a
-            if (epoch+1) > threshold:
-                x_new = self.g_best[self.ID_POS] + (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) * np.tan(w * np.random.rand())
-            else:
-                x_new = self.g_best[self.ID_POS] - (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) * np.tan(w * p)
-            x_new = self.amend_position(x_new, self.problem.lb, self.problem.ub)
-            pop_new.append([x_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(x_new)
-        self.pop = self.update_target_wrapper_population(pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 17:38, 21/05/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalCircleSA(Optimizer):
+    """
+    The original version of: Circle Search Algorithm (CircleSA)
+
+    Links:
+        1. https://doi.org/10.3390/math10101626
+        2. https://www.mdpi.com/2227-7390/10/10/1626
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.math_based.CircleSA import OriginalCircleSA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalCircleSA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Qais, M. H., Hasanien, H. M., Turky, R. A., Alghuwainem, S., Tostado-VÃ©liz, M., & Jurado, F. (2022).
+    Circle Search Algorithm: A Geometry-Based Metaheuristic Optimization Algorithm. Mathematics, 10(10), 1626.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, c_factor=0.8, **kwargs):
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.c_factor = self.validator.check_float("c_factor", c_factor, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "c_factor"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        a = np.pi - np.pi * ((epoch+1)/self.epoch)**2       # Eq. 8
+        p = 1 - 0.9 * ((epoch + 1) / self.epoch) ** 0.5
+        threshold = self.c_factor * self.epoch
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            w = a * np.random.rand() - a
+            if (epoch+1) > threshold:
+                x_new = self.g_best[self.ID_POS] + (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) * np.tan(w * np.random.rand())
+            else:
+                x_new = self.g_best[self.ID_POS] - (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) * np.tan(w * p)
+            x_new = self.amend_position(x_new, self.problem.lb, self.problem.ub)
+            pop_new.append([x_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(x_new)
+        self.pop = self.update_target_wrapper_population(pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/math_based/GBO.py` & `mealpy-2.5.3a1/mealpy/math_based/GBO.py`

 * *Ordering differences only*

 * *Files 6% similar despite different names*

```diff
@@ -1,140 +1,140 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 17:07, 02/03/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalGBO(Optimizer):
-    """
-    The original version of: Gradient-Based Optimizer (GBO)
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + pr (float): [0.2, 0.8], Probability Parameter, default = 0.5
-        + beta_min (float): Fixed parameter (no name in the paper), default = 0.2
-        + beta_max (float): Fixed parameter (no name in the paper), default = 1.2
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.math_based.GBO import OriginalGBO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> pr = 0.5
-    >>> beta_min = 0.2
-    >>> beta_max = 1.2
-    >>> model = OriginalGBO(epoch, pop_size, pr, beta_min, beta_max)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Ahmadianfar, I., Bozorg-Haddad, O. and Chu, X., 2020. Gradient-based optimizer:
-    A new metaheuristic optimization algorithm. Information Sciences, 540, pp.131-159.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, pr=0.5, beta_min=0.2, beta_max=1.2, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            pr (float): Probability Parameter, default = 0.5
-            beta_min (float): Fixed parameter (no name in the paper), default = 0.2
-            beta_max (float): Fixed parameter (no name in the paper), default = 1.2
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.pr = self.validator.check_float("pr", pr, (0, 1.0))
-        self.beta_min = self.validator.check_float("beta_min", beta_min, (0, 2.0))
-        self.beta_max = self.validator.check_float("beta_max", beta_max, (0, 5.0))
-        self.set_parameters(["epoch", "pop_size", "pr", "beta_min", "beta_max"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # Eq.(14.2), Eq.(14.1)
-        beta = self.beta_min + (self.beta_max - self.beta_min) * (1 - ((epoch + 1) / self.epoch) ** 3) ** 2
-        alpha = np.abs(beta * np.sin(3 * np.pi / 2 + np.sin(beta * 3 * np.pi / 2)))
-
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            p1 = 2 * np.random.rand() * alpha - alpha
-            p2 = 2 * np.random.rand() * alpha - alpha
-            #  Four positions randomly selected from population
-            r1, r2, r3, r4 = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 4, replace=False)
-            # Average of Four positions randomly selected from population
-            r0 = (self.pop[r1][self.ID_POS] + self.pop[r2][self.ID_POS] + self.pop[r3][self.ID_POS] + self.pop[r4][self.ID_POS]) / 4
-            # Randomization Epsilon
-            epsilon = 5e-3 * np.random.rand()
-
-            delta = 2 * np.random.rand() * np.abs(r0 - self.pop[idx][self.ID_POS])
-            step = (self.g_best[self.ID_POS] - self.pop[r1][self.ID_POS] + delta) / 2
-            delta_x = np.random.choice(range(0, self.pop_size)) * np.abs(step)
-            x1 = self.pop[idx][self.ID_POS] - np.random.normal() * p1 * 2 * delta_x * \
-                 self.pop[idx][self.ID_POS] / (self.g_worst[self.ID_POS] - self.g_best[self.ID_POS] + epsilon) + \
-                 np.random.rand() * p2 * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-
-            z = self.pop[idx][self.ID_POS] - np.random.normal() * 2 * delta_x * \
-                self.pop[idx][self.ID_POS] / (self.g_worst[self.ID_POS] - self.g_best[self.ID_POS] + epsilon)
-            y_p = np.random.rand() * ((z + self.pop[idx][self.ID_POS]) / 2 + np.random.rand() * delta_x)
-            y_q = np.random.rand() * ((z + self.pop[idx][self.ID_POS]) / 2 - np.random.rand() * delta_x)
-            x2 = self.g_best[self.ID_POS] - np.random.normal() * p1 * 2 * delta_x * self.pop[idx][self.ID_POS] / (y_p - y_q + epsilon) + \
-                 np.random.rand() * p2 * (self.pop[r1][self.ID_POS] - self.pop[r2][self.ID_POS])
-
-            x3 = self.pop[idx][self.ID_POS] - p1 * (x2 - x1)
-            ra = np.random.rand()
-            rb = np.random.rand()
-            pos_new = ra * (rb * x1 + (1 - rb) * x2) + (1 - ra) * x3
-
-            # Local escaping operator
-            if np.random.rand() < self.pr:
-                f1 = np.random.uniform(-1, 1)
-                f2 = np.random.normal(0, 1)
-                L1 = np.round(1 - np.random.rand())
-                u1 = L1 * 2 * np.random.rand() + (1 - L1)
-                u2 = L1 * np.random.rand() + (1 - L1)
-                u3 = L1 * np.random.rand() + (1 - L1)
-
-                L2 = np.round(1 - np.random.rand())
-                x_rand = self.generate_position(self.problem.lb, self.problem.ub)
-                x_p = self.pop[np.random.choice(range(0, self.pop_size))][self.ID_POS]
-                x_m = L2 * x_p + (1 - L2) * x_rand
-
-                if np.random.rand() < 0.5:
-                    pos_new = pos_new + f1 * (u1 * self.g_best[self.ID_POS] - u2 * x_m) + \
-                              f2 * p1 * (u3 * (x2 - x1) + u2 * (self.pop[r1][self.ID_POS] - self.pop[r2][self.ID_POS])) / 2
-                else:
-                    pos_new = self.g_best[self.ID_POS] + f1 * (u1 * self.g_best[self.ID_POS] - u2 * x_m) + f2 * p1 * (
-                                u3 * (x2 - x1) + u2 * (self.pop[r1][self.ID_POS] - self.pop[r2][self.ID_POS])) / 2
-
-            # Check if solutions go outside the search space and bring them back
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(pop_new, self.pop)
-        _, best, worst = self.get_special_solutions(self.pop, best=1, worst=1)
-        self.g_best, self.g_worst = best[0], worst[0]
+#!/usr/bin/env python
+# Created by "Thieu" at 17:07, 02/03/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalGBO(Optimizer):
+    """
+    The original version of: Gradient-Based Optimizer (GBO)
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + pr (float): [0.2, 0.8], Probability Parameter, default = 0.5
+        + beta_min (float): Fixed parameter (no name in the paper), default = 0.2
+        + beta_max (float): Fixed parameter (no name in the paper), default = 1.2
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.math_based.GBO import OriginalGBO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> pr = 0.5
+    >>> beta_min = 0.2
+    >>> beta_max = 1.2
+    >>> model = OriginalGBO(epoch, pop_size, pr, beta_min, beta_max)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Ahmadianfar, I., Bozorg-Haddad, O. and Chu, X., 2020. Gradient-based optimizer:
+    A new metaheuristic optimization algorithm. Information Sciences, 540, pp.131-159.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, pr=0.5, beta_min=0.2, beta_max=1.2, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            pr (float): Probability Parameter, default = 0.5
+            beta_min (float): Fixed parameter (no name in the paper), default = 0.2
+            beta_max (float): Fixed parameter (no name in the paper), default = 1.2
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.pr = self.validator.check_float("pr", pr, (0, 1.0))
+        self.beta_min = self.validator.check_float("beta_min", beta_min, (0, 2.0))
+        self.beta_max = self.validator.check_float("beta_max", beta_max, (0, 5.0))
+        self.set_parameters(["epoch", "pop_size", "pr", "beta_min", "beta_max"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # Eq.(14.2), Eq.(14.1)
+        beta = self.beta_min + (self.beta_max - self.beta_min) * (1 - ((epoch + 1) / self.epoch) ** 3) ** 2
+        alpha = np.abs(beta * np.sin(3 * np.pi / 2 + np.sin(beta * 3 * np.pi / 2)))
+
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            p1 = 2 * np.random.rand() * alpha - alpha
+            p2 = 2 * np.random.rand() * alpha - alpha
+            #  Four positions randomly selected from population
+            r1, r2, r3, r4 = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 4, replace=False)
+            # Average of Four positions randomly selected from population
+            r0 = (self.pop[r1][self.ID_POS] + self.pop[r2][self.ID_POS] + self.pop[r3][self.ID_POS] + self.pop[r4][self.ID_POS]) / 4
+            # Randomization Epsilon
+            epsilon = 5e-3 * np.random.rand()
+
+            delta = 2 * np.random.rand() * np.abs(r0 - self.pop[idx][self.ID_POS])
+            step = (self.g_best[self.ID_POS] - self.pop[r1][self.ID_POS] + delta) / 2
+            delta_x = np.random.choice(range(0, self.pop_size)) * np.abs(step)
+            x1 = self.pop[idx][self.ID_POS] - np.random.normal() * p1 * 2 * delta_x * \
+                 self.pop[idx][self.ID_POS] / (self.g_worst[self.ID_POS] - self.g_best[self.ID_POS] + epsilon) + \
+                 np.random.rand() * p2 * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+
+            z = self.pop[idx][self.ID_POS] - np.random.normal() * 2 * delta_x * \
+                self.pop[idx][self.ID_POS] / (self.g_worst[self.ID_POS] - self.g_best[self.ID_POS] + epsilon)
+            y_p = np.random.rand() * ((z + self.pop[idx][self.ID_POS]) / 2 + np.random.rand() * delta_x)
+            y_q = np.random.rand() * ((z + self.pop[idx][self.ID_POS]) / 2 - np.random.rand() * delta_x)
+            x2 = self.g_best[self.ID_POS] - np.random.normal() * p1 * 2 * delta_x * self.pop[idx][self.ID_POS] / (y_p - y_q + epsilon) + \
+                 np.random.rand() * p2 * (self.pop[r1][self.ID_POS] - self.pop[r2][self.ID_POS])
+
+            x3 = self.pop[idx][self.ID_POS] - p1 * (x2 - x1)
+            ra = np.random.rand()
+            rb = np.random.rand()
+            pos_new = ra * (rb * x1 + (1 - rb) * x2) + (1 - ra) * x3
+
+            # Local escaping operator
+            if np.random.rand() < self.pr:
+                f1 = np.random.uniform(-1, 1)
+                f2 = np.random.normal(0, 1)
+                L1 = np.round(1 - np.random.rand())
+                u1 = L1 * 2 * np.random.rand() + (1 - L1)
+                u2 = L1 * np.random.rand() + (1 - L1)
+                u3 = L1 * np.random.rand() + (1 - L1)
+
+                L2 = np.round(1 - np.random.rand())
+                x_rand = self.generate_position(self.problem.lb, self.problem.ub)
+                x_p = self.pop[np.random.choice(range(0, self.pop_size))][self.ID_POS]
+                x_m = L2 * x_p + (1 - L2) * x_rand
+
+                if np.random.rand() < 0.5:
+                    pos_new = pos_new + f1 * (u1 * self.g_best[self.ID_POS] - u2 * x_m) + \
+                              f2 * p1 * (u3 * (x2 - x1) + u2 * (self.pop[r1][self.ID_POS] - self.pop[r2][self.ID_POS])) / 2
+                else:
+                    pos_new = self.g_best[self.ID_POS] + f1 * (u1 * self.g_best[self.ID_POS] - u2 * x_m) + f2 * p1 * (
+                                u3 * (x2 - x1) + u2 * (self.pop[r1][self.ID_POS] - self.pop[r2][self.ID_POS])) / 2
+
+            # Check if solutions go outside the search space and bring them back
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(pop_new, self.pop)
+        _, best, worst = self.get_special_solutions(self.pop, best=1, worst=1)
+        self.g_best, self.g_worst = best[0], worst[0]
```

### Comparing `mealpy-2.5.3/mealpy/math_based/HC.py` & `mealpy-2.5.3a1/mealpy/math_based/HC.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,162 +1,162 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 10:08, 02/03/2021 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalHC(Optimizer):
-    """
-    The original version of: Hill Climbing (HC)
-
-    Notes
-    ~~~~~
-    + The number of neighbour solutions are equal to user defined
-    + The step size to calculate neighbour is randomized
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + neighbour_size (int): [pop_size/2, pop_size], fixed parameter, sensitive exploitation parameter, Default: 50
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.math_based.HC import OriginalHC
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> neighbour_size = 50
-    >>> model = OriginalHC(epoch, pop_size, neighbour_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Mitchell, M., Holland, J. and Forrest, S., 1993. When will a genetic algorithm
-    outperform hill climbing. Advances in neural information processing systems, 6.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, neighbour_size=50, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            neighbour_size (int): fixed parameter, sensitive exploitation parameter, Default: 50
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.neighbour_size = self.validator.check_int("neighbour_size", neighbour_size, [2, self.pop_size])
-        self.set_parameters(["epoch", "pop_size", "neighbour_size"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        step_size = np.mean(self.problem.ub - self.problem.lb) * np.exp(-2 * (epoch + 1) / self.epoch)
-        pop_neighbours = []
-        for idx in range(0, self.neighbour_size):
-            pos_new = self.g_best[self.ID_POS] + np.random.normal(0, 1, self.problem.n_dims) * step_size
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_neighbours.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_neighbours[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop_neighbours = self.update_target_wrapper_population(pop_neighbours)
-        self.pop = pop_neighbours
-
-
-class SwarmHC(Optimizer):
-    """
-    The developed version: Swarm-based Hill Climbing (S-HC)
-
-    Notes
-    ~~~~~
-    + Based on swarm-of people are trying to climb on the mountain idea
-    + The number of neighbour solutions are equal to population size
-    + The step size to calculate neighbour is randomized and based on rank of solution.
-        + The guys near on top of mountain will move slower than the guys on bottom of mountain.
-        + Imagination: exploration when far from global best, and exploitation when near global best
-    + Who on top of mountain first will be the winner. (global optimal)
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + neighbour_size (int): [2, pop_size/2], fixed parameter, sensitive exploitation parameter, Default: 10
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.math_based.HC import SwarmHC
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> neighbour_size = 10
-    >>> model = SwarmHC(epoch, pop_size, neighbour_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, neighbour_size=10, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            neighbour_size (int): fixed parameter, sensitive exploitation parameter, Default: 10
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.neighbour_size = self.validator.check_int("neighbour_size", neighbour_size, [2, int(self.pop_size/2)])
-        self.set_parameters(["epoch", "pop_size", "neighbour_size"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        Args:
-            epoch (int): The current iteration
-        """
-        ranks = np.array(list(range(1, self.pop_size + 1)))
-        ranks = ranks / sum(ranks)
-        step_size = np.mean(self.problem.ub - self.problem.lb) * np.exp(-2 * (epoch + 1) / self.epoch)
-
-        pop = []
-        for idx in range(0, self.pop_size):
-            ss = step_size * ranks[idx]
-            pop_neighbours = []
-            for j in range(0, self.neighbour_size):
-                pos_new = self.pop[idx][self.ID_POS] + np.random.normal(0, 1, self.problem.n_dims) * ss
-                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                pop_neighbours.append([pos_new, None])
-                if self.mode not in self.AVAILABLE_MODES:
-                    pop_neighbours[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-            pop_neighbours = self.update_target_wrapper_population(pop_neighbours)
-            _, agent = self.get_global_best_solution(pop_neighbours)
-            pop.append(agent)
-            if self.mode not in self.AVAILABLE_MODES:
-                self.pop[idx] = self.get_better_solution(agent, self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            self.pop = self.greedy_selection_population(self.pop, pop)
+#!/usr/bin/env python
+# Created by "Thieu" at 10:08, 02/03/2021 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalHC(Optimizer):
+    """
+    The original version of: Hill Climbing (HC)
+
+    Notes
+    ~~~~~
+    + The number of neighbour solutions are equal to user defined
+    + The step size to calculate neighbour is randomized
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + neighbour_size (int): [pop_size/2, pop_size], fixed parameter, sensitive exploitation parameter, Default: 50
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.math_based.HC import OriginalHC
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> neighbour_size = 50
+    >>> model = OriginalHC(epoch, pop_size, neighbour_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Mitchell, M., Holland, J. and Forrest, S., 1993. When will a genetic algorithm
+    outperform hill climbing. Advances in neural information processing systems, 6.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, neighbour_size=50, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            neighbour_size (int): fixed parameter, sensitive exploitation parameter, Default: 50
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.neighbour_size = self.validator.check_int("neighbour_size", neighbour_size, [2, self.pop_size])
+        self.set_parameters(["epoch", "pop_size", "neighbour_size"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        step_size = np.mean(self.problem.ub - self.problem.lb) * np.exp(-2 * (epoch + 1) / self.epoch)
+        pop_neighbours = []
+        for idx in range(0, self.neighbour_size):
+            pos_new = self.g_best[self.ID_POS] + np.random.normal(0, 1, self.problem.n_dims) * step_size
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_neighbours.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_neighbours[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop_neighbours = self.update_target_wrapper_population(pop_neighbours)
+        self.pop = pop_neighbours
+
+
+class SwarmHC(Optimizer):
+    """
+    The developed version: Swarm-based Hill Climbing (S-HC)
+
+    Notes
+    ~~~~~
+    + Based on swarm-of people are trying to climb on the mountain idea
+    + The number of neighbour solutions are equal to population size
+    + The step size to calculate neighbour is randomized and based on rank of solution.
+        + The guys near on top of mountain will move slower than the guys on bottom of mountain.
+        + Imagination: exploration when far from global best, and exploitation when near global best
+    + Who on top of mountain first will be the winner. (global optimal)
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + neighbour_size (int): [2, pop_size/2], fixed parameter, sensitive exploitation parameter, Default: 10
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.math_based.HC import SwarmHC
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> neighbour_size = 10
+    >>> model = SwarmHC(epoch, pop_size, neighbour_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, neighbour_size=10, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            neighbour_size (int): fixed parameter, sensitive exploitation parameter, Default: 10
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.neighbour_size = self.validator.check_int("neighbour_size", neighbour_size, [2, int(self.pop_size/2)])
+        self.set_parameters(["epoch", "pop_size", "neighbour_size"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        Args:
+            epoch (int): The current iteration
+        """
+        ranks = np.array(list(range(1, self.pop_size + 1)))
+        ranks = ranks / sum(ranks)
+        step_size = np.mean(self.problem.ub - self.problem.lb) * np.exp(-2 * (epoch + 1) / self.epoch)
+
+        pop = []
+        for idx in range(0, self.pop_size):
+            ss = step_size * ranks[idx]
+            pop_neighbours = []
+            for j in range(0, self.neighbour_size):
+                pos_new = self.pop[idx][self.ID_POS] + np.random.normal(0, 1, self.problem.n_dims) * ss
+                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                pop_neighbours.append([pos_new, None])
+                if self.mode not in self.AVAILABLE_MODES:
+                    pop_neighbours[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+            pop_neighbours = self.update_target_wrapper_population(pop_neighbours)
+            _, agent = self.get_global_best_solution(pop_neighbours)
+            pop.append(agent)
+            if self.mode not in self.AVAILABLE_MODES:
+                self.pop[idx] = self.get_better_solution(agent, self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            self.pop = self.greedy_selection_population(self.pop, pop)
```

### Comparing `mealpy-2.5.3/mealpy/math_based/INFO.py` & `mealpy-2.5.3a1/mealpy/math_based/INFO.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,153 +1,153 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 17:29, 21/05/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalINFO(Optimizer):
-    """
-    The original version of: weIghted meaN oF vectOrs (INFO)
-
-    Links:
-        1. https://www.sciencedirect.com/science/article/abs/pii/S0957417422000173
-        2. https://aliasgharheidari.com/INFO.html
-        3. https://doi.org/10.1016/j.eswa.2022.116516
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.math_based.PSS import OriginalPSS
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalINFO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Ahmadianfar, I., Heidari, A. A., Noshadian, S., Chen, H., & Gandomi, A. H. (2022). INFO: An efficient optimization
-    algorithm based on weighted mean of vectors. Expert Systems with Applications, 195, 116516.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = True
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        alpha = 2 * np.exp(-4 * ((self.epoch+1) / self.epoch))      # Eqs.(5.1) - Eq.(9.1)
-
-        idx_better = np.random.randint(2, 6)
-        better = self.pop[idx_better]
-        g_worst = self.pop[-1]
-
-        pop_new = []
-        for idx in range(0, self.pop_size):
-
-            ## Updating rule stage
-            delta = 2 * np.random.rand() * alpha - alpha            # Eq. (5)
-            sigma = 2 * np.random.rand() * alpha - alpha            # Eq. (9)
-
-            ## Select three random solution
-            a, b, c = np.random.choice(range(0, self.pop_size), 3, replace=False)
-            e1 = 1e-25
-            epsilon = e1 * np.random.rand()
-
-            fit_a = self.pop[a][self.ID_TAR][self.ID_FIT]
-            fit_b = self.pop[b][self.ID_TAR][self.ID_FIT]
-            fit_c = self.pop[c][self.ID_TAR][self.ID_FIT]
-            omg1 = np.max([fit_a, fit_b, fit_c])
-            MM1 = np.array([fit_a - fit_b, fit_a - fit_c, fit_b - fit_c])
-
-            w1 = np.cos(MM1[0] + np.pi) * np.exp(-np.abs(MM1[0] / omg1))       # Eq. (4.2)
-            w2 = np.cos(MM1[1] + np.pi) * np.exp(-np.abs(MM1[1] / omg1))       # Eq. (4.3)
-            w3 = np.cos(MM1[2] + np.pi) * np.exp(-np.abs(MM1[2] / omg1))       # Eq. (4.4)
-            Wt1 = np.sum([w1, w2, w3])
-            WM1 = delta * (w1 * (self.pop[a][self.ID_POS] - self.pop[b][self.ID_POS]) +         #  Eq.(4.1)
-                w2 * (self.pop[a][self.ID_POS] - self.pop[c][self.ID_POS]) +
-                w3 * (self.pop[b][self.ID_POS] - self.pop[c][self.ID_POS])) / (Wt1 + 1) + epsilon
-
-            fit_1 = self.g_best[self.ID_TAR][self.ID_FIT]
-            fit_2 = better[self.ID_TAR][self.ID_FIT]
-            fit_3 = g_worst[self.ID_TAR][self.ID_FIT]
-            omg2 = np.max([fit_1, fit_2, fit_3])
-            MM2 = np.array([fit_1 - fit_2, fit_1 - fit_3, fit_2 - fit_3])
-            w4 = np.cos(MM2[0] + np.pi) * np.exp(-np.abs(MM2[0] / omg2))        # Eq. (4.7)
-            w5 = np.cos(MM2[1] + np.pi) * np.exp(-np.abs(MM2[1] / omg2))        # Eq. (4.8)
-            w6 = np.cos(MM2[2] + np.pi) * np.exp(-np.abs(MM2[2] / omg2))        # Eq. (4.9)
-            Wt2 = np.sum([w4, w5, w6])
-            WM2 = delta * (w4 * (self.g_best[self.ID_POS] - better[self.ID_POS]) +          # Eq. (4.6)
-                           w5 * (self.g_best[self.ID_POS] - g_worst[self.ID_POS]) +
-                            w6 * (better[self.ID_POS] - g_worst[self.ID_POS])) / (Wt2 + 1) + epsilon
-
-            ## Determine MeanRule
-            r = np.random.uniform(0.1, 0.5)
-            mean_rule = r * WM1 + (1 - r) * WM2         # Eq. (4)
-
-            if np.random.random() < 0.5:                # Eq. (8)
-                z1 = self.pop[idx][self.ID_POS] + sigma * (np.random.rand() * mean_rule) + np.random.rand() * \
-                     (self.g_best[self.ID_POS] - self.pop[a][self.ID_POS]) / (fit_1 - fit_a + 1)
-                z2 = self.g_best[self.ID_POS] + sigma * (np.random.rand() * mean_rule) + np.random.rand() * \
-                     (self.pop[a][self.ID_POS] - self.pop[b][self.ID_POS]) / (fit_a - fit_b + 1)
-            else:
-                z1 = self.pop[a][self.ID_POS] + sigma * (np.random.rand() * mean_rule) + np.random.rand() * \
-                     (self.pop[b][self.ID_POS] - self.pop[c][self.ID_POS]) / (fit_b - fit_c + 1)
-                z2 = better[self.ID_POS] + sigma * (np.random.rand() * mean_rule) + np.random.rand() * \
-                     (self.pop[a][self.ID_POS] - self.pop[b][self.ID_POS]) / (fit_a - fit_b + 1)
-
-            ## Vector combining stage
-            mu = 0.05 * np.random.random(self.problem.n_dims)
-            u1 = z1 + mu * np.abs(z1 - z2)      # Eq. (10.1)
-            u2 = z2 + mu * np.abs(z1 - z2)      # Eq. (10.2)
-
-            cond1 = np.random.random(self.problem.n_dims) < 0.05
-            cond2 = np.random.random(self.problem.n_dims) < 0.05
-            x1 = np.where(cond1, u1, u2)
-            pos_new = np.where(cond2, x1, self.pop[idx][self.ID_POS])       # Eq. (10.3)
-
-            ## Local search stage
-            if np.random.rand() < 0.5:
-                L = int(np.random.rand() < 0.5)     # 0 or 1
-                v1 = (1 - L) * 2 * np.random.rand() + L     # Eqs. (11.5)
-                v2 = np.random.rand() * L + (1 - L)         # Eq. (11.6)
-                x_avg = (self.pop[a][self.ID_POS] + self.pop[b][self.ID_POS] + self.pop[c][self.ID_POS]) / 3            # Eq. (11.4)
-                phi = np.random.rand()
-                x_rand = phi * x_avg + (1 - phi) * (phi * better[self.ID_POS] + (1 - phi) * self.g_best[self.ID_POS])   # Eq. (11.3)
-                n_rand = L * np.random.random(self.problem.n_dims) + (1 - L) * np.random.rand()
-                if np.random.rand() < 0.5:          # Eq. (11.1)
-                    pos_new = self.g_best[self.ID_POS] + n_rand * (mean_rule + np.random.rand() * (self.g_best[self.ID_POS] - self.pop[a][self.ID_POS]))
-                else:                               # Eq. (11.2)
-                    pos_new = x_rand + n_rand * (mean_rule + np.random.rand() * (v1 * self.g_best[self.ID_POS] - v2 * x_rand))
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        self.pop = self.update_target_wrapper_population(pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 17:29, 21/05/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalINFO(Optimizer):
+    """
+    The original version of: weIghted meaN oF vectOrs (INFO)
+
+    Links:
+        1. https://www.sciencedirect.com/science/article/abs/pii/S0957417422000173
+        2. https://aliasgharheidari.com/INFO.html
+        3. https://doi.org/10.1016/j.eswa.2022.116516
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.math_based.PSS import OriginalPSS
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalINFO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Ahmadianfar, I., Heidari, A. A., Noshadian, S., Chen, H., & Gandomi, A. H. (2022). INFO: An efficient optimization
+    algorithm based on weighted mean of vectors. Expert Systems with Applications, 195, 116516.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = True
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        alpha = 2 * np.exp(-4 * ((self.epoch+1) / self.epoch))      # Eqs.(5.1) - Eq.(9.1)
+
+        idx_better = np.random.randint(2, 6)
+        better = self.pop[idx_better]
+        g_worst = self.pop[-1]
+
+        pop_new = []
+        for idx in range(0, self.pop_size):
+
+            ## Updating rule stage
+            delta = 2 * np.random.rand() * alpha - alpha            # Eq. (5)
+            sigma = 2 * np.random.rand() * alpha - alpha            # Eq. (9)
+
+            ## Select three random solution
+            a, b, c = np.random.choice(range(0, self.pop_size), 3, replace=False)
+            e1 = 1e-25
+            epsilon = e1 * np.random.rand()
+
+            fit_a = self.pop[a][self.ID_TAR][self.ID_FIT]
+            fit_b = self.pop[b][self.ID_TAR][self.ID_FIT]
+            fit_c = self.pop[c][self.ID_TAR][self.ID_FIT]
+            omg1 = np.max([fit_a, fit_b, fit_c])
+            MM1 = np.array([fit_a - fit_b, fit_a - fit_c, fit_b - fit_c])
+
+            w1 = np.cos(MM1[0] + np.pi) * np.exp(-np.abs(MM1[0] / omg1))       # Eq. (4.2)
+            w2 = np.cos(MM1[1] + np.pi) * np.exp(-np.abs(MM1[1] / omg1))       # Eq. (4.3)
+            w3 = np.cos(MM1[2] + np.pi) * np.exp(-np.abs(MM1[2] / omg1))       # Eq. (4.4)
+            Wt1 = np.sum([w1, w2, w3])
+            WM1 = delta * (w1 * (self.pop[a][self.ID_POS] - self.pop[b][self.ID_POS]) +         #  Eq.(4.1)
+                w2 * (self.pop[a][self.ID_POS] - self.pop[c][self.ID_POS]) +
+                w3 * (self.pop[b][self.ID_POS] - self.pop[c][self.ID_POS])) / (Wt1 + 1) + epsilon
+
+            fit_1 = self.g_best[self.ID_TAR][self.ID_FIT]
+            fit_2 = better[self.ID_TAR][self.ID_FIT]
+            fit_3 = g_worst[self.ID_TAR][self.ID_FIT]
+            omg2 = np.max([fit_1, fit_2, fit_3])
+            MM2 = np.array([fit_1 - fit_2, fit_1 - fit_3, fit_2 - fit_3])
+            w4 = np.cos(MM2[0] + np.pi) * np.exp(-np.abs(MM2[0] / omg2))        # Eq. (4.7)
+            w5 = np.cos(MM2[1] + np.pi) * np.exp(-np.abs(MM2[1] / omg2))        # Eq. (4.8)
+            w6 = np.cos(MM2[2] + np.pi) * np.exp(-np.abs(MM2[2] / omg2))        # Eq. (4.9)
+            Wt2 = np.sum([w4, w5, w6])
+            WM2 = delta * (w4 * (self.g_best[self.ID_POS] - better[self.ID_POS]) +          # Eq. (4.6)
+                           w5 * (self.g_best[self.ID_POS] - g_worst[self.ID_POS]) +
+                            w6 * (better[self.ID_POS] - g_worst[self.ID_POS])) / (Wt2 + 1) + epsilon
+
+            ## Determine MeanRule
+            r = np.random.uniform(0.1, 0.5)
+            mean_rule = r * WM1 + (1 - r) * WM2         # Eq. (4)
+
+            if np.random.random() < 0.5:                # Eq. (8)
+                z1 = self.pop[idx][self.ID_POS] + sigma * (np.random.rand() * mean_rule) + np.random.rand() * \
+                     (self.g_best[self.ID_POS] - self.pop[a][self.ID_POS]) / (fit_1 - fit_a + 1)
+                z2 = self.g_best[self.ID_POS] + sigma * (np.random.rand() * mean_rule) + np.random.rand() * \
+                     (self.pop[a][self.ID_POS] - self.pop[b][self.ID_POS]) / (fit_a - fit_b + 1)
+            else:
+                z1 = self.pop[a][self.ID_POS] + sigma * (np.random.rand() * mean_rule) + np.random.rand() * \
+                     (self.pop[b][self.ID_POS] - self.pop[c][self.ID_POS]) / (fit_b - fit_c + 1)
+                z2 = better[self.ID_POS] + sigma * (np.random.rand() * mean_rule) + np.random.rand() * \
+                     (self.pop[a][self.ID_POS] - self.pop[b][self.ID_POS]) / (fit_a - fit_b + 1)
+
+            ## Vector combining stage
+            mu = 0.05 * np.random.random(self.problem.n_dims)
+            u1 = z1 + mu * np.abs(z1 - z2)      # Eq. (10.1)
+            u2 = z2 + mu * np.abs(z1 - z2)      # Eq. (10.2)
+
+            cond1 = np.random.random(self.problem.n_dims) < 0.05
+            cond2 = np.random.random(self.problem.n_dims) < 0.05
+            x1 = np.where(cond1, u1, u2)
+            pos_new = np.where(cond2, x1, self.pop[idx][self.ID_POS])       # Eq. (10.3)
+
+            ## Local search stage
+            if np.random.rand() < 0.5:
+                L = int(np.random.rand() < 0.5)     # 0 or 1
+                v1 = (1 - L) * 2 * np.random.rand() + L     # Eqs. (11.5)
+                v2 = np.random.rand() * L + (1 - L)         # Eq. (11.6)
+                x_avg = (self.pop[a][self.ID_POS] + self.pop[b][self.ID_POS] + self.pop[c][self.ID_POS]) / 3            # Eq. (11.4)
+                phi = np.random.rand()
+                x_rand = phi * x_avg + (1 - phi) * (phi * better[self.ID_POS] + (1 - phi) * self.g_best[self.ID_POS])   # Eq. (11.3)
+                n_rand = L * np.random.random(self.problem.n_dims) + (1 - L) * np.random.rand()
+                if np.random.rand() < 0.5:          # Eq. (11.1)
+                    pos_new = self.g_best[self.ID_POS] + n_rand * (mean_rule + np.random.rand() * (self.g_best[self.ID_POS] - self.pop[a][self.ID_POS]))
+                else:                               # Eq. (11.2)
+                    pos_new = x_rand + n_rand * (mean_rule + np.random.rand() * (v1 * self.g_best[self.ID_POS] - v2 * x_rand))
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        self.pop = self.update_target_wrapper_population(pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/math_based/PSS.py` & `mealpy-2.5.3a1/mealpy/math_based/PSS.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,140 +1,140 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 19:38, 10/03/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from scipy.stats import qmc
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalPSS(Optimizer):
-    """
-    The original version of: Pareto-like Sequential Sampling (PSS)
-
-    Links:
-        1. https://doi.org/10.1007/s00500-021-05853-8
-        2. https://github.com/eesd-epfl/pareto-optimizer
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + acceptance_rate (float): [0.7-0.96], the probability of accepting a solution in the normal range, default=0.9
-        + sampling_method (str): 'LHS': Latin-Hypercube or 'MC': 'MonteCarlo', default="LHS"
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.math_based.PSS import OriginalPSS
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> acceptance_rate = 0.8
-    >>> sampling_method = "LHS"
-    >>> model = OriginalPSS(epoch, pop_size, acceptance_rate, sampling_method)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Shaqfa, M. and Beyer, K., 2021. Pareto-like sequential sampling heuristic for global optimisation. Soft Computing, 25(14), pp.9077-9096.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, acceptance_rate=0.9, sampling_method="LHS", **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            acceptance_rate (float): the probability of accepting a solution in the normal range, default = 0.9
-            sampling_method (str): 'LHS': Latin-Hypercube or 'MC': 'MonteCarlo', default = "LHS"
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.acceptance_rate = self.validator.check_float("acceptance_rate", acceptance_rate, (0, 1.0))
-        self.sampling_method = self.validator.check_str("sampling_method", sampling_method, ["MC", "LHS"])
-        self.set_parameters(["epoch", "pop_size", "acceptance_rate", "sampling_method"])
-        self.sort_flag = False
-
-    def initialize_variables(self):
-        self.step = 10e-10
-        self.steps = np.ones(self.problem.n_dims) * self.step
-        self.new_solution = True
-
-    def create_population(self, pop_size=None):
-        if self.sampling_method == "MC":
-            pop = np.random.rand(self.pop_size, self.problem.n_dims)
-        else:       # Default: "LHS"
-            sampler = qmc.LatinHypercube(d=self.problem.n_dims)
-            pop = sampler.random(n=pop_size)
-        return pop
-
-    def initialization(self):
-        lb_pop = np.repeat(np.reshape(self.problem.lb, (1, -1)), self.pop_size, axis=0)
-        ub_pop = np.repeat(np.reshape(self.problem.ub, (1, -1)), self.pop_size, axis=0)
-        steps_mat = np.repeat(np.reshape(self.steps, (1, -1)), self.pop_size, axis=0)
-
-        random_pop = self.create_population(self.pop_size)
-        pop = np.round((lb_pop + random_pop * (ub_pop - lb_pop)) / steps_mat) * steps_mat
-        self.pop = []
-        for pos in pop:
-            pos_new = self.amend_position(pos, self.problem.lb, self.problem.ub)
-            target = self.get_target_wrapper(pos_new)
-            self.pop.append([pos_new, target])
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = []
-        pop_rand = self.create_population(self.pop_size)
-        for idx in range(0, self.pop_size):
-            pos_new = deepcopy(self.pop[idx][self.ID_POS]).astype(float)
-            for k in range(self.problem.n_dims):
-                # Update the ranges
-                deviation = np.random.uniform(0, self.g_best[self.ID_POS][k])
-                if self.new_solution:
-                    # The deviation is positive dynamic real number
-                    deviation = abs(0.5 * (1. - self.acceptance_rate) * (self.problem.ub[k] - self.problem.lb[k])) * (1 - ((epoch+1) / self.epoch))
-
-                reduced_lb = self.g_best[self.ID_POS][k] - deviation
-                reduced_lb = np.amax([reduced_lb, self.problem.lb[k]])
-
-                reduced_ub = reduced_lb + deviation * 2.
-                reduced_ub = np.amin([reduced_ub, self.problem.ub[k]])
-
-                # Choose new solution
-                if np.random.rand() <= self.acceptance_rate:
-                    # choose a solution from the prominent domain
-                    pos_new[k] = reduced_lb + pop_rand[idx, k] * (reduced_ub - reduced_lb)
-                else:
-                    # choose a solution from the overall domain
-                    pos_new[k] = self.problem.lb[k] + pop_rand[idx, k] * (self.problem.ub[k] - self.problem.lb[k])
-
-                # Round for the step size
-                pos_new = np.round(pos_new / self.steps) * self.steps
-            # Check the bound
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop_new = self.update_target_wrapper_population(pop_new)
-        self.pop = pop_new
-        _, current_best = self.get_global_best_solution(pop_new)
-        if self.compare_agent(current_best, self.g_best):
-            self.new_solution = True
-        else:
-            self.new_solution = False
+#!/usr/bin/env python
+# Created by "Thieu" at 19:38, 10/03/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from scipy.stats import qmc
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalPSS(Optimizer):
+    """
+    The original version of: Pareto-like Sequential Sampling (PSS)
+
+    Links:
+        1. https://doi.org/10.1007/s00500-021-05853-8
+        2. https://github.com/eesd-epfl/pareto-optimizer
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + acceptance_rate (float): [0.7-0.96], the probability of accepting a solution in the normal range, default=0.9
+        + sampling_method (str): 'LHS': Latin-Hypercube or 'MC': 'MonteCarlo', default="LHS"
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.math_based.PSS import OriginalPSS
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> acceptance_rate = 0.8
+    >>> sampling_method = "LHS"
+    >>> model = OriginalPSS(epoch, pop_size, acceptance_rate, sampling_method)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Shaqfa, M. and Beyer, K., 2021. Pareto-like sequential sampling heuristic for global optimisation. Soft Computing, 25(14), pp.9077-9096.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, acceptance_rate=0.9, sampling_method="LHS", **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            acceptance_rate (float): the probability of accepting a solution in the normal range, default = 0.9
+            sampling_method (str): 'LHS': Latin-Hypercube or 'MC': 'MonteCarlo', default = "LHS"
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.acceptance_rate = self.validator.check_float("acceptance_rate", acceptance_rate, (0, 1.0))
+        self.sampling_method = self.validator.check_str("sampling_method", sampling_method, ["MC", "LHS"])
+        self.set_parameters(["epoch", "pop_size", "acceptance_rate", "sampling_method"])
+        self.sort_flag = False
+
+    def initialize_variables(self):
+        self.step = 10e-10
+        self.steps = np.ones(self.problem.n_dims) * self.step
+        self.new_solution = True
+
+    def create_population(self, pop_size=None):
+        if self.sampling_method == "MC":
+            pop = np.random.rand(self.pop_size, self.problem.n_dims)
+        else:       # Default: "LHS"
+            sampler = qmc.LatinHypercube(d=self.problem.n_dims)
+            pop = sampler.random(n=pop_size)
+        return pop
+
+    def initialization(self):
+        lb_pop = np.repeat(np.reshape(self.problem.lb, (1, -1)), self.pop_size, axis=0)
+        ub_pop = np.repeat(np.reshape(self.problem.ub, (1, -1)), self.pop_size, axis=0)
+        steps_mat = np.repeat(np.reshape(self.steps, (1, -1)), self.pop_size, axis=0)
+
+        random_pop = self.create_population(self.pop_size)
+        pop = np.round((lb_pop + random_pop * (ub_pop - lb_pop)) / steps_mat) * steps_mat
+        self.pop = []
+        for pos in pop:
+            pos_new = self.amend_position(pos, self.problem.lb, self.problem.ub)
+            target = self.get_target_wrapper(pos_new)
+            self.pop.append([pos_new, target])
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = []
+        pop_rand = self.create_population(self.pop_size)
+        for idx in range(0, self.pop_size):
+            pos_new = deepcopy(self.pop[idx][self.ID_POS]).astype(float)
+            for k in range(self.problem.n_dims):
+                # Update the ranges
+                deviation = np.random.uniform(0, self.g_best[self.ID_POS][k])
+                if self.new_solution:
+                    # The deviation is positive dynamic real number
+                    deviation = abs(0.5 * (1. - self.acceptance_rate) * (self.problem.ub[k] - self.problem.lb[k])) * (1 - ((epoch+1) / self.epoch))
+
+                reduced_lb = self.g_best[self.ID_POS][k] - deviation
+                reduced_lb = np.amax([reduced_lb, self.problem.lb[k]])
+
+                reduced_ub = reduced_lb + deviation * 2.
+                reduced_ub = np.amin([reduced_ub, self.problem.ub[k]])
+
+                # Choose new solution
+                if np.random.rand() <= self.acceptance_rate:
+                    # choose a solution from the prominent domain
+                    pos_new[k] = reduced_lb + pop_rand[idx, k] * (reduced_ub - reduced_lb)
+                else:
+                    # choose a solution from the overall domain
+                    pos_new[k] = self.problem.lb[k] + pop_rand[idx, k] * (self.problem.ub[k] - self.problem.lb[k])
+
+                # Round for the step size
+                pos_new = np.round(pos_new / self.steps) * self.steps
+            # Check the bound
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop_new = self.update_target_wrapper_population(pop_new)
+        self.pop = pop_new
+        _, current_best = self.get_global_best_solution(pop_new)
+        if self.compare_agent(current_best, self.g_best):
+            self.new_solution = True
+        else:
+            self.new_solution = False
```

### Comparing `mealpy-2.5.3/mealpy/math_based/RUN.py` & `mealpy-2.5.3a1/mealpy/math_based/RUN.py`

 * *Ordering differences only*

 * *Files 15% similar despite different names*

```diff
@@ -1,153 +1,153 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 07:50, 14/10/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalRUN(Optimizer):
-    """
-    The original version of: RUNge Kutta optimizer (RUN)
-
-    Links:
-        1. https://doi.org/10.1016/j.eswa.2021.115079
-        2. https://imanahmadianfar.com/codes/
-        3. https://www.aliasgharheidari.com/RUN.html
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.math_based.PSS import OriginalPSS
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalRUN(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Ahmadianfar, I., Heidari, A. A., Gandomi, A. H., Chu, X., & Chen, H. (2021). RUN beyond the metaphor: An efficient
-    optimization algorithm based on Runge Kutta method. Expert Systems with Applications, 181, 115079.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.support_parallel_modes = False
-        self.sort_flag = False
-
-    def runge_kutta__(self, xb, xw, delta_x):
-        dim = len(xb)
-        C = np.random.randint(1, 3) * (1 - np.random.rand())
-        r1 = np.random.random(dim)
-        r2 = np.random.random(dim)
-        K1 = 0.5 * (np.random.rand() * xw - C * xb)
-        K2 = 0.5 * (np.random.rand() * (xw + r2*K1*delta_x/2) - (C*xb + r1*K1*delta_x/2))
-        K3 = 0.5 * (np.random.rand() * (xw + r2*K2*delta_x/2) - (C*xb + r1*K2*delta_x/2))
-        K4 = 0.5 * (np.random.rand() * (xw + r2*K3*delta_x) - (C*xb + r1*K3*delta_x))
-        return (K1 + 2*K2 + 2*K3 + K4)/6
-
-    def uniform_random__(self, a, b, size):
-        a2, b2 = a/2, b/2
-        mu = a2 + b2
-        sig = b2 - a2
-        return mu + sig * (2 * np.random.uniform(0, 1, size) - 1)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        f = 20 * np.exp(-(12. * (epoch+1) / self.epoch))        # Eq.17.6
-        SF = 2.*(0.5 - np.random.random(self.pop_size)) * f     # Eq.17.5
-        x_list = np.array([agent[self.ID_POS] for agent in self.pop])
-        x_average = np.mean(x_list, axis=0)     # Determine the Average of Solutions
-        for idx in range(0, self.pop_size):
-            ## Determine Delta X (Eqs. 11.1 to 11.3)
-            gama = np.random.rand() * (self.pop[idx][self.ID_POS] - np.random.uniform(0, 1, self.problem.n_dims) *
-                                       (self.problem.ub - self.problem.lb)) * np.exp(-4*(epoch+1) / self.epoch)
-            stp = np.random.uniform(0, 1, self.problem.n_dims) * ((self.g_best[self.ID_POS] - np.random.rand() * x_average) + gama)
-            delta_x = 2 * np.random.uniform(0, 1, self.problem.n_dims) * np.abs(stp)
-
-            ## Determine Three Random Indices of Solutions
-            a, b, c = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 3, replace=False)
-            id_min_x = self.get_index_best([self.pop[a], self.pop[b], self.pop[c]])
-            ## Determine Xb and Xw for using in Runge Kutta method
-            if self.compare_agent(self.pop[idx], self.pop[id_min_x]):
-                xb, xw = self.pop[idx][self.ID_POS], self.pop[id_min_x][self.ID_POS]
-            else:
-                xb, xw = self.pop[id_min_x][self.ID_POS], self.pop[idx][self.ID_POS]
-            ## Search Mechanism (SM) of RUN based on Runge Kutta Method
-            SM = self.runge_kutta__(xb, xw, delta_x)
-
-            _, local_best = self.get_global_best_solution(self.pop)
-            L = np.random.choice(range(0, 2), self.problem.n_dims)
-            xc = L * self.pop[idx][self.ID_POS] + (1 - L) * self.pop[a][self.ID_POS]        # Eq. 17.3
-            xm = L * self.g_best[self.ID_POS] + (1 - L) * local_best[self.ID_POS]           # Eq. 17.4
-
-            r = np.random.choice([1, -1], self.problem.n_dims)          # An Interger number
-            g = 2 * np.random.rand()
-            mu = 0.5 + 1 * np.random.uniform(0, 1, self.problem.n_dims)
-
-            ## Determine New Solution Based on Runge Kutta Method (Eq.18)
-            if np.random.rand() < 0.5:
-                pos_new = xc + r * SF[idx] * g * xc + SF[idx] * SM + mu * (xm - xc)
-            else:
-                pos_new = xm + r * SF[idx] * g * xm + SF[idx] * SM + mu * (self.pop[a][self.ID_POS] - self.pop[b][self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            tar_new = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
-                self.pop[idx] = [pos_new, tar_new]
-
-            ## Enhanced solution quality (ESQ)  (Eq. 19)
-            if np.random.rand() < 0.5:
-                w = self.uniform_random__(0, 2, self.problem.n_dims) * np.exp(-5*np.random.rand() * (epoch + 1) / self.epoch)        # Eq.19-1
-                r = np.floor(self.uniform_random__(-1, 2, 1))
-                u = 2 * np.random.random(self.problem.n_dims)
-
-                a, b, c = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 3, replace=False)
-                x_ave = (self.pop[a][self.ID_POS] + self.pop[b][self.ID_POS] + self.pop[c][self.ID_POS]) / 3                # Eq.19-2
-
-                beta = np.random.random(self.problem.n_dims)
-                x_new1 = beta * self.g_best[self.ID_POS] + (1 - beta) * x_ave                                               # Eq.19-3
-
-                x_new2_temp1 = x_new1 + r*w * np.abs(np.random.normal(0, 1, self.problem.n_dims) + (x_new1 - x_ave))
-                x_new2_temp2 = x_new1 - x_ave + r*w*np.abs(np.random.normal(0, 1, self.problem.n_dims) + u * x_new1 - x_ave)
-                x_new2 = np.where(w < 1, x_new2_temp1, x_new2_temp2)
-                pos_new2 = self.amend_position(x_new2, self.problem.lb, self.problem.ub)
-                tar_new2 = self.get_target_wrapper(pos_new2)
-
-                if self.compare_agent([pos_new2, tar_new2], self.pop[idx]):
-                    self.pop[idx] = [pos_new2, tar_new2]
-                else:
-                    if w[np.random.randint(0, self.problem.n_dims)] > np.random.rand():
-                        SM = self.runge_kutta__(self.pop[idx][self.ID_POS], pos_new2, delta_x)
-                        x_new3 = pos_new2 - np.random.rand()*pos_new2 + \
-                                 SF[idx] * (SM + (2 * np.random.random(self.problem.n_dims)*self.g_best[self.ID_POS] - pos_new2))       # Eq. 20
-                        pos_new3 = self.amend_position(x_new3, self.problem.lb, self.problem.ub)
-                        tar_new3 = self.get_target_wrapper(pos_new3)
-                        if self.compare_agent([pos_new3, tar_new3], self.pop[idx]):
-                            self.pop[idx] = [pos_new3, tar_new3]
+#!/usr/bin/env python
+# Created by "Thieu" at 07:50, 14/10/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalRUN(Optimizer):
+    """
+    The original version of: RUNge Kutta optimizer (RUN)
+
+    Links:
+        1. https://doi.org/10.1016/j.eswa.2021.115079
+        2. https://imanahmadianfar.com/codes/
+        3. https://www.aliasgharheidari.com/RUN.html
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.math_based.PSS import OriginalPSS
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalRUN(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Ahmadianfar, I., Heidari, A. A., Gandomi, A. H., Chu, X., & Chen, H. (2021). RUN beyond the metaphor: An efficient
+    optimization algorithm based on Runge Kutta method. Expert Systems with Applications, 181, 115079.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.support_parallel_modes = False
+        self.sort_flag = False
+
+    def runge_kutta__(self, xb, xw, delta_x):
+        dim = len(xb)
+        C = np.random.randint(1, 3) * (1 - np.random.rand())
+        r1 = np.random.random(dim)
+        r2 = np.random.random(dim)
+        K1 = 0.5 * (np.random.rand() * xw - C * xb)
+        K2 = 0.5 * (np.random.rand() * (xw + r2*K1*delta_x/2) - (C*xb + r1*K1*delta_x/2))
+        K3 = 0.5 * (np.random.rand() * (xw + r2*K2*delta_x/2) - (C*xb + r1*K2*delta_x/2))
+        K4 = 0.5 * (np.random.rand() * (xw + r2*K3*delta_x) - (C*xb + r1*K3*delta_x))
+        return (K1 + 2*K2 + 2*K3 + K4)/6
+
+    def uniform_random__(self, a, b, size):
+        a2, b2 = a/2, b/2
+        mu = a2 + b2
+        sig = b2 - a2
+        return mu + sig * (2 * np.random.uniform(0, 1, size) - 1)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        f = 20 * np.exp(-(12. * (epoch+1) / self.epoch))        # Eq.17.6
+        SF = 2.*(0.5 - np.random.random(self.pop_size)) * f     # Eq.17.5
+        x_list = np.array([agent[self.ID_POS] for agent in self.pop])
+        x_average = np.mean(x_list, axis=0)     # Determine the Average of Solutions
+        for idx in range(0, self.pop_size):
+            ## Determine Delta X (Eqs. 11.1 to 11.3)
+            gama = np.random.rand() * (self.pop[idx][self.ID_POS] - np.random.uniform(0, 1, self.problem.n_dims) *
+                                       (self.problem.ub - self.problem.lb)) * np.exp(-4*(epoch+1) / self.epoch)
+            stp = np.random.uniform(0, 1, self.problem.n_dims) * ((self.g_best[self.ID_POS] - np.random.rand() * x_average) + gama)
+            delta_x = 2 * np.random.uniform(0, 1, self.problem.n_dims) * np.abs(stp)
+
+            ## Determine Three Random Indices of Solutions
+            a, b, c = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 3, replace=False)
+            id_min_x = self.get_index_best([self.pop[a], self.pop[b], self.pop[c]])
+            ## Determine Xb and Xw for using in Runge Kutta method
+            if self.compare_agent(self.pop[idx], self.pop[id_min_x]):
+                xb, xw = self.pop[idx][self.ID_POS], self.pop[id_min_x][self.ID_POS]
+            else:
+                xb, xw = self.pop[id_min_x][self.ID_POS], self.pop[idx][self.ID_POS]
+            ## Search Mechanism (SM) of RUN based on Runge Kutta Method
+            SM = self.runge_kutta__(xb, xw, delta_x)
+
+            _, local_best = self.get_global_best_solution(self.pop)
+            L = np.random.choice(range(0, 2), self.problem.n_dims)
+            xc = L * self.pop[idx][self.ID_POS] + (1 - L) * self.pop[a][self.ID_POS]        # Eq. 17.3
+            xm = L * self.g_best[self.ID_POS] + (1 - L) * local_best[self.ID_POS]           # Eq. 17.4
+
+            r = np.random.choice([1, -1], self.problem.n_dims)          # An Interger number
+            g = 2 * np.random.rand()
+            mu = 0.5 + 1 * np.random.uniform(0, 1, self.problem.n_dims)
+
+            ## Determine New Solution Based on Runge Kutta Method (Eq.18)
+            if np.random.rand() < 0.5:
+                pos_new = xc + r * SF[idx] * g * xc + SF[idx] * SM + mu * (xm - xc)
+            else:
+                pos_new = xm + r * SF[idx] * g * xm + SF[idx] * SM + mu * (self.pop[a][self.ID_POS] - self.pop[b][self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            tar_new = self.get_target_wrapper(pos_new)
+            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
+                self.pop[idx] = [pos_new, tar_new]
+
+            ## Enhanced solution quality (ESQ)  (Eq. 19)
+            if np.random.rand() < 0.5:
+                w = self.uniform_random__(0, 2, self.problem.n_dims) * np.exp(-5*np.random.rand() * (epoch + 1) / self.epoch)        # Eq.19-1
+                r = np.floor(self.uniform_random__(-1, 2, 1))
+                u = 2 * np.random.random(self.problem.n_dims)
+
+                a, b, c = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 3, replace=False)
+                x_ave = (self.pop[a][self.ID_POS] + self.pop[b][self.ID_POS] + self.pop[c][self.ID_POS]) / 3                # Eq.19-2
+
+                beta = np.random.random(self.problem.n_dims)
+                x_new1 = beta * self.g_best[self.ID_POS] + (1 - beta) * x_ave                                               # Eq.19-3
+
+                x_new2_temp1 = x_new1 + r*w * np.abs(np.random.normal(0, 1, self.problem.n_dims) + (x_new1 - x_ave))
+                x_new2_temp2 = x_new1 - x_ave + r*w*np.abs(np.random.normal(0, 1, self.problem.n_dims) + u * x_new1 - x_ave)
+                x_new2 = np.where(w < 1, x_new2_temp1, x_new2_temp2)
+                pos_new2 = self.amend_position(x_new2, self.problem.lb, self.problem.ub)
+                tar_new2 = self.get_target_wrapper(pos_new2)
+
+                if self.compare_agent([pos_new2, tar_new2], self.pop[idx]):
+                    self.pop[idx] = [pos_new2, tar_new2]
+                else:
+                    if w[np.random.randint(0, self.problem.n_dims)] > np.random.rand():
+                        SM = self.runge_kutta__(self.pop[idx][self.ID_POS], pos_new2, delta_x)
+                        x_new3 = pos_new2 - np.random.rand()*pos_new2 + \
+                                 SF[idx] * (SM + (2 * np.random.random(self.problem.n_dims)*self.g_best[self.ID_POS] - pos_new2))       # Eq. 20
+                        pos_new3 = self.amend_position(x_new3, self.problem.lb, self.problem.ub)
+                        tar_new3 = self.get_target_wrapper(pos_new3)
+                        if self.compare_agent([pos_new3, tar_new3], self.pop[idx]):
+                            self.pop[idx] = [pos_new3, tar_new3]
```

### Comparing `mealpy-2.5.3/mealpy/math_based/SCA.py` & `mealpy-2.5.3a1/mealpy/math_based/SCA.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,331 +1,331 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 17:44, 18/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class BaseSCA(Optimizer):
-    """
-    The developed version: Sine Cosine Algorithm (SCA)
-
-    Notes
-    ~~~~~
-    + The flow and few equations are changed
-    + Third loops are removed faster computational time
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.math_based.SCA import BaseSCA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = BaseSCA(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = True
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            # Eq 3.4, r1 decreases linearly from a to 0
-            a = 2.0
-            r1 = a - (epoch + 1) * (a / self.epoch)
-            # Update r2, r3, and r4 for Eq. (3.3), remove third loop here
-            r2 = 2 * np.pi * np.random.uniform(0, 1, self.problem.n_dims)
-            r3 = 2 * np.random.uniform(0, 1, self.problem.n_dims)
-            # Eq. 3.3, 3.1 and 3.2
-            pos_new1 = self.pop[idx][self.ID_POS] + r1 * np.sin(r2) * np.abs(r3 * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-            pos_new2 = self.pop[idx][self.ID_POS] + r1 * np.cos(r2) * np.abs(r3 * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-            pos_new = np.where(np.random.random(self.problem.n_dims) < 0.5, pos_new1, pos_new2)
-            # Check the bound
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-
-class OriginalSCA(BaseSCA):
-    """
-    The original version of: Sine Cosine Algorithm (SCA)
-
-    Links:
-        1. https://doi.org/10.1016/j.knosys.2015.12.022
-        2. https://www.mathworks.com/matlabcentral/fileexchange/54948-sca-a-sine-cosine-algorithm
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.math_based.SCA import OriginalSCA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalSCA(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Mirjalili, S., 2016. SCA: a sine cosine algorithm for solving optimization problems. Knowledge-based systems, 96, pp.120-133.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(epoch, pop_size, **kwargs)
-        self.sort_flag = False
-
-    def amend_position(self, position=None, lb=None, ub=None):
-        """
-        Depend on what kind of problem are we trying to solve, there will be an different amend_position
-        function to rebound the position of agent into the valid range.
-
-        Args:
-            position: vector position (location) of the solution.
-            lb: list of lower bound values
-            ub: list of upper bound values
-
-        Returns:
-            Amended position (make the position is in bound)
-        """
-        return np.where(np.logical_and(lb <= position, position <= ub), position, np.random.uniform(lb, ub))
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            # Eq 3.4, r1 decreases linearly from a to 0
-            a = 2.0
-            r1 = a - (epoch + 1) * (a / self.epoch)
-            pos_new = deepcopy(self.pop[idx][self.ID_POS])
-            for j in range(self.problem.n_dims):  # j-th dimension
-                # Update r2, r3, and r4 for Eq. (3.3)
-                r2 = 2 * np.pi * np.random.uniform()
-                r3 = 2 * np.random.uniform()
-                r4 = np.random.uniform()
-                # Eq. 3.3, 3.1 and 3.2
-                if r4 < 0.5:
-                    pos_new[j] = pos_new[j] + r1 * np.sin(r2) * np.abs(r3 * self.g_best[self.ID_POS][j] - pos_new[j])
-                else:
-                    pos_new[j] = pos_new[j] + r1 * np.cos(r2) * np.abs(r3 * self.g_best[self.ID_POS][j] - pos_new[j])
-            # Check the bound
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-
-class QTable:
-    def __init__(self, n_states, n_actions):
-        self.n_states = n_states
-        self.n_actions = n_actions
-        # Initialize the Q-table with zeros
-        self.table = np.zeros((n_states, n_actions))
-        # Define the ranges for r1 and r3
-        self.r1_ranges = [(0, 0.666), (0.667, 1.332), (1.333, 2)]
-        self.r3_ranges = [(0, 0.666), (0.667, 1.332), (1.333, 2)]
-        # Define the ranges for density and distance
-        self.density_ranges = [(0, 0.333), (0.334, 0.666), (0.667, 1)]
-        self.distance_ranges = [(0, 0.333), (0.334, 0.666), (0.667, 1)]
-        self.epsilon = 0.1
-
-    def get_state(self, density, distance):
-        density_range = next(i for i, r in enumerate(self.density_ranges) if density <= r[1])
-        distance_range = next(i for i, r in enumerate(self.distance_ranges) if distance <= r[1])
-        return density_range * 3 + distance_range
-
-    def get_action(self, state):
-        acts = self.table[state, :]
-        # Find the maximum value in the array
-        max_val = np.max(acts)
-        # Create a boolean mask that identifies all elements with the maximum value
-        max_indices = np.where(acts == max_val)[0]
-        # Use np.random.choice to randomly select an index from the list of indices with maximum value
-        return np.random.choice(max_indices)
-
-    def get_action_params(self, action):
-        r1_range = self.r1_ranges[action // 3]
-        r3_range = self.r3_ranges[action % 3]
-        return r1_range, r3_range
-
-    def update(self, state, action, reward, alpha=0.1, gamma=0.9):
-        self.table[state][action] += alpha * (reward + gamma * np.max(self.table[state]) - self.table[state][action])
-
-
-class QleSCA(BaseSCA):
-    """
-    The original version of: QLE Sine Cosine Algorithm (QLE-SCA)
-
-    Links:
-        1. https://www.sciencedirect.com/science/article/abs/pii/S0957417421017048
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + alpha (float): [0.1-1.0], the is the learning rate in Q-learning, default=0.1
-        + gamma (float): [0.1-1.0]: the discount factor, default=0.9
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.math_based.SCA import QleSCA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = QleSCA(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Hamad, Q. S., Samma, H., Suandi, S. A., & Mohamad-Saleh, J. (2022). Q-learning embedded sine cosine
-    algorithm (QLESCA). Expert Systems with Applications, 193, 116417.
-    """
-    ID_QTB = 2
-
-    def __init__(self, epoch=10000, pop_size=100, alpha=0.1, gamma=0.9, **kwargs):
-        """
-        Args:
-
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            alpha (float): the learning rate, default=0.1
-            gamma (float): the discount factor, default=0.9
-        """
-        super().__init__(epoch, pop_size, **kwargs)
-        self.alpha = self.validator.check_float("alpha", alpha, [0.0, 1.0])
-        self.gamma = self.validator.check_float("gamma", gamma, [0.0, 1.0])
-        self.set_parameters(["epoch", "pop_size", "alpha", "gamma"])
-        self.sort_flag = False
-        self.support_parallel_modes = False
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        position = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(position)
-        q_table = QTable(n_states=9, n_actions=9)
-        return [position, target, q_table]
-
-    def amend_position(self, position=None, lb=None, ub=None):
-        return np.where(np.logical_and(lb <= position, position <= ub), position, np.random.uniform(lb, ub))
-
-    def density__(self, pop):
-        agents = np.array([agent[self.ID_POS] for agent in pop])
-        # calculate the mean of each dimension of the agents
-        Y = np.mean(agents, axis=0)
-        # calculate the longest diagonal length L
-        distances = np.sqrt(np.sum((agents[:, np.newaxis, :] - agents) ** 2, axis=-1))
-        L = np.max(distances)
-        # calculate the density
-        return 1 / (len(pop) * L) * np.sum(np.sqrt(np.sum((agents - Y) ** 2, axis=1)))
-
-    def distance__(self, best, pop, lb, ub):
-        agents = np.array([agent[self.ID_POS] for agent in pop])
-        # calculate the numerator of the distance
-        numerator = np.sum(np.sqrt(np.sum((best[self.ID_POS] - agents) ** 2, axis=1)))
-        # calculate the denominator of the distance
-        denominator = np.sum([ np.sqrt(np.sum((ub - lb) ** 2)) for _ in range(0, len(pop))])
-        # calculate the distance
-        return numerator / denominator
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        for idx in range(0, self.pop_size):
-            agent = deepcopy(self.pop[idx])
-            ## Step 3: State computation
-            den = self.density__(self.pop)
-            dis = self.distance__(self.g_best, self.pop, self.problem.lb, self.problem.ub)
-            ## Step 4: Action execution
-            state = self.pop[idx][self.ID_QTB].get_state(density=den, distance=dis)
-            action = self.pop[idx][self.ID_QTB].get_action(state=state)
-            r1_bound, r3_bound = self.pop[idx][self.ID_QTB].get_action_params(action)
-            r1 = np.random.uniform(r1_bound[0], r1_bound[1])
-            r3 = np.random.uniform(r3_bound[0], r3_bound[1])
-            r2 = 2 * np.pi * np.random.uniform()
-            r4 = np.random.uniform()
-            if r4 < 0.5:
-                pos_new = self.pop[idx][self.ID_POS] + r1 * np.sin(r2) * (r3 * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-            else:
-                pos_new = self.pop[idx][self.ID_POS] + r1 * np.cos(r2) * (r3 * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-            # Check the bound
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            agent[self.ID_POS] = pos_new
-            agent[self.ID_TAR] = self.get_target_wrapper(pos_new)
-            if self.compare_agent(agent, self.pop[idx]):
-                self.pop[idx] = agent
-                self.pop[idx][self.ID_QTB].update(state, action, reward=1, alpha=self.alpha, gamma=self.gamma)
-            else:
-                self.pop[idx][self.ID_QTB].update(state, action, reward=-1, alpha=self.alpha, gamma=self.gamma)
+#!/usr/bin/env python
+# Created by "Thieu" at 17:44, 18/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class BaseSCA(Optimizer):
+    """
+    The developed version: Sine Cosine Algorithm (SCA)
+
+    Notes
+    ~~~~~
+    + The flow and few equations are changed
+    + Third loops are removed faster computational time
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.math_based.SCA import BaseSCA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = BaseSCA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = True
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            # Eq 3.4, r1 decreases linearly from a to 0
+            a = 2.0
+            r1 = a - (epoch + 1) * (a / self.epoch)
+            # Update r2, r3, and r4 for Eq. (3.3), remove third loop here
+            r2 = 2 * np.pi * np.random.uniform(0, 1, self.problem.n_dims)
+            r3 = 2 * np.random.uniform(0, 1, self.problem.n_dims)
+            # Eq. 3.3, 3.1 and 3.2
+            pos_new1 = self.pop[idx][self.ID_POS] + r1 * np.sin(r2) * np.abs(r3 * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+            pos_new2 = self.pop[idx][self.ID_POS] + r1 * np.cos(r2) * np.abs(r3 * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+            pos_new = np.where(np.random.random(self.problem.n_dims) < 0.5, pos_new1, pos_new2)
+            # Check the bound
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+
+class OriginalSCA(BaseSCA):
+    """
+    The original version of: Sine Cosine Algorithm (SCA)
+
+    Links:
+        1. https://doi.org/10.1016/j.knosys.2015.12.022
+        2. https://www.mathworks.com/matlabcentral/fileexchange/54948-sca-a-sine-cosine-algorithm
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.math_based.SCA import OriginalSCA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalSCA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Mirjalili, S., 2016. SCA: a sine cosine algorithm for solving optimization problems. Knowledge-based systems, 96, pp.120-133.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(epoch, pop_size, **kwargs)
+        self.sort_flag = False
+
+    def amend_position(self, position=None, lb=None, ub=None):
+        """
+        Depend on what kind of problem are we trying to solve, there will be an different amend_position
+        function to rebound the position of agent into the valid range.
+
+        Args:
+            position: vector position (location) of the solution.
+            lb: list of lower bound values
+            ub: list of upper bound values
+
+        Returns:
+            Amended position (make the position is in bound)
+        """
+        return np.where(np.logical_and(lb <= position, position <= ub), position, np.random.uniform(lb, ub))
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            # Eq 3.4, r1 decreases linearly from a to 0
+            a = 2.0
+            r1 = a - (epoch + 1) * (a / self.epoch)
+            pos_new = deepcopy(self.pop[idx][self.ID_POS])
+            for j in range(self.problem.n_dims):  # j-th dimension
+                # Update r2, r3, and r4 for Eq. (3.3)
+                r2 = 2 * np.pi * np.random.uniform()
+                r3 = 2 * np.random.uniform()
+                r4 = np.random.uniform()
+                # Eq. 3.3, 3.1 and 3.2
+                if r4 < 0.5:
+                    pos_new[j] = pos_new[j] + r1 * np.sin(r2) * np.abs(r3 * self.g_best[self.ID_POS][j] - pos_new[j])
+                else:
+                    pos_new[j] = pos_new[j] + r1 * np.cos(r2) * np.abs(r3 * self.g_best[self.ID_POS][j] - pos_new[j])
+            # Check the bound
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+
+class QTable:
+    def __init__(self, n_states, n_actions):
+        self.n_states = n_states
+        self.n_actions = n_actions
+        # Initialize the Q-table with zeros
+        self.table = np.zeros((n_states, n_actions))
+        # Define the ranges for r1 and r3
+        self.r1_ranges = [(0, 0.666), (0.667, 1.332), (1.333, 2)]
+        self.r3_ranges = [(0, 0.666), (0.667, 1.332), (1.333, 2)]
+        # Define the ranges for density and distance
+        self.density_ranges = [(0, 0.333), (0.334, 0.666), (0.667, 1)]
+        self.distance_ranges = [(0, 0.333), (0.334, 0.666), (0.667, 1)]
+        self.epsilon = 0.1
+
+    def get_state(self, density, distance):
+        density_range = next(i for i, r in enumerate(self.density_ranges) if density <= r[1])
+        distance_range = next(i for i, r in enumerate(self.distance_ranges) if distance <= r[1])
+        return density_range * 3 + distance_range
+
+    def get_action(self, state):
+        acts = self.table[state, :]
+        # Find the maximum value in the array
+        max_val = np.max(acts)
+        # Create a boolean mask that identifies all elements with the maximum value
+        max_indices = np.where(acts == max_val)[0]
+        # Use np.random.choice to randomly select an index from the list of indices with maximum value
+        return np.random.choice(max_indices)
+
+    def get_action_params(self, action):
+        r1_range = self.r1_ranges[action // 3]
+        r3_range = self.r3_ranges[action % 3]
+        return r1_range, r3_range
+
+    def update(self, state, action, reward, alpha=0.1, gamma=0.9):
+        self.table[state][action] += alpha * (reward + gamma * np.max(self.table[state]) - self.table[state][action])
+
+
+class QleSCA(BaseSCA):
+    """
+    The original version of: QLE Sine Cosine Algorithm (QLE-SCA)
+
+    Links:
+        1. https://www.sciencedirect.com/science/article/abs/pii/S0957417421017048
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + alpha (float): [0.1-1.0], the is the learning rate in Q-learning, default=0.1
+        + gamma (float): [0.1-1.0]: the discount factor, default=0.9
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.math_based.SCA import QleSCA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = QleSCA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Hamad, Q. S., Samma, H., Suandi, S. A., & Mohamad-Saleh, J. (2022). Q-learning embedded sine cosine
+    algorithm (QLESCA). Expert Systems with Applications, 193, 116417.
+    """
+    ID_QTB = 2
+
+    def __init__(self, epoch=10000, pop_size=100, alpha=0.1, gamma=0.9, **kwargs):
+        """
+        Args:
+
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            alpha (float): the learning rate, default=0.1
+            gamma (float): the discount factor, default=0.9
+        """
+        super().__init__(epoch, pop_size, **kwargs)
+        self.alpha = self.validator.check_float("alpha", alpha, [0.0, 1.0])
+        self.gamma = self.validator.check_float("gamma", gamma, [0.0, 1.0])
+        self.set_parameters(["epoch", "pop_size", "alpha", "gamma"])
+        self.sort_flag = False
+        self.support_parallel_modes = False
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        if pos is None:
+            pos = self.generate_position(lb, ub)
+        position = self.amend_position(pos, lb, ub)
+        target = self.get_target_wrapper(position)
+        q_table = QTable(n_states=9, n_actions=9)
+        return [position, target, q_table]
+
+    def amend_position(self, position=None, lb=None, ub=None):
+        return np.where(np.logical_and(lb <= position, position <= ub), position, np.random.uniform(lb, ub))
+
+    def density__(self, pop):
+        agents = np.array([agent[self.ID_POS] for agent in pop])
+        # calculate the mean of each dimension of the agents
+        Y = np.mean(agents, axis=0)
+        # calculate the longest diagonal length L
+        distances = np.sqrt(np.sum((agents[:, np.newaxis, :] - agents) ** 2, axis=-1))
+        L = np.max(distances)
+        # calculate the density
+        return 1 / (len(pop) * L) * np.sum(np.sqrt(np.sum((agents - Y) ** 2, axis=1)))
+
+    def distance__(self, best, pop, lb, ub):
+        agents = np.array([agent[self.ID_POS] for agent in pop])
+        # calculate the numerator of the distance
+        numerator = np.sum(np.sqrt(np.sum((best[self.ID_POS] - agents) ** 2, axis=1)))
+        # calculate the denominator of the distance
+        denominator = np.sum([ np.sqrt(np.sum((ub - lb) ** 2)) for _ in range(0, len(pop))])
+        # calculate the distance
+        return numerator / denominator
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        for idx in range(0, self.pop_size):
+            agent = deepcopy(self.pop[idx])
+            ## Step 3: State computation
+            den = self.density__(self.pop)
+            dis = self.distance__(self.g_best, self.pop, self.problem.lb, self.problem.ub)
+            ## Step 4: Action execution
+            state = self.pop[idx][self.ID_QTB].get_state(density=den, distance=dis)
+            action = self.pop[idx][self.ID_QTB].get_action(state=state)
+            r1_bound, r3_bound = self.pop[idx][self.ID_QTB].get_action_params(action)
+            r1 = np.random.uniform(r1_bound[0], r1_bound[1])
+            r3 = np.random.uniform(r3_bound[0], r3_bound[1])
+            r2 = 2 * np.pi * np.random.uniform()
+            r4 = np.random.uniform()
+            if r4 < 0.5:
+                pos_new = self.pop[idx][self.ID_POS] + r1 * np.sin(r2) * (r3 * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+            else:
+                pos_new = self.pop[idx][self.ID_POS] + r1 * np.cos(r2) * (r3 * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+            # Check the bound
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            agent[self.ID_POS] = pos_new
+            agent[self.ID_TAR] = self.get_target_wrapper(pos_new)
+            if self.compare_agent(agent, self.pop[idx]):
+                self.pop[idx] = agent
+                self.pop[idx][self.ID_QTB].update(state, action, reward=1, alpha=self.alpha, gamma=self.gamma)
+            else:
+                self.pop[idx][self.ID_QTB].update(state, action, reward=-1, alpha=self.alpha, gamma=self.gamma)
```

### Comparing `mealpy-2.5.3/mealpy/math_based/SHIO.py` & `mealpy-2.5.3a1/mealpy/math_based/SHIO.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,84 +1,85 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 18:09, 13/03/2023 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalSHIO(Optimizer):
-    """
-    The original version of: Success History Intelligent Optimizer (SHIO)
-
-    Links:
-        1. https://link.springer.com/article/10.1007/s11227-021-04093-9
-        2. https://www.mathworks.com/matlabcentral/fileexchange/122157-success-history-intelligent-optimizer-shio
-
-    Notes:
-        1. The algorithm is designed with simplicity and ease of implementation in mind, utilizing basic operators.
-        2. This algorithm has several limitations and weak when dealing with several problems
-        3. The algorithm's convergence is slow. The Matlab code has many errors and unnecessary things.
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.math_based.SHIO import OriginalSHIO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalSHIO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Fakhouri, H. N., Hamad, F., & Alawamrah, A. (2022). Success history intelligent optimizer. The Journal of Supercomputing, 1-42.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        _, (b1, b2, b3), _ = self.get_special_solutions(self.pop, best=3, worst=1)
-        a = 1.5
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            a = a - 0.04
-            x1 = b1[self.ID_POS] + (a*2*np.random.rand(self.problem.n_dims) - a)*np.abs(np.random.rand(self.problem.n_dims) * b1[self.ID_POS] - self.pop[idx][self.ID_POS])
-            x2 = b2[self.ID_POS] + (a*2*np.random.rand(self.problem.n_dims) - a)*np.abs(np.random.rand(self.problem.n_dims) * b1[self.ID_POS] - self.pop[idx][self.ID_POS])
-            x3 = b3[self.ID_POS] + (a*2*np.random.rand(self.problem.n_dims) - a)*np.abs(np.random.rand(self.problem.n_dims) * b1[self.ID_POS] - self.pop[idx][self.ID_POS])
-            pos_new = (x1 + x2 + x3) / 3
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-        self.pop = pop_new
+#!/usr/bin/env python
+# Created by "Thieu" at 18:09, 13/03/2023 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalSHIO(Optimizer):
+    """
+    The original version of: Success History Intelligent Optimizer (SHIO)
+
+    Links:
+        1. https://link.springer.com/article/10.1007/s11227-021-04093-9
+        2. https://www.mathworks.com/matlabcentral/fileexchange/122157-success-history-intelligent-optimizer-shio
+
+    Notes:
+        1. The algorithm is very easy with no special operators.
+        2. This is a weak algorithm and should not be used in research or practical problems.
+        3. There is slow convergence in the algorithm. If we look at the Matlab code, we can see that a student
+        is trying to implement it with many errors and unnecessary things. Not sure why it got accepted in that journal
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.math_based.SHIO import OriginalSHIO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalSHIO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Fakhouri, H. N., Hamad, F., & Alawamrah, A. (2022). Success history intelligent optimizer. The Journal of Supercomputing, 1-42.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        _, (b1, b2, b3), _ = self.get_special_solutions(self.pop, best=3, worst=1)
+        a = 1.5
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            a = a - 0.04
+            x1 = b1[self.ID_POS] + (a*2*np.random.rand(self.problem.n_dims) - a)*np.abs(np.random.rand(self.problem.n_dims) * b1[self.ID_POS] - self.pop[idx][self.ID_POS])
+            x2 = b2[self.ID_POS] + (a*2*np.random.rand(self.problem.n_dims) - a)*np.abs(np.random.rand(self.problem.n_dims) * b1[self.ID_POS] - self.pop[idx][self.ID_POS])
+            x3 = b3[self.ID_POS] + (a*2*np.random.rand(self.problem.n_dims) - a)*np.abs(np.random.rand(self.problem.n_dims) * b1[self.ID_POS] - self.pop[idx][self.ID_POS])
+            pos_new = (x1 + x2 + x3) / 3
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+        self.pop = pop_new
```

### Comparing `mealpy-2.5.3/mealpy/multitask.py` & `mealpy-2.5.3a1/mealpy/multitask.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,171 +1,173 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 22:21, 06/09/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import pandas as pd
-from pathlib import Path
-from mealpy.optimizer import Optimizer
-from mealpy.utils.problem import Problem
-from mealpy.utils.termination import Termination
-from mealpy.utils.validator import Validator
-from functools import partial
-import concurrent.futures as parallel
-from copy import deepcopy
-import os
-
-
-class Multitask:
-    """Multitask utility class.
-
-    This feature enables the execution of multiple algorithms across multiple problems and trials.
-    Additionally, it allows for exporting results in various formats such as Pandas DataFrame, JSON, and CSV.
-
-    Args:
-        algorithms (list, tuple): List of algorithms to run
-        problems (list, tuple): List of problems to run
-        terminations (list, tuple): List of terminations to apply on algorithm/problem
-        modes (list, tuple): List of modes to apply on algorithm/problem
-    """
-    def __init__(self, algorithms=(), problems=(), terminations=None, modes=None, **kwargs):
-        self.__set_keyword_arguments(kwargs)
-        self.validator = Validator(log_to="console", log_file=None)
-        self.algorithms = self.validator.check_list_tuple("algorithms", algorithms, "Optimizer")
-        self.problems = self.validator.check_list_tuple("problems", problems, "Problem")
-        self.n_algorithms = len(self.algorithms)
-        self.m_problems = len(self.problems)
-        self.terminations = self.check_input("terminations", terminations, "Termination")
-        self.modes = self.check_input("modes", modes, "str (thread, process, single, swarm)")
-
-    def check_input(self, name=None, values=None, kind=None):
-        if values is None:
-            return None
-        elif type(values) in (list, tuple):
-            if len(values) == 1:
-                values_final = [[deepcopy(values[0]) for _ in range(0, self.m_problems)] for _ in range(0, self.n_algorithms)]
-            elif len(values) == self.n_algorithms:
-                values_final = [deepcopy(values[idx] for _ in range(0, self.m_problems)) for idx in range(0, self.n_algorithms)]
-            elif len(values) == self.m_problems:
-                values_final = [deepcopy(values) for _ in range(0, self.n_algorithms)]
-            elif len(values) == (self.n_algorithms * self.m_problems):
-                values_final = values
-            else:
-                raise ValueError(f"{name} should be list of {kind} instances with size (1) or (n) or (m) or (n*m), n: #algorithms, m: #problems.")
-            return values_final
-        else:
-            raise ValueError(f"{name} should be list of {kind} instances.")
-
-    def __set_keyword_arguments(self, kwargs):
-        for key, value in kwargs.items():
-            setattr(self, key, value)
-
-    @staticmethod
-    def export_to_dataframe(result: pd.DataFrame, save_path: str):
-        result.to_pickle(f"{save_path}.pkl")
-
-    @staticmethod
-    def export_to_json(result: pd.DataFrame, save_path: str):
-        result.to_json(f"{save_path}.json")
-
-    @staticmethod
-    def export_to_csv(result: pd.DataFrame, save_path: str):
-        result.to_csv(f"{save_path}.csv", header=True, index=False)
-
-    def __run__(self, id_trial, model, problem, termination=None, mode="single"):
-        _, best_fitness = model.solve(problem, mode=mode, termination=termination)
-        return {
-            "id_trial": id_trial,
-            "best_fitness": best_fitness,
-            "convergence": model.history.list_global_best_fit
-        }
-
-    def execute(self, n_trials=2, n_jobs=None, save_path="history", save_as="csv", save_convergence=False, verbose=False):
-        """Execute multitask utility.
-
-        Args:
-            n_trials (int): Number of repetitions
-            n_jobs (int, None): Number of processes will be used to speed up the computation (<=1 or None: sequential, >=2: parallel)
-            save_path (str): The path to the folder that hold results
-            save_as (str): Saved file type (e.g. dataframe, json, csv) (default: "csv")
-            save_convergence (bool): Save the error (convergence/fitness) during generations (default: False)
-            verbose (bool): Switch for verbose logging (default: False)
-
-        Raises:
-            TypeError: Raises TypeError if export type is not supported
-
-        """
-        n_trials = self.validator.check_int("n_trials", n_trials, [1, 100000])
-        n_workers = None
-        if (n_jobs is not None) and (n_jobs >= 1):
-            n_workers = self.validator.check_int("n_jobs", n_jobs, [2, min(61, os.cpu_count() - 1)])
-
-        ## Get export function
-        save_as = self.validator.check_str("save_as", save_as, ["csv", "json", "dataframe"])
-        export_function = getattr(self, f"export_to_{save_as}")
-
-        for id_model, model in enumerate(self.algorithms):
-            if not isinstance(model, Optimizer):
-                print(f"Model: {id_model+1} is not an instance of Optimizer class.")
-                continue
-
-            ## Check parent directories
-            path_best_fit = f"{save_path}/best_fit"
-            path_convergence = f"{save_path}/convergence/{model.get_name()}"
-            Path(path_best_fit).mkdir(parents=True, exist_ok=True)
-            Path(path_convergence).mkdir(parents=True, exist_ok=True)
-
-            best_fit_model_results = {}
-            for id_prob, problem in enumerate(self.problems):
-                if not isinstance(problem, Problem):
-                    if not type(problem) is dict:
-                        print(f"Problem: {id_prob+1} is not an instance of Problem class or a Python dict.")
-                        continue
-                    else:
-                        problem = Problem(**problem)
-
-                term = None
-                if self.terminations is not None:
-                    term = self.terminations[id_model][id_prob]
-                    if not isinstance(term, Termination):
-                        if not type(term) is dict:
-                            print(f"Termination: {id_prob + 1} is not an instance of Termination class or a Python dict.")
-                            continue
-                        else:
-                            term = Termination(**term)
-
-                mode = "single"
-                if self.modes is not None:
-                    mode = self.modes[id_model][id_prob]
-                    if mode not in ("process", "thread", "single", "swarm"):
-                        mode = "single"
-                        print(f"Mode: {id_prob + 1} is fall back on 'single'")
-
-                convergence_trials = {}
-                best_fit_trials = []
-
-                trial_list = list(range(1, n_trials+1))
-
-                if n_workers is not None:
-                    with parallel.ProcessPoolExecutor(n_workers) as executor:
-                        list_results = executor.map(partial(self.__run__, model=model, problem=problem, termination=term, mode=mode), trial_list)
-                        for result in list_results:
-                            convergence_trials[f"trial_{result['id_trial']}"] = result['convergence']
-                            best_fit_trials.append(result['best_fitness'])
-                            if verbose:
-                                print(f"Solving problem: {problem.get_name()} using algorithm: {model.get_name()}, on the: {result['id_trial']} trial")
-                else:
-                    for idx in trial_list:
-                        result = self.__run__(idx, model, problem, termination=term, mode=mode)
-                        convergence_trials[f"trial_{result['id_trial']}"] = result['convergence']
-                        best_fit_trials.append(result['best_fitness'])
-                        if verbose:
-                            print(f"Solving problem: {problem.get_name()} using algorithm: {model.get_name()}, on the: {result['id_trial']} trial")
-
-                best_fit_model_results[problem.get_name()] = best_fit_trials
-                if save_convergence:
-                    df1 = pd.DataFrame(convergence_trials)
-                    export_function(df1, f"{path_convergence}/{problem.get_name()}_convergence")
-
-            df2 = pd.DataFrame(best_fit_model_results)
-            export_function(df2, f"{path_best_fit}/{model.get_name()}_best_fit")
+#!/usr/bin/env python
+# Created by "Thieu" at 22:21, 06/09/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import pandas as pd
+from pathlib import Path
+from mealpy.optimizer import Optimizer
+from mealpy.utils.problem import Problem
+from mealpy.utils.termination import Termination
+from mealpy.utils.validator import Validator
+from functools import partial
+import concurrent.futures as parallel
+from copy import deepcopy
+import os
+
+
+class Multitask:
+    """Multitask utility class.
+
+    This feature enables the execution of multiple algorithms across multiple problems and trials.
+    Additionally, it allows for exporting results in various formats such as Pandas DataFrame, JSON, and CSV.
+
+    Args:
+        algorithms (list, tuple): List of algorithms to run
+        problems (list, tuple): List of problems to run
+        terminations (list, tuple): List of terminations to apply on algorithm/problem
+        modes (list, tuple): List of modes to apply on algorithm/problem
+    """
+    def __init__(self, algorithms=(), problems=(), terminations=None, modes=None, **kwargs):
+        self.__set_keyword_arguments(kwargs)
+        self.validator = Validator(log_to="console", log_file=None)
+        self.algorithms = self.validator.check_list_tuple("algorithms", algorithms, "Optimizer")
+        self.problems = self.validator.check_list_tuple("problems", problems, "Problem")
+        self.n_algorithms = len(self.algorithms)
+        self.m_problems = len(self.problems)
+        self.terminations = self.check_input("terminations", terminations, "Termination")
+        self.modes = self.check_input("modes", modes, "str (thread, process, single, swarm)")
+
+    def check_input(self, name=None, values=None, kind=None):
+        if values is None:
+            return None
+        elif type(values) in (list, tuple):
+            if len(values) == 1:
+                values_final = [[deepcopy(values[0]) for _ in range(0, self.m_problems)] for _ in range(0, self.n_algorithms)]
+            elif len(values) == self.n_algorithms:
+                values_final = [deepcopy(values[idx] for _ in range(0, self.m_problems)) for idx in range(0, self.n_algorithms)]
+            elif len(values) == self.m_problems:
+                values_final = [deepcopy(values) for _ in range(0, self.n_algorithms)]
+            elif len(values) == (self.n_algorithms * self.m_problems):
+                values_final = values
+            else:
+                raise ValueError(f"{name} should be list of {kind} instances with size (1) or (n) or (m) or (n*m), n: #algorithms, m: #problems.")
+            return values_final
+        else:
+            raise ValueError(f"{name} should be list of {kind} instances.")
+
+    def __set_keyword_arguments(self, kwargs):
+        for key, value in kwargs.items():
+            setattr(self, key, value)
+
+    @staticmethod
+    def export_to_dataframe(result: pd.DataFrame, save_path: str):
+        result.to_pickle(f"{save_path}.pkl")
+
+    @staticmethod
+    def export_to_json(result: pd.DataFrame, save_path: str):
+        result.to_json(f"{save_path}.json")
+
+    @staticmethod
+    def export_to_csv(result: pd.DataFrame, save_path: str):
+        result.to_csv(f"{save_path}.csv", header=True, index=False)
+
+    def __run__(self, id_trial, model, problem, termination=None, mode="single"):
+        _, best_fitness = model.solve(problem, mode=mode, termination=termination)
+        return {
+            "id_trial": id_trial,
+            "best_fitness": best_fitness,
+            "convergence": model.history.list_global_best_fit
+        }
+
+    def execute(self, n_trials=2, mode="sequential", n_workers=2, save_path="history", save_as="csv", save_convergence=False, verbose=False):
+        """Execute multitask utility.
+
+        Args:
+            n_trials (int): Number of repetitions
+            mode (str): Execute problem using "sequential" or "parallel" mode, default = "sequential"
+            n_workers (int): Number of processes if mode is "parallel"
+            save_path (str): The path to the folder that hold results
+            save_as (str): Saved file type (e.g. dataframe, json, csv) (default: "csv")
+            save_convergence (bool): Save the error (convergence/fitness) during generations (default: False)
+            verbose (bool): Switch for verbose logging (default: False)
+
+        Raises:
+            TypeError: Raises TypeError if export type is not supported
+
+        """
+        n_trials = self.validator.check_int("n_trials", n_trials, [1, 100000])
+        mode = self.validator.check_str("mode", mode, ["parallel", "sequential"])
+        if mode == "parallel":
+            n_workers = self.validator.check_int("n_workers", n_workers, [2, min(61, os.cpu_count() - 1)])
+        else:
+            n_workers = None
+        ## Get export function
+        save_as = self.validator.check_str("save_as", save_as, ["csv", "json", "dataframe"])
+        export_function = getattr(self, f"export_to_{save_as}")
+
+        for id_model, model in enumerate(self.algorithms):
+            if not isinstance(model, Optimizer):
+                print(f"Model: {id_model+1} is not an instance of Optimizer class.")
+                continue
+
+            ## Check parent directories
+            path_best_fit = f"{save_path}/best_fit"
+            path_convergence = f"{save_path}/convergence/{model.get_name()}"
+            Path(path_best_fit).mkdir(parents=True, exist_ok=True)
+            Path(path_convergence).mkdir(parents=True, exist_ok=True)
+
+            best_fit_model_results = {}
+            for id_prob, problem in enumerate(self.problems):
+                if not isinstance(problem, Problem):
+                    if not type(problem) is dict:
+                        print(f"Problem: {id_prob+1} is not an instance of Problem class or a Python dict.")
+                        continue
+                    else:
+                        problem = Problem(**problem)
+
+                term = None
+                if self.terminations is not None:
+                    term = self.terminations[id_model][id_prob]
+                    if not isinstance(term, Termination):
+                        if not type(term) is dict:
+                            print(f"Termination: {id_prob + 1} is not an instance of Termination class or a Python dict.")
+                            continue
+                        else:
+                            term = Termination(**term)
+
+                mode = "single"
+                if self.modes is not None:
+                    mode = self.modes[id_model][id_prob]
+                    if mode not in ("process", "thread", "single", "swarm"):
+                        mode = "single"
+                        print(f"Mode: {id_prob + 1} is fall back on 'single'")
+
+                convergence_trials = {}
+                best_fit_trials = []
+
+                trial_list = list(range(1, n_trials+1))
+
+                if mode == "parallel":
+                    with parallel.ProcessPoolExecutor(n_workers) as executor:
+                        list_results = executor.map(partial(self.__run__, model=model, problem=problem, termination=term, mode=mode), trial_list)
+                        for result in list_results:
+                            convergence_trials[f"trial_{result['id_trial']}"] = result['convergence']
+                            best_fit_trials.append(result['best_fitness'])
+                            if verbose:
+                                print(f"Solving problem: {problem.get_name()} using algorithm: {model.get_name()}, on the: {result['id_trial']} trial")
+                else:
+                    for idx in trial_list:
+                        result = self.__run__(idx, model, problem, termination=term, mode=mode)
+                        convergence_trials[f"trial_{result['id_trial']}"] = result['convergence']
+                        best_fit_trials.append(result['best_fitness'])
+                        if verbose:
+                            print(f"Solving problem: {problem.get_name()} using algorithm: {model.get_name()}, on the: {result['id_trial']} trial")
+
+                best_fit_model_results[problem.get_name()] = best_fit_trials
+                if save_convergence:
+                    df1 = pd.DataFrame(convergence_trials)
+                    export_function(df1, f"{path_convergence}/{problem.get_name()}_convergence")
+
+            df2 = pd.DataFrame(best_fit_model_results)
+            export_function(df2, f"{path_best_fit}/{model.get_name()}_best_fit")
```

### Comparing `mealpy-2.5.3/mealpy/music_based/HS.py` & `mealpy-2.5.3a1/mealpy/music_based/HS.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,183 +1,183 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 17:48, 18/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class BaseHS(Optimizer):
-    """
-    The developed version: Harmony Search (HS)
-
-    Links:
-        1. https://doi.org/10.1177/003754970107600201
-
-    Notes
-    ~~~~~
-    - Used the global best in the harmony memories
-    - Removed all third for loops
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + c_r (float): [0.1, 0.5], Harmony Memory Consideration Rate), default = 0.15
-        + pa_r (float): [0.3, 0.8], Pitch Adjustment Rate, default=0.5
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.music_based.HS import BaseHS
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> c_r = 0.95
-    >>> pa_r = 0.05
-    >>> model = BaseHS(epoch, pop_size, c_r, pa_r)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, c_r=0.95, pa_r=0.05, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            c_r (float): Harmony Memory Consideration Rate, default = 0.15
-            pa_r (float): Pitch Adjustment Rate, default=0.5
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.c_r = self.validator.check_float("c_r", c_r, (0, 1.0))
-        self.pa_r = self.validator.check_float("pa_r", pa_r, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "c_r", "pa_r"])
-        self.sort_flag = False
-
-    def initialize_variables(self):
-        self.fw = 0.0001 * (self.problem.ub - self.problem.lb)  # Fret Width (Bandwidth)
-        self.fw_damp = 0.9995  # Fret Width Damp Ratio
-        self.dyn_fw = self.fw
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            # Create New Harmony Position
-            pos_new = np.random.uniform(self.problem.lb, self.problem.ub)
-            delta = self.dyn_fw * np.random.normal(self.problem.lb, self.problem.ub)
-
-            # Use Harmony Memory
-            pos_new = np.where(np.random.random(self.problem.n_dims) < self.c_r, self.g_best[self.ID_POS], pos_new)
-            # Pitch Adjustment
-            x_new = pos_new + delta
-            pos_new = np.where(np.random.random(self.problem.n_dims) < self.pa_r, x_new, pos_new)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop_new = self.update_target_wrapper_population(pop_new)
-
-        # Update Damp Fret Width
-        self.dyn_fw = self.dyn_fw * self.fw_damp
-
-        # Merge Harmony Memory and New Harmonies, Then sort them, Then truncate extra harmonies
-        self.pop = self.get_sorted_strim_population(self.pop + pop_new, self.pop_size)
-
-
-class OriginalHS(BaseHS):
-    """
-    The original version of: Harmony Search (HS)
-
-    Links:
-        1. https://doi.org/10.1177/003754970107600201
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + c_r (float): [0.1, 0.5], Harmony Memory Consideration Rate), default = 0.15
-        + pa_r (float): [0.3, 0.8], Pitch Adjustment Rate, default=0.5
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.music_based.HS import OriginalHS
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>>     "verbose": True,
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> c_r = 0.95
-    >>> pa_r = 0.05
-    >>> model = OriginalHS(epoch, pop_size, c_r, pa_r)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Geem, Z.W., Kim, J.H. and Loganathan, G.V., 2001. A new heuristic
-    optimization algorithm: harmony search. simulation, 76(2), pp.60-68.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, c_r=0.95, pa_r=0.05, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            c_r (float): Harmony Memory Consideration Rate), default = 0.15
-            pa_r (float): Pitch Adjustment Rate, default=0.5
-        """
-        super().__init__(epoch, pop_size, c_r, pa_r, **kwargs)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            pos_new = np.random.uniform(self.problem.lb, self.problem.ub)
-            for j in range(self.problem.n_dims):
-                # Use Harmony Memory
-                if np.random.uniform() <= self.c_r:
-                    random_index = np.random.randint(0, self.pop_size)
-                    pos_new[j] = self.pop[random_index][self.ID_POS][j]
-                # Pitch Adjustment
-                if np.random.uniform() <= self.pa_r:
-                    delta = self.dyn_fw * np.random.normal(self.problem.lb, self.problem.ub)  # Gaussian(Normal)
-                    pos_new[j] = pos_new[j] + delta[j]
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop_new = self.update_target_wrapper_population(pop_new)
-
-        # Update Damp Fret Width
-        self.dyn_fw = self.dyn_fw * self.fw_damp
-
-        # Merge Harmony Memory and New Harmonies, Then sort them, Then truncate extra harmonies
-        self.pop = self.get_sorted_strim_population(self.pop + pop_new, self.pop_size)
+#!/usr/bin/env python
+# Created by "Thieu" at 17:48, 18/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class BaseHS(Optimizer):
+    """
+    The developed version: Harmony Search (HS)
+
+    Links:
+        1. https://doi.org/10.1177/003754970107600201
+
+    Notes
+    ~~~~~
+    - Used the global best in the harmony memories
+    - Removed all third for loops
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + c_r (float): [0.1, 0.5], Harmony Memory Consideration Rate), default = 0.15
+        + pa_r (float): [0.3, 0.8], Pitch Adjustment Rate, default=0.5
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.music_based.HS import BaseHS
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> c_r = 0.95
+    >>> pa_r = 0.05
+    >>> model = BaseHS(epoch, pop_size, c_r, pa_r)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, c_r=0.95, pa_r=0.05, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            c_r (float): Harmony Memory Consideration Rate, default = 0.15
+            pa_r (float): Pitch Adjustment Rate, default=0.5
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.c_r = self.validator.check_float("c_r", c_r, (0, 1.0))
+        self.pa_r = self.validator.check_float("pa_r", pa_r, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "c_r", "pa_r"])
+        self.sort_flag = False
+
+    def initialize_variables(self):
+        self.fw = 0.0001 * (self.problem.ub - self.problem.lb)  # Fret Width (Bandwidth)
+        self.fw_damp = 0.9995  # Fret Width Damp Ratio
+        self.dyn_fw = self.fw
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            # Create New Harmony Position
+            pos_new = np.random.uniform(self.problem.lb, self.problem.ub)
+            delta = self.dyn_fw * np.random.normal(self.problem.lb, self.problem.ub)
+
+            # Use Harmony Memory
+            pos_new = np.where(np.random.random(self.problem.n_dims) < self.c_r, self.g_best[self.ID_POS], pos_new)
+            # Pitch Adjustment
+            x_new = pos_new + delta
+            pos_new = np.where(np.random.random(self.problem.n_dims) < self.pa_r, x_new, pos_new)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop_new = self.update_target_wrapper_population(pop_new)
+
+        # Update Damp Fret Width
+        self.dyn_fw = self.dyn_fw * self.fw_damp
+
+        # Merge Harmony Memory and New Harmonies, Then sort them, Then truncate extra harmonies
+        self.pop = self.get_sorted_strim_population(self.pop + pop_new, self.pop_size)
+
+
+class OriginalHS(BaseHS):
+    """
+    The original version of: Harmony Search (HS)
+
+    Links:
+        1. https://doi.org/10.1177/003754970107600201
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + c_r (float): [0.1, 0.5], Harmony Memory Consideration Rate), default = 0.15
+        + pa_r (float): [0.3, 0.8], Pitch Adjustment Rate, default=0.5
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.music_based.HS import OriginalHS
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>>     "verbose": True,
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> c_r = 0.95
+    >>> pa_r = 0.05
+    >>> model = OriginalHS(epoch, pop_size, c_r, pa_r)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Geem, Z.W., Kim, J.H. and Loganathan, G.V., 2001. A new heuristic
+    optimization algorithm: harmony search. simulation, 76(2), pp.60-68.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, c_r=0.95, pa_r=0.05, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            c_r (float): Harmony Memory Consideration Rate), default = 0.15
+            pa_r (float): Pitch Adjustment Rate, default=0.5
+        """
+        super().__init__(epoch, pop_size, c_r, pa_r, **kwargs)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            pos_new = np.random.uniform(self.problem.lb, self.problem.ub)
+            for j in range(self.problem.n_dims):
+                # Use Harmony Memory
+                if np.random.uniform() <= self.c_r:
+                    random_index = np.random.randint(0, self.pop_size)
+                    pos_new[j] = self.pop[random_index][self.ID_POS][j]
+                # Pitch Adjustment
+                if np.random.uniform() <= self.pa_r:
+                    delta = self.dyn_fw * np.random.normal(self.problem.lb, self.problem.ub)  # Gaussian(Normal)
+                    pos_new[j] = pos_new[j] + delta[j]
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop_new = self.update_target_wrapper_population(pop_new)
+
+        # Update Damp Fret Width
+        self.dyn_fw = self.dyn_fw * self.fw_damp
+
+        # Merge Harmony Memory and New Harmonies, Then sort them, Then truncate extra harmonies
+        self.pop = self.get_sorted_strim_population(self.pop + pop_new, self.pop_size)
```

### Comparing `mealpy-2.5.3/mealpy/optimizer.py` & `mealpy-2.5.3a1/mealpy/optimizer.py`

 * *Ordering differences only*

 * *Files 11% similar despite different names*

```diff
@@ -1,725 +1,725 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 08:58, 16/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from math import gamma
-from copy import deepcopy
-from mealpy.utils.history import History
-from mealpy.utils.problem import Problem
-from mealpy.utils.termination import Termination
-from mealpy.utils.logger import Logger
-from mealpy.utils.validator import Validator
-import concurrent.futures as parallel
-from functools import partial
-import os
-import time
-
-
-class Optimizer:
-    """
-    The base class of all algorithms. All methods in this class will be inherited
-
-    Notes
-    ~~~~~
-    + The function solve() is the most important method, trained the model
-    + The parallel (multithreading or multiprocessing) is used in method: create_population(), update_target_wrapper_population()
-    + The general format of:
-        + population = [agent_1, agent_2, ..., agent_N]
-        + agent = global_best = solution = [position, target]
-        + target = [fitness value, objective_list]
-        + objective_list = [obj_1, obj_2, ..., obj_M]
-    + Access to the:
-        + position of solution/agent: solution[0] or solution[self.ID_POS] or model.solution[model.ID_POS]
-        + fitness: solution[1][0] or solution[self.ID_TAR][self.ID_FIT] or model.solution[model.ID_TAR][model.ID_FIT]
-        + objective values: solution[1][1] or solution[self.ID_TAR][self.ID_OBJ] or model.solution[model.ID_TAR][model.ID_OBJ]
-    """
-
-    ID_POS = 0  # Index of position/location of solution/agent
-    ID_TAR = 1  # Index of target list, (includes fitness value and objectives list)
-
-    ID_FIT = 0  # Index of target (the final fitness) in fitness
-    ID_OBJ = 1  # Index of objective list in target
-
-    EPSILON = 10E-10
-
-    def __init__(self, **kwargs):
-        super(Optimizer, self).__init__()
-        self.epoch, self.pop_size, self.solution = None, None, None
-        self.mode, self.n_workers, self.name = None, None, None
-        self.pop, self.g_best, self.g_worst = None, None, None
-        self.problem, self.logger, self.history = None, None, None
-        self.__set_keyword_arguments(kwargs)
-        self.validator = Validator(log_to="console", log_file=None)
-
-        if self.name is None: self.name = self.__class__.__name__
-        self.sort_flag = False
-        self.nfe_counter = -1       # The first one is tested in Problem class
-        self.parameters, self.params_name_ordered = {}, None
-        self.AVAILABLE_MODES = ["process", "thread", "swarm"]
-        self.support_parallel_modes = True
-
-    def __set_keyword_arguments(self, kwargs):
-        for key, value in kwargs.items():
-            setattr(self, key, value)
-
-    def set_parameters(self, parameters):
-        """
-        Set the parameters for current optimizer.
-
-        if paras is a list of parameter's name, then it will set the default value in optimizer as current parameters
-        if paras is a dict of parameter's name and value, then it will override the current parameters
-
-        Args:
-            parameters (list, dict): List or dict of parameters
-        """
-        if type(parameters) in (list, tuple):
-            self.params_name_ordered = tuple(parameters)
-            self.parameters = {}
-            for name in parameters:
-                self.parameters[name] = self.__dict__[name]
-
-        if type(parameters) is dict:
-            valid_para_names = set(self.parameters.keys())
-            new_para_names = set(parameters.keys())
-            if new_para_names.issubset(valid_para_names):
-                for key, value in parameters.items():
-                    setattr(self, key, value)
-                    self.parameters[key] = value
-            else:
-                raise ValueError(f"Invalid input parameters: {new_para_names} for {self.get_name()} optimizer. "
-                                 f"Valid parameters are: {valid_para_names}.")
-
-    def get_parameters(self):
-        """
-        Get parameters of optimizer.
-
-        Returns:
-            dict: [str, any]
-        """
-        return self.parameters
-
-    def get_attributes(self):
-        """
-        Get all attributes in optimizer.
-
-        Returns:
-            dict: [str, any]
-        """
-        return self.__dict__
-
-    def get_name(self):
-        return self.name
-
-    def __str__(self):
-        temp = ""
-        for key in self.params_name_ordered:
-            temp += f"{key}={self.parameters[key]}, "
-        temp = temp[:-2]
-        return f"{self.__class__.__name__}({temp})"
-
-    def before_initialization(self, starting_positions=None):
-        if starting_positions is None:
-            pass
-        elif type(starting_positions) in [list, np.ndarray] and len(starting_positions) == self.pop_size:
-            if isinstance(starting_positions[0], np.ndarray) and len(starting_positions[0]) == self.problem.n_dims:
-                self.pop = [self.create_solution(self.problem.lb, self.problem.ub, pos) for pos in starting_positions]
-            else:
-                raise ValueError("Starting positions should be a list of positions or 2D matrix of positions only.")
-        else:
-            raise ValueError("Starting positions should be a list/2D matrix of positions with same length as pop_size hyper-parameter.")
-
-    def initialization(self):
-        if self.pop is None:
-            self.pop = self.create_population(self.pop_size)
-
-    def after_initialization(self):
-        # The initial population is sorted or not depended on algorithm's strategy
-        pop_temp, best, worst = self.get_special_solutions(self.pop, best=1, worst=1)
-        self.g_best, self.g_worst = best[0], worst[0]
-        # pop_temp, self.g_best = self.get_global_best_solution(self.pop)
-        if self.sort_flag: self.pop = pop_temp
-        ## Store initial best and worst solutions
-        self.history.store_initial_best_worst(self.g_best, self.g_worst)
-
-    def before_main_loop(self):
-        pass
-
-    def initialize_variables(self):
-        pass
-
-    def get_target_wrapper(self, position, counted=True):
-        """
-        Args:
-            position (nd.array): position (nd.array): 1-D numpy array
-            counted (bool): indicating the number of function evaluations is increasing or not
-
-        Returns:
-            [fitness, [obj1, obj2,...]]
-        """
-        if counted:
-            self.nfe_counter += 1
-        objs = self.problem.fit_func(position)
-        if not self.problem.obj_is_list:
-            objs = [objs]
-        fit = np.dot(objs, self.problem.obj_weights)
-        return [fit, objs]
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        """
-        To get the position, target wrapper [fitness and obj list]
-            + A[self.ID_POS]                  --> Return: position
-            + A[self.ID_TAR]                  --> Return: [fitness, [obj1, obj2, ...]]
-            + A[self.ID_TAR][self.ID_FIT]     --> Return: fitness
-            + A[self.ID_TAR][self.ID_OBJ]     --> Return: [obj1, obj2, ...]
-
-        Args:
-            lb: list of lower bound values
-            ub: list of upper bound values
-            pos (np.ndarray): the known position. If None is passed, the default function generate_position() will be used
-
-        Returns:
-            list: wrapper of solution with format [position, [fitness, [obj1, obj2, ...]]]
-        """
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        position = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(position)
-        return [position, target]
-
-    def evolve(self, epoch):
-        pass
-
-    def check_problem(self, problem):
-        self.problem = problem if isinstance(problem, Problem) else Problem(**problem)
-        self.amend_position = self.problem.amend_position
-        self.generate_position = self.problem.generate_position
-        self.logger = Logger(self.problem.log_to, log_file=self.problem.log_file).create_logger(name=f"{self.__module__}.{self.__class__.__name__}")
-        self.logger.info(self.problem.msg)
-        self.history = History(log_to=self.problem.log_to, log_file=self.problem.log_file)
-        self.pop, self.g_best, self.g_worst = None, None, None
-
-    def check_mode_and_workers(self, mode, n_workers):
-        self.mode = self.validator.check_str("mode", mode, ["single", "swarm", "thread", "process"])
-        if self.mode in ("process", "thread"):
-            if not self.support_parallel_modes:
-                self.logger.warning(f"{self.__class__.__name__} doesn't support parallelization. The default mode 'single' is activated.")
-                self.mode = "single"
-            elif n_workers is not None:
-                if self.mode == "process":
-                    self.n_workers = self.validator.check_int("n_workers", n_workers, [2, min(61, os.cpu_count() - 1)])
-                if self.mode == "thread":
-                    self.n_workers = self.validator.check_int("n_workers", n_workers, [2, min(32, os.cpu_count() + 4)])
-            else:
-                self.logger.warning(f"The parallel mode: {self.mode} is selected. But n_workers is not set. The default n_workers = 4 is used.")
-                self.n_workers = 4
-
-    def check_termination(self, mode="start", termination=None, epoch=None):
-        if mode == "start":
-            self.termination = termination
-            if termination is not None:
-                if isinstance(termination, Termination):
-                    self.termination = termination
-                elif type(termination) == dict:
-                    self.termination = Termination(log_to=self.problem.log_to, log_file=self.problem.log_file, **termination)
-                else:
-                    raise ValueError("Termination needs to be a dict or an instance of Termination class.")
-                self.nfe_counter = 0
-                self.termination.set_start_values(0, self.nfe_counter, time.perf_counter(), 0)
-        else:
-            finished = False
-            if self.termination is not None:
-                es = self.history.get_global_repeated_times(self.ID_TAR, self.ID_FIT, self.termination.epsilon)
-                finished = self.termination.should_terminate(epoch, self.nfe_counter, time.perf_counter(), es)
-                if finished:
-                    self.logger.warning(self.termination.message)
-            return finished
-
-    def solve(self, problem=None, mode='single', starting_positions=None, n_workers=None, termination=None):
-        """
-        Args:
-            problem (Problem, dict): an instance of Problem class or a dictionary
-
-                problem = {
-                    "fit_func": your objective function,
-                    "lb": list of value
-                    "ub": list of value
-                    "minmax": "min" or "max"
-                    "verbose": True or False
-                    "n_dims": int (Optional)
-                    "obj_weights": list weights corresponding to all objectives (Optional, default = [1, 1, ...1])
-                }
-
-            mode (str): Parallel: 'process', 'thread'; Sequential: 'swarm', 'single'.
-
-                * 'process': The parallel mode with multiple cores run the tasks
-                * 'thread': The parallel mode with multiple threads run the tasks
-                * 'swarm': The sequential mode that no effect on updating phase of other agents
-                * 'single': The sequential mode that effect on updating phase of other agents, default
-
-            starting_positions(list, np.ndarray): List or 2D matrix (numpy array) of starting positions with length equal pop_size parameter
-            n_workers (int): The number of workers (cores or threads) to do the tasks (effect only on parallel mode)
-            termination (dict, None): The termination dictionary or an instance of Termination class
-
-        Returns:
-            list: [position, fitness value]
-        """
-        self.check_problem(problem)
-        self.check_mode_and_workers(mode, n_workers)
-        self.check_termination("start", termination, None)
-        self.initialize_variables()
-
-        self.before_initialization(starting_positions)
-        self.initialization()
-        self.after_initialization()
-
-        self.before_main_loop()
-        for epoch in range(0, self.epoch):
-            time_epoch = time.perf_counter()
-
-            ## Evolve method will be called in child class
-            self.evolve(epoch)
-
-            # Update global best position, the population is sorted or not depended on algorithm's strategy
-            pop_temp, self.g_best = self.update_global_best_solution(self.pop)
-            if self.sort_flag: self.pop = pop_temp
-
-            time_epoch = time.perf_counter() - time_epoch
-            self.track_optimize_step(self.pop, epoch + 1, time_epoch)
-            if self.check_termination("end", None, epoch+1):
-                break
-        self.track_optimize_process()
-        return self.solution[self.ID_POS], self.solution[self.ID_TAR][self.ID_FIT]
-
-    def track_optimize_step(self, population=None, epoch=None, runtime=None):
-        """
-        Save some historical data and print out the detailed information of training process in each epoch
-
-        Args:
-            population (list): the current population
-            epoch (int): current iteration
-            runtime (float): the runtime for current iteration
-        """
-        ## Save history data
-        pop = deepcopy(population)
-        if self.problem.save_population:
-            self.history.list_population.append(pop)
-        self.history.list_epoch_time.append(runtime)
-        self.history.list_global_best_fit.append(self.history.list_global_best[-1][self.ID_TAR][self.ID_FIT])
-        self.history.list_current_best_fit.append(self.history.list_current_best[-1][self.ID_TAR][self.ID_FIT])
-        # Save the exploration and exploitation data for later usage
-        pos_matrix = np.array([agent[self.ID_POS] for agent in pop])
-        div = np.mean(np.abs(np.median(pos_matrix, axis=0) - pos_matrix), axis=0)
-        self.history.list_diversity.append(np.mean(div, axis=0))
-        ## Print epoch
-        self.logger.info(f">Problem: {self.problem.name}, Epoch: {epoch}, Current best: {self.history.list_current_best[-1][self.ID_TAR][self.ID_FIT]}, "
-                         f"Global best: {self.history.list_global_best[-1][self.ID_TAR][self.ID_FIT]}, Runtime: {runtime:.5f} seconds")
-
-    def track_optimize_process(self):
-        """
-        Save some historical data after training process finished
-        """
-        self.history.epoch = len(self.history.list_diversity)
-        div_max = np.max(self.history.list_diversity)
-        self.history.list_exploration = 100 * (np.array(self.history.list_diversity) / div_max)
-        self.history.list_exploitation = 100 - self.history.list_exploration
-        self.history.list_global_best = self.history.list_global_best[1:]
-        self.history.list_current_best = self.history.list_current_best[1:]
-        self.solution = self.history.list_global_best[-1]
-        self.history.list_global_worst = self.history.list_global_worst[1:]
-        self.history.list_current_worst = self.history.list_current_worst[1:]
-
-    def create_population(self, pop_size=None):
-        """
-        Args:
-            pop_size (int): number of solutions
-
-        Returns:
-            list: population or list of solutions/agents
-        """
-        if pop_size is None:
-            pop_size = self.pop_size
-        pop = []
-        if self.mode == "thread":
-            with parallel.ThreadPoolExecutor(self.n_workers) as executor:
-                list_executors = [executor.submit(self.create_solution, self.problem.lb, self.problem.ub) for _ in range(pop_size)]
-                # This method yield the result everytime a thread finished their job (not by order)
-                for f in parallel.as_completed(list_executors):
-                    pop.append(f.result())
-        elif self.mode == "process":
-            with parallel.ProcessPoolExecutor(self.n_workers) as executor:
-                list_executors = [executor.submit(self.create_solution, self.problem.lb, self.problem.ub) for _ in range(pop_size)]
-                # This method yield the result everytime a cpu finished their job (not by order).
-                for f in parallel.as_completed(list_executors):
-                    pop.append(f.result())
-        else:
-            pop = [self.create_solution(self.problem.lb, self.problem.ub) for _ in range(0, pop_size)]
-        return pop
-
-    def update_target_wrapper_population(self, pop=None):
-        """
-        Update target wrapper for input population
-
-        Args:
-            pop (list): the population
-
-        Returns:
-            list: population with updated fitness value
-        """
-        pos_list = [agent[self.ID_POS] for agent in pop]
-        if self.mode == "thread":
-            with parallel.ThreadPoolExecutor(self.n_workers) as executor:
-                # Return result as original order, not the future object
-                list_results = executor.map(partial(self.get_target_wrapper, counted=False), pos_list)
-                for idx, target in enumerate(list_results):
-                    pop[idx][self.ID_TAR] = target
-        elif self.mode == "process":
-            with parallel.ProcessPoolExecutor(self.n_workers) as executor:
-                # Return result as original order, not the future object
-                list_results = executor.map(partial(self.get_target_wrapper, counted=False), pos_list)
-                for idx, target in enumerate(list_results):
-                    pop[idx][self.ID_TAR] = target
-        elif self.mode == "swarm":
-            for idx, pos in enumerate(pos_list):
-                pop[idx][self.ID_TAR] = self.get_target_wrapper(pos, counted=False)
-        else:
-            return pop
-        self.nfe_counter += len(pop)
-        return pop
-
-    def get_global_best_solution(self, pop: list):
-        """
-        Sort population and return the sorted population and the best solution
-
-        Args:
-            pop (list): The population of pop_size individuals
-
-        Returns:
-            Sorted population and global best solution
-        """
-        sorted_pop = sorted(pop, key=lambda agent: agent[self.ID_TAR][self.ID_FIT])  # Already returned a new sorted list
-        if self.problem.minmax == "min":
-            return sorted_pop, deepcopy(sorted_pop[0])
-        else:
-            return sorted_pop, deepcopy(sorted_pop[-1])
-
-    def get_better_solution(self, agent1: list, agent2: list, reverse=False):
-        """
-        Args:
-            agent1 (list): A solution
-            agent2 (list): Another solution
-            reverse (bool): Transform this function to get_worse_solution if reverse=True, default=False
-
-        Returns:
-            The better solution between them
-        """
-        if self.problem.minmax == "min":
-            if agent1[self.ID_TAR][self.ID_FIT] < agent2[self.ID_TAR][self.ID_FIT]:
-                return deepcopy(agent1) if reverse is False else deepcopy(agent2)
-            return deepcopy(agent2) if reverse is False else deepcopy(agent1)
-        else:
-            if agent1[self.ID_TAR][self.ID_FIT] < agent2[self.ID_TAR][self.ID_FIT]:
-                return deepcopy(agent2) if reverse is False else deepcopy(agent1)
-            return deepcopy(agent1) if reverse is False else deepcopy(agent2)
-
-    def compare_agent(self, agent_new: list, agent_old: list):
-        """
-        Args:
-            agent_new (list): The new solution
-            agent_old (list): The old solution
-
-        Returns:
-            boolean: Return True if the new solution is better than the old one and otherwise
-        """
-        if self.problem.minmax == "min":
-            if agent_new[self.ID_TAR][self.ID_FIT] < agent_old[self.ID_TAR][self.ID_FIT]:
-                return True
-            return False
-        else:
-            if agent_new[self.ID_TAR][self.ID_FIT] < agent_old[self.ID_TAR][self.ID_FIT]:
-                return False
-            return True
-
-    def get_special_solutions(self, pop=None, best=3, worst=3):
-        """
-        Args:
-            pop (list): The population
-            best (int): Top k1 best solutions, default k1=3, good level reduction
-            worst (int): Top k2 worst solutions, default k2=3, worst level reduction
-
-        Returns:
-            list: sorted_population, k1 best solutions and k2 worst solutions
-        """
-        if self.problem.minmax == "min":
-            pop = sorted(pop, key=lambda agent: agent[self.ID_TAR][self.ID_FIT])
-        else:
-            pop = sorted(pop, key=lambda agent: agent[self.ID_TAR][self.ID_FIT], reverse=True)
-        if best is None:
-            if worst is None:
-                raise ValueError("Best and Worst can not be None in get_special_solutions function!")
-            else:
-                return pop, None, deepcopy(pop[::-1][:worst])
-        else:
-            if worst is None:
-                return pop, deepcopy(pop[:best]), None
-            else:
-                return pop, deepcopy(pop[:best]), deepcopy(pop[::-1][:worst])
-
-    def get_special_fitness(self, pop=None):
-        """
-        Args:
-            pop (list): The population
-
-        Returns:
-            list: Total fitness, best fitness, worst fitness
-        """
-        total_fitness = np.sum([agent[self.ID_TAR][self.ID_FIT] for agent in pop])
-        if self.problem.minmax == "min":
-            pop = sorted(pop, key=lambda agent: agent[self.ID_TAR][self.ID_FIT])
-        else:
-            pop = sorted(pop, key=lambda agent: agent[self.ID_TAR][self.ID_FIT], reverse=True)
-        return total_fitness, pop[0][self.ID_TAR][self.ID_FIT], pop[-1][self.ID_TAR][self.ID_FIT]
-
-    def update_global_best_solution(self, pop=None, save=True):
-        """
-        Update global best and current best solutions in history object.
-        Also update global worst and current worst solutions in history object.
-
-        Args:
-            pop (list): The population of pop_size individuals
-            save (bool): True if you want to add new current/global best to history, False if you just want to update current/global best
-
-        Returns:
-            list: Sorted population and the global best solution
-        """
-        if self.problem.minmax == "min":
-            sorted_pop = sorted(pop, key=lambda agent: agent[self.ID_TAR][self.ID_FIT])
-        else:
-            sorted_pop = sorted(pop, key=lambda agent: agent[self.ID_TAR][self.ID_FIT], reverse=True)
-        current_best = sorted_pop[0]
-        current_worst = sorted_pop[-1]
-        if save:
-            ## Save current best
-            self.history.list_current_best.append(current_best)
-            better = self.get_better_solution(current_best, self.history.list_global_best[-1])
-            self.history.list_global_best.append(better)
-            ## Save current worst
-            self.history.list_current_worst.append(current_worst)
-            worse = self.get_better_solution(current_worst, self.history.list_global_worst[-1], reverse=True)
-            self.history.list_global_worst.append(worse)
-            return deepcopy(sorted_pop), deepcopy(better)
-        else:
-            ## Handle current best
-            local_better = self.get_better_solution(current_best, self.history.list_current_best[-1])
-            self.history.list_current_best[-1] = local_better
-            global_better = self.get_better_solution(current_best, self.history.list_global_best[-1])
-            self.history.list_global_best[-1] = global_better
-            ## Handle current worst
-            local_worst = self.get_better_solution(current_worst, self.history.list_current_worst[-1], reverse=True)
-            self.history.list_current_worst[-1] = local_worst
-            global_worst = self.get_better_solution(current_worst, self.history.list_global_worst[-1], reverse=True)
-            self.history.list_global_worst[-1] = global_worst
-            return deepcopy(sorted_pop), deepcopy(global_better)
-
-    def get_index_best(self, pop):
-        fit_list = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in pop])
-        if self.problem.minmax == "min":
-            return np.argmin(fit_list)
-        else:
-            return np.argmax(fit_list)
-
-    ## Selection techniques
-    def get_index_roulette_wheel_selection(self, list_fitness: np.array):
-        """
-        This method can handle min/max problem, and negative or positive fitness value.
-
-        Args:
-            list_fitness (nd.array): 1-D numpy array
-
-        Returns:
-            int: Index of selected solution
-        """
-        if type(list_fitness) in [list, tuple, np.ndarray]:
-            list_fitness = np.array(list_fitness).flatten()
-        if list_fitness.ptp() == 0:
-            return int(np.random.randint(0, len(list_fitness)))
-        if np.any(list_fitness) < 0:
-            list_fitness = list_fitness - np.min(list_fitness)
-        final_fitness = list_fitness
-        if self.problem.minmax == "min":
-            final_fitness = np.max(list_fitness) - list_fitness
-        prob = final_fitness / np.sum(final_fitness)
-        return int(np.random.choice(range(0, len(list_fitness)), p=prob))
-
-    def get_index_kway_tournament_selection(self, pop=None, k_way=0.2, output=2, reverse=False):
-        """
-        Args:
-            pop: The population
-            k_way (float/int): The percent or number of solutions are randomized pick
-            output (int): The number of outputs
-            reverse (bool): set True when finding the worst fitness
-
-        Returns:
-            list: List of the selected indexes
-        """
-        if 0 < k_way < 1:
-            k_way = int(k_way * len(pop))
-        list_id = np.random.choice(range(len(pop)), k_way, replace=False)
-        list_parents = [[idx, pop[idx][self.ID_TAR][self.ID_FIT]] for idx in list_id]
-        if self.problem.minmax == "min":
-            list_parents = sorted(list_parents, key=lambda agent: agent[1])
-        else:
-            list_parents = sorted(list_parents, key=lambda agent: agent[1], reverse=True)
-        if reverse:
-            return [parent[0] for parent in list_parents[-output:]]
-        return [parent[0] for parent in list_parents[:output]]
-
-    def get_levy_flight_step(self, beta=1.0, multiplier=0.001, size=None, case=0):
-        """
-        Get the Levy-flight step size
-
-        Args:
-            beta (float): Should be in range [0, 2].
-
-                * 0-1: small range --> exploit
-                * 1-2: large range --> explore
-
-            multiplier (float): default = 0.001
-            size (tuple, list): size of levy-flight steps, for example: (3, 2), 5, (4, )
-            case (int): Should be one of these value [0, 1, -1].
-
-                * 0: return multiplier * s * np.random.uniform()
-                * 1: return multiplier * s * np.random.normal(0, 1)
-                * -1: return multiplier * s
-
-        Returns:
-            int: The step size of Levy-flight trajectory
-        """
-        # u and v are two random variables which follow np.random.normal distribution
-        # sigma_u : standard deviation of u
-        sigma_u = np.power(gamma(1 + beta) * np.sin(np.pi * beta / 2) / (gamma((1 + beta) / 2) * beta * np.power(2, (beta - 1) / 2)), 1 / beta)
-        # sigma_v : standard deviation of v
-        sigma_v = 1
-        size = 1 if size is None else size
-        u = np.random.normal(0, sigma_u ** 2, size)
-        v = np.random.normal(0, sigma_v ** 2, size)
-        s = u / np.power(np.abs(v), 1 / beta)
-        if case == 0:
-            step = multiplier * s * np.random.uniform()
-        elif case == 1:
-            step = multiplier * s * np.random.normal(0, 1)
-        else:
-            step = multiplier * s
-        return step[0] if size == 1 else step
-
-    ### Survivor Selection
-    def greedy_selection_population(self, pop_old=None, pop_new=None):
-        """
-        Args:
-            pop_old (list): The current population
-            pop_new (list): The next population
-
-        Returns:
-            The new population with better solutions
-        """
-        len_old, len_new = len(pop_old), len(pop_new)
-        if len_old != len_new:
-            raise ValueError("Greedy selection of two population with different length.")
-        if self.problem.minmax == "min":
-            return [pop_new[i] if pop_new[i][self.ID_TAR][self.ID_FIT] < pop_old[i][self.ID_TAR][self.ID_FIT]
-                    else pop_old[i] for i in range(len_old)]
-        else:
-            return [pop_new[i] if pop_new[i][self.ID_TAR] > pop_old[i][self.ID_TAR]
-                    else pop_old[i] for i in range(len_old)]
-
-    def get_sorted_strim_population(self, pop=None, pop_size=None, reverse=False):
-        """
-        Args:
-            pop (list): The population
-            pop_size (int): The number of population
-            reverse (bool): False (ascending fitness order), and True (descending fitness order)
-
-        Returns:
-            The sorted population with pop_size size
-        """
-        if self.problem.minmax == "min":
-            pop = sorted(pop, key=lambda agent: agent[self.ID_TAR][self.ID_FIT], reverse=reverse)
-        else:
-            pop = sorted(pop, key=lambda agent: agent[self.ID_TAR][self.ID_FIT], reverse=reverse)
-        return pop[:pop_size]
-
-    def create_opposition_position(self, agent=None, g_best=None):
-        """
-        Args:
-            agent: The current solution (agent)
-            g_best: the global best solution (agent)
-
-        Returns:
-            The opposite position
-        """
-        return self.problem.lb + self.problem.ub - g_best[self.ID_POS] + np.random.uniform() * (g_best[self.ID_POS] - agent[self.ID_POS])
-
-    def create_pop_group(self, pop, n_groups, m_agents):
-        pop_group = []
-        for i in range(0, n_groups):
-            group = pop[i * m_agents: (i + 1) * m_agents]
-            pop_group.append(deepcopy(group))
-        return pop_group
-
-    ### Crossover
-    def crossover_arithmetic(self, dad_pos=None, mom_pos=None):
-        """
-        Args:
-            dad_pos: position of dad
-            mom_pos: position of mom
-
-        Returns:
-            list: position of 1st and 2nd child
-        """
-        r = np.random.uniform()  # w1 = w2 when r =0.5
-        w1 = np.multiply(r, dad_pos) + np.multiply((1 - r), mom_pos)
-        w2 = np.multiply(r, mom_pos) + np.multiply((1 - r), dad_pos)
-        return w1, w2
-
-    #### Improved techniques can be used in any algorithms: 1
-    ## Based on this paper: An efficient equilibrium optimizer with mutation strategy for numerical optimization (but still different)
-    ## This scheme used after the original and including 4 step:
-    ##  s1: sort population, take p1 = 1/2 best population for next round
-    ##  s2: do the mutation for p1, using greedy method to select the better solution
-    ##  s3: do the search mechanism for p1 (based on global best solution and the updated p1 above), to make p2 population
-    ##  s4: construct the new population for next generation
-    def improved_ms(self, pop=None, g_best=None):  ## m: mutation, s: search
-        pop_len = int(len(pop) / 2)
-        ## Sort the updated population based on fitness
-        pop = sorted(pop, key=lambda item: item[self.ID_TAR][self.ID_FIT])
-        pop_s1, pop_s2 = pop[:pop_len], pop[pop_len:]
-
-        ## Mutation scheme
-        pop_new = []
-        for i in range(0, pop_len):
-            agent = deepcopy(pop_s1[i])
-            pos_new = pop_s1[i][self.ID_POS] * (1 + np.random.normal(0, 1, self.problem.n_dims))
-            agent[self.ID_POS] = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append(agent)
-        pop_new = self.update_target_wrapper_population(pop_new)
-        pop_s1 = self.greedy_selection_population(pop_s1, pop_new)  ## Greedy method --> improved exploitation
-
-        ## Search Mechanism
-        pos_s1_list = [item[self.ID_POS] for item in pop_s1]
-        pos_s1_mean = np.mean(pos_s1_list, axis=0)
-        pop_new = []
-        for i in range(0, pop_len):
-            agent = deepcopy(pop_s2[i])
-            pos_new = (g_best[self.ID_POS] - pos_s1_mean) - np.random.random() * \
-                      (self.problem.lb + np.random.random() * (self.problem.ub - self.problem.lb))
-            agent[self.ID_POS] = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append(agent)
-        ## Keep the diversity of populatoin and still improved the exploration
-        pop_s2 = self.update_target_wrapper_population(pop_new)
-        pop_s2 = self.greedy_selection_population(pop_s2, pop_new)
-
-        ## Construct a new population
-        pop = pop_s1 + pop_s2
-        return pop
+#!/usr/bin/env python
+# Created by "Thieu" at 08:58, 16/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from math import gamma
+from copy import deepcopy
+from mealpy.utils.history import History
+from mealpy.utils.problem import Problem
+from mealpy.utils.termination import Termination
+from mealpy.utils.logger import Logger
+from mealpy.utils.validator import Validator
+import concurrent.futures as parallel
+from functools import partial
+import os
+import time
+
+
+class Optimizer:
+    """
+    The base class of all algorithms. All methods in this class will be inherited
+
+    Notes
+    ~~~~~
+    + The function solve() is the most important method, trained the model
+    + The parallel (multithreading or multiprocessing) is used in method: create_population(), update_target_wrapper_population()
+    + The general format of:
+        + population = [agent_1, agent_2, ..., agent_N]
+        + agent = global_best = solution = [position, target]
+        + target = [fitness value, objective_list]
+        + objective_list = [obj_1, obj_2, ..., obj_M]
+    + Access to the:
+        + position of solution/agent: solution[0] or solution[self.ID_POS] or model.solution[model.ID_POS]
+        + fitness: solution[1][0] or solution[self.ID_TAR][self.ID_FIT] or model.solution[model.ID_TAR][model.ID_FIT]
+        + objective values: solution[1][1] or solution[self.ID_TAR][self.ID_OBJ] or model.solution[model.ID_TAR][model.ID_OBJ]
+    """
+
+    ID_POS = 0  # Index of position/location of solution/agent
+    ID_TAR = 1  # Index of target list, (includes fitness value and objectives list)
+
+    ID_FIT = 0  # Index of target (the final fitness) in fitness
+    ID_OBJ = 1  # Index of objective list in target
+
+    EPSILON = 10E-10
+
+    def __init__(self, **kwargs):
+        super(Optimizer, self).__init__()
+        self.epoch, self.pop_size, self.solution = None, None, None
+        self.mode, self.n_workers, self.name = None, None, None
+        self.pop, self.g_best, self.g_worst = None, None, None
+        self.problem, self.logger, self.history = None, None, None
+        self.__set_keyword_arguments(kwargs)
+        self.validator = Validator(log_to="console", log_file=None)
+
+        if self.name is None: self.name = self.__class__.__name__
+        self.sort_flag = False
+        self.nfe_counter = -1       # The first one is tested in Problem class
+        self.parameters, self.params_name_ordered = {}, None
+        self.AVAILABLE_MODES = ["process", "thread", "swarm"]
+        self.support_parallel_modes = True
+
+    def __set_keyword_arguments(self, kwargs):
+        for key, value in kwargs.items():
+            setattr(self, key, value)
+
+    def set_parameters(self, parameters):
+        """
+        Set the parameters for current optimizer.
+
+        if paras is a list of parameter's name, then it will set the default value in optimizer as current parameters
+        if paras is a dict of parameter's name and value, then it will override the current parameters
+
+        Args:
+            parameters (list, dict): List or dict of parameters
+        """
+        if type(parameters) in (list, tuple):
+            self.params_name_ordered = tuple(parameters)
+            self.parameters = {}
+            for name in parameters:
+                self.parameters[name] = self.__dict__[name]
+
+        if type(parameters) is dict:
+            valid_para_names = set(self.parameters.keys())
+            new_para_names = set(parameters.keys())
+            if new_para_names.issubset(valid_para_names):
+                for key, value in parameters.items():
+                    setattr(self, key, value)
+                    self.parameters[key] = value
+            else:
+                raise ValueError(f"Invalid input parameters: {new_para_names} for {self.get_name()} optimizer. "
+                                 f"Valid parameters are: {valid_para_names}.")
+
+    def get_parameters(self):
+        """
+        Get parameters of optimizer.
+
+        Returns:
+            dict: [str, any]
+        """
+        return self.parameters
+
+    def get_attributes(self):
+        """
+        Get all attributes in optimizer.
+
+        Returns:
+            dict: [str, any]
+        """
+        return self.__dict__
+
+    def get_name(self):
+        return self.name
+
+    def __str__(self):
+        temp = ""
+        for key in self.params_name_ordered:
+            temp += f"{key}={self.parameters[key]}, "
+        temp = temp[:-2]
+        return f"{self.__class__.__name__}({temp})"
+
+    def before_initialization(self, starting_positions=None):
+        if starting_positions is None:
+            pass
+        elif type(starting_positions) in [list, np.ndarray] and len(starting_positions) == self.pop_size:
+            if isinstance(starting_positions[0], np.ndarray) and len(starting_positions[0]) == self.problem.n_dims:
+                self.pop = [self.create_solution(self.problem.lb, self.problem.ub, pos) for pos in starting_positions]
+            else:
+                raise ValueError("Starting positions should be a list of positions or 2D matrix of positions only.")
+        else:
+            raise ValueError("Starting positions should be a list/2D matrix of positions with same length as pop_size hyper-parameter.")
+
+    def initialization(self):
+        if self.pop is None:
+            self.pop = self.create_population(self.pop_size)
+
+    def after_initialization(self):
+        # The initial population is sorted or not depended on algorithm's strategy
+        pop_temp, best, worst = self.get_special_solutions(self.pop, best=1, worst=1)
+        self.g_best, self.g_worst = best[0], worst[0]
+        # pop_temp, self.g_best = self.get_global_best_solution(self.pop)
+        if self.sort_flag: self.pop = pop_temp
+        ## Store initial best and worst solutions
+        self.history.store_initial_best_worst(self.g_best, self.g_worst)
+
+    def before_main_loop(self):
+        pass
+
+    def initialize_variables(self):
+        pass
+
+    def get_target_wrapper(self, position, counted=True):
+        """
+        Args:
+            position (nd.array): position (nd.array): 1-D numpy array
+            counted (bool): indicating the number of function evaluations is increasing or not
+
+        Returns:
+            [fitness, [obj1, obj2,...]]
+        """
+        if counted:
+            self.nfe_counter += 1
+        objs = self.problem.fit_func(position)
+        if not self.problem.obj_is_list:
+            objs = [objs]
+        fit = np.dot(objs, self.problem.obj_weights)
+        return [fit, objs]
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        """
+        To get the position, target wrapper [fitness and obj list]
+            + A[self.ID_POS]                  --> Return: position
+            + A[self.ID_TAR]                  --> Return: [fitness, [obj1, obj2, ...]]
+            + A[self.ID_TAR][self.ID_FIT]     --> Return: fitness
+            + A[self.ID_TAR][self.ID_OBJ]     --> Return: [obj1, obj2, ...]
+
+        Args:
+            lb: list of lower bound values
+            ub: list of upper bound values
+            pos (np.ndarray): the known position. If None is passed, the default function generate_position() will be used
+
+        Returns:
+            list: wrapper of solution with format [position, [fitness, [obj1, obj2, ...]]]
+        """
+        if pos is None:
+            pos = self.generate_position(lb, ub)
+        position = self.amend_position(pos, lb, ub)
+        target = self.get_target_wrapper(position)
+        return [position, target]
+
+    def evolve(self, epoch):
+        pass
+
+    def check_problem(self, problem):
+        self.problem = problem if isinstance(problem, Problem) else Problem(**problem)
+        self.amend_position = self.problem.amend_position
+        self.generate_position = self.problem.generate_position
+        self.logger = Logger(self.problem.log_to, log_file=self.problem.log_file).create_logger(name=f"{self.__module__}.{self.__class__.__name__}")
+        self.logger.info(self.problem.msg)
+        self.history = History(log_to=self.problem.log_to, log_file=self.problem.log_file)
+        self.pop, self.g_best, self.g_worst = None, None, None
+
+    def check_mode_and_workers(self, mode, n_workers):
+        self.mode = self.validator.check_str("mode", mode, ["single", "swarm", "thread", "process"])
+        if self.mode in ("process", "thread"):
+            if not self.support_parallel_modes:
+                self.logger.warning(f"{self.__class__.__name__} doesn't support parallelization. The default mode 'single' is activated.")
+                self.mode = "single"
+            elif n_workers is not None:
+                if self.mode == "process":
+                    self.n_workers = self.validator.check_int("n_workers", n_workers, [2, min(61, os.cpu_count() - 1)])
+                if self.mode == "thread":
+                    self.n_workers = self.validator.check_int("n_workers", n_workers, [2, min(32, os.cpu_count() + 4)])
+            else:
+                self.logger.warning(f"The parallel mode: {self.mode} is selected. But n_workers is not set. The default n_workers = 4 is used.")
+                self.n_workers = 4
+
+    def check_termination(self, mode="start", termination=None, epoch=None):
+        if mode == "start":
+            self.termination = termination
+            if termination is not None:
+                if isinstance(termination, Termination):
+                    self.termination = termination
+                elif type(termination) == dict:
+                    self.termination = Termination(log_to=self.problem.log_to, log_file=self.problem.log_file, **termination)
+                else:
+                    raise ValueError("Termination needs to be a dict or an instance of Termination class.")
+                self.nfe_counter = 0
+                self.termination.set_start_values(0, self.nfe_counter, time.perf_counter(), 0)
+        else:
+            finished = False
+            if self.termination is not None:
+                es = self.history.get_global_repeated_times(self.ID_TAR, self.ID_FIT, self.termination.epsilon)
+                finished = self.termination.should_terminate(epoch, self.nfe_counter, time.perf_counter(), es)
+                if finished:
+                    self.logger.warning(self.termination.message)
+            return finished
+
+    def solve(self, problem=None, mode='single', starting_positions=None, n_workers=None, termination=None):
+        """
+        Args:
+            problem (Problem, dict): an instance of Problem class or a dictionary
+
+                problem = {
+                    "fit_func": your objective function,
+                    "lb": list of value
+                    "ub": list of value
+                    "minmax": "min" or "max"
+                    "verbose": True or False
+                    "n_dims": int (Optional)
+                    "obj_weights": list weights corresponding to all objectives (Optional, default = [1, 1, ...1])
+                }
+
+            mode (str): Parallel: 'process', 'thread'; Sequential: 'swarm', 'single'.
+
+                * 'process': The parallel mode with multiple cores run the tasks
+                * 'thread': The parallel mode with multiple threads run the tasks
+                * 'swarm': The sequential mode that no effect on updating phase of other agents
+                * 'single': The sequential mode that effect on updating phase of other agents, default
+
+            starting_positions(list, np.ndarray): List or 2D matrix (numpy array) of starting positions with length equal pop_size parameter
+            n_workers (int): The number of workers (cores or threads) to do the tasks (effect only on parallel mode)
+            termination (dict, None): The termination dictionary or an instance of Termination class
+
+        Returns:
+            list: [position, fitness value]
+        """
+        self.check_problem(problem)
+        self.check_mode_and_workers(mode, n_workers)
+        self.check_termination("start", termination, None)
+        self.initialize_variables()
+
+        self.before_initialization(starting_positions)
+        self.initialization()
+        self.after_initialization()
+
+        self.before_main_loop()
+        for epoch in range(0, self.epoch):
+            time_epoch = time.perf_counter()
+
+            ## Evolve method will be called in child class
+            self.evolve(epoch)
+
+            # Update global best position, the population is sorted or not depended on algorithm's strategy
+            pop_temp, self.g_best = self.update_global_best_solution(self.pop)
+            if self.sort_flag: self.pop = pop_temp
+
+            time_epoch = time.perf_counter() - time_epoch
+            self.track_optimize_step(self.pop, epoch + 1, time_epoch)
+            if self.check_termination("end", None, epoch+1):
+                break
+        self.track_optimize_process()
+        return self.solution[self.ID_POS], self.solution[self.ID_TAR][self.ID_FIT]
+
+    def track_optimize_step(self, population=None, epoch=None, runtime=None):
+        """
+        Save some historical data and print out the detailed information of training process in each epoch
+
+        Args:
+            population (list): the current population
+            epoch (int): current iteration
+            runtime (float): the runtime for current iteration
+        """
+        ## Save history data
+        pop = deepcopy(population)
+        if self.problem.save_population:
+            self.history.list_population.append(pop)
+        self.history.list_epoch_time.append(runtime)
+        self.history.list_global_best_fit.append(self.history.list_global_best[-1][self.ID_TAR][self.ID_FIT])
+        self.history.list_current_best_fit.append(self.history.list_current_best[-1][self.ID_TAR][self.ID_FIT])
+        # Save the exploration and exploitation data for later usage
+        pos_matrix = np.array([agent[self.ID_POS] for agent in pop])
+        div = np.mean(np.abs(np.median(pos_matrix, axis=0) - pos_matrix), axis=0)
+        self.history.list_diversity.append(np.mean(div, axis=0))
+        ## Print epoch
+        self.logger.info(f">Problem: {self.problem.name}, Epoch: {epoch}, Current best: {self.history.list_current_best[-1][self.ID_TAR][self.ID_FIT]}, "
+                         f"Global best: {self.history.list_global_best[-1][self.ID_TAR][self.ID_FIT]}, Runtime: {runtime:.5f} seconds")
+
+    def track_optimize_process(self):
+        """
+        Save some historical data after training process finished
+        """
+        self.history.epoch = len(self.history.list_diversity)
+        div_max = np.max(self.history.list_diversity)
+        self.history.list_exploration = 100 * (np.array(self.history.list_diversity) / div_max)
+        self.history.list_exploitation = 100 - self.history.list_exploration
+        self.history.list_global_best = self.history.list_global_best[1:]
+        self.history.list_current_best = self.history.list_current_best[1:]
+        self.solution = self.history.list_global_best[-1]
+        self.history.list_global_worst = self.history.list_global_worst[1:]
+        self.history.list_current_worst = self.history.list_current_worst[1:]
+
+    def create_population(self, pop_size=None):
+        """
+        Args:
+            pop_size (int): number of solutions
+
+        Returns:
+            list: population or list of solutions/agents
+        """
+        if pop_size is None:
+            pop_size = self.pop_size
+        pop = []
+        if self.mode == "thread":
+            with parallel.ThreadPoolExecutor(self.n_workers) as executor:
+                list_executors = [executor.submit(self.create_solution, self.problem.lb, self.problem.ub) for _ in range(pop_size)]
+                # This method yield the result everytime a thread finished their job (not by order)
+                for f in parallel.as_completed(list_executors):
+                    pop.append(f.result())
+        elif self.mode == "process":
+            with parallel.ProcessPoolExecutor(self.n_workers) as executor:
+                list_executors = [executor.submit(self.create_solution, self.problem.lb, self.problem.ub) for _ in range(pop_size)]
+                # This method yield the result everytime a cpu finished their job (not by order).
+                for f in parallel.as_completed(list_executors):
+                    pop.append(f.result())
+        else:
+            pop = [self.create_solution(self.problem.lb, self.problem.ub) for _ in range(0, pop_size)]
+        return pop
+
+    def update_target_wrapper_population(self, pop=None):
+        """
+        Update target wrapper for input population
+
+        Args:
+            pop (list): the population
+
+        Returns:
+            list: population with updated fitness value
+        """
+        pos_list = [agent[self.ID_POS] for agent in pop]
+        if self.mode == "thread":
+            with parallel.ThreadPoolExecutor(self.n_workers) as executor:
+                # Return result as original order, not the future object
+                list_results = executor.map(partial(self.get_target_wrapper, counted=False), pos_list)
+                for idx, target in enumerate(list_results):
+                    pop[idx][self.ID_TAR] = target
+        elif self.mode == "process":
+            with parallel.ProcessPoolExecutor(self.n_workers) as executor:
+                # Return result as original order, not the future object
+                list_results = executor.map(partial(self.get_target_wrapper, counted=False), pos_list)
+                for idx, target in enumerate(list_results):
+                    pop[idx][self.ID_TAR] = target
+        elif self.mode == "swarm":
+            for idx, pos in enumerate(pos_list):
+                pop[idx][self.ID_TAR] = self.get_target_wrapper(pos, counted=False)
+        else:
+            return pop
+        self.nfe_counter += len(pop)
+        return pop
+
+    def get_global_best_solution(self, pop: list):
+        """
+        Sort population and return the sorted population and the best solution
+
+        Args:
+            pop (list): The population of pop_size individuals
+
+        Returns:
+            Sorted population and global best solution
+        """
+        sorted_pop = sorted(pop, key=lambda agent: agent[self.ID_TAR][self.ID_FIT])  # Already returned a new sorted list
+        if self.problem.minmax == "min":
+            return sorted_pop, deepcopy(sorted_pop[0])
+        else:
+            return sorted_pop, deepcopy(sorted_pop[-1])
+
+    def get_better_solution(self, agent1: list, agent2: list, reverse=False):
+        """
+        Args:
+            agent1 (list): A solution
+            agent2 (list): Another solution
+            reverse (bool): Transform this function to get_worse_solution if reverse=True, default=False
+
+        Returns:
+            The better solution between them
+        """
+        if self.problem.minmax == "min":
+            if agent1[self.ID_TAR][self.ID_FIT] < agent2[self.ID_TAR][self.ID_FIT]:
+                return deepcopy(agent1) if reverse is False else deepcopy(agent2)
+            return deepcopy(agent2) if reverse is False else deepcopy(agent1)
+        else:
+            if agent1[self.ID_TAR][self.ID_FIT] < agent2[self.ID_TAR][self.ID_FIT]:
+                return deepcopy(agent2) if reverse is False else deepcopy(agent1)
+            return deepcopy(agent1) if reverse is False else deepcopy(agent2)
+
+    def compare_agent(self, agent_new: list, agent_old: list):
+        """
+        Args:
+            agent_new (list): The new solution
+            agent_old (list): The old solution
+
+        Returns:
+            boolean: Return True if the new solution is better than the old one and otherwise
+        """
+        if self.problem.minmax == "min":
+            if agent_new[self.ID_TAR][self.ID_FIT] < agent_old[self.ID_TAR][self.ID_FIT]:
+                return True
+            return False
+        else:
+            if agent_new[self.ID_TAR][self.ID_FIT] < agent_old[self.ID_TAR][self.ID_FIT]:
+                return False
+            return True
+
+    def get_special_solutions(self, pop=None, best=3, worst=3):
+        """
+        Args:
+            pop (list): The population
+            best (int): Top k1 best solutions, default k1=3, good level reduction
+            worst (int): Top k2 worst solutions, default k2=3, worst level reduction
+
+        Returns:
+            list: sorted_population, k1 best solutions and k2 worst solutions
+        """
+        if self.problem.minmax == "min":
+            pop = sorted(pop, key=lambda agent: agent[self.ID_TAR][self.ID_FIT])
+        else:
+            pop = sorted(pop, key=lambda agent: agent[self.ID_TAR][self.ID_FIT], reverse=True)
+        if best is None:
+            if worst is None:
+                raise ValueError("Best and Worst can not be None in get_special_solutions function!")
+            else:
+                return pop, None, deepcopy(pop[::-1][:worst])
+        else:
+            if worst is None:
+                return pop, deepcopy(pop[:best]), None
+            else:
+                return pop, deepcopy(pop[:best]), deepcopy(pop[::-1][:worst])
+
+    def get_special_fitness(self, pop=None):
+        """
+        Args:
+            pop (list): The population
+
+        Returns:
+            list: Total fitness, best fitness, worst fitness
+        """
+        total_fitness = np.sum([agent[self.ID_TAR][self.ID_FIT] for agent in pop])
+        if self.problem.minmax == "min":
+            pop = sorted(pop, key=lambda agent: agent[self.ID_TAR][self.ID_FIT])
+        else:
+            pop = sorted(pop, key=lambda agent: agent[self.ID_TAR][self.ID_FIT], reverse=True)
+        return total_fitness, pop[0][self.ID_TAR][self.ID_FIT], pop[-1][self.ID_TAR][self.ID_FIT]
+
+    def update_global_best_solution(self, pop=None, save=True):
+        """
+        Update global best and current best solutions in history object.
+        Also update global worst and current worst solutions in history object.
+
+        Args:
+            pop (list): The population of pop_size individuals
+            save (bool): True if you want to add new current/global best to history, False if you just want to update current/global best
+
+        Returns:
+            list: Sorted population and the global best solution
+        """
+        if self.problem.minmax == "min":
+            sorted_pop = sorted(pop, key=lambda agent: agent[self.ID_TAR][self.ID_FIT])
+        else:
+            sorted_pop = sorted(pop, key=lambda agent: agent[self.ID_TAR][self.ID_FIT], reverse=True)
+        current_best = sorted_pop[0]
+        current_worst = sorted_pop[-1]
+        if save:
+            ## Save current best
+            self.history.list_current_best.append(current_best)
+            better = self.get_better_solution(current_best, self.history.list_global_best[-1])
+            self.history.list_global_best.append(better)
+            ## Save current worst
+            self.history.list_current_worst.append(current_worst)
+            worse = self.get_better_solution(current_worst, self.history.list_global_worst[-1], reverse=True)
+            self.history.list_global_worst.append(worse)
+            return deepcopy(sorted_pop), deepcopy(better)
+        else:
+            ## Handle current best
+            local_better = self.get_better_solution(current_best, self.history.list_current_best[-1])
+            self.history.list_current_best[-1] = local_better
+            global_better = self.get_better_solution(current_best, self.history.list_global_best[-1])
+            self.history.list_global_best[-1] = global_better
+            ## Handle current worst
+            local_worst = self.get_better_solution(current_worst, self.history.list_current_worst[-1], reverse=True)
+            self.history.list_current_worst[-1] = local_worst
+            global_worst = self.get_better_solution(current_worst, self.history.list_global_worst[-1], reverse=True)
+            self.history.list_global_worst[-1] = global_worst
+            return deepcopy(sorted_pop), deepcopy(global_better)
+
+    def get_index_best(self, pop):
+        fit_list = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in pop])
+        if self.problem.minmax == "min":
+            return np.argmin(fit_list)
+        else:
+            return np.argmax(fit_list)
+
+    ## Selection techniques
+    def get_index_roulette_wheel_selection(self, list_fitness: np.array):
+        """
+        This method can handle min/max problem, and negative or positive fitness value.
+
+        Args:
+            list_fitness (nd.array): 1-D numpy array
+
+        Returns:
+            int: Index of selected solution
+        """
+        if type(list_fitness) in [list, tuple, np.ndarray]:
+            list_fitness = np.array(list_fitness).flatten()
+        if list_fitness.ptp() == 0:
+            return int(np.random.randint(0, len(list_fitness)))
+        if np.any(list_fitness) < 0:
+            list_fitness = list_fitness - np.min(list_fitness)
+        final_fitness = list_fitness
+        if self.problem.minmax == "min":
+            final_fitness = np.max(list_fitness) - list_fitness
+        prob = final_fitness / np.sum(final_fitness)
+        return int(np.random.choice(range(0, len(list_fitness)), p=prob))
+
+    def get_index_kway_tournament_selection(self, pop=None, k_way=0.2, output=2, reverse=False):
+        """
+        Args:
+            pop: The population
+            k_way (float/int): The percent or number of solutions are randomized pick
+            output (int): The number of outputs
+            reverse (bool): set True when finding the worst fitness
+
+        Returns:
+            list: List of the selected indexes
+        """
+        if 0 < k_way < 1:
+            k_way = int(k_way * len(pop))
+        list_id = np.random.choice(range(len(pop)), k_way, replace=False)
+        list_parents = [[idx, pop[idx][self.ID_TAR][self.ID_FIT]] for idx in list_id]
+        if self.problem.minmax == "min":
+            list_parents = sorted(list_parents, key=lambda agent: agent[1])
+        else:
+            list_parents = sorted(list_parents, key=lambda agent: agent[1], reverse=True)
+        if reverse:
+            return [parent[0] for parent in list_parents[-output:]]
+        return [parent[0] for parent in list_parents[:output]]
+
+    def get_levy_flight_step(self, beta=1.0, multiplier=0.001, size=None, case=0):
+        """
+        Get the Levy-flight step size
+
+        Args:
+            beta (float): Should be in range [0, 2].
+
+                * 0-1: small range --> exploit
+                * 1-2: large range --> explore
+
+            multiplier (float): default = 0.001
+            size (tuple, list): size of levy-flight steps, for example: (3, 2), 5, (4, )
+            case (int): Should be one of these value [0, 1, -1].
+
+                * 0: return multiplier * s * np.random.uniform()
+                * 1: return multiplier * s * np.random.normal(0, 1)
+                * -1: return multiplier * s
+
+        Returns:
+            int: The step size of Levy-flight trajectory
+        """
+        # u and v are two random variables which follow np.random.normal distribution
+        # sigma_u : standard deviation of u
+        sigma_u = np.power(gamma(1 + beta) * np.sin(np.pi * beta / 2) / (gamma((1 + beta) / 2) * beta * np.power(2, (beta - 1) / 2)), 1 / beta)
+        # sigma_v : standard deviation of v
+        sigma_v = 1
+        size = 1 if size is None else size
+        u = np.random.normal(0, sigma_u ** 2, size)
+        v = np.random.normal(0, sigma_v ** 2, size)
+        s = u / np.power(np.abs(v), 1 / beta)
+        if case == 0:
+            step = multiplier * s * np.random.uniform()
+        elif case == 1:
+            step = multiplier * s * np.random.normal(0, 1)
+        else:
+            step = multiplier * s
+        return step[0] if size == 1 else step
+
+    ### Survivor Selection
+    def greedy_selection_population(self, pop_old=None, pop_new=None):
+        """
+        Args:
+            pop_old (list): The current population
+            pop_new (list): The next population
+
+        Returns:
+            The new population with better solutions
+        """
+        len_old, len_new = len(pop_old), len(pop_new)
+        if len_old != len_new:
+            raise ValueError("Greedy selection of two population with different length.")
+        if self.problem.minmax == "min":
+            return [pop_new[i] if pop_new[i][self.ID_TAR][self.ID_FIT] < pop_old[i][self.ID_TAR][self.ID_FIT]
+                    else pop_old[i] for i in range(len_old)]
+        else:
+            return [pop_new[i] if pop_new[i][self.ID_TAR] > pop_old[i][self.ID_TAR]
+                    else pop_old[i] for i in range(len_old)]
+
+    def get_sorted_strim_population(self, pop=None, pop_size=None, reverse=False):
+        """
+        Args:
+            pop (list): The population
+            pop_size (int): The number of population
+            reverse (bool): False (ascending fitness order), and True (descending fitness order)
+
+        Returns:
+            The sorted population with pop_size size
+        """
+        if self.problem.minmax == "min":
+            pop = sorted(pop, key=lambda agent: agent[self.ID_TAR][self.ID_FIT], reverse=reverse)
+        else:
+            pop = sorted(pop, key=lambda agent: agent[self.ID_TAR][self.ID_FIT], reverse=reverse)
+        return pop[:pop_size]
+
+    def create_opposition_position(self, agent=None, g_best=None):
+        """
+        Args:
+            agent: The current solution (agent)
+            g_best: the global best solution (agent)
+
+        Returns:
+            The opposite position
+        """
+        return self.problem.lb + self.problem.ub - g_best[self.ID_POS] + np.random.uniform() * (g_best[self.ID_POS] - agent[self.ID_POS])
+
+    def create_pop_group(self, pop, n_groups, m_agents):
+        pop_group = []
+        for i in range(0, n_groups):
+            group = pop[i * m_agents: (i + 1) * m_agents]
+            pop_group.append(deepcopy(group))
+        return pop_group
+
+    ### Crossover
+    def crossover_arithmetic(self, dad_pos=None, mom_pos=None):
+        """
+        Args:
+            dad_pos: position of dad
+            mom_pos: position of mom
+
+        Returns:
+            list: position of 1st and 2nd child
+        """
+        r = np.random.uniform()  # w1 = w2 when r =0.5
+        w1 = np.multiply(r, dad_pos) + np.multiply((1 - r), mom_pos)
+        w2 = np.multiply(r, mom_pos) + np.multiply((1 - r), dad_pos)
+        return w1, w2
+
+    #### Improved techniques can be used in any algorithms: 1
+    ## Based on this paper: An efficient equilibrium optimizer with mutation strategy for numerical optimization (but still different)
+    ## This scheme used after the original and including 4 step:
+    ##  s1: sort population, take p1 = 1/2 best population for next round
+    ##  s2: do the mutation for p1, using greedy method to select the better solution
+    ##  s3: do the search mechanism for p1 (based on global best solution and the updated p1 above), to make p2 population
+    ##  s4: construct the new population for next generation
+    def improved_ms(self, pop=None, g_best=None):  ## m: mutation, s: search
+        pop_len = int(len(pop) / 2)
+        ## Sort the updated population based on fitness
+        pop = sorted(pop, key=lambda item: item[self.ID_TAR][self.ID_FIT])
+        pop_s1, pop_s2 = pop[:pop_len], pop[pop_len:]
+
+        ## Mutation scheme
+        pop_new = []
+        for i in range(0, pop_len):
+            agent = deepcopy(pop_s1[i])
+            pos_new = pop_s1[i][self.ID_POS] * (1 + np.random.normal(0, 1, self.problem.n_dims))
+            agent[self.ID_POS] = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append(agent)
+        pop_new = self.update_target_wrapper_population(pop_new)
+        pop_s1 = self.greedy_selection_population(pop_s1, pop_new)  ## Greedy method --> improved exploitation
+
+        ## Search Mechanism
+        pos_s1_list = [item[self.ID_POS] for item in pop_s1]
+        pos_s1_mean = np.mean(pos_s1_list, axis=0)
+        pop_new = []
+        for i in range(0, pop_len):
+            agent = deepcopy(pop_s2[i])
+            pos_new = (g_best[self.ID_POS] - pos_s1_mean) - np.random.random() * \
+                      (self.problem.lb + np.random.random() * (self.problem.ub - self.problem.lb))
+            agent[self.ID_POS] = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append(agent)
+        ## Keep the diversity of populatoin and still improved the exploration
+        pop_s2 = self.update_target_wrapper_population(pop_new)
+        pop_s2 = self.greedy_selection_population(pop_s2, pop_new)
+
+        ## Construct a new population
+        pop = pop_s1 + pop_s2
+        return pop
```

### Comparing `mealpy-2.5.3/mealpy/physics_based/ASO.py` & `mealpy-2.5.3a1/mealpy/physics_based/ASO.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,185 +1,185 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 07:03, 18/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalASO(Optimizer):
-    """
-    The original version of: Atom Search Optimization (ASO)
-
-    Links:
-        1. https://doi.org/10.1016/j.knosys.2018.08.030
-        2. https://www.mathworks.com/matlabcentral/fileexchange/67011-atom-search-optimization-aso-algorithm
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + alpha (int): Depth weight, default = 10, depend on the problem
-        + beta (float): Multiplier weight, default = 0.2
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.physics_based.ASO import OriginalASO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> alpha = 50
-    >>> beta = 0.2
-    >>> model = OriginalASO(epoch, pop_size, alpha, beta)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Zhao, W., Wang, L. and Zhang, Z., 2019. Atom search optimization and its application to solve a
-    hydrogeologic parameter estimation problem. Knowledge-Based Systems, 163, pp.283-304.
-    """
-
-    ID_POS = 0
-    ID_TAR = 1
-    ID_VEL = 2  # Velocity
-    ID_MAS = 3  # Mass of atom
-
-    def __init__(self, epoch=10000, pop_size=100, alpha=10, beta=0.2, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            alpha (int): [2, 20], Depth weight, default = 10
-            beta (float): [0.1, 1.0], Multiplier weight, default = 0.2
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.alpha = self.validator.check_int("alpha", alpha, [1, 100])
-        self.beta = self.validator.check_float("beta", beta, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "alpha", "beta"])
-        self.sort_flag = False
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        """
-        Overriding method in Optimizer class
-
-        Returns:
-            list: wrapper of solution with format [position, target, velocity, mass]
-        """
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        position = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(position)
-        velocity = self.generate_position(lb, ub)
-        mass = 0.0
-        return [position, target, velocity, mass]
-
-    def amend_position(self, position=None, lb=None, ub=None):
-        """
-        Args:
-            position: vector position (location) of the solution.
-            lb: list of lower bound values
-            ub: list of upper bound values
-
-        Returns:
-            Amended position (make the position is in bound)
-        """
-        condition = np.logical_and(lb <= position, position <= ub)
-        rand_pos = np.random.uniform(lb, ub)
-        return np.where(condition, position, rand_pos)
-
-    def update_mass__(self, population):
-        list_fit = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in population])
-        list_fit = np.exp(-(list_fit - np.max(list_fit)) / (np.max(list_fit) - np.min(list_fit) + self.EPSILON))
-        list_fit = list_fit / np.sum(list_fit)
-        for idx in range(0, self.pop_size):
-            population[idx][self.ID_MAS] = list_fit[idx]
-        return population
-
-    def find_LJ_potential__(self, iteration, average_dist, radius):
-        c = (1 - iteration / self.epoch) ** 3
-        # g0 = 1.1, u = 2.4
-        rsmin = 1.1 + 0.1 * np.sin((iteration + 1) / self.epoch * np.pi / 2)
-        rsmax = 1.24
-        if radius / average_dist < rsmin:
-            rs = rsmin
-        else:
-            if radius / average_dist > rsmax:
-                rs = rsmax
-            else:
-                rs = radius / average_dist
-        potential = c * (12 * (-rs) ** (-13) - 6 * (-rs) ** (-7))
-        return potential
-
-    def acceleration__(self, population, g_best, iteration):
-        eps = 2 ** (-52)
-        pop = self.update_mass__(population)
-
-        G = np.exp(-20.0 * (iteration + 1) / self.epoch)
-        k_best = int(self.pop_size - (self.pop_size - 2) * ((iteration + 1) / self.epoch) ** 0.5) + 1
-        if self.problem.minmax == "min":
-            k_best_pop = deepcopy(sorted(pop, key=lambda agent: agent[self.ID_MAS], reverse=True)[:k_best])
-        else:
-            k_best_pop = deepcopy(sorted(pop, key=lambda agent: agent[self.ID_MAS])[:k_best])
-        mk_average = np.mean([item[self.ID_POS] for item in k_best_pop])
-
-        acc_list = np.zeros((self.pop_size, self.problem.n_dims))
-        for i in range(0, self.pop_size):
-            dist_average = np.linalg.norm(pop[i][self.ID_POS] - mk_average)
-            temp = np.zeros((self.problem.n_dims))
-
-            for atom in k_best_pop:
-                # calculate LJ-potential
-                radius = np.linalg.norm(pop[i][self.ID_POS] - atom[self.ID_POS])
-                potential = self.find_LJ_potential__(iteration, dist_average, radius)
-                temp += potential * np.random.uniform(0, 1, self.problem.n_dims) * ((atom[self.ID_POS] - pop[i][self.ID_POS]) / (radius + eps))
-            temp = self.alpha * temp + self.beta * (g_best[self.ID_POS] - pop[i][self.ID_POS])
-            # calculate acceleration
-            acc = G * temp / pop[i][self.ID_MAS]
-            acc_list[i] = acc
-        return acc_list
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # Calculate acceleration.
-        atom_acc_list = self.acceleration__(self.pop, self.g_best, iteration=epoch)
-
-        # Update velocity based on random dimensions and position of global best
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            agent = deepcopy(self.pop[idx])
-            velocity = np.random.random(self.problem.n_dims) * self.pop[idx][self.ID_VEL] + atom_acc_list[idx]
-            # print(velocity)
-            pos_new = self.pop[idx][self.ID_POS] + velocity
-            # Relocate atom out of range
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            # print(pos_new)
-            agent[self.ID_POS] = pos_new
-            pop_new.append(agent)
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                agent[self.ID_TAR] = target
-                self.pop[idx] = self.get_better_solution(agent, self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-        _, current_best = self.get_global_best_solution(pop_new)
-        if self.compare_agent(self.g_best, current_best):
-            self.pop[np.random.randint(0, self.pop_size)] = deepcopy(self.g_best)
+#!/usr/bin/env python
+# Created by "Thieu" at 07:03, 18/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalASO(Optimizer):
+    """
+    The original version of: Atom Search Optimization (ASO)
+
+    Links:
+        1. https://doi.org/10.1016/j.knosys.2018.08.030
+        2. https://www.mathworks.com/matlabcentral/fileexchange/67011-atom-search-optimization-aso-algorithm
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + alpha (int): Depth weight, default = 10, depend on the problem
+        + beta (float): Multiplier weight, default = 0.2
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.physics_based.ASO import OriginalASO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> alpha = 50
+    >>> beta = 0.2
+    >>> model = OriginalASO(epoch, pop_size, alpha, beta)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Zhao, W., Wang, L. and Zhang, Z., 2019. Atom search optimization and its application to solve a
+    hydrogeologic parameter estimation problem. Knowledge-Based Systems, 163, pp.283-304.
+    """
+
+    ID_POS = 0
+    ID_TAR = 1
+    ID_VEL = 2  # Velocity
+    ID_MAS = 3  # Mass of atom
+
+    def __init__(self, epoch=10000, pop_size=100, alpha=10, beta=0.2, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            alpha (int): [2, 20], Depth weight, default = 10
+            beta (float): [0.1, 1.0], Multiplier weight, default = 0.2
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.alpha = self.validator.check_int("alpha", alpha, [1, 100])
+        self.beta = self.validator.check_float("beta", beta, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "alpha", "beta"])
+        self.sort_flag = False
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        """
+        Overriding method in Optimizer class
+
+        Returns:
+            list: wrapper of solution with format [position, target, velocity, mass]
+        """
+        if pos is None:
+            pos = self.generate_position(lb, ub)
+        position = self.amend_position(pos, lb, ub)
+        target = self.get_target_wrapper(position)
+        velocity = self.generate_position(lb, ub)
+        mass = 0.0
+        return [position, target, velocity, mass]
+
+    def amend_position(self, position=None, lb=None, ub=None):
+        """
+        Args:
+            position: vector position (location) of the solution.
+            lb: list of lower bound values
+            ub: list of upper bound values
+
+        Returns:
+            Amended position (make the position is in bound)
+        """
+        condition = np.logical_and(lb <= position, position <= ub)
+        rand_pos = np.random.uniform(lb, ub)
+        return np.where(condition, position, rand_pos)
+
+    def update_mass__(self, population):
+        list_fit = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in population])
+        list_fit = np.exp(-(list_fit - np.max(list_fit)) / (np.max(list_fit) - np.min(list_fit) + self.EPSILON))
+        list_fit = list_fit / np.sum(list_fit)
+        for idx in range(0, self.pop_size):
+            population[idx][self.ID_MAS] = list_fit[idx]
+        return population
+
+    def find_LJ_potential__(self, iteration, average_dist, radius):
+        c = (1 - iteration / self.epoch) ** 3
+        # g0 = 1.1, u = 2.4
+        rsmin = 1.1 + 0.1 * np.sin((iteration + 1) / self.epoch * np.pi / 2)
+        rsmax = 1.24
+        if radius / average_dist < rsmin:
+            rs = rsmin
+        else:
+            if radius / average_dist > rsmax:
+                rs = rsmax
+            else:
+                rs = radius / average_dist
+        potential = c * (12 * (-rs) ** (-13) - 6 * (-rs) ** (-7))
+        return potential
+
+    def acceleration__(self, population, g_best, iteration):
+        eps = 2 ** (-52)
+        pop = self.update_mass__(population)
+
+        G = np.exp(-20.0 * (iteration + 1) / self.epoch)
+        k_best = int(self.pop_size - (self.pop_size - 2) * ((iteration + 1) / self.epoch) ** 0.5) + 1
+        if self.problem.minmax == "min":
+            k_best_pop = deepcopy(sorted(pop, key=lambda agent: agent[self.ID_MAS], reverse=True)[:k_best])
+        else:
+            k_best_pop = deepcopy(sorted(pop, key=lambda agent: agent[self.ID_MAS])[:k_best])
+        mk_average = np.mean([item[self.ID_POS] for item in k_best_pop])
+
+        acc_list = np.zeros((self.pop_size, self.problem.n_dims))
+        for i in range(0, self.pop_size):
+            dist_average = np.linalg.norm(pop[i][self.ID_POS] - mk_average)
+            temp = np.zeros((self.problem.n_dims))
+
+            for atom in k_best_pop:
+                # calculate LJ-potential
+                radius = np.linalg.norm(pop[i][self.ID_POS] - atom[self.ID_POS])
+                potential = self.find_LJ_potential__(iteration, dist_average, radius)
+                temp += potential * np.random.uniform(0, 1, self.problem.n_dims) * ((atom[self.ID_POS] - pop[i][self.ID_POS]) / (radius + eps))
+            temp = self.alpha * temp + self.beta * (g_best[self.ID_POS] - pop[i][self.ID_POS])
+            # calculate acceleration
+            acc = G * temp / pop[i][self.ID_MAS]
+            acc_list[i] = acc
+        return acc_list
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # Calculate acceleration.
+        atom_acc_list = self.acceleration__(self.pop, self.g_best, iteration=epoch)
+
+        # Update velocity based on random dimensions and position of global best
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            agent = deepcopy(self.pop[idx])
+            velocity = np.random.random(self.problem.n_dims) * self.pop[idx][self.ID_VEL] + atom_acc_list[idx]
+            # print(velocity)
+            pos_new = self.pop[idx][self.ID_POS] + velocity
+            # Relocate atom out of range
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            # print(pos_new)
+            agent[self.ID_POS] = pos_new
+            pop_new.append(agent)
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                agent[self.ID_TAR] = target
+                self.pop[idx] = self.get_better_solution(agent, self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+        _, current_best = self.get_global_best_solution(pop_new)
+        if self.compare_agent(self.g_best, current_best):
+            self.pop[np.random.randint(0, self.pop_size)] = deepcopy(self.g_best)
```

### Comparing `mealpy-2.5.3/mealpy/physics_based/ArchOA.py` & `mealpy-2.5.3a1/mealpy/physics_based/ArchOA.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,161 +1,161 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 16:10, 08/07/2021 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalArchOA(Optimizer):
-    """
-    The original version of: Archimedes Optimization Algorithm (ArchOA)
-
-    Links:
-        1. https://doi.org/10.1007/s10489-020-01893-z
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + c1 (int): factor, default belongs to [1, 2]
-        + c2 (int): factor, Default belongs to [2, 4, 6]
-        + c3 (int): factor, Default belongs to [1, 2]
-        + c4 (float): factor, Default belongs to [0.5, 1]
-        + acc_max (float): acceleration max, Default 0.9
-        + acc_min (float): acceleration min, Default 0.1
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.physics_based.ArchOA import OriginalArchOA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> c1 = 2
-    >>> c2 = 5
-    >>> c3 = 2
-    >>> c4 = 0.5
-    >>> acc_max = 0.9
-    >>> acc_min = 0.1
-    >>> model = OriginalArchOA(epoch, pop_size, c1, c2, c3, c4, acc_max, acc_min)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Hashim, F.A., Hussain, K., Houssein, E.H., Mabrouk, M.S. and Al-Atabany, W., 2021. Archimedes optimization
-    algorithm: a new metaheuristic algorithm for solving optimization problems. Applied Intelligence, 51(3), pp.1531-1551.
-    """
-
-    ID_POS = 0
-    ID_TAR = 1
-    ID_DEN = 2  # Density
-    ID_VOL = 3  # Volume
-    ID_ACC = 4  # Acceleration
-
-    def __init__(self, epoch=10000, pop_size=100, c1=2, c2=6, c3=2, c4=0.5, acc_max=0.9, acc_min=0.1, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            c1 (int): factor, default belongs [1, 2]
-            c2 (int): factor, Default belongs [2, 4, 6]
-            c3 (int): factor, Default belongs [1, 2]
-            c4 (float): factor, Default belongs [0.5, 1]
-            acc_max (float): acceleration max, Default 0.9
-            acc_min (float): acceleration min, Default 0.1
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.c1 = self.validator.check_int("c1", c1, [1, 3])
-        self.c2 = self.validator.check_int("c2", c2, [2, 6])
-        self.c3 = self.validator.check_int("c3", c3, [1, 3])
-        self.c4 = self.validator.check_float("c4", c4, (0, 1.0))
-        self.acc_max = self.validator.check_float("acc_max", acc_max, (0.3, 1.0))
-        self.acc_min = self.validator.check_float("acc_min", acc_min, (0, 0.3))
-        self.set_parameters(["epoch", "pop_size", "c1", "c2", "c3", "c4", "acc_max", "acc_min"])
-        self.sort_flag = False
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        """
-        Overriding method in Optimizer class
-
-        Returns:
-            list: wrapper of solution with format [position, target, density, volume, acceleration]
-        """
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        position = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(position)
-        den = np.random.uniform(lb, ub)
-        vol = np.random.uniform(lb, ub)
-        acc = lb + np.random.uniform(lb, ub) * (ub - lb)
-        return [position, target, den, vol, acc]
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        ## Transfer operator Eq. 8
-        tf = np.exp((epoch + 1) / self.epoch - 1)
-        ## Density decreasing factor Eq. 9
-        ddf = np.exp(1 - (epoch + 1) / self.epoch) - (epoch + 1) / self.epoch
-
-        list_acc = []
-        ## Calculate new density, volume and acceleration
-        for i in range(0, self.pop_size):
-            # Update density and volume of each object using Eq. 7
-            new_den = self.pop[i][self.ID_DEN] + np.random.uniform() * (self.g_best[self.ID_DEN] - self.pop[i][self.ID_DEN])
-            new_vol = self.pop[i][self.ID_VOL] + np.random.uniform() * (self.g_best[self.ID_VOL] - self.pop[i][self.ID_VOL])
-            # Exploration phase
-            if tf <= 0.5:
-                # Update acceleration using Eq. 10 and normalize acceleration using Eq. 12
-                id_rand = np.random.choice(list(set(range(0, self.pop_size)) - {i}))
-                new_acc = (self.pop[id_rand][self.ID_DEN] + self.pop[id_rand][self.ID_VOL] * self.pop[id_rand][self.ID_ACC]) / (new_den * new_vol)
-            else:
-                new_acc = (self.g_best[self.ID_DEN] + self.g_best[self.ID_VOL] * self.g_best[self.ID_ACC]) / (new_den * new_vol)
-            list_acc.append(new_acc)
-            self.pop[i][self.ID_DEN] = new_den
-            self.pop[i][self.ID_VOL] = new_vol
-        min_acc = np.min(list_acc)
-        max_acc = np.max(list_acc)
-        ## Normalize acceleration using Eq. 12
-        for i in range(0, self.pop_size):
-            self.pop[i][self.ID_ACC] = self.acc_max * (list_acc[i] - min_acc) / (max_acc - min_acc) + self.acc_min
-
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            solution = deepcopy(self.pop[idx])
-            if tf <= 0.5:  # update position using Eq. 13
-                id_rand = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
-                pos_new = self.pop[idx][self.ID_POS] + self.c1 * np.random.uniform() * \
-                          self.pop[idx][self.ID_ACC] * ddf * (self.pop[id_rand][self.ID_POS] - self.pop[idx][self.ID_POS])
-            else:
-                p = 2 * np.random.rand() - self.c4
-                f = 1 if p <= 0.5 else -1
-                t = self.c3 * tf
-                pos_new = self.g_best[self.ID_POS] + f * self.c2 * np.random.rand() * self.pop[idx][self.ID_ACC] * \
-                          ddf * (t * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            solution[self.ID_POS] = pos_new
-            pop_new.append(solution)
-            if self.mode not in self.AVAILABLE_MODES:
-                solution[self.ID_TAR] = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution(solution, self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 16:10, 08/07/2021 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalArchOA(Optimizer):
+    """
+    The original version of: Archimedes Optimization Algorithm (ArchOA)
+
+    Links:
+        1. https://doi.org/10.1007/s10489-020-01893-z
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + c1 (int): factor, default belongs to [1, 2]
+        + c2 (int): factor, Default belongs to [2, 4, 6]
+        + c3 (int): factor, Default belongs to [1, 2]
+        + c4 (float): factor, Default belongs to [0.5, 1]
+        + acc_max (float): acceleration max, Default 0.9
+        + acc_min (float): acceleration min, Default 0.1
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.physics_based.ArchOA import OriginalArchOA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> c1 = 2
+    >>> c2 = 5
+    >>> c3 = 2
+    >>> c4 = 0.5
+    >>> acc_max = 0.9
+    >>> acc_min = 0.1
+    >>> model = OriginalArchOA(epoch, pop_size, c1, c2, c3, c4, acc_max, acc_min)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Hashim, F.A., Hussain, K., Houssein, E.H., Mabrouk, M.S. and Al-Atabany, W., 2021. Archimedes optimization
+    algorithm: a new metaheuristic algorithm for solving optimization problems. Applied Intelligence, 51(3), pp.1531-1551.
+    """
+
+    ID_POS = 0
+    ID_TAR = 1
+    ID_DEN = 2  # Density
+    ID_VOL = 3  # Volume
+    ID_ACC = 4  # Acceleration
+
+    def __init__(self, epoch=10000, pop_size=100, c1=2, c2=6, c3=2, c4=0.5, acc_max=0.9, acc_min=0.1, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            c1 (int): factor, default belongs [1, 2]
+            c2 (int): factor, Default belongs [2, 4, 6]
+            c3 (int): factor, Default belongs [1, 2]
+            c4 (float): factor, Default belongs [0.5, 1]
+            acc_max (float): acceleration max, Default 0.9
+            acc_min (float): acceleration min, Default 0.1
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.c1 = self.validator.check_int("c1", c1, [1, 3])
+        self.c2 = self.validator.check_int("c2", c2, [2, 6])
+        self.c3 = self.validator.check_int("c3", c3, [1, 3])
+        self.c4 = self.validator.check_float("c4", c4, (0, 1.0))
+        self.acc_max = self.validator.check_float("acc_max", acc_max, (0.3, 1.0))
+        self.acc_min = self.validator.check_float("acc_min", acc_min, (0, 0.3))
+        self.set_parameters(["epoch", "pop_size", "c1", "c2", "c3", "c4", "acc_max", "acc_min"])
+        self.sort_flag = False
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        """
+        Overriding method in Optimizer class
+
+        Returns:
+            list: wrapper of solution with format [position, target, density, volume, acceleration]
+        """
+        if pos is None:
+            pos = self.generate_position(lb, ub)
+        position = self.amend_position(pos, lb, ub)
+        target = self.get_target_wrapper(position)
+        den = np.random.uniform(lb, ub)
+        vol = np.random.uniform(lb, ub)
+        acc = lb + np.random.uniform(lb, ub) * (ub - lb)
+        return [position, target, den, vol, acc]
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        ## Transfer operator Eq. 8
+        tf = np.exp((epoch + 1) / self.epoch - 1)
+        ## Density decreasing factor Eq. 9
+        ddf = np.exp(1 - (epoch + 1) / self.epoch) - (epoch + 1) / self.epoch
+
+        list_acc = []
+        ## Calculate new density, volume and acceleration
+        for i in range(0, self.pop_size):
+            # Update density and volume of each object using Eq. 7
+            new_den = self.pop[i][self.ID_DEN] + np.random.uniform() * (self.g_best[self.ID_DEN] - self.pop[i][self.ID_DEN])
+            new_vol = self.pop[i][self.ID_VOL] + np.random.uniform() * (self.g_best[self.ID_VOL] - self.pop[i][self.ID_VOL])
+            # Exploration phase
+            if tf <= 0.5:
+                # Update acceleration using Eq. 10 and normalize acceleration using Eq. 12
+                id_rand = np.random.choice(list(set(range(0, self.pop_size)) - {i}))
+                new_acc = (self.pop[id_rand][self.ID_DEN] + self.pop[id_rand][self.ID_VOL] * self.pop[id_rand][self.ID_ACC]) / (new_den * new_vol)
+            else:
+                new_acc = (self.g_best[self.ID_DEN] + self.g_best[self.ID_VOL] * self.g_best[self.ID_ACC]) / (new_den * new_vol)
+            list_acc.append(new_acc)
+            self.pop[i][self.ID_DEN] = new_den
+            self.pop[i][self.ID_VOL] = new_vol
+        min_acc = np.min(list_acc)
+        max_acc = np.max(list_acc)
+        ## Normalize acceleration using Eq. 12
+        for i in range(0, self.pop_size):
+            self.pop[i][self.ID_ACC] = self.acc_max * (list_acc[i] - min_acc) / (max_acc - min_acc) + self.acc_min
+
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            solution = deepcopy(self.pop[idx])
+            if tf <= 0.5:  # update position using Eq. 13
+                id_rand = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
+                pos_new = self.pop[idx][self.ID_POS] + self.c1 * np.random.uniform() * \
+                          self.pop[idx][self.ID_ACC] * ddf * (self.pop[id_rand][self.ID_POS] - self.pop[idx][self.ID_POS])
+            else:
+                p = 2 * np.random.rand() - self.c4
+                f = 1 if p <= 0.5 else -1
+                t = self.c3 * tf
+                pos_new = self.g_best[self.ID_POS] + f * self.c2 * np.random.rand() * self.pop[idx][self.ID_ACC] * \
+                          ddf * (t * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            solution[self.ID_POS] = pos_new
+            pop_new.append(solution)
+            if self.mode not in self.AVAILABLE_MODES:
+                solution[self.ID_TAR] = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution(solution, self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/physics_based/CDO.py` & `mealpy-2.5.3a1/mealpy/swarm_based/PFA.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,100 +1,96 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 21:45, 13/03/2023 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalCDO(Optimizer):
-    """
-    The original version of: Chernobyl Disaster Optimizer (CDO)
-
-    Links:
-        1. https://link.springer.com/article/10.1007/s00521-023-08261-1
-        2. https://www.mathworks.com/matlabcentral/fileexchange/124351-chernobyl-disaster-optimizer-cdo
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.physics_based.CDO import OriginalCDO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalCDO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Shehadeh, H. A. (2023). Chernobyl disaster optimizer (CDO): a novel meta-heuristic method
-    for global optimization. Neural Computing and Applications, 1-17.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        _, (b1, b2, b3), _ = self.get_special_solutions(self.pop, best=3, worst=1)
-        a = 3 - (epoch+1)*3/self.epoch
-        a1 = np.log10((16000-1) * np.random.rand()+16000)
-        a2 = np.log10((270000-1)*np.random.rand() + 270000)
-        a3 = np.log10((300000-1)*np.random.rand() + 300000)
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            r1 = np.random.rand(self.problem.n_dims)
-            r2 = np.random.rand(self.problem.n_dims)
-            pa = np.pi * r1*r1 / (0.25 * a1) - a*np.random.rand(self.problem.n_dims)
-            c1 = r2 * r2 * np.pi
-            alpha = np.abs(c1*b1[self.ID_POS] - self.pop[idx][self.ID_POS])
-            pos_a = 0.25 * (b1[self.ID_POS] - pa * alpha)
-
-            r3 = np.random.rand(self.problem.n_dims)
-            r4 = np.random.rand(self.problem.n_dims)
-            pb = np.pi * r3 * r3 / (0.5 * a2) - a * np.random.rand(self.problem.n_dims)
-            c2 = r4 * r4 * np.pi
-            beta = np.abs(c2 * b2[self.ID_POS] - self.pop[idx][self.ID_POS])
-            pos_b = 0.5 * (b2[self.ID_POS] - pb * beta)
-
-            r5 = np.random.rand(self.problem.n_dims)
-            r6 = np.random.rand(self.problem.n_dims)
-            pc = np.pi * r5 * r5 / a3 - a * np.random.rand(self.problem.n_dims)
-            c3 = r6 * r6 * np.pi
-            gama = np.abs(c3 * b3[self.ID_POS] - self.pop[idx][self.ID_POS])
-            pos_c = b3[self.ID_POS] - pc * gama
-
-            pos_new = (pos_a + pos_b + pos_c) / 3
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-        self.pop = pop_new
+#!/usr/bin/env python
+# Created by "Thieu" at 14:51, 17/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalPFA(Optimizer):
+    """
+    The original version of: Pathfinder Algorithm (PFA)
+
+    Links:
+        1. https://doi.org/10.1016/j.asoc.2019.03.012
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.PFA import OriginalPFA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalPFA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Yapici, H. and Cetinkaya, N., 2019. A new meta-heuristic optimizer: Pathfinder algorithm.
+    Applied soft computing, 78, pp.545-568.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = True
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        alpha, beta = np.random.uniform(1, 2, 2)
+        A = np.random.uniform(self.problem.lb, self.problem.ub) * np.exp(-2 * (epoch + 1) / self.epoch)
+        t = 1 - (epoch + 1) * 1.0 / self.epoch
+        space = self.problem.ub - self.problem.lb
+
+        ## Update the position of pathfinder and check the bound
+        pos_new = self.pop[0][self.ID_POS] + 2 * np.random.uniform() * (self.g_best[self.ID_POS] - self.pop[0][self.ID_POS]) + A
+        pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+        target = self.get_target_wrapper(pos_new)
+        pop_new = [[pos_new, target], ]
+
+        ## Update positions of members, check the bound and calculate new fitness
+        for idx in range(1, self.pop_size):
+            agent = deepcopy(self.pop[idx])
+            pos_new = deepcopy(self.pop[idx][self.ID_POS]).astype(float)
+            for k in range(1, self.pop_size):
+                dist = np.sqrt(np.sum((self.pop[k][self.ID_POS] - self.pop[idx][self.ID_POS]) ** 2)) / self.problem.n_dims
+                t2 = alpha * np.random.uniform() * (self.pop[k][self.ID_POS] - self.pop[idx][self.ID_POS])
+                ## First stabilize the distance
+                t3 = np.random.uniform() * t * (dist / space)
+                pos_new += t2 + t3
+            ## Second stabilize the population size
+            t1 = beta * np.random.uniform() * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+            pos_new = (pos_new + t1) / self.pop_size
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            agent[self.ID_POS] = pos_new
+            pop_new.append(agent)
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+        self.pop = self.greedy_selection_population(self.pop, pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/physics_based/EFO.py` & `mealpy-2.5.3a1/mealpy/physics_based/EFO.py`

 * *Ordering differences only*

 * *Files 8% similar despite different names*

```diff
@@ -1,233 +1,233 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 21:19, 17/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class BaseEFO(Optimizer):
-    """
-    The developed version: Electromagnetic Field Optimization (EFO)
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + r_rate (float): [0.1, 0.6], default = 0.3, like mutation parameter in GA but for one variable
-        + ps_rate (float): [0.5, 0.95], default = 0.85, like crossover parameter in GA
-        + p_field (float): [0.05, 0.3], default = 0.1, portion of population, positive field
-        + n_field (float): [0.3, 0.7], default = 0.45, portion of population, negative field
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.physics_based.EFO import BaseEFO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> r_rate = 0.3
-    >>> ps_rate = 0.85
-    >>> p_field = 0.1
-    >>> n_field = 0.45
-    >>> model = BaseEFO(epoch, pop_size, r_rate, ps_rate, p_field, n_field)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, r_rate=0.3, ps_rate=0.85, p_field=0.1, n_field=0.45, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            r_rate (float): default = 0.3     Like mutation parameter in GA but for one variable
-            ps_rate (float): default = 0.85    Like crossover parameter in GA
-            p_field (float): default = 0.1     portion of population, positive field
-            n_field (float): default = 0.45    portion of population, negative field
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.r_rate = self.validator.check_float("r_rate", r_rate, (0, 1.0))
-        self.ps_rate = self.validator.check_float("ps_rate", ps_rate, (0, 1.0))
-        self.p_field = self.validator.check_float("p_field", p_field, (0, 1.0))
-        self.n_field = self.validator.check_float("n_field", n_field, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "r_rate", "ps_rate", "p_field", "n_field"])
-        self.phi = (1 + np.sqrt(5)) / 2  # golden ratio
-        self.sort_flag = True
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            r_idx1 = np.random.randint(0, int(self.pop_size * self.p_field))  # top
-            r_idx2 = np.random.randint(int(self.pop_size * (1 - self.n_field)), self.pop_size)  # bottom
-            r_idx3 = np.random.randint(int((self.pop_size * self.p_field) + 1), int(self.pop_size * (1 - self.n_field)))  # middle
-            if np.random.rand() < self.ps_rate:
-                # new = g_best + phi* r1 * (top - middle) + r2 (top - bottom)
-                # pos_new = g_best[self.ID_POS] + \
-                #            phi * np.random.uniform() * (pop[r_idx1][self.ID_POS] - pop[r_idx3][self.ID_POS]) + \
-                #            np.random.uniform() * (pop[r_idx1][self.ID_POS] - pop[r_idx2][self.ID_POS])
-                # new = top + phi * r1 * (g_best - bottom) + r2 * (g_best - middle)
-                pos_new = self.pop[r_idx1][self.ID_POS] + self.phi * np.random.rand() * (self.g_best[self.ID_POS] - self.pop[r_idx3][self.ID_POS]) \
-                          + np.random.rand() * (self.g_best[self.ID_POS] - self.pop[r_idx2][self.ID_POS])
-            else:
-                pos_new = self.generate_position(self.problem.lb, self.problem.ub)
-
-            # replacement of one electromagnet of generated particle with a random number
-            # (only for some generated particles) to bring diversity to the population
-            if np.random.rand() < self.r_rate:
-                RI = np.random.randint(0, self.problem.n_dims)
-                pos_new[np.random.randint(0, self.problem.n_dims)] = np.random.uniform(self.problem.lb[RI], self.problem.ub[RI])
-
-            # checking whether the generated number is inside boundary or not
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-
-class OriginalEFO(BaseEFO):
-    """
-    The original version of: Electromagnetic Field Optimization (EFO)
-
-    Links:
-        2. https://www.mathworks.com/matlabcentral/fileexchange/52744-electromagnetic-field-optimization-a-physics-inspired-metaheuristic-optimization-algorithm
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + r_rate (float): [0.1, 0.6], default = 0.3, like mutation parameter in GA but for one variable
-        + ps_rate (float): [0.5, 0.95], default = 0.85, like crossover parameter in GA
-        + p_field (float): [0.05, 0.3], default = 0.1, portion of population, positive field
-        + n_field (float): [0.3, 0.7], default = 0.45, portion of population, negative field
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.physics_based.EFO import OriginalEFO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> r_rate = 0.3
-    >>> ps_rate = 0.85
-    >>> p_field = 0.1
-    >>> n_field = 0.45
-    >>> model = OriginalEFO(epoch, pop_size, r_rate, ps_rate, p_field, n_field)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Abedinpourshotorban, H., Shamsuddin, S.M., Beheshti, Z. and Jawawi, D.N., 2016.
-    Electromagnetic field optimization: a physics-inspired metaheuristic optimization algorithm.
-    Swarm and Evolutionary Computation, 26, pp.8-22.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, r_rate=0.3, ps_rate=0.85, p_field=0.1, n_field=0.45, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            r_rate (float): default = 0.3     Like mutation parameter in GA but for one variable
-            ps_rate (float): default = 0.85    Like crossover parameter in GA
-            p_field (float): default = 0.1     portion of population, positive field
-            n_field (float): default = 0.45    portion of population, negative field
-        """
-        super().__init__(epoch, pop_size, r_rate, ps_rate, p_field, n_field, **kwargs)
-        self.support_parallel_modes = False
-
-    def amend_position(self, position=None, lb=None, ub=None):
-        """
-        Depend on what kind of problem are we trying to solve, there will be an different amend_position
-        function to rebound the position of agent into the valid range.
-
-        Args:
-            position: vector position (location) of the solution.
-            lb: list of lower bound values
-            ub: list of upper bound values
-
-        Returns:
-            Amended position (make the position is in bound)
-        """
-        return np.where(np.logical_and(lb <= position, position <= ub), position, np.random.uniform(lb, ub))
-
-    def initialization(self):
-        # %random vectors (this is to increase the calculation speed instead of determining the random values in each
-        # iteration we allocate them in the beginning before algorithm start
-        self.r_index1 = np.random.randint(0, int(self.pop_size * self.p_field), (self.problem.n_dims, self.epoch))
-        # random particles from positive field
-        self.r_index2 = np.random.randint(int(self.pop_size * (1 - self.n_field)), self.pop_size, (self.problem.n_dims, self.epoch))
-        # random particles from negative field
-        self.r_index3 = np.random.randint(int((self.pop_size * self.p_field) + 1), int(self.pop_size * (1 - self.n_field)), (self.problem.n_dims, self.epoch))
-        # random particles from neutral field
-        self.ps = np.random.uniform(0, 1, (self.problem.n_dims, self.epoch))
-        # Probability of selecting electromagnets of generated particle from the positive field
-        self.r_force = np.random.uniform(0, 1, self.epoch)
-        # random force in each generation
-        self.rp = np.random.uniform(0, 1, self.epoch)
-        # Some random numbers for checking randomness probability in each generation
-        self.randomization = np.random.uniform(0, 1, self.epoch)
-        # Coefficient of randomization when generated electro magnet is out of boundary
-        self.RI = 0
-        # index of the electromagnet (variable) which is going to be initialized by random number
-
-        if self.pop is None:
-            self.pop = self.create_population(self.pop_size)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        r = self.r_force[epoch]
-        x_new = np.zeros(self.problem.n_dims)  # temporary array to store generated particle
-        for i in range(0, self.problem.n_dims):
-            if self.ps[i, epoch] > self.ps_rate:
-                x_new[i] = self.pop[self.r_index3[i, epoch]][self.ID_POS][i] + \
-                           self.phi * r * (self.pop[self.r_index1[i, epoch]][self.ID_POS][i] - self.pop[self.r_index3[i, epoch]][self.ID_POS][i]) + \
-                           r * (self.pop[self.r_index3[i, epoch]][self.ID_POS][i] - self.pop[self.r_index2[i, epoch]][self.ID_POS][i])
-            else:
-                x_new[i] = self.pop[self.r_index1[i, epoch]][self.ID_POS][i]
-
-        # replacement of one electromagnet of generated particle with a random number (only for some generated particles) to bring diversity to the population
-        if self.rp[epoch] < self.r_rate:
-            x_new[self.RI] = self.problem.lb[self.RI] + (self.problem.ub[self.RI] - self.problem.lb[self.RI]) * self.randomization[epoch]
-            RI = self.RI + 1
-            if RI >= self.problem.n_dims:
-                self.RI = 0
-
-        # checking whether the generated number is inside boundary or not
-        pos_new = self.amend_position(x_new, self.problem.lb, self.problem.ub)
-        target = self.get_target_wrapper(pos_new)
-        # Updating the population if the fitness of the generated particle is better than worst fitness in
-        #     the population (because the population is sorted by fitness, the last particle is the worst)
-        self.pop[-1] = [pos_new, target]
+#!/usr/bin/env python
+# Created by "Thieu" at 21:19, 17/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class BaseEFO(Optimizer):
+    """
+    The developed version: Electromagnetic Field Optimization (EFO)
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + r_rate (float): [0.1, 0.6], default = 0.3, like mutation parameter in GA but for one variable
+        + ps_rate (float): [0.5, 0.95], default = 0.85, like crossover parameter in GA
+        + p_field (float): [0.05, 0.3], default = 0.1, portion of population, positive field
+        + n_field (float): [0.3, 0.7], default = 0.45, portion of population, negative field
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.physics_based.EFO import BaseEFO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> r_rate = 0.3
+    >>> ps_rate = 0.85
+    >>> p_field = 0.1
+    >>> n_field = 0.45
+    >>> model = BaseEFO(epoch, pop_size, r_rate, ps_rate, p_field, n_field)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, r_rate=0.3, ps_rate=0.85, p_field=0.1, n_field=0.45, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            r_rate (float): default = 0.3     Like mutation parameter in GA but for one variable
+            ps_rate (float): default = 0.85    Like crossover parameter in GA
+            p_field (float): default = 0.1     portion of population, positive field
+            n_field (float): default = 0.45    portion of population, negative field
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.r_rate = self.validator.check_float("r_rate", r_rate, (0, 1.0))
+        self.ps_rate = self.validator.check_float("ps_rate", ps_rate, (0, 1.0))
+        self.p_field = self.validator.check_float("p_field", p_field, (0, 1.0))
+        self.n_field = self.validator.check_float("n_field", n_field, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "r_rate", "ps_rate", "p_field", "n_field"])
+        self.phi = (1 + np.sqrt(5)) / 2  # golden ratio
+        self.sort_flag = True
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            r_idx1 = np.random.randint(0, int(self.pop_size * self.p_field))  # top
+            r_idx2 = np.random.randint(int(self.pop_size * (1 - self.n_field)), self.pop_size)  # bottom
+            r_idx3 = np.random.randint(int((self.pop_size * self.p_field) + 1), int(self.pop_size * (1 - self.n_field)))  # middle
+            if np.random.rand() < self.ps_rate:
+                # new = g_best + phi* r1 * (top - middle) + r2 (top - bottom)
+                # pos_new = g_best[self.ID_POS] + \
+                #            phi * np.random.uniform() * (pop[r_idx1][self.ID_POS] - pop[r_idx3][self.ID_POS]) + \
+                #            np.random.uniform() * (pop[r_idx1][self.ID_POS] - pop[r_idx2][self.ID_POS])
+                # new = top + phi * r1 * (g_best - bottom) + r2 * (g_best - middle)
+                pos_new = self.pop[r_idx1][self.ID_POS] + self.phi * np.random.rand() * (self.g_best[self.ID_POS] - self.pop[r_idx3][self.ID_POS]) \
+                          + np.random.rand() * (self.g_best[self.ID_POS] - self.pop[r_idx2][self.ID_POS])
+            else:
+                pos_new = self.generate_position(self.problem.lb, self.problem.ub)
+
+            # replacement of one electromagnet of generated particle with a random number
+            # (only for some generated particles) to bring diversity to the population
+            if np.random.rand() < self.r_rate:
+                RI = np.random.randint(0, self.problem.n_dims)
+                pos_new[np.random.randint(0, self.problem.n_dims)] = np.random.uniform(self.problem.lb[RI], self.problem.ub[RI])
+
+            # checking whether the generated number is inside boundary or not
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+
+class OriginalEFO(BaseEFO):
+    """
+    The original version of: Electromagnetic Field Optimization (EFO)
+
+    Links:
+        2. https://www.mathworks.com/matlabcentral/fileexchange/52744-electromagnetic-field-optimization-a-physics-inspired-metaheuristic-optimization-algorithm
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + r_rate (float): [0.1, 0.6], default = 0.3, like mutation parameter in GA but for one variable
+        + ps_rate (float): [0.5, 0.95], default = 0.85, like crossover parameter in GA
+        + p_field (float): [0.05, 0.3], default = 0.1, portion of population, positive field
+        + n_field (float): [0.3, 0.7], default = 0.45, portion of population, negative field
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.physics_based.EFO import OriginalEFO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> r_rate = 0.3
+    >>> ps_rate = 0.85
+    >>> p_field = 0.1
+    >>> n_field = 0.45
+    >>> model = OriginalEFO(epoch, pop_size, r_rate, ps_rate, p_field, n_field)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Abedinpourshotorban, H., Shamsuddin, S.M., Beheshti, Z. and Jawawi, D.N., 2016.
+    Electromagnetic field optimization: a physics-inspired metaheuristic optimization algorithm.
+    Swarm and Evolutionary Computation, 26, pp.8-22.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, r_rate=0.3, ps_rate=0.85, p_field=0.1, n_field=0.45, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            r_rate (float): default = 0.3     Like mutation parameter in GA but for one variable
+            ps_rate (float): default = 0.85    Like crossover parameter in GA
+            p_field (float): default = 0.1     portion of population, positive field
+            n_field (float): default = 0.45    portion of population, negative field
+        """
+        super().__init__(epoch, pop_size, r_rate, ps_rate, p_field, n_field, **kwargs)
+        self.support_parallel_modes = False
+
+    def amend_position(self, position=None, lb=None, ub=None):
+        """
+        Depend on what kind of problem are we trying to solve, there will be an different amend_position
+        function to rebound the position of agent into the valid range.
+
+        Args:
+            position: vector position (location) of the solution.
+            lb: list of lower bound values
+            ub: list of upper bound values
+
+        Returns:
+            Amended position (make the position is in bound)
+        """
+        return np.where(np.logical_and(lb <= position, position <= ub), position, np.random.uniform(lb, ub))
+
+    def initialization(self):
+        # %random vectors (this is to increase the calculation speed instead of determining the random values in each
+        # iteration we allocate them in the beginning before algorithm start
+        self.r_index1 = np.random.randint(0, int(self.pop_size * self.p_field), (self.problem.n_dims, self.epoch))
+        # random particles from positive field
+        self.r_index2 = np.random.randint(int(self.pop_size * (1 - self.n_field)), self.pop_size, (self.problem.n_dims, self.epoch))
+        # random particles from negative field
+        self.r_index3 = np.random.randint(int((self.pop_size * self.p_field) + 1), int(self.pop_size * (1 - self.n_field)), (self.problem.n_dims, self.epoch))
+        # random particles from neutral field
+        self.ps = np.random.uniform(0, 1, (self.problem.n_dims, self.epoch))
+        # Probability of selecting electromagnets of generated particle from the positive field
+        self.r_force = np.random.uniform(0, 1, self.epoch)
+        # random force in each generation
+        self.rp = np.random.uniform(0, 1, self.epoch)
+        # Some random numbers for checking randomness probability in each generation
+        self.randomization = np.random.uniform(0, 1, self.epoch)
+        # Coefficient of randomization when generated electro magnet is out of boundary
+        self.RI = 0
+        # index of the electromagnet (variable) which is going to be initialized by random number
+
+        if self.pop is None:
+            self.pop = self.create_population(self.pop_size)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        r = self.r_force[epoch]
+        x_new = np.zeros(self.problem.n_dims)  # temporary array to store generated particle
+        for i in range(0, self.problem.n_dims):
+            if self.ps[i, epoch] > self.ps_rate:
+                x_new[i] = self.pop[self.r_index3[i, epoch]][self.ID_POS][i] + \
+                           self.phi * r * (self.pop[self.r_index1[i, epoch]][self.ID_POS][i] - self.pop[self.r_index3[i, epoch]][self.ID_POS][i]) + \
+                           r * (self.pop[self.r_index3[i, epoch]][self.ID_POS][i] - self.pop[self.r_index2[i, epoch]][self.ID_POS][i])
+            else:
+                x_new[i] = self.pop[self.r_index1[i, epoch]][self.ID_POS][i]
+
+        # replacement of one electromagnet of generated particle with a random number (only for some generated particles) to bring diversity to the population
+        if self.rp[epoch] < self.r_rate:
+            x_new[self.RI] = self.problem.lb[self.RI] + (self.problem.ub[self.RI] - self.problem.lb[self.RI]) * self.randomization[epoch]
+            RI = self.RI + 1
+            if RI >= self.problem.n_dims:
+                self.RI = 0
+
+        # checking whether the generated number is inside boundary or not
+        pos_new = self.amend_position(x_new, self.problem.lb, self.problem.ub)
+        target = self.get_target_wrapper(pos_new)
+        # Updating the population if the fitness of the generated particle is better than worst fitness in
+        #     the population (because the population is sorted by fitness, the last particle is the worst)
+        self.pop[-1] = [pos_new, target]
```

### Comparing `mealpy-2.5.3/mealpy/physics_based/EO.py` & `mealpy-2.5.3a1/mealpy/physics_based/EO.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,309 +1,309 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 07:03, 18/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalEO(Optimizer):
-    """
-    The original version of: Equilibrium Optimizer (EO)
-
-    Links:
-        1. https://doi.org/10.1016/j.knosys.2019.105190
-        2. https://www.mathworks.com/matlabcentral/fileexchange/73352-equilibrium-optimizer-eo
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.physics_based.EO import OriginalEO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalEO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Faramarzi, A., Heidarinejad, M., Stephens, B. and Mirjalili, S., 2020. Equilibrium optimizer: A novel
-    optimization algorithm. Knowledge-Based Systems, 191, p.105190.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-        ## Fixed parameter proposed by authors
-        self.V = 1
-        self.a1 = 2
-        self.a2 = 1
-        self.GP = 0.5
-
-    def make_equilibrium_pool__(self, list_equilibrium=None):
-        pos_list = [item[self.ID_POS] for item in list_equilibrium]
-        pos_mean = np.mean(pos_list, axis=0)
-        pos_mean = self.amend_position(pos_mean, self.problem.lb, self.problem.ub)
-        target = self.get_target_wrapper(pos_mean)
-        list_equilibrium.append([pos_mean, target])
-        return list_equilibrium
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # ---------------- Memory saving-------------------  make equilibrium pool
-        _, c_eq_list, _ = self.get_special_solutions(self.pop, best=4)
-        c_pool = self.make_equilibrium_pool__(c_eq_list)
-        # Eq. 9
-        t = (1 - epoch / self.epoch) ** (self.a2 * epoch / self.epoch)
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            lamda = np.random.uniform(0, 1, self.problem.n_dims)  # lambda in Eq. 11
-            r = np.random.uniform(0, 1, self.problem.n_dims)  # r in Eq. 11
-            c_eq = c_pool[np.random.randint(0, len(c_pool))][self.ID_POS]  # random selection 1 of candidate from the pool
-            f = self.a1 * np.sign(r - 0.5) * (np.exp(-lamda * t) - 1.0)  # Eq. 11
-            r1 = np.random.uniform()
-            r2 = np.random.uniform()  # r1, r2 in Eq. 15
-            gcp = 0.5 * r1 * np.ones(self.problem.n_dims) * (r2 >= self.GP)  # Eq. 15
-            g0 = gcp * (c_eq - lamda * self.pop[idx][self.ID_POS])  # Eq. 14
-            g = g0 * f  # Eq. 13
-            pos_new = c_eq + (self.pop[idx][self.ID_POS] - c_eq) * f + (g * self.V / lamda) * (1.0 - f)  # Eq. 16
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-
-class ModifiedEO(OriginalEO):
-    """
-    The original version of: Modified Equilibrium Optimizer (MEO)
-
-    Links:
-        1. https://doi.org/10.1016/j.asoc.2020.106542
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.physics_based.EO import ModifiedEO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = ModifiedEO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Gupta, S., Deep, K. and Mirjalili, S., 2020. An efficient equilibrium optimizer with mutation
-    strategy for numerical optimization. Applied Soft Computing, 96, p.106542.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(epoch, pop_size, **kwargs)
-        self.sort_flag = False
-        self.pop_len = int(self.pop_size / 3)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # ---------------- Memory saving-------------------  make equilibrium pool
-        _, c_eq_list, _ = self.get_special_solutions(self.pop, best=4)
-        c_pool = self.make_equilibrium_pool__(c_eq_list)
-
-        # Eq. 9
-        t = (1 - epoch / self.epoch) ** (self.a2 * epoch / self.epoch)
-
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            lamda = np.random.uniform(0, 1, self.problem.n_dims)  # lambda in Eq. 11
-            r = np.random.uniform(0, 1, self.problem.n_dims)  # r in Eq. 11
-            c_eq = c_pool[np.random.randint(0, len(c_pool))][self.ID_POS]  # random selection 1 of candidate from the pool
-            f = self.a1 * np.sign(r - 0.5) * (np.exp(-lamda * t) - 1.0)  # Eq. 11
-            r1 = np.random.uniform()
-            r2 = np.random.uniform()  # r1, r2 in Eq. 15
-            gcp = 0.5 * r1 * np.ones(self.problem.n_dims) * (r2 >= self.GP)  # Eq. 15
-            g0 = gcp * (c_eq - lamda * self.pop[idx][self.ID_POS])  # Eq. 14
-            g = g0 * f  # Eq. 13
-            pos_new = c_eq + (self.pop[idx][self.ID_POS] - c_eq) * f + (g * self.V / lamda) * (1.0 - f)  # Eq. 16
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-        ## Sort the updated population based on fitness
-        _, pop_s1, _ = self.get_special_solutions(self.pop, best=self.pop_len)
-
-        ## Mutation scheme
-        pop_s2 = deepcopy(pop_s1)
-        pop_s2_new = []
-        for i in range(0, self.pop_len):
-            pos_new = pop_s2[i][self.ID_POS] * (1 + np.random.normal(0, 1, self.problem.n_dims))  # Eq. 12
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_s2_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                pop_s2[i] = self.get_better_solution([pos_new, target], pop_s2[i])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_s2_new = self.update_target_wrapper_population(pop_s2_new)
-            pop_s2 = self.greedy_selection_population(pop_s2_new, pop_s2)
-
-        ## Search Mechanism
-        pos_s1_list = [item[self.ID_POS] for item in pop_s1]
-        pos_s1_mean = np.mean(pos_s1_list, axis=0)
-        pop_s3 = []
-        for i in range(0, self.pop_len):
-            pos_new = (c_pool[0][self.ID_POS] - pos_s1_mean) - np.random.random() * \
-                      (self.problem.lb + np.random.random() * (self.problem.ub - self.problem.lb))
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_s3.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_s3[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop_s3 = self.update_target_wrapper_population(pop_s3)
-
-        ## Construct a new population
-        self.pop = pop_s1 + pop_s2 + pop_s3
-        n_left = self.pop_size - len(self.pop)
-        idx_selected = np.random.choice(range(0, len(c_pool)), n_left, replace=False)
-        for i in range(0, n_left):
-            self.pop.append(c_pool[idx_selected[i]])
-
-
-class AdaptiveEO(OriginalEO):
-    """
-    The original version of: Adaptive Equilibrium Optimization (AEO)
-
-    Links:
-        1. https://doi.org/10.1016/j.engappai.2020.103836
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.physics_based.EO import AdaptiveEO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = AdaptiveEO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Wunnava, A., Naik, M.K., Panda, R., Jena, B. and Abraham, A., 2020. A novel interdependence based
-    multilevel thresholding technique using adaptive equilibrium optimizer. Engineering Applications of
-    Artificial Intelligence, 94, p.103836.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(epoch, pop_size, **kwargs)
-        self.sort_flag = False
-        self.pop_len = int(self.pop_size / 3)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # ---------------- Memory saving-------------------  make equilibrium pool
-        _, c_eq_list, _ = self.get_special_solutions(self.pop, best=4)
-        c_pool = self.make_equilibrium_pool__(c_eq_list)
-
-        # Eq. 9
-        t = (1 - epoch / self.epoch) ** (self.a2 * epoch / self.epoch)
-
-        ## Memory saving, Eq 20, 21
-        t = (1 - epoch / self.epoch) ** (self.a2 * epoch / self.epoch)
-
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            lamda = np.random.uniform(0, 1, self.problem.n_dims)
-            r = np.random.uniform(0, 1, self.problem.n_dims)
-            c_eq = c_pool[np.random.randint(0, len(c_pool))][self.ID_POS]  # random selection 1 of candidate from the pool
-            f = self.a1 * np.sign(r - 0.5) * (np.exp(-lamda * t) - 1.0)  # Eq. 14
-
-            r1 = np.random.uniform()
-            r2 = np.random.uniform()
-            gcp = 0.5 * r1 * np.ones(self.problem.n_dims) * (r2 >= self.GP)
-            g0 = gcp * (c_eq - lamda * self.pop[idx][self.ID_POS])
-            g = g0 * f
-
-            fit_average = np.mean([item[self.ID_TAR][self.ID_FIT] for item in self.pop])  # Eq. 19
-            pos_new = c_eq + (self.pop[idx][self.ID_POS] - c_eq) * f + (g * self.V / lamda) * (1.0 - f)  # Eq. 9
-            if self.pop[idx][self.ID_TAR][self.ID_FIT] >= fit_average:
-                pos_new = np.multiply(pos_new, (0.5 + np.random.uniform(0, 1, self.problem.n_dims)))
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 07:03, 18/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalEO(Optimizer):
+    """
+    The original version of: Equilibrium Optimizer (EO)
+
+    Links:
+        1. https://doi.org/10.1016/j.knosys.2019.105190
+        2. https://www.mathworks.com/matlabcentral/fileexchange/73352-equilibrium-optimizer-eo
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.physics_based.EO import OriginalEO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalEO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Faramarzi, A., Heidarinejad, M., Stephens, B. and Mirjalili, S., 2020. Equilibrium optimizer: A novel
+    optimization algorithm. Knowledge-Based Systems, 191, p.105190.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+        ## Fixed parameter proposed by authors
+        self.V = 1
+        self.a1 = 2
+        self.a2 = 1
+        self.GP = 0.5
+
+    def make_equilibrium_pool__(self, list_equilibrium=None):
+        pos_list = [item[self.ID_POS] for item in list_equilibrium]
+        pos_mean = np.mean(pos_list, axis=0)
+        pos_mean = self.amend_position(pos_mean, self.problem.lb, self.problem.ub)
+        target = self.get_target_wrapper(pos_mean)
+        list_equilibrium.append([pos_mean, target])
+        return list_equilibrium
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # ---------------- Memory saving-------------------  make equilibrium pool
+        _, c_eq_list, _ = self.get_special_solutions(self.pop, best=4)
+        c_pool = self.make_equilibrium_pool__(c_eq_list)
+        # Eq. 9
+        t = (1 - epoch / self.epoch) ** (self.a2 * epoch / self.epoch)
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            lamda = np.random.uniform(0, 1, self.problem.n_dims)  # lambda in Eq. 11
+            r = np.random.uniform(0, 1, self.problem.n_dims)  # r in Eq. 11
+            c_eq = c_pool[np.random.randint(0, len(c_pool))][self.ID_POS]  # random selection 1 of candidate from the pool
+            f = self.a1 * np.sign(r - 0.5) * (np.exp(-lamda * t) - 1.0)  # Eq. 11
+            r1 = np.random.uniform()
+            r2 = np.random.uniform()  # r1, r2 in Eq. 15
+            gcp = 0.5 * r1 * np.ones(self.problem.n_dims) * (r2 >= self.GP)  # Eq. 15
+            g0 = gcp * (c_eq - lamda * self.pop[idx][self.ID_POS])  # Eq. 14
+            g = g0 * f  # Eq. 13
+            pos_new = c_eq + (self.pop[idx][self.ID_POS] - c_eq) * f + (g * self.V / lamda) * (1.0 - f)  # Eq. 16
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+
+class ModifiedEO(OriginalEO):
+    """
+    The original version of: Modified Equilibrium Optimizer (MEO)
+
+    Links:
+        1. https://doi.org/10.1016/j.asoc.2020.106542
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.physics_based.EO import ModifiedEO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = ModifiedEO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Gupta, S., Deep, K. and Mirjalili, S., 2020. An efficient equilibrium optimizer with mutation
+    strategy for numerical optimization. Applied Soft Computing, 96, p.106542.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(epoch, pop_size, **kwargs)
+        self.sort_flag = False
+        self.pop_len = int(self.pop_size / 3)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # ---------------- Memory saving-------------------  make equilibrium pool
+        _, c_eq_list, _ = self.get_special_solutions(self.pop, best=4)
+        c_pool = self.make_equilibrium_pool__(c_eq_list)
+
+        # Eq. 9
+        t = (1 - epoch / self.epoch) ** (self.a2 * epoch / self.epoch)
+
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            lamda = np.random.uniform(0, 1, self.problem.n_dims)  # lambda in Eq. 11
+            r = np.random.uniform(0, 1, self.problem.n_dims)  # r in Eq. 11
+            c_eq = c_pool[np.random.randint(0, len(c_pool))][self.ID_POS]  # random selection 1 of candidate from the pool
+            f = self.a1 * np.sign(r - 0.5) * (np.exp(-lamda * t) - 1.0)  # Eq. 11
+            r1 = np.random.uniform()
+            r2 = np.random.uniform()  # r1, r2 in Eq. 15
+            gcp = 0.5 * r1 * np.ones(self.problem.n_dims) * (r2 >= self.GP)  # Eq. 15
+            g0 = gcp * (c_eq - lamda * self.pop[idx][self.ID_POS])  # Eq. 14
+            g = g0 * f  # Eq. 13
+            pos_new = c_eq + (self.pop[idx][self.ID_POS] - c_eq) * f + (g * self.V / lamda) * (1.0 - f)  # Eq. 16
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+        ## Sort the updated population based on fitness
+        _, pop_s1, _ = self.get_special_solutions(self.pop, best=self.pop_len)
+
+        ## Mutation scheme
+        pop_s2 = deepcopy(pop_s1)
+        pop_s2_new = []
+        for i in range(0, self.pop_len):
+            pos_new = pop_s2[i][self.ID_POS] * (1 + np.random.normal(0, 1, self.problem.n_dims))  # Eq. 12
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_s2_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                pop_s2[i] = self.get_better_solution([pos_new, target], pop_s2[i])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_s2_new = self.update_target_wrapper_population(pop_s2_new)
+            pop_s2 = self.greedy_selection_population(pop_s2_new, pop_s2)
+
+        ## Search Mechanism
+        pos_s1_list = [item[self.ID_POS] for item in pop_s1]
+        pos_s1_mean = np.mean(pos_s1_list, axis=0)
+        pop_s3 = []
+        for i in range(0, self.pop_len):
+            pos_new = (c_pool[0][self.ID_POS] - pos_s1_mean) - np.random.random() * \
+                      (self.problem.lb + np.random.random() * (self.problem.ub - self.problem.lb))
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_s3.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_s3[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop_s3 = self.update_target_wrapper_population(pop_s3)
+
+        ## Construct a new population
+        self.pop = pop_s1 + pop_s2 + pop_s3
+        n_left = self.pop_size - len(self.pop)
+        idx_selected = np.random.choice(range(0, len(c_pool)), n_left, replace=False)
+        for i in range(0, n_left):
+            self.pop.append(c_pool[idx_selected[i]])
+
+
+class AdaptiveEO(OriginalEO):
+    """
+    The original version of: Adaptive Equilibrium Optimization (AEO)
+
+    Links:
+        1. https://doi.org/10.1016/j.engappai.2020.103836
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.physics_based.EO import AdaptiveEO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = AdaptiveEO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Wunnava, A., Naik, M.K., Panda, R., Jena, B. and Abraham, A., 2020. A novel interdependence based
+    multilevel thresholding technique using adaptive equilibrium optimizer. Engineering Applications of
+    Artificial Intelligence, 94, p.103836.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(epoch, pop_size, **kwargs)
+        self.sort_flag = False
+        self.pop_len = int(self.pop_size / 3)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # ---------------- Memory saving-------------------  make equilibrium pool
+        _, c_eq_list, _ = self.get_special_solutions(self.pop, best=4)
+        c_pool = self.make_equilibrium_pool__(c_eq_list)
+
+        # Eq. 9
+        t = (1 - epoch / self.epoch) ** (self.a2 * epoch / self.epoch)
+
+        ## Memory saving, Eq 20, 21
+        t = (1 - epoch / self.epoch) ** (self.a2 * epoch / self.epoch)
+
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            lamda = np.random.uniform(0, 1, self.problem.n_dims)
+            r = np.random.uniform(0, 1, self.problem.n_dims)
+            c_eq = c_pool[np.random.randint(0, len(c_pool))][self.ID_POS]  # random selection 1 of candidate from the pool
+            f = self.a1 * np.sign(r - 0.5) * (np.exp(-lamda * t) - 1.0)  # Eq. 14
+
+            r1 = np.random.uniform()
+            r2 = np.random.uniform()
+            gcp = 0.5 * r1 * np.ones(self.problem.n_dims) * (r2 >= self.GP)
+            g0 = gcp * (c_eq - lamda * self.pop[idx][self.ID_POS])
+            g = g0 * f
+
+            fit_average = np.mean([item[self.ID_TAR][self.ID_FIT] for item in self.pop])  # Eq. 19
+            pos_new = c_eq + (self.pop[idx][self.ID_POS] - c_eq) * f + (g * self.V / lamda) * (1.0 - f)  # Eq. 9
+            if self.pop[idx][self.ID_TAR][self.ID_FIT] >= fit_average:
+                pos_new = np.multiply(pos_new, (0.5 + np.random.uniform(0, 1, self.problem.n_dims)))
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/physics_based/EVO.py` & `mealpy-2.5.3a1/mealpy/physics_based/EVO.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,111 +1,111 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 18:09, 13/03/2023 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalEVO(Optimizer):
-    """
-    The original version of: Energy Valley Optimizer (EVO)
-
-    Links:
-        1. https://www.nature.com/articles/s41598-022-27344-y
-        2. https://www.mathworks.com/matlabcentral/fileexchange/123130-energy-valley-optimizer-a-novel-metaheuristic-algorithm
-
-    Notes:
-        1. The algorithm is straightforward and does not require any specialized knowledge or techniques.
-        2. The algorithm may not perform optimally due to slow convergence and no good operations, which could be improved by implementing better strategies and operations.
-        3. The problem is that it is stuck at a local optimal around 1/2 of the max generations because fitness distance is being used as a factor in the equations.
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.physics_based.EVO import OriginalEVO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalEVO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Azizi, M., Aickelin, U., A. Khorshidi, H., & Baghalzadeh Shishehgarkhaneh, M. (2023). Energy valley optimizer: a novel
-    metaheuristic algorithm for global and engineering optimization. Scientific Reports, 13(1), 226.
-    """
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = True
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            pos_list = np.array([agent[self.ID_POS] for agent in self.pop])
-            fit_list = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in self.pop])
-            dis = np.sqrt(np.sum((self.pop[idx][self.ID_POS] - pos_list)**2, axis=1))
-            idx_dis_sort = np.argsort(dis)
-            CnPtIdx = np.random.choice(list(set(range(2, self.pop_size)) - {idx}))
-            x_team = pos_list[idx_dis_sort[1:CnPtIdx], :]
-            x_avg_team = np.mean(x_team, axis=0)
-            x_avg_pop = np.mean(pos_list, axis=0)
-            eb = np.mean(fit_list)
-            sl = (fit_list[idx] - self.g_best[self.ID_TAR][self.ID_FIT]) / (self.g_worst[self.ID_TAR][self.ID_FIT] - self.g_best[self.ID_TAR][self.ID_FIT] + self.EPSILON)
-
-            pos_new1 = self.pop[idx][self.ID_POS].copy()
-            pos_new2 = self.pop[idx][self.ID_POS].copy()
-            if self.compare_agent([None, [eb]], self.pop[idx]):
-                if np.random.rand() > sl:
-                    a1_idx = np.random.randint(self.problem.n_dims)
-                    a2_idx = np.random.randint(0, self.problem.n_dims, size=a1_idx)
-                    pos_new1[a2_idx] = self.g_best[self.ID_POS][a2_idx]
-                    g1_idx = np.random.randint(self.problem.n_dims)
-                    g2_idx = np.random.randint(0, self.problem.n_dims, size=g1_idx)
-                    pos_new2[g2_idx] = x_avg_team[g2_idx]
-                else:
-                    ir = np.random.uniform(0, 1, 2)
-                    jr = np.random.uniform(0, 1, self.problem.n_dims)
-                    pos_new1 += jr * (ir[0] * self.g_best[self.ID_POS] - ir[1] * x_avg_pop) / sl
-                    ir = np.random.uniform(0, 1, 2)
-                    jr = np.random.uniform(0, 1, self.problem.n_dims)
-                    pos_new2 += jr * (ir[0] * self.g_best[self.ID_POS] - ir[1] * x_avg_team)
-                pos_new1 = self.amend_position(pos_new1, self.problem.lb, self.problem.ub)
-                pos_new2 = self.amend_position(pos_new2, self.problem.lb, self.problem.ub)
-                pop_new.append([pos_new1, None])
-                pop_new.append([pos_new2, None])
-            else:
-                pos_new = pos_new1 + np.random.randn() * sl * np.random.uniform(self.problem.lb, self.problem.ub, self.problem.n_dims)
-                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                pop_new.append([pos_new, None])
-        if self.mode not in self.AVAILABLE_MODES:
-            for idx in range(0, len(pop_new)):
-                pop_new[idx][self.ID_TAR] = self.get_target_wrapper(pop_new[idx][self.ID_POS])
-        pop_new = self.update_target_wrapper_population(pop_new)
-        self.pop = self.get_sorted_strim_population(self.pop + pop_new, self.pop_size)
+#!/usr/bin/env python
+# Created by "Thieu" at 18:09, 13/03/2023 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalEVO(Optimizer):
+    """
+    The original version of: Energy Valley Optimizer (EVO)
+
+    Links:
+        1. https://www.nature.com/articles/s41598-022-27344-y
+        2. https://www.mathworks.com/matlabcentral/fileexchange/123130-energy-valley-optimizer-a-novel-metaheuristic-algorithm
+
+    Notes (parameters):
+        1. The algorithm is very easy, and there is nothing special about this one.
+        2. This is a very weak algorithm with slow convergence because there is no good strategy, and no special operations are performed.
+        3. The problem is that it is stuck at a local optimal around 1/2 of the max generations because fitness distance is being used as a factor in the equations.
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.physics_based.EVO import OriginalEVO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalEVO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Azizi, M., Aickelin, U., A. Khorshidi, H., & Baghalzadeh Shishehgarkhaneh, M. (2023). Energy valley optimizer: a novel
+    metaheuristic algorithm for global and engineering optimization. Scientific Reports, 13(1), 226.
+    """
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = True
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            pos_list = np.array([agent[self.ID_POS] for agent in self.pop])
+            fit_list = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in self.pop])
+            dis = np.sqrt(np.sum((self.pop[idx][self.ID_POS] - pos_list)**2, axis=1))
+            idx_dis_sort = np.argsort(dis)
+            CnPtIdx = np.random.choice(list(set(range(2, self.pop_size)) - {idx}))
+            x_team = pos_list[idx_dis_sort[1:CnPtIdx], :]
+            x_avg_team = np.mean(x_team, axis=0)
+            x_avg_pop = np.mean(pos_list, axis=0)
+            eb = np.mean(fit_list)
+            sl = (fit_list[idx] - self.g_best[self.ID_TAR][self.ID_FIT]) / (self.g_worst[self.ID_TAR][self.ID_FIT] - self.g_best[self.ID_TAR][self.ID_FIT] + self.EPSILON)
+
+            pos_new1 = self.pop[idx][self.ID_POS].copy()
+            pos_new2 = self.pop[idx][self.ID_POS].copy()
+            if self.compare_agent([None, [eb]], self.pop[idx]):
+                if np.random.rand() > sl:
+                    a1_idx = np.random.randint(self.problem.n_dims)
+                    a2_idx = np.random.randint(0, self.problem.n_dims, size=a1_idx)
+                    pos_new1[a2_idx] = self.g_best[self.ID_POS][a2_idx]
+                    g1_idx = np.random.randint(self.problem.n_dims)
+                    g2_idx = np.random.randint(0, self.problem.n_dims, size=g1_idx)
+                    pos_new2[g2_idx] = x_avg_team[g2_idx]
+                else:
+                    ir = np.random.uniform(0, 1, 2)
+                    jr = np.random.uniform(0, 1, self.problem.n_dims)
+                    pos_new1 += jr * (ir[0] * self.g_best[self.ID_POS] - ir[1] * x_avg_pop) / sl
+                    ir = np.random.uniform(0, 1, 2)
+                    jr = np.random.uniform(0, 1, self.problem.n_dims)
+                    pos_new2 += jr * (ir[0] * self.g_best[self.ID_POS] - ir[1] * x_avg_team)
+                pos_new1 = self.amend_position(pos_new1, self.problem.lb, self.problem.ub)
+                pos_new2 = self.amend_position(pos_new2, self.problem.lb, self.problem.ub)
+                pop_new.append([pos_new1, None])
+                pop_new.append([pos_new2, None])
+            else:
+                pos_new = pos_new1 + np.random.randn() * sl * np.random.uniform(self.problem.lb, self.problem.ub, self.problem.n_dims)
+                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                pop_new.append([pos_new, None])
+        if self.mode not in self.AVAILABLE_MODES:
+            for idx in range(0, len(pop_new)):
+                pop_new[idx][self.ID_TAR] = self.get_target_wrapper(pop_new[idx][self.ID_POS])
+        pop_new = self.update_target_wrapper_population(pop_new)
+        self.pop = self.get_sorted_strim_population(self.pop + pop_new, self.pop_size)
```

### Comparing `mealpy-2.5.3/mealpy/physics_based/FLA.py` & `mealpy-2.5.3a1/mealpy/physics_based/FLA.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,217 +1,217 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 21:00, 14/03/2023 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalFLA(Optimizer):
-    """
-    The original version of: Fick's Law Algorithm (FLA)
-
-    Links:
-        1. https://www.mathworks.com/matlabcentral/fileexchange/121033-fick-s-law-algorithm-fla
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + C1 (float): factor C1, default=0.5
-        + C2 (float): factor C2, default=2.0
-        + C3 (float): factor C3, default=0.1
-        + C4 (float): factor C4, default=0.2
-        + C5 (float): factor C5, default=2.0
-        + DD (float): factor D in the paper, default=0.01
-
-    Notes:
-        1. The algorithm contains a high number of parameters, some of which may be unnecessary.
-        2. Despite the complexity of the algorithms, they may not perform optimally and could potentially become trapped in local optima.
-        3. Division by the fitness value may cause overflow issues to arise.
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.physics_based.FLA import OriginalFLA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> C1 = 0.5
-    >>> C2 = 2.0
-    >>> C3 = 0.1
-    >>> C4 = 0.2
-    >>> C5 = 2.0
-    >>> DD = 0.01
-    >>> model = OriginalFLA(epoch, pop_size, C1, C2, C3, C4, C5, DD)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Fatma Hashim, Reham R Mostafa, Abdelazim G. Hussien, Seyedali Mirjalili, & Karam M. Sallam   Knowledge-based Systems
-    """
-    def __init__(self, epoch=10000, pop_size=100, C1=0.5, C2=2.0, C3=0.1, C4=0.2, C5=2.0, DD=0.01, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            C1 (float): factor C1, default=0.5
-            C2 (float): factor C2, default=2.0
-            C3 (float): factor C3, default=0.1
-            C4 (float): factor C4, default=0.2
-            C5 (float): factor C5, default=2.0
-            DD (float): factor D in the paper, default=0.01
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.C1 = self.validator.check_float("C1", C1, (-100., 100.))
-        self.C2 = self.validator.check_float("C2", C2, (-100., 100.))
-        self.C3 = self.validator.check_float("C3", C3, (-100., 100.))
-        self.C4 = self.validator.check_float("C4", C4, (-100., 100.))
-        self.C5 = self.validator.check_float("C5", C5, (-100., 100.))
-        self.DD = self.validator.check_float("DD", DD, (-100., 100.))
-        self.set_parameters(["epoch", "pop_size", "C1", "C2", "C3", "C4", "C5", "DD"])
-        self.sort_flag = False
-
-    def before_main_loop(self):
-        self.xss, self.g_best = self.get_global_best_solution(self.pop)
-        self.n1 = int(np.round(self.pop_size/2))
-        self.n2 = self.pop_size - self.n1
-        self.pop1 = deepcopy(self.pop[:self.n1])
-        self.pop2 = deepcopy(self.pop[self.n1:])
-        _, self.best1 = self.get_global_best_solution(self.pop1)
-        _, self.best2 = self.get_global_best_solution(self.pop2)
-        if self.compare_agent(self.best1, self.best2):
-            self.fsss = self.best1[self.ID_TAR][self.ID_FIT]
-        else:
-            self.fsss = self.best2[self.ID_TAR][self.ID_FIT]
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pos_list = np.array([agent[self.ID_POS] for agent in self.pop])
-        pos1_list = np.array([agent[self.ID_POS] for agent in self.pop1])
-        pos2_list = np.array([agent[self.ID_POS] for agent in self.pop2])
-        xm1 = np.mean(pos1_list, axis=0)
-        xm2 = np.mean(pos2_list, axis=0)
-        xm = np.mean(pos_list, axis=0)
-        tf = np.sinh((epoch+1) / self.epoch)**self.C1
-        pop_new = []
-        if tf < 0.9:
-            dof = np.exp(-(self.C2 * tf - np.random.rand()))**self.C2
-            tdo = self.C5 * tf - np.random.rand()
-            if tdo < np.random.rand():
-                m1n, m2n = self.C3*self.n1, self.C4*self.n1
-                nt12 = int(np.round((m2n - m1n)*np.random.rand() + m1n))
-                for idx in range(0, nt12):
-                    dfg = np.random.randint(1, 3)
-                    jj = -self.DD * (xm2 - xm1) / np.linalg.norm(self.best2[self.ID_POS] - self.pop1[idx][self.ID_POS] + self.EPSILON)
-                    pos_new = self.best2[self.ID_POS] + dfg*dof*np.random.rand(self.problem.n_dims)*(jj*self.best2[self.ID_POS] - self.pop1[idx][self.ID_POS])
-                    pop_new.append([self.amend_position(pos_new, self.problem.lb, self.problem.ub), None])
-                for idx in range(nt12, self.n1):
-                    tt = self.pop1[idx][self.ID_POS] + dof * (np.random.rand(self.problem.n_dims) * (self.problem.ub - self.problem.lb) + self.problem.lb)
-                    pp = np.random.rand(self.problem.n_dims)
-                    pos_new = np.where(pp < 0.8, self.best1[self.ID_POS], np.where(pp >=0.9, self.pop1[idx][self.ID_POS], tt))
-                    pop_new.append([self.amend_position(pos_new, self.problem.lb, self.problem.ub), None])
-                for idx in range(0, self.n2):
-                    pos_new = self.best2[self.ID_POS] + dof * (np.random.rand(self.problem.n_dims) * (self.problem.ub - self.problem.lb) + self.problem.lb)
-                    pop_new.append([self.amend_position(pos_new, self.problem.lb, self.problem.ub), None])
-            else:
-                m1n, m2n = 0.1 * self.n2, 0.2 * self.n2
-                nt12 = int(np.round((m2n - m1n) * np.random.rand() + m1n))
-                for idx in range(0, nt12):
-                    dfg = np.random.randint(1, 3)
-                    jj = -self.DD*(xm1-xm2) / np.linalg.norm(self.best1[self.ID_POS] - self.pop2[idx][self.ID_POS] + self.EPSILON)
-                    pos_new = self.best1[self.ID_POS] + dfg * dof * np.random.rand(self.problem.n_dims) * (jj * self.best1[self.ID_POS] - self.pop2[idx][self.ID_POS])
-                    pop_new.append([self.amend_position(pos_new, self.problem.lb, self.problem.ub), None])
-                for idx in range(nt12, self.n2):
-                    tt = self.pop2[idx][self.ID_POS] + dof * (np.random.rand(self.problem.n_dims) * (self.problem.ub - self.problem.lb) + self.problem.lb)
-                    pp = np.random.rand(self.problem.n_dims)
-                    pos_new = np.where(pp < 0.8, self.best2[self.ID_POS], np.where(pp >= 0.9, self.pop2[idx][self.ID_POS], tt))
-                    pop_new.append([self.amend_position(pos_new, self.problem.lb, self.problem.ub), None])
-                for idx in range(0, self.n1):
-                    pos_new = self.best1[self.ID_POS] + dof * (np.random.rand(self.problem.n_dims) * (self.problem.ub - self.problem.lb) + self.problem.lb)
-                    pop_new.append([self.amend_position(pos_new, self.problem.lb, self.problem.ub), None])
-        else:       # Equilibrium operator (EO)
-            if tf <= 1:
-                for idx in range(0, self.n1):
-                    dfg = np.random.randint(1, 3)
-                    tttt = np.linalg.norm(self.best1[self.ID_POS] - self.pop1[idx][self.ID_POS])
-                    if tttt == 0:
-                        jj = 0
-                    else:
-                        jj = -self.DD*(self.best1[self.ID_POS] - xm1) / tttt
-                    drf = np.exp(-jj / tf)
-                    ms = np.exp(-self.best1[self.ID_TAR][self.ID_FIT] / self.pop1[idx][self.ID_TAR][self.ID_FIT] + self.EPSILON)
-                    qeo = dfg * drf * np.random.rand(self.problem.n_dims)
-                    pos_new = self.best1[self.ID_POS] + qeo*self.pop1[idx][self.ID_POS] + qeo *(ms * self.best1[self.ID_POS] - self.pop1[idx][self.ID_POS])
-                    pop_new.append([self.amend_position(pos_new, self.problem.lb, self.problem.ub), None])
-                for idx in range(0, self.n2):
-                    dfg = np.random.randint(1, 3)
-                    tttt = np.linalg.norm(self.best2[self.ID_POS] - self.pop2[idx][self.ID_POS])
-                    if tttt == 0:
-                        jj = 0
-                    else:
-                        jj = -self.DD * (self.best2[self.ID_POS] - xm2) / tttt
-                    drf = np.exp(-jj / tf)
-                    ms = np.exp(-self.best2[self.ID_TAR][self.ID_FIT] / self.pop2[idx][self.ID_TAR][self.ID_FIT] + self.EPSILON)
-                    qeo = dfg * drf * np.random.rand(self.problem.n_dims)
-                    pos_new = self.best2[self.ID_POS] + qeo * self.pop2[idx][self.ID_POS] + qeo * (ms * self.best2[self.ID_POS] - self.pop2[idx][self.ID_POS])
-                    pop_new.append([self.amend_position(pos_new, self.problem.lb, self.problem.ub), None])
-            else:   # Steady state operator (SSO)
-                for idx in range(0, self.n1):
-                    dfg = np.random.randint(1, 3)
-                    tttt = np.linalg.norm(self.g_best[self.ID_POS] - self.pop1[idx][self.ID_POS])
-                    if tttt == 0:
-                        jj = 0
-                    else:
-                        jj = -self.DD * (xm - xm1) / tttt
-                    drf = np.exp(-jj / tf)
-                    ms = np.exp(-self.fsss / self.pop1[idx][self.ID_TAR][self.ID_FIT] + self.EPSILON)
-                    qg = dfg * drf * np.random.rand(self.problem.n_dims)
-                    pos_new = self.g_best[self.ID_POS] + qg * self.pop1[idx][self.ID_POS] + qg * (ms * self.best1[self.ID_POS] - self.pop1[idx][self.ID_POS])
-                    pop_new.append([self.amend_position(pos_new, self.problem.lb, self.problem.ub), None])
-                for idx in range(0, self.n2):
-                    dfg = np.random.randint(1, 3)
-                    tttt = np.linalg.norm(self.g_best[self.ID_POS] - self.pop2[idx][self.ID_POS])
-                    if tttt == 0:
-                        jj = 0
-                    else:
-                        jj = -self.DD * (xm - xm2) / tttt
-                    drf = np.exp(-jj / tf)
-                    ms = np.exp(-self.fsss / self.pop2[idx][self.ID_TAR][self.ID_FIT] + self.EPSILON)
-                    qg = dfg * drf * np.random.rand(self.problem.n_dims)
-                    pos_new = self.g_best[self.ID_POS] + qg * self.pop2[idx][self.ID_POS] + qg * (ms * self.g_best[self.ID_POS] - self.pop2[idx][self.ID_POS])
-                    pop_new.append([self.amend_position(pos_new, self.problem.lb, self.problem.ub), None])
-
-        if self.mode not in self.AVAILABLE_MODES:
-            for idx in range(0, self.pop_size):
-                pop_new[idx][self.ID_TAR] = self.get_target_wrapper(pop_new[idx][self.ID_POS])
-        else:
-            pop_new = self.update_target_wrapper_population(pop_new)
-        for idx in range(0, self.pop_size):
-            if self.compare_agent(pop_new[idx], self.pop[idx]):
-                self.pop[idx] = pop_new[idx]
-        self.pop1 = deepcopy(self.pop[:self.n1])
-        self.pop2 = deepcopy(self.pop[self.n1:])
-        _, self.best1 = self.get_global_best_solution(self.pop1)
-        _, self.best2 = self.get_global_best_solution(self.pop2)
-        if self.compare_agent(self.best1, self.best2):
-            self.fsss = self.best1[self.ID_TAR][self.ID_FIT]
-        else:
-            self.fsss = self.best2[self.ID_TAR][self.ID_FIT]
+#!/usr/bin/env python
+# Created by "Thieu" at 21:00, 14/03/2023 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalFLA(Optimizer):
+    """
+    The original version of: Fick's Law Algorithm (FLA)
+
+    Links:
+        1. https://www.mathworks.com/matlabcentral/fileexchange/121033-fick-s-law-algorithm-fla
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + C1 (float): factor C1, default=0.5
+        + C2 (float): factor C2, default=2.0
+        + C3 (float): factor C3, default=0.1
+        + C4 (float): factor C4, default=0.2
+        + C5 (float): factor C5, default=2.0
+        + DD (float): factor D in the paper, default=0.01
+
+    Notes:
+        1. Too many parameters, and they are unnecessary
+        2. The algorithms are complex, but they are weak, making it easy to get stuck in local optima.
+        3. Overflow problems will occur due to the division by the fitness value.
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.physics_based.FLA import OriginalFLA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> C1 = 0.5
+    >>> C2 = 2.0
+    >>> C3 = 0.1
+    >>> C4 = 0.2
+    >>> C5 = 2.0
+    >>> DD = 0.01
+    >>> model = OriginalFLA(epoch, pop_size, C1, C2, C3, C4, C5, DD)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Fatma Hashim, Reham R Mostafa, Abdelazim G. Hussien, Seyedali Mirjalili, & Karam M. Sallam   Knowledge-based Systems
+    """
+    def __init__(self, epoch=10000, pop_size=100, C1=0.5, C2=2.0, C3=0.1, C4=0.2, C5=2.0, DD=0.01, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            C1 (float): factor C1, default=0.5
+            C2 (float): factor C2, default=2.0
+            C3 (float): factor C3, default=0.1
+            C4 (float): factor C4, default=0.2
+            C5 (float): factor C5, default=2.0
+            DD (float): factor D in the paper, default=0.01
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.C1 = self.validator.check_float("C1", C1, (-100., 100.))
+        self.C2 = self.validator.check_float("C2", C2, (-100., 100.))
+        self.C3 = self.validator.check_float("C3", C3, (-100., 100.))
+        self.C4 = self.validator.check_float("C4", C4, (-100., 100.))
+        self.C5 = self.validator.check_float("C5", C5, (-100., 100.))
+        self.DD = self.validator.check_float("DD", DD, (-100., 100.))
+        self.set_parameters(["epoch", "pop_size", "C1", "C2", "C3", "C4", "C5", "DD"])
+        self.sort_flag = False
+
+    def before_main_loop(self):
+        self.xss, self.g_best = self.get_global_best_solution(self.pop)
+        self.n1 = int(np.round(self.pop_size/2))
+        self.n2 = self.pop_size - self.n1
+        self.pop1 = deepcopy(self.pop[:self.n1])
+        self.pop2 = deepcopy(self.pop[self.n1:])
+        _, self.best1 = self.get_global_best_solution(self.pop1)
+        _, self.best2 = self.get_global_best_solution(self.pop2)
+        if self.compare_agent(self.best1, self.best2):
+            self.fsss = self.best1[self.ID_TAR][self.ID_FIT]
+        else:
+            self.fsss = self.best2[self.ID_TAR][self.ID_FIT]
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pos_list = np.array([agent[self.ID_POS] for agent in self.pop])
+        pos1_list = np.array([agent[self.ID_POS] for agent in self.pop1])
+        pos2_list = np.array([agent[self.ID_POS] for agent in self.pop2])
+        xm1 = np.mean(pos1_list, axis=0)
+        xm2 = np.mean(pos2_list, axis=0)
+        xm = np.mean(pos_list, axis=0)
+        tf = np.sinh((epoch+1) / self.epoch)**self.C1
+        pop_new = []
+        if tf < 0.9:
+            dof = np.exp(-(self.C2 * tf - np.random.rand()))**self.C2
+            tdo = self.C5 * tf - np.random.rand()
+            if tdo < np.random.rand():
+                m1n, m2n = self.C3*self.n1, self.C4*self.n1
+                nt12 = int(np.round((m2n - m1n)*np.random.rand() + m1n))
+                for idx in range(0, nt12):
+                    dfg = np.random.randint(1, 3)
+                    jj = -self.DD * (xm2 - xm1) / np.linalg.norm(self.best2[self.ID_POS] - self.pop1[idx][self.ID_POS] + self.EPSILON)
+                    pos_new = self.best2[self.ID_POS] + dfg*dof*np.random.rand(self.problem.n_dims)*(jj*self.best2[self.ID_POS] - self.pop1[idx][self.ID_POS])
+                    pop_new.append([self.amend_position(pos_new, self.problem.lb, self.problem.ub), None])
+                for idx in range(nt12, self.n1):
+                    tt = self.pop1[idx][self.ID_POS] + dof * (np.random.rand(self.problem.n_dims) * (self.problem.ub - self.problem.lb) + self.problem.lb)
+                    pp = np.random.rand(self.problem.n_dims)
+                    pos_new = np.where(pp < 0.8, self.best1[self.ID_POS], np.where(pp >=0.9, self.pop1[idx][self.ID_POS], tt))
+                    pop_new.append([self.amend_position(pos_new, self.problem.lb, self.problem.ub), None])
+                for idx in range(0, self.n2):
+                    pos_new = self.best2[self.ID_POS] + dof * (np.random.rand(self.problem.n_dims) * (self.problem.ub - self.problem.lb) + self.problem.lb)
+                    pop_new.append([self.amend_position(pos_new, self.problem.lb, self.problem.ub), None])
+            else:
+                m1n, m2n = 0.1 * self.n2, 0.2 * self.n2
+                nt12 = int(np.round((m2n - m1n) * np.random.rand() + m1n))
+                for idx in range(0, nt12):
+                    dfg = np.random.randint(1, 3)
+                    jj = -self.DD*(xm1-xm2) / np.linalg.norm(self.best1[self.ID_POS] - self.pop2[idx][self.ID_POS] + self.EPSILON)
+                    pos_new = self.best1[self.ID_POS] + dfg * dof * np.random.rand(self.problem.n_dims) * (jj * self.best1[self.ID_POS] - self.pop2[idx][self.ID_POS])
+                    pop_new.append([self.amend_position(pos_new, self.problem.lb, self.problem.ub), None])
+                for idx in range(nt12, self.n2):
+                    tt = self.pop2[idx][self.ID_POS] + dof * (np.random.rand(self.problem.n_dims) * (self.problem.ub - self.problem.lb) + self.problem.lb)
+                    pp = np.random.rand(self.problem.n_dims)
+                    pos_new = np.where(pp < 0.8, self.best2[self.ID_POS], np.where(pp >= 0.9, self.pop2[idx][self.ID_POS], tt))
+                    pop_new.append([self.amend_position(pos_new, self.problem.lb, self.problem.ub), None])
+                for idx in range(0, self.n1):
+                    pos_new = self.best1[self.ID_POS] + dof * (np.random.rand(self.problem.n_dims) * (self.problem.ub - self.problem.lb) + self.problem.lb)
+                    pop_new.append([self.amend_position(pos_new, self.problem.lb, self.problem.ub), None])
+        else:       # Equilibrium operator (EO)
+            if tf <= 1:
+                for idx in range(0, self.n1):
+                    dfg = np.random.randint(1, 3)
+                    tttt = np.linalg.norm(self.best1[self.ID_POS] - self.pop1[idx][self.ID_POS])
+                    if tttt == 0:
+                        jj = 0
+                    else:
+                        jj = -self.DD*(self.best1[self.ID_POS] - xm1) / tttt
+                    drf = np.exp(-jj / tf)
+                    ms = np.exp(-self.best1[self.ID_TAR][self.ID_FIT] / self.pop1[idx][self.ID_TAR][self.ID_FIT] + self.EPSILON)
+                    qeo = dfg * drf * np.random.rand(self.problem.n_dims)
+                    pos_new = self.best1[self.ID_POS] + qeo*self.pop1[idx][self.ID_POS] + qeo *(ms * self.best1[self.ID_POS] - self.pop1[idx][self.ID_POS])
+                    pop_new.append([self.amend_position(pos_new, self.problem.lb, self.problem.ub), None])
+                for idx in range(0, self.n2):
+                    dfg = np.random.randint(1, 3)
+                    tttt = np.linalg.norm(self.best2[self.ID_POS] - self.pop2[idx][self.ID_POS])
+                    if tttt == 0:
+                        jj = 0
+                    else:
+                        jj = -self.DD * (self.best2[self.ID_POS] - xm2) / tttt
+                    drf = np.exp(-jj / tf)
+                    ms = np.exp(-self.best2[self.ID_TAR][self.ID_FIT] / self.pop2[idx][self.ID_TAR][self.ID_FIT] + self.EPSILON)
+                    qeo = dfg * drf * np.random.rand(self.problem.n_dims)
+                    pos_new = self.best2[self.ID_POS] + qeo * self.pop2[idx][self.ID_POS] + qeo * (ms * self.best2[self.ID_POS] - self.pop2[idx][self.ID_POS])
+                    pop_new.append([self.amend_position(pos_new, self.problem.lb, self.problem.ub), None])
+            else:   # Steady state operator (SSO)
+                for idx in range(0, self.n1):
+                    dfg = np.random.randint(1, 3)
+                    tttt = np.linalg.norm(self.g_best[self.ID_POS] - self.pop1[idx][self.ID_POS])
+                    if tttt == 0:
+                        jj = 0
+                    else:
+                        jj = -self.DD * (xm - xm1) / tttt
+                    drf = np.exp(-jj / tf)
+                    ms = np.exp(-self.fsss / self.pop1[idx][self.ID_TAR][self.ID_FIT] + self.EPSILON)
+                    qg = dfg * drf * np.random.rand(self.problem.n_dims)
+                    pos_new = self.g_best[self.ID_POS] + qg * self.pop1[idx][self.ID_POS] + qg * (ms * self.best1[self.ID_POS] - self.pop1[idx][self.ID_POS])
+                    pop_new.append([self.amend_position(pos_new, self.problem.lb, self.problem.ub), None])
+                for idx in range(0, self.n2):
+                    dfg = np.random.randint(1, 3)
+                    tttt = np.linalg.norm(self.g_best[self.ID_POS] - self.pop2[idx][self.ID_POS])
+                    if tttt == 0:
+                        jj = 0
+                    else:
+                        jj = -self.DD * (xm - xm2) / tttt
+                    drf = np.exp(-jj / tf)
+                    ms = np.exp(-self.fsss / self.pop2[idx][self.ID_TAR][self.ID_FIT] + self.EPSILON)
+                    qg = dfg * drf * np.random.rand(self.problem.n_dims)
+                    pos_new = self.g_best[self.ID_POS] + qg * self.pop2[idx][self.ID_POS] + qg * (ms * self.g_best[self.ID_POS] - self.pop2[idx][self.ID_POS])
+                    pop_new.append([self.amend_position(pos_new, self.problem.lb, self.problem.ub), None])
+
+        if self.mode not in self.AVAILABLE_MODES:
+            for idx in range(0, self.pop_size):
+                pop_new[idx][self.ID_TAR] = self.get_target_wrapper(pop_new[idx][self.ID_POS])
+        else:
+            pop_new = self.update_target_wrapper_population(pop_new)
+        for idx in range(0, self.pop_size):
+            if self.compare_agent(pop_new[idx], self.pop[idx]):
+                self.pop[idx] = pop_new[idx]
+        self.pop1 = deepcopy(self.pop[:self.n1])
+        self.pop2 = deepcopy(self.pop[self.n1:])
+        _, self.best1 = self.get_global_best_solution(self.pop1)
+        _, self.best2 = self.get_global_best_solution(self.pop2)
+        if self.compare_agent(self.best1, self.best2):
+            self.fsss = self.best1[self.ID_TAR][self.ID_FIT]
+        else:
+            self.fsss = self.best2[self.ID_TAR][self.ID_FIT]
```

### Comparing `mealpy-2.5.3/mealpy/physics_based/HGSO.py` & `mealpy-2.5.3a1/mealpy/physics_based/HGSO.py`

 * *Ordering differences only*

 * *Files 15% similar despite different names*

```diff
@@ -1,151 +1,151 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 07:03, 18/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalHGSO(Optimizer):
-    """
-    The original version of: Henry Gas Solubility Optimization (HGSO)
-
-    Links:
-        1. https://www.sciencedirect.com/science/article/abs/pii/S0167739X19306557
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + n_clusters (int): [2, 10], number of clusters, default = 2
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.physics_based.HGSO import OriginalHGSO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> n_clusters = 3
-    >>> model = OriginalHGSO(epoch, pop_size, n_clusters)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Hashim, F.A., Houssein, E.H., Mabrouk, M.S., Al-Atabany, W. and Mirjalili, S., 2019. Henry gas solubility
-    optimization: A novel physics-based algorithm. Future Generation Computer Systems, 101, pp.646-667.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, n_clusters=2, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            n_clusters (int): number of clusters, default = 2
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.n_clusters = self.validator.check_int("n_clusters", n_clusters, [2, int(self.pop_size/5)])
-        self.set_parameters(["epoch", "pop_size", "n_clusters"])
-        self.n_elements = int(self.pop_size / self.n_clusters)
-        self.sort_flag = False
-        self.T0 = 298.15
-        self.K = 1.0
-        self.beta = 1.0
-        self.alpha = 1
-        self.epxilon = 0.05
-        self.l1 = 5E-2
-        self.l2 = 100.0
-        self.l3 = 1E-2
-
-    def initialize_variables(self):
-        self.H_j = self.l1 * np.random.uniform()
-        self.P_ij = self.l2 * np.random.uniform()
-        self.C_j = self.l3 * np.random.uniform()
-        self.pop_group, self.p_best = None, None
-
-    def initialization(self):
-        if self.pop is None:
-            self.pop = self.create_population(self.pop_size)
-        self.pop_group = self.create_pop_group(self.pop, self.n_clusters, self.n_elements)
-        self.p_best = self.get_best_solution_in_team__(self.pop_group)  # multiple element
-
-    def flatten_group__(self, group):
-        pop = []
-        for idx in range(0, self.n_clusters):
-            pop += group[idx]
-        return pop
-
-    def get_best_solution_in_team__(self, group=None):
-        list_best = []
-        for i in range(len(group)):
-            _, best_agent = self.get_global_best_solution(group[i])
-            list_best.append(best_agent)
-        return list_best
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        ## Loop based on the number of cluster in swarm (number of gases type)
-        for i in range(self.n_clusters):
-            ### Loop based on the number of individual in each gases type
-            pop_new = []
-            for j in range(self.n_elements):
-                F = -1.0 if np.random.uniform() < 0.5 else 1.0
-
-                ##### Based on Eq. 8, 9, 10
-                self.H_j = self.H_j * np.exp(-self.C_j * (1.0 / np.exp(-epoch / self.epoch) - 1.0 / self.T0))
-                S_ij = self.K * self.H_j * self.P_ij
-                gama = self.beta * np.exp(- ((self.p_best[i][self.ID_TAR][self.ID_FIT] + self.epxilon) /
-                                             (self.pop_group[i][j][self.ID_TAR][self.ID_FIT] + self.epxilon)))
-                X_ij = self.pop_group[i][j][self.ID_POS] + F * np.random.uniform() * gama * \
-                       (self.p_best[i][self.ID_POS] - self.pop_group[i][j][self.ID_POS]) + \
-                       F * np.random.uniform() * self.alpha * (S_ij * self.g_best[self.ID_POS] - self.pop_group[i][j][self.ID_POS])
-                pos_new = self.amend_position(X_ij, self.problem.lb, self.problem.ub)
-                pop_new.append([pos_new, None])
-                if self.mode not in self.AVAILABLE_MODES:
-                    pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop_group[i] = pop_new
-        self.pop = self.flatten_group__(self.pop_group)
-
-        ## Update Henry's coefficient using Eq.8
-        self.H_j = self.H_j * np.exp(-self.C_j * (1.0 / np.exp(-epoch / self.epoch) - 1.0 / self.T0))
-        ## Update the solubility of each gas using Eq.9
-        S_ij = self.K * self.H_j * self.P_ij
-        ## Rank and select the number of worst agents using Eq. 11
-        N_w = int(self.pop_size * (np.random.uniform(0, 0.1) + 0.1))
-        ## Update the position of the worst agents using Eq. 12
-        sorted_id_pos = np.argsort([x[self.ID_TAR][self.ID_FIT] for x in self.pop])
-
-        pop_new = []
-        pop_idx = []
-        for item in range(N_w):
-            id = sorted_id_pos[item]
-            X_new = np.random.uniform(self.problem.lb, self.problem.ub)
-            pos_new = self.amend_position(X_new, self.problem.lb, self.problem.ub)
-            pop_idx.append(id)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop_new = self.update_target_wrapper_population(pop_new)
-        for idx, id_selected in enumerate(pop_idx):
-            self.pop[id_selected] = deepcopy(pop_new[idx])
-        self.pop_group = self.create_pop_group(self.pop, self.n_clusters, self.n_elements)
-        self.p_best = self.get_best_solution_in_team__(self.pop_group)
+#!/usr/bin/env python
+# Created by "Thieu" at 07:03, 18/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalHGSO(Optimizer):
+    """
+    The original version of: Henry Gas Solubility Optimization (HGSO)
+
+    Links:
+        1. https://www.sciencedirect.com/science/article/abs/pii/S0167739X19306557
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + n_clusters (int): [2, 10], number of clusters, default = 2
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.physics_based.HGSO import OriginalHGSO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> n_clusters = 3
+    >>> model = OriginalHGSO(epoch, pop_size, n_clusters)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Hashim, F.A., Houssein, E.H., Mabrouk, M.S., Al-Atabany, W. and Mirjalili, S., 2019. Henry gas solubility
+    optimization: A novel physics-based algorithm. Future Generation Computer Systems, 101, pp.646-667.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, n_clusters=2, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            n_clusters (int): number of clusters, default = 2
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.n_clusters = self.validator.check_int("n_clusters", n_clusters, [2, int(self.pop_size/5)])
+        self.set_parameters(["epoch", "pop_size", "n_clusters"])
+        self.n_elements = int(self.pop_size / self.n_clusters)
+        self.sort_flag = False
+        self.T0 = 298.15
+        self.K = 1.0
+        self.beta = 1.0
+        self.alpha = 1
+        self.epxilon = 0.05
+        self.l1 = 5E-2
+        self.l2 = 100.0
+        self.l3 = 1E-2
+
+    def initialize_variables(self):
+        self.H_j = self.l1 * np.random.uniform()
+        self.P_ij = self.l2 * np.random.uniform()
+        self.C_j = self.l3 * np.random.uniform()
+        self.pop_group, self.p_best = None, None
+
+    def initialization(self):
+        if self.pop is None:
+            self.pop = self.create_population(self.pop_size)
+        self.pop_group = self.create_pop_group(self.pop, self.n_clusters, self.n_elements)
+        self.p_best = self.get_best_solution_in_team__(self.pop_group)  # multiple element
+
+    def flatten_group__(self, group):
+        pop = []
+        for idx in range(0, self.n_clusters):
+            pop += group[idx]
+        return pop
+
+    def get_best_solution_in_team__(self, group=None):
+        list_best = []
+        for i in range(len(group)):
+            _, best_agent = self.get_global_best_solution(group[i])
+            list_best.append(best_agent)
+        return list_best
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        ## Loop based on the number of cluster in swarm (number of gases type)
+        for i in range(self.n_clusters):
+            ### Loop based on the number of individual in each gases type
+            pop_new = []
+            for j in range(self.n_elements):
+                F = -1.0 if np.random.uniform() < 0.5 else 1.0
+
+                ##### Based on Eq. 8, 9, 10
+                self.H_j = self.H_j * np.exp(-self.C_j * (1.0 / np.exp(-epoch / self.epoch) - 1.0 / self.T0))
+                S_ij = self.K * self.H_j * self.P_ij
+                gama = self.beta * np.exp(- ((self.p_best[i][self.ID_TAR][self.ID_FIT] + self.epxilon) /
+                                             (self.pop_group[i][j][self.ID_TAR][self.ID_FIT] + self.epxilon)))
+                X_ij = self.pop_group[i][j][self.ID_POS] + F * np.random.uniform() * gama * \
+                       (self.p_best[i][self.ID_POS] - self.pop_group[i][j][self.ID_POS]) + \
+                       F * np.random.uniform() * self.alpha * (S_ij * self.g_best[self.ID_POS] - self.pop_group[i][j][self.ID_POS])
+                pos_new = self.amend_position(X_ij, self.problem.lb, self.problem.ub)
+                pop_new.append([pos_new, None])
+                if self.mode not in self.AVAILABLE_MODES:
+                    pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop_group[i] = pop_new
+        self.pop = self.flatten_group__(self.pop_group)
+
+        ## Update Henry's coefficient using Eq.8
+        self.H_j = self.H_j * np.exp(-self.C_j * (1.0 / np.exp(-epoch / self.epoch) - 1.0 / self.T0))
+        ## Update the solubility of each gas using Eq.9
+        S_ij = self.K * self.H_j * self.P_ij
+        ## Rank and select the number of worst agents using Eq. 11
+        N_w = int(self.pop_size * (np.random.uniform(0, 0.1) + 0.1))
+        ## Update the position of the worst agents using Eq. 12
+        sorted_id_pos = np.argsort([x[self.ID_TAR][self.ID_FIT] for x in self.pop])
+
+        pop_new = []
+        pop_idx = []
+        for item in range(N_w):
+            id = sorted_id_pos[item]
+            X_new = np.random.uniform(self.problem.lb, self.problem.ub)
+            pos_new = self.amend_position(X_new, self.problem.lb, self.problem.ub)
+            pop_idx.append(id)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop_new = self.update_target_wrapper_population(pop_new)
+        for idx, id_selected in enumerate(pop_idx):
+            self.pop[id_selected] = deepcopy(pop_new[idx])
+        self.pop_group = self.create_pop_group(self.pop, self.n_clusters, self.n_elements)
+        self.p_best = self.get_best_solution_in_team__(self.pop_group)
```

### Comparing `mealpy-2.5.3/mealpy/physics_based/MVO.py` & `mealpy-2.5.3a1/mealpy/swarm_based/GWO.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,223 +1,252 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 21:19, 17/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class BaseMVO(Optimizer):
-    """
-    The developed version: Multi-Verse Optimizer (MVO)
-
-    Notes
-    ~~~~~
-    + New routtele wheel selection can handle negative values
-    + Removed condition when np.random.normalize fitness. So the chance to choose while whole higher --> better
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + wep_min (float): [0.05, 0.3], Wormhole Existence Probability (min in Eq.(3.3) paper, default = 0.2
-        + wep_max (float: [0.75, 1.0], Wormhole Existence Probability (max in Eq.(3.3) paper, default = 1.0
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.physics_based.MVO import BaseMVO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> wep_min = 0.2
-    >>> wep_max = 1.0
-    >>> model = BaseMVO(epoch, pop_size, wep_min, wep_max)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, wep_min=0.2, wep_max=1.0, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            wep_min (float): Wormhole Existence Probability (min in Eq.(3.3) paper, default = 0.2
-            wep_max (float: Wormhole Existence Probability (max in Eq.(3.3) paper, default = 1.0
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.wep_min = self.validator.check_float("wep_min", wep_min, (0, 0.5))
-        self.wep_max = self.validator.check_float("wep_max", wep_max, [0.5, 3.0])
-        self.set_parameters(["epoch", "pop_size", "wep_min", "wep_max"])
-        self.sort_flag = True
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # Eq. (3.3) in the paper
-        wep = self.wep_max - (epoch + 1) * ((self.wep_max - self.wep_min) / self.epoch)
-
-        # Travelling Distance Rate (Formula): Eq. (3.4) in the paper
-        tdr = 1 - (epoch + 1) ** (1.0 / 6) / self.epoch ** (1.0 / 6)
-
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            if np.random.uniform() < wep:
-                list_fitness = np.array([item[self.ID_TAR][self.ID_FIT] for item in self.pop])
-                white_hole_id = self.get_index_roulette_wheel_selection(list_fitness)
-                black_hole_pos_1 = self.pop[idx][self.ID_POS] + tdr * np.random.normal(0, 1) * \
-                                   (self.pop[white_hole_id][self.ID_POS] - self.pop[idx][self.ID_POS])
-                black_hole_pos_2 = self.g_best[self.ID_POS] + tdr * np.random.normal(0, 1) * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-                black_hole_pos = np.where(np.random.random(self.problem.n_dims) < 0.5, black_hole_pos_1, black_hole_pos_2)
-            else:
-                black_hole_pos = self.generate_position(self.problem.lb, self.problem.ub)
-            pos_new = self.amend_position(black_hole_pos, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-
-class OriginalMVO(BaseMVO):
-    """
-    The original version of: Multi-Verse Optimizer (MVO)
-
-    Links:
-        1. https://dx.doi.org/10.1007/s00521-015-1870-7
-        2. https://www.mathworks.com/matlabcentral/fileexchange/50112-multi-verse-optimizer-mvo
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + wep_min (float): [0.05, 0.3], Wormhole Existence Probability (min in Eq.(3.3) paper, default = 0.2
-        + wep_max (float: [0.75, 1.0], Wormhole Existence Probability (max in Eq.(3.3) paper, default = 1.0
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.physics_based.MVO import OriginalMVO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> wep_min = 0.2
-    >>> wep_max = 1.0
-    >>> model = OriginalMVO(epoch, pop_size, wep_min, wep_max)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Mirjalili, S., Mirjalili, S.M. and Hatamlou, A., 2016. Multi-verse optimizer: a nature-inspired
-    algorithm for global optimization. Neural Computing and Applications, 27(2), pp.495-513.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, wep_min=0.2, wep_max=1.0, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            wep_min (float): Wormhole Existence Probability (min in Eq.(3.3) paper, default = 0.2
-            wep_max (float: Wormhole Existence Probability (max in Eq.(3.3) paper, default = 1.0
-        """
-        super().__init__(epoch, pop_size, wep_min, wep_max, **kwargs)
-
-    # sorted_inflation_rates
-    def roulette_wheel_selection__(self, weights=None):
-        accumulation = np.cumsum(weights)
-        p = np.random.uniform() * accumulation[-1]
-        chosen_idx = None
-        for idx in range(len(accumulation)):
-            if accumulation[idx] > p:
-                chosen_idx = idx
-                break
-        return chosen_idx
-
-    def normalize__(self, d, to_sum=True):
-        # d is a (n x dimension) np np.array
-        d -= np.min(d, axis=0)
-        if to_sum:
-            total_vector = np.sum(d, axis=0)
-            if 0 in total_vector:
-                return np.random.uniform(0.2, 0.8, self.pop_size)
-            return d / np.sum(d, axis=0)
-        else:
-            ptp_vector = np.ptp(d, axis=0)
-            if 0 in ptp_vector:
-                return np.random.uniform(0.2, 0.8, self.pop_size)
-            return d / np.ptp(d, axis=0)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # Eq. (3.3) in the paper
-        wep = self.wep_min + (epoch + 1) * ((self.wep_max - self.wep_min) / self.epoch)
-
-        # Travelling Distance Rate (Formula): Eq. (3.4) in the paper
-        tdr = 1 - (epoch + 1) ** (1.0 / 6) / self.epoch ** (1.0 / 6)
-
-        list_fitness_raw = np.array([item[self.ID_TAR][self.ID_FIT] for item in self.pop])
-        maxx = max(list_fitness_raw)
-        if maxx > (2 ** 64 - 1):
-            list_fitness_normalized = np.random.uniform(0, 0.1, self.pop_size)
-        else:
-            ### Normalize inflation rates (NI in Eq. (3.1) in the paper)
-            list_fitness_normalized = np.reshape(self.normalize__(np.array([list_fitness_raw])), self.pop_size)  # Matrix
-
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            black_hole_pos = deepcopy(self.pop[idx][self.ID_POS])
-            for j in range(0, self.problem.n_dims):
-                r1 = np.random.uniform()
-                if r1 < list_fitness_normalized[idx]:
-                    white_hole_id = self.roulette_wheel_selection__((-1 * list_fitness_raw))
-                    if white_hole_id == None or white_hole_id == -1:
-                        white_hole_id = 0
-                    # Eq. (3.1) in the paper
-                    black_hole_pos[j] = self.pop[white_hole_id][self.ID_POS][j]
-
-                # Eq. (3.2) in the paper if the boundaries are all the same
-                r2 = np.random.uniform()
-                if r2 < wep:
-                    r3 = np.random.uniform()
-                    if r3 < 0.5:
-                        black_hole_pos[j] = self.g_best[self.ID_POS][j] + tdr * np.random.uniform(self.problem.lb[j], self.problem.ub[j])
-                    else:
-                        black_hole_pos[j] = self.g_best[self.ID_POS][j] - tdr * np.random.uniform(self.problem.lb[j], self.problem.ub[j])
-            pos_new = self.amend_position(black_hole_pos, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 11:59, 17/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalGWO(Optimizer):
+    """
+    The original version of: Grey Wolf Optimizer (GWO)
+
+    Links:
+        1. https://doi.org/10.1016/j.advengsoft.2013.12.007
+        2. https://www.mathworks.com/matlabcentral/fileexchange/44974-grey-wolf-optimizer-gwo?s_tid=FX_rc3_behav
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.GWO import OriginalGWO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalGWO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Mirjalili, S., Mirjalili, S.M. and Lewis, A., 2014. Grey wolf optimizer. Advances in engineering software, 69, pp.46-61.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # linearly decreased from 2 to 0
+        a = 2 - 2 * epoch / (self.epoch - 1)
+        _, list_best, _ = self.get_special_solutions(self.pop, best=3)
+
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            A1, A2, A3 = a * (2 * np.random.uniform() - 1), a * (2 * np.random.uniform() - 1), a * (2 * np.random.uniform() - 1)
+            C1, C2, C3 = 2 * np.random.uniform(), 2 * np.random.uniform(), 2 * np.random.uniform()
+            X1 = list_best[0][self.ID_POS] - A1 * np.abs(C1 * list_best[0][self.ID_POS] - self.pop[idx][self.ID_POS])
+            X2 = list_best[1][self.ID_POS] - A2 * np.abs(C2 * list_best[1][self.ID_POS] - self.pop[idx][self.ID_POS])
+            X3 = list_best[2][self.ID_POS] - A3 * np.abs(C3 * list_best[2][self.ID_POS] - self.pop[idx][self.ID_POS])
+            pos_new = (X1 + X2 + X3) / 3.0
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+
+class RW_GWO(Optimizer):
+    """
+    The original version of: Random Walk Grey Wolf Optimizer (RW-GWO)
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.GWO import RW_GWO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = RW_GWO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Gupta, S. and Deep, K., 2019. A novel random walk grey wolf optimizer. Swarm and evolutionary computation, 44, pp.101-112.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # linearly decreased from 2 to 0, Eq. 5
+        b = 2 - 2 * epoch / (self.epoch - 1)
+        # linearly decreased from 2 to 0
+        a = 2 - 2 * epoch / (self.epoch - 1)
+        _, leaders, _ = self.get_special_solutions(self.pop, best=3)
+
+        ## Random walk here
+        leaders_new = []
+        for i in range(0, len(leaders)):
+            pos_new = leaders[i][self.ID_POS] + a * np.random.standard_cauchy(self.problem.n_dims)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            leaders_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                leaders[i] = self.get_better_solution([pos_new, target], leaders[i])
+        if self.mode in self.AVAILABLE_MODES:
+            leaders_new = self.update_target_wrapper_population(leaders_new)
+            leaders = self.greedy_selection_population(leaders, leaders_new)
+
+        ## Update other wolfs
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            # Eq. 3
+            miu1, miu2, miu3 = b * (2 * np.random.uniform() - 1), b * (2 * np.random.uniform() - 1), b * (2 * np.random.uniform() - 1)
+            # Eq. 4
+            c1, c2, c3 = 2 * np.random.uniform(), 2 * np.random.uniform(), 2 * np.random.uniform()
+            X1 = leaders[0][self.ID_POS] - miu1 * np.abs(c1 * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+            X2 = leaders[1][self.ID_POS] - miu2 * np.abs(c2 * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+            X3 = leaders[2][self.ID_POS] - miu3 * np.abs(c3 * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+            pos_new = (X1 + X2 + X3) / 3.0
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+        self.pop = self.get_sorted_strim_population(self.pop + leaders, self.pop_size)
+
+
+class GWO_WOA(OriginalGWO):
+    """
+    The original version of: Hybrid Grey Wolf - Whale Optimization Algorithm (GWO_WOA)
+
+    Links:
+        1. https://sci-hub.se/https://doi.org/10.1177/10775463211003402
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.GWO import GWO_WOA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = GWO_WOA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Obadina, O. O., Thaha, M. A., Althoefer, K., & Shaheed, M. H. (2022). Dynamic characterization of a masterâslave
+    robotic manipulator using a hybrid grey wolfâwhale optimization algorithm. Journal of Vibration and Control, 28(15-16), 1992-2003.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(epoch, pop_size, **kwargs)
+        self.b = 1.0
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # linearly decreased from 2 to 0
+        a = 2 - (epoch + 1) / self.epoch
+        _, list_best, _ = self.get_special_solutions(self.pop, best=3)
+
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            A1, A2, A3 = a * (2 * np.random.uniform() - 1), a * (2 * np.random.uniform() - 1), a * (2 * np.random.uniform() - 1)
+            C1, C2, C3 = 2 * np.random.uniform(), 2 * np.random.uniform(), 2 * np.random.uniform()
+            if np.random.random() < 0.5:
+                da = np.random.random() * np.abs(C1 * list_best[0][self.ID_POS] - self.pop[idx][self.ID_POS])
+            else:
+                P, L = np.random.random(), np.random.uniform(-1, 1)
+                da = P * np.exp(self.b * L) * np.cos(2*np.pi*L) * np.abs(C1 * list_best[0][self.ID_POS] - self.pop[idx][self.ID_POS])
+            X1 = list_best[0][self.ID_POS] - A1 * da
+            X2 = list_best[1][self.ID_POS] - A2 * np.abs(C2 * list_best[1][self.ID_POS] - self.pop[idx][self.ID_POS])
+            X3 = list_best[2][self.ID_POS] - A3 * np.abs(C3 * list_best[2][self.ID_POS] - self.pop[idx][self.ID_POS])
+            pos_new = (X1 + X2 + X3) / 3.0
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `mealpy-2.5.3/mealpy/physics_based/NRO.py` & `mealpy-2.5.3a1/mealpy/physics_based/NRO.py`

 * *Ordering differences only*

 * *Files 7% similar despite different names*

```diff
@@ -1,210 +1,210 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 07:02, 18/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-import math
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalNRO(Optimizer):
-    """
-    The original version of: Nuclear Reaction Optimization (NRO)
-
-    Links:
-        1. https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8720256
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.physics_based.NRO import OriginalNRO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalNRO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Wei, Z., Huang, C., Wang, X., Han, T. and Li, Y., 2019. Nuclear reaction optimization: A novel and
-    powerful physics-based algorithm for global optimization. IEEE Access, 7, pp.66084-66109.
-    [2] Wei, Z.L., Zhang, Z.R., Huang, C.Q., Han, B., Tang, S.Q. and Wang, L., 2019, June. An Approach
-    Inspired from Nuclear Reaction Processes for Numerical Optimization. In Journal of Physics:
-    Conference Series (Vol. 1213, No. 3, p. 032009). IOP Publishing.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def amend_position(self, position=None, lb=None, ub=None):
-        """
-        Depend on what kind of problem are we trying to solve, there will be an different amend_position
-        function to rebound the position of agent into the valid range.
-
-        Args:
-            position: vector position (location) of the solution.
-            lb: list of lower bound values
-            ub: list of upper bound values
-
-        Returns:
-            Amended position (make the position is in bound)
-        """
-        rand_pos = np.random.uniform(lb, ub)
-        condition = np.logical_and(lb <= position, position <= ub)
-        return np.where(condition, position, rand_pos)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        xichma_v = 1
-        xichma_u = ((math.gamma(1 + 1.5) * math.sin(math.pi * 1.5 / 2)) / (math.gamma((1 + 1.5) / 2) * 1.5 * 2 ** ((1.5 - 1) / 2))) ** (1.0 / 1.5)
-        levy_b = (np.random.normal(0, xichma_u ** 2)) / (np.sqrt(np.abs(np.random.normal(0, xichma_v ** 2))) ** (1.0 / 1.5))
-
-        # NFi phase
-        Pb = np.random.uniform()
-        Pfi = np.random.uniform()
-        freq = 0.05
-        alpha = 0.01
-
-        pop_new = []
-        for i in range(self.pop_size):
-            ## Calculate neutron vector Nei by Eq. (2)
-            ## Random 1 more index to select neutron
-            temp1 = list(set(range(0, self.pop_size)) - {i})
-            i1 = np.random.choice(temp1, replace=False)
-            Nei = (self.pop[i][self.ID_POS] + self.pop[i1][self.ID_POS]) / 2
-            ## Update population of fission products according to Eq.(3), (6) or (9);
-            if np.random.uniform() <= Pfi:
-                ### Update based on Eq. 3
-                if np.random.uniform() <= Pb:
-                    xichma1 = (np.log(epoch + 1) * 1.0 / (epoch + 1)) * np.abs(np.subtract(self.pop[i][self.ID_POS], self.g_best[self.ID_POS]))
-                    gauss = np.array([np.random.normal(self.g_best[self.ID_POS][j], xichma1[j]) for j in range(self.problem.n_dims)])
-                    Xi = gauss + np.random.uniform() * self.g_best[self.ID_POS] - round(np.random.rand() + 1) * Nei
-                ### Update based on Eq. 6
-                else:
-                    i2 = np.random.choice(temp1, replace=False)
-                    xichma2 = (np.log(epoch + 1) * 1.0 / (epoch + 1)) * np.abs(np.subtract(self.pop[i2][self.ID_POS], self.g_best[self.ID_POS]))
-                    gauss = np.array([np.random.normal(self.pop[i][self.ID_POS][j], xichma2[j]) for j in range(self.problem.n_dims)])
-                    Xi = gauss + np.random.uniform() * self.g_best[self.ID_POS] - round(np.random.rand() + 2) * Nei
-            ## Update based on Eq. 9
-            else:
-                i3 = np.random.choice(temp1, replace=False)
-                xichma2 = (np.log(epoch + 1) * 1.0 / (epoch + 1)) * np.abs(np.subtract(self.pop[i3][self.ID_POS], self.g_best[self.ID_POS]))
-                Xi = np.array([np.random.normal(self.pop[i][self.ID_POS][j], xichma2[j]) for j in range(self.problem.n_dims)])
-
-            ## Check the boundary and evaluate the fitness function
-            pos_new = self.amend_position(Xi, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[i] = self.get_better_solution([pos_new, target], self.pop[i])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-        # NFu phase
-
-        ## Ionization stage
-        ## Calculate the Pa through Eq. (10)
-        pop_child = []
-        ranked_pop = np.argsort([self.pop[i][self.ID_TAR][self.ID_FIT] for i in range(self.pop_size)])
-        for i in range(self.pop_size):
-            X_ion = deepcopy(self.pop[i][self.ID_POS])
-            if (ranked_pop[i] * 1.0 / self.pop_size) < np.random.random():
-                i1, i2 = np.random.choice(list(set(range(0, self.pop_size)) - {i}), 2, replace=False)
-                for j in range(self.problem.n_dims):
-                    #### Levy flight strategy is described as Eq. 18
-                    if self.pop[i2][self.ID_POS][j] == self.pop[i][self.ID_POS][j]:
-                        X_ion[j] = self.pop[i][self.ID_POS][j] + alpha * levy_b * (self.pop[i][self.ID_POS][j] - self.g_best[self.ID_POS][j])
-                    #### If not, based on Eq. 11, 12
-                    else:
-                        if np.random.uniform() <= 0.5:
-                            X_ion[j] = self.pop[i1][self.ID_POS][j] + np.random.uniform() * (self.pop[i2][self.ID_POS][j] - self.pop[i][self.ID_POS][j])
-                        else:
-                            X_ion[j] = self.pop[i1][self.ID_POS][j] - np.random.uniform() * (self.pop[i2][self.ID_POS][j] - self.pop[i][self.ID_POS][j])
-
-            else:  #### Levy flight strategy is described as Eq. 21
-                _, _, worst = self.get_special_solutions(self.pop, worst=1)
-                X_worst = worst[0]
-                for j in range(self.problem.n_dims):
-                    ##### Based on Eq. 21
-                    if X_worst[self.ID_POS][j] == self.g_best[self.ID_POS][j]:
-                        X_ion[j] = self.pop[i][self.ID_POS][j] + alpha * levy_b * (self.problem.ub[j] - self.problem.lb[j])
-                    ##### Based on Eq. 13
-                    else:
-                        X_ion[j] = self.pop[i][self.ID_POS][j] + round(np.random.uniform()) * np.random.uniform() * \
-                                   (X_worst[self.ID_POS][j] - self.g_best[self.ID_POS][j])
-
-            ## Check the boundary and evaluate the fitness function for X_ion
-            pos_new = self.amend_position(X_ion, self.problem.lb, self.problem.ub)
-            pop_child.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[i] = self.get_better_solution([pos_new, target], self.pop[i])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_child = self.update_target_wrapper_population(pop_child)
-            self.pop = self.greedy_selection_population(pop_child, self.pop)
-
-        ## Fusion Stage
-
-        ### all ions obtained from ionization are ranked based on (14) - Calculate the Pc through Eq. (14)
-        pop_new = []
-        ranked_pop = np.argsort([self.pop[i][self.ID_TAR][self.ID_FIT] for i in range(self.pop_size)])
-        for i in range(self.pop_size):
-            i1, i2 = np.random.choice(list(set(range(0, self.pop_size)) - {i}), 2, replace=False)
-
-            #### Generate fusion nucleus
-            if (ranked_pop[i] * 1.0 / self.pop_size) < np.random.random():
-                t1 = np.random.uniform() * (self.pop[i1][self.ID_POS] - self.g_best[self.ID_POS])
-                t2 = np.random.uniform() * (self.pop[i2][self.ID_POS] - self.g_best[self.ID_POS])
-                temp2 = self.pop[i1][self.ID_POS] - self.pop[i2][self.ID_POS]
-                X_fu = self.pop[i][self.ID_POS] + t1 + t2 - np.exp(-np.linalg.norm(temp2)) * temp2
-            #### Else
-            else:
-                ##### Based on Eq. 22
-                check_equal = (self.pop[i1][self.ID_POS] == self.pop[i2][self.ID_POS])
-                if check_equal.all():
-                    X_fu = self.pop[i][self.ID_POS] + alpha * levy_b * (self.pop[i][self.ID_POS] - self.g_best[self.ID_POS])
-                ##### Based on Eq. 16, 17
-                else:
-                    if np.random.uniform() > 0.5:
-                        X_fu = self.pop[i][self.ID_POS] - 0.5 * (np.sin(2 * np.pi * freq * epoch + np.pi) *
-                            (self.epoch - epoch) / self.epoch + 1) * (self.pop[i1][self.ID_POS] - self.pop[i2][self.ID_POS])
-                    else:
-                        X_fu = self.pop[i][self.ID_POS] - 0.5 * (np.sin(2 * np.pi * freq * epoch + np.pi) * epoch / self.epoch + 1) * \
-                               (self.pop[i1][self.ID_POS] - self.pop[i2][self.ID_POS])
-            pos_new = self.amend_position(X_fu, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[i] = self.get_better_solution([pos_new, target], self.pop[i])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 07:02, 18/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+import math
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalNRO(Optimizer):
+    """
+    The original version of: Nuclear Reaction Optimization (NRO)
+
+    Links:
+        1. https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8720256
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.physics_based.NRO import OriginalNRO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalNRO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Wei, Z., Huang, C., Wang, X., Han, T. and Li, Y., 2019. Nuclear reaction optimization: A novel and
+    powerful physics-based algorithm for global optimization. IEEE Access, 7, pp.66084-66109.
+    [2] Wei, Z.L., Zhang, Z.R., Huang, C.Q., Han, B., Tang, S.Q. and Wang, L., 2019, June. An Approach
+    Inspired from Nuclear Reaction Processes for Numerical Optimization. In Journal of Physics:
+    Conference Series (Vol. 1213, No. 3, p. 032009). IOP Publishing.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def amend_position(self, position=None, lb=None, ub=None):
+        """
+        Depend on what kind of problem are we trying to solve, there will be an different amend_position
+        function to rebound the position of agent into the valid range.
+
+        Args:
+            position: vector position (location) of the solution.
+            lb: list of lower bound values
+            ub: list of upper bound values
+
+        Returns:
+            Amended position (make the position is in bound)
+        """
+        rand_pos = np.random.uniform(lb, ub)
+        condition = np.logical_and(lb <= position, position <= ub)
+        return np.where(condition, position, rand_pos)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        xichma_v = 1
+        xichma_u = ((math.gamma(1 + 1.5) * math.sin(math.pi * 1.5 / 2)) / (math.gamma((1 + 1.5) / 2) * 1.5 * 2 ** ((1.5 - 1) / 2))) ** (1.0 / 1.5)
+        levy_b = (np.random.normal(0, xichma_u ** 2)) / (np.sqrt(np.abs(np.random.normal(0, xichma_v ** 2))) ** (1.0 / 1.5))
+
+        # NFi phase
+        Pb = np.random.uniform()
+        Pfi = np.random.uniform()
+        freq = 0.05
+        alpha = 0.01
+
+        pop_new = []
+        for i in range(self.pop_size):
+            ## Calculate neutron vector Nei by Eq. (2)
+            ## Random 1 more index to select neutron
+            temp1 = list(set(range(0, self.pop_size)) - {i})
+            i1 = np.random.choice(temp1, replace=False)
+            Nei = (self.pop[i][self.ID_POS] + self.pop[i1][self.ID_POS]) / 2
+            ## Update population of fission products according to Eq.(3), (6) or (9);
+            if np.random.uniform() <= Pfi:
+                ### Update based on Eq. 3
+                if np.random.uniform() <= Pb:
+                    xichma1 = (np.log(epoch + 1) * 1.0 / (epoch + 1)) * np.abs(np.subtract(self.pop[i][self.ID_POS], self.g_best[self.ID_POS]))
+                    gauss = np.array([np.random.normal(self.g_best[self.ID_POS][j], xichma1[j]) for j in range(self.problem.n_dims)])
+                    Xi = gauss + np.random.uniform() * self.g_best[self.ID_POS] - round(np.random.rand() + 1) * Nei
+                ### Update based on Eq. 6
+                else:
+                    i2 = np.random.choice(temp1, replace=False)
+                    xichma2 = (np.log(epoch + 1) * 1.0 / (epoch + 1)) * np.abs(np.subtract(self.pop[i2][self.ID_POS], self.g_best[self.ID_POS]))
+                    gauss = np.array([np.random.normal(self.pop[i][self.ID_POS][j], xichma2[j]) for j in range(self.problem.n_dims)])
+                    Xi = gauss + np.random.uniform() * self.g_best[self.ID_POS] - round(np.random.rand() + 2) * Nei
+            ## Update based on Eq. 9
+            else:
+                i3 = np.random.choice(temp1, replace=False)
+                xichma2 = (np.log(epoch + 1) * 1.0 / (epoch + 1)) * np.abs(np.subtract(self.pop[i3][self.ID_POS], self.g_best[self.ID_POS]))
+                Xi = np.array([np.random.normal(self.pop[i][self.ID_POS][j], xichma2[j]) for j in range(self.problem.n_dims)])
+
+            ## Check the boundary and evaluate the fitness function
+            pos_new = self.amend_position(Xi, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[i] = self.get_better_solution([pos_new, target], self.pop[i])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+        # NFu phase
+
+        ## Ionization stage
+        ## Calculate the Pa through Eq. (10)
+        pop_child = []
+        ranked_pop = np.argsort([self.pop[i][self.ID_TAR][self.ID_FIT] for i in range(self.pop_size)])
+        for i in range(self.pop_size):
+            X_ion = deepcopy(self.pop[i][self.ID_POS])
+            if (ranked_pop[i] * 1.0 / self.pop_size) < np.random.random():
+                i1, i2 = np.random.choice(list(set(range(0, self.pop_size)) - {i}), 2, replace=False)
+                for j in range(self.problem.n_dims):
+                    #### Levy flight strategy is described as Eq. 18
+                    if self.pop[i2][self.ID_POS][j] == self.pop[i][self.ID_POS][j]:
+                        X_ion[j] = self.pop[i][self.ID_POS][j] + alpha * levy_b * (self.pop[i][self.ID_POS][j] - self.g_best[self.ID_POS][j])
+                    #### If not, based on Eq. 11, 12
+                    else:
+                        if np.random.uniform() <= 0.5:
+                            X_ion[j] = self.pop[i1][self.ID_POS][j] + np.random.uniform() * (self.pop[i2][self.ID_POS][j] - self.pop[i][self.ID_POS][j])
+                        else:
+                            X_ion[j] = self.pop[i1][self.ID_POS][j] - np.random.uniform() * (self.pop[i2][self.ID_POS][j] - self.pop[i][self.ID_POS][j])
+
+            else:  #### Levy flight strategy is described as Eq. 21
+                _, _, worst = self.get_special_solutions(self.pop, worst=1)
+                X_worst = worst[0]
+                for j in range(self.problem.n_dims):
+                    ##### Based on Eq. 21
+                    if X_worst[self.ID_POS][j] == self.g_best[self.ID_POS][j]:
+                        X_ion[j] = self.pop[i][self.ID_POS][j] + alpha * levy_b * (self.problem.ub[j] - self.problem.lb[j])
+                    ##### Based on Eq. 13
+                    else:
+                        X_ion[j] = self.pop[i][self.ID_POS][j] + round(np.random.uniform()) * np.random.uniform() * \
+                                   (X_worst[self.ID_POS][j] - self.g_best[self.ID_POS][j])
+
+            ## Check the boundary and evaluate the fitness function for X_ion
+            pos_new = self.amend_position(X_ion, self.problem.lb, self.problem.ub)
+            pop_child.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[i] = self.get_better_solution([pos_new, target], self.pop[i])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_child = self.update_target_wrapper_population(pop_child)
+            self.pop = self.greedy_selection_population(pop_child, self.pop)
+
+        ## Fusion Stage
+
+        ### all ions obtained from ionization are ranked based on (14) - Calculate the Pc through Eq. (14)
+        pop_new = []
+        ranked_pop = np.argsort([self.pop[i][self.ID_TAR][self.ID_FIT] for i in range(self.pop_size)])
+        for i in range(self.pop_size):
+            i1, i2 = np.random.choice(list(set(range(0, self.pop_size)) - {i}), 2, replace=False)
+
+            #### Generate fusion nucleus
+            if (ranked_pop[i] * 1.0 / self.pop_size) < np.random.random():
+                t1 = np.random.uniform() * (self.pop[i1][self.ID_POS] - self.g_best[self.ID_POS])
+                t2 = np.random.uniform() * (self.pop[i2][self.ID_POS] - self.g_best[self.ID_POS])
+                temp2 = self.pop[i1][self.ID_POS] - self.pop[i2][self.ID_POS]
+                X_fu = self.pop[i][self.ID_POS] + t1 + t2 - np.exp(-np.linalg.norm(temp2)) * temp2
+            #### Else
+            else:
+                ##### Based on Eq. 22
+                check_equal = (self.pop[i1][self.ID_POS] == self.pop[i2][self.ID_POS])
+                if check_equal.all():
+                    X_fu = self.pop[i][self.ID_POS] + alpha * levy_b * (self.pop[i][self.ID_POS] - self.g_best[self.ID_POS])
+                ##### Based on Eq. 16, 17
+                else:
+                    if np.random.uniform() > 0.5:
+                        X_fu = self.pop[i][self.ID_POS] - 0.5 * (np.sin(2 * np.pi * freq * epoch + np.pi) *
+                            (self.epoch - epoch) / self.epoch + 1) * (self.pop[i1][self.ID_POS] - self.pop[i2][self.ID_POS])
+                    else:
+                        X_fu = self.pop[i][self.ID_POS] - 0.5 * (np.sin(2 * np.pi * freq * epoch + np.pi) * epoch / self.epoch + 1) * \
+                               (self.pop[i1][self.ID_POS] - self.pop[i2][self.ID_POS])
+            pos_new = self.amend_position(X_fu, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[i] = self.get_better_solution([pos_new, target], self.pop[i])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/physics_based/RIME.py` & `mealpy-2.5.3a1/mealpy/physics_based/RIME.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,94 +1,94 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 18:09, 13/03/2023 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalRIME(Optimizer):
-    """
-    The original version of: physical phenomenon of RIME-ice  (RIME)
-
-    Links:
-        1. https://doi.org/10.1016/j.neucom.2023.02.010
-        2. https://www.mathworks.com/matlabcentral/fileexchange/124610-rime-a-physics-based-optimization
-
-    Notes (parameters):
-        1. w (float): Soft-rime parameters, default=5.0
-        2. The algorithm is straightforward and does not require any specialized knowledge or techniques.
-        3. The algorithm may exhibit slow convergence and may not perform optimally.
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.physics_based.RIME import OriginalRIME
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> w = 5.0
-    >>> model = OriginalRIME(epoch, pop_size, w)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Su, H., Zhao, D., Heidari, A. A., Liu, L., Zhang, X., Mafarja, M., & Chen, H. (2023). RIME: A physics-based optimization. Neurocomputing.
-    """
-    def __init__(self, epoch=10000, pop_size=100, w=5., **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            w (float): Soft-rime parameters, default=5.0
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.w = self.validator.check_float("w", w, (0., 100.))
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        rime_factor = (np.random.rand() - 0.5)*2*np.cos(np.pi*(epoch+1)/(self.epoch/10)) * (1 - np.round((epoch+1)*self.w/self.epoch) / self.w)
-        ee = np.sqrt((epoch+1)/self.epoch)
-        fits = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in self.pop]).reshape((1, -1))
-        fits_norm = fits / np.linalg.norm(fits, axis=1, keepdims=True)
-        LB = self.problem.lb
-        UB = self.problem.ub
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            pos_new = self.pop[idx][self.ID_POS].copy()
-            for jdx in range(0, self.problem.n_dims):
-                # Soft-rime search strategy
-                if np.random.rand() < ee:
-                    pos_new[jdx] = self.g_best[self.ID_POS][jdx] + rime_factor*(LB[jdx] + np.random.rand() * (UB[jdx] - LB[jdx]))
-                # Hard-rime puncture mechanism
-                if np.random.rand() < fits_norm[0, idx]:
-                    pos_new[jdx] = self.g_best[self.ID_POS][jdx]
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 18:09, 13/03/2023 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalRIME(Optimizer):
+    """
+    The original version of: Artificial Gorilla Troops Optimization (RIME)
+
+    Links:
+        1. https://doi.org/10.1016/j.neucom.2023.02.010
+        2. https://www.mathworks.com/matlabcentral/fileexchange/124610-rime-a-physics-based-optimization
+
+    Notes (parameters):
+        1. w (float): Soft-rime parameters, default=5.0
+        2. The algorithm is very easy and there is nothing special about this one.
+        3. This is very weak algorithm, slow convergence.
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.physics_based.RIME import OriginalRIME
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> w = 5.0
+    >>> model = OriginalRIME(epoch, pop_size, w)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Su, H., Zhao, D., Heidari, A. A., Liu, L., Zhang, X., Mafarja, M., & Chen, H. (2023). RIME: A physics-based optimization. Neurocomputing.
+    """
+    def __init__(self, epoch=10000, pop_size=100, w=5., **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            w (float): Soft-rime parameters, default=5.0
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.w = self.validator.check_float("w", w, (0., 100.))
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        rime_factor = (np.random.rand() - 0.5)*2*np.cos(np.pi*(epoch+1)/(self.epoch/10)) * (1 - np.round((epoch+1)*self.w/self.epoch) / self.w)
+        ee = np.sqrt((epoch+1)/self.epoch)
+        fits = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in self.pop]).reshape((1, -1))
+        fits_norm = fits / np.linalg.norm(fits, axis=1, keepdims=True)
+        LB = self.problem.lb
+        UB = self.problem.ub
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            pos_new = self.pop[idx][self.ID_POS].copy()
+            for jdx in range(0, self.problem.n_dims):
+                # Soft-rime search strategy
+                if np.random.rand() < ee:
+                    pos_new[jdx] = self.g_best[self.ID_POS][jdx] + rime_factor*(LB[jdx] + np.random.rand() * (UB[jdx] - LB[jdx]))
+                # Hard-rime puncture mechanism
+                if np.random.rand() < fits_norm[0, idx]:
+                    pos_new[jdx] = self.g_best[self.ID_POS][jdx]
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/physics_based/SA.py` & `mealpy-2.5.3a1/mealpy/physics_based/SA.py`

 * *Ordering differences only*

 * *Files 13% similar despite different names*

```diff
@@ -1,142 +1,142 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 22:08, 01/03/2021 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalSA(Optimizer):
-    """
-    The original version of: Simulated Annealing (SA)
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + max_sub_iter (int): [5, 10, 15], Maximum Number of Sub-Iteration (within fixed temperature), default=5
-        + t0 (int): Fixed parameter, Initial Temperature, default=1000
-        + t1 (int): Fixed parameter, Final Temperature, default=1
-        + move_count (int): [5, 20], Move Count per Individual Solution, default=5
-        + mutation_rate (float): [0.01, 0.2], Mutation Rate, default=0.1
-        + mutation_step_size (float): [0.05, 0.1, 0.15], Mutation Step Size, default=0.1
-        + mutation_step_size_damp (float): [0.8, 0.99], Mutation Step Size Damp, default=0.99
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.physics_based.SA import OriginalSA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> max_sub_iter = 5
-    >>> t0 = 1000
-    >>> t1 = 1
-    >>> move_count = 5
-    >>> mutation_rate = 0.1
-    >>> mutation_step_size = 0.1
-    >>> mutation_step_size_damp = 0.99
-    >>> model = OriginalSA(epoch, pop_size, max_sub_iter, t0, t1, move_count, mutation_rate, mutation_step_size, mutation_step_size_damp)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Van Laarhoven, P.J. and Aarts, E.H., 1987. Simulated annealing. In Simulated
-    annealing: Theory and applications (pp. 7-15). Springer, Dordrecht.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, max_sub_iter=5, t0=1000, t1=1, move_count=5,
-                 mutation_rate=0.1, mutation_step_size=0.1, mutation_step_size_damp=0.99, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            max_sub_iter (int): Maximum Number of Sub-Iteration (within fixed temperature), default=5
-            t0 (int): Initial Temperature, default=1000
-            t1 (int): Final Temperature, default=1
-            move_count (int): Move Count per Individual Solution, default=5
-            mutation_rate (float): Mutation Rate, default=0.1
-            mutation_step_size (float): Mutation Step Size, default=0.1
-            mutation_step_size_damp (float): Mutation Step Size Damp, default=0.99
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.max_sub_iter = self.validator.check_int("max_sub_iter", max_sub_iter, [1, 100000])
-        self.t0 = self.validator.check_int("t0", t0, [500, 2000])
-        self.t1 = self.validator.check_int("t1", t1, [1, 100])
-        self.move_count = self.validator.check_int("move_count", move_count, [2, int(self.pop_size/2)])
-        self.mutation_rate = self.validator.check_float("mutation_rate", mutation_rate, (0, 1.0))
-        self.mutation_step_size = self.validator.check_float("mutation_step_size", mutation_step_size, (0, 1.0))
-        self.mutation_step_size_damp = self.validator.check_float("mutation_step_size_damp", mutation_step_size_damp, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "max_sub_iter", "t0", "t1", "move_count",
-                             "mutation_rate", "mutation_step_size", "mutation_step_size_damp"])
-        self.sort_flag = True
-        self.dyn_t, self.t_damp, self.dyn_sigma = None, None, None
-
-    def mutate__(self, position, sigma):
-        # Select Mutating Variables
-        pos_new = position + sigma * np.random.uniform(self.problem.lb, self.problem.ub)
-        pos_new = np.where(np.random.random(self.problem.n_dims) < self.mutation_rate, position, pos_new)
-        if np.all(pos_new == position):  # Select at least one variable to mutate
-            pos_new[np.random.randint(0, self.problem.n_dims)] = np.random.uniform()
-        return self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-
-    def initialization(self):
-        # Initial Temperature
-        self.dyn_t = self.t0  # Initial Temperature
-        self.t_damp = (self.t1 / self.t0) ** (1.0 / self.epoch)  # Calculate Temperature Damp Rate
-        self.dyn_sigma = self.mutation_step_size  # Initial Value of Step Size
-        if self.pop is None:
-            self.pop = self.create_population(self.pop_size)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # Sub-Iterations
-        for g in range(0, self.max_sub_iter):
-
-            # Create new population
-            pop_new = []
-            for idx in range(0, self.pop_size):
-                for j in range(0, self.move_count):
-                    # Perform Mutation (Move)
-                    pos_new = self.mutate__(self.pop[idx][self.ID_POS], self.dyn_sigma)
-                    pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                    pop_new.append([pos_new, None])
-                    if self.mode not in self.AVAILABLE_MODES:
-                        pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-            pop_new = self.update_target_wrapper_population(pop_new)
-
-            # Columnize and Sort Newly Created Population
-            pop_new = self.get_sorted_strim_population(pop_new, self.pop_size)
-
-            # Randomized Selection
-            for idx in range(0, self.pop_size):
-                # Check if new solution is better than current
-                if self.compare_agent(pop_new[idx], self.pop[idx]):
-                    self.pop[idx] = deepcopy(pop_new[idx])
-                else:
-                    # Compute difference according to problem type
-                    delta = np.abs(pop_new[idx][self.ID_TAR][self.ID_FIT] - self.pop[idx][self.ID_TAR][self.ID_FIT])
-                    p = np.exp(-delta / self.dyn_t)  # Compute Acceptance Probability
-                    if np.random.uniform() <= p:  # Accept / Reject
-                        self.pop[idx] = deepcopy(pop_new[idx])
-        # Update Temperature
-        self.dyn_t = self.t_damp * self.dyn_t
-        self.dyn_sigma = self.mutation_step_size_damp * self.dyn_sigma
+#!/usr/bin/env python
+# Created by "Thieu" at 22:08, 01/03/2021 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalSA(Optimizer):
+    """
+    The original version of: Simulated Annealing (SA)
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + max_sub_iter (int): [5, 10, 15], Maximum Number of Sub-Iteration (within fixed temperature), default=5
+        + t0 (int): Fixed parameter, Initial Temperature, default=1000
+        + t1 (int): Fixed parameter, Final Temperature, default=1
+        + move_count (int): [5, 20], Move Count per Individual Solution, default=5
+        + mutation_rate (float): [0.01, 0.2], Mutation Rate, default=0.1
+        + mutation_step_size (float): [0.05, 0.1, 0.15], Mutation Step Size, default=0.1
+        + mutation_step_size_damp (float): [0.8, 0.99], Mutation Step Size Damp, default=0.99
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.physics_based.SA import OriginalSA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> max_sub_iter = 5
+    >>> t0 = 1000
+    >>> t1 = 1
+    >>> move_count = 5
+    >>> mutation_rate = 0.1
+    >>> mutation_step_size = 0.1
+    >>> mutation_step_size_damp = 0.99
+    >>> model = OriginalSA(epoch, pop_size, max_sub_iter, t0, t1, move_count, mutation_rate, mutation_step_size, mutation_step_size_damp)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Van Laarhoven, P.J. and Aarts, E.H., 1987. Simulated annealing. In Simulated
+    annealing: Theory and applications (pp. 7-15). Springer, Dordrecht.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, max_sub_iter=5, t0=1000, t1=1, move_count=5,
+                 mutation_rate=0.1, mutation_step_size=0.1, mutation_step_size_damp=0.99, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            max_sub_iter (int): Maximum Number of Sub-Iteration (within fixed temperature), default=5
+            t0 (int): Initial Temperature, default=1000
+            t1 (int): Final Temperature, default=1
+            move_count (int): Move Count per Individual Solution, default=5
+            mutation_rate (float): Mutation Rate, default=0.1
+            mutation_step_size (float): Mutation Step Size, default=0.1
+            mutation_step_size_damp (float): Mutation Step Size Damp, default=0.99
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.max_sub_iter = self.validator.check_int("max_sub_iter", max_sub_iter, [1, 100000])
+        self.t0 = self.validator.check_int("t0", t0, [500, 2000])
+        self.t1 = self.validator.check_int("t1", t1, [1, 100])
+        self.move_count = self.validator.check_int("move_count", move_count, [2, int(self.pop_size/2)])
+        self.mutation_rate = self.validator.check_float("mutation_rate", mutation_rate, (0, 1.0))
+        self.mutation_step_size = self.validator.check_float("mutation_step_size", mutation_step_size, (0, 1.0))
+        self.mutation_step_size_damp = self.validator.check_float("mutation_step_size_damp", mutation_step_size_damp, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "max_sub_iter", "t0", "t1", "move_count",
+                             "mutation_rate", "mutation_step_size", "mutation_step_size_damp"])
+        self.sort_flag = True
+        self.dyn_t, self.t_damp, self.dyn_sigma = None, None, None
+
+    def mutate__(self, position, sigma):
+        # Select Mutating Variables
+        pos_new = position + sigma * np.random.uniform(self.problem.lb, self.problem.ub)
+        pos_new = np.where(np.random.random(self.problem.n_dims) < self.mutation_rate, position, pos_new)
+        if np.all(pos_new == position):  # Select at least one variable to mutate
+            pos_new[np.random.randint(0, self.problem.n_dims)] = np.random.uniform()
+        return self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+
+    def initialization(self):
+        # Initial Temperature
+        self.dyn_t = self.t0  # Initial Temperature
+        self.t_damp = (self.t1 / self.t0) ** (1.0 / self.epoch)  # Calculate Temperature Damp Rate
+        self.dyn_sigma = self.mutation_step_size  # Initial Value of Step Size
+        if self.pop is None:
+            self.pop = self.create_population(self.pop_size)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # Sub-Iterations
+        for g in range(0, self.max_sub_iter):
+
+            # Create new population
+            pop_new = []
+            for idx in range(0, self.pop_size):
+                for j in range(0, self.move_count):
+                    # Perform Mutation (Move)
+                    pos_new = self.mutate__(self.pop[idx][self.ID_POS], self.dyn_sigma)
+                    pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                    pop_new.append([pos_new, None])
+                    if self.mode not in self.AVAILABLE_MODES:
+                        pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+            pop_new = self.update_target_wrapper_population(pop_new)
+
+            # Columnize and Sort Newly Created Population
+            pop_new = self.get_sorted_strim_population(pop_new, self.pop_size)
+
+            # Randomized Selection
+            for idx in range(0, self.pop_size):
+                # Check if new solution is better than current
+                if self.compare_agent(pop_new[idx], self.pop[idx]):
+                    self.pop[idx] = deepcopy(pop_new[idx])
+                else:
+                    # Compute difference according to problem type
+                    delta = np.abs(pop_new[idx][self.ID_TAR][self.ID_FIT] - self.pop[idx][self.ID_TAR][self.ID_FIT])
+                    p = np.exp(-delta / self.dyn_t)  # Compute Acceptance Probability
+                    if np.random.uniform() <= p:  # Accept / Reject
+                        self.pop[idx] = deepcopy(pop_new[idx])
+        # Update Temperature
+        self.dyn_t = self.t_damp * self.dyn_t
+        self.dyn_sigma = self.mutation_step_size_damp * self.dyn_sigma
```

### Comparing `mealpy-2.5.3/mealpy/physics_based/TWO.py` & `mealpy-2.5.3a1/mealpy/physics_based/TWO.py`

 * *Ordering differences only*

 * *Files 9% similar despite different names*

```diff
@@ -1,448 +1,448 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 21:18, 17/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalTWO(Optimizer):
-    """
-    The original version of: Tug of War Optimization (TWO)
-
-    Links:
-        1. https://www.researchgate.net/publication/332088054_Tug_of_War_Optimization_Algorithm
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.physics_based.TWO import OriginalTWO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalTWO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Kaveh, A., 2017. Tug of war optimization. In Advances in metaheuristic algorithms for
-    optimal design of structures (pp. 451-487). Springer, Cham.
-    """
-
-    ID_POS = 0
-    ID_TAR = 1
-    ID_WEIGHT = 2
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-        self.muy_s = 1
-        self.muy_k = 1
-        self.delta_t = 1
-        self.alpha = 0.99
-        self.beta = 0.1
-
-    def initialization(self):
-        if self.pop is None:
-            self.pop = self.create_population(self.pop_size)
-        self.pop = self.update_weight__(self.pop)
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        """
-        Overriding method in Optimizer class
-
-        Returns:
-            list: wrapper of solution with format [position, target, weight]
-        """
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        position = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(position)
-        weight = 0.0
-        return [position, target, weight]
-
-    def update_weight__(self, teams):
-        list_fits = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in teams])
-        maxx, minn = np.max(list_fits), np.min(list_fits)
-        if maxx == minn:
-            list_fits = np.random.uniform(0.0, 1.0, self.pop_size)
-        list_weights = np.exp(-(list_fits - maxx) / (maxx - minn))
-        list_weights = list_weights/np.sum(list_weights) + 0.1
-        for idx in range(self.pop_size):
-            teams[idx][self.ID_WEIGHT] = list_weights[idx]
-        return teams
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = deepcopy(self.pop)
-        for idx in range(self.pop_size):
-            pos_new = pop_new[idx][self.ID_POS].astype(float)
-            for j in range(self.pop_size):
-                if self.pop[idx][self.ID_WEIGHT] < self.pop[j][self.ID_WEIGHT]:
-                    force = max(self.pop[idx][self.ID_WEIGHT] * self.muy_s, self.pop[j][self.ID_WEIGHT] * self.muy_s)
-                    resultant_force = force - self.pop[idx][self.ID_WEIGHT] * self.muy_k
-                    g = self.pop[j][self.ID_POS] - self.pop[idx][self.ID_POS]
-                    acceleration = resultant_force * g / (self.pop[idx][self.ID_WEIGHT] * self.muy_k)
-                    delta_x = 0.5 * acceleration + np.power(self.alpha, epoch + 1) * self.beta * \
-                              (self.problem.ub - self.problem.lb) * np.random.normal(0, 1, self.problem.n_dims)
-                    pos_new += delta_x
-            pop_new[idx][self.ID_POS] = pos_new
-        for idx in range(self.pop_size):
-            pos_new = pop_new[idx][self.ID_POS].astype(float)
-            for j in range(self.problem.n_dims):
-                if pos_new[j] < self.problem.lb[j] or pos_new[j] > self.problem.ub[j]:
-                    if np.random.random() <= 0.5:
-                        pos_new[j] = self.g_best[self.ID_POS][j] + np.random.randn() / (epoch + 1) * \
-                                                     (self.g_best[self.ID_POS][j] - pos_new[j])
-                        if pos_new[j] < self.problem.lb[j] or pos_new[j] > self.problem.ub[j]:
-                            pos_new[j] = self.pop[idx][self.ID_POS][j]
-                    else:
-                        if pos_new[j] < self.problem.lb[j]:
-                            pos_new[j] = self.problem.lb[j]
-                        if pos_new[j] > self.problem.ub[j]:
-                            pos_new[j] = self.problem.ub[j]
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new[idx][self.ID_POS] = pos_new
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[idx][self.ID_TAR] = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution(pop_new[idx], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-        self.pop = self.update_weight__(self.pop)
-
-
-class OppoTWO(OriginalTWO):
-    """
-    The opossition-based learning version: Tug of War Optimization (OTWO)
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.physics_based.TWO import OppoTWO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OppoTWO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(epoch, pop_size, **kwargs)
-
-    def initialization(self):
-        if self.pop is None:
-            self.pop = self.create_population(self.pop_size)
-        list_idx = np.random.choice(range(0, self.pop_size), int(self.pop_size/2), replace=False)
-        pop_temp = [self.pop[list_idx[idx]] for idx in range(0, int(self.pop_size/2))]
-        pop_oppo = []
-        for i in range(len(pop_temp)):
-            pos_opposite = self.problem.ub + self.problem.lb - pop_temp[i][self.ID_POS]
-            pos_opposite = self.amend_position(pos_opposite, self.problem.lb, self.problem.ub)
-            pop_oppo.append([pos_opposite, None, 0.0])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_oppo[-1][self.ID_TAR] = self.get_target_wrapper(pos_opposite)
-        pop_oppo = self.update_target_wrapper_population(pop_oppo)
-        self.pop = pop_temp + pop_oppo
-        self.pop = self.update_weight__(self.pop)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        ## Apply force of others solution on each individual solution
-        pop_new = deepcopy(self.pop)
-        for idx in range(self.pop_size):
-            pos_new = pop_new[idx][self.ID_POS].astype(float)
-            for j in range(self.pop_size):
-                if self.pop[idx][self.ID_WEIGHT] < self.pop[j][self.ID_WEIGHT]:
-                    force = max(self.pop[idx][self.ID_WEIGHT] * self.muy_s, self.pop[j][self.ID_WEIGHT] * self.muy_s)
-                    resultant_force = force - self.pop[idx][self.ID_WEIGHT] * self.muy_k
-                    g = self.pop[j][self.ID_POS] - self.pop[idx][self.ID_POS]
-                    temp = (self.pop[idx][self.ID_WEIGHT] * self.muy_k)
-                    acceleration = resultant_force * g / temp
-                    delta_x = 1 / 2 * acceleration + np.power(self.alpha, epoch + 1) * self.beta * \
-                              (self.problem.ub - self.problem.lb) * np.random.normal(0, 1, self.problem.n_dims)
-                    pos_new += delta_x
-            self.pop[idx][self.ID_POS] = pos_new
-
-        ## Amend solution and update fitness value
-        for idx in range(self.pop_size):
-            pos_new = self.g_best[self.ID_POS] + np.random.normal(0, 1, self.problem.n_dims) / (epoch + 1) * \
-                      (self.g_best[self.ID_POS] - pop_new[idx][self.ID_POS])
-            conditions = np.logical_or(pop_new[idx][self.ID_POS] < self.problem.lb, pop_new[idx][self.ID_POS] > self.problem.ub)
-            conditions = np.logical_and(conditions, np.random.random(self.problem.n_dims) < 0.5)
-            pos_new = np.where(conditions, pos_new, self.pop[idx][self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new[idx][self.ID_POS] = pos_new
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[idx][self.ID_TAR] = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution(pop_new[idx], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-        ## Opposition-based here
-        pop = []
-        for idx in range(self.pop_size):
-            C_op = self.create_opposition_position(self.pop[idx][self.ID_POS], self.g_best[self.ID_POS])
-            pos_new = self.amend_position(C_op, self.problem.lb, self.problem.ub)
-            pop.append([pos_new, None, 0.0])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target, 0.0], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop = self.update_target_wrapper_population(pop)
-            self.pop = self.greedy_selection_population(self.pop, pop)
-        self.pop = self.update_weight__(self.pop)
-
-
-class LevyTWO(OriginalTWO):
-    """
-    The Levy-flight version of: Tug of War Optimization (LevyTWO)
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.physics_based.TWO import LevyTWO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = LevyTWO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(epoch, pop_size, **kwargs)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = deepcopy(self.pop)
-        for i in range(self.pop_size):
-            pos_new = self.pop[i][self.ID_POS].astype(float)
-            for k in range(self.pop_size):
-                if self.pop[i][self.ID_WEIGHT] < self.pop[k][self.ID_WEIGHT]:
-                    force = max(self.pop[i][self.ID_WEIGHT] * self.muy_s, self.pop[k][self.ID_WEIGHT] * self.muy_s)
-                    resultant_force = force - self.pop[i][self.ID_WEIGHT] * self.muy_k
-                    g = self.pop[k][self.ID_POS] - self.pop[i][self.ID_POS]
-                    acceleration = resultant_force * g / (self.pop[i][self.ID_WEIGHT] * self.muy_k)
-                    delta_x = 1 / 2 * acceleration + np.power(self.alpha, epoch + 1) * self.beta * \
-                              (self.problem.ub - self.problem.lb) * np.random.normal(0, 1, self.problem.n_dims)
-                    pos_new +=delta_x
-            pop_new[i][self.ID_POS] = pos_new
-        for i in range(self.pop_size):
-            pos_new = self.pop[i][self.ID_POS].astype(float)
-            for j in range(self.problem.n_dims):
-                if pos_new[j] < self.problem.lb[j] or pos_new[j] > self.problem.ub[j]:
-                    if np.random.random() <= 0.5:
-                        pos_new[j] = self.g_best[self.ID_POS][j] + np.random.randn() / (epoch + 1) * \
-                                                     (self.g_best[self.ID_POS][j] - pos_new[j])
-                        if pos_new[j] < self.problem.lb[j] or pos_new[j] > self.problem.ub[j]:
-                            pos_new[j] = self.pop[i][self.ID_POS][j]
-                    else:
-                        if pos_new[j] < self.problem.lb[j]:
-                            pos_new[j] = self.problem.lb[j]
-                        if pos_new[j] > self.problem.ub[j]:
-                            pos_new[j] = self.problem.ub[j]
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new[i][self.ID_POS] = pos_new
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[i][self.ID_TAR] = self.get_target_wrapper(pos_new)
-                self.pop[i] = self.get_better_solution(pop_new[i], self.pop[i])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-        ### Apply levy-flight here
-        for i in range(self.pop_size):
-            ## Chance for each agent to update using levy is 50%
-            if np.random.rand() < 0.5:
-                levy_step = self.get_levy_flight_step(beta=1.0, multiplier=0.1, size=self.problem.n_dims, case=-1)
-                pos_new = pop_new[i][self.ID_POS] + levy_step
-                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                target = self.get_target_wrapper(pos_new)
-                if self.compare_agent([pos_new, target, 0.0], pop_new[i]):
-                    pop_new[i] = [pos_new, target, 0.0]
-        self.pop = self.update_weight__(pop_new)
-
-
-class EnhancedTWO(OppoTWO, LevyTWO):
-    """
-    The original version of: Enhenced Tug of War Optimization (ETWO)
-
-    Links:
-        1. https://doi.org/10.1016/j.procs.2020.03.063
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.physics_based.TWO import EnhancedTWO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = EnhancedTWO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Nguyen, T., Hoang, B., Nguyen, G. and Nguyen, B.M., 2020. A new workload prediction model using
-    extreme learning machine and enhanced tug of war optimization. Procedia Computer Science, 170, pp.362-369.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(epoch, pop_size, **kwargs)
-
-    def initialization(self):
-        if self.pop is None:
-            self.pop = self.create_population(self.pop_size)
-        pop_oppo = deepcopy(self.pop)
-        for i in range(self.pop_size):
-            pos_opposite = self.problem.ub + self.problem.lb - self.pop[i][self.ID_POS]
-            pos_new = self.amend_position(pos_opposite, self.problem.lb, self.problem.ub)
-            pop_oppo[i][self.ID_POS] = pos_new
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_oppo[i][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop_oppo = self.update_target_wrapper_population(pop_oppo)
-        self.pop = self.get_sorted_strim_population(self.pop + pop_oppo, self.pop_size)
-        self.pop = self.update_weight__(self.pop)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = deepcopy(self.pop)
-        for i in range(self.pop_size):
-            pos_new = self.pop[i][self.ID_POS].astype(float)
-            for k in range(self.pop_size):
-                if self.pop[i][self.ID_WEIGHT] < self.pop[k][self.ID_WEIGHT]:
-                    force = max(self.pop[i][self.ID_WEIGHT] * self.muy_s, self.pop[k][self.ID_WEIGHT] * self.muy_s)
-                    resultant_force = force - self.pop[i][self.ID_WEIGHT] * self.muy_k
-                    g = self.pop[k][self.ID_POS] - self.pop[i][self.ID_POS]
-                    acceleration = resultant_force * g / (self.pop[i][self.ID_WEIGHT] * self.muy_k)
-                    delta_x = 1 / 2 * acceleration + np.power(self.alpha, epoch + 1) * self.beta * \
-                              (self.problem.ub - self.problem.lb) * np.random.normal(0, 1, self.problem.n_dims)
-                    pos_new += delta_x
-            pop_new[i][self.ID_POS] = pos_new
-        for i in range(self.pop_size):
-            pos_new = self.pop[i][self.ID_POS].astype(float)
-            for j in range(self.problem.n_dims):
-                if pos_new[j] < self.problem.lb[j] or pos_new[j] > self.problem.ub[j]:
-                    if np.random.random() <= 0.5:
-                        pos_new[j] = self.g_best[self.ID_POS][j] + np.random.randn() / (epoch + 1) * \
-                                                     (self.g_best[self.ID_POS][j] - pos_new[j])
-                        if pos_new[j] < self.problem.lb[j] or pos_new[j] > self.problem.ub[j]:
-                            pos_new[j] = self.pop[i][self.ID_POS][j]
-                    else:
-                        if pos_new[j] < self.problem.lb[j]:
-                            pos_new[j] = self.problem.lb[j]
-                        if pos_new[j] > self.problem.ub[j]:
-                            pos_new[j] = self.problem.ub[j]
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new[i][self.ID_POS] = pos_new
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[i][self.ID_TAR] = self.get_target_wrapper(pos_new)
-                self.pop[i] = self.get_better_solution(pop_new[i], self.pop[i])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-        for i in range(self.pop_size):
-            C_op = self.create_opposition_position(pop_new[i][self.ID_POS], self.g_best[self.ID_POS])
-            C_op = self.amend_position(C_op, self.problem.lb, self.problem.ub)
-            target_op = self.get_target_wrapper(C_op)
-            if self.compare_agent([C_op, target_op], pop_new[i]):
-                pop_new[i] = [C_op, target_op, 0.0]
-            else:
-                levy_step = self.get_levy_flight_step(beta=1.0, multiplier=1.0, size=self.problem.n_dims, case=-1)
-                pos_new = pop_new[i][self.ID_POS] + 1.0 / np.sqrt(epoch + 1) * levy_step
-                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                target = self.get_target_wrapper(pos_new)
-                if self.compare_agent([pos_new, target], pop_new[i]):
-                    pop_new[i] = [pos_new, target, 0.0]
-        self.pop = self.update_weight__(pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 21:18, 17/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalTWO(Optimizer):
+    """
+    The original version of: Tug of War Optimization (TWO)
+
+    Links:
+        1. https://www.researchgate.net/publication/332088054_Tug_of_War_Optimization_Algorithm
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.physics_based.TWO import OriginalTWO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalTWO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Kaveh, A., 2017. Tug of war optimization. In Advances in metaheuristic algorithms for
+    optimal design of structures (pp. 451-487). Springer, Cham.
+    """
+
+    ID_POS = 0
+    ID_TAR = 1
+    ID_WEIGHT = 2
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+        self.muy_s = 1
+        self.muy_k = 1
+        self.delta_t = 1
+        self.alpha = 0.99
+        self.beta = 0.1
+
+    def initialization(self):
+        if self.pop is None:
+            self.pop = self.create_population(self.pop_size)
+        self.pop = self.update_weight__(self.pop)
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        """
+        Overriding method in Optimizer class
+
+        Returns:
+            list: wrapper of solution with format [position, target, weight]
+        """
+        if pos is None:
+            pos = self.generate_position(lb, ub)
+        position = self.amend_position(pos, lb, ub)
+        target = self.get_target_wrapper(position)
+        weight = 0.0
+        return [position, target, weight]
+
+    def update_weight__(self, teams):
+        list_fits = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in teams])
+        maxx, minn = np.max(list_fits), np.min(list_fits)
+        if maxx == minn:
+            list_fits = np.random.uniform(0.0, 1.0, self.pop_size)
+        list_weights = np.exp(-(list_fits - maxx) / (maxx - minn))
+        list_weights = list_weights/np.sum(list_weights) + 0.1
+        for idx in range(self.pop_size):
+            teams[idx][self.ID_WEIGHT] = list_weights[idx]
+        return teams
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = deepcopy(self.pop)
+        for idx in range(self.pop_size):
+            pos_new = pop_new[idx][self.ID_POS].astype(float)
+            for j in range(self.pop_size):
+                if self.pop[idx][self.ID_WEIGHT] < self.pop[j][self.ID_WEIGHT]:
+                    force = max(self.pop[idx][self.ID_WEIGHT] * self.muy_s, self.pop[j][self.ID_WEIGHT] * self.muy_s)
+                    resultant_force = force - self.pop[idx][self.ID_WEIGHT] * self.muy_k
+                    g = self.pop[j][self.ID_POS] - self.pop[idx][self.ID_POS]
+                    acceleration = resultant_force * g / (self.pop[idx][self.ID_WEIGHT] * self.muy_k)
+                    delta_x = 0.5 * acceleration + np.power(self.alpha, epoch + 1) * self.beta * \
+                              (self.problem.ub - self.problem.lb) * np.random.normal(0, 1, self.problem.n_dims)
+                    pos_new += delta_x
+            pop_new[idx][self.ID_POS] = pos_new
+        for idx in range(self.pop_size):
+            pos_new = pop_new[idx][self.ID_POS].astype(float)
+            for j in range(self.problem.n_dims):
+                if pos_new[j] < self.problem.lb[j] or pos_new[j] > self.problem.ub[j]:
+                    if np.random.random() <= 0.5:
+                        pos_new[j] = self.g_best[self.ID_POS][j] + np.random.randn() / (epoch + 1) * \
+                                                     (self.g_best[self.ID_POS][j] - pos_new[j])
+                        if pos_new[j] < self.problem.lb[j] or pos_new[j] > self.problem.ub[j]:
+                            pos_new[j] = self.pop[idx][self.ID_POS][j]
+                    else:
+                        if pos_new[j] < self.problem.lb[j]:
+                            pos_new[j] = self.problem.lb[j]
+                        if pos_new[j] > self.problem.ub[j]:
+                            pos_new[j] = self.problem.ub[j]
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new[idx][self.ID_POS] = pos_new
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[idx][self.ID_TAR] = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution(pop_new[idx], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+        self.pop = self.update_weight__(self.pop)
+
+
+class OppoTWO(OriginalTWO):
+    """
+    The opossition-based learning version: Tug of War Optimization (OTWO)
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.physics_based.TWO import OppoTWO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OppoTWO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(epoch, pop_size, **kwargs)
+
+    def initialization(self):
+        if self.pop is None:
+            self.pop = self.create_population(self.pop_size)
+        list_idx = np.random.choice(range(0, self.pop_size), int(self.pop_size/2), replace=False)
+        pop_temp = [self.pop[list_idx[idx]] for idx in range(0, int(self.pop_size/2))]
+        pop_oppo = []
+        for i in range(len(pop_temp)):
+            pos_opposite = self.problem.ub + self.problem.lb - pop_temp[i][self.ID_POS]
+            pos_opposite = self.amend_position(pos_opposite, self.problem.lb, self.problem.ub)
+            pop_oppo.append([pos_opposite, None, 0.0])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_oppo[-1][self.ID_TAR] = self.get_target_wrapper(pos_opposite)
+        pop_oppo = self.update_target_wrapper_population(pop_oppo)
+        self.pop = pop_temp + pop_oppo
+        self.pop = self.update_weight__(self.pop)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        ## Apply force of others solution on each individual solution
+        pop_new = deepcopy(self.pop)
+        for idx in range(self.pop_size):
+            pos_new = pop_new[idx][self.ID_POS].astype(float)
+            for j in range(self.pop_size):
+                if self.pop[idx][self.ID_WEIGHT] < self.pop[j][self.ID_WEIGHT]:
+                    force = max(self.pop[idx][self.ID_WEIGHT] * self.muy_s, self.pop[j][self.ID_WEIGHT] * self.muy_s)
+                    resultant_force = force - self.pop[idx][self.ID_WEIGHT] * self.muy_k
+                    g = self.pop[j][self.ID_POS] - self.pop[idx][self.ID_POS]
+                    temp = (self.pop[idx][self.ID_WEIGHT] * self.muy_k)
+                    acceleration = resultant_force * g / temp
+                    delta_x = 1 / 2 * acceleration + np.power(self.alpha, epoch + 1) * self.beta * \
+                              (self.problem.ub - self.problem.lb) * np.random.normal(0, 1, self.problem.n_dims)
+                    pos_new += delta_x
+            self.pop[idx][self.ID_POS] = pos_new
+
+        ## Amend solution and update fitness value
+        for idx in range(self.pop_size):
+            pos_new = self.g_best[self.ID_POS] + np.random.normal(0, 1, self.problem.n_dims) / (epoch + 1) * \
+                      (self.g_best[self.ID_POS] - pop_new[idx][self.ID_POS])
+            conditions = np.logical_or(pop_new[idx][self.ID_POS] < self.problem.lb, pop_new[idx][self.ID_POS] > self.problem.ub)
+            conditions = np.logical_and(conditions, np.random.random(self.problem.n_dims) < 0.5)
+            pos_new = np.where(conditions, pos_new, self.pop[idx][self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new[idx][self.ID_POS] = pos_new
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[idx][self.ID_TAR] = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution(pop_new[idx], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+        ## Opposition-based here
+        pop = []
+        for idx in range(self.pop_size):
+            C_op = self.create_opposition_position(self.pop[idx][self.ID_POS], self.g_best[self.ID_POS])
+            pos_new = self.amend_position(C_op, self.problem.lb, self.problem.ub)
+            pop.append([pos_new, None, 0.0])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target, 0.0], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop = self.update_target_wrapper_population(pop)
+            self.pop = self.greedy_selection_population(self.pop, pop)
+        self.pop = self.update_weight__(self.pop)
+
+
+class LevyTWO(OriginalTWO):
+    """
+    The Levy-flight version of: Tug of War Optimization (LevyTWO)
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.physics_based.TWO import LevyTWO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = LevyTWO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(epoch, pop_size, **kwargs)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = deepcopy(self.pop)
+        for i in range(self.pop_size):
+            pos_new = self.pop[i][self.ID_POS].astype(float)
+            for k in range(self.pop_size):
+                if self.pop[i][self.ID_WEIGHT] < self.pop[k][self.ID_WEIGHT]:
+                    force = max(self.pop[i][self.ID_WEIGHT] * self.muy_s, self.pop[k][self.ID_WEIGHT] * self.muy_s)
+                    resultant_force = force - self.pop[i][self.ID_WEIGHT] * self.muy_k
+                    g = self.pop[k][self.ID_POS] - self.pop[i][self.ID_POS]
+                    acceleration = resultant_force * g / (self.pop[i][self.ID_WEIGHT] * self.muy_k)
+                    delta_x = 1 / 2 * acceleration + np.power(self.alpha, epoch + 1) * self.beta * \
+                              (self.problem.ub - self.problem.lb) * np.random.normal(0, 1, self.problem.n_dims)
+                    pos_new +=delta_x
+            pop_new[i][self.ID_POS] = pos_new
+        for i in range(self.pop_size):
+            pos_new = self.pop[i][self.ID_POS].astype(float)
+            for j in range(self.problem.n_dims):
+                if pos_new[j] < self.problem.lb[j] or pos_new[j] > self.problem.ub[j]:
+                    if np.random.random() <= 0.5:
+                        pos_new[j] = self.g_best[self.ID_POS][j] + np.random.randn() / (epoch + 1) * \
+                                                     (self.g_best[self.ID_POS][j] - pos_new[j])
+                        if pos_new[j] < self.problem.lb[j] or pos_new[j] > self.problem.ub[j]:
+                            pos_new[j] = self.pop[i][self.ID_POS][j]
+                    else:
+                        if pos_new[j] < self.problem.lb[j]:
+                            pos_new[j] = self.problem.lb[j]
+                        if pos_new[j] > self.problem.ub[j]:
+                            pos_new[j] = self.problem.ub[j]
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new[i][self.ID_POS] = pos_new
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[i][self.ID_TAR] = self.get_target_wrapper(pos_new)
+                self.pop[i] = self.get_better_solution(pop_new[i], self.pop[i])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+        ### Apply levy-flight here
+        for i in range(self.pop_size):
+            ## Chance for each agent to update using levy is 50%
+            if np.random.rand() < 0.5:
+                levy_step = self.get_levy_flight_step(beta=1.0, multiplier=0.1, size=self.problem.n_dims, case=-1)
+                pos_new = pop_new[i][self.ID_POS] + levy_step
+                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                target = self.get_target_wrapper(pos_new)
+                if self.compare_agent([pos_new, target, 0.0], pop_new[i]):
+                    pop_new[i] = [pos_new, target, 0.0]
+        self.pop = self.update_weight__(pop_new)
+
+
+class EnhancedTWO(OppoTWO, LevyTWO):
+    """
+    The original version of: Enhenced Tug of War Optimization (ETWO)
+
+    Links:
+        1. https://doi.org/10.1016/j.procs.2020.03.063
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.physics_based.TWO import EnhancedTWO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = EnhancedTWO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Nguyen, T., Hoang, B., Nguyen, G. and Nguyen, B.M., 2020. A new workload prediction model using
+    extreme learning machine and enhanced tug of war optimization. Procedia Computer Science, 170, pp.362-369.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(epoch, pop_size, **kwargs)
+
+    def initialization(self):
+        if self.pop is None:
+            self.pop = self.create_population(self.pop_size)
+        pop_oppo = deepcopy(self.pop)
+        for i in range(self.pop_size):
+            pos_opposite = self.problem.ub + self.problem.lb - self.pop[i][self.ID_POS]
+            pos_new = self.amend_position(pos_opposite, self.problem.lb, self.problem.ub)
+            pop_oppo[i][self.ID_POS] = pos_new
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_oppo[i][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop_oppo = self.update_target_wrapper_population(pop_oppo)
+        self.pop = self.get_sorted_strim_population(self.pop + pop_oppo, self.pop_size)
+        self.pop = self.update_weight__(self.pop)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = deepcopy(self.pop)
+        for i in range(self.pop_size):
+            pos_new = self.pop[i][self.ID_POS].astype(float)
+            for k in range(self.pop_size):
+                if self.pop[i][self.ID_WEIGHT] < self.pop[k][self.ID_WEIGHT]:
+                    force = max(self.pop[i][self.ID_WEIGHT] * self.muy_s, self.pop[k][self.ID_WEIGHT] * self.muy_s)
+                    resultant_force = force - self.pop[i][self.ID_WEIGHT] * self.muy_k
+                    g = self.pop[k][self.ID_POS] - self.pop[i][self.ID_POS]
+                    acceleration = resultant_force * g / (self.pop[i][self.ID_WEIGHT] * self.muy_k)
+                    delta_x = 1 / 2 * acceleration + np.power(self.alpha, epoch + 1) * self.beta * \
+                              (self.problem.ub - self.problem.lb) * np.random.normal(0, 1, self.problem.n_dims)
+                    pos_new += delta_x
+            pop_new[i][self.ID_POS] = pos_new
+        for i in range(self.pop_size):
+            pos_new = self.pop[i][self.ID_POS].astype(float)
+            for j in range(self.problem.n_dims):
+                if pos_new[j] < self.problem.lb[j] or pos_new[j] > self.problem.ub[j]:
+                    if np.random.random() <= 0.5:
+                        pos_new[j] = self.g_best[self.ID_POS][j] + np.random.randn() / (epoch + 1) * \
+                                                     (self.g_best[self.ID_POS][j] - pos_new[j])
+                        if pos_new[j] < self.problem.lb[j] or pos_new[j] > self.problem.ub[j]:
+                            pos_new[j] = self.pop[i][self.ID_POS][j]
+                    else:
+                        if pos_new[j] < self.problem.lb[j]:
+                            pos_new[j] = self.problem.lb[j]
+                        if pos_new[j] > self.problem.ub[j]:
+                            pos_new[j] = self.problem.ub[j]
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new[i][self.ID_POS] = pos_new
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[i][self.ID_TAR] = self.get_target_wrapper(pos_new)
+                self.pop[i] = self.get_better_solution(pop_new[i], self.pop[i])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+        for i in range(self.pop_size):
+            C_op = self.create_opposition_position(pop_new[i][self.ID_POS], self.g_best[self.ID_POS])
+            C_op = self.amend_position(C_op, self.problem.lb, self.problem.ub)
+            target_op = self.get_target_wrapper(C_op)
+            if self.compare_agent([C_op, target_op], pop_new[i]):
+                pop_new[i] = [C_op, target_op, 0.0]
+            else:
+                levy_step = self.get_levy_flight_step(beta=1.0, multiplier=1.0, size=self.problem.n_dims, case=-1)
+                pos_new = pop_new[i][self.ID_POS] + 1.0 / np.sqrt(epoch + 1) * levy_step
+                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                target = self.get_target_wrapper(pos_new)
+                if self.compare_agent([pos_new, target], pop_new[i]):
+                    pop_new[i] = [pos_new, target, 0.0]
+        self.pop = self.update_weight__(pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/physics_based/WDO.py` & `mealpy-2.5.3a1/mealpy/swarm_based/FFA.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,115 +1,120 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 21:18, 17/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalWDO(Optimizer):
-    """
-    The original version of: Wind Driven Optimization (WDO)
-
-    Links:
-        1. https://ieeexplore.ieee.org/abstract/document/6407788
-
-    Notes
-    ~~~~~
-    + pop is the set of "air parcel" - "position"
-    + air parcel: is the set of gas atoms. Each atom represents a dimension in position and has its own velocity
-    + pressure represented by fitness value
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + RT (int): [2, 3, 4], RT coefficient, default = 3
-        + g_c (float): [0.1, 0.5], gravitational constant, default = 0.2
-        + alp (float): [0.3, 0.8], constants in the update equation, default=0.4
-        + c_e (float): [0.1, 0.9], coriolis effect, default=0.4
-        + max_v (float): [0.1, 0.9], maximum allowed speed, default=0.3
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.physics_based.WDO import OriginalWDO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>>     "log_to": None,
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> RT = 3
-    >>> g_c = 0.2
-    >>> alp = 0.4
-    >>> c_e = 0.4
-    >>> max_v = 0.3
-    >>> model = OriginalWDO(epoch, pop_size, RT, g_c, alp, c_e, max_v)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Bayraktar, Z., Komurcu, M., Bossard, J.A. and Werner, D.H., 2013. The wind driven optimization
-    technique and its application in electromagnetics. IEEE transactions on antennas and
-    propagation, 61(5), pp.2745-2757.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, RT=3, g_c=0.2, alp=0.4, c_e=0.4, max_v=0.3, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            RT (int): RT coefficient, default = 3
-            g_c (float): gravitational constant, default = 0.2
-            alp (float): constants in the update equation, default=0.4
-            c_e (float): coriolis effect, default=0.4
-            max_v (float): maximum allowed speed, default=0.3
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.RT = self.validator.check_int("RT", RT, [1, 4])
-        self.g_c = self.validator.check_float("g_c", g_c, (0, 1.0))
-        self.alp = self.validator.check_float("alp", alp, (0, 1.0))
-        self.c_e = self.validator.check_float("c_e", c_e, (0, 1.0))
-        self.max_v = self.validator.check_float("max_v", max_v, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "RT", "g_c", "alp", "c_e", "max_v"])
-        self.sort_flag = False
-
-    def initialize_variables(self):
-        self.dyn_list_velocity = self.max_v * np.random.uniform(self.problem.lb, self.problem.ub, (self.pop_size, self.problem.n_dims))
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            rand_dim = np.random.randint(0, self.problem.n_dims)
-            temp = self.dyn_list_velocity[idx][rand_dim] * np.ones(self.problem.n_dims)
-            vel = (1 - self.alp) * self.dyn_list_velocity[idx] - self.g_c * self.pop[idx][self.ID_POS] + \
-                  (1 - 1.0 / (idx + 1)) * self.RT * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) + self.c_e * temp / (idx + 1)
-            vel = np.clip(vel, -self.max_v, self.max_v)
-
-            # Update air parcel positions, check the bound and calculate pressure (fitness)
-            self.dyn_list_velocity[idx] = vel
-            pos = self.pop[idx][self.ID_POS] + vel
-            pos_new = self.amend_position(pos, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(pop_new, self.pop)
+#!/usr/bin/env python
+# Created by "Thieu" at 17:13, 01/03/2021 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalFFA(Optimizer):
+    """
+    The original version of: Firefly Algorithm (FFA)
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + gamma (float): Light Absorption Coefficient, default = 0.001
+        + beta_base (float): Attraction Coefficient Base Value, default = 2
+        + alpha (float): Mutation Coefficient, default = 0.2
+        + alpha_damp (float): Mutation Coefficient Damp Rate, default = 0.99
+        + delta (float): Mutation Step Size, default = 0.05
+        + exponent (int): Exponent (m in the paper), default = 2
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.FFA import OriginalFFA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> gamma = 0.001
+    >>> beta_base = 2
+    >>> alpha = 0.2
+    >>> alpha_damp = 0.99
+    >>> delta = 0.05
+    >>> exponent = 2
+    >>> model = OriginalFFA(epoch, pop_size, gamma, beta_base, alpha, alpha_damp, delta, exponent)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Gandomi, A.H., Yang, X.S. and Alavi, A.H., 2011. Mixed variable structural optimization
+    using firefly algorithm. Computers & Structures, 89(23-24), pp.2325-2336.
+    [2] Arora, S. and Singh, S., 2013. The firefly optimization algorithm: convergence analysis and
+    parameter selection. International Journal of Computer Applications, 69(3).
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, gamma=0.001, beta_base=2, alpha=0.2, alpha_damp=0.99, delta=0.05, exponent=2, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            gamma (float): Light Absorption Coefficient, default = 0.001
+            beta_base (float): Attraction Coefficient Base Value, default = 2
+            alpha (float): Mutation Coefficient, default = 0.2
+            alpha_damp (float): Mutation Coefficient Damp Rate, default = 0.99
+            delta (float): Mutation Step Size, default = 0.05
+            exponent (int): Exponent (m in the paper), default = 2
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.gamma = self.validator.check_float("gamma", gamma, (0, 1.0))
+        self.beta_base = self.validator.check_float("beta_base", beta_base, (0, 3.0))
+        self.alpha = self.validator.check_float("alpha", alpha, (0, 1.0))
+        self.alpha_damp = self.validator.check_float("alpha_damp", alpha_damp, (0, 1.0))
+        self.delta = self.validator.check_float("delta", delta, (0, 1.0))
+        self.exponent = self.validator.check_int("exponent", exponent, [2, 4])
+        self.set_parameters(["epoch", "pop_size", "gamma", "beta_base", "alpha", "alpha_damp", "delta", "exponent"])
+        self.support_parallel_modes = False
+        self.sort_flag = False
+
+    def initialize_variables(self):
+        self.dyn_alpha = self.alpha  # Initial Value of Mutation Coefficient
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # Maximum Distance
+        dmax = np.sqrt(self.problem.n_dims)
+        for idx in range(0, self.pop_size):
+            agent = deepcopy(self.pop[idx])
+            pop_child = []
+            for j in range(idx + 1, self.pop_size):
+                # Move Towards Better Solutions
+                if self.compare_agent(self.pop[j], agent):
+                    # Calculate Radius and Attraction Level
+                    rij = np.linalg.norm(agent[self.ID_POS] - self.pop[j][self.ID_POS]) / dmax
+                    beta = self.beta_base * np.exp(-self.gamma * rij ** self.exponent)
+                    # Mutation Vector
+                    mutation_vector = self.delta * np.random.uniform(0, 1, self.problem.n_dims)
+                    temp = np.matmul((self.pop[j][self.ID_POS] - agent[self.ID_POS]),
+                                     np.random.uniform(0, 1, (self.problem.n_dims, self.problem.n_dims)))
+                    pos_new = agent[self.ID_POS] + self.dyn_alpha * mutation_vector + beta * temp
+                    pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                    target = self.get_target_wrapper(pos_new)
+                    pop_child.append([pos_new, target])
+            if len(pop_child) < self.pop_size:
+                pop_child += self.create_population(self.pop_size - len(pop_child))
+            _, local_best = self.get_global_best_solution(pop_child)
+            # Compare to Previous Solution
+            if self.compare_agent(local_best, agent):
+                self.pop[idx] = local_best
+        self.pop.append(self.g_best)
+        self.dyn_alpha = self.alpha_damp * self.alpha
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/ABC.py` & `mealpy-2.5.3a1/mealpy/swarm_based/ABC.py`

 * *Ordering differences only*

 * *Files 8% similar despite different names*

```diff
@@ -1,112 +1,112 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 09:57, 17/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalABC(Optimizer):
-    """
-    The original version of: Artificial Bee Colony (ABC)
-
-    Links:
-        1. https://www.sciencedirect.com/topics/computer-science/artificial-bee-colony
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + n_limits (int): Limit of trials before abandoning a food source, default=25
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.ABC import OriginalABC
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> n_limits = 50
-    >>> model = OriginalABC(epoch, pop_size, n_limits)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] B. Basturk, D. Karaboga, An artificial bee colony (ABC) algorithm for numeric function optimization,
-    in: IEEE Swarm Intelligence Symposium 2006, May 12â14, Indianapolis, IN, USA, 2006.
-    """
-    def __init__(self, epoch=10000, pop_size=100, n_limits=25, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size = onlooker bees = employed bees, default = 100
-            n_limits (int): Limit of trials before abandoning a food source, default=25
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.n_limits = self.validator.check_int("n_limits", n_limits, [1, 1000])
-        self.support_parallel_modes = False
-        self.set_parameters(["epoch", "pop_size", "n_limits"])
-        self.sort_flag = False
-
-    def initialize_variables(self):
-        self.trials = np.zeros(self.pop_size)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        for idx in range(0, self.pop_size):
-            # Choose a random employed bee to generate a new solution
-            t = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
-            # Generate a new solution by the equation x_{ij} = x_{ij} + phi_{ij} * (x_{tj} - x_{ij})
-            phi = np.random.uniform(low=-1, high=1, size=self.problem.n_dims)
-            pos_new = self.pop[idx][self.ID_POS] + phi * (self.pop[t][self.ID_POS] - self.pop[idx][self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            target = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, target], self.pop[idx]):
-                self.pop[idx] = [pos_new, target]
-                self.trials[idx] = 0
-            else:
-                self.trials[idx] += 1
-
-        # Onlooker bees phase
-        # Calculate the probabilities of each employed bee
-        employed_fits = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in self.pop])
-        # probabilities = employed_fits / np.sum(employed_fits)
-        for idx in range(0, self.pop_size):
-            # Select an employed bee using roulette wheel selection
-            selected_bee = self.get_index_roulette_wheel_selection(employed_fits)
-            # Choose a random employed bee to generate a new solution
-            t = np.random.choice(list(set(range(0, self.pop_size)) - {idx, selected_bee}))
-            # Generate a new solution by the equation x_{ij} = x_{ij} + phi_{ij} * (x_{tj} - x_{ij})
-            phi = np.random.uniform(low=-1, high=1, size=self.problem.n_dims)
-            pos_new = self.pop[selected_bee][self.ID_POS] + phi * (self.pop[t][self.ID_POS] - self.pop[selected_bee][self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            target = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, target], self.pop[selected_bee]):
-                self.pop[selected_bee] = [pos_new, target]
-                self.trials[selected_bee] = 0
-            else:
-                self.trials[selected_bee] += 1
-
-        # Scout bees phase
-        # Check the number of trials for each employed bee and abandon the food source if the limit is exceeded
-        abandoned = np.where(self.trials >= self.n_limits)[0]
-        for idx in abandoned:
-            self.pop[idx] = self.create_solution(self.problem.lb, self.problem.ub)
-            self.trials[idx] = 0
+#!/usr/bin/env python
+# Created by "Thieu" at 09:57, 17/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalABC(Optimizer):
+    """
+    The original version of: Artificial Bee Colony (ABC)
+
+    Links:
+        1. https://www.sciencedirect.com/topics/computer-science/artificial-bee-colony
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + n_limits (int): Limit of trials before abandoning a food source, default=25
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.ABC import OriginalABC
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> n_limits = 50
+    >>> model = OriginalABC(epoch, pop_size, n_limits)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] B. Basturk, D. Karaboga, An artificial bee colony (ABC) algorithm for numeric function optimization,
+    in: IEEE Swarm Intelligence Symposium 2006, May 12â14, Indianapolis, IN, USA, 2006.
+    """
+    def __init__(self, epoch=10000, pop_size=100, n_limits=25, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size = onlooker bees = employed bees, default = 100
+            n_limits (int): Limit of trials before abandoning a food source, default=25
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.n_limits = self.validator.check_int("n_limits", n_limits, [1, 1000])
+        self.support_parallel_modes = False
+        self.set_parameters(["epoch", "pop_size", "n_limits"])
+        self.sort_flag = False
+
+    def initialize_variables(self):
+        self.trials = np.zeros(self.pop_size)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        for idx in range(0, self.pop_size):
+            # Choose a random employed bee to generate a new solution
+            t = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
+            # Generate a new solution by the equation x_{ij} = x_{ij} + phi_{ij} * (x_{tj} - x_{ij})
+            phi = np.random.uniform(low=-1, high=1, size=self.problem.n_dims)
+            pos_new = self.pop[idx][self.ID_POS] + phi * (self.pop[t][self.ID_POS] - self.pop[idx][self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            target = self.get_target_wrapper(pos_new)
+            if self.compare_agent([pos_new, target], self.pop[idx]):
+                self.pop[idx] = [pos_new, target]
+                self.trials[idx] = 0
+            else:
+                self.trials[idx] += 1
+
+        # Onlooker bees phase
+        # Calculate the probabilities of each employed bee
+        employed_fits = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in self.pop])
+        # probabilities = employed_fits / np.sum(employed_fits)
+        for idx in range(0, self.pop_size):
+            # Select an employed bee using roulette wheel selection
+            selected_bee = self.get_index_roulette_wheel_selection(employed_fits)
+            # Choose a random employed bee to generate a new solution
+            t = np.random.choice(list(set(range(0, self.pop_size)) - {idx, selected_bee}))
+            # Generate a new solution by the equation x_{ij} = x_{ij} + phi_{ij} * (x_{tj} - x_{ij})
+            phi = np.random.uniform(low=-1, high=1, size=self.problem.n_dims)
+            pos_new = self.pop[selected_bee][self.ID_POS] + phi * (self.pop[t][self.ID_POS] - self.pop[selected_bee][self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            target = self.get_target_wrapper(pos_new)
+            if self.compare_agent([pos_new, target], self.pop[selected_bee]):
+                self.pop[selected_bee] = [pos_new, target]
+                self.trials[selected_bee] = 0
+            else:
+                self.trials[selected_bee] += 1
+
+        # Scout bees phase
+        # Check the number of trials for each employed bee and abandon the food source if the limit is exceeded
+        abandoned = np.where(self.trials >= self.n_limits)[0]
+        for idx in abandoned:
+            self.pop[idx] = self.create_solution(self.problem.lb, self.problem.ub)
+            self.trials[idx] = 0
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/ACOR.py` & `mealpy-2.5.3a1/mealpy/swarm_based/ACOR.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,108 +1,108 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 14:14, 01/03/2021 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalACOR(Optimizer):
-    """
-    The original version of: Ant Colony Optimization Continuous (ACOR)
-
-    Notes
-    ~~~~~
-    + Use Gaussian Distribution (np.random.normal() function) instead of random number (np.random.rand())
-    + Amend solution when they went out of space
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + sample_count (int): [2, 10000], Number of Newly Generated Samples, default = 25
-        + intent_factor (float): [0.2, 1.0], Intensification Factor (Selection Pressure), (q in the paper), default = 0.5
-        + zeta (float): [1, 2, 3], Deviation-Distance Ratio, default = 1
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.ACOR import OriginalACOR
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> sample_count = 25
-    >>> intent_factor = 0.5
-    >>> zeta = 1.0
-    >>> model = OriginalACOR(epoch, pop_size, sample_count, intent_factor, zeta)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Socha, K. and Dorigo, M., 2008. Ant colony optimization for continuous domains.
-    European journal of operational research, 185(3), pp.1155-1173.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, sample_count=25, intent_factor=0.5, zeta=1.0, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            sample_count (int): Number of Newly Generated Samples, default = 25
-            intent_factor (float): Intensification Factor (Selection Pressure) (q in the paper), default = 0.5
-            zeta (float): Deviation-Distance Ratio, default = 1.0
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.sample_count = self.validator.check_int("sample_count", sample_count, [2, 10000])
-        self.intent_factor = self.validator.check_float("intent_factor", intent_factor, (0, 1.0))
-        self.zeta = self.validator.check_float("zeta", zeta, (0, 5))
-        self.set_parameters(["epoch", "pop_size", "sample_count", "intent_factor", "zeta"])
-        self.sort_flag = True
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # Calculate Selection Probabilities
-        pop_rank = np.array([i for i in range(1, self.pop_size + 1)])
-        qn = self.intent_factor * self.pop_size
-        matrix_w = 1 / (np.sqrt(2 * np.pi) * qn) * np.exp(-0.5 * ((pop_rank - 1) / qn) ** 2)
-        matrix_p = matrix_w / np.sum(matrix_w)  # Normalize to find the probability.
-
-        # Means and Standard Deviations
-        matrix_pos = np.array([solution[self.ID_POS] for solution in self.pop])
-        matrix_sigma = []
-        for i in range(0, self.pop_size):
-            matrix_i = np.repeat(self.pop[i][self.ID_POS].reshape((1, -1)), self.pop_size, axis=0)
-            D = np.sum(np.abs(matrix_pos - matrix_i), axis=0)
-            temp = self.zeta * D / (self.pop_size - 1)
-            matrix_sigma.append(temp)
-        matrix_sigma = np.array(matrix_sigma)
-
-        # Generate Samples
-        pop_new = []
-        for i in range(0, self.sample_count):
-            child = np.zeros(self.problem.n_dims)
-            for j in range(0, self.problem.n_dims):
-                idx = self.get_index_roulette_wheel_selection(matrix_p)
-                child[j] = self.pop[idx][self.ID_POS][j] + np.random.normal() * matrix_sigma[idx, j]  # (1)
-            pos_new = self.amend_position(child, self.problem.lb, self.problem.ub)  # (2)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop_new = self.update_target_wrapper_population(pop_new)
-        self.pop = self.get_sorted_strim_population(self.pop + pop_new, self.pop_size)
+#!/usr/bin/env python
+# Created by "Thieu" at 14:14, 01/03/2021 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalACOR(Optimizer):
+    """
+    The original version of: Ant Colony Optimization Continuous (ACOR)
+
+    Notes
+    ~~~~~
+    + Use Gaussian Distribution instead of random number (np.random.normal() function)
+    + Amend solution when they went out of space
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + sample_count (int): [2, 10000], Number of Newly Generated Samples, default = 25
+        + intent_factor (float): [0.2, 1.0], Intensification Factor (Selection Pressure), (q in the paper), default = 0.5
+        + zeta (float): [1, 2, 3], Deviation-Distance Ratio, default = 1
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.ACOR import OriginalACOR
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> sample_count = 25
+    >>> intent_factor = 0.5
+    >>> zeta = 1.0
+    >>> model = OriginalACOR(epoch, pop_size, sample_count, intent_factor, zeta)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Socha, K. and Dorigo, M., 2008. Ant colony optimization for continuous domains.
+    European journal of operational research, 185(3), pp.1155-1173.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, sample_count=25, intent_factor=0.5, zeta=1.0, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            sample_count (int): Number of Newly Generated Samples, default = 25
+            intent_factor (float): Intensification Factor (Selection Pressure) (q in the paper), default = 0.5
+            zeta (float): Deviation-Distance Ratio, default = 1.0
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.sample_count = self.validator.check_int("sample_count", sample_count, [2, 10000])
+        self.intent_factor = self.validator.check_float("intent_factor", intent_factor, (0, 1.0))
+        self.zeta = self.validator.check_float("zeta", zeta, (0, 5))
+        self.set_parameters(["epoch", "pop_size", "sample_count", "intent_factor", "zeta"])
+        self.sort_flag = True
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # Calculate Selection Probabilities
+        pop_rank = np.array([i for i in range(1, self.pop_size + 1)])
+        qn = self.intent_factor * self.pop_size
+        matrix_w = 1 / (np.sqrt(2 * np.pi) * qn) * np.exp(-0.5 * ((pop_rank - 1) / qn) ** 2)
+        matrix_p = matrix_w / np.sum(matrix_w)  # Normalize to find the probability.
+
+        # Means and Standard Deviations
+        matrix_pos = np.array([solution[self.ID_POS] for solution in self.pop])
+        matrix_sigma = []
+        for i in range(0, self.pop_size):
+            matrix_i = np.repeat(self.pop[i][self.ID_POS].reshape((1, -1)), self.pop_size, axis=0)
+            D = np.sum(np.abs(matrix_pos - matrix_i), axis=0)
+            temp = self.zeta * D / (self.pop_size - 1)
+            matrix_sigma.append(temp)
+        matrix_sigma = np.array(matrix_sigma)
+
+        # Generate Samples
+        pop_new = []
+        for i in range(0, self.sample_count):
+            child = np.zeros(self.problem.n_dims)
+            for j in range(0, self.problem.n_dims):
+                idx = self.get_index_roulette_wheel_selection(matrix_p)
+                child[j] = self.pop[idx][self.ID_POS][j] + np.random.normal() * matrix_sigma[idx, j]  # (1)
+            pos_new = self.amend_position(child, self.problem.lb, self.problem.ub)  # (2)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop_new = self.update_target_wrapper_population(pop_new)
+        self.pop = self.get_sorted_strim_population(self.pop + pop_new, self.pop_size)
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/AGTO.py` & `mealpy-2.5.3a1/mealpy/human_based/LCO.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,245 +1,284 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 00:08, 27/10/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalAGTO(Optimizer):
-    """
-    The original version of: Artificial Gorilla Troops Optimization (AGTO)
-
-    Links:
-        1. https://doi.org/10.1002/int.22535
-        2. https://www.mathworks.com/matlabcentral/fileexchange/95953-artificial-gorilla-troops-optimizer
-
-    Notes (parameters):
-        1. p1 (float): the probability of transition in exploration phase (p in the paper), default = 0.03
-        2. p2 (float): the probability of transition in exploitation phase (w in the paper), default = 0.8
-        3. beta (float): coefficient in updating equation, should be in [-5.0, 5.0], default = 3.0
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.AGTO import OriginalAGTO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalAGTO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Abdollahzadeh, B., Soleimanian Gharehchopogh, F., & Mirjalili, S. (2021). Artificial gorilla troops optimizer: a new
-    natureâinspired metaheuristic algorithm for global optimization problems. International Journal of Intelligent Systems, 36(10), 5887-5958.
-    """
-    def __init__(self, epoch=10000, pop_size=100, p1=0.03, p2=0.8, beta=3.0, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.p1 = self.validator.check_float("p1", p1, (0, 1))      # p in the paper
-        self.p2 = self.validator.check_float("p2", p2, (0, 1))      # w in the paper
-        self.beta = self.validator.check_float("beta", beta, [-10.0, 10.0])
-        self.set_parameters(["epoch", "pop_size", "p1", "p2", "beta"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        a = (np.cos(2*np.random.rand())+1) * (1 - (epoch+1)/self.epoch)
-        c = a * (2 * np.random.rand() - 1)
-
-        ## Exploration
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            if np.random.rand() < self.p1:
-                pos_new = self.generate_position(self.problem.lb, self.problem.ub)
-            else:
-                if np.random.rand() >= 0.5:
-                    z = np.random.uniform(-a, a, self.problem.n_dims)
-                    rand_idx = np.random.randint(0, self.pop_size)
-                    pos_new = (np.random.rand() - a) * self.pop[rand_idx][self.ID_POS] + c * z * self.pop[idx][self.ID_POS]
-                else:
-                    id1, id2 = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 2, replace=False)
-                    pos_new = self.pop[idx][self.ID_POS] - c*(c*self.pop[idx][self.ID_POS] - self.pop[id1][self.ID_POS]) + \
-                        np.random.rand() * (self.pop[idx][self.ID_POS] - self.pop[id2][self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-        _, self.g_best = self.update_global_best_solution(self.pop, save=False)
-
-        pos_list = np.array([agent[self.ID_POS] for agent in self.pop])
-        ## Exploitation
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            if a >= self.p2:
-                g = 2 ** c
-                delta = (np.abs(np.mean(pos_list, axis=0)) ** g) ** (1.0 / g)
-                pos_new = c*delta*(self.pop[idx][self.ID_POS] - self.g_best[self.ID_POS]) + self.pop[idx][self.ID_POS]
-            else:
-                if np.random.rand() >= 0.5:
-                    h = np.random.normal(0, 1, self.problem.n_dims)
-                else:
-                    h = np.random.normal(0, 1)
-                r1 = np.random.rand()
-                pos_new = self.g_best[self.ID_POS] - (2*r1-1)*(self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) * (self.beta * h)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-
-class MGTO(Optimizer):
-    """
-    The original version of: Modified Gorilla Troops Optimization (mGTO)
-
-    Notes (parameters):
-        1. pp (float): the probability of transition in exploration phase (p in the paper), default = 0.03
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.AGTO import MGTO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalAGTO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Mostafa, R. R., Gaheen, M. A., Abd ElAziz, M., Al-Betar, M. A., & Ewees, A. A. (2023). An improved gorilla
-    troops optimizer for global optimization problems and feature selection. Knowledge-Based Systems, 110462.
-    """
-    def __init__(self, epoch=10000, pop_size=100, pp=0.03,  **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            pp (float): the probability of transition in exploration phase (p in the paper), default = 0.03
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.pp = self.validator.check_float("p1", pp, (0, 1))      # p in the paper
-        self.set_parameters(["epoch", "pop_size", "pp"])
-        self.sort_flag = False
-
-    def amend_position(self, position=None, lb=None, ub=None):
-        condition = np.logical_and(lb <= position, position <= ub)
-        random_pos = np.random.uniform(lb, ub)
-        return np.where(condition, position, random_pos)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        F = 1 + np.cos(2 * np.random.rand())
-        C = F * (1 - (epoch+1) / self.epoch)
-        L = C * np.random.choice([-1, 1])
-
-        ## Elite opposition-based learning
-        pos_list = np.array([agent[self.ID_POS] for agent in self.pop])
-        d_lb, d_ub = np.min(pos_list, axis=0), np.max(pos_list, axis=0)
-        pos_list = d_lb + d_ub - pos_list
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            pos_new = self.amend_position(pos_list[idx], self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-        self.pop = pop_new
-        _, self.g_best = self.update_global_best_solution(self.pop, save=False)
-
-        ## Exploration
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            if np.random.rand() < self.pp:
-                pos_new = self.generate_position(self.problem.lb, self.problem.ub)
-            else:
-                if np.random.rand() >= 0.5:
-                    rand_idx = np.random.randint(0, self.pop_size)
-                    pos_new = (np.random.rand() - C) * self.pop[rand_idx][self.ID_POS] + L * np.random.uniform(-C, C) * self.pop[idx][self.ID_POS]
-                else:
-                    id1, id2 = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 2, replace=False)
-                    pos_new = self.pop[idx][self.ID_POS] - L*(L*self.pop[idx][self.ID_POS] - self.pop[id1][self.ID_POS]) + \
-                        np.random.rand() * (self.pop[idx][self.ID_POS] - self.pop[id2][self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-        _, self.g_best = self.update_global_best_solution(self.pop, save=False)
-
-        pos_list = np.array([agent[self.ID_POS] for agent in self.pop])
-        ## Exploitation
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            if np.abs(C) >= 1:
-                g = np.random.choice([-0.5, 2])
-                M = (np.abs(np.mean(pos_list, axis=0)) ** g) ** (1.0 / g)
-                p = np.random.uniform(0, 1, self.problem.n_dims)
-                pos_new = L * M * (self.pop[idx][self.ID_POS] - self.g_best[self.ID_POS]) * (0.01 * np.tan(np.pi*( p - 0.5)))
-            else:
-                Q = 2 * np.random.rand() - 1
-                v = np.random.uniform(0, 1)
-                pos_new = self.g_best[self.ID_POS] - Q * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) * np.tan(v * np.pi/2)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 11:16, 18/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalLCO(Optimizer):
+    """
+    The original version of: Life Choice-based Optimization (LCO)
+
+    Links:
+        1. https://doi.org/10.1007/s00500-019-04443-z
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + r1 (float): [1.5, 4], coefficient factor, default = 2.35
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.LCO import OriginalLCO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> r1 = 2.35
+    >>> model = OriginalLCO(epoch, pop_size, r1)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Khatri, A., Gaba, A., Rana, K.P.S. and Kumar, V., 2020. A novel life choice-based optimizer. Soft Computing, 24(12), pp.9121-9141.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, r1=2.35, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            r1 (float): coefficient factor
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.r1 = self.validator.check_float("r1", r1, [1.0, 3.0])
+        self.set_parameters(["epoch", "pop_size", "r1"])
+        self.n_agents = int(np.ceil(np.sqrt(self.pop_size)))
+        self.sort_flag = True
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            prob = np.random.rand()
+            if prob > 0.875:  # Update using Eq. 1, update from n best position
+                temp = np.array([np.random.rand() * self.pop[j][self.ID_POS] for j in range(0, self.n_agents)])
+                temp = np.mean(temp, axis=0)
+            elif prob < 0.7:  # Update using Eq. 2-6
+                f1 = 1 - epoch / self.epoch
+                f2 = 1 - f1
+                prev_pos = self.g_best[self.ID_POS] if idx == 0 else self.pop[idx-1][self.ID_POS]
+                best_diff = f1 * self.r1 * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+                better_diff = f2 * self.r1 * (prev_pos - self.pop[idx][self.ID_POS])
+                temp = self.pop[idx][self.ID_POS] + np.random.rand() * better_diff + np.random.rand() * best_diff
+            else:
+                temp = self.problem.ub - (self.pop[idx][self.ID_POS] - self.problem.lb) * np.random.rand()
+            pos_new = self.amend_position(temp, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(pop_new, self.pop)
+
+
+class BaseLCO(OriginalLCO):
+    """
+    The developed version: Life Choice-based Optimization (LCO)
+
+    Notes
+    ~~~~~
+    The flow is changed with if else statement.
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + r1 (float): [1.5, 4], coefficient factor, default = 2.35
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.LCO import BaseLCO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> r1 = 2.35
+    >>> model = BaseLCO(epoch, pop_size, r1)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, r1=2.35, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            r1 (float): coefficient factor
+        """
+        super().__init__(epoch, pop_size, r1, **kwargs)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # epoch: current chance, self.epoch: number of chances
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            prob = np.random.rand()
+            if prob > 0.875:  # Update using Eq. 1, update from n best position
+                temp = np.array([np.random.rand() * self.pop[j][self.ID_POS] for j in range(0, self.n_agents)])
+                temp = np.mean(temp, axis=0)
+            elif prob < 0.7:  # Update using Eq. 2-6
+                f = (epoch + 1) / self.epoch
+                if idx != 0:
+                    better_diff = f * self.r1 * (self.pop[idx - 1][self.ID_POS] - self.pop[idx][self.ID_POS])
+                else:
+                    better_diff = f * self.r1 * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+                best_diff = (1 - f) * self.r1 * (self.pop[0][self.ID_POS] - self.pop[idx][self.ID_POS])
+                temp = self.pop[idx][self.ID_POS] + np.random.rand() * better_diff + np.random.rand() * best_diff
+            else:
+                temp = self.generate_position(self.problem.lb, self.problem.ub)
+            pos_new = self.amend_position(temp, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(pop_new, self.pop)
+
+
+class ImprovedLCO(Optimizer):
+    """
+    The improved version: Life Choice-based Optimization (ILCO)
+
+    Notes
+    ~~~~~
+    + The flow of the original LCO is kept.
+    + Gaussian distribution and mutation mechanism are added
+    + R1 parameter is removed
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.LCO import BaseLCO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = BaseLCO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.pop_len = int(self.pop_size / 2)
+        self.sort_flag = True
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # epoch: current chance, self.epoch: number of chances
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            rand = np.random.random()
+            if rand > 0.875:  # Update using Eq. 1, update from n best position
+                n = int(np.ceil(np.sqrt(self.pop_size)))
+                pos_new = np.array([np.random.rand() * self.pop[j][self.ID_POS] for j in range(0, n)])
+                pos_new = np.mean(pos_new, axis=0)
+            elif rand < 0.7:  # Update using Eq. 2-6
+                f = (epoch + 1) / self.epoch
+                if idx != 0:
+                    better_diff = f * np.random.rand() * (self.pop[idx - 1][self.ID_POS] - self.pop[idx][self.ID_POS])
+                else:
+                    better_diff = f * np.random.rand() * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+                best_diff = (1 - f) * np.random.rand() * (self.pop[0][self.ID_POS] - self.pop[idx][self.ID_POS])
+                pos_new = self.pop[idx][self.ID_POS] + better_diff + best_diff
+            else:
+                pos_new = self.problem.ub - (self.pop[idx][self.ID_POS] - self.problem.lb) * np.random.rand()
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(pop_new, self.pop)
+
+        ## Sort the updated population based on fitness
+        pop, local_best = self.get_global_best_solution(self.pop)
+        pop_s1, pop_s2 = pop[:self.pop_len], pop[self.pop_len:]
+
+        ## Mutation scheme
+        pop_child1 = []
+        for idx in range(0, self.pop_len):
+            pos_new = pop_s1[idx][self.ID_POS] + np.random.normal(0, 1, self.problem.n_dims) * pop_s1[idx][self.ID_POS]
+            # np.random.rand() * ((epoch+1) / self.epoch) * np.random.normal(0, 1, self.problem.n_dims)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_child1.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                pop_s1[idx] = self.get_better_solution([pos_new, target], pop_s1[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_child1 = self.update_target_wrapper_population(pop_child1)
+            pop_s1 = self.greedy_selection_population(pop_s1, pop_child1)
+
+        ## Search Mechanism
+        pos_s1_list = [item[self.ID_POS] for item in pop_s1]
+        pos_s1_mean = np.mean(pos_s1_list, axis=0)
+        pop_child2 = []
+        for idx in range(0, self.pop_len):
+            pos_new = local_best[self.ID_POS] + np.random.uniform(0, 1) * pos_s1_mean * ((epoch+1) / self.epoch)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_child2.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                pop_s2[idx] = self.get_better_solution(pop_s2[idx], [pos_new, target])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_child2 = self.update_target_wrapper_population(pop_s2)
+            pop_s2 = self.greedy_selection_population(pop_s2, pop_child2)
+        ## Construct a new population
+        self.pop = pop_s1 + pop_s2
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/ALO.py` & `mealpy-2.5.3a1/mealpy/swarm_based/ALO.py`

 * *Ordering differences only*

 * *Files 20% similar despite different names*

```diff
@@ -1,203 +1,203 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 12:01, 17/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalALO(Optimizer):
-    """
-    The original version of: Ant Lion Optimizer (ALO)
-
-    Links:
-        1. https://www.mathworks.com/matlabcentral/fileexchange/49920-ant-lion-optimizer-alo
-        2. https://dx.doi.org/10.1016/j.advengsoft.2015.01.010
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.ALO import OriginalALO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalALO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Mirjalili, S., 2015. The ant lion optimizer. Advances in engineering software, 83, pp.80-98.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = True
-
-    def random_walk_antlion__(self, solution, current_epoch):
-        I = 1  # I is the ratio in Equations (2.10) and (2.11)
-        if current_epoch > self.epoch / 10:
-            I = 1 + 100 * (current_epoch / self.epoch)
-        if current_epoch > self.epoch / 2:
-            I = 1 + 1000 * (current_epoch / self.epoch)
-        if current_epoch > self.epoch * (3 / 4):
-            I = 1 + 10000 * (current_epoch / self.epoch)
-        if current_epoch > self.epoch * 0.9:
-            I = 1 + 100000 * (current_epoch / self.epoch)
-        if current_epoch > self.epoch * 0.95:
-            I = 1 + 1000000 * (current_epoch / self.epoch)
-
-        # Decrease boundaries to converge towards antlion
-        lb = self.problem.lb / I  # Equation (2.10) in the paper
-        ub = self.problem.ub / I  # Equation (2.10) in the paper
-
-        # Move the interval of [lb ub] around the antlion [lb+anlion ub+antlion]
-        if np.random.rand() < 0.5:
-            lb = lb + solution  # Equation(2.8) in the paper
-        else:
-            lb = -lb + solution
-        if np.random.rand() < 0.5:
-            ub = ub + solution  # Equation(2.9) in the paper
-        else:
-            ub = -ub + solution
-
-        # This function creates n random walks and normalize according to lb and ub vectors,
-        temp = []
-        for k in range(0, self.problem.n_dims):
-            X = np.cumsum(2 * (np.random.rand(self.epoch, 1) > 0.5) - 1)
-            a = np.min(X)
-            b = np.max(X)
-            c = lb[k]  # [a b] - -->[c d]
-            d = ub[k]
-            X_norm = ((X - a) * (d - c)) / (b - a) + c  # Equation(2.7) in the paper
-            temp.append(X_norm)
-        return np.array(temp)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        list_fitness = np.array([item[self.ID_TAR][self.ID_FIT] for item in self.pop])
-        # This for loop simulate random walks
-
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            # Select ant lions based on their fitness (the better anlion the higher chance of catching ant)
-            rolette_index = self.get_index_roulette_wheel_selection(list_fitness)
-
-            # RA is the random walk around the selected antlion by rolette wheel
-            RA = self.random_walk_antlion__(self.pop[rolette_index][self.ID_POS], epoch)
-
-            # RE is the random walk around the elite (the best antlion so far)
-            RE = self.random_walk_antlion__(self.g_best[self.ID_POS], epoch)
-
-            temp = (RA[:, epoch] + RE[:, epoch]) / 2  # Equation(2.13) in the paper
-
-            # Bound checking (bring back the antlions of ants inside search space if they go beyonds the boundaries
-            pos_new = self.amend_position(temp, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop_new = self.update_target_wrapper_population(pop_new)
-
-        # Update antlion positions and fitnesses based on the ants (if an ant becomes fitter than an antlion
-        # we assume it was caught by the antlion and the antlion update goes to its position to build the trap)
-        self.pop = self.get_sorted_strim_population(self.pop + pop_new, self.pop_size)
-
-        # Keep the elite in the population
-        self.pop[-1] = deepcopy(self.g_best)
-
-
-class BaseALO(OriginalALO):
-    """
-    The developed version: Ant Lion Optimizer (ALO)
-
-    Notes
-    ~~~~~
-    + Improved performance by using matrix multiplication
-    + The flow of updating a new position is updated
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.ALO import BaseALO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = BaseALO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(epoch, pop_size, **kwargs)
-
-    def random_walk_antlion__(self, solution, current_epoch):
-        I = 1  # I is the ratio in Equations (2.10) and (2.11)
-        if current_epoch > self.epoch / 10:
-            I = 1 + 100 * (current_epoch / self.epoch)
-        if current_epoch > self.epoch / 2:
-            I = 1 + 1000 * (current_epoch / self.epoch)
-        if current_epoch > self.epoch * (3 / 4):
-            I = 1 + 10000 * (current_epoch / self.epoch)
-        if current_epoch > self.epoch * 0.9:
-            I = 1 + 100000 * (current_epoch / self.epoch)
-        if current_epoch > self.epoch * 0.95:
-            I = 1 + 1000000 * (current_epoch / self.epoch)
-
-        # Decrease boundaries to converge towards antlion
-        lb = self.problem.lb / I  # Equation (2.10) in the paper
-        ub = self.problem.ub / I  # Equation (2.10) in the paper
-
-        # Move the interval of [lb ub] around the antlion [lb+anlion ub+antlion]. Eq 2.8, 2.9
-        lb = lb + solution if np.random.rand() < 0.5 else -lb + solution
-        ub = ub + solution if np.random.rand() < 0.5 else -ub + solution
-
-        # This function creates n random walks and normalize according to lb and ub vectors,
-        ## Using matrix and vector for better performance
-        X = np.array([np.cumsum(2 * (np.random.rand(self.epoch, 1) > 0.5) - 1) for _ in range(0, self.problem.n_dims)])
-        a = np.min(X, axis=1)
-        b = np.max(X, axis=1)
-        temp1 = np.reshape((ub - lb) / (b - a), (self.problem.n_dims, 1))
-        temp0 = X - np.reshape(a, (self.problem.n_dims, 1))
-        X_norm = temp0 * temp1 + np.reshape(lb, (self.problem.n_dims, 1))
-        return X_norm
+#!/usr/bin/env python
+# Created by "Thieu" at 12:01, 17/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalALO(Optimizer):
+    """
+    The original version of: Ant Lion Optimizer (ALO)
+
+    Links:
+        1. https://www.mathworks.com/matlabcentral/fileexchange/49920-ant-lion-optimizer-alo
+        2. https://dx.doi.org/10.1016/j.advengsoft.2015.01.010
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.ALO import OriginalALO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalALO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Mirjalili, S., 2015. The ant lion optimizer. Advances in engineering software, 83, pp.80-98.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = True
+
+    def random_walk_antlion__(self, solution, current_epoch):
+        I = 1  # I is the ratio in Equations (2.10) and (2.11)
+        if current_epoch > self.epoch / 10:
+            I = 1 + 100 * (current_epoch / self.epoch)
+        if current_epoch > self.epoch / 2:
+            I = 1 + 1000 * (current_epoch / self.epoch)
+        if current_epoch > self.epoch * (3 / 4):
+            I = 1 + 10000 * (current_epoch / self.epoch)
+        if current_epoch > self.epoch * 0.9:
+            I = 1 + 100000 * (current_epoch / self.epoch)
+        if current_epoch > self.epoch * 0.95:
+            I = 1 + 1000000 * (current_epoch / self.epoch)
+
+        # Decrease boundaries to converge towards antlion
+        lb = self.problem.lb / I  # Equation (2.10) in the paper
+        ub = self.problem.ub / I  # Equation (2.10) in the paper
+
+        # Move the interval of [lb ub] around the antlion [lb+anlion ub+antlion]
+        if np.random.rand() < 0.5:
+            lb = lb + solution  # Equation(2.8) in the paper
+        else:
+            lb = -lb + solution
+        if np.random.rand() < 0.5:
+            ub = ub + solution  # Equation(2.9) in the paper
+        else:
+            ub = -ub + solution
+
+        # This function creates n random walks and normalize according to lb and ub vectors,
+        temp = []
+        for k in range(0, self.problem.n_dims):
+            X = np.cumsum(2 * (np.random.rand(self.epoch, 1) > 0.5) - 1)
+            a = np.min(X)
+            b = np.max(X)
+            c = lb[k]  # [a b] - -->[c d]
+            d = ub[k]
+            X_norm = ((X - a) * (d - c)) / (b - a) + c  # Equation(2.7) in the paper
+            temp.append(X_norm)
+        return np.array(temp)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        list_fitness = np.array([item[self.ID_TAR][self.ID_FIT] for item in self.pop])
+        # This for loop simulate random walks
+
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            # Select ant lions based on their fitness (the better anlion the higher chance of catching ant)
+            rolette_index = self.get_index_roulette_wheel_selection(list_fitness)
+
+            # RA is the random walk around the selected antlion by rolette wheel
+            RA = self.random_walk_antlion__(self.pop[rolette_index][self.ID_POS], epoch)
+
+            # RE is the random walk around the elite (the best antlion so far)
+            RE = self.random_walk_antlion__(self.g_best[self.ID_POS], epoch)
+
+            temp = (RA[:, epoch] + RE[:, epoch]) / 2  # Equation(2.13) in the paper
+
+            # Bound checking (bring back the antlions of ants inside search space if they go beyonds the boundaries
+            pos_new = self.amend_position(temp, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop_new = self.update_target_wrapper_population(pop_new)
+
+        # Update antlion positions and fitnesses based on the ants (if an ant becomes fitter than an antlion
+        # we assume it was caught by the antlion and the antlion update goes to its position to build the trap)
+        self.pop = self.get_sorted_strim_population(self.pop + pop_new, self.pop_size)
+
+        # Keep the elite in the population
+        self.pop[-1] = deepcopy(self.g_best)
+
+
+class BaseALO(OriginalALO):
+    """
+    The developed version: Ant Lion Optimizer (ALO)
+
+    Notes
+    ~~~~~
+    + Improved performance by using matrix multiplication
+    + The flow of updating a new position is updated
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.ALO import BaseALO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = BaseALO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(epoch, pop_size, **kwargs)
+
+    def random_walk_antlion__(self, solution, current_epoch):
+        I = 1  # I is the ratio in Equations (2.10) and (2.11)
+        if current_epoch > self.epoch / 10:
+            I = 1 + 100 * (current_epoch / self.epoch)
+        if current_epoch > self.epoch / 2:
+            I = 1 + 1000 * (current_epoch / self.epoch)
+        if current_epoch > self.epoch * (3 / 4):
+            I = 1 + 10000 * (current_epoch / self.epoch)
+        if current_epoch > self.epoch * 0.9:
+            I = 1 + 100000 * (current_epoch / self.epoch)
+        if current_epoch > self.epoch * 0.95:
+            I = 1 + 1000000 * (current_epoch / self.epoch)
+
+        # Decrease boundaries to converge towards antlion
+        lb = self.problem.lb / I  # Equation (2.10) in the paper
+        ub = self.problem.ub / I  # Equation (2.10) in the paper
+
+        # Move the interval of [lb ub] around the antlion [lb+anlion ub+antlion]. Eq 2.8, 2.9
+        lb = lb + solution if np.random.rand() < 0.5 else -lb + solution
+        ub = ub + solution if np.random.rand() < 0.5 else -ub + solution
+
+        # This function creates n random walks and normalize according to lb and ub vectors,
+        ## Using matrix and vector for better performance
+        X = np.array([np.cumsum(2 * (np.random.rand(self.epoch, 1) > 0.5) - 1) for _ in range(0, self.problem.n_dims)])
+        a = np.min(X, axis=1)
+        b = np.max(X, axis=1)
+        temp1 = np.reshape((ub - lb) / (b - a), (self.problem.n_dims, 1))
+        temp0 = X - np.reshape(a, (self.problem.n_dims, 1))
+        X_norm = temp0 * temp1 + np.reshape(lb, (self.problem.n_dims, 1))
+        return X_norm
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/AO.py` & `mealpy-2.5.3a1/mealpy/swarm_based/AO.py`

 * *Ordering differences only*

 * *Files 7% similar despite different names*

```diff
@@ -1,104 +1,104 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 15:53, 07/07/2021 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalAO(Optimizer):
-    """
-    The original version of: Aquila Optimization (AO)
-
-    Links:
-        1. https://doi.org/10.1016/j.cie.2021.107250
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.AO import OriginalAO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalAO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Abualigah, L., Yousri, D., Abd Elaziz, M., Ewees, A.A., Al-Qaness, M.A. and Gandomi, A.H., 2021.
-    Aquila optimizer: a novel meta-heuristic optimization algorithm. Computers & Industrial Engineering, 157, p.107250.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        alpha = delta = 0.1
-        g1 = 2 * np.random.rand() - 1  # Eq. 16
-        g2 = 2 * (1 - epoch / self.epoch)  # Eq. 17
-
-        dim_list = np.array(list(range(1, self.problem.n_dims + 1)))
-        miu = 0.00565
-        r0 = 10
-        r = r0 + miu * dim_list
-        w = 0.005
-        phi0 = 3 * np.pi / 2
-        phi = -w * dim_list + phi0
-        x = r * np.sin(phi)  # Eq.(9)
-        y = r * np.cos(phi)  # Eq.(10)
-        QF = (epoch + 1) ** ((2 * np.random.rand() - 1) / (1 - self.epoch) ** 2)  # Eq.(15)        Quality function
-
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            x_mean = np.mean(np.array([item[self.ID_TAR][self.ID_FIT] for item in self.pop]), axis=0)
-            levy_step = self.get_levy_flight_step(beta=1.5, multiplier=1.0, case=-1)
-            if (epoch + 1) <= (2 / 3) * self.epoch:  # Eq. 3, 4
-                if np.random.rand() < 0.5:
-                    pos_new = self.g_best[self.ID_POS] * (1 - (epoch + 1) / self.epoch) + \
-                              np.random.rand() * (x_mean - self.g_best[self.ID_POS])
-                else:
-                    idx = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
-                    pos_new = self.g_best[self.ID_POS] * levy_step + self.pop[idx][self.ID_POS] + np.random.rand() * (y - x)  # Eq. 5
-            else:
-                if np.random.rand() < 0.5:
-                    pos_new = alpha * (self.g_best[self.ID_POS] - x_mean) - np.random.rand() * \
-                              (np.random.rand() * (self.problem.ub - self.problem.lb) + self.problem.lb) * delta  # Eq. 13
-                else:
-                    pos_new = QF * self.g_best[self.ID_POS] - (g2 * self.pop[idx][self.ID_POS] * np.random.rand()) - \
-                              g2 * levy_step + np.random.rand() * g1  # Eq. 14
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 15:53, 07/07/2021 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalAO(Optimizer):
+    """
+    The original version of: Aquila Optimization (AO)
+
+    Links:
+        1. https://doi.org/10.1016/j.cie.2021.107250
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.AO import OriginalAO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalAO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Abualigah, L., Yousri, D., Abd Elaziz, M., Ewees, A.A., Al-Qaness, M.A. and Gandomi, A.H., 2021.
+    Aquila optimizer: a novel meta-heuristic optimization algorithm. Computers & Industrial Engineering, 157, p.107250.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        alpha = delta = 0.1
+        g1 = 2 * np.random.rand() - 1  # Eq. 16
+        g2 = 2 * (1 - epoch / self.epoch)  # Eq. 17
+
+        dim_list = np.array(list(range(1, self.problem.n_dims + 1)))
+        miu = 0.00565
+        r0 = 10
+        r = r0 + miu * dim_list
+        w = 0.005
+        phi0 = 3 * np.pi / 2
+        phi = -w * dim_list + phi0
+        x = r * np.sin(phi)  # Eq.(9)
+        y = r * np.cos(phi)  # Eq.(10)
+        QF = (epoch + 1) ** ((2 * np.random.rand() - 1) / (1 - self.epoch) ** 2)  # Eq.(15)        Quality function
+
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            x_mean = np.mean(np.array([item[self.ID_TAR][self.ID_FIT] for item in self.pop]), axis=0)
+            levy_step = self.get_levy_flight_step(beta=1.5, multiplier=1.0, case=-1)
+            if (epoch + 1) <= (2 / 3) * self.epoch:  # Eq. 3, 4
+                if np.random.rand() < 0.5:
+                    pos_new = self.g_best[self.ID_POS] * (1 - (epoch + 1) / self.epoch) + \
+                              np.random.rand() * (x_mean - self.g_best[self.ID_POS])
+                else:
+                    idx = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
+                    pos_new = self.g_best[self.ID_POS] * levy_step + self.pop[idx][self.ID_POS] + np.random.rand() * (y - x)  # Eq. 5
+            else:
+                if np.random.rand() < 0.5:
+                    pos_new = alpha * (self.g_best[self.ID_POS] - x_mean) - np.random.rand() * \
+                              (np.random.rand() * (self.problem.ub - self.problem.lb) + self.problem.lb) * delta  # Eq. 13
+                else:
+                    pos_new = QF * self.g_best[self.ID_POS] - (g2 * self.pop[idx][self.ID_POS] * np.random.rand()) - \
+                              g2 * levy_step + np.random.rand() * g1  # Eq. 14
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/ARO.py` & `mealpy-2.5.3a1/mealpy/swarm_based/SLO.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,277 +1,334 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 22:46, 26/10/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalARO(Optimizer):
-    """
-    The original version of: Artificial Rabbits Optimization (ARO)
-
-    Links:
-        1. https://doi.org/10.1016/j.engappai.2022.105082
-        2. https://www.mathworks.com/matlabcentral/fileexchange/110250-artificial-rabbits-optimization-aro
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.ARO import OriginalARO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalARO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Wang, L., Cao, Q., Zhang, Z., Mirjalili, S., & Zhao, W. (2022). Artificial rabbits optimization: A new bio-inspired
-    meta-heuristic algorithm for solving engineering optimization problems. Engineering Applications of Artificial Intelligence, 114, 105082.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        theta = 2 * (1 - (epoch+1)/self.epoch)
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            L = (np.exp(1) - np.exp((epoch / self.epoch)**2)) * (np.sin(2*np.pi*np.random.rand()))
-            temp = np.zeros(self.problem.n_dims)
-            rd_index = np.random.choice(np.arange(0, self.problem.n_dims), int(np.ceil(np.random.rand()*self.problem.n_dims)), replace=False)
-            temp[rd_index] = 1
-            R = L * temp        # Eq 2
-            A = 2 * np.log(1.0 / np.random.rand()) * theta      # Eq. 15
-            if A > 1:   # detour foraging strategy
-                rand_idx = np.random.randint(0, self.pop_size)
-                pos_new = self.pop[rand_idx][self.ID_POS] + R * (self.pop[idx][self.ID_POS] - self.pop[rand_idx][self.ID_POS]) + \
-                    np.round(0.5 * (0.05 + np.random.rand())) * np.random.normal(0, 1)      # Eq. 1
-            else:       # Random hiding stage
-                gr = np.zeros(self.problem.n_dims)
-                rd_index = np.random.choice(np.arange(0, self.problem.n_dims), int(np.ceil(np.random.rand() * self.problem.n_dims)), replace=False)
-                gr[rd_index] = 1        # Eq. 12
-                H = np.random.normal(0, 1) * (epoch / self.epoch)       # Eq. 8
-                b = self.pop[idx][self.ID_POS] + H * gr * self.pop[idx][self.ID_POS]        # Eq. 13
-                pos_new = self.pop[idx][self.ID_POS] + R * (np.random.rand() * b - self.pop[idx][self.ID_POS])      # Eq. 11
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-
-class LARO(Optimizer):
-    """
-    The improved version of:  LÃ©vy flight, and the selective opposition version of the artificial rabbit algorithm (LARO)
-
-    Links:
-        1. https://doi.org/10.3390/sym14112282
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.ARO import LARO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalARO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Wang, Y., Huang, L., Zhong, J., & Hu, G. (2022). LARO: Opposition-based learning boosted
-    artificial rabbits-inspired optimization algorithm with LÃ©vy flight. Symmetry, 14(11), 2282.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        theta = 2 * (1 - (epoch+1)/self.epoch)
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            L = (np.exp(1) - np.exp((epoch / self.epoch)**2)) * (np.sin(2*np.pi*np.random.rand()))
-            temp = np.zeros(self.problem.n_dims)
-            rd_index = np.random.choice(np.arange(0, self.problem.n_dims), int(np.ceil(np.random.rand()*self.problem.n_dims)), replace=False)
-            temp[rd_index] = 1
-            R = L * temp        # Eq 2
-            A = 2 * np.log(1.0 / np.random.rand()) * theta      # Eq. 15
-            if A > 1:   # # detour foraging strategy
-                rand_idx = np.random.randint(0, self.pop_size)
-                pos_new = self.pop[rand_idx][self.ID_POS] + R * (self.pop[idx][self.ID_POS] - self.pop[rand_idx][self.ID_POS]) + \
-                    np.round(0.5 * (0.05 + np.random.rand())) * np.random.normal(0, 1)      # Eq. 1
-            else:       # Random hiding stage
-                gr = np.zeros(self.problem.n_dims)
-                rd_index = np.random.choice(np.arange(0, self.problem.n_dims), int(np.ceil(np.random.rand() * self.problem.n_dims)), replace=False)
-                gr[rd_index] = 1        # Eq. 12
-                H = np.random.normal(0, 1) * (epoch / self.epoch)       # Eq. 8
-                b = self.pop[idx][self.ID_POS] + H * gr * self.pop[idx][self.ID_POS]        # Eq. 13
-                levy = self.get_levy_flight_step(beta=1.5, multiplier=0.1)
-                pos_new = self.pop[idx][self.ID_POS] + R * (levy * b - self.pop[idx][self.ID_POS])      # Eq. 11
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-        # Selective Opposition (SO) Strategy
-        TS = 2 - (2*(epoch+1) / self.epoch)
-        for idx in range(0, self.pop_size):
-            if self.pop[idx][self.ID_TAR][self.ID_FIT] != self.g_best[self.ID_TAR][self.ID_FIT]:
-                dd = np.abs(self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-                idx_far = np.sign(dd - TS) < 0
-                n_df = np.sum(idx_far)
-                n_dc = np.sum(np.sign(dd - TS) > 0)
-                src = 1 - 6*np.sum(dd**2) / np.dot(dd, (dd**2 - 1))
-                df_lb, df_ub = np.min(dd[idx_far]), np.max(dd[idx_far])
-                if src <= 0 and n_df > n_dc:
-                    pos_new = df_lb + df_ub - self.pop[idx][self.ID_POS]
-                    pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                    tar_new = self.get_target_wrapper(pos_new)
-                    if self.compare_agent([pos_new, tar_new], self.pop[idx]):
-                        self.pop[idx] = [pos_new, tar_new]
-
-
-class IARO(Optimizer):
-    """
-    The improved version of: Improved Artificial Rabbits Optimization (ARO)
-
-    Links:
-        1. https://doi.org/10.1016/j.engappai.2022.105082
-        2. https://www.mathworks.com/matlabcentral/fileexchange/110250-artificial-rabbits-optimization-aro
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.ARO import IARO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalARO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Wang, L., Cao, Q., Zhang, Z., Mirjalili, S., & Zhao, W. (2022). Artificial rabbits optimization: A new bio-inspired
-    meta-heuristic algorithm for solving engineering optimization problems. Engineering Applications of Artificial Intelligence, 114, 105082.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        theta = 2 * (1 - (epoch+1)/self.epoch)
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            L = (np.exp(1) - np.exp((epoch / self.epoch)**2)) * (np.sin(2*np.pi*np.random.rand()))
-            temp = np.zeros(self.problem.n_dims)
-            rd_index = np.random.choice(np.arange(0, self.problem.n_dims), int(np.ceil(np.random.rand()*self.problem.n_dims)), replace=False)
-            temp[rd_index] = 1
-            R = L * temp        # Eq 2
-            A = 2 * np.log(1.0 / np.random.rand()) * theta      # Eq. 15
-            if A > 1:   # # detour foraging strategy
-                rand_idx = np.random.randint(0, self.pop_size)
-                pos_new = self.pop[rand_idx][self.ID_POS] + R * (self.pop[idx][self.ID_POS] - self.pop[rand_idx][self.ID_POS]) + \
-                    np.round(0.5 * (0.05 + np.random.rand())) * np.random.normal(0, 1)      # Eq. 1
-            else:       # Random hiding stage
-                gr = np.zeros(self.problem.n_dims)
-                rd_index = np.random.choice(np.arange(0, self.problem.n_dims), int(np.ceil(np.random.rand() * self.problem.n_dims)), replace=False)
-                gr[rd_index] = 1        # Eq. 12
-                H = np.random.normal(0, 1) * (epoch / self.epoch)       # Eq. 8
-                b = self.pop[idx][self.ID_POS] + H * gr * self.pop[idx][self.ID_POS]        # Eq. 13
-                pos_new = self.pop[idx][self.ID_POS] + R * (np.random.rand() * b - self.pop[idx][self.ID_POS])      # Eq. 11
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 15:05, 03/06/2021 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from math import gamma
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalSLO(Optimizer):
+    """
+    The original version of: Sea Lion Optimization Algorithm (SLO)
+
+    Links:
+        1. https://www.researchgate.net/publication/333516932_Sea_Lion_Optimization_Algorithm
+        2. https://doi.org/10.14569/IJACSA.2019.0100548
+
+    Notes
+    ~~~~~
+    + There are some unclear equations and parameters in the original paper 
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.SLO import OriginalSLO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalSLO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Masadeh, R., Mahafzah, B.A. and Sharieh, A., 2019. Sea lion optimization algorithm. Sea, 10(5), p.388.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def amend_position(self, position=None, lb=None, ub=None):
+        """
+        Args:
+            position: vector position (location) of the solution.
+            lb: list of lower bound values
+            ub: list of upper bound values
+
+        Returns:
+            Amended position (make the position is in bound)
+        """
+        condition = np.logical_and(lb <= position, position <= ub)
+        pos_rand = np.random.uniform(lb, ub)
+        return np.where(condition, position, pos_rand)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        c = 2 - 2 * epoch / self.epoch
+        t0 = np.random.rand()
+        v1 = np.sin(2 * np.pi * t0)
+        v2 = np.sin(2 * np.pi * (1 - t0))
+        SP_leader = np.abs(v1 * (1 + v2) / v2)  # In the paper this is not clear how to calculate
+
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            if SP_leader < 0.25:
+                if c < 1:
+                    pos_new = self.g_best[self.ID_POS] - c * np.abs(2 * np.random.rand() *
+                                                                    self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+                else:
+                    ri = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))  # random index
+                    pos_new = self.pop[ri][self.ID_POS] - c * np.abs(2 * np.random.rand() *
+                                                                     self.pop[ri][self.ID_POS] - self.pop[idx][self.ID_POS])
+            else:
+                pos_new = np.abs(self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) * \
+                          np.cos(2 * np.pi * np.random.uniform(-1, 1)) + self.g_best[self.ID_POS]
+            # In the paper doesn't check also doesn't update old solution at this point
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+
+class ModifiedSLO(Optimizer):
+    """
+    The original version of: Modified Sea Lion Optimization (M-SLO)
+
+    Notes
+    ~~~~~
+    + Local best idea in PSO is inspired 
+    + Levy-flight technique is used 
+    + Shrink encircling idea is used 
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.SLO import ModifiedSLO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = ModifiedSLO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    ID_LOC_POS = 2
+    ID_LOC_FIT = 3
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        """
+        Overriding method in Optimizer class
+
+        Returns:
+            list: wrapper of solution with format [position, [target, [obj1, obj2, ...]], local_pos, local_fit]
+        """
+        ## Increase exploration at the first initial population using opposition-based learning.
+        if pos is None:
+            pos = self.generate_position(lb, ub)
+        position = self.amend_position(pos, lb, ub)
+        target = self.get_target_wrapper(position)
+        local_pos = lb + ub - position
+        local_pos = self.amend_position(local_pos, lb, ub)
+        local_target = self.get_target_wrapper(local_pos)
+        if self.compare_agent([None, target], [None, local_target]):
+            return [local_pos, local_target, position, target]
+        else:
+            return [position, target, local_pos, local_target]
+
+    def shrink_encircling_levy__(self, current_pos, epoch, dist, c, beta=1):
+        up = gamma(1 + beta) * np.sin(np.pi * beta / 2)
+        down = (gamma((1 + beta) / 2) * beta * np.power(2, (beta - 1) / 2))
+        xich_ma_1 = np.power(up / down, 1 / beta)
+        xich_ma_2 = 1
+        a = np.random.normal(0, xich_ma_1, 1)
+        b = np.random.normal(0, xich_ma_2, 1)
+        LB = 0.01 * a / (np.power(np.abs(b), 1 / beta)) * dist * c
+        D = np.random.uniform(self.problem.lb, self.problem.ub)
+        levy = LB * D
+        return (current_pos - np.sqrt(epoch + 1) * np.sign(np.random.random(1) - 0.5)) * levy
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+
+        c = 2 - 2 * epoch / self.epoch
+        if c > 1:
+            pa = 0.3  # At the beginning of the process, the probability for shrinking encircling is small
+        else:
+            pa = 0.7  # But at the end of the process, it become larger. Because sea lion are shrinking encircling prey
+        SP_leader = np.random.uniform(0, 1)
+
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            agent = deepcopy(self.pop[idx])
+            if SP_leader >= 0.6:
+                pos_new = np.cos(2 * np.pi * np.random.normal(0, 1)) * \
+                          np.abs(self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) + self.g_best[self.ID_POS]
+            else:
+                if np.random.uniform() < pa:
+                    dist1 = np.random.uniform() * np.abs(2 * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+                    pos_new = self.shrink_encircling_levy__(self.pop[idx][self.ID_POS], epoch, dist1, c)
+                else:
+                    rand_SL = self.pop[np.random.randint(0, self.pop_size)][self.ID_LOC_POS]
+                    rand_SL = 2 * self.g_best[self.ID_POS] - rand_SL
+                    pos_new = rand_SL - c * np.abs(np.random.uniform() * rand_SL - self.pop[idx][self.ID_POS])
+            agent[self.ID_POS] = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append(agent)
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(agent[self.ID_POS])
+        pop_new = self.update_target_wrapper_population(pop_new)
+
+        for idx in range(0, self.pop_size):
+            if self.compare_agent(pop_new[idx], self.pop[idx]):
+                self.pop[idx] = deepcopy(pop_new[idx])
+                if self.compare_agent(pop_new[idx], [None, self.pop[idx][self.ID_LOC_FIT]]):
+                    self.pop[idx][self.ID_LOC_POS] = deepcopy(pop_new[idx][self.ID_POS])
+                    self.pop[idx][self.ID_LOC_FIT] = deepcopy(pop_new[idx][self.ID_TAR])
+
+
+class ImprovedSLO(ModifiedSLO):
+    """
+    The original version: Improved Sea Lion Optimization (ImprovedSLO)
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + c1 (float): Local coefficient same as PSO, default = 1.2
+        + c2 (float): Global coefficient same as PSO, default = 1.2
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.SLO import ImprovedSLO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> c1 = 1.2
+    >>> c2 = 1.5
+    >>> model = ImprovedSLO(epoch, pop_size, c1, c2)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, c1=1.2, c2=1.2, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            c1 (float): Local coefficient same as PSO, default = 1.2
+            c2 (float): Global coefficient same as PSO, default = 1.2
+        """
+        super().__init__(epoch, pop_size, **kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.c1 = self.validator.check_float("c1", c1, (0, 5.0))
+        self.c2 = self.validator.check_float("c2", c2, (0, 5.0))
+        self.set_parameters(["epoch", "pop_size", "c1", "c2"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        c = 2 - 2 * epoch / self.epoch
+        t0 = np.random.rand()
+        v1 = np.sin(2 * np.pi * t0)
+        v2 = np.sin(2 * np.pi * (1 - t0))
+        SP_leader = np.abs(v1 * (1 + v2) / v2)
+
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            agent = deepcopy(self.pop[idx])
+            if SP_leader < 0.5:
+                if c < 1:  # Exploitation improved by historical movement + global best affect
+                    # pos_new = g_best[self.ID_POS] - c * np.abs(2 * rand() * g_best[self.ID_POS] - pop[i][self.ID_POS])
+                    dif1 = np.abs(2 * np.random.rand() * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+                    dif2 = np.abs(2 * np.random.rand() * self.pop[idx][self.ID_LOC_POS] - self.pop[idx][self.ID_POS])
+                    pos_new = self.c1 * np.random.rand() * (self.pop[idx][self.ID_POS] - dif1) + \
+                              self.c2 * np.random.rand() * (self.pop[idx][self.ID_POS] - dif2)
+                else:  # Exploration improved by opposition-based learning
+                    # Create a new solution by equation below
+                    # Then create an opposition solution of above solution
+                    # Compare both of them and keep the good one (Searching at both direction)
+                    pos_new = self.g_best[self.ID_POS] + c * np.random.normal(0, 1, self.problem.n_dims) * \
+                              (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+                    pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                    target_new = self.get_target_wrapper(pos_new)
+                    pos_new_oppo = self.problem.lb + self.problem.ub - self.g_best[self.ID_POS] + \
+                                   np.random.rand() * (self.g_best[self.ID_POS] - pos_new)
+                    target_new_oppo = self.get_target_wrapper(self.amend_position(pos_new_oppo, self.problem.lb, self.problem.ub))
+                    if self.compare_agent([pos_new_oppo, target_new_oppo], [pos_new, target_new]):
+                        pos_new = pos_new_oppo
+            else:  # Exploitation
+                pos_new = self.g_best[self.ID_POS] + np.cos(2 * np.pi * np.random.uniform(-1, 1)) * \
+                          np.abs(self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+            agent[self.ID_POS] = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append(agent)
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(agent[self.ID_POS])
+        pop_new = self.update_target_wrapper_population(pop_new)
+
+        for idx in range(0, self.pop_size):
+            if self.compare_agent(pop_new[idx], self.pop[idx]):
+                self.pop[idx] = deepcopy(pop_new[idx])
+                if self.compare_agent(pop_new[idx], [None, self.pop[idx][self.ID_LOC_FIT]]):
+                    self.pop[idx][self.ID_LOC_POS] = deepcopy(pop_new[idx][self.ID_POS])
+                    self.pop[idx][self.ID_LOC_FIT] = deepcopy(pop_new[idx][self.ID_TAR])
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/AVOA.py` & `mealpy-2.5.3a1/mealpy/swarm_based/AVOA.py`

 * *Ordering differences only*

 * *Files 7% similar despite different names*

```diff
@@ -1,125 +1,125 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 21:45, 26/10/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalAVOA(Optimizer):
-    """
-    The original version of: African Vultures Optimization Algorithm (AVOA)
-
-    Links:
-        1. https://www.sciencedirect.com/science/article/abs/pii/S0360835221003120
-        2. https://www.mathworks.com/matlabcentral/fileexchange/94820-african-vultures-optimization-algorithm
-
-    Notes (parameters):
-        + p1 (float): probability of status transition, default 0.6
-        + p2 (float): probability of status transition, default 0.4
-        + p3 (float): probability of status transition, default 0.6
-        + alpha (float): probability of 1st best, default = 0.8
-        + gama (float): a factor in the paper (not much affect to algorithm), default = 2.5
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.AVOA import OriginalAVOA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> p1 = 0.6
-    >>> p2 = 0.4
-    >>> p3 = 0.6
-    >>> alpha = 0.8
-    >>> gama = 2.5
-    >>> model = OriginalAVOA(epoch, pop_size, p1, p2, p3, alpha, gama)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Abdollahzadeh, B., Gharehchopogh, F. S., & Mirjalili, S. (2021). African vultures optimization algorithm: A new
-    nature-inspired metaheuristic algorithm for global optimization problems. Computers & Industrial Engineering, 158, 107408.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, p1=0.6, p2=0.4, p3=0.6, alpha=0.8, gama=2.5, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.p1 = self.validator.check_float("p1", p1, (0, 1))
-        self.p2 = self.validator.check_float("p2", p2, (0, 1))
-        self.p3 = self.validator.check_float("p3", p3, (0, 1))
-        self.alpha = self.validator.check_float("alpha", alpha, (0, 1))
-        self.gama = self.validator.check_float("gama", gama, (0, 5.0))
-        self.set_parameters(["epoch", "pop_size", "p1", "p2", "p3", "alpha", "gama"])
-        self.sort_flag = False
-
-    def get_levy_flight__(self, beta=1.0, size=None):
-        sigma = np.random.gamma(1 + beta) * np.sin(np.pi * beta/2) / (np.random.gamma((1+beta)/2) * beta * 2**((beta-1)/2)) ** (1 / beta)
-        u = np.random.normal(0, 1, size) * sigma
-        v = np.random.normal(0, 1, size)
-        step = u / np.abs(v)**(1 / beta)
-        return step
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        a = np.random.uniform(-2, 2) * ((np.sin((np.pi / 2) * (epoch / self.epoch)) ** self.gama) + np.cos((np.pi / 2) * (epoch / self.epoch)) - 1)
-        ppp = (2 * np.random.rand() + 1) * (1 - epoch/self.epoch) + a
-
-        _, best_list, _ = self.get_special_solutions(self.pop, best=2)
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            F = ppp * (2 * np.random.rand() -1)
-            rand_idx = np.random.choice([0, 1], p=[self.alpha, 1-self.alpha])
-            rand_pos = best_list[rand_idx][self.ID_POS]
-            if np.abs(F) >= 1:      # Exploration
-                if np.random.rand() < self.p1:
-                    pos_new = rand_pos - (np.abs((2 * np.random.rand()) * rand_pos - self.pop[idx][self.ID_POS])) * F
-                else:
-                    pos_new = rand_pos - F + np.random.rand()*((self.problem.ub - self.problem.lb)*np.random.rand() + self.problem.lb)
-            else:                   # Exploitation
-                if np.abs(F) < 0.5:      # Phase 1
-                    best_x1 = best_list[0][self.ID_POS]
-                    best_x2 = best_list[1][self.ID_POS]
-                    if np.random.rand() < self.p2:
-                        A = best_x1 - ((best_x1 * self.pop[idx][self.ID_POS]) / (best_x1 - self.pop[idx][self.ID_POS]**2))*F
-                        B = best_x2-((best_x2 * self.pop[idx][self.ID_POS]) / (best_x2 - self.pop[idx][self.ID_POS]**2))*F
-                        pos_new = (A + B) / 2
-                    else:
-                        pos_new = rand_pos - np.abs(rand_pos - self.pop[idx][self.ID_POS]) * F * self.get_levy_flight__(beta=1.5, size=self.problem.n_dims)
-                else:       # Phase 2
-                    if np.random.rand() < self.p3:
-                        pos_new = (np.abs((2 * np.random.rand()) * rand_pos - self.pop[idx][self.ID_POS])) * (F + np.random.rand()) - \
-                                  (rand_pos - self.pop[idx][self.ID_POS])
-                    else:
-                        s1 = rand_pos * (np.random.rand() * self.pop[idx][self.ID_POS] / (2 * np.pi)) * np.cos(self.pop[idx][self.ID_POS])
-                        s2 = rand_pos * (np.random.rand() * self.pop[idx][self.ID_POS] / (2 * np.pi)) * np.sin(self.pop[idx][self.ID_POS])
-                        pos_new = rand_pos - (s1 + s2)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        self.pop = self.update_target_wrapper_population(pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 21:45, 26/10/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalAVOA(Optimizer):
+    """
+    The original version of: African Vultures Optimization Algorithm (AVOA)
+
+    Links:
+        1. https://www.sciencedirect.com/science/article/abs/pii/S0360835221003120
+        2. https://www.mathworks.com/matlabcentral/fileexchange/94820-african-vultures-optimization-algorithm
+
+    Notes (parameters):
+        + p1 (float): probability of status transition, default 0.6
+        + p2 (float): probability of status transition, default 0.4
+        + p3 (float): probability of status transition, default 0.6
+        + alpha (float): probability of 1st best, default = 0.8
+        + gama (float): a factor in the paper (not much affect to algorithm), default = 2.5
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.AVOA import OriginalAVOA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> p1 = 0.6
+    >>> p2 = 0.4
+    >>> p3 = 0.6
+    >>> alpha = 0.8
+    >>> gama = 2.5
+    >>> model = OriginalAVOA(epoch, pop_size, p1, p2, p3, alpha, gama)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Abdollahzadeh, B., Gharehchopogh, F. S., & Mirjalili, S. (2021). African vultures optimization algorithm: A new
+    nature-inspired metaheuristic algorithm for global optimization problems. Computers & Industrial Engineering, 158, 107408.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, p1=0.6, p2=0.4, p3=0.6, alpha=0.8, gama=2.5, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.p1 = self.validator.check_float("p1", p1, (0, 1))
+        self.p2 = self.validator.check_float("p2", p2, (0, 1))
+        self.p3 = self.validator.check_float("p3", p3, (0, 1))
+        self.alpha = self.validator.check_float("alpha", alpha, (0, 1))
+        self.gama = self.validator.check_float("gama", gama, (0, 5.0))
+        self.set_parameters(["epoch", "pop_size", "p1", "p2", "p3", "alpha", "gama"])
+        self.sort_flag = False
+
+    def get_levy_flight__(self, beta=1.0, size=None):
+        sigma = np.random.gamma(1 + beta) * np.sin(np.pi * beta/2) / (np.random.gamma((1+beta)/2) * beta * 2**((beta-1)/2)) ** (1 / beta)
+        u = np.random.normal(0, 1, size) * sigma
+        v = np.random.normal(0, 1, size)
+        step = u / np.abs(v)**(1 / beta)
+        return step
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        a = np.random.uniform(-2, 2) * ((np.sin((np.pi / 2) * (epoch / self.epoch)) ** self.gama) + np.cos((np.pi / 2) * (epoch / self.epoch)) - 1)
+        ppp = (2 * np.random.rand() + 1) * (1 - epoch/self.epoch) + a
+
+        _, best_list, _ = self.get_special_solutions(self.pop, best=2)
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            F = ppp * (2 * np.random.rand() -1)
+            rand_idx = np.random.choice([0, 1], p=[self.alpha, 1-self.alpha])
+            rand_pos = best_list[rand_idx][self.ID_POS]
+            if np.abs(F) >= 1:      # Exploration
+                if np.random.rand() < self.p1:
+                    pos_new = rand_pos - (np.abs((2 * np.random.rand()) * rand_pos - self.pop[idx][self.ID_POS])) * F
+                else:
+                    pos_new = rand_pos - F + np.random.rand()*((self.problem.ub - self.problem.lb)*np.random.rand() + self.problem.lb)
+            else:                   # Exploitation
+                if np.abs(F) < 0.5:      # Phase 1
+                    best_x1 = best_list[0][self.ID_POS]
+                    best_x2 = best_list[1][self.ID_POS]
+                    if np.random.rand() < self.p2:
+                        A = best_x1 - ((best_x1 * self.pop[idx][self.ID_POS]) / (best_x1 - self.pop[idx][self.ID_POS]**2))*F
+                        B = best_x2-((best_x2 * self.pop[idx][self.ID_POS]) / (best_x2 - self.pop[idx][self.ID_POS]**2))*F
+                        pos_new = (A + B) / 2
+                    else:
+                        pos_new = rand_pos - np.abs(rand_pos - self.pop[idx][self.ID_POS]) * F * self.get_levy_flight__(beta=1.5, size=self.problem.n_dims)
+                else:       # Phase 2
+                    if np.random.rand() < self.p3:
+                        pos_new = (np.abs((2 * np.random.rand()) * rand_pos - self.pop[idx][self.ID_POS])) * (F + np.random.rand()) - \
+                                  (rand_pos - self.pop[idx][self.ID_POS])
+                    else:
+                        s1 = rand_pos * (np.random.rand() * self.pop[idx][self.ID_POS] / (2 * np.pi)) * np.cos(self.pop[idx][self.ID_POS])
+                        s2 = rand_pos * (np.random.rand() * self.pop[idx][self.ID_POS] / (2 * np.pi)) * np.sin(self.pop[idx][self.ID_POS])
+                        pos_new = rand_pos - (s1 + s2)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        self.pop = self.update_target_wrapper_population(pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/BA.py` & `mealpy-2.5.3a1/mealpy/swarm_based/BA.py`

 * *Ordering differences only*

 * *Files 11% similar despite different names*

```diff
@@ -1,341 +1,341 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 12:00, 17/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalBA(Optimizer):
-    """
-    The original version of: Bat-inspired Algorithm (BA)
-
-    Notes
-    ~~~~~
-    + The value of A and r parameters are constant
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + loudness (float): (1.0, 2.0), loudness, default = 0.8
-        + pulse_rate (float): (0.15, 0.85), pulse rate / emission rate, default = 0.95
-        + pulse_frequency (list, tuple): (pf_min, pf_max) -> ([0, 3], [5, 20]), pulse frequency, default = (0, 10)
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.BA import OriginalBA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> loudness = 0.8
-    >>> pulse_rate = 0.95
-    >>> pf_min = 0.
-    >>> pf_max = 10.
-    >>> model = OriginalBA(epoch, pop_size, loudness, pulse_rate, pf_min, pf_max)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Yang, X.S., 2010. A new metaheuristic bat-inspired algorithm. In Nature inspired cooperative
-    strategies for optimization (NICSO 2010) (pp. 65-74). Springer, Berlin, Heidelberg.
-    """
-
-    ID_VEC = 2  # Velocity
-    ID_PFRE = 3  # Pulse Frequency
-
-    def __init__(self, epoch=10000, pop_size=100, loudness=0.8, pulse_rate=0.95, pf_min=0., pf_max=10., **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            loudness (float): (A_min, A_max): loudness, default = 0.8
-            pulse_rate (float): (r_min, r_max): pulse rate / emission rate, default = 0.95
-            pf_min (float): pulse frequency min, default = 0
-            pf_max (float): pulse frequency max, default = 10
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.loudness = self.validator.check_float("loudness", loudness, (0, 1.0))
-        self.pulse_rate = self.validator.check_float("pulse_rate", pulse_rate, (0, 1.0))
-        self.pf_min = self.validator.check_float("pf_min", pf_min, [0., 3.0])
-        self.pf_max = self.validator.check_float("pf_max", pf_max, [5., 20.])
-        self.set_parameters(["epoch", "pop_size", "loudness", "pulse_rate", "pf_min", "pf_max"])
-        self.alpha = self.gamma = 0.9
-        self.sort_flag = False
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        """
-        Overriding method in Optimizer class
-
-        Returns:
-            list: a solution with format [position, target, velocity, pulse_frequency]
-        """
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        position = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(position)
-        velocity = np.random.uniform(lb, ub)
-        pulse_frequency = self.pf_min + (self.pf_max - self.pf_min) * np.random.uniform()
-        return [position, target, velocity, pulse_frequency]
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            agent = deepcopy(self.pop[idx])
-            agent[self.ID_VEC] = agent[self.ID_VEC] + self.pop[idx][self.ID_PFRE] * (self.pop[idx][self.ID_POS] - self.g_best[self.ID_POS])
-            x = self.pop[idx][self.ID_POS] + agent[self.ID_VEC]
-            ## Local Search around g_best position
-            if np.random.uniform() > self.pulse_rate:
-                x = self.g_best[self.ID_POS] + 0.0001 * np.random.normal(self.problem.n_dims)  # gauss
-            pos_new = self.amend_position(x, self.problem.lb, self.problem.ub)
-            agent[self.ID_POS] = pos_new
-            pop_new.append(agent)
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop_new = self.update_target_wrapper_population(pop_new)
-        for idx in range(self.pop_size):
-            ## Replace the old position by the new one when its has better fitness.
-            ##  and then update loudness and emission rate
-            if self.compare_agent(pop_new[idx], self.pop[idx]) and np.random.rand() < self.loudness:
-                self.pop[idx] = deepcopy(pop_new[idx])
-
-
-class AdaptiveBA(Optimizer):
-    """
-    The original version of: Adaptive Bat-inspired Algorithm (BA)
-
-    Notes
-    ~~~~~
-    + The value of A and r are changing after each iteration
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + loudness_min (float): A_min - loudness, default=1.0
-        + loudness_max (float): A_max - loudness, default=2.0
-        + pr_min (float): pulse rate / emission rate min, default = 0.15
-        + pr_max (float): pulse rate / emission rate max, default = 0.85
-        + pf_min (float): pulse frequency min, default = 0
-        + pf_max (float): pulse frequency max, default = 10
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.BA import AdaptiveBA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> loudness_min = 1.0 
-    >>> loudness_max = 2.0 
-    >>> pr_min = 0.15
-    >>> pr_max = 0.85
-    >>> pf_min = 0.
-    >>> pf_max = 10.
-    >>> model = AdaptiveBA(epoch, pop_size, loudness_min, loudness_max, pr_min, pr_max, pf_min, pf_max)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Yang, X.S., 2010. A new metaheuristic bat-inspired algorithm. In Nature inspired cooperative
-    strategies for optimization (NICSO 2010) (pp. 65-74). Springer, Berlin, Heidelberg.
-    """
-
-    ID_VEC = 2  # Velocity
-    ID_LOUD = 3  # Loudness
-    ID_PRAT = 4  # Pulse Rate
-    ID_PFRE = 5  # Pulse Frequency
-
-    def __init__(self, epoch=10000, pop_size=100, loudness_min=1.0, loudness_max=2.0, pr_min=0.15, pr_max=0.85, pf_min=0., pf_max=10., **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            loudness_min (float): A_min - loudness, default=1.0
-            loudness_max (float): A_max - loudness, default=2.0
-            pr_min (float): pulse rate / emission rate min, default = 0.15
-            pr_max (float): pulse rate / emission rate max, default = 0.85
-            pf_min (float): pulse frequency min, default = 0
-            pf_max (float): pulse frequency max, default = 10
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.loudness_min = self.validator.check_float("loudness_min", loudness_min, [0.5, 1.5])
-        self.loudness_max = self.validator.check_float("loudness_max", loudness_max, [1.5, 3.0])
-        self.pr_min = self.validator.check_float("pr_min", pr_min, (0, 1.0))
-        self.pr_max = self.validator.check_float("pr_max", pr_max, (0, 1.0))
-        self.pf_min = self.validator.check_float("pf_min", pf_min, [0, 2])
-        self.pf_max = self.validator.check_float("pf_max", pf_max, [2, 10])
-        self.alpha = self.gamma = 0.9
-        self.set_parameters(["epoch", "pop_size", "loudness_min", "loudness_max", "pr_min", "pr_max", "pf_min", "pf_max"])
-        self.sort_flag = False
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        """
-        Overriding method in Optimizer class
-
-        Returns:
-            list: a solution with format [position, target, velocity, loudness, pulse_rate, pulse_frequency]
-        """
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        position = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(position)
-        velocity = np.random.uniform(lb, ub)
-        loudness = np.random.uniform(self.loudness_min, self.loudness_max)
-        pulse_rate = np.random.uniform(self.pr_min, self.pr_max)
-        pulse_frequency = self.pf_min + (self.pf_max - self.pf_min) * np.random.uniform()
-        return [position, target, velocity, loudness, pulse_rate, pulse_frequency]
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        mean_a = np.mean([agent[self.ID_LOUD] for agent in self.pop])
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            agent = deepcopy(self.pop[idx])
-            agent[self.ID_VEC] = agent[self.ID_VEC] + self.pop[idx][self.ID_PFRE] * (self.pop[idx][self.ID_POS] - self.g_best[self.ID_POS])
-            x = self.pop[idx][self.ID_POS] + agent[self.ID_VEC]
-            ## Local Search around g_best position
-            if np.random.uniform() > agent[self.ID_PRAT]:
-                # print(f"{epoch}, {mean_a}, {self.dyn_r}")
-                x = self.g_best[self.ID_POS] + mean_a * np.random.normal(-1, 1)
-            pos_new = self.amend_position(x, self.problem.lb, self.problem.ub)
-            agent[self.ID_POS] = pos_new
-            pop_new.append(agent)
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop_new = self.update_target_wrapper_population(pop_new)
-        for idx in range(0, self.pop_size):
-            ## Replace the old position by the new one when its has better fitness.
-            ##  and then update loudness and emission rate
-            if self.compare_agent(pop_new[idx], self.pop[idx]) and np.random.rand() < pop_new[idx][self.ID_LOUD]:
-                pop_new[idx][self.ID_LOUD] = self.alpha * pop_new[idx][self.ID_LOUD]
-                pop_new[idx][self.ID_PRAT] = pop_new[idx][self.ID_PRAT] * (1 - np.exp(-self.gamma * (epoch + 1)))
-                self.pop[idx] = deepcopy(pop_new[idx])
-
-
-class ModifiedBA(Optimizer):
-    """
-    The original version of: Modified Bat-inspired Algorithm (MBA)
-
-    Notes
-    ~~~~~
-    + A (loudness) parameter is removed
-    + Flow is changed:
-        + 1st: the exploration phase is proceed (using frequency)
-        + 2nd: If new position has better fitness, replace the old position
-        + 3rd: Otherwise, proceed exploitation phase (using finding around the best position so far)
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + pulse_rate (float): [0.7, 1.0], pulse rate / emission rate, default = 0.95
-        + pulse_frequency (tuple, list): (pf_min, pf_max) -> ([0, 3], [5, 20]), pulse frequency, default = (0, 10)
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.BA import ModifiedBA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> pulse_rate = 0.95
-    >>> pf_min = 0.
-    >>> pf_max = 10.
-    >>> model = ModifiedBA(epoch, pop_size, pulse_rate, pf_min, pf_max)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, pulse_rate=0.95, pf_min=0., pf_max=10., **kwargs):
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.pulse_rate = self.validator.check_float("pulse_rate", pulse_rate, (0, 1.0))
-        self.pf_min = self.validator.check_float("pf_min", pf_min, [0, 2])
-        self.pf_max = self.validator.check_float("pf_max", pf_max, [2, 10])
-        self.alpha = self.gamma = 0.9
-        self.set_parameters(["epoch", "pop_size", "pulse_rate", "pf_min", "pf_max"])
-        self.sort_flag = False
-
-    def initialize_variables(self):
-        self.dyn_list_velocity = np.zeros((self.pop_size, self.problem.n_dims))
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            pf = self.pf_min + (self.pf_max - self.pf_min) * np.random.uniform()  # Eq. 2
-            self.dyn_list_velocity[idx] = np.random.uniform() * self.dyn_list_velocity[idx] + \
-                                          (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) * pf  # Eq. 3
-            x = self.pop[idx][self.ID_POS] + self.dyn_list_velocity[idx]  # Eq. 4
-            pos_new = self.amend_position(x, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop_new = self.update_target_wrapper_population(pop_new)
-        pop_child_idx = []
-        pop_child = []
-        for idx in range(0, self.pop_size):
-            if self.compare_agent(pop_new[idx], self.pop[idx]):
-                self.pop[idx] = deepcopy(pop_new[idx])
-            else:
-                if np.random.random() > self.pulse_rate:
-                    x = self.g_best[self.ID_POS] + 0.01 * np.random.uniform(self.problem.lb, self.problem.ub)
-                    pos_new = self.amend_position(x, self.problem.lb, self.problem.ub)
-                    pop_child_idx.append(idx)
-                    pop_child.append([pos_new, None])
-                    if self.mode not in self.AVAILABLE_MODES:
-                        pop_child[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop_child = self.update_target_wrapper_population(pop_child)
-        for idx, idx_selected in enumerate(pop_child_idx):
-            if self.compare_agent(pop_child[idx], pop_new[idx_selected]):
-                pop_new[idx_selected] = deepcopy(pop_child[idx])
-        self.pop = pop_new
+#!/usr/bin/env python
+# Created by "Thieu" at 12:00, 17/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalBA(Optimizer):
+    """
+    The original version of: Bat-inspired Algorithm (BA)
+
+    Notes
+    ~~~~~
+    + The value of A and r parameters are constant
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + loudness (float): (1.0, 2.0), loudness, default = 0.8
+        + pulse_rate (float): (0.15, 0.85), pulse rate / emission rate, default = 0.95
+        + pulse_frequency (list, tuple): (pf_min, pf_max) -> ([0, 3], [5, 20]), pulse frequency, default = (0, 10)
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.BA import OriginalBA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> loudness = 0.8
+    >>> pulse_rate = 0.95
+    >>> pf_min = 0.
+    >>> pf_max = 10.
+    >>> model = OriginalBA(epoch, pop_size, loudness, pulse_rate, pf_min, pf_max)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Yang, X.S., 2010. A new metaheuristic bat-inspired algorithm. In Nature inspired cooperative
+    strategies for optimization (NICSO 2010) (pp. 65-74). Springer, Berlin, Heidelberg.
+    """
+
+    ID_VEC = 2  # Velocity
+    ID_PFRE = 3  # Pulse Frequency
+
+    def __init__(self, epoch=10000, pop_size=100, loudness=0.8, pulse_rate=0.95, pf_min=0., pf_max=10., **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            loudness (float): (A_min, A_max): loudness, default = 0.8
+            pulse_rate (float): (r_min, r_max): pulse rate / emission rate, default = 0.95
+            pf_min (float): pulse frequency min, default = 0
+            pf_max (float): pulse frequency max, default = 10
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.loudness = self.validator.check_float("loudness", loudness, (0, 1.0))
+        self.pulse_rate = self.validator.check_float("pulse_rate", pulse_rate, (0, 1.0))
+        self.pf_min = self.validator.check_float("pf_min", pf_min, [0., 3.0])
+        self.pf_max = self.validator.check_float("pf_max", pf_max, [5., 20.])
+        self.set_parameters(["epoch", "pop_size", "loudness", "pulse_rate", "pf_min", "pf_max"])
+        self.alpha = self.gamma = 0.9
+        self.sort_flag = False
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        """
+        Overriding method in Optimizer class
+
+        Returns:
+            list: a solution with format [position, target, velocity, pulse_frequency]
+        """
+        if pos is None:
+            pos = self.generate_position(lb, ub)
+        position = self.amend_position(pos, lb, ub)
+        target = self.get_target_wrapper(position)
+        velocity = np.random.uniform(lb, ub)
+        pulse_frequency = self.pf_min + (self.pf_max - self.pf_min) * np.random.uniform()
+        return [position, target, velocity, pulse_frequency]
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            agent = deepcopy(self.pop[idx])
+            agent[self.ID_VEC] = agent[self.ID_VEC] + self.pop[idx][self.ID_PFRE] * (self.pop[idx][self.ID_POS] - self.g_best[self.ID_POS])
+            x = self.pop[idx][self.ID_POS] + agent[self.ID_VEC]
+            ## Local Search around g_best position
+            if np.random.uniform() > self.pulse_rate:
+                x = self.g_best[self.ID_POS] + 0.0001 * np.random.normal(self.problem.n_dims)  # gauss
+            pos_new = self.amend_position(x, self.problem.lb, self.problem.ub)
+            agent[self.ID_POS] = pos_new
+            pop_new.append(agent)
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop_new = self.update_target_wrapper_population(pop_new)
+        for idx in range(self.pop_size):
+            ## Replace the old position by the new one when its has better fitness.
+            ##  and then update loudness and emission rate
+            if self.compare_agent(pop_new[idx], self.pop[idx]) and np.random.rand() < self.loudness:
+                self.pop[idx] = deepcopy(pop_new[idx])
+
+
+class AdaptiveBA(Optimizer):
+    """
+    The original version of: Adaptive Bat-inspired Algorithm (BA)
+
+    Notes
+    ~~~~~
+    + The value of A and r are changing after each iteration
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + loudness_min (float): A_min - loudness, default=1.0
+        + loudness_max (float): A_max - loudness, default=2.0
+        + pr_min (float): pulse rate / emission rate min, default = 0.15
+        + pr_max (float): pulse rate / emission rate max, default = 0.85
+        + pf_min (float): pulse frequency min, default = 0
+        + pf_max (float): pulse frequency max, default = 10
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.BA import AdaptiveBA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> loudness_min = 1.0 
+    >>> loudness_max = 2.0 
+    >>> pr_min = 0.15
+    >>> pr_max = 0.85
+    >>> pf_min = 0.
+    >>> pf_max = 10.
+    >>> model = AdaptiveBA(epoch, pop_size, loudness_min, loudness_max, pr_min, pr_max, pf_min, pf_max)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Yang, X.S., 2010. A new metaheuristic bat-inspired algorithm. In Nature inspired cooperative
+    strategies for optimization (NICSO 2010) (pp. 65-74). Springer, Berlin, Heidelberg.
+    """
+
+    ID_VEC = 2  # Velocity
+    ID_LOUD = 3  # Loudness
+    ID_PRAT = 4  # Pulse Rate
+    ID_PFRE = 5  # Pulse Frequency
+
+    def __init__(self, epoch=10000, pop_size=100, loudness_min=1.0, loudness_max=2.0, pr_min=0.15, pr_max=0.85, pf_min=0., pf_max=10., **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            loudness_min (float): A_min - loudness, default=1.0
+            loudness_max (float): A_max - loudness, default=2.0
+            pr_min (float): pulse rate / emission rate min, default = 0.15
+            pr_max (float): pulse rate / emission rate max, default = 0.85
+            pf_min (float): pulse frequency min, default = 0
+            pf_max (float): pulse frequency max, default = 10
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.loudness_min = self.validator.check_float("loudness_min", loudness_min, [0.5, 1.5])
+        self.loudness_max = self.validator.check_float("loudness_max", loudness_max, [1.5, 3.0])
+        self.pr_min = self.validator.check_float("pr_min", pr_min, (0, 1.0))
+        self.pr_max = self.validator.check_float("pr_max", pr_max, (0, 1.0))
+        self.pf_min = self.validator.check_float("pf_min", pf_min, [0, 2])
+        self.pf_max = self.validator.check_float("pf_max", pf_max, [2, 10])
+        self.alpha = self.gamma = 0.9
+        self.set_parameters(["epoch", "pop_size", "loudness_min", "loudness_max", "pr_min", "pr_max", "pf_min", "pf_max"])
+        self.sort_flag = False
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        """
+        Overriding method in Optimizer class
+
+        Returns:
+            list: a solution with format [position, target, velocity, loudness, pulse_rate, pulse_frequency]
+        """
+        if pos is None:
+            pos = self.generate_position(lb, ub)
+        position = self.amend_position(pos, lb, ub)
+        target = self.get_target_wrapper(position)
+        velocity = np.random.uniform(lb, ub)
+        loudness = np.random.uniform(self.loudness_min, self.loudness_max)
+        pulse_rate = np.random.uniform(self.pr_min, self.pr_max)
+        pulse_frequency = self.pf_min + (self.pf_max - self.pf_min) * np.random.uniform()
+        return [position, target, velocity, loudness, pulse_rate, pulse_frequency]
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        mean_a = np.mean([agent[self.ID_LOUD] for agent in self.pop])
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            agent = deepcopy(self.pop[idx])
+            agent[self.ID_VEC] = agent[self.ID_VEC] + self.pop[idx][self.ID_PFRE] * (self.pop[idx][self.ID_POS] - self.g_best[self.ID_POS])
+            x = self.pop[idx][self.ID_POS] + agent[self.ID_VEC]
+            ## Local Search around g_best position
+            if np.random.uniform() > agent[self.ID_PRAT]:
+                # print(f"{epoch}, {mean_a}, {self.dyn_r}")
+                x = self.g_best[self.ID_POS] + mean_a * np.random.normal(-1, 1)
+            pos_new = self.amend_position(x, self.problem.lb, self.problem.ub)
+            agent[self.ID_POS] = pos_new
+            pop_new.append(agent)
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop_new = self.update_target_wrapper_population(pop_new)
+        for idx in range(0, self.pop_size):
+            ## Replace the old position by the new one when its has better fitness.
+            ##  and then update loudness and emission rate
+            if self.compare_agent(pop_new[idx], self.pop[idx]) and np.random.rand() < pop_new[idx][self.ID_LOUD]:
+                pop_new[idx][self.ID_LOUD] = self.alpha * pop_new[idx][self.ID_LOUD]
+                pop_new[idx][self.ID_PRAT] = pop_new[idx][self.ID_PRAT] * (1 - np.exp(-self.gamma * (epoch + 1)))
+                self.pop[idx] = deepcopy(pop_new[idx])
+
+
+class ModifiedBA(Optimizer):
+    """
+    The original version of: Modified Bat-inspired Algorithm (MBA)
+
+    Notes
+    ~~~~~
+    + A (loudness) parameter is removed
+    + Flow is changed:
+        + 1st: the exploration phase is proceed (using frequency)
+        + 2nd: If new position has better fitness, replace the old position
+        + 3rd: Otherwise, proceed exploitation phase (using finding around the best position so far)
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + pulse_rate (float): [0.7, 1.0], pulse rate / emission rate, default = 0.95
+        + pulse_frequency (tuple, list): (pf_min, pf_max) -> ([0, 3], [5, 20]), pulse frequency, default = (0, 10)
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.BA import ModifiedBA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> pulse_rate = 0.95
+    >>> pf_min = 0.
+    >>> pf_max = 10.
+    >>> model = ModifiedBA(epoch, pop_size, pulse_rate, pf_min, pf_max)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, pulse_rate=0.95, pf_min=0., pf_max=10., **kwargs):
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.pulse_rate = self.validator.check_float("pulse_rate", pulse_rate, (0, 1.0))
+        self.pf_min = self.validator.check_float("pf_min", pf_min, [0, 2])
+        self.pf_max = self.validator.check_float("pf_max", pf_max, [2, 10])
+        self.alpha = self.gamma = 0.9
+        self.set_parameters(["epoch", "pop_size", "pulse_rate", "pf_min", "pf_max"])
+        self.sort_flag = False
+
+    def initialize_variables(self):
+        self.dyn_list_velocity = np.zeros((self.pop_size, self.problem.n_dims))
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            pf = self.pf_min + (self.pf_max - self.pf_min) * np.random.uniform()  # Eq. 2
+            self.dyn_list_velocity[idx] = np.random.uniform() * self.dyn_list_velocity[idx] + \
+                                          (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) * pf  # Eq. 3
+            x = self.pop[idx][self.ID_POS] + self.dyn_list_velocity[idx]  # Eq. 4
+            pos_new = self.amend_position(x, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop_new = self.update_target_wrapper_population(pop_new)
+        pop_child_idx = []
+        pop_child = []
+        for idx in range(0, self.pop_size):
+            if self.compare_agent(pop_new[idx], self.pop[idx]):
+                self.pop[idx] = deepcopy(pop_new[idx])
+            else:
+                if np.random.random() > self.pulse_rate:
+                    x = self.g_best[self.ID_POS] + 0.01 * np.random.uniform(self.problem.lb, self.problem.ub)
+                    pos_new = self.amend_position(x, self.problem.lb, self.problem.ub)
+                    pop_child_idx.append(idx)
+                    pop_child.append([pos_new, None])
+                    if self.mode not in self.AVAILABLE_MODES:
+                        pop_child[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop_child = self.update_target_wrapper_population(pop_child)
+        for idx, idx_selected in enumerate(pop_child_idx):
+            if self.compare_agent(pop_child[idx], pop_new[idx_selected]):
+                pop_new[idx_selected] = deepcopy(pop_child[idx])
+        self.pop = pop_new
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/BES.py` & `mealpy-2.5.3a1/mealpy/swarm_based/BES.py`

 * *Ordering differences only*

 * *Files 15% similar despite different names*

```diff
@@ -1,155 +1,155 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 14:52, 17/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalBES(Optimizer):
-    """
-    The original version of: Bald Eagle Search (BES)
-
-    Links:
-        1. https://doi.org/10.1007/s10462-019-09732-5
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + a_factor (int): default: 10, determining the corner between point search in the central point, in [5, 10]
-        + R_factor (float): default: 1.5, determining the number of search cycles, in [0.5, 2]
-        + alpha (float): default: 2, parameter for controlling the changes in position, in [1.5, 2]
-        + c1 (float): default: 2, in [1, 2]
-        + c2 (float): c1 and c2 increase the movement intensity of bald eagles towards the best and centre points
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.BES import OriginalBES
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> a_factor = 10
-    >>> R_factor = 1.5
-    >>> alpha = 2.0
-    >>> c1 = 2.0
-    >>> c2 = 2.0
-    >>> model = OriginalBES(epoch, pop_size, a_factor, R_factor, alpha, c1, c2)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Alsattar, H.A., Zaidan, A.A. and Zaidan, B.B., 2020. Novel meta-heuristic bald eagle
-    search optimisation algorithm. Artificial Intelligence Review, 53(3), pp.2237-2264.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, a_factor=10, R_factor=1.5, alpha=2.0, c1=2.0, c2=2.0, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            a_factor (int): default: 10, determining the corner between point search in the central point, in [5, 10]
-            R_factor (float): default: 1.5, determining the number of search cycles, in [0.5, 2]
-            alpha (float): default: 2, parameter for controlling the changes in position, in [1.5, 2]
-            c1 (float): default: 2, in [1, 2]
-            c2 (float): c1 and c2 increase the movement intensity of bald eagles towards the best and centre points
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.a_factor = self.validator.check_int("a_factor", a_factor, [2, 20])
-        self.R_factor = self.validator.check_float("R_factor", R_factor, [0.1, 3.0])
-        self.alpha = self.validator.check_float("alpha", alpha, [0.5, 3.0])
-        self.c1 = self.validator.check_float("c1", c1, (0, 4.0))
-        self.c2 = self.validator.check_float("c2", c2, (0, 4.0))
-        self.set_parameters(["epoch", "pop_size", "a_factor", "R_factor", "alpha", "c1", "c2"])
-        self.sort_flag = False
-
-    def create_x_y_x1_y1__(self):
-        """ Using numpy vector for faster computational time """
-        ## Eq. 2
-        phi = self.a_factor * np.pi * np.random.uniform(0, 1, self.pop_size)
-        r = phi + self.R_factor * np.random.uniform(0, 1, self.pop_size)
-        xr, yr = r * np.sin(phi), r * np.cos(phi)
-
-        ## Eq. 3
-        r1 = phi1 = self.a_factor * np.pi * np.random.uniform(0, 1, self.pop_size)
-        xr1, yr1 = r1 * np.sinh(phi1), r1 * np.cosh(phi1)
-
-        x_list = xr / np.max(xr)
-        y_list = yr / np.max(yr)
-        x1_list = xr1 / np.max(xr1)
-        y1_list = yr1 / np.max(yr1)
-        return x_list, y_list, x1_list, y1_list
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        ## 0. Pre-definded
-        x_list, y_list, x1_list, y1_list = self.create_x_y_x1_y1__()
-
-        # Three parts: selecting the search space, searching within the selected search space and swooping.
-        ## 1. Select space
-        pos_list = np.array([individual[self.ID_POS] for individual in self.pop])
-        pos_mean = np.mean(pos_list, axis=0)
-
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            pos_new = self.g_best[self.ID_POS] + self.alpha * np.random.uniform() * (pos_mean - self.pop[idx][self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-        ## 2. Search in space
-        pos_list = np.array([individual[self.ID_POS] for individual in self.pop])
-        pos_mean = np.mean(pos_list, axis=0)
-
-        pop_child = []
-        for idx in range(0, self.pop_size):
-            idx_rand = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
-            pos_new = self.pop[idx][self.ID_POS] + y_list[idx] * (self.pop[idx][self.ID_POS] - self.pop[idx_rand][self.ID_POS]) + \
-                      x_list[idx] * (self.pop[idx][self.ID_POS] - pos_mean)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_child.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_child = self.update_target_wrapper_population(pop_child)
-            self.pop = self.greedy_selection_population(self.pop, pop_child)
-
-        ## 3. Swoop
-        pos_list = np.array([individual[self.ID_POS] for individual in self.pop])
-        pos_mean = np.mean(pos_list, axis=0)
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            pos_new = np.random.uniform() * self.g_best[self.ID_POS] + x1_list[idx] * (self.pop[idx][self.ID_POS] - self.c1 * pos_mean) \
-                      + y1_list[idx] * (self.pop[idx][self.ID_POS] - self.c2 * self.g_best[self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 14:52, 17/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalBES(Optimizer):
+    """
+    The original version of: Bald Eagle Search (BES)
+
+    Links:
+        1. https://doi.org/10.1007/s10462-019-09732-5
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + a_factor (int): default: 10, determining the corner between point search in the central point, in [5, 10]
+        + R_factor (float): default: 1.5, determining the number of search cycles, in [0.5, 2]
+        + alpha (float): default: 2, parameter for controlling the changes in position, in [1.5, 2]
+        + c1 (float): default: 2, in [1, 2]
+        + c2 (float): c1 and c2 increase the movement intensity of bald eagles towards the best and centre points
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.BES import OriginalBES
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> a_factor = 10
+    >>> R_factor = 1.5
+    >>> alpha = 2.0
+    >>> c1 = 2.0
+    >>> c2 = 2.0
+    >>> model = OriginalBES(epoch, pop_size, a_factor, R_factor, alpha, c1, c2)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Alsattar, H.A., Zaidan, A.A. and Zaidan, B.B., 2020. Novel meta-heuristic bald eagle
+    search optimisation algorithm. Artificial Intelligence Review, 53(3), pp.2237-2264.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, a_factor=10, R_factor=1.5, alpha=2.0, c1=2.0, c2=2.0, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            a_factor (int): default: 10, determining the corner between point search in the central point, in [5, 10]
+            R_factor (float): default: 1.5, determining the number of search cycles, in [0.5, 2]
+            alpha (float): default: 2, parameter for controlling the changes in position, in [1.5, 2]
+            c1 (float): default: 2, in [1, 2]
+            c2 (float): c1 and c2 increase the movement intensity of bald eagles towards the best and centre points
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.a_factor = self.validator.check_int("a_factor", a_factor, [2, 20])
+        self.R_factor = self.validator.check_float("R_factor", R_factor, [0.1, 3.0])
+        self.alpha = self.validator.check_float("alpha", alpha, [0.5, 3.0])
+        self.c1 = self.validator.check_float("c1", c1, (0, 4.0))
+        self.c2 = self.validator.check_float("c2", c2, (0, 4.0))
+        self.set_parameters(["epoch", "pop_size", "a_factor", "R_factor", "alpha", "c1", "c2"])
+        self.sort_flag = False
+
+    def create_x_y_x1_y1__(self):
+        """ Using numpy vector for faster computational time """
+        ## Eq. 2
+        phi = self.a_factor * np.pi * np.random.uniform(0, 1, self.pop_size)
+        r = phi + self.R_factor * np.random.uniform(0, 1, self.pop_size)
+        xr, yr = r * np.sin(phi), r * np.cos(phi)
+
+        ## Eq. 3
+        r1 = phi1 = self.a_factor * np.pi * np.random.uniform(0, 1, self.pop_size)
+        xr1, yr1 = r1 * np.sinh(phi1), r1 * np.cosh(phi1)
+
+        x_list = xr / np.max(xr)
+        y_list = yr / np.max(yr)
+        x1_list = xr1 / np.max(xr1)
+        y1_list = yr1 / np.max(yr1)
+        return x_list, y_list, x1_list, y1_list
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        ## 0. Pre-definded
+        x_list, y_list, x1_list, y1_list = self.create_x_y_x1_y1__()
+
+        # Three parts: selecting the search space, searching within the selected search space and swooping.
+        ## 1. Select space
+        pos_list = np.array([individual[self.ID_POS] for individual in self.pop])
+        pos_mean = np.mean(pos_list, axis=0)
+
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            pos_new = self.g_best[self.ID_POS] + self.alpha * np.random.uniform() * (pos_mean - self.pop[idx][self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+        ## 2. Search in space
+        pos_list = np.array([individual[self.ID_POS] for individual in self.pop])
+        pos_mean = np.mean(pos_list, axis=0)
+
+        pop_child = []
+        for idx in range(0, self.pop_size):
+            idx_rand = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
+            pos_new = self.pop[idx][self.ID_POS] + y_list[idx] * (self.pop[idx][self.ID_POS] - self.pop[idx_rand][self.ID_POS]) + \
+                      x_list[idx] * (self.pop[idx][self.ID_POS] - pos_mean)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_child.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_child = self.update_target_wrapper_population(pop_child)
+            self.pop = self.greedy_selection_population(self.pop, pop_child)
+
+        ## 3. Swoop
+        pos_list = np.array([individual[self.ID_POS] for individual in self.pop])
+        pos_mean = np.mean(pos_list, axis=0)
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            pos_new = np.random.uniform() * self.g_best[self.ID_POS] + x1_list[idx] * (self.pop[idx][self.ID_POS] - self.c1 * pos_mean) \
+                      + y1_list[idx] * (self.pop[idx][self.ID_POS] - self.c2 * self.g_best[self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/BFO.py` & `mealpy-2.5.3a1/mealpy/swarm_based/BFO.py`

 * *Ordering differences only*

 * *Files 9% similar despite different names*

```diff
@@ -1,344 +1,344 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 10:21, 17/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalBFO(Optimizer):
-    """
-    The original version of: Bacterial Foraging Optimization (BFO)
-
-    Links:
-        1. https://www.cleveralgorithms.com/nature-inspired/swarm/bfoa.html
-
-    Notes
-    ~~~~~
-    + Ned and Nre parameters are replaced by epoch (generation)
-    + The Nc parameter will also decrease to reduce the computation time.
-    + Cost in this version equal to Fitness value in the paper.
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + Ci (float): [0.01, 0.3], step size, default=0.01
-        + Ped (float): [0.1, 0.5], probability of elimination, default=0.25
-        + Ned (int): elim_disp_steps (Removed), Ned=5,
-        + Nre (int): reproduction_steps (Removed), Nre=50,
-        + Nc (int): [3, 10], chem_steps (Reduce), Nc = Original Nc/2, default = 5
-        + Ns (int): [2, 10], swim length, default=4
-        + d_attract (float): coefficient to calculate attract force, default = 0.1
-        + w_attract (float): coefficient to calculate attract force, default = 0.2
-        + h_repels (float): coefficient to calculate repel force, default = 0.1
-        + w_repels (float): coefficient to calculate repel force, default = 10
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.BFO import OriginalBFO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> Ci = 0.01
-    >>> Ped = 0.25
-    >>> Nc = 5
-    >>> Ns = 4
-    >>> d_attract=0.1
-    >>> w_attract=0.2
-    >>> h_repels=0.1
-    >>> w_repels=10
-    >>> model = OriginalBFO(epoch, pop_size, Ci, Ped, Nc, Ns, d_attract, w_attract, h_repels, w_repels)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Passino, K.M., 2002. Biomimicry of bacterial foraging for distributed optimization and control.
-    IEEE control systems magazine, 22(3), pp.52-67.
-    """
-
-    ID_POS = 0
-    ID_TAR = 1
-    ID_COST = 2
-    ID_INTER = 3
-    ID_SUM_NUTRIENTS = 4
-
-    def __init__(self, epoch=10000, pop_size=100, Ci=0.01, Ped=0.25, Nc=5, Ns=4,
-                 d_attract=0.1, w_attract=0.2, h_repels=0.1, w_repels=10, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            Ci (float): step size, default=0.01
-            Ped (float): p_eliminate, default=0.25
-            Ned (int): elim_disp_steps (Removed)         Ned=5,
-            Nre (int): reproduction_steps (Removed)      Nre=50,
-            Nc (int): chem_steps (Reduce)                Nc = Original Nc/2, default = 5
-            Ns (int): swim_length, default=4
-            d_attract (float): coefficient to calculate attract force, default = 0.1
-            w_attract (float): coefficient to calculate attract force, default = 0.2
-            h_repels (float): coefficient to calculate repel force, default = 0.1
-            w_repels (float): coefficient to calculate repel force, default = 10
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.step_size = self.Ci = self.validator.check_int("Ci", Ci, (0, 5.0))
-        self.p_eliminate = self.Ped = self.validator.check_float("Ped", Ped, (0, 1.0))
-        self.chem_steps = self.Nc = self.validator.check_int("Nc", Nc, [2, 100])
-        self.swim_length = self.Ns = self.validator.check_int("Ns", Ns, [2, 100])
-        self.d_attract = self.validator.check_float("d_attract", d_attract, (0, 1.0))
-        self.w_attract = self.validator.check_float("w_attract", w_attract, (0, 1.0))
-        self.h_repels = self.validator.check_float("h_repels", h_repels, (0, 1.0))
-        self.w_repels = self.validator.check_float("w_repels", w_repels, (2.0, 20.0))
-        self.set_parameters(["epoch", "pop_size", "Ci", "Ped", "Nc", "Ns", "d_attract", "w_attract", "h_repels", "w_repels"])
-        self.half_pop_size = int(self.pop_size / 2)
-        self.support_parallel_modes = False
-        self.sort_flag = False
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        """
-        Overriding method in Optimizer class
-
-        Returns:
-            list: wrapper of solution with format [position, target, cost, interaction, sum_nutrients]
-        """
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        position = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(position)
-        cost = 0.0
-        interaction = 0.0
-        sum_nutrients = 0.0
-        return [position, target, cost, interaction, sum_nutrients]
-
-    def compute_cell_interaction__(self, cell, cells, d, w):
-        sum_inter = 0.0
-        for other in cells:
-            diff = self.problem.n_dims * ((cell[self.ID_POS] - other[self.ID_POS]) ** 2).mean(axis=None)
-            sum_inter += d * np.exp(w * diff)
-        return sum_inter
-
-    def attract_repel__(self, idx, cells):
-        attract = self.compute_cell_interaction__(cells[idx], cells, -self.d_attract, -self.w_attract)
-        repel = self.compute_cell_interaction__(cells[idx], cells, self.h_repels, -self.w_repels)
-        return attract + repel
-
-    def evaluate__(self, idx, cells):
-        cells[idx][self.ID_INTER] = self.attract_repel__(idx, cells)
-        cells[idx][self.ID_COST] = cells[idx][self.ID_TAR][self.ID_FIT] + cells[idx][self.ID_INTER]
-        return cells
-
-    def tumble_cell__(self, cell, step_size):
-        delta_i = np.random.uniform(self.problem.lb, self.problem.ub)
-        unit_vector = delta_i / np.sqrt(np.abs(np.dot(delta_i, delta_i.T)))
-        vector = cell[self.ID_POS] + step_size * unit_vector
-        return [vector, 0.0, 0.0, 0.0, 0.0]
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        for j in range(0, self.chem_steps):
-            for idx in range(0, self.pop_size):
-                sum_nutrients = 0.0
-                self.pop = self.evaluate__(idx, self.pop)
-                sum_nutrients += self.pop[idx][self.ID_COST]
-
-                for m in range(0, self.swim_length):
-                    delta_i = np.random.uniform(self.problem.lb, self.problem.ub)
-                    unit_vector = delta_i / np.sqrt(np.abs(np.dot(delta_i, delta_i.T)))
-                    pos_new = self.pop[idx][self.ID_POS] + self.step_size * unit_vector
-                    pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                    target = self.get_target_wrapper(pos_new)
-                    if self.compare_agent([pos_new, target], self.pop[idx]):
-                        self.pop[idx][self.ID_POS] = pos_new
-                        self.pop[idx][self.ID_TAR] = target
-                        break
-                    sum_nutrients += self.pop[idx][self.ID_COST]
-                self.pop[idx][self.ID_SUM_NUTRIENTS] = sum_nutrients
-
-            cells = sorted(self.pop, key=lambda cell: cell[self.ID_SUM_NUTRIENTS])
-            self.pop = deepcopy(cells[0:self.half_pop_size]) + deepcopy(cells[0:self.half_pop_size])
-
-            for idc in range(self.pop_size):
-                if np.random.rand() < self.p_eliminate:
-                    self.pop[idc] = self.create_solution(self.problem.lb, self.problem.ub)
-
-
-class ABFO(Optimizer):
-    """
-    The original version of: Adaptive Bacterial Foraging Optimization (ABFO)
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-
-        + C_s (float): step size start, default=0.1
-        + C_e (float): step size end, default=0.001
-        + Ped (float): Probability eliminate, default=0.01
-        + Ns (int): swim_length, default=4
-        + N_adapt (int): Dead threshold value default=2
-        + N_split (int): Split threshold value, default=40
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.BFO import ABFO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> C_s=0.1
-    >>> C_e=0.001
-    >>> Ped = 0.01
-    >>> Ns = 4
-    >>> N_adapt = 2
-    >>> N_split = 40
-    >>> model = ABFO(epoch, pop_size, C_s, C_e, Ped, Ns, N_adapt, N_split)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Nguyen, T., Nguyen, B.M. and Nguyen, G., 2019, April. Building resource auto-scaler with functional-link
-    neural network and adaptive bacterial foraging optimization. In International Conference on
-    Theory and Applications of Models of Computation (pp. 501-517). Springer, Cham.
-    """
-
-    ID_NUT = 2
-    ID_LOC_POS = 3
-    ID_LOC_FIT = 4
-
-    def __init__(self, epoch=10000, pop_size=100, C_s=0.1, C_e=0.001, Ped=0.01, Ns=4, N_adapt=2, N_split=40, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            C_s (float): step size start, default=0.1
-            C_e (float): step size end, default=0.001
-            Ped (float): Probability eliminate, default=0.01
-            Ns (int): swim_length, default=4
-            N_adapt (int): Dead threshold value default=2
-            N_split (int): Split threshold value, default=40
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.C_s = self.Ped = self.validator.check_float("C_s", C_s, (0, 2.0))
-        self.C_e = self.Ped = self.validator.check_float("C_e", C_e, (0, 1.0))
-        self.p_eliminate = self.Ped = self.validator.check_float("Ped", Ped, (0, 1.0))
-        self.swim_length = self.Ns = self.validator.check_int("Ns", Ns, [2, 100])
-        self.N_adapt = self.validator.check_int("N_adapt", N_adapt, [0, 4])
-        self.N_split = self.validator.check_int("N_split", N_split, [5, 50])
-        self.set_parameters(["epoch", "pop_size", "C_s", "C_e", "Ped", "Ns", "N_adapt", "N_split"])
-        self.support_parallel_modes = False
-        self.sort_flag = False
-
-    def initialize_variables(self):
-        self.C_s = self.C_s * (self.problem.ub - self.problem.lb)
-        self.C_e = self.C_e * (self.problem.ub - self.problem.lb)
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        """
-        Overriding method in Optimizer class
-
-        Returns:
-            list: wrapper of solution with format [position, target, nutrient, local_pos_best, local_fit_best]
-        """
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        position = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(position)
-        nutrient = 0  # total nutrient gained by the bacterium in its whole searching process.(int number)
-        local_pos_best = deepcopy(position)
-        local_fit_best = deepcopy(target)
-        return [position, target, nutrient, local_pos_best, local_fit_best]
-
-    def update_step_size__(self, pop=None, idx=None):
-        total_fitness = np.sum([temp[self.ID_TAR][self.ID_FIT] for temp in pop])
-        step_size = self.C_s - (self.C_s - self.C_e) * pop[idx][self.ID_TAR][self.ID_FIT] / total_fitness
-        step_size = step_size / self.pop[idx][self.ID_NUT] if self.pop[idx][self.ID_NUT] > 0 else step_size
-        return step_size
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        for i in range(0, self.pop_size):
-            step_size = self.update_step_size__(self.pop, i)
-            for m in range(0, self.swim_length):  # Ns
-                delta_i = (self.g_best[self.ID_POS] - self.pop[i][self.ID_POS]) + \
-                          (self.pop[i][self.ID_LOC_POS] - self.pop[i][self.ID_POS])
-                delta = np.sqrt(np.abs(np.dot(delta_i, delta_i.T)))
-                unit_vector = np.random.uniform(self.problem.lb, self.problem.ub) if delta == 0 else (delta_i / delta)
-                pos_new = self.pop[i][self.ID_POS] + step_size * unit_vector
-                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                target = self.get_target_wrapper(pos_new)
-                if self.compare_agent([pos_new, target], self.pop[i]):
-                    self.pop[i][self.ID_POS] = pos_new
-                    self.pop[i][self.ID_TAR] = target
-                    self.pop[i][self.ID_NUT] += 1
-                    # Update personal best
-                    if self.compare_agent([pos_new, target], [None, self.pop[i][self.ID_LOC_FIT]]):
-                        self.pop[i][self.ID_LOC_POS] = deepcopy(pos_new)
-                        self.pop[i][self.ID_LOC_FIT] = deepcopy(target)
-                else:
-                    self.pop[i][self.ID_NUT] -= 1
-
-            if self.pop[i][self.ID_NUT] > max(self.N_split, self.N_split + (len(self.pop) - self.pop_size) / self.N_adapt):
-                pos_new = self.pop[i][self.ID_POS] + np.random.normal(self.problem.lb, self.problem.ub) * \
-                          (self.g_best[self.ID_POS] - self.pop[i][self.ID_POS])
-                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                target = self.get_target_wrapper(pos_new)
-                self.pop.append([pos_new, target, 0, deepcopy(pos_new), deepcopy(target)])
-
-            nut_min = min(self.N_adapt, self.N_adapt + (len(self.pop) - self.pop_size) / self.N_adapt)
-            if self.pop[i][self.ID_NUT] < nut_min or np.random.rand() < self.p_eliminate:
-                self.pop[i] = self.create_solution(self.problem.lb, self.problem.ub)
-
-        ## Make sure the population does not have duplicates.
-        new_set = set()
-        for idx, obj in enumerate(self.pop):
-            if tuple(obj[self.ID_POS].tolist()) in new_set:
-                self.pop.pop(idx)
-            else:
-                new_set.add(tuple(obj[self.ID_POS].tolist()))
-
-        ## Balance the population by adding more agents or remove some agents
-        n_agents = len(self.pop) - self.pop_size
-        if n_agents < 0:
-            for idx in range(0, n_agents):
-                self.pop.append(self.create_solution(self.problem.lb, self.problem.ub))
-        elif n_agents > 0:
-            list_idx_removed = np.random.choice(range(0, len(self.pop)), n_agents, replace=False)
-            pop_new = []
-            for idx in range(0, len(self.pop)):
-                if idx not in list_idx_removed:
-                    pop_new.append(self.pop[idx])
-            self.pop = pop_new
+#!/usr/bin/env python
+# Created by "Thieu" at 10:21, 17/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalBFO(Optimizer):
+    """
+    The original version of: Bacterial Foraging Optimization (BFO)
+
+    Links:
+        1. https://www.cleveralgorithms.com/nature-inspired/swarm/bfoa.html
+
+    Notes
+    ~~~~~
+    + Ned and Nre parameters are replaced by epoch (generation)
+    + The Nc parameter will also decrease to reduce the computation time.
+    + Cost in this version equal to Fitness value in the paper.
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + Ci (float): [0.01, 0.3], step size, default=0.01
+        + Ped (float): [0.1, 0.5], probability of elimination, default=0.25
+        + Ned (int): elim_disp_steps (Removed), Ned=5,
+        + Nre (int): reproduction_steps (Removed), Nre=50,
+        + Nc (int): [3, 10], chem_steps (Reduce), Nc = Original Nc/2, default = 5
+        + Ns (int): [2, 10], swim length, default=4
+        + d_attract (float): coefficient to calculate attract force, default = 0.1
+        + w_attract (float): coefficient to calculate attract force, default = 0.2
+        + h_repels (float): coefficient to calculate repel force, default = 0.1
+        + w_repels (float): coefficient to calculate repel force, default = 10
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.BFO import OriginalBFO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> Ci = 0.01
+    >>> Ped = 0.25
+    >>> Nc = 5
+    >>> Ns = 4
+    >>> d_attract=0.1
+    >>> w_attract=0.2
+    >>> h_repels=0.1
+    >>> w_repels=10
+    >>> model = OriginalBFO(epoch, pop_size, Ci, Ped, Nc, Ns, d_attract, w_attract, h_repels, w_repels)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Passino, K.M., 2002. Biomimicry of bacterial foraging for distributed optimization and control.
+    IEEE control systems magazine, 22(3), pp.52-67.
+    """
+
+    ID_POS = 0
+    ID_TAR = 1
+    ID_COST = 2
+    ID_INTER = 3
+    ID_SUM_NUTRIENTS = 4
+
+    def __init__(self, epoch=10000, pop_size=100, Ci=0.01, Ped=0.25, Nc=5, Ns=4,
+                 d_attract=0.1, w_attract=0.2, h_repels=0.1, w_repels=10, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            Ci (float): step size, default=0.01
+            Ped (float): p_eliminate, default=0.25
+            Ned (int): elim_disp_steps (Removed)         Ned=5,
+            Nre (int): reproduction_steps (Removed)      Nre=50,
+            Nc (int): chem_steps (Reduce)                Nc = Original Nc/2, default = 5
+            Ns (int): swim_length, default=4
+            d_attract (float): coefficient to calculate attract force, default = 0.1
+            w_attract (float): coefficient to calculate attract force, default = 0.2
+            h_repels (float): coefficient to calculate repel force, default = 0.1
+            w_repels (float): coefficient to calculate repel force, default = 10
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.step_size = self.Ci = self.validator.check_int("Ci", Ci, (0, 5.0))
+        self.p_eliminate = self.Ped = self.validator.check_float("Ped", Ped, (0, 1.0))
+        self.chem_steps = self.Nc = self.validator.check_int("Nc", Nc, [2, 100])
+        self.swim_length = self.Ns = self.validator.check_int("Ns", Ns, [2, 100])
+        self.d_attract = self.validator.check_float("d_attract", d_attract, (0, 1.0))
+        self.w_attract = self.validator.check_float("w_attract", w_attract, (0, 1.0))
+        self.h_repels = self.validator.check_float("h_repels", h_repels, (0, 1.0))
+        self.w_repels = self.validator.check_float("w_repels", w_repels, (2.0, 20.0))
+        self.set_parameters(["epoch", "pop_size", "Ci", "Ped", "Nc", "Ns", "d_attract", "w_attract", "h_repels", "w_repels"])
+        self.half_pop_size = int(self.pop_size / 2)
+        self.support_parallel_modes = False
+        self.sort_flag = False
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        """
+        Overriding method in Optimizer class
+
+        Returns:
+            list: wrapper of solution with format [position, target, cost, interaction, sum_nutrients]
+        """
+        if pos is None:
+            pos = self.generate_position(lb, ub)
+        position = self.amend_position(pos, lb, ub)
+        target = self.get_target_wrapper(position)
+        cost = 0.0
+        interaction = 0.0
+        sum_nutrients = 0.0
+        return [position, target, cost, interaction, sum_nutrients]
+
+    def compute_cell_interaction__(self, cell, cells, d, w):
+        sum_inter = 0.0
+        for other in cells:
+            diff = self.problem.n_dims * ((cell[self.ID_POS] - other[self.ID_POS]) ** 2).mean(axis=None)
+            sum_inter += d * np.exp(w * diff)
+        return sum_inter
+
+    def attract_repel__(self, idx, cells):
+        attract = self.compute_cell_interaction__(cells[idx], cells, -self.d_attract, -self.w_attract)
+        repel = self.compute_cell_interaction__(cells[idx], cells, self.h_repels, -self.w_repels)
+        return attract + repel
+
+    def evaluate__(self, idx, cells):
+        cells[idx][self.ID_INTER] = self.attract_repel__(idx, cells)
+        cells[idx][self.ID_COST] = cells[idx][self.ID_TAR][self.ID_FIT] + cells[idx][self.ID_INTER]
+        return cells
+
+    def tumble_cell__(self, cell, step_size):
+        delta_i = np.random.uniform(self.problem.lb, self.problem.ub)
+        unit_vector = delta_i / np.sqrt(np.abs(np.dot(delta_i, delta_i.T)))
+        vector = cell[self.ID_POS] + step_size * unit_vector
+        return [vector, 0.0, 0.0, 0.0, 0.0]
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        for j in range(0, self.chem_steps):
+            for idx in range(0, self.pop_size):
+                sum_nutrients = 0.0
+                self.pop = self.evaluate__(idx, self.pop)
+                sum_nutrients += self.pop[idx][self.ID_COST]
+
+                for m in range(0, self.swim_length):
+                    delta_i = np.random.uniform(self.problem.lb, self.problem.ub)
+                    unit_vector = delta_i / np.sqrt(np.abs(np.dot(delta_i, delta_i.T)))
+                    pos_new = self.pop[idx][self.ID_POS] + self.step_size * unit_vector
+                    pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                    target = self.get_target_wrapper(pos_new)
+                    if self.compare_agent([pos_new, target], self.pop[idx]):
+                        self.pop[idx][self.ID_POS] = pos_new
+                        self.pop[idx][self.ID_TAR] = target
+                        break
+                    sum_nutrients += self.pop[idx][self.ID_COST]
+                self.pop[idx][self.ID_SUM_NUTRIENTS] = sum_nutrients
+
+            cells = sorted(self.pop, key=lambda cell: cell[self.ID_SUM_NUTRIENTS])
+            self.pop = deepcopy(cells[0:self.half_pop_size]) + deepcopy(cells[0:self.half_pop_size])
+
+            for idc in range(self.pop_size):
+                if np.random.rand() < self.p_eliminate:
+                    self.pop[idc] = self.create_solution(self.problem.lb, self.problem.ub)
+
+
+class ABFO(Optimizer):
+    """
+    The original version of: Adaptive Bacterial Foraging Optimization (ABFO)
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+
+        + C_s (float): step size start, default=0.1
+        + C_e (float): step size end, default=0.001
+        + Ped (float): Probability eliminate, default=0.01
+        + Ns (int): swim_length, default=4
+        + N_adapt (int): Dead threshold value default=2
+        + N_split (int): Split threshold value, default=40
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.BFO import ABFO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> C_s=0.1
+    >>> C_e=0.001
+    >>> Ped = 0.01
+    >>> Ns = 4
+    >>> N_adapt = 2
+    >>> N_split = 40
+    >>> model = ABFO(epoch, pop_size, C_s, C_e, Ped, Ns, N_adapt, N_split)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Nguyen, T., Nguyen, B.M. and Nguyen, G., 2019, April. Building resource auto-scaler with functional-link
+    neural network and adaptive bacterial foraging optimization. In International Conference on
+    Theory and Applications of Models of Computation (pp. 501-517). Springer, Cham.
+    """
+
+    ID_NUT = 2
+    ID_LOC_POS = 3
+    ID_LOC_FIT = 4
+
+    def __init__(self, epoch=10000, pop_size=100, C_s=0.1, C_e=0.001, Ped=0.01, Ns=4, N_adapt=2, N_split=40, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            C_s (float): step size start, default=0.1
+            C_e (float): step size end, default=0.001
+            Ped (float): Probability eliminate, default=0.01
+            Ns (int): swim_length, default=4
+            N_adapt (int): Dead threshold value default=2
+            N_split (int): Split threshold value, default=40
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.C_s = self.Ped = self.validator.check_float("C_s", C_s, (0, 2.0))
+        self.C_e = self.Ped = self.validator.check_float("C_e", C_e, (0, 1.0))
+        self.p_eliminate = self.Ped = self.validator.check_float("Ped", Ped, (0, 1.0))
+        self.swim_length = self.Ns = self.validator.check_int("Ns", Ns, [2, 100])
+        self.N_adapt = self.validator.check_int("N_adapt", N_adapt, [0, 4])
+        self.N_split = self.validator.check_int("N_split", N_split, [5, 50])
+        self.set_parameters(["epoch", "pop_size", "C_s", "C_e", "Ped", "Ns", "N_adapt", "N_split"])
+        self.support_parallel_modes = False
+        self.sort_flag = False
+
+    def initialize_variables(self):
+        self.C_s = self.C_s * (self.problem.ub - self.problem.lb)
+        self.C_e = self.C_e * (self.problem.ub - self.problem.lb)
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        """
+        Overriding method in Optimizer class
+
+        Returns:
+            list: wrapper of solution with format [position, target, nutrient, local_pos_best, local_fit_best]
+        """
+        if pos is None:
+            pos = self.generate_position(lb, ub)
+        position = self.amend_position(pos, lb, ub)
+        target = self.get_target_wrapper(position)
+        nutrient = 0  # total nutrient gained by the bacterium in its whole searching process.(int number)
+        local_pos_best = deepcopy(position)
+        local_fit_best = deepcopy(target)
+        return [position, target, nutrient, local_pos_best, local_fit_best]
+
+    def update_step_size__(self, pop=None, idx=None):
+        total_fitness = np.sum([temp[self.ID_TAR][self.ID_FIT] for temp in pop])
+        step_size = self.C_s - (self.C_s - self.C_e) * pop[idx][self.ID_TAR][self.ID_FIT] / total_fitness
+        step_size = step_size / self.pop[idx][self.ID_NUT] if self.pop[idx][self.ID_NUT] > 0 else step_size
+        return step_size
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        for i in range(0, self.pop_size):
+            step_size = self.update_step_size__(self.pop, i)
+            for m in range(0, self.swim_length):  # Ns
+                delta_i = (self.g_best[self.ID_POS] - self.pop[i][self.ID_POS]) + \
+                          (self.pop[i][self.ID_LOC_POS] - self.pop[i][self.ID_POS])
+                delta = np.sqrt(np.abs(np.dot(delta_i, delta_i.T)))
+                unit_vector = np.random.uniform(self.problem.lb, self.problem.ub) if delta == 0 else (delta_i / delta)
+                pos_new = self.pop[i][self.ID_POS] + step_size * unit_vector
+                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                target = self.get_target_wrapper(pos_new)
+                if self.compare_agent([pos_new, target], self.pop[i]):
+                    self.pop[i][self.ID_POS] = pos_new
+                    self.pop[i][self.ID_TAR] = target
+                    self.pop[i][self.ID_NUT] += 1
+                    # Update personal best
+                    if self.compare_agent([pos_new, target], [None, self.pop[i][self.ID_LOC_FIT]]):
+                        self.pop[i][self.ID_LOC_POS] = deepcopy(pos_new)
+                        self.pop[i][self.ID_LOC_FIT] = deepcopy(target)
+                else:
+                    self.pop[i][self.ID_NUT] -= 1
+
+            if self.pop[i][self.ID_NUT] > max(self.N_split, self.N_split + (len(self.pop) - self.pop_size) / self.N_adapt):
+                pos_new = self.pop[i][self.ID_POS] + np.random.normal(self.problem.lb, self.problem.ub) * \
+                          (self.g_best[self.ID_POS] - self.pop[i][self.ID_POS])
+                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                target = self.get_target_wrapper(pos_new)
+                self.pop.append([pos_new, target, 0, deepcopy(pos_new), deepcopy(target)])
+
+            nut_min = min(self.N_adapt, self.N_adapt + (len(self.pop) - self.pop_size) / self.N_adapt)
+            if self.pop[i][self.ID_NUT] < nut_min or np.random.rand() < self.p_eliminate:
+                self.pop[i] = self.create_solution(self.problem.lb, self.problem.ub)
+
+        ## Make sure the population does not have duplicates.
+        new_set = set()
+        for idx, obj in enumerate(self.pop):
+            if tuple(obj[self.ID_POS].tolist()) in new_set:
+                self.pop.pop(idx)
+            else:
+                new_set.add(tuple(obj[self.ID_POS].tolist()))
+
+        ## Balance the population by adding more agents or remove some agents
+        n_agents = len(self.pop) - self.pop_size
+        if n_agents < 0:
+            for idx in range(0, n_agents):
+                self.pop.append(self.create_solution(self.problem.lb, self.problem.ub))
+        elif n_agents > 0:
+            list_idx_removed = np.random.choice(range(0, len(self.pop)), n_agents, replace=False)
+            pop_new = []
+            for idx in range(0, len(self.pop)):
+                if idx not in list_idx_removed:
+                    pop_new.append(self.pop[idx])
+            self.pop = pop_new
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/BSA.py` & `mealpy-2.5.3a1/mealpy/swarm_based/NMRA.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,202 +1,200 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 11:59, 17/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalBSA(Optimizer):
-    """
-    The original version of: Bird Swarm Algorithm (BSA)
-
-    Links:
-        1. https://doi.org/10.1080/0952813X.2015.1042530
-        2. https://www.mathworks.com/matlabcentral/fileexchange/51256-bird-swarm-algorithm-bsa
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + ff (int): (5, 20), flight frequency - default = 10
-        + pff (float): the probability of foraging for food - default = 0.8
-        + c_couples (list, tuple): [c1, c2] -> (2.0, 2.0), Cognitive accelerated coefficient, Social accelerated coefficient same as PSO
-        + a_couples (list, tuple): [a1, a2] -> (1.5, 1.5), The indirect and direct effect on the birds' vigilance behaviours.
-        + fl (float): (0.1, 1.0), The followed coefficient - default = 0.5
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.BSA import OriginalBSA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> ff = 10
-    >>> pff = 0.8
-    >>> c1 = 1.5
-    >>> c2 = 1.5
-    >>> a1 = 1.0
-    >>> a2 = 1.0
-    >>> fl = 0.5
-    >>> model = OriginalBSA(epoch, pop_size, ff, pff, c1, c2, a1, a2, fl)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Meng, X.B., Gao, X.Z., Lu, L., Liu, Y. and Zhang, H., 2016. A new bio-inspired optimisation
-    algorithm: Bird Swarm Algorithm. Journal of Experimental & Theoretical Artificial
-    Intelligence, 28(4), pp.673-687.
-    """
-
-    ID_POS = 0
-    ID_TAR = 1
-    ID_LBP = 2  # local best position
-    ID_LBF = 3  # local best fitness
-
-    def __init__(self, epoch=10000, pop_size=100, ff=10, pff=0.8, c1=1.5, c2=1.5, a1=1.0, a2=1.0, fl=0.5, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            ff (int): flight frequency - default = 10
-            pff (float): the probability of foraging for food - default = 0.8
-            c1 (float): Cognitive accelerated coefficient same as PSO
-            c2 (float): Social accelerated coefficient same as PSO
-            a1 (float): The indirect effect on the birds' vigilance behaviours.
-            a2 (float): The direct effect on the birds' vigilance behaviours.
-            fl (float): The followed coefficient - default = 0.5
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.ff = self.validator.check_int("ff", ff, [2, int(self.pop_size/2)])
-        self.pff = self.validator.check_float("pff", pff, (0, 1.0))
-        self.c1 = self.validator.check_float("c1", c1, (0, 5.0))
-        self.c2 = self.validator.check_float("c2", c2, (0, 5.0))
-        self.a1 = self.validator.check_float("a1", a1, (0, 5.0))
-        self.a2 = self.validator.check_float("a2", a2, (0, 5.0))
-        self.fl = self.validator.check_float("fl", fl, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "ff", "pff", "c1", "c2", "a1", "a2", "fl"])
-        self.sort_flag = False
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        """
-        Overriding method in Optimizer class
-
-        Returns:
-            list: a solution with format [position, target, local_position, local_fitness]
-        """
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        position = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(position)
-        local_position = deepcopy(position)
-        local_fitness = deepcopy(target)
-        return [position, target, local_position, local_fitness]
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pos_list = np.array([item[self.ID_POS] for item in self.pop])
-        fit_list = np.array([item[self.ID_LBF][self.ID_FIT] for item in self.pop])
-        pos_mean = np.mean(pos_list, axis=0)
-        fit_sum = np.sum(fit_list)
-
-        if epoch % self.ff != 0:
-            pop_new = []
-            for i in range(0, self.pop_size):
-                agent = deepcopy(self.pop[i])
-                prob = np.random.uniform() * 0.2 + self.pff  # The probability of foraging for food
-                if np.random.uniform() < prob:  # Birds forage for food. Eq. 1
-                    x_new = self.pop[i][self.ID_POS] + self.c1 * \
-                            np.random.uniform() * (self.pop[i][self.ID_LBP] - self.pop[i][self.ID_POS]) + \
-                            self.c2 * np.random.uniform() * (self.g_best[self.ID_POS] - self.pop[i][self.ID_POS])
-                else:  # Birds keep vigilance. Eq. 2
-                    A1 = self.a1 * np.exp(-self.pop_size * self.pop[i][self.ID_LBF][self.ID_FIT] / (self.EPSILON + fit_sum))
-                    k = np.random.choice(list(set(range(0, self.pop_size)) - {i}))
-                    t1 = (fit_list[i] - fit_list[k]) / (abs(fit_list[i] - fit_list[k]) + self.EPSILON)
-                    A2 = self.a2 * np.exp(t1 * self.pop_size * fit_list[k] / (fit_sum + self.EPSILON))
-                    x_new = self.pop[i][self.ID_POS] + A1 * np.random.uniform(0, 1) * (pos_mean - self.pop[i][self.ID_POS]) + \
-                            A2 * np.random.uniform(-1, 1) * (self.g_best[self.ID_POS] - self.pop[i][self.ID_POS])
-                pos_new = self.amend_position(x_new, self.problem.lb, self.problem.ub)
-                agent[self.ID_POS] = pos_new
-                pop_new.append(agent)
-                if self.mode not in self.AVAILABLE_MODES:
-                    agent[self.ID_TAR] = self.get_target_wrapper(pos_new)
-                    self.pop[i] = self.get_better_solution(agent, self.pop[i])
-            if self.mode in self.AVAILABLE_MODES:
-                pop_new = self.update_target_wrapper_population(pop_new)
-                self.pop = self.greedy_selection_population(self.pop, pop_new)
-        else:
-            pop_new = deepcopy(self.pop)
-            # Divide the bird swarm into two parts: producers and scroungers.
-            min_idx = np.argmin(fit_list)
-            max_idx = np.argmax(fit_list)
-            choose = 0
-            if min_idx < 0.5 * self.pop_size and max_idx < 0.5 * self.pop_size:
-                choose = 1
-            if min_idx > 0.5 * self.pop_size and max_idx < 0.5 * self.pop_size:
-                choose = 2
-            if min_idx < 0.5 * self.pop_size and max_idx > 0.5 * self.pop_size:
-                choose = 3
-            if min_idx > 0.5 * self.pop_size and max_idx > 0.5 * self.pop_size:
-                choose = 4
-
-            if choose < 3:  # Producing (Equation 5)
-                for i in range(int(self.pop_size / 2 + 1), self.pop_size):
-                    agent = deepcopy(self.pop[i])
-                    x_new = self.pop[i][self.ID_POS] + np.random.uniform(self.problem.lb, self.problem.ub) * self.pop[i][self.ID_POS]
-                    agent[self.ID_POS] = self.amend_position(x_new, self.problem.lb, self.problem.ub)
-                    pop_new[i] = agent
-                if choose == 1:
-                    x_new = self.pop[min_idx][self.ID_POS] + np.random.uniform(self.problem.lb, self.problem.ub) * self.pop[min_idx][self.ID_POS]
-                    agent = deepcopy(self.pop[min_idx])
-                    agent[self.ID_POS] = self.amend_position(x_new, self.problem.lb, self.problem.ub)
-                    pop_new[min_idx] = agent
-                for i in range(0, int(self.pop_size / 2)):
-                    if choose == 2 or min_idx != i:
-                        agent = deepcopy(self.pop[i])
-                        FL = np.random.uniform() * 0.4 + self.fl
-                        idx = np.random.randint(0.5 * self.pop_size + 1, self.pop_size)
-                        x_new = self.pop[i][self.ID_POS] + (self.pop[idx][self.ID_POS] - self.pop[i][self.ID_POS]) * FL
-                        agent[self.ID_POS] = self.amend_position(x_new, self.problem.lb, self.problem.ub)
-                        pop_new[i] = agent
-            else:  # Scrounging (Equation 6)
-                for i in range(0, int(0.5 * self.pop_size)):
-                    agent = deepcopy(self.pop[i])
-                    x_new = self.pop[i][self.ID_POS] + np.random.uniform(self.problem.lb, self.problem.ub) * self.pop[i][self.ID_POS]
-                    agent[self.ID_POS] = self.amend_position(x_new, self.problem.lb, self.problem.ub)
-                    pop_new[i] = agent
-                if choose == 4:
-                    agent = deepcopy(self.pop[min_idx])
-                    x_new = self.pop[min_idx][self.ID_POS] + np.random.uniform(self.problem.lb, self.problem.ub) * self.pop[min_idx][self.ID_POS]
-                    agent[self.ID_POS] = self.amend_position(x_new, self.problem.lb, self.problem.ub)
-                for i in range(int(self.pop_size / 2 + 1), self.pop_size):
-                    if choose == 3 or min_idx != i:
-                        agent = deepcopy(self.pop[i])
-                        FL = np.random.uniform() * 0.4 + self.fl
-                        idx = np.random.randint(0, 0.5 * self.pop_size)
-                        x_new = self.pop[i][self.ID_POS] + (self.pop[idx][self.ID_POS] - self.pop[i][self.ID_POS]) * FL
-                        agent[self.ID_POS] = self.amend_position(x_new, self.problem.lb, self.problem.ub)
-                        pop_new[i] = agent
-            if self.mode in self.AVAILABLE_MODES:
-                pop_new = self.update_target_wrapper_population(pop_new)
-            else:
-                for idx in range(0, self.pop_size):
-                    pop_new[idx][self.ID_TAR] = self.get_target_wrapper(pop_new[idx][self.ID_POS])
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 14:52, 17/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalNMRA(Optimizer):
+    """
+    The original version of: Naked Mole-Rat Algorithm (NMRA)
+
+    Links:
+        1. https://www.doi.org10.1007/s00521-019-04464-7
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + pb (float): [0.5, 0.95], probability of breeding, default = 0.75
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.NMRA import OriginalNMRA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> pb = 0.75
+    >>> model = OriginalNMRA(epoch, pop_size, pb)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Salgotra, R. and Singh, U., 2019. The naked mole-rat algorithm.
+    Neural Computing and Applications, 31(12), pp.8837-8857.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, pb=0.75, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            pb (float): probability of breeding, default = 0.75
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.pb = self.validator.check_float("pb", pb, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "pb"])
+        self.sort_flag = True
+        self.size_b = int(self.pop_size / 5)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            pos_new = deepcopy(self.pop[idx][self.ID_POS])
+            if idx < self.size_b:  # breeding operators
+                if np.random.uniform() < self.pb:
+                    alpha = np.random.uniform()
+                    pos_new = (1 - alpha) * self.pop[idx][self.ID_POS] + alpha * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+            else:  # working operators
+                t1, t2 = np.random.choice(range(self.size_b, self.pop_size), 2, replace=False)
+                pos_new = self.pop[idx][self.ID_POS] + np.random.uniform() * (self.pop[t1][self.ID_POS] - self.pop[t2][self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+
+class ImprovedNMRA(Optimizer):
+    """
+    The original version of: Improved Naked Mole-Rat Algorithm (I-NMRA)
+
+    Notes:
+    + Use mutation probability idea
+    + Use crossover operator
+    + Use Levy-flight technique
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + pb (float): [0.5, 0.95], probability of breeding, default = 0.75
+        + pm (float): [0.01, 0.1], probability of mutation, default = 0.01
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.NMRA import ImprovedNMRA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> pb = 0.75
+    >>> pm = 0.01
+    >>> model = ImprovedNMRA(epoch, pop_size, pb, pm)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Salgotra, R. and Singh, U., 2019. The naked mole-rat algorithm.
+    Neural Computing and Applications, 31(12), pp.8837-8857.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, pb=0.75, pm=0.01, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            pb (float): breeding probability, default = 0.75
+            pm (float): probability of mutation, default = 0.01
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.pb = self.validator.check_float("pb", pb, (0, 1.0))
+        self.pm = self.validator.check_float("pm", pm, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "pb", "pm"])
+        self.sort_flag = True
+        self.size_b = int(self.pop_size / 5)
+
+    def crossover_random__(self, pop, g_best):
+        start_point = np.random.randint(0, self.problem.n_dims / 2)
+        id1 = start_point
+        id2 = int(start_point + self.problem.n_dims / 3)
+        id3 = int(self.problem.n_dims)
+
+        partner = pop[np.random.randint(0, self.pop_size)][self.ID_POS]
+        new_temp = deepcopy(g_best[self.ID_POS])
+        new_temp[0:id1] = g_best[self.ID_POS][0:id1]
+        new_temp[id1:id2] = partner[id1:id2]
+        new_temp[id2:id3] = g_best[self.ID_POS][id2:id3]
+        return new_temp
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            # Exploration
+            if idx < self.size_b:  # breeding operators
+                if np.random.uniform() < self.pb:
+                    pos_new = self.pop[idx][self.ID_POS] + np.random.normal(0, 1, self.problem.n_dims) * \
+                              (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+                else:
+                    levy_step = self.get_levy_flight_step(beta=1, multiplier=0.001, case=-1)
+                    pos_new = self.pop[idx][self.ID_POS] + 1.0 / np.sqrt(epoch + 1) * np.sign(np.random.random() - 0.5) * \
+                              levy_step * (self.pop[idx][self.ID_POS] - self.g_best[self.ID_POS])
+            # Exploitation
+            else:  # working operators
+                if np.random.uniform() < 0.5:
+                    t1, t2 = np.random.choice(range(self.size_b, self.pop_size), 2, replace=False)
+                    pos_new = self.pop[idx][self.ID_POS] + np.random.normal(0, 1, self.problem.n_dims) * \
+                              (self.pop[t1][self.ID_POS] - self.pop[t2][self.ID_POS])
+                else:
+                    pos_new = self.crossover_random__(self.pop, self.g_best)
+            # Mutation
+            temp = np.random.uniform(self.problem.lb, self.problem.ub)
+            pos_new = np.where(np.random.uniform(0, 1, self.problem.n_dims) < self.pm, temp, pos_new)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/COA.py` & `mealpy-2.5.3a1/mealpy/swarm_based/JA.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,160 +1,212 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 13:59, 24/06/2021 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalCOA(Optimizer):
-    """
-    The original version of: Coyote Optimization Algorithm (COA)
-
-    Links:
-        1. https://ieeexplore.ieee.org/document/8477769
-        2. https://github.com/jkpir/COA/blob/master/COA.py  (Old version Mealpy < 1.2.2)
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + n_coyotes (int): [3, 15], number of coyotes per group, default=5
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.COA import OriginalCOA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> n_coyotes = 5
-    >>> model = OriginalCOA(epoch, pop_size, n_coyotes)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Pierezan, J. and Coelho, L.D.S., 2018, July. Coyote optimization algorithm: a new metaheuristic
-    for global optimization problems. In 2018 IEEE congress on evolutionary computation (CEC) (pp. 1-8). IEEE.
-    """
-
-    ID_AGE = 2
-
-    def __init__(self, epoch=10000, pop_size=100, n_coyotes=5, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            n_coyotes (int): number of coyotes per group, default=5
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.n_coyotes = self.validator.check_int("n_coyotes", n_coyotes, [2, int(self.pop_size / 2)])
-        self.set_parameters(["epoch", "pop_size", "n_coyotes"])
-        self.n_packs = int(pop_size / self.n_coyotes)
-        self.sort_flag = False
-
-    def initialization(self):
-        if self.pop is None:
-            self.pop = self.create_population(self.pop_size)
-        self.pop_group = self.create_pop_group(self.pop, self.n_packs, self.n_coyotes)
-        self.ps = 1 / self.problem.n_dims
-        self.p_leave = 0.005 * (self.n_coyotes ** 2)  # Probability of leaving a pack
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        """
-        Overriding method in Optimizer class
-
-        Returns:
-            list: wrapper of solution with format [position, target, age]
-        """
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        pos = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(pos)
-        age = 1
-        return [pos, target, age]
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # Execute the operations inside each pack
-        for p in range(self.n_packs):
-            # Get the coyotes that belong to each pack
-
-            self.pop_group[p], local_best = self.get_global_best_solution(self.pop_group[p])
-            # Detect alphas according to the costs (Eq. 5)
-
-            # Compute the social tendency of the pack (Eq. 6)
-            tendency = np.mean([agent[self.ID_POS] for agent in self.pop_group[p]])
-
-            #  Update coyotes' social condition
-            pop_new = []
-            for i in range(self.n_coyotes):
-                rc1, rc2 = np.random.choice(list(set(range(0, self.n_coyotes)) - {i}), 2, replace=False)
-
-                # Try to update the social condition according to the alpha and the pack tendency(Eq. 12)
-                pos_new = self.pop_group[p][i][self.ID_POS] + np.random.rand() * \
-                          (self.pop_group[p][0][self.ID_POS] - self.pop_group[p][rc1][self.ID_POS]) + \
-                          np.random.rand() * (tendency - self.pop_group[p][rc2][self.ID_POS])
-                # Keep the coyotes in the search space (optimization problem constraint)
-                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                pop_new.append([pos_new, None, self.pop_group[p][i][self.ID_AGE]])
-                if self.mode not in self.AVAILABLE_MODES:
-                    pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-            # Evaluate the new social condition (Eq. 13)
-            pop_new = self.update_target_wrapper_population(pop_new)
-            # Adaptation (Eq. 14)
-            self.pop_group[p] = self.greedy_selection_population(self.pop_group[p], pop_new)
-
-            # Birth of a new coyote from random parents (Eq. 7 and Alg. 1)
-            id_dad, id_mom = np.random.choice(list(range(0, self.n_coyotes)), 2, replace=False)
-            prob1 = (1 - self.ps) / 2
-            # Generate the pup considering intrinsic and extrinsic influence
-            pup = np.where(np.random.random(self.problem.n_dims) < prob1,
-                           self.pop_group[p][id_dad][self.ID_POS], self.pop_group[p][id_mom][self.ID_POS])
-            # Eventual noise
-            pos_new = np.random.normal(0, 1) * pup
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            target = self.get_target_wrapper(pos_new)
-
-            # Verify if the pup will survive
-            packs, local_best = self.get_global_best_solution(self.pop_group[p])
-            # Find index of element has fitness larger than new child
-            # If existed an element like that, new child is good
-            if self.compare_agent([pos_new, target], packs[-1]):
-                if self.problem.minmax == "min":
-                    packs = sorted(packs, key=lambda agent: agent[self.ID_AGE])
-                else:
-                    packs = sorted(packs, key=lambda agent: agent[self.ID_AGE], reverse=True)
-                # Replace worst element by new child, New born child with age = 0
-                packs[-1] = [pos_new, target, 0]
-                self.pop_group[p] = deepcopy(packs)
-
-        # A coyote can leave a pack and enter in another pack (Eq. 4)
-        if self.n_packs > 1:
-            if np.random.rand() < self.p_leave:
-                id_pack1, id_pack2 = np.random.choice(list(range(0, self.n_packs)), 2, replace=False)
-                id1, id2 = np.random.choice(list(range(0, self.n_coyotes)), 2, replace=False)
-                self.pop_group[id_pack1][id1], self.pop_group[id_pack2][id2] = self.pop_group[id_pack2][id2], self.pop_group[id_pack1][id1]
-
-        # Update coyotes ages
-        for id_pack in range(0, self.n_packs):
-            for id_coy in range(0, self.n_coyotes):
-                self.pop_group[id_pack][id_coy][self.ID_AGE] += 1
-        self.pop = [agent for pack in self.pop_group for agent in pack]
+#!/usr/bin/env python
+# Created by "Thieu" at 16:30, 16/11/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class BaseJA(Optimizer):
+    """
+    The developed version: Jaya Algorithm (JA)
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.JA import BaseJA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = BaseJA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Rao, R., 2016. Jaya: A simple and new optimization algorithm for solving constrained and
+    unconstrained optimization problems. International Journal of Industrial Engineering Computations, 7(1), pp.19-34.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        _, best, worst = self.get_special_solutions(self.pop, best=1, worst=1)
+        g_best, g_worst = best[0], worst[0]
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            pos_new = self.pop[idx][self.ID_POS] + np.random.uniform() * (g_best[self.ID_POS] - np.abs(self.pop[idx][self.ID_POS])) + \
+                      np.random.normal() * (g_worst[self.ID_POS] - np.abs(self.pop[idx][self.ID_POS]))
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+
+class OriginalJA(BaseJA):
+    """
+    The original version of: Jaya Algorithm (JA)
+
+    Links:
+        1. https://www.growingscience.com/ijiec/Vol7/IJIEC_2015_32.pdf
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.JA import OriginalJA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalJA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Rao, R., 2016. Jaya: A simple and new optimization algorithm for solving constrained and
+    unconstrained optimization problems. International Journal of Industrial Engineering Computations, 7(1), pp.19-34.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(epoch, pop_size, **kwargs)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        _, best, worst = self.get_special_solutions(self.pop, best=1, worst=1)
+        g_best, g_worst = best[0], worst[0]
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            pos_new = self.pop[idx][self.ID_POS] + np.random.uniform(0, 1, self.problem.n_dims) * \
+                      (g_best[self.ID_POS] - np.abs(self.pop[idx][self.ID_POS])) - \
+                      np.random.uniform(0, 1, self.problem.n_dims) * (g_worst[self.ID_POS] - np.abs(self.pop[idx][self.ID_POS]))
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[idx][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+        self.pop = pop_new
+
+
+class LevyJA(BaseJA):
+    """
+    The original version of: Levy-flight Jaya Algorithm (LJA)
+
+    Links:
+        1. https://doi.org/10.1016/j.eswa.2020.113902
+
+    Notes
+    ~~~~~
+    + All third loops in this version also are removed
+    + The beta value of Levy-flight equal to 1.8 as the best value in the paper.
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.JA import LevyJA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = LevyJA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Iacca, G., dos Santos Junior, V.C. and de Melo, V.V., 2021. An improved Jaya optimization
+    algorithm with LÃ©vy flight. Expert Systems with Applications, 165, p.113902.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(epoch, pop_size, **kwargs)
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        _, best, worst = self.get_special_solutions(self.pop, best=1, worst=1)
+        g_best, g_worst = best[0], worst[0]
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            L1 = self.get_levy_flight_step(multiplier=1.0, beta=1.8, case=-1)
+            L2 = self.get_levy_flight_step(multiplier=1.0, beta=1.8, case=-1)
+            pos_new = self.pop[idx][self.ID_POS] + np.abs(L1) * (g_best[self.ID_POS] - np.abs(self.pop[idx][self.ID_POS])) - \
+                      np.abs(L2) * (g_worst[self.ID_POS] - np.abs(self.pop[idx][self.ID_POS]))
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/CSA.py` & `mealpy-2.5.3a1/mealpy/swarm_based/CSA.py`

 * *Ordering differences only*

 * *Files 15% similar despite different names*

```diff
@@ -1,93 +1,93 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 18:37, 28/05/2021 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalCSA(Optimizer):
-    """
-    The original version of: Cuckoo Search Algorithm (CSA)
-
-    Links:
-        1. https://doi.org/10.1109/NABIC.2009.5393690
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + p_a (float): [0.1, 0.7], probability a, default=0.3
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.CSA import OriginalCSA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> p_a = 0.3
-    >>> model = OriginalCSA(epoch, pop_size, p_a)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Yang, X.S. and Deb, S., 2009, December. Cuckoo search via LÃ©vy flights. In 2009 World
-    congress on nature & biologically inspired computing (NaBIC) (pp. 210-214). Ieee.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, p_a=0.3, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            p_a (float): probability a, default=0.3
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.p_a = self.validator.check_float("p_a", p_a, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "p_a"])
-        self.n_cut = int(self.p_a * self.pop_size)
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = deepcopy(self.pop)
-        for i in range(0, self.pop_size):
-            ## Generate levy-flight solution
-            levy_step = self.get_levy_flight_step(multiplier=0.001, case=-1)
-            pos_new = self.pop[i][self.ID_POS] + 1.0 / np.sqrt(epoch + 1) * np.sign(np.random.random() - 0.5) * \
-                      levy_step * (self.pop[i][self.ID_POS] - self.g_best[self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            target = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, target], self.pop[i]):
-                pop_new[i] = [pos_new, target]
-
-        ## Abandoned some worst nests
-        pop = self.get_sorted_strim_population(pop_new, self.pop_size)
-        pop_new = []
-        for i in range(0, self.n_cut):
-            pos_new = np.random.uniform(self.problem.lb, self.problem.ub)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop_new = self.update_target_wrapper_population(pop_new)
-        self.pop = pop[:(self.pop_size - self.n_cut)] + pop_new
+#!/usr/bin/env python
+# Created by "Thieu" at 18:37, 28/05/2021 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalCSA(Optimizer):
+    """
+    The original version of: Cuckoo Search Algorithm (CSA)
+
+    Links:
+        1. https://doi.org/10.1109/NABIC.2009.5393690
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + p_a (float): [0.1, 0.7], probability a, default=0.3
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.CSA import OriginalCSA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> p_a = 0.3
+    >>> model = OriginalCSA(epoch, pop_size, p_a)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Yang, X.S. and Deb, S., 2009, December. Cuckoo search via LÃ©vy flights. In 2009 World
+    congress on nature & biologically inspired computing (NaBIC) (pp. 210-214). Ieee.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, p_a=0.3, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            p_a (float): probability a, default=0.3
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.p_a = self.validator.check_float("p_a", p_a, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "p_a"])
+        self.n_cut = int(self.p_a * self.pop_size)
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = deepcopy(self.pop)
+        for i in range(0, self.pop_size):
+            ## Generate levy-flight solution
+            levy_step = self.get_levy_flight_step(multiplier=0.001, case=-1)
+            pos_new = self.pop[i][self.ID_POS] + 1.0 / np.sqrt(epoch + 1) * np.sign(np.random.random() - 0.5) * \
+                      levy_step * (self.pop[i][self.ID_POS] - self.g_best[self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            target = self.get_target_wrapper(pos_new)
+            if self.compare_agent([pos_new, target], self.pop[i]):
+                pop_new[i] = [pos_new, target]
+
+        ## Abandoned some worst nests
+        pop = self.get_sorted_strim_population(pop_new, self.pop_size)
+        pop_new = []
+        for i in range(0, self.n_cut):
+            pos_new = np.random.uniform(self.problem.lb, self.problem.ub)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop_new = self.update_target_wrapper_population(pop_new)
+        self.pop = pop[:(self.pop_size - self.n_cut)] + pop_new
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/CSO.py` & `mealpy-2.5.3a1/mealpy/swarm_based/CSO.py`

 * *Ordering differences only*

 * *Files 16% similar despite different names*

```diff
@@ -1,180 +1,180 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 10:09, 17/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalCSO(Optimizer):
-    """
-    The original version of: Cat Swarm Optimization (CSO)
-
-    Links:
-        1. https://link.springer.com/chapter/10.1007/978-3-540-36668-3_94
-        2. https://www.hindawi.com/journals/cin/2020/4854895/
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + mixture_ratio (float): joining seeking mode with tracing mode, default=0.15
-        + smp (int): seeking memory pool, default=5 clones (larger is better but time-consuming)
-        + spc (bool): self-position considering, default=False
-        + cdc (float): counts of dimension to change (larger is more diversity but slow convergence), default=0.8
-        + srd (float): seeking range of the selected dimension (smaller is better but slow convergence), default=0.15
-        + c1 (float): same in PSO, default=0.4
-        + w_min (float): same in PSO
-        + w_max (float): same in PSO
-        + selected_strategy (int):  0: best fitness, 1: tournament, 2: roulette wheel, else: random (decrease by quality)
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.CSO import OriginalCSO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> mixture_ratio = 0.15
-    >>> smp = 5
-    >>> spc = False
-    >>> cdc = 0.8
-    >>> srd = 0.15
-    >>> c1 = 0.4
-    >>> w_min = 0.4
-    >>> w_max = 0.9
-    >>> selected_strategy = 1
-    >>> model = OriginalCSO(epoch, pop_size, mixture_ratio, smp, spc, cdc, srd, c1, w_min, w_max, selected_strategy)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Chu, S.C., Tsai, P.W. and Pan, J.S., 2006, August. Cat swarm optimization. In Pacific Rim
-    international conference on artificial intelligence (pp. 854-858). Springer, Berlin, Heidelberg.
-    """
-
-    ID_POS = 0  # position of the cat
-    ID_TAR = 1  # fitness
-    ID_VEL = 2  # velocity
-    ID_FLAG = 3  # status
-
-    def __init__(self, epoch=10000, pop_size=100, mixture_ratio=0.15, smp=5, spc=False,
-                 cdc=0.8, srd=0.15, c1=0.4, w_min=0.5, w_max=0.9, selected_strategy=1, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            mixture_ratio (float): joining seeking mode with tracing mode
-            smp (int): seeking memory pool, 10 clones  (larger is better but time-consuming)
-            spc (bool): self-position considering
-            cdc (float): counts of dimension to change  (larger is more diversity but slow convergence)
-            srd (float): seeking range of the selected dimension (smaller is better but slow convergence)
-            c1 (float): same in PSO
-            w_min (float): same in PSO
-            w_max (float): same in PSO
-            selected_strategy (int):  0: best fitness, 1: tournament, 2: roulette wheel, else: random (decrease by quality)
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.mixture_ratio = self.validator.check_float("mixture_ratio", mixture_ratio, (0, 1.0))
-        self.smp = self.validator.check_int("smp", smp, [2, 10000])
-        self.spc = self.validator.check_bool("spc", spc, [True, False])
-        self.cdc = self.validator.check_float("cdc", cdc, (0, 1.0))
-        self.srd = self.validator.check_float("srd", srd, (0, 1.0))
-        self.c1 = self.validator.check_float("c1", c1, (0, 3.0))
-        self.w_min = self.validator.check_float("w_min", w_min, [0.1, 0.5])
-        self.w_max = self.validator.check_float("w_max", w_max, [0.5, 2.0])
-        self.selected_strategy = self.validator.check_int("selected_strategy", selected_strategy, [0, 4])
-        self.set_parameters(["epoch", "pop_size", "mixture_ratio", "smp", "spc", "cdc", "srd", "c1", "w_min", "w_max", "selected_strategy"])
-        self.sort_flag = False
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        """
-        Overriding method in Optimizer class
-        + x: current position of cat
-        + v: vector v of cat (same amount of dimension as x)
-        + flag: the stage of cat, seeking (looking/finding around) or tracing (chasing/catching) => False: seeking mode , True: tracing mode
-
-        Returns:
-            list: wrapper of solution with format [position, target, velocity, flag]
-        """
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        position = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(position)
-        velocity = np.random.uniform(lb, ub)
-        flag = True if np.random.uniform() < self.mixture_ratio else False
-        return [position, target, velocity, flag]
-
-    def seeking_mode__(self, cat):
-        candidate_cats = []
-        clone_cats = self.create_population(self.smp)
-        if self.spc:
-            candidate_cats.append(deepcopy(cat))
-            clone_cats = [deepcopy(cat) for _ in range(self.smp - 1)]
-
-        for clone in clone_cats:
-            idx = np.random.choice(range(0, self.problem.n_dims), int(self.cdc * self.problem.n_dims), replace=False)
-            pos_new1 = clone[self.ID_POS] * (1 + self.srd)
-            pos_new2 = clone[self.ID_POS] * (1 - self.srd)
-
-            pos_new = np.where(np.random.random(self.problem.n_dims) < 0.5, pos_new1, pos_new2)
-            pos_new[idx] = clone[self.ID_POS][idx]
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            candidate_cats.append([pos_new, None, clone[self.ID_VEL], clone[self.ID_FLAG]])
-            if self.mode not in self.AVAILABLE_MODES:
-                candidate_cats[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        candidate_cats = self.update_target_wrapper_population(candidate_cats)
-
-        if self.selected_strategy == 0:  # Best fitness-self
-            _, cat = self.get_global_best_solution(candidate_cats)
-        elif self.selected_strategy == 1:  # Tournament
-            k_way = 4
-            idx = np.random.choice(range(0, self.smp), k_way, replace=False)
-            cats_k_way = [candidate_cats[_] for _ in idx]
-            _, cat = self.get_global_best_solution(cats_k_way)
-        elif self.selected_strategy == 2:  ### Roul-wheel selection
-            list_fitness = [candidate_cats[u][self.ID_TAR][self.ID_FIT] for u in range(0, len(candidate_cats))]
-            idx = self.get_index_roulette_wheel_selection(list_fitness)
-            cat = candidate_cats[idx]
-        else:
-            idx = np.random.choice(range(0, len(candidate_cats)))
-            cat = candidate_cats[idx]  # Random
-        return cat[self.ID_POS]
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        w = (self.epoch - epoch) / self.epoch * (self.w_max - self.w_min) + self.w_min
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            agent = deepcopy(self.pop[idx])
-            # tracing mode
-            if self.pop[idx][self.ID_FLAG]:
-                pos_new = self.pop[idx][self.ID_POS] + w * self.pop[idx][self.ID_VEL] + \
-                          np.random.uniform() * self.c1 * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            else:
-                pos_new = self.seeking_mode__(self.pop[idx])
-            agent[self.ID_POS] = pos_new
-            agent[self.ID_FLAG] = True if np.random.uniform() < self.mixture_ratio else False
-            pop_new.append(agent)
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        self.pop = self.update_target_wrapper_population(pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 10:09, 17/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalCSO(Optimizer):
+    """
+    The original version of: Cat Swarm Optimization (CSO)
+
+    Links:
+        1. https://link.springer.com/chapter/10.1007/978-3-540-36668-3_94
+        2. https://www.hindawi.com/journals/cin/2020/4854895/
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + mixture_ratio (float): joining seeking mode with tracing mode, default=0.15
+        + smp (int): seeking memory pool, default=5 clones (larger is better but time-consuming)
+        + spc (bool): self-position considering, default=False
+        + cdc (float): counts of dimension to change (larger is more diversity but slow convergence), default=0.8
+        + srd (float): seeking range of the selected dimension (smaller is better but slow convergence), default=0.15
+        + c1 (float): same in PSO, default=0.4
+        + w_min (float): same in PSO
+        + w_max (float): same in PSO
+        + selected_strategy (int):  0: best fitness, 1: tournament, 2: roulette wheel, else: random (decrease by quality)
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.CSO import OriginalCSO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> mixture_ratio = 0.15
+    >>> smp = 5
+    >>> spc = False
+    >>> cdc = 0.8
+    >>> srd = 0.15
+    >>> c1 = 0.4
+    >>> w_min = 0.4
+    >>> w_max = 0.9
+    >>> selected_strategy = 1
+    >>> model = OriginalCSO(epoch, pop_size, mixture_ratio, smp, spc, cdc, srd, c1, w_min, w_max, selected_strategy)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Chu, S.C., Tsai, P.W. and Pan, J.S., 2006, August. Cat swarm optimization. In Pacific Rim
+    international conference on artificial intelligence (pp. 854-858). Springer, Berlin, Heidelberg.
+    """
+
+    ID_POS = 0  # position of the cat
+    ID_TAR = 1  # fitness
+    ID_VEL = 2  # velocity
+    ID_FLAG = 3  # status
+
+    def __init__(self, epoch=10000, pop_size=100, mixture_ratio=0.15, smp=5, spc=False,
+                 cdc=0.8, srd=0.15, c1=0.4, w_min=0.5, w_max=0.9, selected_strategy=1, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            mixture_ratio (float): joining seeking mode with tracing mode
+            smp (int): seeking memory pool, 10 clones  (larger is better but time-consuming)
+            spc (bool): self-position considering
+            cdc (float): counts of dimension to change  (larger is more diversity but slow convergence)
+            srd (float): seeking range of the selected dimension (smaller is better but slow convergence)
+            c1 (float): same in PSO
+            w_min (float): same in PSO
+            w_max (float): same in PSO
+            selected_strategy (int):  0: best fitness, 1: tournament, 2: roulette wheel, else: random (decrease by quality)
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.mixture_ratio = self.validator.check_float("mixture_ratio", mixture_ratio, (0, 1.0))
+        self.smp = self.validator.check_int("smp", smp, [2, 10000])
+        self.spc = self.validator.check_bool("spc", spc, [True, False])
+        self.cdc = self.validator.check_float("cdc", cdc, (0, 1.0))
+        self.srd = self.validator.check_float("srd", srd, (0, 1.0))
+        self.c1 = self.validator.check_float("c1", c1, (0, 3.0))
+        self.w_min = self.validator.check_float("w_min", w_min, [0.1, 0.5])
+        self.w_max = self.validator.check_float("w_max", w_max, [0.5, 2.0])
+        self.selected_strategy = self.validator.check_int("selected_strategy", selected_strategy, [0, 4])
+        self.set_parameters(["epoch", "pop_size", "mixture_ratio", "smp", "spc", "cdc", "srd", "c1", "w_min", "w_max", "selected_strategy"])
+        self.sort_flag = False
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        """
+        Overriding method in Optimizer class
+        + x: current position of cat
+        + v: vector v of cat (same amount of dimension as x)
+        + flag: the stage of cat, seeking (looking/finding around) or tracing (chasing/catching) => False: seeking mode , True: tracing mode
+
+        Returns:
+            list: wrapper of solution with format [position, target, velocity, flag]
+        """
+        if pos is None:
+            pos = self.generate_position(lb, ub)
+        position = self.amend_position(pos, lb, ub)
+        target = self.get_target_wrapper(position)
+        velocity = np.random.uniform(lb, ub)
+        flag = True if np.random.uniform() < self.mixture_ratio else False
+        return [position, target, velocity, flag]
+
+    def seeking_mode__(self, cat):
+        candidate_cats = []
+        clone_cats = self.create_population(self.smp)
+        if self.spc:
+            candidate_cats.append(deepcopy(cat))
+            clone_cats = [deepcopy(cat) for _ in range(self.smp - 1)]
+
+        for clone in clone_cats:
+            idx = np.random.choice(range(0, self.problem.n_dims), int(self.cdc * self.problem.n_dims), replace=False)
+            pos_new1 = clone[self.ID_POS] * (1 + self.srd)
+            pos_new2 = clone[self.ID_POS] * (1 - self.srd)
+
+            pos_new = np.where(np.random.random(self.problem.n_dims) < 0.5, pos_new1, pos_new2)
+            pos_new[idx] = clone[self.ID_POS][idx]
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            candidate_cats.append([pos_new, None, clone[self.ID_VEL], clone[self.ID_FLAG]])
+            if self.mode not in self.AVAILABLE_MODES:
+                candidate_cats[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        candidate_cats = self.update_target_wrapper_population(candidate_cats)
+
+        if self.selected_strategy == 0:  # Best fitness-self
+            _, cat = self.get_global_best_solution(candidate_cats)
+        elif self.selected_strategy == 1:  # Tournament
+            k_way = 4
+            idx = np.random.choice(range(0, self.smp), k_way, replace=False)
+            cats_k_way = [candidate_cats[_] for _ in idx]
+            _, cat = self.get_global_best_solution(cats_k_way)
+        elif self.selected_strategy == 2:  ### Roul-wheel selection
+            list_fitness = [candidate_cats[u][self.ID_TAR][self.ID_FIT] for u in range(0, len(candidate_cats))]
+            idx = self.get_index_roulette_wheel_selection(list_fitness)
+            cat = candidate_cats[idx]
+        else:
+            idx = np.random.choice(range(0, len(candidate_cats)))
+            cat = candidate_cats[idx]  # Random
+        return cat[self.ID_POS]
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        w = (self.epoch - epoch) / self.epoch * (self.w_max - self.w_min) + self.w_min
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            agent = deepcopy(self.pop[idx])
+            # tracing mode
+            if self.pop[idx][self.ID_FLAG]:
+                pos_new = self.pop[idx][self.ID_POS] + w * self.pop[idx][self.ID_VEL] + \
+                          np.random.uniform() * self.c1 * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            else:
+                pos_new = self.seeking_mode__(self.pop[idx])
+            agent[self.ID_POS] = pos_new
+            agent[self.ID_FLAG] = True if np.random.uniform() < self.mixture_ratio else False
+            pop_new.append(agent)
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        self.pop = self.update_target_wrapper_population(pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/CoatiOA.py` & `mealpy-2.5.3a1/mealpy/swarm_based/POA.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,98 +1,93 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 00:08, 27/10/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalCoatiOA(Optimizer):
-    """
-    The original version of: Coati Optimization Algorithm (CoatiOA)
-
-    Links:
-        1. https://www.sciencedirect.com/science/article/pii/S0950705122011042
-        2. https://www.mathworks.com/matlabcentral/fileexchange/116965-coa-coati-optimization-algorithm
-
-    Notes:
-        1. Algorithm design is similar to Zebra Optimization Algorithm (ZOA), Osprey Optimization Algorithm (OOA), Pelican optimization algorithm (POA), Siberian Tiger Optimization (STO), Language Education Optimization (LEO), Serval Optimization Algorithm (SOA), Walrus Optimization Algorithm (WOA), Fennec Fox Optimization (FFO), Three-periods optimization algorithm (TPOA), Teamwork optimization algorithm (TOA), Northern goshawk optimization (NGO), Tasmanian devil optimization (TDO), Archery algorithm (AA), Cat and mouse based optimizer (CMBO)
-        2. It may be useful to compare the Matlab code of this algorithm with those of the similar algorithms to ensure its accuracy and completeness.
-        3. The article may share some similarities with previous work by the same authors, further investigation may be warranted to verify the benchmark results reported in the papers and ensure their reliability and accuracy.
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.CoatiOA import OriginalCoatiOA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalCoatiOA(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Dehghani, M., Montazeri, Z., TrojovskÃ¡, E., & TrojovskÃ½, P. (2023). Coati Optimization Algorithm: A new
-    bio-inspired metaheuristic algorithm for solving optimization problems. Knowledge-Based Systems, 259, 110011.
-    """
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.support_parallel_modes = False
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # Phase1: Hunting and attacking strategy on iguana (Exploration Phase)
-        size2 = int(self.pop_size/2)
-        for idx in range(0, size2):
-
-            pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (self.g_best[self.ID_POS] - np.random.randint(1, 3) * self.pop[idx][self.ID_POS])  # Eq. 4
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            tar_new = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
-                self.pop[idx] = [pos_new, tar_new]
-
-        for idx in range(size2, self.pop_size):
-            iguana = self.create_solution(self.problem.lb, self.problem.ub)
-            if self.compare_agent(iguana, self.pop[idx]):
-                pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (iguana[self.ID_POS] - np.random.randint(1, 3) * self.pop[idx][self.ID_POS])  # Eq. 6
-            else:
-                pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (self.pop[idx][self.ID_POS] - iguana[self.ID_POS])  # Eq. 6
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            tar_new = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
-                self.pop[idx] = [pos_new, tar_new]
-
-        # Phase2: The process of escaping from predators (Exploitation Phase)
-        for idx in range(0, self.pop_size):
-            LO, HI = self.problem.lb / (epoch+1), self.problem.ub / (epoch+1)
-            pos_new = self.pop[idx][self.ID_POS] + (1 - 2 * np.random.rand()) * (LO + np.random.rand() * (HI - LO))     # Eq. 8
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            tar_new = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
-                self.pop[idx] = [pos_new, tar_new]
+#!/usr/bin/env python
+# Created by "Thieu" at 18:22, 11/03/2023 ----------%
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalPOA(Optimizer):
+    """
+    The original version of: Pelican Optimization Algorithm (POA)
+
+    Links:
+        1. https://www.mdpi.com/1424-8220/22/3/855
+        2. https://www.mathworks.com/matlabcentral/fileexchange/106680-pelican-optimization-algorithm-a-novel-nature-inspired
+
+    Notes (Plagiarism):
+        0. This is really disgusting, because the source code for this algorithm is exactly the same as the source code for Northern Goshawk Optimization (NGO)
+        1. Algorithm design is very similar to Zebra Optimization Algorithm (ZOA), Osprey Optimization Algorithm (OOA), Coati Optimization Algorithm (CoatiOA),
+        Siberian Tiger Optimization (STO), Language Education Optimization (LEO), Serval Optimization Algorithm (SOA), Walrus Optimization Algorithm (WOA),
+        Fennec Fox Optimization (FFO), Three-periods optimization algorithm (TPOA), Teamwork optimization algorithm (TOA), Northern goshawk optimization (NGO),
+        Tasmanian devil optimization (TDO), Archery algorithm (AA), Cat and mouse based optimizer (CMBO)
+        2. Check the matlab code of all above algorithms
+        2. Same authors, self-plagiarized article with kinda same algorithm with different meta-metaphors
+        4. Check the results of benchmark functions in the papers, they are mostly make up results
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.POA import OriginalPOA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalPOA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] TrojovskÃ½, P., & Dehghani, M. (2022). Pelican optimization algorithm: A novel nature-inspired
+    algorithm for engineering applications. Sensors, 22(3), 855.
+    """
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.support_parallel_modes = False
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        ## UPDATE location of food
+        kk = np.random.permutation(self.pop_size)[0]
+        for idx in range(0, self.pop_size):
+            # PHASE 1: Moving towards prey (exploration phase)
+            if self.compare_agent(self.pop[kk], self.pop[idx]):     # Eq. 4
+                pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (self.pop[kk][self.ID_POS] - np.random.randint(1, 3) * self.pop[idx][self.ID_POS])
+            else:
+                pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (self.pop[idx][self.ID_POS] - self.pop[kk][self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            tar_new = self.get_target_wrapper(pos_new)
+            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
+                self.pop[idx] = [pos_new, tar_new]
+
+            # PHASE 2: Winging on the water surface (exploitation phase)        # Eq. 6
+            pos_new = self.pop[idx][self.ID_POS] + 0.2 * (1 - (epoch+1)/self.epoch) *(2*np.random.rand(self.problem.n_dims) - 1) * self.pop[idx][self.ID_POS]
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            tar_new = self.get_target_wrapper(pos_new)
+            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
+                self.pop[idx] = [pos_new, tar_new]
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/DMOA.py` & `mealpy-2.5.3a1/mealpy/swarm_based/DMOA.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,235 +1,235 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 17:48, 21/05/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalDMOA(Optimizer):
-    """
-    The original version of: Dwarf Mongoose Optimization Algorithm (DMOA)
-
-    Links:
-        1. https://doi.org/10.1016/j.cma.2022.114570
-        2. https://www.mathworks.com/matlabcentral/fileexchange/105125-dwarf-mongoose-optimization-algorithm
-
-    Notes:
-        1. The Matlab code differs slightly from the original paper
-        2. There are some parameters and equations in the Matlab code that don't seem to have any meaningful purpose.
-        3. The algorithm seems to be weak on solving several problems.
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.DMOA import OriginalDMOA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> n_baby_sitter = 3
-    >>> peep = 2
-    >>> model = OriginalDMOA(epoch, pop_size, n_baby_sitter, peep)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Agushaka, J. O., Ezugwu, A. E., & Abualigah, L. (2022). Dwarf mongoose optimization algorithm.
-    Computer methods in applied mechanics and engineering, 391, 114570.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, n_baby_sitter=3, peep=2, **kwargs):
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.n_baby_sitter = self.validator.check_int("n_baby_sitter", n_baby_sitter, [2, 10])
-        self.peep = self.validator.check_float("peep", peep, [1, 10.])
-        self.n_scout = self.pop_size - self.n_baby_sitter
-        self.support_parallel_modes = False
-        self.set_parameters(["epoch", "pop_size", "n_baby_sitter", "peep"])
-        self.sort_flag = False
-
-    def initialize_variables(self):
-        self.C = np.zeros(self.pop_size)
-        self.tau = -np.inf
-        self.L = np.round(0.6 * self.problem.n_dims * self.n_baby_sitter)
-
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        ## Abandonment Counter
-        CF = (1 - (epoch+1)/self.epoch)**(2*(epoch+1)/self.epoch)
-        fit_list = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in self.pop])
-        mean_cost = np.mean(fit_list)
-        fi = np.exp(-fit_list / mean_cost)
-        for idx in range(0, self.pop_size):
-            alpha = self.get_index_roulette_wheel_selection(fi)
-            k = np.random.choice(list(set(range(0, self.pop_size)) - {idx, alpha}))
-            ## Define Vocalization Coeff.
-            phi = (self.peep / 2) * np.random.uniform(-1, 1, self.problem.n_dims)
-            new_pos = self.pop[alpha][self.ID_POS] + phi * (self.pop[alpha][self.ID_POS] - self.pop[k][self.ID_POS])
-            new_pos = self.amend_position(new_pos, self.problem.lb, self.problem.ub)
-            new_tar = self.get_target_wrapper(new_pos)
-            if self.compare_agent([new_pos, new_tar], self.pop[idx]):
-                self.pop[idx] = [new_pos, new_tar]
-            else:
-                self.C[idx] += 1
-
-        SM = np.zeros(self.pop_size)
-        for idx in range(0, self.pop_size):
-            k = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
-            ## Define Vocalization Coeff.
-            phi = (self.peep / 2) * np.random.uniform(-1, 1, self.problem.n_dims)
-            new_pos = self.pop[idx][self.ID_POS] + phi * (self.pop[idx][self.ID_POS] - self.pop[k][self.ID_POS])
-            new_pos = self.amend_position(new_pos, self.problem.lb, self.problem.ub)
-            new_tar = self.get_target_wrapper(new_pos)
-            ## Sleeping mould
-            SM[idx] = (new_tar[self.ID_FIT] - self.pop[idx][self.ID_TAR][self.ID_FIT])/np.max([new_tar[self.ID_FIT], self.pop[idx][self.ID_TAR][self.ID_FIT]])
-            if self.compare_agent([new_pos, new_tar], self.pop[idx]):
-                self.pop[idx] = [new_pos, new_tar]
-            else:
-                self.C[idx] += 1
-        ## Baby sitters
-        for idx in range(0, self.n_baby_sitter):
-            if self.C[idx] >= self.L:
-                self.pop[idx] = self.create_solution(self.problem.lb, self.problem.ub)
-                self.C[idx] = 0
-
-        ## Next Mongoose position
-        new_tau = np.mean(SM)
-        for idx in range(0, self.pop_size):
-            M = SM[idx] * self.pop[idx][self.ID_POS] / self.pop[idx][self.ID_POS]
-            phi = (self.peep / 2) * np.random.uniform(-1, 1, self.problem.n_dims)
-            if new_tau > self.tau:
-                new_pos = self.pop[idx][self.ID_POS] - CF * phi * np.random.rand() * (self.pop[idx][self.ID_POS] - M)
-            else:
-                new_pos = self.pop[idx][self.ID_POS] + CF * phi * np.random.rand() * (self.pop[idx][self.ID_POS] - M)
-            self.tau = new_tau
-            new_pos = self.amend_position(new_pos, self.problem.lb, self.problem.ub)
-            new_tar = self.get_target_wrapper(new_pos)
-            self.pop[idx] = [new_pos, new_tar]
-
-
-class DevDMOA(Optimizer):
-    """
-    The developed version of: Dwarf Mongoose Optimization Algorithm (DMOA)
-
-    Notes:
-        1. Removed the parameter n_baby_sitter
-        2. Changed in section # Next Mongoose position
-        3. Removed the meaningless variable tau
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.DMOA import DevDMOA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> peep = 2
-    >>> model = DevDMOA(epoch, pop_size, peep)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, peep=2, **kwargs):
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.peep = self.validator.check_float("peep", peep, [1, 10.])
-        self.set_parameters(["epoch", "pop_size", "peep"])
-        self.support_parallel_modes = False
-        self.sort_flag = False
-
-    def initialize_variables(self):
-        self.C = np.zeros(self.pop_size)
-        self.L = np.round(0.6 * self.epoch)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        ## Abandonment Counter
-        CF = (1 - (epoch + 1) / self.epoch) ** (2 * (epoch + 1) / self.epoch)
-        fit_list = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in self.pop])
-        mean_cost = np.mean(fit_list)
-        fi = np.exp(-fit_list / mean_cost)
-
-        ## Foraging led by Alpha female
-        for idx in range(0, self.pop_size):
-            alpha = self.get_index_roulette_wheel_selection(fi)
-            k = np.random.choice(list(set(range(0, self.pop_size)) - {idx, alpha}))
-            ## Define Vocalization Coeff.
-            phi = (self.peep / 2) * np.random.uniform(-1, 1, self.problem.n_dims)
-            new_pos = self.pop[alpha][self.ID_POS] + phi * (self.pop[alpha][self.ID_POS] - self.pop[k][self.ID_POS])
-            new_pos = self.amend_position(new_pos, self.problem.lb, self.problem.ub)
-            new_tar = self.get_target_wrapper(new_pos)
-            if self.compare_agent([new_pos, new_tar], self.pop[idx]):
-                self.pop[idx] = [new_pos, new_tar]
-            else:
-                self.C[idx] += 1
-
-        ## Scout group
-        SM = np.zeros(self.pop_size)
-        for idx in range(0, self.pop_size):
-            k = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
-            ## Define Vocalization Coeff.
-            phi = (self.peep / 2) * np.random.uniform(-1, 1, self.problem.n_dims)
-            new_pos = self.pop[idx][self.ID_POS] + phi * (self.pop[idx][self.ID_POS] - self.pop[k][self.ID_POS])
-            new_pos = self.amend_position(new_pos, self.problem.lb, self.problem.ub)
-            new_tar = self.get_target_wrapper(new_pos)
-            ## Sleeping mould
-            SM[idx] = (new_tar[self.ID_FIT] - self.pop[idx][self.ID_TAR][self.ID_FIT]) / np.max([new_tar[self.ID_FIT], self.pop[idx][self.ID_TAR][self.ID_FIT]])
-            if self.compare_agent([new_pos, new_tar], self.pop[idx]):
-                self.pop[idx] = [new_pos, new_tar]
-            else:
-                self.C[idx] += 1
-
-        ## Baby sitters
-        for idx in range(0, self.pop_size):
-            if self.C[idx] >= self.L:
-                self.pop[idx] = self.create_solution(self.problem.lb, self.problem.ub)
-                self.C[idx] = 0
-
-        ## Next Mongoose position
-        new_tau = np.mean(SM)
-        for idx in range(0, self.pop_size):
-            phi = (self.peep / 2) * np.random.uniform(-1, 1, self.problem.n_dims)
-            if new_tau > SM[idx]:
-                new_pos = self.g_best[self.ID_POS] - CF * phi * (self.g_best[self.ID_POS] - SM[idx] * self.pop[idx][self.ID_POS])
-            else:
-                new_pos = self.pop[idx][self.ID_POS] + CF * phi * (self.g_best[self.ID_POS] - SM[idx] * self.pop[idx][self.ID_POS])
-            new_pos = self.amend_position(new_pos, self.problem.lb, self.problem.ub)
-            new_tar = self.get_target_wrapper(new_pos)
-            if self.compare_agent([new_pos, new_tar], self.pop[idx]):
-                self.pop[idx] = [new_pos, new_tar]
+#!/usr/bin/env python
+# Created by "Thieu" at 17:48, 21/05/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalDMOA(Optimizer):
+    """
+    The original version of: Dwarf Mongoose Optimization Algorithm (DMOA)
+
+    Links:
+        1. https://doi.org/10.1016/j.cma.2022.114570
+        2. https://www.mathworks.com/matlabcentral/fileexchange/105125-dwarf-mongoose-optimization-algorithm
+
+    Notes:
+        1. Matlab code is litle bit difference than original paper
+        2. There are some meaningless parameters and equations in the matlab code
+        3. Weak algorithm
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.DMOA import OriginalDMOA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> n_baby_sitter = 3
+    >>> peep = 2
+    >>> model = OriginalDMOA(epoch, pop_size, n_baby_sitter, peep)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Agushaka, J. O., Ezugwu, A. E., & Abualigah, L. (2022). Dwarf mongoose optimization algorithm.
+    Computer methods in applied mechanics and engineering, 391, 114570.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, n_baby_sitter=3, peep=2, **kwargs):
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.n_baby_sitter = self.validator.check_int("n_baby_sitter", n_baby_sitter, [2, 10])
+        self.peep = self.validator.check_float("peep", peep, [1, 10.])
+        self.n_scout = self.pop_size - self.n_baby_sitter
+        self.support_parallel_modes = False
+        self.set_parameters(["epoch", "pop_size", "n_baby_sitter", "peep"])
+        self.sort_flag = False
+
+    def initialize_variables(self):
+        self.C = np.zeros(self.pop_size)
+        self.tau = -np.inf
+        self.L = np.round(0.6 * self.problem.n_dims * self.n_baby_sitter)
+
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        ## Abandonment Counter
+        CF = (1 - (epoch+1)/self.epoch)**(2*(epoch+1)/self.epoch)
+        fit_list = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in self.pop])
+        mean_cost = np.mean(fit_list)
+        fi = np.exp(-fit_list / mean_cost)
+        for idx in range(0, self.pop_size):
+            alpha = self.get_index_roulette_wheel_selection(fi)
+            k = np.random.choice(list(set(range(0, self.pop_size)) - {idx, alpha}))
+            ## Define Vocalization Coeff.
+            phi = (self.peep / 2) * np.random.uniform(-1, 1, self.problem.n_dims)
+            new_pos = self.pop[alpha][self.ID_POS] + phi * (self.pop[alpha][self.ID_POS] - self.pop[k][self.ID_POS])
+            new_pos = self.amend_position(new_pos, self.problem.lb, self.problem.ub)
+            new_tar = self.get_target_wrapper(new_pos)
+            if self.compare_agent([new_pos, new_tar], self.pop[idx]):
+                self.pop[idx] = [new_pos, new_tar]
+            else:
+                self.C[idx] += 1
+
+        SM = np.zeros(self.pop_size)
+        for idx in range(0, self.pop_size):
+            k = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
+            ## Define Vocalization Coeff.
+            phi = (self.peep / 2) * np.random.uniform(-1, 1, self.problem.n_dims)
+            new_pos = self.pop[idx][self.ID_POS] + phi * (self.pop[idx][self.ID_POS] - self.pop[k][self.ID_POS])
+            new_pos = self.amend_position(new_pos, self.problem.lb, self.problem.ub)
+            new_tar = self.get_target_wrapper(new_pos)
+            ## Sleeping mould
+            SM[idx] = (new_tar[self.ID_FIT] - self.pop[idx][self.ID_TAR][self.ID_FIT])/np.max([new_tar[self.ID_FIT], self.pop[idx][self.ID_TAR][self.ID_FIT]])
+            if self.compare_agent([new_pos, new_tar], self.pop[idx]):
+                self.pop[idx] = [new_pos, new_tar]
+            else:
+                self.C[idx] += 1
+        ## Baby sitters
+        for idx in range(0, self.n_baby_sitter):
+            if self.C[idx] >= self.L:
+                self.pop[idx] = self.create_solution(self.problem.lb, self.problem.ub)
+                self.C[idx] = 0
+
+        ## Next Mongoose position
+        new_tau = np.mean(SM)
+        for idx in range(0, self.pop_size):
+            M = SM[idx] * self.pop[idx][self.ID_POS] / self.pop[idx][self.ID_POS]
+            phi = (self.peep / 2) * np.random.uniform(-1, 1, self.problem.n_dims)
+            if new_tau > self.tau:
+                new_pos = self.pop[idx][self.ID_POS] - CF * phi * np.random.rand() * (self.pop[idx][self.ID_POS] - M)
+            else:
+                new_pos = self.pop[idx][self.ID_POS] + CF * phi * np.random.rand() * (self.pop[idx][self.ID_POS] - M)
+            self.tau = new_tau
+            new_pos = self.amend_position(new_pos, self.problem.lb, self.problem.ub)
+            new_tar = self.get_target_wrapper(new_pos)
+            self.pop[idx] = [new_pos, new_tar]
+
+
+class DevDMOA(Optimizer):
+    """
+    The developed version of: Dwarf Mongoose Optimization Algorithm (DMOA)
+
+    Notes:
+        1. Removed the parameter n_baby_sitter
+        2. Changed in section # Next Mongoose position
+        3. Removed the meaningless variable tau
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.DMOA import DevDMOA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> peep = 2
+    >>> model = DevDMOA(epoch, pop_size, peep)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, peep=2, **kwargs):
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.peep = self.validator.check_float("peep", peep, [1, 10.])
+        self.set_parameters(["epoch", "pop_size", "peep"])
+        self.support_parallel_modes = False
+        self.sort_flag = False
+
+    def initialize_variables(self):
+        self.C = np.zeros(self.pop_size)
+        self.L = np.round(0.6 * self.epoch)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        ## Abandonment Counter
+        CF = (1 - (epoch + 1) / self.epoch) ** (2 * (epoch + 1) / self.epoch)
+        fit_list = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in self.pop])
+        mean_cost = np.mean(fit_list)
+        fi = np.exp(-fit_list / mean_cost)
+
+        ## Foraging led by Alpha female
+        for idx in range(0, self.pop_size):
+            alpha = self.get_index_roulette_wheel_selection(fi)
+            k = np.random.choice(list(set(range(0, self.pop_size)) - {idx, alpha}))
+            ## Define Vocalization Coeff.
+            phi = (self.peep / 2) * np.random.uniform(-1, 1, self.problem.n_dims)
+            new_pos = self.pop[alpha][self.ID_POS] + phi * (self.pop[alpha][self.ID_POS] - self.pop[k][self.ID_POS])
+            new_pos = self.amend_position(new_pos, self.problem.lb, self.problem.ub)
+            new_tar = self.get_target_wrapper(new_pos)
+            if self.compare_agent([new_pos, new_tar], self.pop[idx]):
+                self.pop[idx] = [new_pos, new_tar]
+            else:
+                self.C[idx] += 1
+
+        ## Scout group
+        SM = np.zeros(self.pop_size)
+        for idx in range(0, self.pop_size):
+            k = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
+            ## Define Vocalization Coeff.
+            phi = (self.peep / 2) * np.random.uniform(-1, 1, self.problem.n_dims)
+            new_pos = self.pop[idx][self.ID_POS] + phi * (self.pop[idx][self.ID_POS] - self.pop[k][self.ID_POS])
+            new_pos = self.amend_position(new_pos, self.problem.lb, self.problem.ub)
+            new_tar = self.get_target_wrapper(new_pos)
+            ## Sleeping mould
+            SM[idx] = (new_tar[self.ID_FIT] - self.pop[idx][self.ID_TAR][self.ID_FIT]) / np.max([new_tar[self.ID_FIT], self.pop[idx][self.ID_TAR][self.ID_FIT]])
+            if self.compare_agent([new_pos, new_tar], self.pop[idx]):
+                self.pop[idx] = [new_pos, new_tar]
+            else:
+                self.C[idx] += 1
+
+        ## Baby sitters
+        for idx in range(0, self.pop_size):
+            if self.C[idx] >= self.L:
+                self.pop[idx] = self.create_solution(self.problem.lb, self.problem.ub)
+                self.C[idx] = 0
+
+        ## Next Mongoose position
+        new_tau = np.mean(SM)
+        for idx in range(0, self.pop_size):
+            phi = (self.peep / 2) * np.random.uniform(-1, 1, self.problem.n_dims)
+            if new_tau > SM[idx]:
+                new_pos = self.g_best[self.ID_POS] - CF * phi * (self.g_best[self.ID_POS] - SM[idx] * self.pop[idx][self.ID_POS])
+            else:
+                new_pos = self.pop[idx][self.ID_POS] + CF * phi * (self.g_best[self.ID_POS] - SM[idx] * self.pop[idx][self.ID_POS])
+            new_pos = self.amend_position(new_pos, self.problem.lb, self.problem.ub)
+            new_tar = self.get_target_wrapper(new_pos)
+            if self.compare_agent([new_pos, new_tar], self.pop[idx]):
+                self.pop[idx] = [new_pos, new_tar]
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/DO.py` & `mealpy-2.5.3a1/mealpy/swarm_based/DO.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,162 +1,162 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 04:43, 02/03/2021 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalDO(Optimizer):
-    """
-    The original version of: Dragonfly Optimization (DO)
-
-    Links:
-        1. https://link.springer.com/article/10.1007/s00521-015-1920-1
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.DO import OriginalDO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalDO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Mirjalili, S., 2016. Dragonfly algorithm: a new meta-heuristic optimization technique for
-    solving single-objective, discrete, and multi-objective problems.
-    Neural computing and applications, 27(4), pp.1053-1073.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def initialization(self):
-        if self.pop is None:
-            self.pop = self.create_population(self.pop_size)
-        self.pop_delta = self.create_population(self.pop_size)
-        # Initial radius of dragonflies' neighborhoods
-        self.radius = (self.problem.ub - self.problem.lb) / 10
-        self.delta_max = (self.problem.ub - self.problem.lb) / 10
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        _, best, worst = self.get_special_solutions(self.pop, best=1, worst=1)
-        self.g_best, self.g_worst = best[0], worst[0]
-
-        r = (self.problem.ub - self.problem.lb) / 4 + ((self.problem.ub - self.problem.lb) * (2 * (epoch + 1) / self.epoch))
-        w = 0.9 - (epoch + 1) * ((0.9 - 0.4) / self.epoch)
-        my_c = 0.1 - (epoch + 1) * ((0.1 - 0) / (self.epoch / 2))
-        my_c = 0 if my_c < 0 else my_c
-
-        s = 2 * np.random.rand() * my_c  # Seperation weight
-        a = 2 * np.random.rand() * my_c  # Alignment weight
-        c = 2 * np.random.rand() * my_c  # Cohesion weight
-        f = 2 * np.random.rand()  # Food attraction weight
-        e = my_c  # Enemy distraction weight
-
-        pop_new = []
-        pop_delta_new = []
-        for i in range(0, self.pop_size):
-            pos_neighbours = []
-            pos_neighbours_delta = []
-            neighbours_num = 0
-            # Find the neighbouring solutions
-            for j in range(0, self.pop_size):
-                dist = np.abs(self.pop[i][self.ID_POS] - self.pop[j][self.ID_POS])
-                if np.all(dist <= r) and np.all(dist != 0):
-                    neighbours_num += 1
-                    pos_neighbours.append(self.pop[j][self.ID_POS])
-                    pos_neighbours_delta.append(self.pop_delta[j][self.ID_POS])
-            pos_neighbours = np.array(pos_neighbours)
-            pos_neighbours_delta = np.array(pos_neighbours_delta)
-
-            # Separation: Eq 3.1, Alignment: Eq 3.2, Cohesion: Eq 3.3
-            if neighbours_num > 1:
-                S = np.sum(pos_neighbours, axis=0) - neighbours_num * self.pop[i][self.ID_POS]
-                A = np.sum(pos_neighbours_delta, axis=0) / neighbours_num
-                C_temp = np.sum(pos_neighbours, axis=0) / neighbours_num
-            else:
-                S = np.zeros(self.problem.n_dims)
-                A = deepcopy(self.pop_delta[i][self.ID_POS])
-                C_temp = deepcopy(self.pop[i][self.ID_POS])
-            C = C_temp - self.pop[i][self.ID_POS]
-
-            # Attraction to food: Eq 3.4
-            dist_to_food = np.abs(self.pop[i][self.ID_POS] - self.g_best[self.ID_POS])
-            if np.all(dist_to_food <= r):
-                F = self.g_best[self.ID_POS] - self.pop[i][self.ID_POS]
-            else:
-                F = np.zeros(self.problem.n_dims)
-
-            # Distraction from enemy: Eq 3.5
-            dist_to_enemy = np.abs(self.pop[i][self.ID_POS] - self.g_worst[self.ID_POS])
-            if np.all(dist_to_enemy <= r):
-                enemy = self.g_worst[self.ID_POS] + self.pop[i][self.ID_POS]
-            else:
-                enemy = np.zeros(self.problem.n_dims)
-
-            pos_new = deepcopy(self.pop[i][self.ID_POS]).astype(float)
-            pos_delta_new = deepcopy(self.pop_delta[i][self.ID_POS]).astype(float)
-            if np.any(dist_to_food > r):
-                if neighbours_num > 1:
-                    temp = w * self.pop_delta[i][self.ID_POS] + np.random.uniform(0, 1, self.problem.n_dims) * A + \
-                           np.random.uniform(0, 1, self.problem.n_dims) * C + np.random.uniform(0, 1, self.problem.n_dims) * S
-                    temp = np.clip(temp, -1 * self.delta_max, self.delta_max)
-                    pos_delta_new = deepcopy(temp)
-                    pos_new += temp
-                else:  # Eq. 3.8
-                    pos_new += self.get_levy_flight_step(beta=1.5, multiplier=0.01, case=-1) * self.pop[i][self.ID_POS]
-                    pos_delta_new = np.zeros(self.problem.n_dims)
-            else:
-                # Eq. 3.6
-                temp = (a * A + c * C + s * S + f * F + e * enemy) + w * self.pop_delta[i][self.ID_POS]
-                temp = np.clip(temp, -1 * self.delta_max, self.delta_max)
-                pos_delta_new = temp
-                pos_new += temp
-
-            # Amend solution
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pos_delta_new = self.amend_position(pos_delta_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            pop_delta_new.append([pos_delta_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                target_delta = self.get_target_wrapper(pos_delta_new)
-                self.pop[i] = self.get_better_solution([pos_new, target], self.pop[i])
-                self.pop_delta[i] = self.get_better_solution([pos_delta_new, target_delta], self.pop_delta[i])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            pop_delta_new = self.update_target_wrapper_population(pop_delta_new)
-            self.pop = self.greedy_selection_population(pop_new, self.pop)
-            self.pop_delta = self.greedy_selection_population(pop_delta_new, self.pop_delta)
+#!/usr/bin/env python
+# Created by "Thieu" at 04:43, 02/03/2021 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalDO(Optimizer):
+    """
+    The original version of: Dragonfly Optimization (DO)
+
+    Links:
+        1. https://link.springer.com/article/10.1007/s00521-015-1920-1
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.DO import OriginalDO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalDO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Mirjalili, S., 2016. Dragonfly algorithm: a new meta-heuristic optimization technique for
+    solving single-objective, discrete, and multi-objective problems.
+    Neural computing and applications, 27(4), pp.1053-1073.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def initialization(self):
+        if self.pop is None:
+            self.pop = self.create_population(self.pop_size)
+        self.pop_delta = self.create_population(self.pop_size)
+        # Initial radius of dragonflies' neighborhoods
+        self.radius = (self.problem.ub - self.problem.lb) / 10
+        self.delta_max = (self.problem.ub - self.problem.lb) / 10
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        _, best, worst = self.get_special_solutions(self.pop, best=1, worst=1)
+        self.g_best, self.g_worst = best[0], worst[0]
+
+        r = (self.problem.ub - self.problem.lb) / 4 + ((self.problem.ub - self.problem.lb) * (2 * (epoch + 1) / self.epoch))
+        w = 0.9 - (epoch + 1) * ((0.9 - 0.4) / self.epoch)
+        my_c = 0.1 - (epoch + 1) * ((0.1 - 0) / (self.epoch / 2))
+        my_c = 0 if my_c < 0 else my_c
+
+        s = 2 * np.random.rand() * my_c  # Seperation weight
+        a = 2 * np.random.rand() * my_c  # Alignment weight
+        c = 2 * np.random.rand() * my_c  # Cohesion weight
+        f = 2 * np.random.rand()  # Food attraction weight
+        e = my_c  # Enemy distraction weight
+
+        pop_new = []
+        pop_delta_new = []
+        for i in range(0, self.pop_size):
+            pos_neighbours = []
+            pos_neighbours_delta = []
+            neighbours_num = 0
+            # Find the neighbouring solutions
+            for j in range(0, self.pop_size):
+                dist = np.abs(self.pop[i][self.ID_POS] - self.pop[j][self.ID_POS])
+                if np.all(dist <= r) and np.all(dist != 0):
+                    neighbours_num += 1
+                    pos_neighbours.append(self.pop[j][self.ID_POS])
+                    pos_neighbours_delta.append(self.pop_delta[j][self.ID_POS])
+            pos_neighbours = np.array(pos_neighbours)
+            pos_neighbours_delta = np.array(pos_neighbours_delta)
+
+            # Separation: Eq 3.1, Alignment: Eq 3.2, Cohesion: Eq 3.3
+            if neighbours_num > 1:
+                S = np.sum(pos_neighbours, axis=0) - neighbours_num * self.pop[i][self.ID_POS]
+                A = np.sum(pos_neighbours_delta, axis=0) / neighbours_num
+                C_temp = np.sum(pos_neighbours, axis=0) / neighbours_num
+            else:
+                S = np.zeros(self.problem.n_dims)
+                A = deepcopy(self.pop_delta[i][self.ID_POS])
+                C_temp = deepcopy(self.pop[i][self.ID_POS])
+            C = C_temp - self.pop[i][self.ID_POS]
+
+            # Attraction to food: Eq 3.4
+            dist_to_food = np.abs(self.pop[i][self.ID_POS] - self.g_best[self.ID_POS])
+            if np.all(dist_to_food <= r):
+                F = self.g_best[self.ID_POS] - self.pop[i][self.ID_POS]
+            else:
+                F = np.zeros(self.problem.n_dims)
+
+            # Distraction from enemy: Eq 3.5
+            dist_to_enemy = np.abs(self.pop[i][self.ID_POS] - self.g_worst[self.ID_POS])
+            if np.all(dist_to_enemy <= r):
+                enemy = self.g_worst[self.ID_POS] + self.pop[i][self.ID_POS]
+            else:
+                enemy = np.zeros(self.problem.n_dims)
+
+            pos_new = deepcopy(self.pop[i][self.ID_POS]).astype(float)
+            pos_delta_new = deepcopy(self.pop_delta[i][self.ID_POS]).astype(float)
+            if np.any(dist_to_food > r):
+                if neighbours_num > 1:
+                    temp = w * self.pop_delta[i][self.ID_POS] + np.random.uniform(0, 1, self.problem.n_dims) * A + \
+                           np.random.uniform(0, 1, self.problem.n_dims) * C + np.random.uniform(0, 1, self.problem.n_dims) * S
+                    temp = np.clip(temp, -1 * self.delta_max, self.delta_max)
+                    pos_delta_new = deepcopy(temp)
+                    pos_new += temp
+                else:  # Eq. 3.8
+                    pos_new += self.get_levy_flight_step(beta=1.5, multiplier=0.01, case=-1) * self.pop[i][self.ID_POS]
+                    pos_delta_new = np.zeros(self.problem.n_dims)
+            else:
+                # Eq. 3.6
+                temp = (a * A + c * C + s * S + f * F + e * enemy) + w * self.pop_delta[i][self.ID_POS]
+                temp = np.clip(temp, -1 * self.delta_max, self.delta_max)
+                pos_delta_new = temp
+                pos_new += temp
+
+            # Amend solution
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pos_delta_new = self.amend_position(pos_delta_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            pop_delta_new.append([pos_delta_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                target_delta = self.get_target_wrapper(pos_delta_new)
+                self.pop[i] = self.get_better_solution([pos_new, target], self.pop[i])
+                self.pop_delta[i] = self.get_better_solution([pos_delta_new, target_delta], self.pop_delta[i])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            pop_delta_new = self.update_target_wrapper_population(pop_delta_new)
+            self.pop = self.greedy_selection_population(pop_new, self.pop)
+            self.pop_delta = self.greedy_selection_population(pop_delta_new, self.pop_delta)
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/EHO.py` & `mealpy-2.5.3a1/mealpy/swarm_based/EHO.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,109 +1,109 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 18:41, 08/04/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalEHO(Optimizer):
-    """
-    The original version of: Elephant Herding Optimization (EHO)
-
-    Links:
-        1. https://doi.org/10.1109/ISCBI.2015.8
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + alpha (float): [0.3, 0.8], a factor that determines the influence of the best in each clan, default=0.5
-        + beta (float): [0.3, 0.8], a factor that determines the influence of the x_center, default=0.5
-        + n_clans (int): [3, 10], the number of clans, default=5
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.EHO import OriginalEHO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> alpha = 0.5
-    >>> beta = 0.5
-    >>> n_clans = 5
-    >>> model = OriginalEHO(epoch, pop_size, alpha, beta, n_clans)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Wang, G.G., Deb, S. and Coelho, L.D.S., 2015, December. Elephant herding optimization.
-    In 2015 3rd international symposium on computational and business intelligence (ISCBI) (pp. 1-5). IEEE.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, alpha=0.5, beta=0.5, n_clans=5, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            alpha (float): a factor that determines the influence of the best in each clan, default=0.5
-            beta (float): a factor that determines the influence of the x_center, default=0.5
-            n_clans (int): the number of clans, default=5
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.alpha = self.validator.check_float("alpha", alpha, (0, 3.0))
-        self.beta = self.validator.check_float("beta", beta, (0, 1.0))
-        self.n_clans = self.validator.check_int("n_clans", n_clans, [2, int(self.pop_size/5)])
-        self.set_parameters(["epoch", "pop_size", "alpha", "beta", "n_clans"])
-        self.n_individuals = int(self.pop_size / self.n_clans)
-        self.sort_flag = False
-
-    def initialization(self):
-        if self.pop is None:
-            self.pop = self.create_population(self.pop_size)
-        self.pop_group = self.create_pop_group(self.pop, self.n_clans, self.n_individuals)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # Clan updating operator
-        pop_new = []
-        for i in range(0, self.pop_size):
-            clan_idx = int(i / self.n_individuals)
-            pos_clan_idx = int(i % self.n_individuals)
-
-            if pos_clan_idx == 0:  # The best in clan, because all clans are sorted based on fitness
-                center = np.mean(np.array([item[self.ID_POS] for item in self.pop_group[clan_idx]]), axis=0)
-                pos_new = self.beta * center
-            else:
-                pos_new = self.pop_group[clan_idx][pos_clan_idx][self.ID_POS] + self.alpha * np.random.uniform() * \
-                          (self.pop_group[clan_idx][0][self.ID_POS] - self.pop_group[clan_idx][pos_clan_idx][self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[i] = self.get_better_solution([pos_new, target], self.pop[i])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(pop_new, self.pop)
-        self.pop_group = self.create_pop_group(self.pop, self.n_clans, self.n_individuals)
-        # Separating operator
-        for i in range(0, self.n_clans):
-            self.pop_group[i], _ = self.get_global_best_solution(self.pop_group[i])
-            self.pop_group[i][-1] = self.create_solution(self.problem.lb, self.problem.ub)
-        self.pop = [agent for pack in self.pop_group for agent in pack]
+#!/usr/bin/env python
+# Created by "Thieu" at 18:41, 08/04/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalEHO(Optimizer):
+    """
+    The original version of: Elephant Herding Optimization (EHO)
+
+    Links:
+        1. https://doi.org/10.1109/ISCBI.2015.8
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + alpha (float): [0.3, 0.8], a factor that determines the influence of the best in each clan, default=0.5
+        + beta (float): [0.3, 0.8], a factor that determines the influence of the x_center, default=0.5
+        + n_clans (int): [3, 10], the number of clans, default=5
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.EHO import OriginalEHO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> alpha = 0.5
+    >>> beta = 0.5
+    >>> n_clans = 5
+    >>> model = OriginalEHO(epoch, pop_size, alpha, beta, n_clans)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Wang, G.G., Deb, S. and Coelho, L.D.S., 2015, December. Elephant herding optimization.
+    In 2015 3rd international symposium on computational and business intelligence (ISCBI) (pp. 1-5). IEEE.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, alpha=0.5, beta=0.5, n_clans=5, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            alpha (float): a factor that determines the influence of the best in each clan, default=0.5
+            beta (float): a factor that determines the influence of the x_center, default=0.5
+            n_clans (int): the number of clans, default=5
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.alpha = self.validator.check_float("alpha", alpha, (0, 3.0))
+        self.beta = self.validator.check_float("beta", beta, (0, 1.0))
+        self.n_clans = self.validator.check_int("n_clans", n_clans, [2, int(self.pop_size/5)])
+        self.set_parameters(["epoch", "pop_size", "alpha", "beta", "n_clans"])
+        self.n_individuals = int(self.pop_size / self.n_clans)
+        self.sort_flag = False
+
+    def initialization(self):
+        if self.pop is None:
+            self.pop = self.create_population(self.pop_size)
+        self.pop_group = self.create_pop_group(self.pop, self.n_clans, self.n_individuals)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # Clan updating operator
+        pop_new = []
+        for i in range(0, self.pop_size):
+            clan_idx = int(i / self.n_individuals)
+            pos_clan_idx = int(i % self.n_individuals)
+
+            if pos_clan_idx == 0:  # The best in clan, because all clans are sorted based on fitness
+                center = np.mean(np.array([item[self.ID_POS] for item in self.pop_group[clan_idx]]), axis=0)
+                pos_new = self.beta * center
+            else:
+                pos_new = self.pop_group[clan_idx][pos_clan_idx][self.ID_POS] + self.alpha * np.random.uniform() * \
+                          (self.pop_group[clan_idx][0][self.ID_POS] - self.pop_group[clan_idx][pos_clan_idx][self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[i] = self.get_better_solution([pos_new, target], self.pop[i])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(pop_new, self.pop)
+        self.pop_group = self.create_pop_group(self.pop, self.n_clans, self.n_individuals)
+        # Separating operator
+        for i in range(0, self.n_clans):
+            self.pop_group[i], _ = self.get_global_best_solution(self.pop_group[i])
+            self.pop_group[i][-1] = self.create_solution(self.problem.lb, self.problem.ub)
+        self.pop = [agent for pack in self.pop_group for agent in pack]
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/ESOA.py` & `mealpy-2.5.3a1/mealpy/swarm_based/ESOA.py`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,151 +1,151 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 17:48, 21/05/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-from copy import deepcopy
-
-
-class OriginalESOA(Optimizer):
-    """
-    The original version of: Egret Swarm Optimization Algorithm (ESOA)
-
-    Links:
-        1. https://www.mathworks.com/matlabcentral/fileexchange/115595-egret-swarm-optimization-algorithm-esoa
-        2. https://www.mdpi.com/2313-7673/7/4/144
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.ESOA import OriginalESOA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalESOA(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Chen, Z., Francis, A., Li, S., Liao, B., Xiao, D., Ha, T. T., ... & Cao, X. (2022). Egret Swarm Optimization Algorithm:
-    An Evolutionary Computation Approach for Model Free Optimization. Biomimetics, 7(4), 144.
-    """
-
-    ID_WEI = 2
-    ID_LOC_X = 3
-    ID_LOC_Y = 4
-    ID_G = 5
-    ID_M = 6
-    ID_V = 7
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.support_parallel_modes = False
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        position = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(position)
-        weights = np.random.uniform(-1, 1, len(lb))
-        g = (np.sum(weights * position) - target[self.ID_FIT]) * position
-        m = np.zeros(self.problem.n_dims)
-        v = np.zeros(self.problem.n_dims)
-        return [position, target, weights, position.copy(), deepcopy(target), g, m, v]
-
-    def initialize_variables(self):
-        self.beta1 = 0.9
-        self.beta2 = 0.99
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        hop = self.problem.ub - self.problem.lb
-        for idx in range(0, self.pop_size):
-            # Individual Direction
-            p_d = self.pop[idx][self.ID_LOC_X] - self.pop[idx][self.ID_POS]
-            p_d = p_d * (self.pop[idx][self.ID_LOC_Y][self.ID_FIT] - self.pop[idx][self.ID_TAR][self.ID_FIT])
-            p_d = p_d / ((np.sum(p_d) + self.EPSILON)**2)
-            d_p = p_d + self.pop[idx][self.ID_G]
-
-            # Group Direction
-            c_d = self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]
-            c_d = c_d * (self.g_best[self.ID_TAR][self.ID_FIT] - self.pop[idx][self.ID_TAR][self.ID_FIT])
-            c_d = c_d / ((np.sum(c_d) + self.EPSILON)**2)
-            d_g = c_d + self.g_best[self.ID_G]
-
-            # Gradient Estimation
-            r1 = np.random.random(self.problem.n_dims)
-            r2 = np.random.random(self.problem.n_dims)
-            g = (1 - r1 - r2) * self.pop[idx][self.ID_G] + r1 * d_p + r2 * d_g
-            g = g / (np.sum(g) + self.EPSILON)
-
-            self.pop[idx][self.ID_M] = self.beta1 * self.pop[idx][self.ID_M] + (1 - self.beta1) * g
-            self.pop[idx][self.ID_V] = self.beta2 * self.pop[idx][self.ID_V] + (1 - self.beta2) * g**2
-            self.pop[idx][self.ID_WEI] -= self.pop[idx][self.ID_M] / (np.sqrt(self.pop[idx][self.ID_V]) + self.EPSILON)
-
-            # Advice Forward
-            x_0 = self.pop[idx][self.ID_POS] + np.exp(-1.0 / (0.1 * self.epoch)) * 0.1 * hop * g
-            x_0 = self.amend_position(x_0, self.problem.lb, self.problem.ub)
-            y_0 = self.get_target_wrapper(x_0)
-
-            # Random Search
-            r3 = np.random.uniform(-np.pi/2, np.pi/2, self.problem.n_dims)
-            x_n = self.pop[idx][self.ID_POS] + np.tan(r3) * hop / (1 + epoch) * 0.5
-            x_n = self.amend_position(x_n, self.problem.lb, self.problem.ub)
-            y_n = self.get_target_wrapper(x_n)
-
-            # Encircling Mechanism
-            d = self.pop[idx][self.ID_LOC_X] - self.pop[idx][self.ID_POS]
-            d_g = self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]
-            r1 = np.random.random(self.problem.n_dims)
-            r2 = np.random.random(self.problem.n_dims)
-            x_m = (1 - r1 - r2) * self.pop[idx][self.ID_POS] + r1 * d + r2 * d_g
-            x_m = self.amend_position(x_m, self.problem.lb, self.problem.ub)
-            y_m = self.get_target_wrapper(x_m)
-
-            # Discriminant Condition
-            y_list_compare = [y_0[self.ID_FIT], y_n[self.ID_FIT], y_m[self.ID_FIT]]
-            y_list = [y_0, y_n, y_m]
-            x_list = [x_0, x_n, x_m]
-            if self.problem.minmax == "min":
-                id_best = np.argmin(y_list_compare)
-                x_best = x_list[id_best]
-                y_best = y_list[id_best]
-            else:
-                id_best = np.argmax(y_list_compare)
-                x_best = x_list[id_best]
-                y_best = y_list[id_best]
-
-            if self.compare_agent([x_best, y_best], self.pop[idx]):
-                self.pop[idx][self.ID_POS] = x_best
-                self.pop[idx][self.ID_TAR] = y_best
-                if self.compare_agent([x_best, y_best], [self.pop[idx][self.ID_LOC_X], self.pop[idx][self.ID_LOC_Y]]):
-                    self.pop[idx][self.ID_LOC_X] = x_best
-                    self.pop[idx][self.ID_LOC_Y] = y_best
-                    self.pop[idx][self.ID_G] = (np.sum(self.pop[idx][self.ID_WEI] * self.pop[idx][self.ID_POS]) - self.pop[idx][self.ID_TAR][self.ID_FIT]) * self.pop[idx][self.ID_POS]
-            else:
-                if np.random.rand() < 0.3:
-                    self.pop[idx][self.ID_POS] = x_best
-                    self.pop[idx][self.ID_TAR] = y_best
+#!/usr/bin/env python
+# Created by "Thieu" at 17:48, 21/05/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+from copy import deepcopy
+
+
+class OriginalESOA(Optimizer):
+    """
+    The original version of: Egret Swarm Optimization Algorithm (ESOA)
+
+    Links:
+        1. https://www.mathworks.com/matlabcentral/fileexchange/115595-egret-swarm-optimization-algorithm-esoa
+        2. https://www.mdpi.com/2313-7673/7/4/144
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.ESOA import OriginalESOA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalESOA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Chen, Z., Francis, A., Li, S., Liao, B., Xiao, D., Ha, T. T., ... & Cao, X. (2022). Egret Swarm Optimization Algorithm:
+    An Evolutionary Computation Approach for Model Free Optimization. Biomimetics, 7(4), 144.
+    """
+
+    ID_WEI = 2
+    ID_LOC_X = 3
+    ID_LOC_Y = 4
+    ID_G = 5
+    ID_M = 6
+    ID_V = 7
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.support_parallel_modes = False
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        if pos is None:
+            pos = self.generate_position(lb, ub)
+        position = self.amend_position(pos, lb, ub)
+        target = self.get_target_wrapper(position)
+        weights = np.random.uniform(-1, 1, len(lb))
+        g = (np.sum(weights * position) - target[self.ID_FIT]) * position
+        m = np.zeros(self.problem.n_dims)
+        v = np.zeros(self.problem.n_dims)
+        return [position, target, weights, position.copy(), deepcopy(target), g, m, v]
+
+    def initialize_variables(self):
+        self.beta1 = 0.9
+        self.beta2 = 0.99
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        hop = self.problem.ub - self.problem.lb
+        for idx in range(0, self.pop_size):
+            # Individual Direction
+            p_d = self.pop[idx][self.ID_LOC_X] - self.pop[idx][self.ID_POS]
+            p_d = p_d * (self.pop[idx][self.ID_LOC_Y][self.ID_FIT] - self.pop[idx][self.ID_TAR][self.ID_FIT])
+            p_d = p_d / ((np.sum(p_d) + self.EPSILON)**2)
+            d_p = p_d + self.pop[idx][self.ID_G]
+
+            # Group Direction
+            c_d = self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]
+            c_d = c_d * (self.g_best[self.ID_TAR][self.ID_FIT] - self.pop[idx][self.ID_TAR][self.ID_FIT])
+            c_d = c_d / ((np.sum(c_d) + self.EPSILON)**2)
+            d_g = c_d + self.g_best[self.ID_G]
+
+            # Gradient Estimation
+            r1 = np.random.random(self.problem.n_dims)
+            r2 = np.random.random(self.problem.n_dims)
+            g = (1 - r1 - r2) * self.pop[idx][self.ID_G] + r1 * d_p + r2 * d_g
+            g = g / (np.sum(g) + self.EPSILON)
+
+            self.pop[idx][self.ID_M] = self.beta1 * self.pop[idx][self.ID_M] + (1 - self.beta1) * g
+            self.pop[idx][self.ID_V] = self.beta2 * self.pop[idx][self.ID_V] + (1 - self.beta2) * g**2
+            self.pop[idx][self.ID_WEI] -= self.pop[idx][self.ID_M] / (np.sqrt(self.pop[idx][self.ID_V]) + self.EPSILON)
+
+            # Advice Forward
+            x_0 = self.pop[idx][self.ID_POS] + np.exp(-1.0 / (0.1 * self.epoch)) * 0.1 * hop * g
+            x_0 = self.amend_position(x_0, self.problem.lb, self.problem.ub)
+            y_0 = self.get_target_wrapper(x_0)
+
+            # Random Search
+            r3 = np.random.uniform(-np.pi/2, np.pi/2, self.problem.n_dims)
+            x_n = self.pop[idx][self.ID_POS] + np.tan(r3) * hop / (1 + epoch) * 0.5
+            x_n = self.amend_position(x_n, self.problem.lb, self.problem.ub)
+            y_n = self.get_target_wrapper(x_n)
+
+            # Encircling Mechanism
+            d = self.pop[idx][self.ID_LOC_X] - self.pop[idx][self.ID_POS]
+            d_g = self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]
+            r1 = np.random.random(self.problem.n_dims)
+            r2 = np.random.random(self.problem.n_dims)
+            x_m = (1 - r1 - r2) * self.pop[idx][self.ID_POS] + r1 * d + r2 * d_g
+            x_m = self.amend_position(x_m, self.problem.lb, self.problem.ub)
+            y_m = self.get_target_wrapper(x_m)
+
+            # Discriminant Condition
+            y_list_compare = [y_0[self.ID_FIT], y_n[self.ID_FIT], y_m[self.ID_FIT]]
+            y_list = [y_0, y_n, y_m]
+            x_list = [x_0, x_n, x_m]
+            if self.problem.minmax == "min":
+                id_best = np.argmin(y_list_compare)
+                x_best = x_list[id_best]
+                y_best = y_list[id_best]
+            else:
+                id_best = np.argmax(y_list_compare)
+                x_best = x_list[id_best]
+                y_best = y_list[id_best]
+
+            if self.compare_agent([x_best, y_best], self.pop[idx]):
+                self.pop[idx][self.ID_POS] = x_best
+                self.pop[idx][self.ID_TAR] = y_best
+                if self.compare_agent([x_best, y_best], [self.pop[idx][self.ID_LOC_X], self.pop[idx][self.ID_LOC_Y]]):
+                    self.pop[idx][self.ID_LOC_X] = x_best
+                    self.pop[idx][self.ID_LOC_Y] = y_best
+                    self.pop[idx][self.ID_G] = (np.sum(self.pop[idx][self.ID_WEI] * self.pop[idx][self.ID_POS]) - self.pop[idx][self.ID_TAR][self.ID_FIT]) * self.pop[idx][self.ID_POS]
+            else:
+                if np.random.rand() < 0.3:
+                    self.pop[idx][self.ID_POS] = x_best
+                    self.pop[idx][self.ID_TAR] = y_best
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/FA.py` & `mealpy-2.5.3a1/mealpy/swarm_based/FA.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,133 +1,133 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 22:07, 07/04/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalFA(Optimizer):
-    """
-    The original version of: Fireworks Algorithm (FA)
-
-    Links:
-        1. https://doi.org/10.1007/978-3-642-13495-1_44
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + max_sparks (int): parameter controlling the total number of sparks generated by the pop_size fireworks, default=100
-        + p_a (float): percent (const parameter), default=0.04
-        + p_b (float): percent (const parameter), default=0.8
-        + max_ea (int): maximum explosion amplitude, default=40
-        + m_sparks (int): number of sparks generated in each explosion generation, default=100
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.FA import OriginalFA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> max_sparks = 50
-    >>> p_a = 0.04
-    >>> p_b = 0.8
-    >>> max_ea = 40
-    >>> m_sparks = 50
-    >>> model = OriginalFA(epoch, pop_size, max_sparks, p_a, p_b, max_ea, m_sparks)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Tan, Y. and Zhu, Y., 2010, June. Fireworks algorithm for optimization. In International
-    conference in swarm intelligence (pp. 355-364). Springer, Berlin, Heidelberg.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, max_sparks=100, p_a=0.04, p_b=0.8, max_ea=40, m_sparks=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            max_sparks (int): parameter controlling the total number of sparks generated by the pop_size fireworks, default=100
-            p_a (float): percent (const parameter), default=0.04
-            p_b (float): percent (const parameter), default=0.8
-            max_ea (int): maximum explosion amplitude, default=40
-            m_sparks (int): number of sparks generated in each explosion generation, default=100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.max_sparks = self.validator.check_int("max_sparks", max_sparks, [2, 10000])
-        self.p_a = self.validator.check_float("p_a", p_a, (0, 1.0))
-        self.p_b = self.validator.check_float("p_b", p_b, (0, 1.0))
-        self.max_ea = self.validator.check_int("max_ea", max_ea, [2, 100])
-        self.m_sparks = self.validator.check_int("m_sparks", m_sparks, [2, 10000])
-        self.set_parameters(["epoch", "pop_size", "max_sparks", "p_a", "p_b", "max_ea", "m_sparks"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        fit_list = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in self.pop])
-        fit_list = sorted(fit_list)
-
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            si = self.max_sparks * (fit_list[-1] - self.pop[idx][self.ID_TAR][self.ID_FIT] + self.EPSILON) / \
-                 (self.pop_size * fit_list[-1] - np.sum(fit_list) + self.EPSILON)
-            Ai = self.max_ea * (self.pop[idx][self.ID_TAR][self.ID_FIT] - fit_list[0] + self.EPSILON) / \
-                 (np.sum(fit_list) - fit_list[0] + self.EPSILON)
-            if si < self.p_a * self.max_sparks:
-                si_ = int(round(self.p_a * self.max_sparks) + 1)
-            elif si > self.p_b * self.m_sparks:
-                si_ = int(round(self.p_b * self.max_sparks) + 1)
-            else:
-                si_ = int(round(si) + 1)
-
-            ## Algorithm 1
-            pop_new = []
-            for j in range(0, si_):
-                pos_new = deepcopy(self.pop[idx][self.ID_POS])
-                list_idx = np.random.choice(range(0, self.problem.n_dims), round(np.random.uniform() * self.problem.n_dims), replace=False)
-                displacement = Ai * np.random.uniform(-1, 1)
-                pos_new[list_idx] = pos_new[list_idx] + displacement
-                pos_new = np.where(np.logical_or(pos_new < self.problem.lb, pos_new > self.problem.ub),
-                                   self.problem.lb + np.abs(pos_new) % (self.problem.ub - self.problem.lb), pos_new)
-                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                pop_new.append([pos_new, None])
-                if self.mode not in self.AVAILABLE_MODES:
-                    pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-            pop_new = self.update_target_wrapper_population(pop_new)
-
-        for _ in range(0, self.m_sparks):
-            idx = np.random.randint(0, self.pop_size)
-            pos_new = deepcopy(self.pop[idx][self.ID_POS])
-            list_idx = np.random.choice(range(0, self.problem.n_dims), round(np.random.uniform() * self.problem.n_dims), replace=False)
-            pos_new[list_idx] = pos_new[list_idx] + np.random.normal(0, 1, len(list_idx))  # Gaussian
-            condition = np.logical_or(pos_new < self.problem.lb, pos_new > self.problem.ub)
-            pos_true = self.problem.lb + np.abs(pos_new) % (self.problem.ub - self.problem.lb)
-            pos_new = np.where(condition, pos_true, pos_new)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop_new = self.update_target_wrapper_population(pop_new)
-
-        ## Update the global best
-        self.pop = self.get_sorted_strim_population(pop_new + self.pop, self.pop_size)
+#!/usr/bin/env python
+# Created by "Thieu" at 22:07, 07/04/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalFA(Optimizer):
+    """
+    The original version of: Fireworks Algorithm (FA)
+
+    Links:
+        1. https://doi.org/10.1007/978-3-642-13495-1_44
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + max_sparks (int): parameter controlling the total number of sparks generated by the pop_size fireworks, default=100
+        + p_a (float): percent (const parameter), default=0.04
+        + p_b (float): percent (const parameter), default=0.8
+        + max_ea (int): maximum explosion amplitude, default=40
+        + m_sparks (int): number of sparks generated in each explosion generation, default=100
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.FA import OriginalFA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> max_sparks = 50
+    >>> p_a = 0.04
+    >>> p_b = 0.8
+    >>> max_ea = 40
+    >>> m_sparks = 50
+    >>> model = OriginalFA(epoch, pop_size, max_sparks, p_a, p_b, max_ea, m_sparks)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Tan, Y. and Zhu, Y., 2010, June. Fireworks algorithm for optimization. In International
+    conference in swarm intelligence (pp. 355-364). Springer, Berlin, Heidelberg.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, max_sparks=100, p_a=0.04, p_b=0.8, max_ea=40, m_sparks=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            max_sparks (int): parameter controlling the total number of sparks generated by the pop_size fireworks, default=100
+            p_a (float): percent (const parameter), default=0.04
+            p_b (float): percent (const parameter), default=0.8
+            max_ea (int): maximum explosion amplitude, default=40
+            m_sparks (int): number of sparks generated in each explosion generation, default=100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.max_sparks = self.validator.check_int("max_sparks", max_sparks, [2, 10000])
+        self.p_a = self.validator.check_float("p_a", p_a, (0, 1.0))
+        self.p_b = self.validator.check_float("p_b", p_b, (0, 1.0))
+        self.max_ea = self.validator.check_int("max_ea", max_ea, [2, 100])
+        self.m_sparks = self.validator.check_int("m_sparks", m_sparks, [2, 10000])
+        self.set_parameters(["epoch", "pop_size", "max_sparks", "p_a", "p_b", "max_ea", "m_sparks"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        fit_list = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in self.pop])
+        fit_list = sorted(fit_list)
+
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            si = self.max_sparks * (fit_list[-1] - self.pop[idx][self.ID_TAR][self.ID_FIT] + self.EPSILON) / \
+                 (self.pop_size * fit_list[-1] - np.sum(fit_list) + self.EPSILON)
+            Ai = self.max_ea * (self.pop[idx][self.ID_TAR][self.ID_FIT] - fit_list[0] + self.EPSILON) / \
+                 (np.sum(fit_list) - fit_list[0] + self.EPSILON)
+            if si < self.p_a * self.max_sparks:
+                si_ = int(round(self.p_a * self.max_sparks) + 1)
+            elif si > self.p_b * self.m_sparks:
+                si_ = int(round(self.p_b * self.max_sparks) + 1)
+            else:
+                si_ = int(round(si) + 1)
+
+            ## Algorithm 1
+            pop_new = []
+            for j in range(0, si_):
+                pos_new = deepcopy(self.pop[idx][self.ID_POS])
+                list_idx = np.random.choice(range(0, self.problem.n_dims), round(np.random.uniform() * self.problem.n_dims), replace=False)
+                displacement = Ai * np.random.uniform(-1, 1)
+                pos_new[list_idx] = pos_new[list_idx] + displacement
+                pos_new = np.where(np.logical_or(pos_new < self.problem.lb, pos_new > self.problem.ub),
+                                   self.problem.lb + np.abs(pos_new) % (self.problem.ub - self.problem.lb), pos_new)
+                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                pop_new.append([pos_new, None])
+                if self.mode not in self.AVAILABLE_MODES:
+                    pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+            pop_new = self.update_target_wrapper_population(pop_new)
+
+        for _ in range(0, self.m_sparks):
+            idx = np.random.randint(0, self.pop_size)
+            pos_new = deepcopy(self.pop[idx][self.ID_POS])
+            list_idx = np.random.choice(range(0, self.problem.n_dims), round(np.random.uniform() * self.problem.n_dims), replace=False)
+            pos_new[list_idx] = pos_new[list_idx] + np.random.normal(0, 1, len(list_idx))  # Gaussian
+            condition = np.logical_or(pos_new < self.problem.lb, pos_new > self.problem.ub)
+            pos_true = self.problem.lb + np.abs(pos_new) % (self.problem.ub - self.problem.lb)
+            pos_new = np.where(condition, pos_true, pos_new)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop_new = self.update_target_wrapper_population(pop_new)
+
+        ## Update the global best
+        self.pop = self.get_sorted_strim_population(pop_new + self.pop, self.pop_size)
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/FFA.py` & `mealpy-2.5.3a1/mealpy/human_based/HCO.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,120 +1,134 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 17:13, 01/03/2021 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalFFA(Optimizer):
-    """
-    The original version of: Firefly Algorithm (FFA)
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + gamma (float): Light Absorption Coefficient, default = 0.001
-        + beta_base (float): Attraction Coefficient Base Value, default = 2
-        + alpha (float): Mutation Coefficient, default = 0.2
-        + alpha_damp (float): Mutation Coefficient Damp Rate, default = 0.99
-        + delta (float): Mutation Step Size, default = 0.05
-        + exponent (int): Exponent (m in the paper), default = 2
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.FFA import OriginalFFA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> gamma = 0.001
-    >>> beta_base = 2
-    >>> alpha = 0.2
-    >>> alpha_damp = 0.99
-    >>> delta = 0.05
-    >>> exponent = 2
-    >>> model = OriginalFFA(epoch, pop_size, gamma, beta_base, alpha, alpha_damp, delta, exponent)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Gandomi, A.H., Yang, X.S. and Alavi, A.H., 2011. Mixed variable structural optimization
-    using firefly algorithm. Computers & Structures, 89(23-24), pp.2325-2336.
-    [2] Arora, S. and Singh, S., 2013. The firefly optimization algorithm: convergence analysis and
-    parameter selection. International Journal of Computer Applications, 69(3).
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, gamma=0.001, beta_base=2, alpha=0.2, alpha_damp=0.99, delta=0.05, exponent=2, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            gamma (float): Light Absorption Coefficient, default = 0.001
-            beta_base (float): Attraction Coefficient Base Value, default = 2
-            alpha (float): Mutation Coefficient, default = 0.2
-            alpha_damp (float): Mutation Coefficient Damp Rate, default = 0.99
-            delta (float): Mutation Step Size, default = 0.05
-            exponent (int): Exponent (m in the paper), default = 2
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.gamma = self.validator.check_float("gamma", gamma, (0, 1.0))
-        self.beta_base = self.validator.check_float("beta_base", beta_base, (0, 3.0))
-        self.alpha = self.validator.check_float("alpha", alpha, (0, 1.0))
-        self.alpha_damp = self.validator.check_float("alpha_damp", alpha_damp, (0, 1.0))
-        self.delta = self.validator.check_float("delta", delta, (0, 1.0))
-        self.exponent = self.validator.check_int("exponent", exponent, [2, 4])
-        self.set_parameters(["epoch", "pop_size", "gamma", "beta_base", "alpha", "alpha_damp", "delta", "exponent"])
-        self.support_parallel_modes = False
-        self.sort_flag = False
-
-    def initialize_variables(self):
-        self.dyn_alpha = self.alpha  # Initial Value of Mutation Coefficient
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # Maximum Distance
-        dmax = np.sqrt(self.problem.n_dims)
-        for idx in range(0, self.pop_size):
-            agent = deepcopy(self.pop[idx])
-            pop_child = []
-            for j in range(idx + 1, self.pop_size):
-                # Move Towards Better Solutions
-                if self.compare_agent(self.pop[j], agent):
-                    # Calculate Radius and Attraction Level
-                    rij = np.linalg.norm(agent[self.ID_POS] - self.pop[j][self.ID_POS]) / dmax
-                    beta = self.beta_base * np.exp(-self.gamma * rij ** self.exponent)
-                    # Mutation Vector
-                    mutation_vector = self.delta * np.random.uniform(0, 1, self.problem.n_dims)
-                    temp = np.matmul((self.pop[j][self.ID_POS] - agent[self.ID_POS]),
-                                     np.random.uniform(0, 1, (self.problem.n_dims, self.problem.n_dims)))
-                    pos_new = agent[self.ID_POS] + self.dyn_alpha * mutation_vector + beta * temp
-                    pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                    target = self.get_target_wrapper(pos_new)
-                    pop_child.append([pos_new, target])
-            if len(pop_child) < self.pop_size:
-                pop_child += self.create_population(self.pop_size - len(pop_child))
-            _, local_best = self.get_global_best_solution(pop_child)
-            # Compare to Previous Solution
-            if self.compare_agent(local_best, agent):
-                self.pop[idx] = local_best
-        self.pop.append(self.g_best)
-        self.dyn_alpha = self.alpha_damp * self.alpha
+#!/usr/bin/env python
+# Created by "Thieu" at 08:57, 12/03/2023 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalHCO(Optimizer):
+    """
+    The original version of: Human Conception Optimizer (HCO)
+
+    Links:
+        1. https://www.mathworks.com/matlabcentral/fileexchange/124200-human-conception-optimizer-hco
+        2. https://www.nature.com/articles/s41598-022-25031-6
+
+    Notes:
+        1. Kinda similar to PSO algorithm. Just the concepts of nature-inspired animals are difference
+        2. Matlab code different to the paper
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + w (float): (0, 1.) - weight factor for probability of fitness selection, default=0.65
+        + w1 (float): (0, 1.0) - weight factor for velocity update stage, default=0.05
+        + c1 (float): (0., 3.0) - acceleration coefficient, same as PSO, default=1.4
+        + c2 (float): (0., 3.0) - acceleration coefficient, same as PSO, default=1.4
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.human_based.HCO import OriginalHCO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalHCO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Acharya, D., & Das, D. K. (2022). A novel Human Conception Optimizer for solving optimization problems. Scientific Reports, 12(1), 21631.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, w=0.65, w1=0.05, c1=1.4, c2=1.4, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            w (float): weight factor for probability of fitness selection, default=0.65
+            w1 (float): weight factor for velocity update stage, default=0.05
+            c1 (float): acceleration coefficient, same as PSO, default=1.4
+            c2 (float): acceleration coefficient, same as PSO, default=1.4
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.w = self.validator.check_float("w", w, [0, 1.0])
+        self.w1 = self.validator.check_float("w1", w1, [0, 1.0])
+        self.c1 = self.validator.check_float("c1", c1, [0., 100.])
+        self.c2 = self.validator.check_float("c2", c2, [1., 100.])
+        self.set_parameters(["epoch", "pop_size", "w", "w1", "c1", "c2"])
+        self.sort_flag = False
+
+    def initialization(self):
+        if self.pop is None:
+            self.pop = self.create_population(self.pop_size)
+        pop_op = []
+        for idx in range(0, self.pop_size):
+            pos_new = self.problem.ub + self.problem.lb - self.pop[idx][self.ID_POS]
+            pop_op.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_op = self.update_target_wrapper_population(pop_op)
+            self.pop = self.greedy_selection_population(self.pop, pop_op)
+        _, (best,), (worst,) = self.get_special_solutions(self.pop, best=1, worst=1)
+        pfit = (worst[self.ID_TAR][self.ID_FIT] - best[self.ID_TAR][self.ID_FIT]) * self.w + best[self.ID_TAR][self.ID_FIT]
+        for idx in range(0, self.pop_size):
+            if self.compare_agent([None, [pfit, None]], self.pop[idx]):
+                while True:
+                    sol = self.create_solution(self.problem.lb, self.problem.ub)
+                    if self.compare_agent(sol, [None, [pfit, None]]):
+                        self.pop[idx] = sol
+                        break
+        self.vec = np.random.rand(self.pop_size, self.problem.n_dims)
+        self.pop_p = deepcopy(self.pop)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        lamda = np.random.rand()
+        neu = 2
+        fits = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in self.pop])
+        fit_mean = np.mean(fits)
+        RR = (self.g_best[self.ID_TAR][self.ID_FIT] - fits) ** 2
+        rr = (fit_mean - fits) ** 2
+        ll = RR - rr
+        LL = (self.g_best[self.ID_TAR][self.ID_FIT] - fit_mean)
+        VV = lamda * (ll / (4 * neu * LL))
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            a1 = self.pop_p[idx][self.ID_POS] - self.pop[idx][self.ID_POS]
+            a2 = self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]
+            self.vec[idx] = self.w1 * (VV[idx] + self.vec[idx]) + self.c1 * a1*np.sin(2*np.pi*(epoch+1)/self.epoch) + self.c2*a2*np.sin(2*np.pi*(epoch+1)/self.epoch)
+            pos_new = self.pop[idx][self.ID_POS] + self.vec[idx]
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+
+        for idx in range(0, self.pop_size):
+            if self.compare_agent(pop_new[idx], self.pop[idx]):
+                self.pop[idx] = pop_new[idx]
+                if self.compare_agent(pop_new[idx], self.pop_p[idx]):
+                    self.pop_p[idx] = deepcopy(pop_new[idx])
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/FFO.py` & `mealpy-2.5.3a1/mealpy/swarm_based/FFO.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,88 +1,92 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 18:22, 11/03/2023 ----------%
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalFFO(Optimizer):
-    """
-    The original version of: Fennec Fox Optimization (FFO)
-
-    Links:
-        1. https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9853509
-
-    Notes:
-        1. This is somewhat concerning, as there appears to be a high degree of similarity between the source code for this algorithm and the Pelican Optimization Algorithm (POA).
-        2. Algorithm design is similar to Zebra Optimization Algorithm (ZOA), Osprey Optimization Algorithm (OOA), Coati Optimization Algorithm (CoatiOA), Siberian Tiger Optimization (STO), Language Education Optimization (LEO), Serval Optimization Algorithm (SOA), Walrus Optimization Algorithm (WOA), Pelican Optimization Algorithm (POA), Three-periods optimization algorithm (TPOA), Teamwork optimization algorithm (TOA), Northern goshawk optimization (NGO), Tasmanian devil optimization (TDO), Archery algorithm (AA), Cat and mouse based optimizer (CMBO)
-        3. It may be useful to compare the Matlab code of this algorithm with those of the similar algorithms to ensure its accuracy and completeness.
-        4. The article may share some similarities with previous work by the same authors, further investigation may be warranted to verify the benchmark results reported in the papers and ensure their reliability and accuracy.
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.FFO import OriginalFFO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalFFO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] TrojovskÃ¡, E., Dehghani, M., & TrojovskÃ½, P. (2022). Fennec Fox Optimization: A New
-    Nature-Inspired Optimization Algorithm. IEEE Access, 10, 84417-84443.
-    """
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.support_parallel_modes = False
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        for idx in range(0, self.pop_size):
-            # PHASE 1: THE DIGGING TO LOOK FOR PREY UNDER THE SAND (EXPLOITATION)
-            rr = 0.2 * (1 - (epoch+1) / self.epoch) * self.pop[idx][self.ID_POS]
-            pos_new = self.pop[idx][self.ID_POS] + (2 * np.random.rand() * 1) * rr
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            tar_new = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
-                self.pop[idx] = [pos_new, tar_new]
-
-            # PHASE 2: ESCAPE STRATEGY FROM THE PREDATORSâ ATTACK (EXPLORATION)
-            kk = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
-            if self.compare_agent(self.pop[kk], self.pop[idx]):
-                pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (self.pop[kk][self.ID_POS] - np.random.randint(1, 3) * self.pop[idx][self.ID_POS])
-            else:
-                pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (self.pop[idx][self.ID_POS] - self.pop[kk][self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            tar_new = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
-                self.pop[idx] = [pos_new, tar_new]
+#!/usr/bin/env python
+# Created by "Thieu" at 18:22, 11/03/2023 ----------%
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalFFO(Optimizer):
+    """
+    The original version of: Fennec Fox Optimization (FFO)
+
+    Links:
+        1. https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9853509
+
+    Notes (Plagiarism):
+        0. This is really disgusting, because the source code for this algorithm is almost exactly the same as the source code for Pelican Optimization Algorithm (POA)
+        1. Algorithm design is very similar to Zebra Optimization Algorithm (ZOA), Osprey Optimization Algorithm (OOA), Coati Optimization Algorithm (CoatiOA),
+        Siberian Tiger Optimization (STO), Language Education Optimization (LEO), Serval Optimization Algorithm (SOA), Walrus Optimization Algorithm (WOA),
+        Pelican Optimization Algorithm (POA), Three-periods optimization algorithm (TPOA), Teamwork optimization algorithm (TOA), Northern goshawk optimization (NGO),
+        Tasmanian devil optimization (TDO), Archery algorithm (AA), Cat and mouse based optimizer (CMBO)
+        2. Check the matlab code of all above algorithms
+        2. Same authors, self-plagiarized article with kinda same algorithm with different meta-metaphors
+        4. Check the results of benchmark functions in the papers, they are mostly make up results
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.FFO import OriginalFFO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalFFO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] TrojovskÃ¡, E., Dehghani, M., & TrojovskÃ½, P. (2022). Fennec Fox Optimization: A New
+    Nature-Inspired Optimization Algorithm. IEEE Access, 10, 84417-84443.
+    """
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.support_parallel_modes = False
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        for idx in range(0, self.pop_size):
+            # PHASE 1: THE DIGGING TO LOOK FOR PREY UNDER THE SAND (EXPLOITATION)
+            rr = 0.2 * (1 - (epoch+1) / self.epoch) * self.pop[idx][self.ID_POS]
+            pos_new = self.pop[idx][self.ID_POS] + (2 * np.random.rand() * 1) * rr
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            tar_new = self.get_target_wrapper(pos_new)
+            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
+                self.pop[idx] = [pos_new, tar_new]
+
+            # PHASE 2: ESCAPE STRATEGY FROM THE PREDATORSâ ATTACK (EXPLORATION)
+            kk = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
+            if self.compare_agent(self.pop[kk], self.pop[idx]):
+                pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (self.pop[kk][self.ID_POS] - np.random.randint(1, 3) * self.pop[idx][self.ID_POS])
+            else:
+                pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (self.pop[idx][self.ID_POS] - self.pop[kk][self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            tar_new = self.get_target_wrapper(pos_new)
+            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
+                self.pop[idx] = [pos_new, tar_new]
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/FOA.py` & `mealpy-2.5.3a1/mealpy/swarm_based/WOA.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,237 +1,201 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 14:01, 16/11/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalFOA(Optimizer):
-    """
-    The original version of: Fruit-fly Optimization Algorithm (FOA)
-
-    Links:
-        1. https://doi.org/10.1016/j.knosys.2011.07.001
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.FOA import OriginalFOA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalFOA(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Pan, W.T., 2012. A new fruit fly optimization algorithm: taking the financial distress model
-    as an example. Knowledge-Based Systems, 26, pp.69-74.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def norm_consecutive_adjacent__(self, position=None):
-        return np.array([np.linalg.norm([position[x], position[x + 1]]) for x in range(0, self.problem.n_dims - 1)] + \
-                        [np.linalg.norm([position[-1], position[0]])])
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        """
-        Overriding method in Optimizer class
-
-        Returns:
-            list: a solution with format [position, target]
-        """
-        if pos is None:
-            pos = self.generate_position(self.problem.lb, self.problem.ub)
-        s = self.norm_consecutive_adjacent__(pos)
-        pos = self.amend_position(s, self.problem.lb, self.problem.ub)
-        target = self.get_target_wrapper(pos)
-        return [pos, target]
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * np.random.normal(self.problem.lb, self.problem.ub)
-            pos_new = self.norm_consecutive_adjacent__(pos_new)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(pop_new, self.pop)
-
-
-class BaseFOA(OriginalFOA):
-    """
-    The developed version: Fruit-fly Optimization Algorithm (FOA)
-
-    Notes
-    ~~~~~
-    + The fitness function (small function) is changed by taking the distance each 2 adjacent dimensions
-    + Update the position if only new generated solution is better
-    + The updated position is created by norm distance * gaussian random number
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.FOA import BaseFOA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = BaseFOA(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(epoch, pop_size, **kwargs)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        c = 1 - epoch / self.epoch
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            pos_new = self.pop[idx][self.ID_POS] + np.random.normal(self.problem.lb, self.problem.ub)
-            pos_new = c * np.random.rand() * self.norm_consecutive_adjacent__(pos_new)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(pop_new, self.pop)
-
-
-class WhaleFOA(OriginalFOA):
-    """
-    The original version of: Whale Fruit-fly Optimization Algorithm (WFOA)
-
-    Links:
-        1. https://doi.org/10.1016/j.eswa.2020.113502
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.FOA import WhaleFOA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = WhaleFOA(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Fan, Y., Wang, P., Heidari, A.A., Wang, M., Zhao, X., Chen, H. and Li, C., 2020. Boosted hunting-based
-    fruit fly optimization and advances in real-world problems. Expert Systems with Applications, 159, p.113502.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(epoch, pop_size, **kwargs)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        a = 2 - 2 * epoch / (self.epoch - 1)  # linearly decreased from 2 to 0
-
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            r = np.random.rand()
-            A = 2 * a * r - a
-            C = 2 * r
-            l = np.random.uniform(-1, 1)
-            p = 0.5
-            b = 1
-            if np.random.rand() < p:
-                if np.abs(A) < 1:
-                    D = np.abs(C * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-                    pos_new = self.g_best[self.ID_POS] - A * D
-                else:
-                    # select random 1 position in pop
-                    x_rand = self.pop[np.random.randint(self.pop_size)]
-                    D = np.abs(C * x_rand[self.ID_POS] - self.pop[idx][self.ID_POS])
-                    pos_new = (x_rand[self.ID_POS] - A * D)
-            else:
-                D1 = np.abs(self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-                pos_new = D1 * np.exp(b * l) * np.cos(2 * np.pi * l) + self.g_best[self.ID_POS]
-            smell = self.norm_consecutive_adjacent__(pos_new)
-            pos_new = self.amend_position(smell, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(pop_new, self.pop)
+#!/usr/bin/env python
+# Created by "Thieu" at 10:06, 17/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalWOA(Optimizer):
+    """
+    The original version of: Whale Optimization Algorithm (WOA)
+
+    Links:
+        1. https://doi.org/10.1016/j.advengsoft.2016.01.008
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.WOA import OriginalWOA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalWOA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Mirjalili, S. and Lewis, A., 2016. The whale optimization algorithm.
+    Advances in engineering software, 95, pp.51-67.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        a = 2 - 2 * epoch / (self.epoch - 1)  # linearly decreased from 2 to 0
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            r = np.random.rand()
+            A = 2 * a * r - a
+            C = 2 * r
+            l = np.random.uniform(-1, 1)
+            p = 0.5
+            b = 1
+            if np.random.uniform() < p:
+                if np.abs(A) < 1:
+                    D = np.abs(C * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+                    pos_new = self.g_best[self.ID_POS] - A * D
+                else:
+                    # x_rand = pop[np.random.np.random.randint(self.pop_size)]         # select random 1 position in pop
+                    x_rand = self.create_solution(self.problem.lb, self.problem.ub)
+                    D = np.abs(C * x_rand[self.ID_POS] - self.pop[idx][self.ID_POS])
+                    pos_new = x_rand[self.ID_POS] - A * D
+            else:
+                D1 = np.abs(self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+                pos_new = self.g_best[self.ID_POS] + np.exp(b * l) * np.cos(2 * np.pi * l) * D1
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            print(len(pop_new))
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+
+class HI_WOA(Optimizer):
+    """
+    The original version of: Hybrid Improved Whale Optimization Algorithm (HI-WOA)
+
+    Links:
+        1. https://ieenp.explore.ieee.org/document/8900003
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + feedback_max (int): maximum iterations of each feedback, default = 10
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.WOA import HI_WOA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> feedback_max = 10
+    >>> model = HI_WOA(epoch, pop_size, feedback_max)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Tang, C., Sun, W., Wu, W. and Xue, M., 2019, July. A hybrid improved whale optimization algorithm.
+    In 2019 IEEE 15th International Conference on Control and Automation (ICCA) (pp. 362-367). IEEE.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, feedback_max=10, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            feedback_max (int): maximum iterations of each feedback, default = 10
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.feedback_max = self.validator.check_int("feedback_max", feedback_max, [2, 2+int(self.epoch/2)])
+        # The maximum of times g_best doesn't change -> need to change half of population
+        self.set_parameters(["epoch", "pop_size", "feedback_max"])
+        self.sort_flag = True
+
+    def initialize_variables(self):
+        self.n_changes = int(self.pop_size / 2)
+        self.dyn_feedback_count = 0
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        a = 2 + 2 * np.cos(np.pi / 2 * (1 + epoch / self.epoch))  # Eq. 8
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            r = np.random.rand()
+            A = 2 * a * r - a
+            C = 2 * r
+            l = np.random.uniform(-1, 1)
+            p = 0.5
+            b = 1
+            if np.random.uniform() < p:
+                if np.abs(A) < 1:
+                    D = np.abs(C * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+                    pos_new = self.g_best[self.ID_POS] - A * D
+                else:
+                    # x_rand = pop[np.random.np.random.randint(self.pop_size)]         # select random 1 position in pop
+                    x_rand = self.create_solution(self.problem.lb, self.problem.ub)
+                    D = np.abs(C * x_rand[self.ID_POS] - self.pop[idx][self.ID_POS])
+                    pos_new = x_rand[self.ID_POS] - A * D
+            else:
+                D1 = np.abs(self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+                pos_new = self.g_best[self.ID_POS] + np.exp(b * l) * np.cos(2 * np.pi * l) * D1
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+        ## Feedback Mechanism
+        _, current_best = self.get_global_best_solution(self.pop)
+        if current_best[self.ID_TAR][self.ID_FIT] == self.g_best[self.ID_TAR][self.ID_FIT]:
+            self.dyn_feedback_count += 1
+        else:
+            self.dyn_feedback_count = 0
+
+        if self.dyn_feedback_count >= self.feedback_max:
+            idx_list = np.random.choice(range(0, self.pop_size), self.n_changes, replace=False)
+            pop_child = self.create_population(self.n_changes)
+            for idx_counter, idx in enumerate(idx_list):
+                self.pop[idx] = pop_child[idx_counter]
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/FOX.py` & `mealpy-2.5.3a1/mealpy/swarm_based/FOX.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,103 +1,105 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 00:08, 27/10/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalFOX(Optimizer):
-    """
-    The original version of: Fox Optimizer (FOX)
-
-    Links:
-        1. https://link.springer.com/article/10.1007/s10489-022-03533-0
-        2. https://www.mathworks.com/matlabcentral/fileexchange/121592-fox-a-fox-inspired-optimization-algorithm
-
-    Notes (parameters):
-        1. c1 (float): the probability of jumping (c1 in the paper), default = 0.18
-        2. c2 (float): the probability of jumping (c2 in the paper), default = 0.82
-
-    Notes:
-        1. The equation used to calculate the distance_S_travel value in the Matlab code seems to be lacking in meaning.
-        2. The if-else conditions used with p > 0.18 seem to lack a clear justification. The authors seem to have simply chosen the best value based on their experiments without explaining the rationale behind it.
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.FOX import OriginalFOX
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalFOX(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Mohammed, H., & Rashid, T. (2023). FOX: a FOX-inspired optimization algorithm. Applied Intelligence, 53(1), 1030-1050.
-    """
-    def __init__(self, epoch=10000, pop_size=100, c1=0.18, c2=0.82, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            c1 (float): the probability of jumping (c1 in the paper), default = 0.18
-            c2 (float): the probability of jumping (c2 in the paper), default = 0.82
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.c1 = self.validator.check_float("c1", c1, (-100., 100.))      # c1 in the paper
-        self.c2 = self.validator.check_float("c2", c2, (-100., 100.))      # c2 in the paper
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def initialize_variables(self):
-        self.mint = 10000000
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        aa = 2 * (1 - (1.0 / self.epoch))
-        pop_new = []
-        for idx in range(0, self.pop_size):
-
-            if np.random.rand() >= 0.5:
-                t1 = np.random.rand(self.problem.n_dims)
-                sps = self.g_best[self.ID_POS] / t1
-                dis = 0.5 * sps * t1
-                tt = np.mean(t1)
-                t = tt / 2
-                jump = 0.5 * 9.81 * t ** 2
-                if np.random.rand() > 0.18:
-                    pos_new = dis * jump * self.c1
-                else:
-                    pos_new = dis * jump * self.c2
-                if self.mint > tt:
-                    self.mint = tt
-            else:
-                pos_new = self.g_best[self.ID_POS] + np.random.randn(self.problem.n_dims) * (self.mint * aa)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = [pos_new, target]
-        if self.mode in self.AVAILABLE_MODES:
-            self.pop = self.update_target_wrapper_population(pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 00:08, 27/10/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalFOX(Optimizer):
+    """
+    The original version of: Fox Optimizer (FOX)
+
+    Links:
+        1. https://link.springer.com/article/10.1007/s10489-022-03533-0
+        2. https://www.mathworks.com/matlabcentral/fileexchange/121592-fox-a-fox-inspired-optimization-algorithm
+
+    Notes (parameters):
+        1. c1 (float): the probability of jumping (c1 in the paper), default = 0.18
+        2. c2 (float): the probability of jumping (c2 in the paper), default = 0.82
+
+    Notes (Algorithm's design):
+        1. I don't know how this algorithm get accepted in Applied Intelligence journal
+        2. The equation to calculate distance_S_travel value in matlab code is meaningless
+        3. The whole point of if else conditions with p > 0.18 is meaningless. The authors just choice the best value
+        based on his experiment without explaining it.
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.FOX import OriginalFOX
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalFOX(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Mohammed, H., & Rashid, T. (2023). FOX: a FOX-inspired optimization algorithm. Applied Intelligence, 53(1), 1030-1050.
+    """
+    def __init__(self, epoch=10000, pop_size=100, c1=0.18, c2=0.82, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            c1 (float): the probability of jumping (c1 in the paper), default = 0.18
+            c2 (float): the probability of jumping (c2 in the paper), default = 0.82
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.c1 = self.validator.check_float("c1", c1, (-100., 100.))      # c1 in the paper
+        self.c2 = self.validator.check_float("c2", c2, (-100., 100.))      # c2 in the paper
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def initialize_variables(self):
+        self.mint = 10000000
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        aa = 2 * (1 - (1.0 / self.epoch))
+        pop_new = []
+        for idx in range(0, self.pop_size):
+
+            if np.random.rand() >= 0.5:
+                t1 = np.random.rand(self.problem.n_dims)
+                sps = self.g_best[self.ID_POS] / t1
+                dis = 0.5 * sps * t1
+                tt = np.mean(t1)
+                t = tt / 2
+                jump = 0.5 * 9.81 * t ** 2
+                if np.random.rand() > 0.18:
+                    pos_new = dis * jump * self.c1
+                else:
+                    pos_new = dis * jump * self.c2
+                if self.mint > tt:
+                    self.mint = tt
+            else:
+                pos_new = self.g_best[self.ID_POS] + np.random.randn(self.problem.n_dims) * (self.mint * aa)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = [pos_new, target]
+        if self.mode in self.AVAILABLE_MODES:
+            self.pop = self.update_target_wrapper_population(pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/GJO.py` & `mealpy-2.5.3a1/mealpy/swarm_based/GJO.py`

 * *Ordering differences only*

 * *Files 9% similar despite different names*

```diff
@@ -1,102 +1,102 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 00:08, 27/10/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-from math import gamma
-
-
-class OriginalGJO(Optimizer):
-    """
-    The original version of: Golden jackal optimization (GJO)
-
-    Links:
-        1. https://www.sciencedirect.com/science/article/abs/pii/S095741742200358X
-        2. https://www.mathworks.com/matlabcentral/fileexchange/108889-golden-jackal-optimization-algorithm
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.GJO import OriginalGJO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalGJO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Chopra, N., & Ansari, M. M. (2022). Golden jackal optimization: A novel nature-inspired
-    optimizer for engineering applications. Expert Systems with Applications, 198, 116924.
-    """
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def levy__(self, beta=1.0, size=None):
-        num = gamma(1 + beta) * np.sin(np.pi * beta/2)
-        den = gamma((1+beta)/2) * beta * 2**((beta-1)/2)
-        sigma_u = (num/den)**(1.0/beta)
-        u = np.random.normal(0, sigma_u, size=size)
-        v = np.random.normal(0, 1, size=size)
-        return u/(np.abs(v)**(1.0/beta))
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        E1 = 1.5*(1-((1+epoch)/self.epoch))
-        RL = 0.05*self.levy__(beta=1.5, size=(self.pop_size, self.problem.n_dims))
-        _, (male, female), _ = self.get_special_solutions(self.pop, best=2, worst=1)
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            male_pos = male[self.ID_POS].copy()
-            female_pos = female[self.ID_POS].copy()
-
-            for jdx in range(0, self.problem.n_dims):
-                r1 = np.random.rand()
-                E0 = 2*r1 - 1
-                E = E1 * E0
-                if np.abs(E) < 1:       # EXPLOITATION
-                    t1 = np.abs( (RL[idx, jdx] * male[self.ID_POS][jdx] - self.pop[idx][self.ID_POS][jdx]) )
-                    male_pos[jdx] = male[self.ID_POS][jdx] - E*t1
-                    t2 = np.abs( (RL[idx, jdx] * female[self.ID_POS][jdx] - self.pop[idx][self.ID_POS][jdx]) )
-                    female_pos[jdx] = female[self.ID_POS][jdx] - E*t2
-                else:                   # EXPLORATION
-                    t1 = np.abs((male[self.ID_POS][jdx] - RL[idx, jdx] * self.pop[idx][self.ID_POS][jdx]))
-                    male_pos[jdx] = male[self.ID_POS][jdx] - E * t1
-                    t2 = np.abs((female[self.ID_POS][jdx] - RL[idx, jdx] * self.pop[idx][self.ID_POS][jdx]))
-                    female_pos[jdx] = female[self.ID_POS][jdx] - E * t2
-            pos_new = (male_pos + female_pos) / 2
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = [pos_new, target]
-        if self.mode in self.AVAILABLE_MODES:
-            self.pop = self.update_target_wrapper_population(pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 00:08, 27/10/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+from math import gamma
+
+
+class OriginalGJO(Optimizer):
+    """
+    The original version of: Golden jackal optimization (GJO)
+
+    Links:
+        1. https://www.sciencedirect.com/science/article/abs/pii/S095741742200358X
+        2. https://www.mathworks.com/matlabcentral/fileexchange/108889-golden-jackal-optimization-algorithm
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.GJO import OriginalGJO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalGJO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Chopra, N., & Ansari, M. M. (2022). Golden jackal optimization: A novel nature-inspired
+    optimizer for engineering applications. Expert Systems with Applications, 198, 116924.
+    """
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def levy__(self, beta=1.0, size=None):
+        num = gamma(1 + beta) * np.sin(np.pi * beta/2)
+        den = gamma((1+beta)/2) * beta * 2**((beta-1)/2)
+        sigma_u = (num/den)**(1.0/beta)
+        u = np.random.normal(0, sigma_u, size=size)
+        v = np.random.normal(0, 1, size=size)
+        return u/(np.abs(v)**(1.0/beta))
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        E1 = 1.5*(1-((1+epoch)/self.epoch))
+        RL = 0.05*self.levy__(beta=1.5, size=(self.pop_size, self.problem.n_dims))
+        _, (male, female), _ = self.get_special_solutions(self.pop, best=2, worst=1)
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            male_pos = male[self.ID_POS].copy()
+            female_pos = female[self.ID_POS].copy()
+
+            for jdx in range(0, self.problem.n_dims):
+                r1 = np.random.rand()
+                E0 = 2*r1 - 1
+                E = E1 * E0
+                if np.abs(E) < 1:       # EXPLOITATION
+                    t1 = np.abs( (RL[idx, jdx] * male[self.ID_POS][jdx] - self.pop[idx][self.ID_POS][jdx]) )
+                    male_pos[jdx] = male[self.ID_POS][jdx] - E*t1
+                    t2 = np.abs( (RL[idx, jdx] * female[self.ID_POS][jdx] - self.pop[idx][self.ID_POS][jdx]) )
+                    female_pos[jdx] = female[self.ID_POS][jdx] - E*t2
+                else:                   # EXPLORATION
+                    t1 = np.abs((male[self.ID_POS][jdx] - RL[idx, jdx] * self.pop[idx][self.ID_POS][jdx]))
+                    male_pos[jdx] = male[self.ID_POS][jdx] - E * t1
+                    t2 = np.abs((female[self.ID_POS][jdx] - RL[idx, jdx] * self.pop[idx][self.ID_POS][jdx]))
+                    female_pos[jdx] = female[self.ID_POS][jdx] - E * t2
+            pos_new = (male_pos + female_pos) / 2
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = [pos_new, target]
+        if self.mode in self.AVAILABLE_MODES:
+            self.pop = self.update_target_wrapper_population(pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/GOA.py` & `mealpy-2.5.3a1/mealpy/swarm_based/SCSO.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,103 +1,97 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 14:53, 17/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalGOA(Optimizer):
-    """
-    The original version of: Grasshopper Optimization Algorithm (GOA)
-
-    Links:
-        1. https://dx.doi.org/10.1016/j.advengsoft.2017.01.004
-        2. https://www.mathworks.com/matlabcentral/fileexchange/61421-grasshopper-optimisation-algorithm-goa
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + c_min (float): coefficient c min, default = 0.00004
-        + c_max (float): coefficient c max, default = 1.0
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.GOA import OriginalGOA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> c_min = 0.00004
-    >>> c_max = 1.0
-    >>> model = OriginalGOA(epoch, pop_size, c_min, c_max)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Saremi, S., Mirjalili, S. and Lewis, A., 2017. Grasshopper optimisation algorithm:
-    theory and application. Advances in Engineering Software, 105, pp.30-47.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, c_min=0.00004, c_max=1.0, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            c_min (float): coefficient c min
-            c_max (float): coefficient c max
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.c_min = self.validator.check_float("c_min", c_min, [0.00001, 0.2])
-        self.c_max = self.validator.check_float("c_max", c_max, [0.2, 5.0])
-        self.set_parameters(["epoch", "pop_size", "c_min", "c_max"])
-        self.sort_flag = False
-
-    def s_function__(self, r_vector=None):
-        f = 0.5
-        l = 1.5
-        # Eq.(2.3) in the paper
-        return f * np.exp(-r_vector / l) - np.exp(-r_vector)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # Eq.(2.8) in the paper
-        c = self.c_max - epoch * ((self.c_max - self.c_min) / self.epoch)
-
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            S_i_total = np.zeros(self.problem.n_dims)
-            for j in range(0, self.pop_size):
-                dist = np.sqrt(np.sum((self.pop[idx][self.ID_POS] - self.pop[j][self.ID_POS]) ** 2))
-                r_ij_vector = (self.pop[idx][self.ID_POS] - self.pop[j][self.ID_POS]) / (dist + self.EPSILON)  # xj - xi / dij in Eq.(2.7)
-                xj_xi = 2 + np.remainder(dist, 2)  # |xjd - xid| in Eq. (2.7)
-                ## The first part inside the big bracket in Eq. (2.7)   16 955 230 764    212 047 193 643
-                ran = (c / 2) * (self.problem.ub - self.problem.lb)
-                s_ij = ran * self.s_function__(xj_xi) * r_ij_vector
-                S_i_total += s_ij
-            x_new = c * np.random.normal() * S_i_total + self.g_best[self.ID_POS]  # Eq. (2.7) in the paper
-            pos_new = self.amend_position(x_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 17:36, 21/05/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalSCSO(Optimizer):
+    """
+    The original version of: Sand Cat Swarm Optimization (SCSO)
+
+    Links:
+        1. https://link.springer.com/article/10.1007/s00366-022-01604-x
+        2. https://www.mathworks.com/matlabcentral/fileexchange/110185-sand-cat-swarm-optimization
+
+    Notes:
+        1. The matlab code will not work since the R value always in the range (-1, 1).
+        2. The authors make a mistake in matlab code. It should be 0 <= R <= 1 in the If condition
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.SCSO import OriginalSCSO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalSCSO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Seyyedabbasi, A., & Kiani, F. (2022). Sand Cat swarm optimization: a nature-inspired algorithm to
+    solve global optimization problems. Engineering with Computers, 1-25.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.P = np.arange(1, 361)
+        self.sort_flag = False
+
+    def initialize_variables(self):
+        self.S = 2      # maximum Sensitivity range
+
+    def get_index_roulette_wheel_selection__(self, p):
+        p = p / np.sum(p)
+        c = np.cumsum(p)
+        return np.argwhere(np.random.rand() < c)[0][0]
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        t = self.epoch + 1
+        guides_r = self.S - (self.S * t / self.epoch)
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            r = np.random.rand() * guides_r
+            R = (2*guides_r)*np.random.rand() - guides_r        # controls to transition phases
+            pos_new = self.pop[idx][self.ID_POS].copy()
+            for jdx in range(0, self.problem.n_dims):
+                teta = self.get_index_roulette_wheel_selection__(self.P)
+                if 0 <= R <= 1:
+                    rand_pos = np.abs(np.random.rand() * self.g_best[self.ID_POS][jdx] - self.pop[idx][self.ID_POS][jdx])
+                    pos_new[jdx] = self.g_best[self.ID_POS][jdx] - r * rand_pos * np.cos(teta)
+                else:
+                    cp = int(np.random.rand() * self.pop_size)
+                    pos_new[jdx] = r * (self.pop[cp][self.ID_POS][jdx] - np.random.rand() * self.pop[idx][self.ID_POS][jdx])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        self.pop = self.update_target_wrapper_population(pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/HBA.py` & `mealpy-2.5.3a1/mealpy/swarm_based/HBA.py`

 * *Ordering differences only*

 * *Files 15% similar despite different names*

```diff
@@ -1,107 +1,107 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 17:55, 21/05/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalHBA(Optimizer):
-    """
-    The original version of: Honey Badger Algorithm (HBA)
-
-    Links:
-        1. https://www.sciencedirect.com/science/article/abs/pii/S0378475421002901
-        2. https://www.mathworks.com/matlabcentral/fileexchange/98204-honey-badger-algorithm
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.HBA import OriginalHBA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalHBA(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Hashim, F. A., Houssein, E. H., Hussain, K., Mabrouk, M. S., & Al-Atabany, W. (2022). Honey Badger Algorithm: New metaheuristic
-    algorithm for solving optimization problems. Mathematics and Computers in Simulation, 192, 84-110.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def initialize_variables(self):
-        self.beta = 6       # the ability of HB to get the food  Eq.(4)
-        self.C = 2          # constant in Eq. (3)
-
-    def get_intensity__(self, best, pop):
-        size = len(pop)
-        di = np.zeros(size)
-        si = np.zeros(size)
-        for idx in range(0, size):
-            di[idx] = (np.linalg.norm(pop[idx][self.ID_POS] - best[self.ID_POS]) + self.EPSILON) ** 2
-            if idx == size - 1:
-                si[idx] = (np.linalg.norm(pop[idx][self.ID_POS] - self.pop[0][self.ID_POS]) + self.EPSILON) ** 2
-            else:
-                si[idx] = (np.linalg.norm(pop[idx][self.ID_POS] - self.pop[idx + 1][self.ID_POS]) + self.EPSILON) ** 2
-        r2 = np.random.rand(size)
-        return r2 * si / (4 * np.pi * di)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        t = self.epoch + 1
-        alpha= self.C * np.exp(-t/self.epoch)   # density factor in Eq. (3)
-        I = self.get_intensity__(self.g_best, self.pop)        # intensity in Eq. (2)
-
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            r = np.random.rand()
-            F = np.random.choice([1, -1])
-            di = self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]
-            r3 = np.random.rand(self.problem.n_dims)
-            r4 = np.random.rand(self.problem.n_dims)
-            r5 = np.random.rand(self.problem.n_dims)
-            r6 = np.random.rand(self.problem.n_dims)
-            r7 = np.random.rand(self.problem.n_dims)
-            temp1 = self.g_best[self.ID_POS] + F * self.beta * I[idx] * self.g_best[self.ID_POS] + \
-                F*r3*alpha*di*np.abs(np.cos(2*np.pi*r4) * (1 - np.cos(2*np.pi*r5)))
-            temp2 = self.g_best[self.ID_POS] + F * r7 * alpha * di
-            pos_new = np.where(r6 < 0.5, temp1, temp2)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 17:55, 21/05/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalHBA(Optimizer):
+    """
+    The original version of: Honey Badger Algorithm (HBA)
+
+    Links:
+        1. https://www.sciencedirect.com/science/article/abs/pii/S0378475421002901
+        2. https://www.mathworks.com/matlabcentral/fileexchange/98204-honey-badger-algorithm
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.HBA import OriginalHBA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalHBA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Hashim, F. A., Houssein, E. H., Hussain, K., Mabrouk, M. S., & Al-Atabany, W. (2022). Honey Badger Algorithm: New metaheuristic
+    algorithm for solving optimization problems. Mathematics and Computers in Simulation, 192, 84-110.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def initialize_variables(self):
+        self.beta = 6       # the ability of HB to get the food  Eq.(4)
+        self.C = 2          # constant in Eq. (3)
+
+    def get_intensity__(self, best, pop):
+        size = len(pop)
+        di = np.zeros(size)
+        si = np.zeros(size)
+        for idx in range(0, size):
+            di[idx] = (np.linalg.norm(pop[idx][self.ID_POS] - best[self.ID_POS]) + self.EPSILON) ** 2
+            if idx == size - 1:
+                si[idx] = (np.linalg.norm(pop[idx][self.ID_POS] - self.pop[0][self.ID_POS]) + self.EPSILON) ** 2
+            else:
+                si[idx] = (np.linalg.norm(pop[idx][self.ID_POS] - self.pop[idx + 1][self.ID_POS]) + self.EPSILON) ** 2
+        r2 = np.random.rand(size)
+        return r2 * si / (4 * np.pi * di)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        t = self.epoch + 1
+        alpha= self.C * np.exp(-t/self.epoch)   # density factor in Eq. (3)
+        I = self.get_intensity__(self.g_best, self.pop)        # intensity in Eq. (2)
+
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            r = np.random.rand()
+            F = np.random.choice([1, -1])
+            di = self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]
+            r3 = np.random.rand(self.problem.n_dims)
+            r4 = np.random.rand(self.problem.n_dims)
+            r5 = np.random.rand(self.problem.n_dims)
+            r6 = np.random.rand(self.problem.n_dims)
+            r7 = np.random.rand(self.problem.n_dims)
+            temp1 = self.g_best[self.ID_POS] + F * self.beta * I[idx] * self.g_best[self.ID_POS] + \
+                F*r3*alpha*di*np.abs(np.cos(2*np.pi*r4) * (1 - np.cos(2*np.pi*r5)))
+            temp2 = self.g_best[self.ID_POS] + F * r7 * alpha * di
+            pos_new = np.where(r6 < 0.5, temp1, temp2)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/HGS.py` & `mealpy-2.5.3a1/mealpy/swarm_based/HGS.py`

 * *Ordering differences only*

 * *Files 13% similar despite different names*

```diff
@@ -1,157 +1,157 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 15:37, 19/03/2021 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalHGS(Optimizer):
-    """
-    The original version of: Hunger Games Search (HGS)
-
-    Links:
-        https://aliasgharheidari.com/HGS.html
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + PUP (float): [0.01, 0.2], The probability of updating position (L in the paper), default = 0.08
-        + LH (float): [1000, 20000], Largest hunger / threshold, default = 10000
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.HGS import OriginalHGS
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> PUP = 0.08
-    >>> LH = 10000
-    >>> model = OriginalHGS(epoch, pop_size, PUP, LH)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Yang, Y., Chen, H., Heidari, A.A. and Gandomi, A.H., 2021. Hunger games search: Visions, conception, implementation,
-    deep analysis, perspectives, and towards performance shifts. Expert Systems with Applications, 177, p.114864.
-    """
-
-    ID_HUN = 2  # ID for Hunger value
-
-    def __init__(self, epoch=10000, pop_size=100, PUP=0.08, LH=10000, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            PUP (float): The probability of updating position (L in the paper), default = 0.08
-            LH (float): Largest hunger / threshold, default = 10000
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.PUP = self.validator.check_float("PUP", PUP, (0, 1.0))
-        self.LH = self.validator.check_float("LH", LH, [1000, 20000])
-        self.set_parameters(["epoch", "pop_size", "PUP", "LH"])
-        self.sort_flag = False
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        """
-        Overriding method in Optimizer class
-
-        Returns:
-            list: wrapper of solution with format [position, target, hunger]
-        """
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        position = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(position)
-        hunger = 1.0
-        return [position, target, hunger]
-
-    def sech__(self, x):
-        if np.abs(x) > 50:
-            return 0.5
-        return 2 / (np.exp(x) + np.exp(-x))
-
-    def update_hunger_value__(self, pop=None, g_best=None, g_worst=None):
-        # min_index = pop.index(min(pop, key=lambda x: x[self.ID_TAR][self.ID_FIT]))
-        # Eq (2.8) and (2.9)
-        for i in range(0, self.pop_size):
-            r = np.random.rand()
-            # space: since we pass lower bound and upper bound as list. Better take the np.mean of them.
-            space = np.mean(self.problem.ub - self.problem.lb)
-            H = (pop[i][self.ID_TAR][self.ID_FIT] - g_best[self.ID_TAR][self.ID_FIT]) / \
-                (g_worst[self.ID_TAR][self.ID_FIT] - g_best[self.ID_TAR][self.ID_FIT] + self.EPSILON) * r * 2 * space
-            if H < self.LH:
-                H = self.LH * (1 + r)
-            pop[i][self.ID_HUN] += H
-
-            if g_best[self.ID_TAR][self.ID_FIT] == pop[i][self.ID_TAR][self.ID_FIT]:
-                pop[i][self.ID_HUN] = 0
-        return pop
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        ## Eq. (2.2)
-        ### Find the current best and current worst
-        _, best, worst = self.get_special_solutions(self.pop, best=1, worst=1)
-        g_best, g_worst = best[0], worst[0]
-        pop = self.update_hunger_value__(self.pop, g_best, g_worst)
-
-        ## Eq. (2.4)
-        shrink = 2 * (1 - (epoch + 1) / self.epoch)
-        total_hunger = np.sum([pop[idx][self.ID_HUN] for idx in range(0, self.pop_size)])
-
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            agent = deepcopy(self.pop[idx])
-            #### Variation control
-            E = self.sech__(self.pop[idx][self.ID_TAR][self.ID_FIT] - g_best[self.ID_TAR][self.ID_FIT])
-
-            # R is a ranging controller added to limit the range of activity, in which the range of R is gradually reduced to 0
-            R = 2 * shrink * np.random.rand() - shrink  # Eq. (2.3)
-
-            ## Calculate the hungry weight of each position
-            if np.random.rand() < self.PUP:
-                W1 = self.pop[idx][self.ID_HUN] * self.pop_size / (total_hunger + self.EPSILON) * np.random.rand()
-            else:
-                W1 = 1
-            W2 = (1 - np.exp(-np.abs(self.pop[idx][self.ID_HUN] - total_hunger))) * np.random.rand() * 2
-
-            ### Udpate position of individual Eq. (2.1)
-            r1 = np.random.rand()
-            r2 = np.random.rand()
-            if r1 < self.PUP:
-                pos_new = self.pop[idx][self.ID_POS] * (1 + np.random.normal(0, 1))
-            else:
-                if r2 > E:
-                    pos_new = W1 * g_best[self.ID_POS] + R * W2 * np.abs(g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-                else:
-                    pos_new = W1 * g_best[self.ID_POS] - R * W2 * np.abs(g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            agent[self.ID_POS] = pos_new
-            pop_new.append(agent)
-            if self.mode not in self.AVAILABLE_MODES:
-                agent[self.ID_TAR] = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution(self.pop[idx], agent)
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 15:37, 19/03/2021 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalHGS(Optimizer):
+    """
+    The original version of: Hunger Games Search (HGS)
+
+    Links:
+        https://aliasgharheidari.com/HGS.html
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + PUP (float): [0.01, 0.2], The probability of updating position (L in the paper), default = 0.08
+        + LH (float): [1000, 20000], Largest hunger / threshold, default = 10000
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.HGS import OriginalHGS
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> PUP = 0.08
+    >>> LH = 10000
+    >>> model = OriginalHGS(epoch, pop_size, PUP, LH)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Yang, Y., Chen, H., Heidari, A.A. and Gandomi, A.H., 2021. Hunger games search: Visions, conception, implementation,
+    deep analysis, perspectives, and towards performance shifts. Expert Systems with Applications, 177, p.114864.
+    """
+
+    ID_HUN = 2  # ID for Hunger value
+
+    def __init__(self, epoch=10000, pop_size=100, PUP=0.08, LH=10000, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            PUP (float): The probability of updating position (L in the paper), default = 0.08
+            LH (float): Largest hunger / threshold, default = 10000
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.PUP = self.validator.check_float("PUP", PUP, (0, 1.0))
+        self.LH = self.validator.check_float("LH", LH, [1000, 20000])
+        self.set_parameters(["epoch", "pop_size", "PUP", "LH"])
+        self.sort_flag = False
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        """
+        Overriding method in Optimizer class
+
+        Returns:
+            list: wrapper of solution with format [position, target, hunger]
+        """
+        if pos is None:
+            pos = self.generate_position(lb, ub)
+        position = self.amend_position(pos, lb, ub)
+        target = self.get_target_wrapper(position)
+        hunger = 1.0
+        return [position, target, hunger]
+
+    def sech__(self, x):
+        if np.abs(x) > 50:
+            return 0.5
+        return 2 / (np.exp(x) + np.exp(-x))
+
+    def update_hunger_value__(self, pop=None, g_best=None, g_worst=None):
+        # min_index = pop.index(min(pop, key=lambda x: x[self.ID_TAR][self.ID_FIT]))
+        # Eq (2.8) and (2.9)
+        for i in range(0, self.pop_size):
+            r = np.random.rand()
+            # space: since we pass lower bound and upper bound as list. Better take the np.mean of them.
+            space = np.mean(self.problem.ub - self.problem.lb)
+            H = (pop[i][self.ID_TAR][self.ID_FIT] - g_best[self.ID_TAR][self.ID_FIT]) / \
+                (g_worst[self.ID_TAR][self.ID_FIT] - g_best[self.ID_TAR][self.ID_FIT] + self.EPSILON) * r * 2 * space
+            if H < self.LH:
+                H = self.LH * (1 + r)
+            pop[i][self.ID_HUN] += H
+
+            if g_best[self.ID_TAR][self.ID_FIT] == pop[i][self.ID_TAR][self.ID_FIT]:
+                pop[i][self.ID_HUN] = 0
+        return pop
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        ## Eq. (2.2)
+        ### Find the current best and current worst
+        _, best, worst = self.get_special_solutions(self.pop, best=1, worst=1)
+        g_best, g_worst = best[0], worst[0]
+        pop = self.update_hunger_value__(self.pop, g_best, g_worst)
+
+        ## Eq. (2.4)
+        shrink = 2 * (1 - (epoch + 1) / self.epoch)
+        total_hunger = np.sum([pop[idx][self.ID_HUN] for idx in range(0, self.pop_size)])
+
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            agent = deepcopy(self.pop[idx])
+            #### Variation control
+            E = self.sech__(self.pop[idx][self.ID_TAR][self.ID_FIT] - g_best[self.ID_TAR][self.ID_FIT])
+
+            # R is a ranging controller added to limit the range of activity, in which the range of R is gradually reduced to 0
+            R = 2 * shrink * np.random.rand() - shrink  # Eq. (2.3)
+
+            ## Calculate the hungry weight of each position
+            if np.random.rand() < self.PUP:
+                W1 = self.pop[idx][self.ID_HUN] * self.pop_size / (total_hunger + self.EPSILON) * np.random.rand()
+            else:
+                W1 = 1
+            W2 = (1 - np.exp(-np.abs(self.pop[idx][self.ID_HUN] - total_hunger))) * np.random.rand() * 2
+
+            ### Udpate position of individual Eq. (2.1)
+            r1 = np.random.rand()
+            r2 = np.random.rand()
+            if r1 < self.PUP:
+                pos_new = self.pop[idx][self.ID_POS] * (1 + np.random.normal(0, 1))
+            else:
+                if r2 > E:
+                    pos_new = W1 * g_best[self.ID_POS] + R * W2 * np.abs(g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+                else:
+                    pos_new = W1 * g_best[self.ID_POS] - R * W2 * np.abs(g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            agent[self.ID_POS] = pos_new
+            pop_new.append(agent)
+            if self.mode not in self.AVAILABLE_MODES:
+                agent[self.ID_TAR] = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution(self.pop[idx], agent)
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/HHO.py` & `mealpy-2.5.3a1/mealpy/swarm_based/HHO.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,126 +1,126 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 14:51, 17/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from math import gamma
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalHHO(Optimizer):
-    """
-    The original version of: Harris Hawks Optimization (HHO)
-
-    Links:
-        1. https://doi.org/10.1016/j.future.2019.02.028
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.HHO import OriginalHHO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalHHO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Heidari, A.A., Mirjalili, S., Faris, H., Aljarah, I., Mafarja, M. and Chen, H., 2019.
-    Harris hawks optimization: Algorithm and applications. Future generation computer systems, 97, pp.849-872.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            # -1 < E0 < 1
-            E0 = 2 * np.random.uniform() - 1
-            # factor to show the decreasing energy of rabbit
-            E = 2 * E0 * (1 - (epoch + 1) * 1.0 / self.epoch)
-            J = 2 * (1 - np.random.uniform())
-
-            # -------- Exploration phase Eq. (1) in paper -------------------
-            if np.abs(E) >= 1:
-                # Harris' hawks perch randomly based on 2 strategy:
-                if np.random.rand() >= 0.5:  # perch based on other family members
-                    X_rand = deepcopy(self.pop[np.random.randint(0, self.pop_size)][self.ID_POS])
-                    pos_new = X_rand - np.random.uniform() * np.abs(X_rand - 2 * np.random.uniform() * self.pop[idx][self.ID_POS])
-
-                else:  # perch on a random tall tree (random site inside group's home range)
-                    X_m = np.mean([x[self.ID_POS] for x in self.pop])
-                    pos_new = (self.g_best[self.ID_POS] - X_m) - np.random.uniform() * \
-                              (self.problem.lb + np.random.uniform() * (self.problem.ub - self.problem.lb))
-                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                pop_new.append([pos_new, None])
-            # -------- Exploitation phase -------------------
-            else:
-                # Attacking the rabbit using 4 strategies regarding the behavior of the rabbit
-                # phase 1: ----- surprise pounce (seven kills) ----------
-                # surprise pounce (seven kills): multiple, short rapid dives by different hawks
-                if (np.random.rand() >= 0.5):
-                    delta_X = self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]
-                    if np.abs(E) >= 0.5:  # Hard besiege Eq. (6) in paper
-                        pos_new = delta_X - E * np.abs(J * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-                    else:  # Soft besiege Eq. (4) in paper
-                        pos_new = self.g_best[self.ID_POS] - E * np.abs(delta_X)
-                    pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                    pop_new.append([pos_new, None])
-                else:
-                    xichma = np.power((gamma(1 + 1.5) * np.sin(np.pi * 1.5 / 2.0)) /
-                                      (gamma((1 + 1.5) * 1.5 * np.power(2, (1.5 - 1) / 2)) / 2.0), 1.0 / 1.5)
-                    LF_D = 0.01 * np.random.uniform() * xichma / np.power(np.abs(np.random.uniform()), 1.0 / 1.5)
-                    if np.abs(E) >= 0.5:  # Soft besiege Eq. (10) in paper
-                        Y = self.g_best[self.ID_POS] - E * np.abs(J * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-                    else:  # Hard besiege Eq. (11) in paper
-                        X_m = np.mean([x[self.ID_POS] for x in self.pop])
-                        Y = self.g_best[self.ID_POS] - E * np.abs(J * self.g_best[self.ID_POS] - X_m)
-                    pos_Y = self.amend_position(Y, self.problem.lb, self.problem.ub)
-                    target_Y = self.get_target_wrapper(pos_Y)
-                    Z = Y + np.random.uniform(self.problem.lb, self.problem.ub) * LF_D
-                    pos_Z = self.amend_position(Z, self.problem.lb, self.problem.ub)
-                    target_Z = self.get_target_wrapper(pos_Z)
-                    if self.compare_agent([pos_Y, target_Y], self.pop[idx]):
-                        pop_new.append([pos_Y, target_Y])
-                        continue
-                    if self.compare_agent([pos_Z, target_Z], self.pop[idx]):
-                        pop_new.append([pos_Z, target_Z])
-                        continue
-                    pop_new.append(deepcopy(self.pop[idx]))
-        if self.mode not in self.AVAILABLE_MODES:
-            for idx, agent in enumerate(pop_new):
-                pop_new[idx][self.ID_TAR] = self.get_target_wrapper(agent[self.ID_POS])
-        else:
-            pop_new = self.update_target_wrapper_population(pop_new)
-        self.pop = self.greedy_selection_population(self.pop, pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 14:51, 17/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from math import gamma
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalHHO(Optimizer):
+    """
+    The original version of: Harris Hawks Optimization (HHO)
+
+    Links:
+        1. https://doi.org/10.1016/j.future.2019.02.028
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.HHO import OriginalHHO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalHHO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Heidari, A.A., Mirjalili, S., Faris, H., Aljarah, I., Mafarja, M. and Chen, H., 2019.
+    Harris hawks optimization: Algorithm and applications. Future generation computer systems, 97, pp.849-872.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            # -1 < E0 < 1
+            E0 = 2 * np.random.uniform() - 1
+            # factor to show the decreasing energy of rabbit
+            E = 2 * E0 * (1 - (epoch + 1) * 1.0 / self.epoch)
+            J = 2 * (1 - np.random.uniform())
+
+            # -------- Exploration phase Eq. (1) in paper -------------------
+            if np.abs(E) >= 1:
+                # Harris' hawks perch randomly based on 2 strategy:
+                if np.random.rand() >= 0.5:  # perch based on other family members
+                    X_rand = deepcopy(self.pop[np.random.randint(0, self.pop_size)][self.ID_POS])
+                    pos_new = X_rand - np.random.uniform() * np.abs(X_rand - 2 * np.random.uniform() * self.pop[idx][self.ID_POS])
+
+                else:  # perch on a random tall tree (random site inside group's home range)
+                    X_m = np.mean([x[self.ID_POS] for x in self.pop])
+                    pos_new = (self.g_best[self.ID_POS] - X_m) - np.random.uniform() * \
+                              (self.problem.lb + np.random.uniform() * (self.problem.ub - self.problem.lb))
+                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                pop_new.append([pos_new, None])
+            # -------- Exploitation phase -------------------
+            else:
+                # Attacking the rabbit using 4 strategies regarding the behavior of the rabbit
+                # phase 1: ----- surprise pounce (seven kills) ----------
+                # surprise pounce (seven kills): multiple, short rapid dives by different hawks
+                if (np.random.rand() >= 0.5):
+                    delta_X = self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]
+                    if np.abs(E) >= 0.5:  # Hard besiege Eq. (6) in paper
+                        pos_new = delta_X - E * np.abs(J * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+                    else:  # Soft besiege Eq. (4) in paper
+                        pos_new = self.g_best[self.ID_POS] - E * np.abs(delta_X)
+                    pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                    pop_new.append([pos_new, None])
+                else:
+                    xichma = np.power((gamma(1 + 1.5) * np.sin(np.pi * 1.5 / 2.0)) /
+                                      (gamma((1 + 1.5) * 1.5 * np.power(2, (1.5 - 1) / 2)) / 2.0), 1.0 / 1.5)
+                    LF_D = 0.01 * np.random.uniform() * xichma / np.power(np.abs(np.random.uniform()), 1.0 / 1.5)
+                    if np.abs(E) >= 0.5:  # Soft besiege Eq. (10) in paper
+                        Y = self.g_best[self.ID_POS] - E * np.abs(J * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+                    else:  # Hard besiege Eq. (11) in paper
+                        X_m = np.mean([x[self.ID_POS] for x in self.pop])
+                        Y = self.g_best[self.ID_POS] - E * np.abs(J * self.g_best[self.ID_POS] - X_m)
+                    pos_Y = self.amend_position(Y, self.problem.lb, self.problem.ub)
+                    target_Y = self.get_target_wrapper(pos_Y)
+                    Z = Y + np.random.uniform(self.problem.lb, self.problem.ub) * LF_D
+                    pos_Z = self.amend_position(Z, self.problem.lb, self.problem.ub)
+                    target_Z = self.get_target_wrapper(pos_Z)
+                    if self.compare_agent([pos_Y, target_Y], self.pop[idx]):
+                        pop_new.append([pos_Y, target_Y])
+                        continue
+                    if self.compare_agent([pos_Z, target_Z], self.pop[idx]):
+                        pop_new.append([pos_Z, target_Z])
+                        continue
+                    pop_new.append(deepcopy(self.pop[idx]))
+        if self.mode not in self.AVAILABLE_MODES:
+            for idx, agent in enumerate(pop_new):
+                pop_new[idx][self.ID_TAR] = self.get_target_wrapper(agent[self.ID_POS])
+        else:
+            pop_new = self.update_target_wrapper_population(pop_new)
+        self.pop = self.greedy_selection_population(self.pop, pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/MFO.py` & `mealpy-2.5.3a1/mealpy/swarm_based/MFO.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,181 +1,181 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 11:59, 17/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class BaseMFO(Optimizer):
-    """
-    The developed version: Moth-Flame Optimization (MFO)
-
-    Notes
-    ~~~~~
-    + The flow of algorithm is changed
-    + The old solution is updated
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.MFO import BaseMFO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = BaseMFO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Mirjalili, S., 2015. Moth-flame optimization algorithm: A novel nature-inspired
-    heuristic paradigm. Knowledge-based systems, 89, pp.228-249.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # Number of flames Eq.(3.14) in the paper (linearly decreased)
-        num_flame = round(self.pop_size - (epoch + 1) * ((self.pop_size - 1) / self.epoch))
-
-        # a linearly decreases from -1 to -2 to calculate t in Eq. (3.12)
-        a = -1 + (epoch + 1) * ((-1) / self.epoch)
-
-        pop_flames, g_best = self.get_global_best_solution(self.pop)
-
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            #   D in Eq.(3.13)
-            distance_to_flame = np.abs(pop_flames[idx][self.ID_POS] - self.pop[idx][self.ID_POS])
-            t = (a - 1) * np.random.uniform(0, 1, self.problem.n_dims) + 1
-            b = 1
-
-            # Update the position of the moth with respect to its corresponding flame, Eq.(3.12).
-            temp_1 = distance_to_flame * np.exp(b * t) * np.cos(t * 2 * np.pi) + pop_flames[idx][self.ID_POS]
-
-            # Update the position of the moth with respect to one flame Eq.(3.12).
-            ## Here is a changed, I used the best position of flames not the position num_flame th (as original code)
-            temp_2 = distance_to_flame * np.exp(b * t) * np.cos(t * 2 * np.pi) + g_best[self.ID_POS]
-
-            list_idx = idx * np.ones(self.problem.n_dims)
-            pos_new = np.where(list_idx < num_flame, temp_1, temp_2)
-
-            ## This is the way I make this algorithm working. I tried to run matlab code with large dimension and it doesn't convergence.
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-
-class OriginalMFO(BaseMFO):
-    """
-    The original version of: Moth-flame Optimization (MFO)
-
-    Link:
-        1. https://www.mathworks.com/matlabcentral/fileexchange/52269-moth-flame-optimization-mfo-algorithm
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.MFO import OriginalMFO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalMFO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Mirjalili, S., 2015. Moth-flame optimization algorithm: A novel nature-inspired
-    heuristic paradigm. Knowledge-based systems, 89, pp.228-249.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(epoch, pop_size, **kwargs)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # Number of flames Eq.(3.14) in the paper (linearly decreased)
-        num_flame = round(self.pop_size - (epoch + 1) * ((self.pop_size - 1) / self.epoch))
-
-        # a linearly decreases from -1 to -2 to calculate t in Eq. (3.12)
-        a = -1 + (epoch + 1) * ((-1) / self.epoch)
-
-        pop_flames, g_best = self.get_global_best_solution(self.pop)
-
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            pos_new = deepcopy(self.pop[idx][self.ID_POS])
-            for j in range(self.problem.n_dims):
-                #   D in Eq.(3.13)
-                distance_to_flame = np.abs(pop_flames[idx][self.ID_POS][j] - self.pop[idx][self.ID_POS][j])
-                t = (a - 1) * np.random.uniform() + 1
-                b = 1
-                if idx <= num_flame:  # Update the position of the moth with respect to its corresponding flame
-                    # Eq.(3.12)
-                    pos_new[j] = distance_to_flame * np.exp(b * t) * np.cos(t * 2 * np.pi) + pop_flames[idx][self.ID_POS][j]
-                else:  # Update the position of the moth with respect to one flame
-                    # Eq.(3.12).
-                    ## Here is a changed, I used the best position of flames not the position num_flame th (as original code)
-                    pos_new[j] = distance_to_flame * np.exp(b * t) * np.cos(t * 2 * np.pi) + pop_flames[num_flame][self.ID_POS][j]
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[idx][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-        self.pop = pop_new
+#!/usr/bin/env python
+# Created by "Thieu" at 11:59, 17/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class BaseMFO(Optimizer):
+    """
+    The developed version: Moth-Flame Optimization (MFO)
+
+    Notes
+    ~~~~~
+    + The flow of algorithm is changed
+    + The old solution is updated
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.MFO import BaseMFO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = BaseMFO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Mirjalili, S., 2015. Moth-flame optimization algorithm: A novel nature-inspired
+    heuristic paradigm. Knowledge-based systems, 89, pp.228-249.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # Number of flames Eq.(3.14) in the paper (linearly decreased)
+        num_flame = round(self.pop_size - (epoch + 1) * ((self.pop_size - 1) / self.epoch))
+
+        # a linearly decreases from -1 to -2 to calculate t in Eq. (3.12)
+        a = -1 + (epoch + 1) * ((-1) / self.epoch)
+
+        pop_flames, g_best = self.get_global_best_solution(self.pop)
+
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            #   D in Eq.(3.13)
+            distance_to_flame = np.abs(pop_flames[idx][self.ID_POS] - self.pop[idx][self.ID_POS])
+            t = (a - 1) * np.random.uniform(0, 1, self.problem.n_dims) + 1
+            b = 1
+
+            # Update the position of the moth with respect to its corresponding flame, Eq.(3.12).
+            temp_1 = distance_to_flame * np.exp(b * t) * np.cos(t * 2 * np.pi) + pop_flames[idx][self.ID_POS]
+
+            # Update the position of the moth with respect to one flame Eq.(3.12).
+            ## Here is a changed, I used the best position of flames not the position num_flame th (as original code)
+            temp_2 = distance_to_flame * np.exp(b * t) * np.cos(t * 2 * np.pi) + g_best[self.ID_POS]
+
+            list_idx = idx * np.ones(self.problem.n_dims)
+            pos_new = np.where(list_idx < num_flame, temp_1, temp_2)
+
+            ## This is the way I make this algorithm working. I tried to run matlab code with large dimension and it doesn't convergence.
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+
+class OriginalMFO(BaseMFO):
+    """
+    The original version of: Moth-flame Optimization (MFO)
+
+    Link:
+        1. https://www.mathworks.com/matlabcentral/fileexchange/52269-moth-flame-optimization-mfo-algorithm
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.MFO import OriginalMFO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalMFO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Mirjalili, S., 2015. Moth-flame optimization algorithm: A novel nature-inspired
+    heuristic paradigm. Knowledge-based systems, 89, pp.228-249.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(epoch, pop_size, **kwargs)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # Number of flames Eq.(3.14) in the paper (linearly decreased)
+        num_flame = round(self.pop_size - (epoch + 1) * ((self.pop_size - 1) / self.epoch))
+
+        # a linearly decreases from -1 to -2 to calculate t in Eq. (3.12)
+        a = -1 + (epoch + 1) * ((-1) / self.epoch)
+
+        pop_flames, g_best = self.get_global_best_solution(self.pop)
+
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            pos_new = deepcopy(self.pop[idx][self.ID_POS])
+            for j in range(self.problem.n_dims):
+                #   D in Eq.(3.13)
+                distance_to_flame = np.abs(pop_flames[idx][self.ID_POS][j] - self.pop[idx][self.ID_POS][j])
+                t = (a - 1) * np.random.uniform() + 1
+                b = 1
+                if idx <= num_flame:  # Update the position of the moth with respect to its corresponding flame
+                    # Eq.(3.12)
+                    pos_new[j] = distance_to_flame * np.exp(b * t) * np.cos(t * 2 * np.pi) + pop_flames[idx][self.ID_POS][j]
+                else:  # Update the position of the moth with respect to one flame
+                    # Eq.(3.12).
+                    ## Here is a changed, I used the best position of flames not the position num_flame th (as original code)
+                    pos_new[j] = distance_to_flame * np.exp(b * t) * np.cos(t * 2 * np.pi) + pop_flames[num_flame][self.ID_POS][j]
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[idx][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+        self.pop = pop_new
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/MGO.py` & `mealpy-2.5.3a1/mealpy/swarm_based/MGO.py`

 * *Ordering differences only*

 * *Files 9% similar despite different names*

```diff
@@ -1,103 +1,103 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 00:08, 27/10/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalMGO(Optimizer):
-    """
-    The original version of: Mountain Gazelle Optimizer (MGO)
-
-    Links:
-        1. https://www.sciencedirect.com/science/article/abs/pii/S0965997822001831
-        2. https://www.mathworks.com/matlabcentral/fileexchange/118680-mountain-gazelle-optimizer
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.MGO import OriginalMGO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalMGO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Abdollahzadeh, B., Gharehchopogh, F. S., Khodadadi, N., & Mirjalili, S. (2022). Mountain gazelle optimizer: a new
-    nature-inspired metaheuristic algorithm for global optimization problems. Advances in Engineering Software, 174, 103282.
-    """
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = True
-
-    def coefficient_vector__(self, n_dims, epoch, max_epoch):
-        a2 = -1 + epoch * ((-1) / max_epoch)
-        u = np.random.randn(n_dims)
-        v = np.random.randn(n_dims)
-        cofi = np.zeros((4, n_dims))
-        cofi[0, :] = np.random.rand(n_dims)
-        cofi[1, :] = (a2 + 1) + np.random.rand()
-        cofi[2, :] = a2 * np.random.randn(n_dims)
-        cofi[3, :] = u * np.power(v, 2) * np.cos((np.random.rand() * 2) * u)
-        return cofi
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            idxs_rand = np.random.permutation(self.pop_size)[:int(np.ceil(self.pop_size/3))]
-            pos_list = np.array([ self.pop[mm][self.ID_POS] for mm in idxs_rand ])
-            idx_rand = np.random.randint(int(np.ceil(self.pop_size / 3)), self.pop_size)
-            M = self.pop[idx_rand][self.ID_POS] * np.floor(np.random.normal()) + np.mean(pos_list, axis=0) * np.ceil(np.random.normal())
-
-            # Calculate the vector of coefficients
-            cofi = self.coefficient_vector__(self.problem.n_dims, epoch+1, self.epoch)
-            A = np.random.randn(self.problem.n_dims) * np.exp(2 - (epoch+1) * (2. / self.epoch))
-            D = (np.abs(self.pop[idx][self.ID_POS]) + np.abs(self.g_best[self.ID_POS]))*(2 * np.random.rand() - 1)
-
-            # Update the location
-            x2 = self.g_best[self.ID_POS] - np.abs((np.random.randint(1, 3)*M - np.random.randint(1, 3)*self.pop[idx][self.ID_POS]) * A) * cofi[np.random.randint(0, 4), :]
-            x3 = M + cofi[np.random.randint(0, 4), :] + (np.random.randint(1, 3)*self.g_best[self.ID_POS] - np.random.randint(1, 3)*self.pop[np.random.randint(self.pop_size)][self.ID_POS])*cofi[np.random.randint(0, 4), :]
-            x4 = self.pop[idx][self.ID_POS] - D + (np.random.randint(1, 3)*self.g_best[self.ID_POS] - np.random.randint(1, 3)*M) * cofi[np.random.randint(0, 4), :]
-
-            x1 = self.generate_position(self.problem.lb, self.problem.ub)
-            x2 = self.amend_position(x2, self.problem.lb, self.problem.ub)
-            x3 = self.amend_position(x3, self.problem.lb, self.problem.ub)
-            x4 = self.amend_position(x4, self.problem.lb, self.problem.ub)
-
-            pop_new += [[x1, None], [x2, None], [x3, None], [x4, None]]
-            if self.mode not in self.AVAILABLE_MODES:
-                for jdx in range(-4, 0):
-                    pop_new[jdx][self.ID_TAR] = self.get_target_wrapper(pop_new[jdx][self.ID_POS])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-        self.pop = self.get_sorted_strim_population(self.pop + pop_new, self.pop_size)
+#!/usr/bin/env python
+# Created by "Thieu" at 00:08, 27/10/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalMGO(Optimizer):
+    """
+    The original version of: Mountain Gazelle Optimizer (MGO)
+
+    Links:
+        1. https://www.sciencedirect.com/science/article/abs/pii/S0965997822001831
+        2. https://www.mathworks.com/matlabcentral/fileexchange/118680-mountain-gazelle-optimizer
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.MGO import OriginalMGO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalMGO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Abdollahzadeh, B., Gharehchopogh, F. S., Khodadadi, N., & Mirjalili, S. (2022). Mountain gazelle optimizer: a new
+    nature-inspired metaheuristic algorithm for global optimization problems. Advances in Engineering Software, 174, 103282.
+    """
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = True
+
+    def coefficient_vector__(self, n_dims, epoch, max_epoch):
+        a2 = -1 + epoch * ((-1) / max_epoch)
+        u = np.random.randn(n_dims)
+        v = np.random.randn(n_dims)
+        cofi = np.zeros((4, n_dims))
+        cofi[0, :] = np.random.rand(n_dims)
+        cofi[1, :] = (a2 + 1) + np.random.rand()
+        cofi[2, :] = a2 * np.random.randn(n_dims)
+        cofi[3, :] = u * np.power(v, 2) * np.cos((np.random.rand() * 2) * u)
+        return cofi
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            idxs_rand = np.random.permutation(self.pop_size)[:int(np.ceil(self.pop_size/3))]
+            pos_list = np.array([ self.pop[mm][self.ID_POS] for mm in idxs_rand ])
+            idx_rand = np.random.randint(int(np.ceil(self.pop_size / 3)), self.pop_size)
+            M = self.pop[idx_rand][self.ID_POS] * np.floor(np.random.normal()) + np.mean(pos_list, axis=0) * np.ceil(np.random.normal())
+
+            # Calculate the vector of coefficients
+            cofi = self.coefficient_vector__(self.problem.n_dims, epoch+1, self.epoch)
+            A = np.random.randn(self.problem.n_dims) * np.exp(2 - (epoch+1) * (2. / self.epoch))
+            D = (np.abs(self.pop[idx][self.ID_POS]) + np.abs(self.g_best[self.ID_POS]))*(2 * np.random.rand() - 1)
+
+            # Update the location
+            x2 = self.g_best[self.ID_POS] - np.abs((np.random.randint(1, 3)*M - np.random.randint(1, 3)*self.pop[idx][self.ID_POS]) * A) * cofi[np.random.randint(0, 4), :]
+            x3 = M + cofi[np.random.randint(0, 4), :] + (np.random.randint(1, 3)*self.g_best[self.ID_POS] - np.random.randint(1, 3)*self.pop[np.random.randint(self.pop_size)][self.ID_POS])*cofi[np.random.randint(0, 4), :]
+            x4 = self.pop[idx][self.ID_POS] - D + (np.random.randint(1, 3)*self.g_best[self.ID_POS] - np.random.randint(1, 3)*M) * cofi[np.random.randint(0, 4), :]
+
+            x1 = self.generate_position(self.problem.lb, self.problem.ub)
+            x2 = self.amend_position(x2, self.problem.lb, self.problem.ub)
+            x3 = self.amend_position(x3, self.problem.lb, self.problem.ub)
+            x4 = self.amend_position(x4, self.problem.lb, self.problem.ub)
+
+            pop_new += [[x1, None], [x2, None], [x3, None], [x4, None]]
+            if self.mode not in self.AVAILABLE_MODES:
+                for jdx in range(-4, 0):
+                    pop_new[jdx][self.ID_TAR] = self.get_target_wrapper(pop_new[jdx][self.ID_POS])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+        self.pop = self.get_sorted_strim_population(self.pop + pop_new, self.pop_size)
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/MPA.py` & `mealpy-2.5.3a1/mealpy/swarm_based/MPA.py`

 * *Ordering differences only*

 * *Files 8% similar despite different names*

```diff
@@ -1,121 +1,121 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 17:28, 21/05/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalMPA(Optimizer):
-    """
-    The developed version: Marine Predators Algorithm (MPA)
-
-    Links:
-        1. https://www.sciencedirect.com/science/article/abs/pii/S0957417420302025
-        2. https://www.mathworks.com/matlabcentral/fileexchange/74578-marine-predators-algorithm-mpa
-
-    Notes
-    ~~~~~
-        1. To use the original paper, set the training mode = "swarm"
-        2. They update the whole population at the same time before update the fitness
-        3. Two variables that they consider it as constants which are FADS = 0.2 and P = 0.5
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.MPA import OriginalMPA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalMPA(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Faramarzi, A., Heidarinejad, M., Mirjalili, S., & Gandomi, A. H. (2020).
-    Marine Predators Algorithm: A nature-inspired metaheuristic. Expert systems with applications, 152, 113377.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def initialize_variables(self):
-        self.FADS = 0.2
-        self.P = 0.5
-
-    def levy_step(self, beta, size=None):
-        num = np.random.gamma(1 + beta) * np.sin(np.pi * beta /2)
-        den = np.random.gamma((1+beta)/2) * beta * 2**((beta-1)/2)
-        sigma_u = (num/den) ** (1 / beta)
-        u = np.random.normal(0, sigma_u, size)
-        v = np.random.normal(0, 1, size)
-        return u / np.abs(v)**(1/beta)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        CF = (1 - (epoch+1)/self.epoch)**(2 * (epoch+1)/self.epoch)
-        # RL = self.get_levy_flight_step(beta=1.5, multiplier=0.05, size=(self.pop_size, self.problem.n_dims), case=-1)
-        RL = 0.05 * self.levy_step(1.5, (self.pop_size, self.problem.n_dims))
-        RB = np.random.randn(self.pop_size, self.problem.n_dims)
-        per1 = np.random.permutation(self.pop_size)
-        per2 = np.random.permutation(self.pop_size)
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            R = np.random.rand(self.problem.n_dims)
-            t = self.epoch + 1
-            if t < self.epoch / 3:     # Phase 1 (Eq.12)
-                step_size = RB[idx] * (self.g_best[self.ID_POS] - RB[idx] * self.pop[idx][self.ID_POS])
-                pos_new = self.pop[idx][self.ID_POS] + self.P * R * step_size
-            elif self.epoch / 3 < t < 2*self.epoch / 3:     # Phase 2 (Eqs. 13 & 14)
-                if idx > self.pop_size / 2:
-                    step_size = RB[idx] * (RB[idx] * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-                    pos_new = self.g_best[self.ID_POS] + self.P * CF * step_size
-                else:
-                    step_size = RL[idx] * (self.g_best[self.ID_POS] - RL[idx] * self.pop[idx][self.ID_POS])
-                    pos_new = self.pop[idx][self.ID_POS] + self.P * R * step_size
-            else:       # Phase 3 (Eq. 15)
-                step_size = RL[idx] * (RL[idx] * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-                pos_new = self.g_best[self.ID_POS] + self.P * CF * step_size
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            if np.random.rand() < self.FADS:
-                u = np.where(np.random.rand(self.problem.n_dims) < self.FADS, 1, 0)
-                pos_new = pos_new + CF * (self.problem.lb + np.random.rand(self.problem.n_dims) * (self.problem.ub - self.problem.lb)) * u
-            else:
-                r = np.random.rand()
-                step_size = (self.FADS * (1 - r) + r) * (self.pop[per1[idx]][self.ID_POS] - self.pop[per2[idx]][self.ID_POS])
-                pos_new = pos_new + step_size
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 17:28, 21/05/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalMPA(Optimizer):
+    """
+    The developed version: Marine Predators Algorithm (MPA)
+
+    Links:
+        1. https://www.sciencedirect.com/science/article/abs/pii/S0957417420302025
+        2. https://www.mathworks.com/matlabcentral/fileexchange/74578-marine-predators-algorithm-mpa
+
+    Notes
+    ~~~~~
+        1. To use the original paper, set the training mode = "swarm"
+        2. They update the whole population at the same time before update the fitness
+        3. Two variables that they consider it as constants which are FADS = 0.2 and P = 0.5
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.MPA import OriginalMPA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalMPA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Faramarzi, A., Heidarinejad, M., Mirjalili, S., & Gandomi, A. H. (2020).
+    Marine Predators Algorithm: A nature-inspired metaheuristic. Expert systems with applications, 152, 113377.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def initialize_variables(self):
+        self.FADS = 0.2
+        self.P = 0.5
+
+    def levy_step(self, beta, size=None):
+        num = np.random.gamma(1 + beta) * np.sin(np.pi * beta /2)
+        den = np.random.gamma((1+beta)/2) * beta * 2**((beta-1)/2)
+        sigma_u = (num/den) ** (1 / beta)
+        u = np.random.normal(0, sigma_u, size)
+        v = np.random.normal(0, 1, size)
+        return u / np.abs(v)**(1/beta)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        CF = (1 - (epoch+1)/self.epoch)**(2 * (epoch+1)/self.epoch)
+        # RL = self.get_levy_flight_step(beta=1.5, multiplier=0.05, size=(self.pop_size, self.problem.n_dims), case=-1)
+        RL = 0.05 * self.levy_step(1.5, (self.pop_size, self.problem.n_dims))
+        RB = np.random.randn(self.pop_size, self.problem.n_dims)
+        per1 = np.random.permutation(self.pop_size)
+        per2 = np.random.permutation(self.pop_size)
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            R = np.random.rand(self.problem.n_dims)
+            t = self.epoch + 1
+            if t < self.epoch / 3:     # Phase 1 (Eq.12)
+                step_size = RB[idx] * (self.g_best[self.ID_POS] - RB[idx] * self.pop[idx][self.ID_POS])
+                pos_new = self.pop[idx][self.ID_POS] + self.P * R * step_size
+            elif self.epoch / 3 < t < 2*self.epoch / 3:     # Phase 2 (Eqs. 13 & 14)
+                if idx > self.pop_size / 2:
+                    step_size = RB[idx] * (RB[idx] * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+                    pos_new = self.g_best[self.ID_POS] + self.P * CF * step_size
+                else:
+                    step_size = RL[idx] * (self.g_best[self.ID_POS] - RL[idx] * self.pop[idx][self.ID_POS])
+                    pos_new = self.pop[idx][self.ID_POS] + self.P * R * step_size
+            else:       # Phase 3 (Eq. 15)
+                step_size = RL[idx] * (RL[idx] * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+                pos_new = self.g_best[self.ID_POS] + self.P * CF * step_size
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            if np.random.rand() < self.FADS:
+                u = np.where(np.random.rand(self.problem.n_dims) < self.FADS, 1, 0)
+                pos_new = pos_new + CF * (self.problem.lb + np.random.rand(self.problem.n_dims) * (self.problem.ub - self.problem.lb)) * u
+            else:
+                r = np.random.rand()
+                step_size = (self.FADS * (1 - r) + r) * (self.pop[per1[idx]][self.ID_POS] - self.pop[per2[idx]][self.ID_POS])
+                pos_new = pos_new + step_size
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/MRFO.py` & `mealpy-2.5.3a1/mealpy/swarm_based/MRFO.py`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,283 +1,283 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 14:52, 17/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalMRFO(Optimizer):
-    """
-    The original version of: Manta Ray Foraging Optimization (MRFO)
-
-    Links:
-        1. https://doi.org/10.1016/j.engappai.2019.103300
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + somersault_range (float): [1.5, 3], somersault factor that decides the somersault range of manta rays, default=2
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.MRFO import OriginalMRFO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> somersault_range = 2.0
-    >>> model = OriginalMRFO(epoch, pop_size, somersault_range)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Zhao, W., Zhang, Z. and Wang, L., 2020. Manta ray foraging optimization: An effective bio-inspired
-    optimizer for engineering applications. Engineering Applications of Artificial Intelligence, 87, p.103300.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, somersault_range=2.0, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            somersault_range (float): somersault factor that decides the somersault range of manta rays, default=2
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.somersault_range = self.validator.check_float("somersault_range", somersault_range, [1.0, 5.0])
-        self.set_parameters(["epoch", "pop_size", "somersault_range"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            # Cyclone foraging (Eq. 5, 6, 7)
-            if np.random.rand() < 0.5:
-                r1 = np.random.uniform()
-                beta = 2 * np.exp(r1 * (self.epoch - epoch) / self.epoch) * np.sin(2 * np.pi * r1)
-
-                if (epoch + 1) / self.epoch < np.random.rand():
-                    x_rand = np.random.uniform(self.problem.lb, self.problem.ub)
-                    if idx == 0:
-                        x_t1 = x_rand + np.random.uniform() * (x_rand - self.pop[idx][self.ID_POS]) + \
-                               beta * (x_rand - self.pop[idx][self.ID_POS])
-                    else:
-                        x_t1 = x_rand + np.random.uniform() * (self.pop[idx - 1][self.ID_POS] - self.pop[idx][self.ID_POS]) + \
-                               beta * (x_rand - self.pop[idx][self.ID_POS])
-                else:
-                    if idx == 0:
-                        x_t1 = self.g_best[self.ID_POS] + np.random.uniform() * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) + \
-                               beta * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-                    else:
-                        x_t1 = self.g_best[self.ID_POS] + np.random.uniform() * (self.pop[idx - 1][self.ID_POS] - self.pop[idx][self.ID_POS]) + \
-                               beta * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-            # Chain foraging (Eq. 1,2)
-            else:
-                r = np.random.uniform()
-                alpha = 2 * r * np.sqrt(np.abs(np.log(r)))
-                if idx == 0:
-                    x_t1 = self.pop[idx][self.ID_POS] + r * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) + \
-                           alpha * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-                else:
-                    x_t1 = self.pop[idx][self.ID_POS] + r * (self.pop[idx - 1][self.ID_POS] - self.pop[idx][self.ID_POS]) + \
-                           alpha * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-            pos_new = self.amend_position(x_t1, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-        _, g_best = self.update_global_best_solution(self.pop, save=False)
-        pop_child = []
-        for idx in range(0, self.pop_size):
-            # Somersault foraging   (Eq. 8)
-            x_t1 = self.pop[idx][self.ID_POS] + self.somersault_range * \
-                   (np.random.uniform() * g_best[self.ID_POS] - np.random.uniform() * self.pop[idx][self.ID_POS])
-            pos_new = self.amend_position(x_t1, self.problem.lb, self.problem.ub)
-            pop_child.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_child = self.update_target_wrapper_population(pop_child)
-            self.pop = self.greedy_selection_population(self.pop, pop_child)
-
-
-class WMQIMRFO(Optimizer):
-    """
-    The original version of: Wavelet Mutation and Quadratic Interpolation MRFO
-
-    Links:
-        1. https://doi.org/10.1016/j.knosys.2021.108071
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + somersault_range (float): [1.5, 3], somersault factor that decides the somersault range of manta rays, default=2
-        + pm (float): (0.0, 1.0), probability mutation, default = 0.5
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.MRFO import WMQIMRFO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> somersault_range = 2.0
-    >>> model = OriginalMRFO(epoch, pop_size, somersault_range)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] G. Hu, M. Li, X. Wang et al., An enhanced manta ray foraging optimization algorithm for shape optimization of
-    complex CCG-Ball curves, Knowledge-Based Systems (2022), doi: https://doi.org/10.1016/j.knosys.2021.108071.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, somersault_range=2.0, pm=0.5, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            somersault_range (float): somersault factor that decides the somersault range of manta rays, default=2
-            pm (float): probability mutation, default = 0.5
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.somersault_range = self.validator.check_float("somersault_range", somersault_range, [1.0, 5.0])
-        self.pm = self.validator.check_float("pm", pm, (0.0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "somersault_range", "pm"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            x_t = self.pop[idx][self.ID_POS]
-            x_t1 = self.pop[idx-1][self.ID_POS]
-
-            ## Morlet wavelet mutation strategy
-            ## Goal is to jump out of local optimum --> Performed in exploration stage
-            s_constant = 2.0
-            a = s_constant * (1.0 / s_constant) ** (1.0 - (epoch + 1) / self.epoch)
-            theta = np.random.uniform(-2.5 * a, 2.5 * a)
-            x = theta / a
-            w = np.exp(-x ** 2 / 2) * np.cos(5 * x)
-            xichma = 1.0 / np.sqrt(a) * w
-
-            if np.random.rand() < 0.5:  # Control parameter adjustment
-                coef = np.log(1 + (np.e - 1) * (epoch + 1) / self.epoch)  # Eq. 3.11
-
-                r1 = np.random.uniform()
-                beta = 2 * np.exp(r1 * (self.epoch - epoch) / self.epoch) * np.sin(2 * np.pi * r1)
-
-                if coef < np.random.rand():     # Cyclone foraging
-                    x_rand = self.generate_position(self.problem.lb, self.problem.ub)
-
-                    if np.random.rand() < self.pm:      # Morlet wavelet mutation
-                        if idx == 0:
-                            pos_new = x_rand + np.random.rand() * (x_rand - x_t) + beta * (x_rand - x_t)
-                        else:
-                            pos_new = x_rand + np.random.rand() * (x_t1 - x_t) + beta * (x_rand - x_t)
-                    else:
-                        conditions = np.random.uniform(0, 1, self.problem.n_dims) > 0.5
-                        if idx == 0:
-                            t1 = x_rand + np.random.rand(self.problem.n_dims) * (x_rand - x_t) + beta * (x_rand - x_t) + xichma * (self.problem.ub - x_t)
-                            t2 = x_rand + np.random.rand(self.problem.n_dims) * (x_rand - x_t) + beta * (x_rand - x_t) + xichma * (x_t - self.problem.lb)
-                        else:
-                            t1 = x_rand + np.random.rand(self.problem.n_dims) * (x_t1 - x_t) + beta * (x_rand - x_t) + xichma * (self.problem.ub - x_t)
-                            t2 = x_rand + np.random.rand(self.problem.n_dims) * (x_t1 - x_t) + beta * (x_rand - x_t) + xichma * (x_t - self.problem.lb)
-                        pos_new = np.where(conditions, t1, t2)
-                else:
-                    if idx == 0:
-                        pos_new = self.g_best[self.ID_POS] + np.random.rand() * (self.g_best[self.ID_POS] - x_t) + beta * (self.g_best[self.ID_POS] - x_t)
-                    else:
-                        pos_new = self.g_best[self.ID_POS] + np.random.rand() * (x_t1 - x_t) + beta * (self.g_best[self.ID_POS] - x_t)
-            else:   # Chain foraging (Eq. 1,2)
-                r = np.random.rand()
-                alpha = 2 * r * np.sqrt(np.abs(np.log(r)))
-                if idx == 0:
-                    pos_new = x_t + r * (self.g_best[self.ID_POS] - x_t) + alpha * (self.g_best[self.ID_POS] - x_t)
-                else:
-                    pos_new = x_t + r * (x_t1 - x_t) + alpha * (self.g_best[self.ID_POS] - x_t)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-        _, g_best = self.update_global_best_solution(self.pop, save=False)
-
-        # Somersault foraging   (Eq. 8)
-        pop_child = []
-        for idx in range(0, self.pop_size):
-            pos_new = self.pop[idx][self.ID_POS] + self.somersault_range * \
-                   (np.random.rand() * g_best[self.ID_POS] - np.random.rand() * self.pop[idx][self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_child.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_child = self.update_target_wrapper_population(pop_child)
-            self.pop = self.greedy_selection_population(self.pop, pop_child)
-        self.pop, g_best = self.update_global_best_solution(self.pop, save=False)
-
-        # Quadratic Interpolation
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            idx2, idx3 = idx + 1, idx + 2
-            if idx == self.pop_size-2:
-                idx2, idx3 = idx + 1, 0
-            if idx == self.pop_size-1:
-                idx2, idx3 = 0, 1
-            f1, f2, f3 = self.pop[idx][self.ID_TAR][self.ID_FIT], self.pop[idx2][self.ID_TAR][self.ID_FIT], self.pop[idx3][self.ID_TAR][self.ID_FIT]
-            x1, x2, x3 = self.pop[idx][self.ID_POS], self.pop[idx2][self.ID_POS], self.pop[idx3][self.ID_POS]
-            a = f1 / ((x1 - x2) * (x1 - x3)) + f2 / ((x2 - x1) * (x2 - x3)) + f3 / ((x3 - x1) * (x3 - x2))
-            gx = ((x3 ** 2 - x2 ** 2) * f1 + (x1 ** 2 - x3 ** 2) * f2 + (x2 ** 2 - x1 ** 2) * f3) / (2 * ((x3 - x2) * f1 + (x1 - x3) * f2 + (x2 - x1) * f3))
-            pos_new = np.where(a > 0, gx, x1)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-        _, g_best = self.update_global_best_solution(self.pop)
+#!/usr/bin/env python
+# Created by "Thieu" at 14:52, 17/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalMRFO(Optimizer):
+    """
+    The original version of: Manta Ray Foraging Optimization (MRFO)
+
+    Links:
+        1. https://doi.org/10.1016/j.engappai.2019.103300
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + somersault_range (float): [1.5, 3], somersault factor that decides the somersault range of manta rays, default=2
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.MRFO import OriginalMRFO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> somersault_range = 2.0
+    >>> model = OriginalMRFO(epoch, pop_size, somersault_range)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Zhao, W., Zhang, Z. and Wang, L., 2020. Manta ray foraging optimization: An effective bio-inspired
+    optimizer for engineering applications. Engineering Applications of Artificial Intelligence, 87, p.103300.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, somersault_range=2.0, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            somersault_range (float): somersault factor that decides the somersault range of manta rays, default=2
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.somersault_range = self.validator.check_float("somersault_range", somersault_range, [1.0, 5.0])
+        self.set_parameters(["epoch", "pop_size", "somersault_range"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            # Cyclone foraging (Eq. 5, 6, 7)
+            if np.random.rand() < 0.5:
+                r1 = np.random.uniform()
+                beta = 2 * np.exp(r1 * (self.epoch - epoch) / self.epoch) * np.sin(2 * np.pi * r1)
+
+                if (epoch + 1) / self.epoch < np.random.rand():
+                    x_rand = np.random.uniform(self.problem.lb, self.problem.ub)
+                    if idx == 0:
+                        x_t1 = x_rand + np.random.uniform() * (x_rand - self.pop[idx][self.ID_POS]) + \
+                               beta * (x_rand - self.pop[idx][self.ID_POS])
+                    else:
+                        x_t1 = x_rand + np.random.uniform() * (self.pop[idx - 1][self.ID_POS] - self.pop[idx][self.ID_POS]) + \
+                               beta * (x_rand - self.pop[idx][self.ID_POS])
+                else:
+                    if idx == 0:
+                        x_t1 = self.g_best[self.ID_POS] + np.random.uniform() * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) + \
+                               beta * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+                    else:
+                        x_t1 = self.g_best[self.ID_POS] + np.random.uniform() * (self.pop[idx - 1][self.ID_POS] - self.pop[idx][self.ID_POS]) + \
+                               beta * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+            # Chain foraging (Eq. 1,2)
+            else:
+                r = np.random.uniform()
+                alpha = 2 * r * np.sqrt(np.abs(np.log(r)))
+                if idx == 0:
+                    x_t1 = self.pop[idx][self.ID_POS] + r * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) + \
+                           alpha * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+                else:
+                    x_t1 = self.pop[idx][self.ID_POS] + r * (self.pop[idx - 1][self.ID_POS] - self.pop[idx][self.ID_POS]) + \
+                           alpha * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+            pos_new = self.amend_position(x_t1, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+        _, g_best = self.update_global_best_solution(self.pop, save=False)
+        pop_child = []
+        for idx in range(0, self.pop_size):
+            # Somersault foraging   (Eq. 8)
+            x_t1 = self.pop[idx][self.ID_POS] + self.somersault_range * \
+                   (np.random.uniform() * g_best[self.ID_POS] - np.random.uniform() * self.pop[idx][self.ID_POS])
+            pos_new = self.amend_position(x_t1, self.problem.lb, self.problem.ub)
+            pop_child.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_child = self.update_target_wrapper_population(pop_child)
+            self.pop = self.greedy_selection_population(self.pop, pop_child)
+
+
+class WMQIMRFO(Optimizer):
+    """
+    The original version of: Wavelet Mutation and Quadratic Interpolation MRFO
+
+    Links:
+        1. https://doi.org/10.1016/j.knosys.2021.108071
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + somersault_range (float): [1.5, 3], somersault factor that decides the somersault range of manta rays, default=2
+        + pm (float): (0.0, 1.0), probability mutation, default = 0.5
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.MRFO import WMQIMRFO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> somersault_range = 2.0
+    >>> model = OriginalMRFO(epoch, pop_size, somersault_range)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] G. Hu, M. Li, X. Wang et al., An enhanced manta ray foraging optimization algorithm for shape optimization of
+    complex CCG-Ball curves, Knowledge-Based Systems (2022), doi: https://doi.org/10.1016/j.knosys.2021.108071.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, somersault_range=2.0, pm=0.5, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            somersault_range (float): somersault factor that decides the somersault range of manta rays, default=2
+            pm (float): probability mutation, default = 0.5
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.somersault_range = self.validator.check_float("somersault_range", somersault_range, [1.0, 5.0])
+        self.pm = self.validator.check_float("pm", pm, (0.0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "somersault_range", "pm"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            x_t = self.pop[idx][self.ID_POS]
+            x_t1 = self.pop[idx-1][self.ID_POS]
+
+            ## Morlet wavelet mutation strategy
+            ## Goal is to jump out of local optimum --> Performed in exploration stage
+            s_constant = 2.0
+            a = s_constant * (1.0 / s_constant) ** (1.0 - (epoch + 1) / self.epoch)
+            theta = np.random.uniform(-2.5 * a, 2.5 * a)
+            x = theta / a
+            w = np.exp(-x ** 2 / 2) * np.cos(5 * x)
+            xichma = 1.0 / np.sqrt(a) * w
+
+            if np.random.rand() < 0.5:  # Control parameter adjustment
+                coef = np.log(1 + (np.e - 1) * (epoch + 1) / self.epoch)  # Eq. 3.11
+
+                r1 = np.random.uniform()
+                beta = 2 * np.exp(r1 * (self.epoch - epoch) / self.epoch) * np.sin(2 * np.pi * r1)
+
+                if coef < np.random.rand():     # Cyclone foraging
+                    x_rand = self.generate_position(self.problem.lb, self.problem.ub)
+
+                    if np.random.rand() < self.pm:      # Morlet wavelet mutation
+                        if idx == 0:
+                            pos_new = x_rand + np.random.rand() * (x_rand - x_t) + beta * (x_rand - x_t)
+                        else:
+                            pos_new = x_rand + np.random.rand() * (x_t1 - x_t) + beta * (x_rand - x_t)
+                    else:
+                        conditions = np.random.uniform(0, 1, self.problem.n_dims) > 0.5
+                        if idx == 0:
+                            t1 = x_rand + np.random.rand(self.problem.n_dims) * (x_rand - x_t) + beta * (x_rand - x_t) + xichma * (self.problem.ub - x_t)
+                            t2 = x_rand + np.random.rand(self.problem.n_dims) * (x_rand - x_t) + beta * (x_rand - x_t) + xichma * (x_t - self.problem.lb)
+                        else:
+                            t1 = x_rand + np.random.rand(self.problem.n_dims) * (x_t1 - x_t) + beta * (x_rand - x_t) + xichma * (self.problem.ub - x_t)
+                            t2 = x_rand + np.random.rand(self.problem.n_dims) * (x_t1 - x_t) + beta * (x_rand - x_t) + xichma * (x_t - self.problem.lb)
+                        pos_new = np.where(conditions, t1, t2)
+                else:
+                    if idx == 0:
+                        pos_new = self.g_best[self.ID_POS] + np.random.rand() * (self.g_best[self.ID_POS] - x_t) + beta * (self.g_best[self.ID_POS] - x_t)
+                    else:
+                        pos_new = self.g_best[self.ID_POS] + np.random.rand() * (x_t1 - x_t) + beta * (self.g_best[self.ID_POS] - x_t)
+            else:   # Chain foraging (Eq. 1,2)
+                r = np.random.rand()
+                alpha = 2 * r * np.sqrt(np.abs(np.log(r)))
+                if idx == 0:
+                    pos_new = x_t + r * (self.g_best[self.ID_POS] - x_t) + alpha * (self.g_best[self.ID_POS] - x_t)
+                else:
+                    pos_new = x_t + r * (x_t1 - x_t) + alpha * (self.g_best[self.ID_POS] - x_t)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+        _, g_best = self.update_global_best_solution(self.pop, save=False)
+
+        # Somersault foraging   (Eq. 8)
+        pop_child = []
+        for idx in range(0, self.pop_size):
+            pos_new = self.pop[idx][self.ID_POS] + self.somersault_range * \
+                   (np.random.rand() * g_best[self.ID_POS] - np.random.rand() * self.pop[idx][self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_child.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_child = self.update_target_wrapper_population(pop_child)
+            self.pop = self.greedy_selection_population(self.pop, pop_child)
+        self.pop, g_best = self.update_global_best_solution(self.pop, save=False)
+
+        # Quadratic Interpolation
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            idx2, idx3 = idx + 1, idx + 2
+            if idx == self.pop_size-2:
+                idx2, idx3 = idx + 1, 0
+            if idx == self.pop_size-1:
+                idx2, idx3 = 0, 1
+            f1, f2, f3 = self.pop[idx][self.ID_TAR][self.ID_FIT], self.pop[idx2][self.ID_TAR][self.ID_FIT], self.pop[idx3][self.ID_TAR][self.ID_FIT]
+            x1, x2, x3 = self.pop[idx][self.ID_POS], self.pop[idx2][self.ID_POS], self.pop[idx3][self.ID_POS]
+            a = f1 / ((x1 - x2) * (x1 - x3)) + f2 / ((x2 - x1) * (x2 - x3)) + f3 / ((x3 - x1) * (x3 - x2))
+            gx = ((x3 ** 2 - x2 ** 2) * f1 + (x1 ** 2 - x3 ** 2) * f2 + (x2 ** 2 - x1 ** 2) * f3) / (2 * ((x3 - x2) * f1 + (x1 - x3) * f2 + (x2 - x1) * f3))
+            pos_new = np.where(a > 0, gx, x1)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+        _, g_best = self.update_global_best_solution(self.pop)
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/NGO.py` & `mealpy-2.5.3a1/mealpy/swarm_based/NGO.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,91 +1,95 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 18:29, 11/03/2023 ----------%
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalNGO(Optimizer):
-    """
-    The original version of: Northern Goshawk Optimization (NGO)
-
-    Links:
-        1. https://ieeexplore.ieee.org/abstract/document/9638618
-        2. https://www.mathworks.com/matlabcentral/fileexchange/106665-northern-goshawk-optimization-a-new-swarm-based-algorithm
-
-    Notes:
-        1. This is somewhat concerning, as there appears to be a high degree of similarity between the source code for this algorithm and the Pelican Optimization Algorithm (POA).
-        2. Algorithm design is similar similar to Zebra Optimization Algorithm (ZOA), Osprey Optimization Algorithm (OOA), Coati Optimization Algorithm (CoatiOA), Siberian Tiger Optimization (STO), Language Education Optimization (LEO), Serval Optimization Algorithm (SOA), Walrus Optimization Algorithm (WOA), Fennec Fox Optimization (FFO), Three-periods optimization algorithm (TPOA), Teamwork optimization algorithm (TOA), Pelican Optimization Algorithm (POA), Tasmanian devil optimization (TDO), Archery algorithm (AA), Cat and mouse based optimizer (CMBO)
-        3. It may be useful to compare the Matlab code of this algorithm with those of the similar algorithms to ensure its accuracy and completeness.
-        4. The article may share some similarities with previous work by the same authors, further investigation may be warranted to verify the benchmark results reported in the papers and ensure their reliability and accuracy.
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.NGO import OriginalNGO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalNGO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Dehghani, M., HubÃ¡lovskÃ½, Å ., & TrojovskÃ½, P. (2021). Northern goshawk optimization: a new swarm-based
-    algorithm for solving optimization problems. IEEE Access, 9, 162059-162080.
-    """
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.support_parallel_modes = False
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        ## UPDATE Northern goshawks based on PHASE1 and PHASE2
-
-        for idx in range(0, self.pop_size):
-            # Phase 1: Exploration
-            kk = np.random.permutation(self.pop_size)[0]
-            if self.compare_agent(self.pop[kk], self.pop[idx]):     # Eq. 4
-                pos_new = self.pop[idx][self.ID_POS] + np.random.rand(self.problem.n_dims) * (self.pop[kk][self.ID_POS] - np.random.randint(1, 3) * self.pop[idx][self.ID_POS])
-            else:
-                pos_new = self.pop[idx][self.ID_POS] + np.random.rand(self.problem.n_dims) * (self.pop[idx][self.ID_POS] - self.pop[kk][self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            tar_new = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
-                self.pop[idx] = [pos_new, tar_new]
-
-            # PHASE 2 Exploitation
-            R = 0.02 * (1 - (epoch+1) / self.epoch)         # Eq. 6
-            pos_new = self.pop[idx][self.ID_POS] + (-R + 2 * R * np.random.rand(self.problem.n_dims)) * self.pop[idx][self.ID_POS]      # Eq. 7
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            tar_new = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
-                self.pop[idx] = [pos_new, tar_new]
+#!/usr/bin/env python
+# Created by "Thieu" at 18:29, 11/03/2023 ----------%
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalNGO(Optimizer):
+    """
+    The original version of: Northern Goshawk Optimization (NGO)
+
+    Links:
+        1. https://ieeexplore.ieee.org/abstract/document/9638618
+        2. https://www.mathworks.com/matlabcentral/fileexchange/106665-northern-goshawk-optimization-a-new-swarm-based-algorithm
+
+    Notes (Plagiarism):
+        0. This is really disgusting, because the source code for this algorithm is exactly the same as the source code for Pelican Optimization Algorithm (POA).
+        1. Algorithm design is very similar to Zebra Optimization Algorithm (ZOA), Osprey Optimization Algorithm (OOA), Coati Optimization Algorithm (CoatiOA),
+        Siberian Tiger Optimization (STO), Language Education Optimization (LEO), Serval Optimization Algorithm (SOA), Walrus Optimization Algorithm (WOA),
+        Fennec Fox Optimization (FFO), Three-periods optimization algorithm (TPOA), Teamwork optimization algorithm (TOA), Pelican Optimization Algorithm (POA),
+        Tasmanian devil optimization (TDO), Archery algorithm (AA), Cat and mouse based optimizer (CMBO)
+        2. Check the matlab code of all above algorithms
+        2. Same authors, self-plagiarized article with kinda same algorithm with different meta-metaphors
+        4. Check the results of benchmark functions in the papers, they are mostly make up results
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.NGO import OriginalNGO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalNGO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Dehghani, M., HubÃ¡lovskÃ½, Å ., & TrojovskÃ½, P. (2021). Northern goshawk optimization: a new swarm-based
+    algorithm for solving optimization problems. IEEE Access, 9, 162059-162080.
+    """
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.support_parallel_modes = False
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        ## UPDATE Northern goshawks based on PHASE1 and PHASE2
+
+        for idx in range(0, self.pop_size):
+            # Phase 1: Exploration
+            kk = np.random.permutation(self.pop_size)[0]
+            if self.compare_agent(self.pop[kk], self.pop[idx]):     # Eq. 4
+                pos_new = self.pop[idx][self.ID_POS] + np.random.rand(self.problem.n_dims) * (self.pop[kk][self.ID_POS] - np.random.randint(1, 3) * self.pop[idx][self.ID_POS])
+            else:
+                pos_new = self.pop[idx][self.ID_POS] + np.random.rand(self.problem.n_dims) * (self.pop[idx][self.ID_POS] - self.pop[kk][self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            tar_new = self.get_target_wrapper(pos_new)
+            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
+                self.pop[idx] = [pos_new, tar_new]
+
+            # PHASE 2 Exploitation
+            R = 0.02 * (1 - (epoch+1) / self.epoch)         # Eq. 6
+            pos_new = self.pop[idx][self.ID_POS] + (-R + 2 * R * np.random.rand(self.problem.n_dims)) * self.pop[idx][self.ID_POS]      # Eq. 7
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            tar_new = self.get_target_wrapper(pos_new)
+            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
+                self.pop[idx] = [pos_new, tar_new]
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/NMRA.py` & `mealpy-2.5.3a1/mealpy/swarm_based/FOA.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,200 +1,237 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 14:52, 17/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalNMRA(Optimizer):
-    """
-    The original version of: Naked Mole-Rat Algorithm (NMRA)
-
-    Links:
-        1. https://www.doi.org10.1007/s00521-019-04464-7
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + pb (float): [0.5, 0.95], probability of breeding, default = 0.75
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.NMRA import OriginalNMRA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> pb = 0.75
-    >>> model = OriginalNMRA(epoch, pop_size, pb)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Salgotra, R. and Singh, U., 2019. The naked mole-rat algorithm.
-    Neural Computing and Applications, 31(12), pp.8837-8857.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, pb=0.75, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            pb (float): probability of breeding, default = 0.75
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.pb = self.validator.check_float("pb", pb, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "pb"])
-        self.sort_flag = True
-        self.size_b = int(self.pop_size / 5)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            pos_new = deepcopy(self.pop[idx][self.ID_POS])
-            if idx < self.size_b:  # breeding operators
-                if np.random.uniform() < self.pb:
-                    alpha = np.random.uniform()
-                    pos_new = (1 - alpha) * self.pop[idx][self.ID_POS] + alpha * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-            else:  # working operators
-                t1, t2 = np.random.choice(range(self.size_b, self.pop_size), 2, replace=False)
-                pos_new = self.pop[idx][self.ID_POS] + np.random.uniform() * (self.pop[t1][self.ID_POS] - self.pop[t2][self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-
-class ImprovedNMRA(Optimizer):
-    """
-    The original version of: Improved Naked Mole-Rat Algorithm (I-NMRA)
-
-    Notes:
-    + Use mutation probability idea
-    + Use crossover operator
-    + Use Levy-flight technique
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + pb (float): [0.5, 0.95], probability of breeding, default = 0.75
-        + pm (float): [0.01, 0.1], probability of mutation, default = 0.01
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.NMRA import ImprovedNMRA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> pb = 0.75
-    >>> pm = 0.01
-    >>> model = ImprovedNMRA(epoch, pop_size, pb, pm)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Salgotra, R. and Singh, U., 2019. The naked mole-rat algorithm.
-    Neural Computing and Applications, 31(12), pp.8837-8857.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, pb=0.75, pm=0.01, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            pb (float): breeding probability, default = 0.75
-            pm (float): probability of mutation, default = 0.01
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.pb = self.validator.check_float("pb", pb, (0, 1.0))
-        self.pm = self.validator.check_float("pm", pm, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "pb", "pm"])
-        self.sort_flag = True
-        self.size_b = int(self.pop_size / 5)
-
-    def crossover_random__(self, pop, g_best):
-        start_point = np.random.randint(0, self.problem.n_dims / 2)
-        id1 = start_point
-        id2 = int(start_point + self.problem.n_dims / 3)
-        id3 = int(self.problem.n_dims)
-
-        partner = pop[np.random.randint(0, self.pop_size)][self.ID_POS]
-        new_temp = deepcopy(g_best[self.ID_POS])
-        new_temp[0:id1] = g_best[self.ID_POS][0:id1]
-        new_temp[id1:id2] = partner[id1:id2]
-        new_temp[id2:id3] = g_best[self.ID_POS][id2:id3]
-        return new_temp
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            # Exploration
-            if idx < self.size_b:  # breeding operators
-                if np.random.uniform() < self.pb:
-                    pos_new = self.pop[idx][self.ID_POS] + np.random.normal(0, 1, self.problem.n_dims) * \
-                              (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-                else:
-                    levy_step = self.get_levy_flight_step(beta=1, multiplier=0.001, case=-1)
-                    pos_new = self.pop[idx][self.ID_POS] + 1.0 / np.sqrt(epoch + 1) * np.sign(np.random.random() - 0.5) * \
-                              levy_step * (self.pop[idx][self.ID_POS] - self.g_best[self.ID_POS])
-            # Exploitation
-            else:  # working operators
-                if np.random.uniform() < 0.5:
-                    t1, t2 = np.random.choice(range(self.size_b, self.pop_size), 2, replace=False)
-                    pos_new = self.pop[idx][self.ID_POS] + np.random.normal(0, 1, self.problem.n_dims) * \
-                              (self.pop[t1][self.ID_POS] - self.pop[t2][self.ID_POS])
-                else:
-                    pos_new = self.crossover_random__(self.pop, self.g_best)
-            # Mutation
-            temp = np.random.uniform(self.problem.lb, self.problem.ub)
-            pos_new = np.where(np.random.uniform(0, 1, self.problem.n_dims) < self.pm, temp, pos_new)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 14:01, 16/11/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalFOA(Optimizer):
+    """
+    The original version of: Fruit-fly Optimization Algorithm (FOA)
+
+    Links:
+        1. https://doi.org/10.1016/j.knosys.2011.07.001
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.FOA import OriginalFOA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalFOA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Pan, W.T., 2012. A new fruit fly optimization algorithm: taking the financial distress model
+    as an example. Knowledge-Based Systems, 26, pp.69-74.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def norm_consecutive_adjacent__(self, position=None):
+        return np.array([np.linalg.norm([position[x], position[x + 1]]) for x in range(0, self.problem.n_dims - 1)] + \
+                        [np.linalg.norm([position[-1], position[0]])])
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        """
+        Overriding method in Optimizer class
+
+        Returns:
+            list: a solution with format [position, target]
+        """
+        if pos is None:
+            pos = self.generate_position(self.problem.lb, self.problem.ub)
+        s = self.norm_consecutive_adjacent__(pos)
+        pos = self.amend_position(s, self.problem.lb, self.problem.ub)
+        target = self.get_target_wrapper(pos)
+        return [pos, target]
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * np.random.normal(self.problem.lb, self.problem.ub)
+            pos_new = self.norm_consecutive_adjacent__(pos_new)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(pop_new, self.pop)
+
+
+class BaseFOA(OriginalFOA):
+    """
+    The developed version: Fruit-fly Optimization Algorithm (FOA)
+
+    Notes
+    ~~~~~
+    + The fitness function (small function) is changed by taking the distance each 2 adjacent dimensions
+    + Update the position if only new generated solution is better
+    + The updated position is created by norm distance * gaussian random number
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.FOA import BaseFOA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = BaseFOA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(epoch, pop_size, **kwargs)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        c = 1 - epoch / self.epoch
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            pos_new = self.pop[idx][self.ID_POS] + np.random.normal(self.problem.lb, self.problem.ub)
+            pos_new = c * np.random.rand() * self.norm_consecutive_adjacent__(pos_new)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(pop_new, self.pop)
+
+
+class WhaleFOA(OriginalFOA):
+    """
+    The original version of: Whale Fruit-fly Optimization Algorithm (WFOA)
+
+    Links:
+        1. https://doi.org/10.1016/j.eswa.2020.113502
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.FOA import WhaleFOA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = WhaleFOA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Fan, Y., Wang, P., Heidari, A.A., Wang, M., Zhao, X., Chen, H. and Li, C., 2020. Boosted hunting-based
+    fruit fly optimization and advances in real-world problems. Expert Systems with Applications, 159, p.113502.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(epoch, pop_size, **kwargs)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        a = 2 - 2 * epoch / (self.epoch - 1)  # linearly decreased from 2 to 0
+
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            r = np.random.rand()
+            A = 2 * a * r - a
+            C = 2 * r
+            l = np.random.uniform(-1, 1)
+            p = 0.5
+            b = 1
+            if np.random.rand() < p:
+                if np.abs(A) < 1:
+                    D = np.abs(C * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+                    pos_new = self.g_best[self.ID_POS] - A * D
+                else:
+                    # select random 1 position in pop
+                    x_rand = self.pop[np.random.randint(self.pop_size)]
+                    D = np.abs(C * x_rand[self.ID_POS] - self.pop[idx][self.ID_POS])
+                    pos_new = (x_rand[self.ID_POS] - A * D)
+            else:
+                D1 = np.abs(self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+                pos_new = D1 * np.exp(b * l) * np.cos(2 * np.pi * l) + self.g_best[self.ID_POS]
+            smell = self.norm_consecutive_adjacent__(pos_new)
+            pos_new = self.amend_position(smell, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(pop_new, self.pop)
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/OOA.py` & `mealpy-2.5.3a1/mealpy/swarm_based/CoatiOA.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,101 +1,102 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 00:08, 27/10/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalOOA(Optimizer):
-    """
-    The original version of: Osprey Optimization Algorithm (OOA)
-
-    Links:
-        1. https://www.frontiersin.org/articles/10.3389/fmech.2022.1126450/full
-        2. https://www.mathworks.com/matlabcentral/fileexchange/124555-osprey-optimization-algorithm
-
-    Notes:
-        1. Algorithm design is similar to Zebra Optimization Algorithm (ZOA), Osprey Optimization Algorithm (OOA), Pelican optimization algorithm (POA), Siberian Tiger Optimization (STO), Language Education Optimization (LEO), Serval Optimization Algorithm (SOA), Walrus Optimization Algorithm (WOA), Fennec Fox Optimization (FFO), Three-periods optimization algorithm (TPOA), Teamwork optimization algorithm (TOA), Northern goshawk optimization (NGO), Tasmanian devil optimization (TDO), Archery algorithm (AA), Cat and mouse based optimizer (CMBO)
-        2. It may be useful to compare the Matlab code of this algorithm with those of the similar algorithms to ensure its accuracy and completeness.
-        3. The article may share some similarities with previous work by the same authors, further investigation may be warranted to verify the benchmark results reported in the papers and ensure their reliability and accuracy.
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.OOA import OriginalOOA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalOOA(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] TrojovskÃ½, P., & Dehghani, M. Osprey Optimization Algorithm: A new bio-inspired metaheuristic algorithm
-    for solving engineering optimization problems. Frontiers in Mechanical Engineering, 8, 136.
-    """
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.support_parallel_modes = False
-        self.sort_flag = False
-
-    def get_indexes_better__(self, pop, idx):
-        fits = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in self.pop])
-        if self.problem.minmax == "min":
-            idxs = np.where(fits < pop[idx][self.ID_TAR][self.ID_FIT])
-        else:
-            idxs = np.where(fits > pop[idx][self.ID_TAR][self.ID_FIT])
-        return idxs[0]
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        for idx in range(0, self.pop_size):
-            # Phase 1: : POSITION IDENTIFICATION AND HUNTING THE FISH (EXPLORATION)
-            idxs = self.get_indexes_better__(self.pop, idx)
-            if len(idxs) == 0:
-                sf = self.g_best
-            else:
-                if np.random.rand() < 0.5:
-                    sf = self.g_best
-                else:
-                    kk = np.random.permutation(idxs)[0]
-                    sf = self.pop[kk]
-            r1 = np.random.randint(1, 3)
-            pos_new = self.pop[idx][self.ID_POS] + np.random.normal(0, 1) * (sf[self.ID_POS] - r1 * self.pop[idx][self.ID_POS])     # Eq. 5
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            tar_new = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
-                self.pop[idx] = [pos_new, tar_new]
-
-            # PHASE 2: CARRYING THE FISH TO THE SUITABLE POSITION (EXPLOITATION)
-            pos_new = self.pop[idx][self.ID_POS] + self.problem.lb + np.random.rand() * (self.problem.ub - self.problem.lb)     # Eq. 7
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            tar_new = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
-                self.pop[idx] = [pos_new, tar_new]
+#!/usr/bin/env python
+# Created by "Thieu" at 00:08, 27/10/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalCoatiOA(Optimizer):
+    """
+    The original version of: Coati Optimization Algorithm (CoatiOA)
+
+    Links:
+        1. https://www.sciencedirect.com/science/article/pii/S0950705122011042
+        2. https://www.mathworks.com/matlabcentral/fileexchange/116965-coa-coati-optimization-algorithm
+
+    Notes (Plagiarism):
+        1. Algorithm design is very similar to Zebra Optimization Algorithm (ZOA), Osprey Optimization Algorithm (OOA), Pelican optimization algorithm (POA),
+        Siberian Tiger Optimization (STO), Language Education Optimization (LEO), Serval Optimization Algorithm (SOA), Walrus Optimization Algorithm (WOA),
+        Fennec Fox Optimization (FFO), Three-periods optimization algorithm (TPOA), Teamwork optimization algorithm (TOA), Northern goshawk optimization (NGO),
+        Tasmanian devil optimization (TDO), Archery algorithm (AA), Cat and mouse based optimizer (CMBO)
+        2. Check the matlab code of all above algorithms
+        2. Same authors, self-plagiarized article with kinda same algorithm with different meta-metaphors
+        4. Check the results of benchmark functions in the papers, they are mostly make up results
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.CoatiOA import OriginalCoatiOA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalCoatiOA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Dehghani, M., Montazeri, Z., TrojovskÃ¡, E., & TrojovskÃ½, P. (2023). Coati Optimization Algorithm: A new
+    bio-inspired metaheuristic algorithm for solving optimization problems. Knowledge-Based Systems, 259, 110011.
+    """
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.support_parallel_modes = False
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # Phase1: Hunting and attacking strategy on iguana (Exploration Phase)
+        size2 = int(self.pop_size/2)
+        for idx in range(0, size2):
+
+            pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (self.g_best[self.ID_POS] - np.random.randint(1, 3) * self.pop[idx][self.ID_POS])  # Eq. 4
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            tar_new = self.get_target_wrapper(pos_new)
+            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
+                self.pop[idx] = [pos_new, tar_new]
+
+        for idx in range(size2, self.pop_size):
+            iguana = self.create_solution(self.problem.lb, self.problem.ub)
+            if self.compare_agent(iguana, self.pop[idx]):
+                pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (iguana[self.ID_POS] - np.random.randint(1, 3) * self.pop[idx][self.ID_POS])  # Eq. 6
+            else:
+                pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (self.pop[idx][self.ID_POS] - iguana[self.ID_POS])  # Eq. 6
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            tar_new = self.get_target_wrapper(pos_new)
+            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
+                self.pop[idx] = [pos_new, tar_new]
+
+        # Phase2: The process of escaping from predators (Exploitation Phase)
+        for idx in range(0, self.pop_size):
+            LO, HI = self.problem.lb / (epoch+1), self.problem.ub / (epoch+1)
+            pos_new = self.pop[idx][self.ID_POS] + (1 - 2 * np.random.rand()) * (LO + np.random.rand() * (HI - LO))     # Eq. 8
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            tar_new = self.get_target_wrapper(pos_new)
+            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
+                self.pop[idx] = [pos_new, tar_new]
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/PFA.py` & `mealpy-2.5.3a1/mealpy/physics_based/CDO.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,96 +1,100 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 14:51, 17/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalPFA(Optimizer):
-    """
-    The original version of: Pathfinder Algorithm (PFA)
-
-    Links:
-        1. https://doi.org/10.1016/j.asoc.2019.03.012
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.PFA import OriginalPFA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalPFA(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Yapici, H. and Cetinkaya, N., 2019. A new meta-heuristic optimizer: Pathfinder algorithm.
-    Applied soft computing, 78, pp.545-568.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = True
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        alpha, beta = np.random.uniform(1, 2, 2)
-        A = np.random.uniform(self.problem.lb, self.problem.ub) * np.exp(-2 * (epoch + 1) / self.epoch)
-        t = 1 - (epoch + 1) * 1.0 / self.epoch
-        space = self.problem.ub - self.problem.lb
-
-        ## Update the position of pathfinder and check the bound
-        pos_new = self.pop[0][self.ID_POS] + 2 * np.random.uniform() * (self.g_best[self.ID_POS] - self.pop[0][self.ID_POS]) + A
-        pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-        target = self.get_target_wrapper(pos_new)
-        pop_new = [[pos_new, target], ]
-
-        ## Update positions of members, check the bound and calculate new fitness
-        for idx in range(1, self.pop_size):
-            agent = deepcopy(self.pop[idx])
-            pos_new = deepcopy(self.pop[idx][self.ID_POS]).astype(float)
-            for k in range(1, self.pop_size):
-                dist = np.sqrt(np.sum((self.pop[k][self.ID_POS] - self.pop[idx][self.ID_POS]) ** 2)) / self.problem.n_dims
-                t2 = alpha * np.random.uniform() * (self.pop[k][self.ID_POS] - self.pop[idx][self.ID_POS])
-                ## First stabilize the distance
-                t3 = np.random.uniform() * t * (dist / space)
-                pos_new += t2 + t3
-            ## Second stabilize the population size
-            t1 = beta * np.random.uniform() * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-            pos_new = (pos_new + t1) / self.pop_size
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            agent[self.ID_POS] = pos_new
-            pop_new.append(agent)
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-        self.pop = self.greedy_selection_population(self.pop, pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 21:45, 13/03/2023 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalCDO(Optimizer):
+    """
+    The original version of: Chernobyl Disaster Optimizer (CDO)
+
+    Links:
+        1. https://link.springer.com/article/10.1007/s00521-023-08261-1
+        2. https://www.mathworks.com/matlabcentral/fileexchange/124351-chernobyl-disaster-optimizer-cdo
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.physics_based.CDO import OriginalCDO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalCDO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Shehadeh, H. A. (2023). Chernobyl disaster optimizer (CDO): a novel meta-heuristic method
+    for global optimization. Neural Computing and Applications, 1-17.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        _, (b1, b2, b3), _ = self.get_special_solutions(self.pop, best=3, worst=1)
+        a = 3 - (epoch+1)*3/self.epoch
+        a1 = np.log10((16000-1) * np.random.rand()+16000)
+        a2 = np.log10((270000-1)*np.random.rand() + 270000)
+        a3 = np.log10((300000-1)*np.random.rand() + 300000)
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            r1 = np.random.rand(self.problem.n_dims)
+            r2 = np.random.rand(self.problem.n_dims)
+            pa = np.pi * r1*r1 / (0.25 * a1) - a*np.random.rand(self.problem.n_dims)
+            c1 = r2 * r2 * np.pi
+            alpha = np.abs(c1*b1[self.ID_POS] - self.pop[idx][self.ID_POS])
+            pos_a = 0.25 * (b1[self.ID_POS] - pa * alpha)
+
+            r3 = np.random.rand(self.problem.n_dims)
+            r4 = np.random.rand(self.problem.n_dims)
+            pb = np.pi * r3 * r3 / (0.5 * a2) - a * np.random.rand(self.problem.n_dims)
+            c2 = r4 * r4 * np.pi
+            beta = np.abs(c2 * b2[self.ID_POS] - self.pop[idx][self.ID_POS])
+            pos_b = 0.5 * (b2[self.ID_POS] - pb * beta)
+
+            r5 = np.random.rand(self.problem.n_dims)
+            r6 = np.random.rand(self.problem.n_dims)
+            pc = np.pi * r5 * r5 / a3 - a * np.random.rand(self.problem.n_dims)
+            c3 = r6 * r6 * np.pi
+            gama = np.abs(c3 * b3[self.ID_POS] - self.pop[idx][self.ID_POS])
+            pos_c = b3[self.ID_POS] - pc * gama
+
+            pos_new = (pos_a + pos_b + pos_c) / 3
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+        self.pop = pop_new
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/POA.py` & `mealpy-2.5.3a1/mealpy/swarm_based/TDO.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,89 +1,108 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 18:22, 11/03/2023 ----------%
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalPOA(Optimizer):
-    """
-    The original version of: Pelican Optimization Algorithm (POA)
-
-    Links:
-        1. https://www.mdpi.com/1424-8220/22/3/855
-        2. https://www.mathworks.com/matlabcentral/fileexchange/106680-pelican-optimization-algorithm-a-novel-nature-inspired
-
-    Notes:
-        1. This is somewhat concerning, as there appears to be a high degree of similarity between the source code for this algorithm and the Northern Goshawk Optimization (NGO)
-        2. Algorithm design is similar to Zebra Optimization Algorithm (ZOA), Osprey Optimization Algorithm (OOA), Coati Optimization Algorithm (CoatiOA), Siberian Tiger Optimization (STO), Language Education Optimization (LEO), Serval Optimization Algorithm (SOA), Walrus Optimization Algorithm (WOA), Fennec Fox Optimization (FFO), Three-periods optimization algorithm (TPOA), Teamwork optimization algorithm (TOA), Northern goshawk optimization (NGO), Tasmanian devil optimization (TDO), Archery algorithm (AA), Cat and mouse based optimizer (CMBO)
-        3. It may be useful to compare the Matlab code of this algorithm with those of the similar algorithms to ensure its accuracy and completeness.
-        4. The article may share some similarities with previous work by the same authors, further investigation may be warranted to verify the benchmark results reported in the papers and ensure their reliability and accuracy.
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.POA import OriginalPOA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalPOA(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] TrojovskÃ½, P., & Dehghani, M. (2022). Pelican optimization algorithm: A novel nature-inspired
-    algorithm for engineering applications. Sensors, 22(3), 855.
-    """
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.support_parallel_modes = False
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        ## UPDATE location of food
-        kk = np.random.permutation(self.pop_size)[0]
-        for idx in range(0, self.pop_size):
-            # PHASE 1: Moving towards prey (exploration phase)
-            if self.compare_agent(self.pop[kk], self.pop[idx]):     # Eq. 4
-                pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (self.pop[kk][self.ID_POS] - np.random.randint(1, 3) * self.pop[idx][self.ID_POS])
-            else:
-                pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (self.pop[idx][self.ID_POS] - self.pop[kk][self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            tar_new = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
-                self.pop[idx] = [pos_new, tar_new]
-
-            # PHASE 2: Winging on the water surface (exploitation phase)        # Eq. 6
-            pos_new = self.pop[idx][self.ID_POS] + 0.2 * (1 - (epoch+1)/self.epoch) *(2*np.random.rand(self.problem.n_dims) - 1) * self.pop[idx][self.ID_POS]
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            tar_new = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
-                self.pop[idx] = [pos_new, tar_new]
+#!/usr/bin/env python
+# Created by "Thieu" at 00:08, 27/10/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalTDO(Optimizer):
+    """
+    The original version of: Tasmanian Devil Optimization (TDO)
+
+    Links:
+        1. https://www.mathworks.com/matlabcentral/fileexchange/111380-tasmanian-devil-optimization-tdo
+        2. https://ieeexplore.ieee.org/abstract/document/9714388
+
+    Notes (Plagiarism):
+        0. This is really disgusting, because the source code for this algorithm is almost exactly the same as the source code of Osprey Optimization Algorithm
+        1. Algorithm design is very similar to Zebra Optimization Algorithm (ZOA), Osprey Optimization Algorithm (OOA), Pelican optimization algorithm (POA),
+        Siberian Tiger Optimization (STO), Language Education Optimization (LEO), Serval Optimization Algorithm (SOA), Walrus Optimization Algorithm (WOA),
+        Fennec Fox Optimization (FFO), Three-periods optimization algorithm (TPOA), Teamwork optimization algorithm (TOA), Northern goshawk optimization (NGO),
+        Osprey Optimization Algorithm (OOA), Archery algorithm (AA), Cat and mouse based optimizer (CMBO)
+        2. Check the matlab code of all above algorithms
+        2. Same authors, self-plagiarized article with kinda same algorithm with different meta-metaphors
+        4. Check the results of benchmark functions in the papers, they are mostly make up results
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.TDO import OriginalTDO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalTDO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Dehghani, M., HubÃ¡lovskÃ½, Å ., & TrojovskÃ½, P. (2022). Tasmanian devil optimization: a new bio-inspired
+    optimization algorithm for solving optimization algorithm. IEEE Access, 10, 19599-19620.
+    """
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.support_parallel_modes = False
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        for idx in range(0, self.pop_size):
+            # PHASE1: Hunting Feeding
+            if np.random.rand() > 0.5:
+                # STRATEGY 1: FEEDING BY EATING CARRION (EXPLORATION PHASE)
+                # CARRION selection using (3)
+                kk = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
+                if self.compare_agent(self.pop[kk], self.pop[idx]):
+                    pos_new = self.pop[idx][self.ID_POS] + np.random.rand(self.problem.n_dims) * (self.pop[kk][self.ID_POS] - np.random.randint(1, 3)*self.pop[idx][self.ID_POS])
+                else:
+                    pos_new = self.pop[idx][self.ID_POS] + np.random.rand(self.problem.n_dims) * (self.pop[idx][self.ID_POS] - self.pop[kk][self.ID_POS])
+                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                tar_new = self.get_target_wrapper(pos_new)
+                if self.compare_agent([pos_new, tar_new], self.pop[idx]):
+                    self.pop[idx] = [pos_new, tar_new]
+            else:
+            # STRATEGY 2: FEEDING BY EATING PREY (EXPLOITATION PHASE)
+            # stage1: prey selection and attack it
+                kk = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
+                if self.compare_agent(self.pop[kk], self.pop[idx]):
+                    pos_new = self.pop[idx][self.ID_POS] + np.random.rand(self.problem.n_dims) * (self.pop[kk][self.ID_POS] - np.random.randint(1, 3) * self.pop[idx][self.ID_POS])
+                else:
+                    pos_new = self.pop[idx][self.ID_POS] + np.random.rand(self.problem.n_dims) * (self.pop[idx][self.ID_POS] - self.pop[kk][self.ID_POS])
+                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                tar_new = self.get_target_wrapper(pos_new)
+                if self.compare_agent([pos_new, tar_new], self.pop[idx]):
+                    self.pop[idx] = [pos_new, tar_new]
+
+            # stage2: prey chasing
+            rr = 0.01 * (1 - (epoch+1)/self.epoch)      # Calculating the neighborhood radius using(9)
+            pos_new = self.pop[idx][self.ID_POS] + (-rr + 2 * rr * np.random.rand(self.problem.n_dims)) * self.pop[idx][self.ID_POS]
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            tar_new = self.get_target_wrapper(pos_new)
+            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
+                self.pop[idx] = [pos_new, tar_new]
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/PSO.py` & `mealpy-2.5.3a1/mealpy/swarm_based/PSO.py`

 * *Ordering differences only*

 * *Files 9% similar despite different names*

```diff
@@ -1,621 +1,621 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 09:49, 17/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalPSO(Optimizer):
-    """
-    The original version of: Particle Swarm Optimization (PSO)
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + c1 (float): [1, 3], local coefficient, default = 2.05
-        + c2 (float): [1, 3], global coefficient, default = 2.05
-        + w_min (float): [0.1, 0.5], Weight min of bird, default = 0.4
-        + w_max (float): [0.8, 2.0], Weight max of bird, default = 0.9
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.PSO import OriginalPSO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> c1 = 2.05
-    >>> c2 = 2.05
-    >>> w_min = 0.4
-    >>> w_max = 0.9
-    >>> model = OriginalPSO(epoch, pop_size, c1, c2, w_min, w_max)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Kennedy, J. and Eberhart, R., 1995, November. Particle swarm optimization. In Proceedings of
-    ICNN'95-international conference on neural networks (Vol. 4, pp. 1942-1948). IEEE.
-    """
-    ID_POS = 0
-    ID_TAR = 1
-    ID_VEC = 2  # Velocity
-    ID_LOP = 3  # Local position
-    ID_LOF = 4  # Local fitness
-
-    def __init__(self, epoch=10000, pop_size=100, c1=2.05, c2=2.05, w_min=0.4, w_max=0.9, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            c1 (float): [0-2] local coefficient
-            c2 (float): [0-2] global coefficient
-            w_min (float): Weight min of bird, default = 0.4
-            w_max (float): Weight max of bird, default = 0.9
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.c1 = self.validator.check_float("c1", c1, (0, 5.0))
-        self.c2 = self.validator.check_float("c2", c2, (0, 5.0))
-        self.w_min = self.validator.check_float("w_min", w_min, (0, 0.5))
-        self.w_max = self.validator.check_float("w_max", w_max, [0.5, 2.0])
-        self.set_parameters(["epoch", "pop_size", "c1", "c2", "w_min", "w_max"])
-        self.sort_flag = False
-
-    def initialize_variables(self):
-        self.v_max = 0.5 * (self.problem.ub - self.problem.lb)
-        self.v_min = -self.v_max
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        """
-        Overriding method in Optimizer class
-
-        Returns:
-            list: wrapper of solution with format [position, target, velocity, local_pos, local_fit]
-        """
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        position = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(position)
-        velocity = np.random.uniform(self.v_min, self.v_max)
-        local_pos = deepcopy(position)
-        local_fit = deepcopy(target)
-        return [position, target, velocity, local_pos, local_fit]
-
-    def amend_position(self, position=None, lb=None, ub=None):
-        """
-        Args:
-            position: vector position (location) of the solution.
-            lb: list of lower bound values
-            ub: list of upper bound values
-
-        Returns:
-            Amended position (make the position is in bound)
-        """
-        condition = np.logical_and(lb <= position, position <= ub)
-        pos_rand = np.random.uniform(lb, ub)
-        return np.where(condition, position, pos_rand)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # Update weight after each move count  (weight down)
-        w = (self.epoch - epoch) / self.epoch * (self.w_max - self.w_min) + self.w_min
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            agent = deepcopy(self.pop[idx])
-            v_new = w * self.pop[idx][self.ID_VEC] + self.c1 * np.random.rand() * (self.pop[idx][self.ID_LOP] - self.pop[idx][self.ID_POS]) + \
-                    self.c2 * np.random.rand() * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-            x_new = self.pop[idx][self.ID_POS] + v_new  # Xi(new) = Xi(old) + Vi(new) * deltaT (deltaT = 1)
-            pos_new = self.amend_position(x_new, self.problem.lb, self.problem.ub)
-            agent[self.ID_POS] = pos_new
-            agent[self.ID_VEC] = v_new
-            pop_new.append(agent)
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-
-        # Update current position, current velocity and compare with past position, past fitness (local best)
-        for idx in range(0, self.pop_size):
-            if self.compare_agent(pop_new[idx], self.pop[idx]):
-                self.pop[idx] = deepcopy(pop_new[idx])
-                if self.compare_agent(pop_new[idx], [None, self.pop[idx][self.ID_LOF]]):
-                    self.pop[idx][self.ID_LOP] = deepcopy(pop_new[idx][self.ID_POS])
-                    self.pop[idx][self.ID_LOF] = deepcopy(pop_new[idx][self.ID_TAR])
-
-
-class PPSO(Optimizer):
-    """
-    The original version of: Phasor Particle Swarm Optimization (P-PSO)
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.PSO import PPSO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = PPSO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Ghasemi, M., Akbari, E., Rahimnejad, A., Razavi, S.E., Ghavidel, S. and Li, L., 2019.
-    Phasor particle swarm optimization: a simple and efficient variant of PSO. Soft Computing, 23(19), pp.9701-9718.
-    """
-
-    ID_VEC = 2  # Velocity
-    ID_LOP = 3  # Local position
-    ID_LOF = 4  # Local fitness
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def initialize_variables(self):
-        self.v_max = 0.5 * (self.problem.ub - self.problem.lb)
-        self.v_min = -self.v_max
-        self.dyn_delta_list = np.random.uniform(0, 2 * np.pi, self.pop_size)
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        """
-        Overriding method in Optimizer class
-
-        Returns:
-            list: wrapper of solution with format [position, target, velocity, local_pos, local_fit]
-        """
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        position = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(position)
-        velocity = np.random.uniform(self.v_min, self.v_max)
-        local_pos = deepcopy(position)
-        local_fit = deepcopy(target)
-        return [position, target, velocity, local_pos, local_fit]
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = []
-        for i in range(0, self.pop_size):
-            agent = deepcopy(self.pop[i])
-            aa = 2 * (np.sin(self.dyn_delta_list[i]))
-            bb = 2 * (np.cos(self.dyn_delta_list[i]))
-            ee = np.abs(np.cos(self.dyn_delta_list[i])) ** aa
-            tt = np.abs(np.sin(self.dyn_delta_list[i])) ** bb
-
-            v_new = ee * (self.pop[i][self.ID_LOP] - self.pop[i][self.ID_POS]) + tt * (self.g_best[self.ID_POS] - self.pop[i][self.ID_POS])
-            v_new = np.minimum(np.maximum(v_new, -self.v_max), self.v_max)
-            agent[self.ID_VEC] = deepcopy(v_new)
-
-            pos_new = self.pop[i][self.ID_POS] + v_new
-            agent[self.ID_POS] = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-
-            self.dyn_delta_list[i] += np.abs(aa + bb) * (2 * np.pi)
-            self.v_max = (np.abs(np.cos(self.dyn_delta_list[i])) ** 2) * (self.problem.ub - self.problem.lb)
-            pop_new.append(agent)
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(agent[self.ID_POS])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-
-        # Update current position, current velocity and compare with past position, past fitness (local best)
-        for idx in range(0, self.pop_size):
-            if self.compare_agent(pop_new[idx], self.pop[idx]):
-                self.pop[idx] = deepcopy(pop_new[idx])
-                if self.compare_agent(pop_new[idx], [None, self.pop[idx][self.ID_LOF]]):
-                    self.pop[idx][self.ID_LOP] = deepcopy(pop_new[idx][self.ID_POS])
-                    self.pop[idx][self.ID_LOF] = deepcopy(pop_new[idx][self.ID_TAR])
-
-
-class HPSO_TVAC(PPSO):
-    """
-    The original version of: Hierarchical PSO Time-Varying Acceleration (HPSO-TVAC)
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + ci (float): [0.3, 1.0], c initial, default = 0.5
-        + cf (float): [0.0, 0.3], c final, default = 0.0
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.PSO import HPSO_TVAC
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> ci = 0.5
-    >>> cf = 0.0
-    >>> model = HPSO_TVAC(epoch, pop_size, ci, cf)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Ghasemi, M., Aghaei, J. and Hadipour, M., 2017. New self-organising hierarchical PSO with
-    jumping time-varying acceleration coefficients. Electronics Letters, 53(20), pp.1360-1362.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, ci=0.5, cf=0.0, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            ci (float): c initial, default = 0.5
-            cf (float): c final, default = 0.0
-        """
-        super().__init__(epoch, pop_size, **kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.ci = self.validator.check_float("ci", ci, [0.3, 1.0])
-        self.cf = self.validator.check_float("cf", cf, [0, 0.3])
-        self.set_parameters(["epoch", "pop_size", "ci", "cf"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        c_it = ((self.cf - self.ci) * ((epoch + 1) / self.epoch)) + self.ci
-        pop_new = []
-        for i in range(0, self.pop_size):
-            agent = deepcopy(self.pop[i])
-            idx_k = np.random.randint(0, self.pop_size)
-            w = np.random.normal()
-            while np.abs(w - 1.0) < 0.01:
-                w = np.random.normal()
-            c1_it = np.abs(w) ** (c_it * w)
-            c2_it = np.abs(1 - w) ** (c_it / (1 - w))
-
-            #################### HPSO
-            v_new = c1_it * np.random.uniform(0, 1, self.problem.n_dims) * (self.pop[i][self.ID_LOP] - self.pop[i][self.ID_POS]) + \
-                    c2_it * np.random.uniform(0, 1, self.problem.n_dims) * \
-                    (self.g_best[self.ID_POS] + self.pop[idx_k][self.ID_LOP] - 2 * self.pop[i][self.ID_POS])
-
-            np.where(v_new == 0, np.sign(0.5 - np.random.uniform()) * np.random.uniform() * self.v_max, v_new)
-            v_new = np.sign(v_new) * np.minimum(np.abs(v_new), self.v_max)
-            #########################
-
-            v_new = np.minimum(np.maximum(v_new, -self.v_max), self.v_max)
-            pos_new = self.pop[i][self.ID_POS] + v_new
-            agent[self.ID_VEC] = v_new
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            agent[self.ID_POS] = pos_new
-            pop_new.append(agent)
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        # Update fitness for all solutions
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-
-        # Update current position, current velocity and compare with past position, past fitness (local best)
-        for idx in range(0, self.pop_size):
-            if self.compare_agent(pop_new[idx], self.pop[idx]):
-                self.pop[idx] = deepcopy(pop_new[idx])
-                if self.compare_agent(pop_new[idx], [None, self.pop[idx][self.ID_LOF]]):
-                    self.pop[idx][self.ID_LOP] = deepcopy(pop_new[idx][self.ID_POS])
-                    self.pop[idx][self.ID_LOF] = deepcopy(pop_new[idx][self.ID_TAR])
-
-
-class C_PSO(OriginalPSO):
-    """
-    The original version of: Chaos Particle Swarm Optimization (C-PSO)
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + c1 (float): [1.0, 3.0] local coefficient, default = 2.05
-        + c2 (float): [1.0, 3.0] global coefficient, default = 2.05
-        + w_min (float): [0.1, 0.4], Weight min of bird, default = 0.4
-        + w_max (float): [0.4, 2.0], Weight max of bird, default = 0.9
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.PSO import C_PSO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> c1 = 2.05
-    >>> c2 = 2.05
-    >>> w_min = 0.4
-    >>> w_max = 0.9
-    >>> model = C_PSO(epoch, pop_size, c1, c2, w_min, w_max)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Liu, B., Wang, L., Jin, Y.H., Tang, F. and Huang, D.X., 2005. Improved particle swarm optimization
-    combined with chaos. Chaos, Solitons & Fractals, 25(5), pp.1261-1271.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, c1=2.05, c2=2.05, w_min=0.4, w_max=0.9, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            c1 (float): [0-2] local coefficient, default = 2.05
-            c2 (float): [0-2] global coefficient, default = 2.05
-            w_min (float): Weight min of bird, default = 0.4
-            w_max (float): Weight max of bird, default = 0.9
-        """
-        super().__init__(epoch, pop_size, c1, c2, w_min, w_max, **kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.c1 = self.validator.check_float("c1", c1, (0, 5.0))
-        self.c2 = self.validator.check_float("c2", c2, (0, 5.0))
-        self.w_min = self.validator.check_float("w_min", w_min, (0, 0.5))
-        self.w_max = self.validator.check_float("w_max", w_max, [0.5, 2.0])
-        self.set_parameters(["epoch", "pop_size", "c1", "c2", "w_min", "w_max"])
-        self.sort_flag = False
-    
-    def initialize_variables(self):
-        self.v_max = 0.5 * (self.problem.ub - self.problem.lb)
-        self.v_min = -self.v_max
-        self.N_CLS = int(self.pop_size / 5)  # Number of chaotic local searches
-        self.dyn_lb = deepcopy(self.problem.lb)
-        self.dyn_ub = deepcopy(self.problem.ub)
-
-    def get_weights__(self, fit, fit_avg, fit_min):
-        temp1 = self.w_min + (self.w_max - self.w_min) * (fit - fit_min) / (fit_avg - fit_min)
-        if self.problem.minmax == "min":
-            output = temp1 if fit <= fit_avg else self.w_max
-        else:
-            output = self.w_max if fit <= fit_avg else temp1
-        return output
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        list_fits = [item[self.ID_TAR][self.ID_FIT] for item in self.pop]
-        fit_avg = np.mean(list_fits)
-        fit_min = np.min(list_fits)
-        pop_new = []
-        for i in range(self.pop_size):
-            agent = deepcopy(self.pop[i])
-            w = self.get_weights__(self.pop[i][self.ID_TAR][self.ID_FIT], fit_avg, fit_min)
-            v_new = w * self.pop[i][self.ID_VEC] + self.c1 * np.random.rand() * (self.pop[i][self.ID_LOP] - self.pop[i][self.ID_POS]) + \
-                    self.c2 * np.random.rand() * (self.g_best[self.ID_POS] - self.pop[i][self.ID_POS])
-            v_new = np.clip(v_new, self.v_min, self.v_max)
-            x_new = self.pop[i][self.ID_POS].astype(float) + v_new
-            agent[self.ID_VEC] = v_new
-            pos_new = self.amend_position(x_new, self.dyn_lb, self.dyn_ub)
-            agent[self.ID_POS] = pos_new
-            pop_new.append(agent)
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-
-        # Update current position, current velocity and compare with past position, past fitness (local best)
-        for idx in range(0, self.pop_size):
-            if self.compare_agent(pop_new[idx], self.pop[idx]):
-                self.pop[idx] = deepcopy(pop_new[idx])
-                if self.compare_agent(pop_new[idx], [None, self.pop[idx][self.ID_LOF]]):
-                    self.pop[idx][self.ID_LOP] = deepcopy(pop_new[idx][self.ID_POS])
-                    self.pop[idx][self.ID_LOF] = deepcopy(pop_new[idx][self.ID_TAR])
-
-        ## Implement chaostic local search for the best solution
-        g_best = self.g_best
-        cx_best_0 = (self.g_best[self.ID_POS] - self.problem.lb) / (self.problem.ub - self.problem.lb)  # Eq. 7
-        cx_best_1 = 4 * cx_best_0 * (1 - cx_best_0)  # Eq. 6
-        x_best = self.problem.lb + cx_best_1 * (self.problem.ub - self.problem.lb)  # Eq. 8
-        x_best = self.amend_position(x_best, self.problem.lb, self.problem.ub)
-        target_best = self.get_target_wrapper(x_best)
-        if self.compare_agent([x_best, target_best], self.g_best):
-            g_best = [x_best, target_best]
-
-        r = np.random.rand()
-        bound_min = np.stack([self.dyn_lb, g_best[self.ID_POS] - r * (self.dyn_ub - self.dyn_lb)])
-        self.dyn_lb = np.max(bound_min, axis=0)
-        bound_max = np.stack([self.dyn_ub, g_best[self.ID_POS] + r * (self.dyn_ub - self.dyn_lb)])
-        self.dyn_ub = np.min(bound_max, axis=0)
-
-        pop_new_child = self.create_population(self.pop_size - self.N_CLS)
-        self.pop = self.get_sorted_strim_population(self.pop + pop_new_child, self.pop_size)
-
-
-class CL_PSO(Optimizer):
-    """
-    The original version of: Comprehensive Learning Particle Swarm Optimization (CL-PSO)
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + c_local (float): [1.0, 3.0], local coefficient, default = 1.2
-        + w_min (float): [0.1, 0.5], Weight min of bird, default = 0.4
-        + w_max (float): [0.7, 2.0], Weight max of bird, default = 0.9
-        + max_flag (int): [5, 20], Number of times, default = 7
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.PSO import CL_PSO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> c_local = 1.2
-    >>> w_min = 0.4
-    >>> w_max = 0.9
-    >>> max_flag = 7
-    >>> model = CL_PSO(epoch, pop_size, c_local, w_min, w_max, max_flag)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Liang, J.J., Qin, A.K., Suganthan, P.N. and Baskar, S., 2006. Comprehensive learning particle swarm optimizer
-    for global optimization of multimodal functions. IEEE transactions on evolutionary computation, 10(3), pp.281-295.
-    """
-
-    ID_VEC = 2
-    ID_LOP = 3
-    ID_LOF = 4
-
-    def __init__(self, epoch=10000, pop_size=100, c_local=1.2, w_min=0.4, w_max=0.9, max_flag=7, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            c_local (float): local coefficient, default = 1.2
-            w_min (float): Weight min of bird, default = 0.4
-            w_max (float): Weight max of bird, default = 0.9
-            max_flag (int): Number of times, default = 7
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.c_local = self.validator.check_float("c_local", c_local, (0, 5.0))
-        self.w_min = self.validator.check_float("w_min", w_min, (0, 0.5))
-        self.w_max = self.validator.check_float("w_max", w_max, [0.5, 2.0])
-        self.max_flag = self.validator.check_int("max_flag", max_flag, [2, 100])
-        self.set_parameters(["epoch", "pop_size", "c_local", "w_min", "w_max", "max_flag"])
-        self.sort_flag = False
-    
-    def initialize_variables(self):
-        self.v_max = 0.5 * (self.problem.ub - self.problem.lb)
-        self.v_min = -self.v_max
-        self.flags = np.zeros(self.pop_size)
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        """
-        Overriding method in Optimizer class
-
-        Returns:
-            list: wrapper of solution with format [position, target, velocity, local_pos, local_fit]
-        """
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        position = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(position)
-        velocity = np.random.uniform(self.v_min, self.v_max)
-        local_pos = deepcopy(position)
-        local_fit = deepcopy(target)
-        return [position, target, velocity, local_pos, local_fit]
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        wk = self.w_max * (epoch / self.epoch) * (self.w_max - self.w_min)
-        pop_new = []
-        for i in range(0, self.pop_size):
-            agent = deepcopy(self.pop[i])
-            if self.flags[i] >= self.max_flag:
-                self.flags[i] = 0
-                agent = self.create_solution(self.problem.lb, self.problem.ub)
-
-            pci = 0.05 + 0.45 * (np.exp(10 * (i + 1) / self.pop_size) - 1) / (np.exp(10) - 1)
-
-            vec_new = deepcopy(self.pop[i][self.ID_VEC])
-            for j in range(0, self.problem.n_dims):
-                if np.random.rand() > pci:
-                    vj = wk * self.pop[i][self.ID_VEC][j] + self.c_local * np.random.rand() * \
-                         (self.pop[i][self.ID_LOP][j] - self.pop[i][self.ID_POS][j])
-                else:
-                    id1, id2 = np.random.choice(list(set(range(0, self.pop_size)) - {i}), 2, replace=False)
-                    if self.compare_agent(self.pop[id1], self.pop[id2]):
-                        vj = wk * self.pop[i][self.ID_VEC][j] + self.c_local * np.random.rand() * \
-                             (self.pop[id1][self.ID_LOP][j] - self.pop[i][self.ID_POS][j])
-                    else:
-                        vj = wk * self.pop[i][self.ID_VEC][j] + self.c_local * np.random.rand() * \
-                             (self.pop[id2][self.ID_LOP][j] - self.pop[i][self.ID_POS][j])
-                vec_new[j] = vj
-            vec_new = np.clip(vec_new, self.v_min, self.v_max)
-            pos_new = self.pop[i][self.ID_POS] + vec_new
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            agent[self.ID_VEC] = vec_new
-            agent[self.ID_POS] = pos_new
-            pop_new.append(agent)
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-
-        # Update current position, current velocity and compare with past position, past fitness (local best)
-        for idx in range(0, self.pop_size):
-            if self.compare_agent(pop_new[idx], self.pop[idx]):
-                self.pop[idx] = deepcopy(pop_new[idx])
-                if self.compare_agent(pop_new[idx], [None, self.pop[idx][self.ID_LOF]]):
-                    self.pop[idx][self.ID_LOP] = deepcopy(pop_new[idx][self.ID_POS])
-                    self.pop[idx][self.ID_LOF] = deepcopy(pop_new[idx][self.ID_TAR])
-                    self.flags[idx] = 0
-                else:
-                    self.flags[idx] += 1
+#!/usr/bin/env python
+# Created by "Thieu" at 09:49, 17/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalPSO(Optimizer):
+    """
+    The original version of: Particle Swarm Optimization (PSO)
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + c1 (float): [1, 3], local coefficient, default = 2.05
+        + c2 (float): [1, 3], global coefficient, default = 2.05
+        + w_min (float): [0.1, 0.5], Weight min of bird, default = 0.4
+        + w_max (float): [0.8, 2.0], Weight max of bird, default = 0.9
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.PSO import OriginalPSO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> c1 = 2.05
+    >>> c2 = 2.05
+    >>> w_min = 0.4
+    >>> w_max = 0.9
+    >>> model = OriginalPSO(epoch, pop_size, c1, c2, w_min, w_max)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Kennedy, J. and Eberhart, R., 1995, November. Particle swarm optimization. In Proceedings of
+    ICNN'95-international conference on neural networks (Vol. 4, pp. 1942-1948). IEEE.
+    """
+    ID_POS = 0
+    ID_TAR = 1
+    ID_VEC = 2  # Velocity
+    ID_LOP = 3  # Local position
+    ID_LOF = 4  # Local fitness
+
+    def __init__(self, epoch=10000, pop_size=100, c1=2.05, c2=2.05, w_min=0.4, w_max=0.9, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            c1 (float): [0-2] local coefficient
+            c2 (float): [0-2] global coefficient
+            w_min (float): Weight min of bird, default = 0.4
+            w_max (float): Weight max of bird, default = 0.9
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.c1 = self.validator.check_float("c1", c1, (0, 5.0))
+        self.c2 = self.validator.check_float("c2", c2, (0, 5.0))
+        self.w_min = self.validator.check_float("w_min", w_min, (0, 0.5))
+        self.w_max = self.validator.check_float("w_max", w_max, [0.5, 2.0])
+        self.set_parameters(["epoch", "pop_size", "c1", "c2", "w_min", "w_max"])
+        self.sort_flag = False
+
+    def initialize_variables(self):
+        self.v_max = 0.5 * (self.problem.ub - self.problem.lb)
+        self.v_min = -self.v_max
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        """
+        Overriding method in Optimizer class
+
+        Returns:
+            list: wrapper of solution with format [position, target, velocity, local_pos, local_fit]
+        """
+        if pos is None:
+            pos = self.generate_position(lb, ub)
+        position = self.amend_position(pos, lb, ub)
+        target = self.get_target_wrapper(position)
+        velocity = np.random.uniform(self.v_min, self.v_max)
+        local_pos = deepcopy(position)
+        local_fit = deepcopy(target)
+        return [position, target, velocity, local_pos, local_fit]
+
+    def amend_position(self, position=None, lb=None, ub=None):
+        """
+        Args:
+            position: vector position (location) of the solution.
+            lb: list of lower bound values
+            ub: list of upper bound values
+
+        Returns:
+            Amended position (make the position is in bound)
+        """
+        condition = np.logical_and(lb <= position, position <= ub)
+        pos_rand = np.random.uniform(lb, ub)
+        return np.where(condition, position, pos_rand)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # Update weight after each move count  (weight down)
+        w = (self.epoch - epoch) / self.epoch * (self.w_max - self.w_min) + self.w_min
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            agent = deepcopy(self.pop[idx])
+            v_new = w * self.pop[idx][self.ID_VEC] + self.c1 * np.random.rand() * (self.pop[idx][self.ID_LOP] - self.pop[idx][self.ID_POS]) + \
+                    self.c2 * np.random.rand() * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+            x_new = self.pop[idx][self.ID_POS] + v_new  # Xi(new) = Xi(old) + Vi(new) * deltaT (deltaT = 1)
+            pos_new = self.amend_position(x_new, self.problem.lb, self.problem.ub)
+            agent[self.ID_POS] = pos_new
+            agent[self.ID_VEC] = v_new
+            pop_new.append(agent)
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+
+        # Update current position, current velocity and compare with past position, past fitness (local best)
+        for idx in range(0, self.pop_size):
+            if self.compare_agent(pop_new[idx], self.pop[idx]):
+                self.pop[idx] = deepcopy(pop_new[idx])
+                if self.compare_agent(pop_new[idx], [None, self.pop[idx][self.ID_LOF]]):
+                    self.pop[idx][self.ID_LOP] = deepcopy(pop_new[idx][self.ID_POS])
+                    self.pop[idx][self.ID_LOF] = deepcopy(pop_new[idx][self.ID_TAR])
+
+
+class PPSO(Optimizer):
+    """
+    The original version of: Phasor Particle Swarm Optimization (P-PSO)
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.PSO import PPSO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = PPSO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Ghasemi, M., Akbari, E., Rahimnejad, A., Razavi, S.E., Ghavidel, S. and Li, L., 2019.
+    Phasor particle swarm optimization: a simple and efficient variant of PSO. Soft Computing, 23(19), pp.9701-9718.
+    """
+
+    ID_VEC = 2  # Velocity
+    ID_LOP = 3  # Local position
+    ID_LOF = 4  # Local fitness
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def initialize_variables(self):
+        self.v_max = 0.5 * (self.problem.ub - self.problem.lb)
+        self.v_min = -self.v_max
+        self.dyn_delta_list = np.random.uniform(0, 2 * np.pi, self.pop_size)
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        """
+        Overriding method in Optimizer class
+
+        Returns:
+            list: wrapper of solution with format [position, target, velocity, local_pos, local_fit]
+        """
+        if pos is None:
+            pos = self.generate_position(lb, ub)
+        position = self.amend_position(pos, lb, ub)
+        target = self.get_target_wrapper(position)
+        velocity = np.random.uniform(self.v_min, self.v_max)
+        local_pos = deepcopy(position)
+        local_fit = deepcopy(target)
+        return [position, target, velocity, local_pos, local_fit]
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = []
+        for i in range(0, self.pop_size):
+            agent = deepcopy(self.pop[i])
+            aa = 2 * (np.sin(self.dyn_delta_list[i]))
+            bb = 2 * (np.cos(self.dyn_delta_list[i]))
+            ee = np.abs(np.cos(self.dyn_delta_list[i])) ** aa
+            tt = np.abs(np.sin(self.dyn_delta_list[i])) ** bb
+
+            v_new = ee * (self.pop[i][self.ID_LOP] - self.pop[i][self.ID_POS]) + tt * (self.g_best[self.ID_POS] - self.pop[i][self.ID_POS])
+            v_new = np.minimum(np.maximum(v_new, -self.v_max), self.v_max)
+            agent[self.ID_VEC] = deepcopy(v_new)
+
+            pos_new = self.pop[i][self.ID_POS] + v_new
+            agent[self.ID_POS] = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+
+            self.dyn_delta_list[i] += np.abs(aa + bb) * (2 * np.pi)
+            self.v_max = (np.abs(np.cos(self.dyn_delta_list[i])) ** 2) * (self.problem.ub - self.problem.lb)
+            pop_new.append(agent)
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(agent[self.ID_POS])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+
+        # Update current position, current velocity and compare with past position, past fitness (local best)
+        for idx in range(0, self.pop_size):
+            if self.compare_agent(pop_new[idx], self.pop[idx]):
+                self.pop[idx] = deepcopy(pop_new[idx])
+                if self.compare_agent(pop_new[idx], [None, self.pop[idx][self.ID_LOF]]):
+                    self.pop[idx][self.ID_LOP] = deepcopy(pop_new[idx][self.ID_POS])
+                    self.pop[idx][self.ID_LOF] = deepcopy(pop_new[idx][self.ID_TAR])
+
+
+class HPSO_TVAC(PPSO):
+    """
+    The original version of: Hierarchical PSO Time-Varying Acceleration (HPSO-TVAC)
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + ci (float): [0.3, 1.0], c initial, default = 0.5
+        + cf (float): [0.0, 0.3], c final, default = 0.0
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.PSO import HPSO_TVAC
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> ci = 0.5
+    >>> cf = 0.0
+    >>> model = HPSO_TVAC(epoch, pop_size, ci, cf)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Ghasemi, M., Aghaei, J. and Hadipour, M., 2017. New self-organising hierarchical PSO with
+    jumping time-varying acceleration coefficients. Electronics Letters, 53(20), pp.1360-1362.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, ci=0.5, cf=0.0, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            ci (float): c initial, default = 0.5
+            cf (float): c final, default = 0.0
+        """
+        super().__init__(epoch, pop_size, **kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.ci = self.validator.check_float("ci", ci, [0.3, 1.0])
+        self.cf = self.validator.check_float("cf", cf, [0, 0.3])
+        self.set_parameters(["epoch", "pop_size", "ci", "cf"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        c_it = ((self.cf - self.ci) * ((epoch + 1) / self.epoch)) + self.ci
+        pop_new = []
+        for i in range(0, self.pop_size):
+            agent = deepcopy(self.pop[i])
+            idx_k = np.random.randint(0, self.pop_size)
+            w = np.random.normal()
+            while np.abs(w - 1.0) < 0.01:
+                w = np.random.normal()
+            c1_it = np.abs(w) ** (c_it * w)
+            c2_it = np.abs(1 - w) ** (c_it / (1 - w))
+
+            #################### HPSO
+            v_new = c1_it * np.random.uniform(0, 1, self.problem.n_dims) * (self.pop[i][self.ID_LOP] - self.pop[i][self.ID_POS]) + \
+                    c2_it * np.random.uniform(0, 1, self.problem.n_dims) * \
+                    (self.g_best[self.ID_POS] + self.pop[idx_k][self.ID_LOP] - 2 * self.pop[i][self.ID_POS])
+
+            np.where(v_new == 0, np.sign(0.5 - np.random.uniform()) * np.random.uniform() * self.v_max, v_new)
+            v_new = np.sign(v_new) * np.minimum(np.abs(v_new), self.v_max)
+            #########################
+
+            v_new = np.minimum(np.maximum(v_new, -self.v_max), self.v_max)
+            pos_new = self.pop[i][self.ID_POS] + v_new
+            agent[self.ID_VEC] = v_new
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            agent[self.ID_POS] = pos_new
+            pop_new.append(agent)
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        # Update fitness for all solutions
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+
+        # Update current position, current velocity and compare with past position, past fitness (local best)
+        for idx in range(0, self.pop_size):
+            if self.compare_agent(pop_new[idx], self.pop[idx]):
+                self.pop[idx] = deepcopy(pop_new[idx])
+                if self.compare_agent(pop_new[idx], [None, self.pop[idx][self.ID_LOF]]):
+                    self.pop[idx][self.ID_LOP] = deepcopy(pop_new[idx][self.ID_POS])
+                    self.pop[idx][self.ID_LOF] = deepcopy(pop_new[idx][self.ID_TAR])
+
+
+class C_PSO(OriginalPSO):
+    """
+    The original version of: Chaos Particle Swarm Optimization (C-PSO)
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + c1 (float): [1.0, 3.0] local coefficient, default = 2.05
+        + c2 (float): [1.0, 3.0] global coefficient, default = 2.05
+        + w_min (float): [0.1, 0.4], Weight min of bird, default = 0.4
+        + w_max (float): [0.4, 2.0], Weight max of bird, default = 0.9
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.PSO import C_PSO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> c1 = 2.05
+    >>> c2 = 2.05
+    >>> w_min = 0.4
+    >>> w_max = 0.9
+    >>> model = C_PSO(epoch, pop_size, c1, c2, w_min, w_max)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Liu, B., Wang, L., Jin, Y.H., Tang, F. and Huang, D.X., 2005. Improved particle swarm optimization
+    combined with chaos. Chaos, Solitons & Fractals, 25(5), pp.1261-1271.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, c1=2.05, c2=2.05, w_min=0.4, w_max=0.9, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            c1 (float): [0-2] local coefficient, default = 2.05
+            c2 (float): [0-2] global coefficient, default = 2.05
+            w_min (float): Weight min of bird, default = 0.4
+            w_max (float): Weight max of bird, default = 0.9
+        """
+        super().__init__(epoch, pop_size, c1, c2, w_min, w_max, **kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.c1 = self.validator.check_float("c1", c1, (0, 5.0))
+        self.c2 = self.validator.check_float("c2", c2, (0, 5.0))
+        self.w_min = self.validator.check_float("w_min", w_min, (0, 0.5))
+        self.w_max = self.validator.check_float("w_max", w_max, [0.5, 2.0])
+        self.set_parameters(["epoch", "pop_size", "c1", "c2", "w_min", "w_max"])
+        self.sort_flag = False
+    
+    def initialize_variables(self):
+        self.v_max = 0.5 * (self.problem.ub - self.problem.lb)
+        self.v_min = -self.v_max
+        self.N_CLS = int(self.pop_size / 5)  # Number of chaotic local searches
+        self.dyn_lb = deepcopy(self.problem.lb)
+        self.dyn_ub = deepcopy(self.problem.ub)
+
+    def get_weights__(self, fit, fit_avg, fit_min):
+        temp1 = self.w_min + (self.w_max - self.w_min) * (fit - fit_min) / (fit_avg - fit_min)
+        if self.problem.minmax == "min":
+            output = temp1 if fit <= fit_avg else self.w_max
+        else:
+            output = self.w_max if fit <= fit_avg else temp1
+        return output
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        list_fits = [item[self.ID_TAR][self.ID_FIT] for item in self.pop]
+        fit_avg = np.mean(list_fits)
+        fit_min = np.min(list_fits)
+        pop_new = []
+        for i in range(self.pop_size):
+            agent = deepcopy(self.pop[i])
+            w = self.get_weights__(self.pop[i][self.ID_TAR][self.ID_FIT], fit_avg, fit_min)
+            v_new = w * self.pop[i][self.ID_VEC] + self.c1 * np.random.rand() * (self.pop[i][self.ID_LOP] - self.pop[i][self.ID_POS]) + \
+                    self.c2 * np.random.rand() * (self.g_best[self.ID_POS] - self.pop[i][self.ID_POS])
+            v_new = np.clip(v_new, self.v_min, self.v_max)
+            x_new = self.pop[i][self.ID_POS].astype(float) + v_new
+            agent[self.ID_VEC] = v_new
+            pos_new = self.amend_position(x_new, self.dyn_lb, self.dyn_ub)
+            agent[self.ID_POS] = pos_new
+            pop_new.append(agent)
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+
+        # Update current position, current velocity and compare with past position, past fitness (local best)
+        for idx in range(0, self.pop_size):
+            if self.compare_agent(pop_new[idx], self.pop[idx]):
+                self.pop[idx] = deepcopy(pop_new[idx])
+                if self.compare_agent(pop_new[idx], [None, self.pop[idx][self.ID_LOF]]):
+                    self.pop[idx][self.ID_LOP] = deepcopy(pop_new[idx][self.ID_POS])
+                    self.pop[idx][self.ID_LOF] = deepcopy(pop_new[idx][self.ID_TAR])
+
+        ## Implement chaostic local search for the best solution
+        g_best = self.g_best
+        cx_best_0 = (self.g_best[self.ID_POS] - self.problem.lb) / (self.problem.ub - self.problem.lb)  # Eq. 7
+        cx_best_1 = 4 * cx_best_0 * (1 - cx_best_0)  # Eq. 6
+        x_best = self.problem.lb + cx_best_1 * (self.problem.ub - self.problem.lb)  # Eq. 8
+        x_best = self.amend_position(x_best, self.problem.lb, self.problem.ub)
+        target_best = self.get_target_wrapper(x_best)
+        if self.compare_agent([x_best, target_best], self.g_best):
+            g_best = [x_best, target_best]
+
+        r = np.random.rand()
+        bound_min = np.stack([self.dyn_lb, g_best[self.ID_POS] - r * (self.dyn_ub - self.dyn_lb)])
+        self.dyn_lb = np.max(bound_min, axis=0)
+        bound_max = np.stack([self.dyn_ub, g_best[self.ID_POS] + r * (self.dyn_ub - self.dyn_lb)])
+        self.dyn_ub = np.min(bound_max, axis=0)
+
+        pop_new_child = self.create_population(self.pop_size - self.N_CLS)
+        self.pop = self.get_sorted_strim_population(self.pop + pop_new_child, self.pop_size)
+
+
+class CL_PSO(Optimizer):
+    """
+    The original version of: Comprehensive Learning Particle Swarm Optimization (CL-PSO)
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + c_local (float): [1.0, 3.0], local coefficient, default = 1.2
+        + w_min (float): [0.1, 0.5], Weight min of bird, default = 0.4
+        + w_max (float): [0.7, 2.0], Weight max of bird, default = 0.9
+        + max_flag (int): [5, 20], Number of times, default = 7
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.PSO import CL_PSO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> c_local = 1.2
+    >>> w_min = 0.4
+    >>> w_max = 0.9
+    >>> max_flag = 7
+    >>> model = CL_PSO(epoch, pop_size, c_local, w_min, w_max, max_flag)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Liang, J.J., Qin, A.K., Suganthan, P.N. and Baskar, S., 2006. Comprehensive learning particle swarm optimizer
+    for global optimization of multimodal functions. IEEE transactions on evolutionary computation, 10(3), pp.281-295.
+    """
+
+    ID_VEC = 2
+    ID_LOP = 3
+    ID_LOF = 4
+
+    def __init__(self, epoch=10000, pop_size=100, c_local=1.2, w_min=0.4, w_max=0.9, max_flag=7, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            c_local (float): local coefficient, default = 1.2
+            w_min (float): Weight min of bird, default = 0.4
+            w_max (float): Weight max of bird, default = 0.9
+            max_flag (int): Number of times, default = 7
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.c_local = self.validator.check_float("c_local", c_local, (0, 5.0))
+        self.w_min = self.validator.check_float("w_min", w_min, (0, 0.5))
+        self.w_max = self.validator.check_float("w_max", w_max, [0.5, 2.0])
+        self.max_flag = self.validator.check_int("max_flag", max_flag, [2, 100])
+        self.set_parameters(["epoch", "pop_size", "c_local", "w_min", "w_max", "max_flag"])
+        self.sort_flag = False
+    
+    def initialize_variables(self):
+        self.v_max = 0.5 * (self.problem.ub - self.problem.lb)
+        self.v_min = -self.v_max
+        self.flags = np.zeros(self.pop_size)
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        """
+        Overriding method in Optimizer class
+
+        Returns:
+            list: wrapper of solution with format [position, target, velocity, local_pos, local_fit]
+        """
+        if pos is None:
+            pos = self.generate_position(lb, ub)
+        position = self.amend_position(pos, lb, ub)
+        target = self.get_target_wrapper(position)
+        velocity = np.random.uniform(self.v_min, self.v_max)
+        local_pos = deepcopy(position)
+        local_fit = deepcopy(target)
+        return [position, target, velocity, local_pos, local_fit]
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        wk = self.w_max * (epoch / self.epoch) * (self.w_max - self.w_min)
+        pop_new = []
+        for i in range(0, self.pop_size):
+            agent = deepcopy(self.pop[i])
+            if self.flags[i] >= self.max_flag:
+                self.flags[i] = 0
+                agent = self.create_solution(self.problem.lb, self.problem.ub)
+
+            pci = 0.05 + 0.45 * (np.exp(10 * (i + 1) / self.pop_size) - 1) / (np.exp(10) - 1)
+
+            vec_new = deepcopy(self.pop[i][self.ID_VEC])
+            for j in range(0, self.problem.n_dims):
+                if np.random.rand() > pci:
+                    vj = wk * self.pop[i][self.ID_VEC][j] + self.c_local * np.random.rand() * \
+                         (self.pop[i][self.ID_LOP][j] - self.pop[i][self.ID_POS][j])
+                else:
+                    id1, id2 = np.random.choice(list(set(range(0, self.pop_size)) - {i}), 2, replace=False)
+                    if self.compare_agent(self.pop[id1], self.pop[id2]):
+                        vj = wk * self.pop[i][self.ID_VEC][j] + self.c_local * np.random.rand() * \
+                             (self.pop[id1][self.ID_LOP][j] - self.pop[i][self.ID_POS][j])
+                    else:
+                        vj = wk * self.pop[i][self.ID_VEC][j] + self.c_local * np.random.rand() * \
+                             (self.pop[id2][self.ID_LOP][j] - self.pop[i][self.ID_POS][j])
+                vec_new[j] = vj
+            vec_new = np.clip(vec_new, self.v_min, self.v_max)
+            pos_new = self.pop[i][self.ID_POS] + vec_new
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            agent[self.ID_VEC] = vec_new
+            agent[self.ID_POS] = pos_new
+            pop_new.append(agent)
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+
+        # Update current position, current velocity and compare with past position, past fitness (local best)
+        for idx in range(0, self.pop_size):
+            if self.compare_agent(pop_new[idx], self.pop[idx]):
+                self.pop[idx] = deepcopy(pop_new[idx])
+                if self.compare_agent(pop_new[idx], [None, self.pop[idx][self.ID_LOF]]):
+                    self.pop[idx][self.ID_LOP] = deepcopy(pop_new[idx][self.ID_POS])
+                    self.pop[idx][self.ID_LOF] = deepcopy(pop_new[idx][self.ID_TAR])
+                    self.flags[idx] = 0
+                else:
+                    self.flags[idx] += 1
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/SCSO.py` & `mealpy-2.5.3a1/mealpy/swarm_based/ARO.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,97 +1,92 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 17:36, 21/05/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalSCSO(Optimizer):
-    """
-    The original version of: Sand Cat Swarm Optimization (SCSO)
-
-    Links:
-        1. https://link.springer.com/article/10.1007/s00366-022-01604-x
-        2. https://www.mathworks.com/matlabcentral/fileexchange/110185-sand-cat-swarm-optimization
-
-    Notes:
-        1. The matlab code will not work since the R value always in the range (-1, 1).
-        2. The authors make a mistake in matlab code. It should be 0 <= R <= 1 in the If condition
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.SCSO import OriginalSCSO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalSCSO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Seyyedabbasi, A., & Kiani, F. (2022). Sand Cat swarm optimization: a nature-inspired algorithm to
-    solve global optimization problems. Engineering with Computers, 1-25.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.P = np.arange(1, 361)
-        self.sort_flag = False
-
-    def initialize_variables(self):
-        self.S = 2      # maximum Sensitivity range
-
-    def get_index_roulette_wheel_selection__(self, p):
-        p = p / np.sum(p)
-        c = np.cumsum(p)
-        return np.argwhere(np.random.rand() < c)[0][0]
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        t = self.epoch + 1
-        guides_r = self.S - (self.S * t / self.epoch)
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            r = np.random.rand() * guides_r
-            R = (2*guides_r)*np.random.rand() - guides_r        # controls to transition phases
-            pos_new = self.pop[idx][self.ID_POS].copy()
-            for jdx in range(0, self.problem.n_dims):
-                teta = self.get_index_roulette_wheel_selection__(self.P)
-                if 0 <= R <= 1:
-                    rand_pos = np.abs(np.random.rand() * self.g_best[self.ID_POS][jdx] - self.pop[idx][self.ID_POS][jdx])
-                    pos_new[jdx] = self.g_best[self.ID_POS][jdx] - r * rand_pos * np.cos(teta)
-                else:
-                    cp = int(np.random.rand() * self.pop_size)
-                    pos_new[jdx] = r * (self.pop[cp][self.ID_POS][jdx] - np.random.rand() * self.pop[idx][self.ID_POS][jdx])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        self.pop = self.update_target_wrapper_population(pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 22:46, 26/10/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalARO(Optimizer):
+    """
+    The original version of: Artificial Rabbits Optimization (ARO)
+
+    Links:
+        1. https://doi.org/10.1016/j.engappai.2022.105082
+        2. https://www.mathworks.com/matlabcentral/fileexchange/110250-artificial-rabbits-optimization-aro
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.ARO import OriginalARO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalARO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Wang, L., Cao, Q., Zhang, Z., Mirjalili, S., & Zhao, W. (2022). Artificial rabbits optimization: A new bio-inspired
+    meta-heuristic algorithm for solving engineering optimization problems. Engineering Applications of Artificial Intelligence, 114, 105082.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        theta = 2 * (1 - (epoch+1)/self.epoch)
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            L = (np.exp(1) - np.exp((epoch / self.epoch)**2)) * (np.sin(2*np.pi*np.random.rand()))
+            temp = np.zeros(self.problem.n_dims)
+            rd_index = np.random.choice(np.arange(0, self.problem.n_dims), int(np.ceil(np.random.rand()*self.problem.n_dims)), replace=False)
+            temp[rd_index] = 1
+            R = L * temp        # Eq 2
+            A = 2 * np.log(1.0 / np.random.rand()) * theta      # Eq. 15
+            if A > 1:
+                rand_idx = np.random.randint(0, self.pop_size)
+                pos_new = self.pop[rand_idx][self.ID_POS] + R * (self.pop[idx][self.ID_POS] - self.pop[rand_idx][self.ID_POS]) + \
+                    np.round(0.5 * (0.05 + np.random.rand())) * np.random.normal(0, 1)      # Eq. 1
+            else:
+                gr = np.zeros(self.problem.n_dims)
+                rd_index = np.random.choice(np.arange(0, self.problem.n_dims), int(np.ceil(np.random.rand() * self.problem.n_dims)), replace=False)
+                gr[rd_index] = 1        # Eq. 12
+                H = np.random.normal(0, 1) * (epoch / self.epoch)       # Eq. 8
+                b = self.pop[idx][self.ID_POS] + H * gr * self.pop[idx][self.ID_POS]        # Eq. 13
+                pos_new = self.pop[idx][self.ID_POS] + R * (np.random.rand() * b - self.pop[idx][self.ID_POS])      # Eq. 11
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/SHO.py` & `mealpy-2.5.3a1/mealpy/physics_based/WDO.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,110 +1,115 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 10:55, 02/12/2019 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalSHO(Optimizer):
-    """
-    The original version of: Spotted Hyena Optimizer (SHO)
-
-    Links:
-        1. https://doi.org/10.1016/j.advengsoft.2017.05.014
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + h_factor (float): default = 5, coefficient linearly decreased from 5 to 0
-        + N_tried (int): default = 10
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.SHO import OriginalSHO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> h_factor = 5.0
-    >>> N_tried = 10
-    >>> model = OriginalSHO(epoch, pop_size, h_factor, N_tried)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Dhiman, G. and Kumar, V., 2017. Spotted hyena optimizer: a novel bio-inspired based metaheuristic
-    technique for engineering applications. Advances in Engineering Software, 114, pp.48-70.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, h_factor=5., N_tried=10, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            h_factor (float): default = 5, coefficient linearly decreased from 5.0 to 0
-            N_tried (int): default = 10,
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.h_factor = self.validator.check_float("h_factor", h_factor, (0.5, 10.0))
-        self.N_tried = self.validator.check_int("N_tried", N_tried, (1, float("inf")))
-        self.set_parameters(["epoch", "pop_size", "h_factor", "N_tried"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            h = self.h_factor - (epoch + 1.0) * (self.h_factor / self.epoch)
-            rd1 = np.random.uniform(0, 1, self.problem.n_dims)
-            rd2 = np.random.uniform(0, 1, self.problem.n_dims)
-            B = 2 * rd1
-            E = 2 * h * rd2 - h
-
-            if np.random.rand() < 0.5:
-                D_h = np.abs(np.dot(B, self.g_best[self.ID_POS]) - self.pop[idx][self.ID_POS])
-                pos_new = self.g_best[self.ID_POS] - np.dot(E, D_h)
-            else:
-                N = 1
-                for i in range(0, self.N_tried):
-                    pos_temp = self.g_best[self.ID_POS] + np.random.normal(0, 1, self.problem.n_dims) * \
-                              np.random.uniform(self.problem.lb, self.problem.ub)
-                    pos_temp = self.amend_position(pos_temp, self.problem.lb, self.problem.ub)
-                    target = self.get_target_wrapper(pos_temp)
-                    if self.compare_agent([pos_temp, target], self.g_best):
-                        N += 1
-                        break
-                    N += 1
-                circle_list = []
-                idx_list = np.random.choice(range(0, self.pop_size), N, replace=False)
-                for j in range(0, N):
-                    D_h = np.abs(np.dot(B, self.g_best[self.ID_POS]) - self.pop[idx_list[j]][self.ID_POS])
-                    p_k = self.g_best[self.ID_POS] - np.dot(E, D_h)
-                    circle_list.append(p_k)
-                pos_new = np.mean(np.array(circle_list), axis=0)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 21:18, 17/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalWDO(Optimizer):
+    """
+    The original version of: Wind Driven Optimization (WDO)
+
+    Links:
+        1. https://ieeexplore.ieee.org/abstract/document/6407788
+
+    Notes
+    ~~~~~
+    + pop is the set of "air parcel" - "position"
+    + air parcel: is the set of gas atoms. Each atom represents a dimension in position and has its own velocity
+    + pressure represented by fitness value
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + RT (int): [2, 3, 4], RT coefficient, default = 3
+        + g_c (float): [0.1, 0.5], gravitational constant, default = 0.2
+        + alp (float): [0.3, 0.8], constants in the update equation, default=0.4
+        + c_e (float): [0.1, 0.9], coriolis effect, default=0.4
+        + max_v (float): [0.1, 0.9], maximum allowed speed, default=0.3
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.physics_based.WDO import OriginalWDO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>>     "log_to": None,
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> RT = 3
+    >>> g_c = 0.2
+    >>> alp = 0.4
+    >>> c_e = 0.4
+    >>> max_v = 0.3
+    >>> model = OriginalWDO(epoch, pop_size, RT, g_c, alp, c_e, max_v)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Bayraktar, Z., Komurcu, M., Bossard, J.A. and Werner, D.H., 2013. The wind driven optimization
+    technique and its application in electromagnetics. IEEE transactions on antennas and
+    propagation, 61(5), pp.2745-2757.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, RT=3, g_c=0.2, alp=0.4, c_e=0.4, max_v=0.3, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            RT (int): RT coefficient, default = 3
+            g_c (float): gravitational constant, default = 0.2
+            alp (float): constants in the update equation, default=0.4
+            c_e (float): coriolis effect, default=0.4
+            max_v (float): maximum allowed speed, default=0.3
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.RT = self.validator.check_int("RT", RT, [1, 4])
+        self.g_c = self.validator.check_float("g_c", g_c, (0, 1.0))
+        self.alp = self.validator.check_float("alp", alp, (0, 1.0))
+        self.c_e = self.validator.check_float("c_e", c_e, (0, 1.0))
+        self.max_v = self.validator.check_float("max_v", max_v, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "RT", "g_c", "alp", "c_e", "max_v"])
+        self.sort_flag = False
+
+    def initialize_variables(self):
+        self.dyn_list_velocity = self.max_v * np.random.uniform(self.problem.lb, self.problem.ub, (self.pop_size, self.problem.n_dims))
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            rand_dim = np.random.randint(0, self.problem.n_dims)
+            temp = self.dyn_list_velocity[idx][rand_dim] * np.ones(self.problem.n_dims)
+            vel = (1 - self.alp) * self.dyn_list_velocity[idx] - self.g_c * self.pop[idx][self.ID_POS] + \
+                  (1 - 1.0 / (idx + 1)) * self.RT * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) + self.c_e * temp / (idx + 1)
+            vel = np.clip(vel, -self.max_v, self.max_v)
+
+            # Update air parcel positions, check the bound and calculate pressure (fitness)
+            self.dyn_list_velocity[idx] = vel
+            pos = self.pop[idx][self.ID_POS] + vel
+            pos_new = self.amend_position(pos, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(pop_new, self.pop)
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/SLO.py` & `mealpy-2.5.3a1/mealpy/swarm_based/SSpiderO.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,333 +1,295 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 15:05, 03/06/2021 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from math import gamma
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalSLO(Optimizer):
-    """
-    The original version of: Sea Lion Optimization Algorithm (SLO)
-
-    Links:
-        1. https://www.researchgate.net/publication/333516932_Sea_Lion_Optimization_Algorithm
-        2. https://doi.org/10.14569/IJACSA.2019.0100548
-
-    Notes:
-        + There are some unclear equations and parameters in the original paper
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.SLO import OriginalSLO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalSLO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Masadeh, R., Mahafzah, B.A. and Sharieh, A., 2019. Sea lion optimization algorithm. Sea, 10(5), p.388.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def amend_position(self, position=None, lb=None, ub=None):
-        """
-        Args:
-            position: vector position (location) of the solution.
-            lb: list of lower bound values
-            ub: list of upper bound values
-
-        Returns:
-            Amended position (make the position is in bound)
-        """
-        condition = np.logical_and(lb <= position, position <= ub)
-        pos_rand = np.random.uniform(lb, ub)
-        return np.where(condition, position, pos_rand)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        c = 2 - 2 * epoch / self.epoch
-        t0 = np.random.rand()
-        v1 = np.sin(2 * np.pi * t0)
-        v2 = np.sin(2 * np.pi * (1 - t0))
-        SP_leader = np.abs(v1 * (1 + v2) / v2)  # In the paper this is not clear how to calculate
-
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            if SP_leader < 0.25:
-                if c < 1:
-                    pos_new = self.g_best[self.ID_POS] - c * np.abs(2 * np.random.rand() *
-                                                                    self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-                else:
-                    ri = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))  # random index
-                    pos_new = self.pop[ri][self.ID_POS] - c * np.abs(2 * np.random.rand() *
-                                                                     self.pop[ri][self.ID_POS] - self.pop[idx][self.ID_POS])
-            else:
-                pos_new = np.abs(self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) * \
-                          np.cos(2 * np.pi * np.random.uniform(-1, 1)) + self.g_best[self.ID_POS]
-            # In the paper doesn't check also doesn't update old solution at this point
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-
-class ModifiedSLO(Optimizer):
-    """
-    The original version of: Modified Sea Lion Optimization (M-SLO)
-
-    Notes
-    ~~~~~
-    + Local best idea in PSO is inspired 
-    + Levy-flight technique is used 
-    + Shrink encircling idea is used 
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.SLO import ModifiedSLO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = ModifiedSLO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    ID_LOC_POS = 2
-    ID_LOC_FIT = 3
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        """
-        Overriding method in Optimizer class
-
-        Returns:
-            list: wrapper of solution with format [position, [target, [obj1, obj2, ...]], local_pos, local_fit]
-        """
-        ## Increase exploration at the first initial population using opposition-based learning.
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        position = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(position)
-        local_pos = lb + ub - position
-        local_pos = self.amend_position(local_pos, lb, ub)
-        local_target = self.get_target_wrapper(local_pos)
-        if self.compare_agent([None, target], [None, local_target]):
-            return [local_pos, local_target, position, target]
-        else:
-            return [position, target, local_pos, local_target]
-
-    def shrink_encircling_levy__(self, current_pos, epoch, dist, c, beta=1):
-        up = gamma(1 + beta) * np.sin(np.pi * beta / 2)
-        down = (gamma((1 + beta) / 2) * beta * np.power(2, (beta - 1) / 2))
-        xich_ma_1 = np.power(up / down, 1 / beta)
-        xich_ma_2 = 1
-        a = np.random.normal(0, xich_ma_1, 1)
-        b = np.random.normal(0, xich_ma_2, 1)
-        LB = 0.01 * a / (np.power(np.abs(b), 1 / beta)) * dist * c
-        D = np.random.uniform(self.problem.lb, self.problem.ub)
-        levy = LB * D
-        return (current_pos - np.sqrt(epoch + 1) * np.sign(np.random.random(1) - 0.5)) * levy
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-
-        c = 2 - 2 * epoch / self.epoch
-        if c > 1:
-            pa = 0.3  # At the beginning of the process, the probability for shrinking encircling is small
-        else:
-            pa = 0.7  # But at the end of the process, it become larger. Because sea lion are shrinking encircling prey
-        SP_leader = np.random.uniform(0, 1)
-
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            agent = deepcopy(self.pop[idx])
-            if SP_leader >= 0.6:
-                pos_new = np.cos(2 * np.pi * np.random.normal(0, 1)) * \
-                          np.abs(self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) + self.g_best[self.ID_POS]
-            else:
-                if np.random.uniform() < pa:
-                    dist1 = np.random.uniform() * np.abs(2 * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-                    pos_new = self.shrink_encircling_levy__(self.pop[idx][self.ID_POS], epoch, dist1, c)
-                else:
-                    rand_SL = self.pop[np.random.randint(0, self.pop_size)][self.ID_LOC_POS]
-                    rand_SL = 2 * self.g_best[self.ID_POS] - rand_SL
-                    pos_new = rand_SL - c * np.abs(np.random.uniform() * rand_SL - self.pop[idx][self.ID_POS])
-            agent[self.ID_POS] = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append(agent)
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(agent[self.ID_POS])
-        pop_new = self.update_target_wrapper_population(pop_new)
-
-        for idx in range(0, self.pop_size):
-            if self.compare_agent(pop_new[idx], self.pop[idx]):
-                self.pop[idx] = deepcopy(pop_new[idx])
-                if self.compare_agent(pop_new[idx], [None, self.pop[idx][self.ID_LOC_FIT]]):
-                    self.pop[idx][self.ID_LOC_POS] = deepcopy(pop_new[idx][self.ID_POS])
-                    self.pop[idx][self.ID_LOC_FIT] = deepcopy(pop_new[idx][self.ID_TAR])
-
-
-class ImprovedSLO(ModifiedSLO):
-    """
-    The original version: Improved Sea Lion Optimization (ImprovedSLO)
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + c1 (float): Local coefficient same as PSO, default = 1.2
-        + c2 (float): Global coefficient same as PSO, default = 1.2
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.SLO import ImprovedSLO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> c1 = 1.2
-    >>> c2 = 1.5
-    >>> model = ImprovedSLO(epoch, pop_size, c1, c2)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, c1=1.2, c2=1.2, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            c1 (float): Local coefficient same as PSO, default = 1.2
-            c2 (float): Global coefficient same as PSO, default = 1.2
-        """
-        super().__init__(epoch, pop_size, **kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.c1 = self.validator.check_float("c1", c1, (0, 5.0))
-        self.c2 = self.validator.check_float("c2", c2, (0, 5.0))
-        self.set_parameters(["epoch", "pop_size", "c1", "c2"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        c = 2 - 2 * epoch / self.epoch
-        t0 = np.random.rand()
-        v1 = np.sin(2 * np.pi * t0)
-        v2 = np.sin(2 * np.pi * (1 - t0))
-        SP_leader = np.abs(v1 * (1 + v2) / v2)
-
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            agent = deepcopy(self.pop[idx])
-            if SP_leader < 0.5:
-                if c < 1:  # Exploitation improved by historical movement + global best affect
-                    # pos_new = g_best[self.ID_POS] - c * np.abs(2 * rand() * g_best[self.ID_POS] - pop[i][self.ID_POS])
-                    dif1 = np.abs(2 * np.random.rand() * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-                    dif2 = np.abs(2 * np.random.rand() * self.pop[idx][self.ID_LOC_POS] - self.pop[idx][self.ID_POS])
-                    pos_new = self.c1 * np.random.rand() * (self.pop[idx][self.ID_POS] - dif1) + \
-                              self.c2 * np.random.rand() * (self.pop[idx][self.ID_POS] - dif2)
-                else:  # Exploration improved by opposition-based learning
-                    # Create a new solution by equation below
-                    # Then create an opposition solution of above solution
-                    # Compare both of them and keep the good one (Searching at both direction)
-                    pos_new = self.g_best[self.ID_POS] + c * np.random.normal(0, 1, self.problem.n_dims) * \
-                              (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-                    pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                    target_new = self.get_target_wrapper(pos_new)
-                    pos_new_oppo = self.problem.lb + self.problem.ub - self.g_best[self.ID_POS] + \
-                                   np.random.rand() * (self.g_best[self.ID_POS] - pos_new)
-                    target_new_oppo = self.get_target_wrapper(self.amend_position(pos_new_oppo, self.problem.lb, self.problem.ub))
-                    if self.compare_agent([pos_new_oppo, target_new_oppo], [pos_new, target_new]):
-                        pos_new = pos_new_oppo
-            else:  # Exploitation
-                pos_new = self.g_best[self.ID_POS] + np.cos(2 * np.pi * np.random.uniform(-1, 1)) * \
-                          np.abs(self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-            agent[self.ID_POS] = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append(agent)
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(agent[self.ID_POS])
-        pop_new = self.update_target_wrapper_population(pop_new)
-
-        for idx in range(0, self.pop_size):
-            if self.compare_agent(pop_new[idx], self.pop[idx]):
-                self.pop[idx] = deepcopy(pop_new[idx])
-                if self.compare_agent(pop_new[idx], [None, self.pop[idx][self.ID_LOC_FIT]]):
-                    self.pop[idx][self.ID_LOC_POS] = deepcopy(pop_new[idx][self.ID_POS])
-                    self.pop[idx][self.ID_LOC_FIT] = deepcopy(pop_new[idx][self.ID_TAR])
+#!/usr/bin/env python
+# Created by "Thieu" at 12:00, 17/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalSSpiderO(Optimizer):
+    """
+    The original version of: Social Spider Optimization (SSpiderO)
+
+    Links:
+        1. https://www.hindawi.com/journals/mpe/2018/6843923/
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + fp_min (float): Female Percent min, default = 0.65
+        + fp_max (float): Female Percent max, default = 0.9
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.SSpiderO import OriginalSSpiderO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> fp_min = 0.65
+    >>> fp_max = 0.9
+    >>> model = OriginalSSpiderO(epoch, pop_size, fp_min, fp_max)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Luque-Chang, A., Cuevas, E., Fausto, F., Zaldivar, D. and PÃ©rez, M., 2018. Social spider
+    optimization algorithm: modifications, applications, and perspectives. Mathematical
+    Problems in Engineering, 2018.
+    """
+
+    ID_POS = 0
+    ID_TAR = 1
+    ID_WEI = 2
+
+    def __init__(self, epoch=10000, pop_size=100, fp_min=0.65, fp_max=0.9, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            fp_min (float): Female Percent min, default = 0.65
+            fp_max (float): Female Percent max, default = 0.9
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        fp_min = self.validator.check_float("fp_min", fp_min, (0., 1.0))
+        fp_max = self.validator.check_float("fp_max", fp_max, (0., 1.0))
+        self.fp_min, self.fp_max = min((fp_min, fp_max)), max((fp_min, fp_max))
+        self.set_parameters(["epoch", "pop_size", "fp_min", "fp_max"])
+
+    def initialization(self):
+        fp_temp = self.fp_min + (self.fp_max - self.fp_min) * np.random.uniform()  # Female Aleatory Percent
+        self.n_f = int(self.pop_size * fp_temp)  # number of female
+        self.n_m = self.pop_size - self.n_f  # number of male
+        # Probabilities of attraction or repulsion Proper tuning for better results
+        self.p_m = (self.epoch + 1 - np.array(range(1, self.epoch + 1))) / (self.epoch + 1)
+
+        idx_males = np.random.choice(range(0, self.pop_size), self.n_m, replace=False)
+        idx_females = set(range(0, self.pop_size)) - set(idx_males)
+        if self.pop is None:
+            self.pop = self.create_population(self.pop_size)
+        self.pop_males = [self.pop[idx] for idx in idx_males]
+        self.pop_females = [self.pop[idx] for idx in idx_females]
+        self.pop = self.recalculate_weights__(self.pop)
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        """
+        Overriding method in Optimizer class
+
+        Returns:
+            list: wrapper of solution with format [position, target, weight]
+        """
+        if pos is None:
+            pos = self.generate_position(lb, ub)
+        position = self.amend_position(pos, lb, ub)
+        target = self.get_target_wrapper(position)
+        weight = 0.0
+        return [position, target, weight]
+
+    def amend_position(self, position=None, lb=None, ub=None):
+        """
+        Depend on what kind of problem are we trying to solve, there will be an different amend_position
+        function to rebound the position of agent into the valid range.
+
+        Args:
+            position: vector position (location) of the solution.
+            lb: list of lower bound values
+            ub: list of upper bound values
+
+        Returns:
+            Amended position (make the position is in bound)
+        """
+        return np.where(np.logical_and(lb <= position, position <= ub), position, np.random.uniform(lb, ub))
+
+    def move_females__(self, epoch=None):
+        scale_distance = np.sum(self.problem.ub - self.problem.lb)
+        pop = self.pop_females + self.pop_males
+        # Start looking for any stronger vibration
+        for i in range(0, self.n_f):  # Move the females
+            ## Find the position s
+            id_min = None
+            dist_min = 2 ** 16
+            for j in range(0, self.pop_size):
+                if self.pop_females[i][self.ID_WEI] < pop[j][self.ID_WEI]:
+                    dt = np.linalg.norm(pop[j][self.ID_POS] - self.pop_females[i][self.ID_POS]) / scale_distance
+                    if dt < dist_min and dt != 0:
+                        dist_min = dt
+                        id_min = j
+            x_s = np.zeros(self.problem.n_dims)
+            vibs = 0
+            if id_min is not None:
+                vibs = 2 * (pop[id_min][self.ID_WEI] * np.exp(-(np.random.uniform() * dist_min ** 2)))  # Vib for the shortest
+                x_s = pop[id_min][self.ID_POS]
+
+            ## Find the position b
+            dtb = np.linalg.norm(self.g_best[self.ID_POS] - self.pop_females[i][self.ID_POS]) / scale_distance
+            vibb = 2 * (self.g_best[self.ID_WEI] * np.exp(-(np.random.uniform() * dtb ** 2)))
+
+            ## Do attraction or repulsion
+            beta = np.random.uniform(0, 1, self.problem.n_dims)
+            gamma = np.random.uniform(0, 1, self.problem.n_dims)
+            random = 2 * self.p_m[epoch] * (np.random.uniform(0, 1, self.problem.n_dims) - 0.5)
+            if np.random.uniform() >= self.p_m[epoch]:  # Do an attraction
+                pos_new = self.pop_females[i][self.ID_POS] + vibs * (x_s - self.pop_females[i][self.ID_POS]) * beta + \
+                          vibb * (self.g_best[self.ID_POS] - self.pop_females[i][self.ID_POS]) * gamma + random
+            else:  # Do a repulsion
+                pos_new = self.pop_females[i][self.ID_POS] - vibs * (x_s - self.pop_females[i][self.ID_POS]) * beta - \
+                          vibb * (self.g_best[self.ID_POS] - self.pop_females[i][self.ID_POS]) * gamma + random
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            self.pop_females[i][self.ID_POS] = pos_new
+            if self.mode not in self.AVAILABLE_MODES:
+                self.pop_females[i][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        self.pop_females = self.update_target_wrapper_population(self.pop_females)
+
+    def move_males__(self, epoch=None):
+        scale_distance = np.sum(self.problem.ub - self.problem.lb)
+        my_median = np.median([it[self.ID_WEI] for it in self.pop_males])
+        pop = self.pop_females + self.pop_males
+        all_pos = np.array([it[self.ID_POS] for it in pop])
+        all_wei = np.array([it[self.ID_WEI] for it in pop]).reshape((self.pop_size, 1))
+        total_wei = np.sum(all_wei)
+        if total_wei == 0:
+            mean = np.mean(all_pos, axis=0)
+        else:
+            mean = np.sum(all_wei * all_pos, axis=0) / total_wei
+        for i in range(0, self.n_m):
+            delta = 2 * np.random.uniform(0, 1, self.problem.n_dims) - 0.5
+            random = 2 * self.p_m[epoch] * (np.random.random(self.problem.n_dims) - 0.5)
+
+            if self.pop_males[i][self.ID_WEI] >= my_median:  # Spider above the median
+                # Start looking for a female with stronger vibration
+                id_min = None
+                dist_min = 99999999
+                for j in range(0, self.n_f):
+                    if self.pop_females[j][self.ID_WEI] > self.pop_males[i][self.ID_WEI]:
+                        dt = np.linalg.norm(self.pop_females[j][self.ID_POS] - self.pop_males[i][self.ID_POS]) / scale_distance
+                        if dt < dist_min and dt != 0:
+                            dist_min = dt
+                            id_min = j
+                x_s = np.zeros(self.problem.n_dims)
+                vibs = 0
+                if id_min != None:
+                    # Vib for the shortest
+                    vibs = 2 * (self.pop_females[id_min][self.ID_WEI] * np.exp(-(np.random.uniform() * dist_min ** 2)))
+                    x_s = self.pop_females[id_min][self.ID_POS]
+                pos_new = self.pop_males[i][self.ID_POS] + vibs * (x_s - self.pop_males[i][self.ID_POS]) * delta + random
+            else:
+                # Spider below median, go to weighted mean
+                pos_new = self.pop_males[i][self.ID_POS] + delta * (mean - self.pop_males[i][self.ID_POS]) + random
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            self.pop_males[i][self.ID_POS] = pos_new
+            if self.mode not in self.AVAILABLE_MODES:
+                self.pop_males[i][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        self.pop_males = self.update_target_wrapper_population(self.pop_males)
+
+    ### Crossover
+    def crossover__(self, mom=None, dad=None, id=0):
+        child1 = np.zeros(self.problem.n_dims)
+        child2 = np.zeros(self.problem.n_dims)
+        if id == 0:  # arithmetic recombination
+            r = np.random.uniform(0.5, 1)  # w1 = w2 when r =0.5
+            child1 = np.multiply(r, mom) + np.multiply((1 - r), dad)
+            child2 = np.multiply(r, dad) + np.multiply((1 - r), mom)
+
+        elif id == 1:
+            id1 = np.random.randint(1, int(self.problem.n_dims / 2))
+            id2 = int(id1 + self.problem.n_dims / 2)
+
+            child1[:id1] = mom[:id1]
+            child1[id1:id2] = dad[id1:id2]
+            child1[id2:] = mom[id2:]
+
+            child2[:id1] = dad[:id1]
+            child2[id1:id2] = mom[id1:id2]
+            child2[id2:] = dad[id2:]
+        elif id == 2:
+            temp = int(self.problem.n_dims / 2)
+            child1[:temp] = mom[:temp]
+            child1[temp:] = dad[temp:]
+            child2[:temp] = dad[:temp]
+            child2[temp:] = mom[temp:]
+
+        return child1, child2
+
+    def mating__(self):
+        # Check whether a spider is good or not (above median)
+        my_median = np.median([it[self.ID_WEI] for it in self.pop_males])
+        pop_males_new = [self.pop_males[i] for i in range(self.n_m) if self.pop_males[i][self.ID_WEI] > my_median]
+
+        # Calculate the radio
+        pop = self.pop_females + self.pop_males
+        all_pos = np.array([it[self.ID_POS] for it in pop])
+        rad = np.max(all_pos, axis=1) - np.min(all_pos, axis=1)
+        r = np.sum(rad) / (2 * self.problem.n_dims)
+
+        # Start looking if there's a good female near
+        list_child = []
+        couples = []
+        for i in range(0, len(pop_males_new)):
+            for j in range(0, self.n_f):
+                dist = np.linalg.norm(pop_males_new[i][self.ID_POS] - self.pop_females[j][self.ID_POS])
+                if dist < r:
+                    couples.append([pop_males_new[i], self.pop_females[j]])
+        if len(couples) >= 2:
+            n_child = len(couples)
+            for k in range(n_child):
+                child1, child2 = self.crossover__(couples[k][0][self.ID_POS], couples[k][1][self.ID_POS], 0)
+                pos1 = self.amend_position(child1, self.problem.lb, self.problem.ub)
+                pos2 = self.amend_position(child2, self.problem.lb, self.problem.ub)
+                target1 = self.get_target_wrapper(pos1)
+                target2 = self.get_target_wrapper(pos2)
+                list_child.append([pos1, target1, 0.0])
+                list_child.append([pos2, target2, 0.0])
+
+        list_child += self.create_population(self.pop_size - len(list_child))
+        return list_child
+
+    def survive__(self, pop=None, pop_child=None):
+        n_child = len(pop)
+        pop_child = self.get_sorted_strim_population(pop_child, n_child)
+        for i in range(0, n_child):
+            if self.compare_agent(pop_child[i], pop[i]):
+                pop[i] = deepcopy(pop_child[i])
+        return pop
+
+    def recalculate_weights__(self, pop=None):
+        fit_total, fit_best, fit_worst = self.get_special_fitness(pop)
+        for i in range(len(pop)):
+            if fit_best == fit_worst:
+                pop[i][self.ID_WEI] = np.random.uniform(0.2, 0.8)
+            else:
+                pop[i][self.ID_WEI] = 0.001 + (pop[i][self.ID_TAR][self.ID_FIT] - fit_worst) / (fit_best - fit_worst)
+        return pop
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        ### Movement of spiders
+        self.move_females__(epoch)
+        self.move_males__(epoch)
+
+        # Recalculate weights
+        pop = self.pop_females + self.pop_males
+        pop = self.recalculate_weights__(pop)
+
+        # Mating Operator
+        pop_child = self.mating__()
+        pop = self.survive__(pop, pop_child)
+        self.pop = self.recalculate_weights__(pop)
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/SRSR.py` & `mealpy-2.5.3a1/mealpy/swarm_based/SRSR.py`

 * *Ordering differences only*

 * *Files 19% similar despite different names*

```diff
@@ -1,252 +1,252 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 14:51, 17/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalSRSR(Optimizer):
-    """
-    The original version of: Swarm Robotics Search And Rescue (SRSR)
-
-    Links:
-        1. https://doi.org/10.1016/j.asoc.2017.02.028
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.SRSR import OriginalSRSR
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalSRSR(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Bakhshipour, M., Ghadi, M.J. and Namdari, F., 2017. Swarm robotics search & rescue: A novel
-    artificial intelligence-inspired optimization approach. Applied Soft Computing, 57, pp.708-726.
-    """
-
-    ID_POS = 0
-    ID_TAR = 1
-    ID_MU = 2
-    ID_SIGMA = 3
-    ID_POS_NEW = 4
-    ID_FIT_NEW = 5
-    ID_FIT_MOVE = 6
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = True
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        """
-        Overriding method in Optimizer class
-
-        Returns:
-            list: wrapper of solution with format [position, target, mu, sigma, x_new, target_new, target_move]
-        """
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        position = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(position)
-        mu = 0
-        sigma = 0
-        x_new = deepcopy(position)
-        target_new = deepcopy(target)
-        target_move = 0
-        return [position, target, mu, sigma, x_new, target_new, target_move]
-
-    def initialize_variables(self):
-        # Control Parameters Of Algorithm
-        # ==============================================================================================
-        #  [c1] movement_factor : Determines Movement Pace Of Robots During Exploration Policy
-        #  [c2] sigma_factor    : Determines Level Of Divergence Of Slave Robots From Master Robot
-        #  [c3] sigma_limit     : Limits Value Of Sigma Factor
-        #  [c4] mu_factor       : Controls Mean Value For Master And Slave Robots
-        #       Control Parameters C1, C2 And C3 Are Automatically Tuned While C4 Should Be Set By User
-        # ==============================================================================================
-        self.mu_factor = 2 / 3  # [0.1-0.9] Controls Dominance Of Master Robot, Preferably 2/3
-        self.sigma_temp = np.zeros(self.pop_size)  # Initializing Temporary Stacks
-        self.SIF = None
-        self.movement_factor = self.problem.ub - self.problem.lb
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # ========================================================================================= %%
-        #            PHASE 1 (ACCUMULATION): CALCULATING Mu AND SIGMA values FOR SOLUTIONS            %
-        # ===========================================================================================%%
-        # ------ CALCULATING MU AND SIGMA FOR MASTER ROBOT ----------
-        self.pop[0][self.ID_SIGMA] = np.random.uniform()
-        if epoch % 2 == 1:
-            self.pop[0][self.ID_MU] = (1 - self.pop[0][self.ID_SIGMA]) * self.pop[0][self.ID_POS]
-        else:
-            self.pop[0][self.ID_MU] = (1 + (1 - self.mu_factor) * self.pop[0][self.ID_SIGMA]) * self.pop[0][self.ID_POS]
-
-        pop_new = []
-        for i in range(0, self.pop_size):
-            agent = deepcopy(self.pop[i])
-            # ---------- CALCULATING MU AND SIGMA FOR SLAVE ROBOTS ---------
-            self.pop[i][self.ID_MU] = self.mu_factor * self.pop[0][self.ID_POS] + (1 - self.mu_factor) * self.pop[i][self.ID_POS]
-            if epoch == 0:
-                self.SIF = 6
-            self.sigma_temp[i] = self.SIF * np.random.uniform()
-            self.pop[i][self.ID_SIGMA] = self.sigma_temp[i] * np.abs(self.pop[0][self.ID_POS] - self.pop[i][self.ID_POS]) + \
-                                         np.random.uniform() ** 2 * ((self.pop[0][self.ID_POS] - self.pop[i][self.ID_POS]) < 0.05)
-
-            # ----- Generating New Positions Using New Obtained Mu And Sigma Values --------------
-            pos_new = np.random.normal(self.pop[i][self.ID_MU], self.pop[i][self.ID_SIGMA], self.problem.n_dims)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            agent[self.ID_POS] = pos_new
-            pop_new.append(agent)
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop_new = self.update_target_wrapper_population(pop_new)
-
-        for idx in range(0, self.pop_size):
-            # --------- Calculate Degree Of Cost Movement Of Robots During Movement --------------
-            self.pop[idx][self.ID_FIT_MOVE] = self.pop[idx][self.ID_TAR][self.ID_FIT] - self.pop[idx][self.ID_FIT_NEW][self.ID_FIT]
-
-            self.pop[idx][self.ID_POS_NEW] = deepcopy(pop_new[idx][self.ID_POS])
-            self.pop[idx][self.ID_FIT_NEW] = deepcopy(pop_new[idx][self.ID_TAR])
-
-            # ---------- Progress Assessment: Replacing More Quality Solutions With Previous Ones ------
-            # Replace Solution If It Reached To A More Quality Position
-            if self.compare_agent(pop_new[idx], self.pop[idx]):
-                self.pop[idx][self.ID_POS] = deepcopy(pop_new[idx][self.ID_POS])
-                self.pop[idx][self.ID_TAR] = deepcopy(pop_new[idx][self.ID_TAR])
-
-        # --------- Determining Sigma Improvement Factor (Sif) Based On Vvss Movement -------------------
-        ## Get best improved fitness
-        fit_id = np.argmax([item[self.ID_FIT_MOVE] for item in self.pop])
-        sigma_factor = 1 + np.random.uniform() * np.max(self.problem.ub - self.problem.lb)
-        self.SIF = sigma_factor * self.sigma_temp[fit_id]
-        # Controlling Parameter Of Algorithm
-        if self.SIF > np.max(self.problem.ub):
-            self.SIF = np.max(self.problem.ub) * np.random.uniform()
-
-        # ========================================================================================= %%
-        #            Phase 2 (Exploration): Moving Slave Robots Toward Master Robot                   %
-        # ===========================================================================================%%
-        pop_new = []
-        for i in range(0, self.pop_size):
-            agent = deepcopy(self.pop[i])
-            gb = np.random.uniform(-1, 1, self.problem.n_dims)
-            gb[gb >= 0] = 1
-            gb[gb < 0] = -1
-            pos_new = self.pop[i][self.ID_POS] * np.random.uniform() + gb * (self.pop[0][self.ID_POS] - self.pop[i][self.ID_POS]) + \
-                   self.movement_factor * np.random.uniform(self.problem.lb, self.problem.ub)
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            agent[self.ID_POS] = pos_new
-            pop_new.append(agent)
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop_new = self.update_target_wrapper_population(pop_new)
-
-        for idx in range(0, self.pop_size):
-            # --------- Calculate Degree Of Cost Movement Of Robots During Movement --------------
-            self.pop[idx][self.ID_FIT_MOVE] = self.pop[idx][self.ID_TAR][self.ID_FIT] - self.pop[idx][self.ID_FIT_NEW][self.ID_FIT]
-
-            self.pop[idx][self.ID_POS_NEW] = deepcopy(pop_new[idx][self.ID_POS])
-            self.pop[idx][self.ID_FIT_NEW] = deepcopy(pop_new[idx][self.ID_TAR])
-
-            # ---------- Progress Assessment: Replacing More Quality Solutions With Previous Ones ------
-            # Replace Solution If It Reached To A More Quality Position
-            if self.compare_agent(pop_new[idx], self.pop[idx]):
-                self.pop[idx][self.ID_POS] = deepcopy(pop_new[idx][self.ID_POS])
-                self.pop[idx][self.ID_TAR] = deepcopy(pop_new[idx][self.ID_TAR])
-
-        # ========================================================================================= %%
-        #        PHASE 3 (LOCAL SEARCH): CREATING SOME WORKER ROBOTS ASSIGNED TO SEARCH               %
-        #                      LOCATIONS AROUND POSITION OF MASTER ROBOT                              %
-        # ===========================================================================================%%
-
-        if epoch > 0:
-            # --- EXTRACTING "INTEGER PART" AND "FRACTIONAL PART"  OF THE ELEMENTS OF MASTER RPBOT POSITION------
-            master_robot = {"original": deepcopy(np.reshape(self.pop[0][self.ID_POS], (self.problem.n_dims, 1))),
-                            "sign": deepcopy(np.reshape(np.sign(self.pop[0][self.ID_POS]), (self.problem.n_dims, 1))),
-                            "abs": deepcopy(np.reshape(abs(self.pop[0][self.ID_POS]), (self.problem.n_dims, 1))),
-                            "int": deepcopy(np.reshape(np.floor(abs(self.pop[0][self.ID_POS])), (self.problem.n_dims, 1))),  # INTEGER PART
-                            "frac": deepcopy(np.reshape(abs(self.pop[0][self.ID_POS]) - np.floor(abs(self.pop[0][self.ID_POS])), (self.problem.n_dims, 1)))
-                            }  # FRACTIONAL PART
-
-            # ------- Applying Nth-root And Nth-exponent Operators To Create Position Of New Worker Robots -------
-            worker_robot1 = (master_robot["int"] + np.power(master_robot["frac"], 1 / (1 + np.random.randint(1, 4)))) * master_robot["sign"]
-            id_changed1 = np.argwhere(np.round(np.random.uniform(self.problem.lb, self.problem.ub)))
-            id_changed1 = np.reshape(id_changed1, (len(id_changed1)))
-            worker_robot1 = np.reshape(worker_robot1, (self.problem.n_dims, 1))
-            worker_robot1[id_changed1] = master_robot["original"][id_changed1]
-
-            worker_robot2 = (master_robot["int"] + np.power(master_robot["frac"], (1 + np.random.randint(1, 4)))) * master_robot["sign"]
-            id_changed2 = np.argwhere(np.round(np.random.uniform(self.problem.lb, self.problem.ub)))
-            id_changed2 = np.reshape(id_changed2, (len(id_changed2)))
-            worker_robot2 = np.reshape(worker_robot2, (self.problem.n_dims, 1))
-            worker_robot2[id_changed2] = master_robot["original"][id_changed2]
-
-            # -------- Applying A Combined Ga-like Operator To Create Position Of New Worker Robot -------------
-            random_per_mutation = np.random.permutation(self.problem.n_dims)
-            sec1 = random_per_mutation[0: int(self.problem.n_dims / 2)]
-            sec2 = random_per_mutation[int(self.problem.n_dims / 2):]
-            worker_robot3 = np.zeros((self.problem.n_dims, 1))
-            worker_robot3[sec1] = (master_robot["int"][sec1] + np.power(master_robot["frac"][sec1],
-                                                                        1 / (1 + np.random.randint(1, 4)))) * master_robot["sign"][sec1]
-            worker_robot3[sec2] = (master_robot["int"][sec2] + master_robot["frac"][sec2] **
-                                   (1 + np.random.randint(1, 4))) * master_robot["sign"][sec2]
-            id_changed3 = np.argwhere(np.round(np.random.uniform(self.problem.lb, self.problem.ub)))
-            id_changed3 = np.reshape(id_changed3, (len(id_changed3)))
-            worker_robot3[id_changed3] = master_robot["original"][id_changed3]
-
-            # ------- Applying Round Operators To Create Position Of New Worker Robot -------------------
-            worker_robot4 = np.ceil(master_robot["abs"]) * master_robot["sign"]
-            id_changed4 = np.argwhere(np.round(np.random.uniform(self.problem.lb, self.problem.ub)))
-            id_changed4 = np.reshape(id_changed4, (len(id_changed4)))
-            worker_robot4[id_changed4] = master_robot["original"][id_changed4]
-
-            worker_robot5 = np.floor(master_robot["abs"]) * master_robot["sign"]
-            id_changed5 = np.argwhere(np.round(np.random.uniform(self.problem.lb, self.problem.ub)))
-            id_changed5 = np.reshape(id_changed5, (len(id_changed5)))
-            worker_robot5[id_changed5] = master_robot["original"][id_changed5]
-
-            # --------- Progress Assessment: Replacing More Quality Solutions With Previous Ones ---------------
-            workers = np.concatenate((worker_robot1.T, worker_robot2.T, worker_robot3.T, worker_robot4.T, worker_robot5.T), axis=0)
-            pop_workers = []
-            for i in range(0, 5):
-                pos_new = self.amend_position(workers[i], self.problem.lb, self.problem.ub)
-                pop_workers.append([pos_new, None])
-                if self.mode not in self.AVAILABLE_MODES:
-                    pop_workers[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-            pop_workers = self.update_target_wrapper_population(pop_workers)
-
-            for i in range(0, 5):
-                if self.compare_agent(pop_workers[i], self.pop[1]):
-                    self.pop[-(i + 1)][self.ID_POS] = deepcopy(pop_workers[i][self.ID_POS])
-                    self.pop[-(i + 1)][self.ID_TAR] = deepcopy(pop_workers[i][self.ID_TAR])
+#!/usr/bin/env python
+# Created by "Thieu" at 14:51, 17/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalSRSR(Optimizer):
+    """
+    The original version of: Swarm Robotics Search And Rescue (SRSR)
+
+    Links:
+        1. https://doi.org/10.1016/j.asoc.2017.02.028
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.SRSR import OriginalSRSR
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalSRSR(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Bakhshipour, M., Ghadi, M.J. and Namdari, F., 2017. Swarm robotics search & rescue: A novel
+    artificial intelligence-inspired optimization approach. Applied Soft Computing, 57, pp.708-726.
+    """
+
+    ID_POS = 0
+    ID_TAR = 1
+    ID_MU = 2
+    ID_SIGMA = 3
+    ID_POS_NEW = 4
+    ID_FIT_NEW = 5
+    ID_FIT_MOVE = 6
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = True
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        """
+        Overriding method in Optimizer class
+
+        Returns:
+            list: wrapper of solution with format [position, target, mu, sigma, x_new, target_new, target_move]
+        """
+        if pos is None:
+            pos = self.generate_position(lb, ub)
+        position = self.amend_position(pos, lb, ub)
+        target = self.get_target_wrapper(position)
+        mu = 0
+        sigma = 0
+        x_new = deepcopy(position)
+        target_new = deepcopy(target)
+        target_move = 0
+        return [position, target, mu, sigma, x_new, target_new, target_move]
+
+    def initialize_variables(self):
+        # Control Parameters Of Algorithm
+        # ==============================================================================================
+        #  [c1] movement_factor : Determines Movement Pace Of Robots During Exploration Policy
+        #  [c2] sigma_factor    : Determines Level Of Divergence Of Slave Robots From Master Robot
+        #  [c3] sigma_limit     : Limits Value Of Sigma Factor
+        #  [c4] mu_factor       : Controls Mean Value For Master And Slave Robots
+        #       Control Parameters C1, C2 And C3 Are Automatically Tuned While C4 Should Be Set By User
+        # ==============================================================================================
+        self.mu_factor = 2 / 3  # [0.1-0.9] Controls Dominance Of Master Robot, Preferably 2/3
+        self.sigma_temp = np.zeros(self.pop_size)  # Initializing Temporary Stacks
+        self.SIF = None
+        self.movement_factor = self.problem.ub - self.problem.lb
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # ========================================================================================= %%
+        #            PHASE 1 (ACCUMULATION): CALCULATING Mu AND SIGMA values FOR SOLUTIONS            %
+        # ===========================================================================================%%
+        # ------ CALCULATING MU AND SIGMA FOR MASTER ROBOT ----------
+        self.pop[0][self.ID_SIGMA] = np.random.uniform()
+        if epoch % 2 == 1:
+            self.pop[0][self.ID_MU] = (1 - self.pop[0][self.ID_SIGMA]) * self.pop[0][self.ID_POS]
+        else:
+            self.pop[0][self.ID_MU] = (1 + (1 - self.mu_factor) * self.pop[0][self.ID_SIGMA]) * self.pop[0][self.ID_POS]
+
+        pop_new = []
+        for i in range(0, self.pop_size):
+            agent = deepcopy(self.pop[i])
+            # ---------- CALCULATING MU AND SIGMA FOR SLAVE ROBOTS ---------
+            self.pop[i][self.ID_MU] = self.mu_factor * self.pop[0][self.ID_POS] + (1 - self.mu_factor) * self.pop[i][self.ID_POS]
+            if epoch == 0:
+                self.SIF = 6
+            self.sigma_temp[i] = self.SIF * np.random.uniform()
+            self.pop[i][self.ID_SIGMA] = self.sigma_temp[i] * np.abs(self.pop[0][self.ID_POS] - self.pop[i][self.ID_POS]) + \
+                                         np.random.uniform() ** 2 * ((self.pop[0][self.ID_POS] - self.pop[i][self.ID_POS]) < 0.05)
+
+            # ----- Generating New Positions Using New Obtained Mu And Sigma Values --------------
+            pos_new = np.random.normal(self.pop[i][self.ID_MU], self.pop[i][self.ID_SIGMA], self.problem.n_dims)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            agent[self.ID_POS] = pos_new
+            pop_new.append(agent)
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop_new = self.update_target_wrapper_population(pop_new)
+
+        for idx in range(0, self.pop_size):
+            # --------- Calculate Degree Of Cost Movement Of Robots During Movement --------------
+            self.pop[idx][self.ID_FIT_MOVE] = self.pop[idx][self.ID_TAR][self.ID_FIT] - self.pop[idx][self.ID_FIT_NEW][self.ID_FIT]
+
+            self.pop[idx][self.ID_POS_NEW] = deepcopy(pop_new[idx][self.ID_POS])
+            self.pop[idx][self.ID_FIT_NEW] = deepcopy(pop_new[idx][self.ID_TAR])
+
+            # ---------- Progress Assessment: Replacing More Quality Solutions With Previous Ones ------
+            # Replace Solution If It Reached To A More Quality Position
+            if self.compare_agent(pop_new[idx], self.pop[idx]):
+                self.pop[idx][self.ID_POS] = deepcopy(pop_new[idx][self.ID_POS])
+                self.pop[idx][self.ID_TAR] = deepcopy(pop_new[idx][self.ID_TAR])
+
+        # --------- Determining Sigma Improvement Factor (Sif) Based On Vvss Movement -------------------
+        ## Get best improved fitness
+        fit_id = np.argmax([item[self.ID_FIT_MOVE] for item in self.pop])
+        sigma_factor = 1 + np.random.uniform() * np.max(self.problem.ub - self.problem.lb)
+        self.SIF = sigma_factor * self.sigma_temp[fit_id]
+        # Controlling Parameter Of Algorithm
+        if self.SIF > np.max(self.problem.ub):
+            self.SIF = np.max(self.problem.ub) * np.random.uniform()
+
+        # ========================================================================================= %%
+        #            Phase 2 (Exploration): Moving Slave Robots Toward Master Robot                   %
+        # ===========================================================================================%%
+        pop_new = []
+        for i in range(0, self.pop_size):
+            agent = deepcopy(self.pop[i])
+            gb = np.random.uniform(-1, 1, self.problem.n_dims)
+            gb[gb >= 0] = 1
+            gb[gb < 0] = -1
+            pos_new = self.pop[i][self.ID_POS] * np.random.uniform() + gb * (self.pop[0][self.ID_POS] - self.pop[i][self.ID_POS]) + \
+                   self.movement_factor * np.random.uniform(self.problem.lb, self.problem.ub)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            agent[self.ID_POS] = pos_new
+            pop_new.append(agent)
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop_new = self.update_target_wrapper_population(pop_new)
+
+        for idx in range(0, self.pop_size):
+            # --------- Calculate Degree Of Cost Movement Of Robots During Movement --------------
+            self.pop[idx][self.ID_FIT_MOVE] = self.pop[idx][self.ID_TAR][self.ID_FIT] - self.pop[idx][self.ID_FIT_NEW][self.ID_FIT]
+
+            self.pop[idx][self.ID_POS_NEW] = deepcopy(pop_new[idx][self.ID_POS])
+            self.pop[idx][self.ID_FIT_NEW] = deepcopy(pop_new[idx][self.ID_TAR])
+
+            # ---------- Progress Assessment: Replacing More Quality Solutions With Previous Ones ------
+            # Replace Solution If It Reached To A More Quality Position
+            if self.compare_agent(pop_new[idx], self.pop[idx]):
+                self.pop[idx][self.ID_POS] = deepcopy(pop_new[idx][self.ID_POS])
+                self.pop[idx][self.ID_TAR] = deepcopy(pop_new[idx][self.ID_TAR])
+
+        # ========================================================================================= %%
+        #        PHASE 3 (LOCAL SEARCH): CREATING SOME WORKER ROBOTS ASSIGNED TO SEARCH               %
+        #                      LOCATIONS AROUND POSITION OF MASTER ROBOT                              %
+        # ===========================================================================================%%
+
+        if epoch > 0:
+            # --- EXTRACTING "INTEGER PART" AND "FRACTIONAL PART"  OF THE ELEMENTS OF MASTER RPBOT POSITION------
+            master_robot = {"original": deepcopy(np.reshape(self.pop[0][self.ID_POS], (self.problem.n_dims, 1))),
+                            "sign": deepcopy(np.reshape(np.sign(self.pop[0][self.ID_POS]), (self.problem.n_dims, 1))),
+                            "abs": deepcopy(np.reshape(abs(self.pop[0][self.ID_POS]), (self.problem.n_dims, 1))),
+                            "int": deepcopy(np.reshape(np.floor(abs(self.pop[0][self.ID_POS])), (self.problem.n_dims, 1))),  # INTEGER PART
+                            "frac": deepcopy(np.reshape(abs(self.pop[0][self.ID_POS]) - np.floor(abs(self.pop[0][self.ID_POS])), (self.problem.n_dims, 1)))
+                            }  # FRACTIONAL PART
+
+            # ------- Applying Nth-root And Nth-exponent Operators To Create Position Of New Worker Robots -------
+            worker_robot1 = (master_robot["int"] + np.power(master_robot["frac"], 1 / (1 + np.random.randint(1, 4)))) * master_robot["sign"]
+            id_changed1 = np.argwhere(np.round(np.random.uniform(self.problem.lb, self.problem.ub)))
+            id_changed1 = np.reshape(id_changed1, (len(id_changed1)))
+            worker_robot1 = np.reshape(worker_robot1, (self.problem.n_dims, 1))
+            worker_robot1[id_changed1] = master_robot["original"][id_changed1]
+
+            worker_robot2 = (master_robot["int"] + np.power(master_robot["frac"], (1 + np.random.randint(1, 4)))) * master_robot["sign"]
+            id_changed2 = np.argwhere(np.round(np.random.uniform(self.problem.lb, self.problem.ub)))
+            id_changed2 = np.reshape(id_changed2, (len(id_changed2)))
+            worker_robot2 = np.reshape(worker_robot2, (self.problem.n_dims, 1))
+            worker_robot2[id_changed2] = master_robot["original"][id_changed2]
+
+            # -------- Applying A Combined Ga-like Operator To Create Position Of New Worker Robot -------------
+            random_per_mutation = np.random.permutation(self.problem.n_dims)
+            sec1 = random_per_mutation[0: int(self.problem.n_dims / 2)]
+            sec2 = random_per_mutation[int(self.problem.n_dims / 2):]
+            worker_robot3 = np.zeros((self.problem.n_dims, 1))
+            worker_robot3[sec1] = (master_robot["int"][sec1] + np.power(master_robot["frac"][sec1],
+                                                                        1 / (1 + np.random.randint(1, 4)))) * master_robot["sign"][sec1]
+            worker_robot3[sec2] = (master_robot["int"][sec2] + master_robot["frac"][sec2] **
+                                   (1 + np.random.randint(1, 4))) * master_robot["sign"][sec2]
+            id_changed3 = np.argwhere(np.round(np.random.uniform(self.problem.lb, self.problem.ub)))
+            id_changed3 = np.reshape(id_changed3, (len(id_changed3)))
+            worker_robot3[id_changed3] = master_robot["original"][id_changed3]
+
+            # ------- Applying Round Operators To Create Position Of New Worker Robot -------------------
+            worker_robot4 = np.ceil(master_robot["abs"]) * master_robot["sign"]
+            id_changed4 = np.argwhere(np.round(np.random.uniform(self.problem.lb, self.problem.ub)))
+            id_changed4 = np.reshape(id_changed4, (len(id_changed4)))
+            worker_robot4[id_changed4] = master_robot["original"][id_changed4]
+
+            worker_robot5 = np.floor(master_robot["abs"]) * master_robot["sign"]
+            id_changed5 = np.argwhere(np.round(np.random.uniform(self.problem.lb, self.problem.ub)))
+            id_changed5 = np.reshape(id_changed5, (len(id_changed5)))
+            worker_robot5[id_changed5] = master_robot["original"][id_changed5]
+
+            # --------- Progress Assessment: Replacing More Quality Solutions With Previous Ones ---------------
+            workers = np.concatenate((worker_robot1.T, worker_robot2.T, worker_robot3.T, worker_robot4.T, worker_robot5.T), axis=0)
+            pop_workers = []
+            for i in range(0, 5):
+                pos_new = self.amend_position(workers[i], self.problem.lb, self.problem.ub)
+                pop_workers.append([pos_new, None])
+                if self.mode not in self.AVAILABLE_MODES:
+                    pop_workers[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+            pop_workers = self.update_target_wrapper_population(pop_workers)
+
+            for i in range(0, 5):
+                if self.compare_agent(pop_workers[i], self.pop[1]):
+                    self.pop[-(i + 1)][self.ID_POS] = deepcopy(pop_workers[i][self.ID_POS])
+                    self.pop[-(i + 1)][self.ID_TAR] = deepcopy(pop_workers[i][self.ID_TAR])
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/SSA.py` & `mealpy-2.5.3a1/mealpy/swarm_based/SSA.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,260 +1,261 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 17:22, 29/05/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class BaseSSA(Optimizer):
-    """
-    The developed version: Sparrow Search Algorithm (SSA)
-
-    Notes:
-        + First, the population is sorted to find g-best and g-worst
-        + In Eq. 4, the np.random.normal() gaussian distribution is used instead of A+ and L
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + ST (float): ST in [0.5, 1.0], safety threshold value, default = 0.8
-        + PD (float): number of producers (percentage), default = 0.2
-        + SD (float): number of sparrows who perceive the danger, default = 0.1
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.SSA import BaseSSA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> ST = 0.8
-    >>> PD = 0.2
-    >>> SD = 0.1
-    >>> model = BaseSSA(epoch, pop_size, ST, PD, SD)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Xue, J. and Shen, B., 2020. A novel swarm intelligence optimization approach:
-    sparrow search algorithm. Systems Science & Control Engineering, 8(1), pp.22-34.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, ST=0.8, PD=0.2, SD=0.1, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            ST (float): ST in [0.5, 1.0], safety threshold value, default = 0.8
-            PD (float): number of producers (percentage), default = 0.2
-            SD (float): number of sparrows who perceive the danger, default = 0.1
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.ST = self.validator.check_float("ST", ST, (0, 1.0))
-        self.PD = self.validator.check_float("PD", PD, (0, 1.0))
-        self.SD = self.validator.check_float("SD", SD, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "ST", "PD", "SD"])
-        self.n1 = int(self.PD * self.pop_size)
-        self.n2 = int(self.SD * self.pop_size)
-        self.sort_flag = True
-
-    def amend_position(self, position=None, lb=None, ub=None):
-        """
-        Args:
-            position: vector position (location) of the solution.
-            lb: list of lower bound values
-            ub: list of upper bound values
-
-        Returns:
-            Amended position (make the position is in bound)
-        """
-        condition = np.logical_and(lb <= position, position <= ub)
-        pos_rand = np.random.uniform(lb, ub)
-        return np.where(condition, position, pos_rand)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        r2 = np.random.uniform()  # R2 in [0, 1], the alarm value, random value
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            # Using equation (3) update the sparrowâs location;
-            if idx < self.n1:
-                if r2 < self.ST:
-                    des = (epoch + 1) / (np.random.uniform() * self.epoch + self.EPSILON)
-                    if des > 5:
-                        des = np.random.normal()
-                    x_new = self.pop[idx][self.ID_POS] * np.exp(des)
-                else:
-                    x_new = self.pop[idx][self.ID_POS] + np.random.normal() * np.ones(self.problem.n_dims)
-            else:
-                # Using equation (4) update the sparrowâs location;
-                _, x_p, worst = self.get_special_solutions(self.pop, best=1, worst=1)
-                g_best = x_p[0], g_worst = worst[0]
-                if idx > int(self.pop_size / 2):
-                    x_new = np.random.normal() * np.exp((g_worst[self.ID_POS] - self.pop[idx][self.ID_POS]) / (idx + 1) ** 2)
-                else:
-                    x_new = g_best[self.ID_POS] + np.abs(self.pop[idx][self.ID_POS] - g_best[self.ID_POS]) * np.random.normal()
-            pos_new = self.amend_position(x_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-        self.pop, best, worst = self.get_special_solutions(self.pop, best=1, worst=1)
-        g_best, g_worst = best[0], worst[0]
-        pop2 = deepcopy(self.pop[self.n2:])
-        child = []
-        for idx in range(0, len(pop2)):
-            #  Using equation (5) update the sparrowâs location;
-            if self.compare_agent(self.pop[idx], g_best):
-                x_new = pop2[idx][self.ID_POS] + np.random.uniform(-1, 1) * (np.abs(pop2[idx][self.ID_POS] - g_worst[self.ID_POS]) /
-                        (pop2[idx][self.ID_TAR][self.ID_FIT] - g_worst[self.ID_TAR][self.ID_FIT] + self.EPSILON))
-            else:
-                x_new = g_best[self.ID_POS] + np.random.normal() * np.abs(pop2[idx][self.ID_POS] - g_best[self.ID_POS])
-            pos_new = self.amend_position(x_new, self.problem.lb, self.problem.ub)
-            child.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                pop2[idx] = self.get_better_solution(pop2[idx], [pos_new, target])
-        if self.mode in self.AVAILABLE_MODES:
-            child = self.update_target_wrapper_population(child)
-            pop2 = self.greedy_selection_population(pop2, child)
-        self.pop = self.pop[:self.n2] + pop2
-
-
-class OriginalSSA(BaseSSA):
-    """
-    The original version of: Sparrow Search Algorithm (SSA)
-
-    Links:
-        1. https://doi.org/10.1080/21642583.2019.1708830
-
-    Notes
-    ~~~~~
-    + The paper contains some unclear equations and symbol
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + ST (float): ST in [0.5, 1.0], safety threshold value, default = 0.8
-        + PD (float): number of producers (percentage), default = 0.2
-        + SD (float): number of sparrows who perceive the danger, default = 0.1
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.SSA import OriginalSSA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> ST = 0.8
-    >>> PD = 0.2
-    >>> SD = 0.1
-    >>> model = OriginalSSA(epoch, pop_size, ST, PD, SD)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Xue, J. and Shen, B., 2020. A novel swarm intelligence optimization approach:
-    sparrow search algorithm. Systems Science & Control Engineering, 8(1), pp.22-34.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, ST=0.8, PD=0.2, SD=0.1, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            ST (float): ST in [0.5, 1.0], safety threshold value, default = 0.8
-            PD (float): number of producers (percentage), default = 0.2
-            SD (float): number of sparrows who perceive the danger, default = 0.1
-        """
-        super().__init__(epoch, pop_size, ST, PD, SD, **kwargs)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        r2 = np.random.uniform()  # R2 in [0, 1], the alarm value, random value
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            # Using equation (3) update the sparrowâs location;
-            if idx < self.n1:
-                if r2 < self.ST:
-                    des = (idx + 1) / (np.random.uniform() * self.epoch + self.EPSILON)
-                    if des > 5:
-                        des = np.random.uniform()
-                    x_new = self.pop[idx][self.ID_POS] * np.exp(des)
-                else:
-                    x_new = self.pop[idx][self.ID_POS] + np.random.normal() * np.ones(self.problem.n_dims)
-            else:
-                # Using equation (4) update the sparrowâs location;
-                _, x_p, worst = self.get_special_solutions(self.pop, best=1, worst=1)
-                g_best, g_worst = x_p[0], worst[0]
-                if idx > int(self.pop_size / 2):
-                    x_new = np.random.normal() * np.exp((g_worst[self.ID_POS] - self.pop[idx][self.ID_POS]) / (idx + 1) ** 2)
-                else:
-                    L = np.ones((1, self.problem.n_dims))
-                    A = np.sign(np.random.uniform(-1, 1, (1, self.problem.n_dims)))
-                    A1 = A.T * np.linalg.inv(np.matmul(A, A.T)) * L
-                    x_new = g_best[self.ID_POS] + np.matmul(np.abs(self.pop[idx][self.ID_POS] - g_best[self.ID_POS]), A1)
-            pos_new = self.amend_position(x_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-        self.pop, best, worst = self.get_special_solutions(self.pop, best=1, worst=1)
-        g_best, g_worst = best[0], worst[0]
-        pop2 = self.pop[self.n2:]
-        child = []
-        for idx in range(0, len(pop2)):
-            #  Using equation (5) update the sparrowâs location;
-            if self.compare_agent(self.pop[idx], g_best):
-                x_new = pop2[idx][self.ID_POS] + np.random.uniform(-1, 1) * (np.abs(pop2[idx][self.ID_POS] - g_worst[self.ID_POS]) /
-                    (pop2[idx][self.ID_TAR][self.ID_FIT] - g_worst[self.ID_TAR][self.ID_FIT] + self.EPSILON))
-            else:
-                x_new = g_best[self.ID_POS] + np.random.normal() * np.abs(pop2[idx][self.ID_POS] - g_best[self.ID_POS])
-            pos_new = self.amend_position(x_new, self.problem.lb, self.problem.ub)
-            child.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                pop2[idx] = self.get_better_solution(pop2[idx], [pos_new, target])
-        if self.mode in self.AVAILABLE_MODES:
-            child = self.update_target_wrapper_population(child)
-            pop2 = self.greedy_selection_population(pop2, child)
-        self.pop = self.pop[:self.n2] + pop2
+#!/usr/bin/env python
+# Created by "Thieu" at 17:22, 29/05/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class BaseSSA(Optimizer):
+    """
+    The developed version: Sparrow Search Algorithm (SSA)
+
+    Notes
+    ~~~~~
+    + First, the population is sorted to find g-best and g-worst
+    + In Eq. 4, the np.random.normal() gaussian distribution is used instead of A+ and L
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + ST (float): ST in [0.5, 1.0], safety threshold value, default = 0.8
+        + PD (float): number of producers (percentage), default = 0.2
+        + SD (float): number of sparrows who perceive the danger, default = 0.1
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.SSA import BaseSSA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> ST = 0.8
+    >>> PD = 0.2
+    >>> SD = 0.1
+    >>> model = BaseSSA(epoch, pop_size, ST, PD, SD)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Xue, J. and Shen, B., 2020. A novel swarm intelligence optimization approach:
+    sparrow search algorithm. Systems Science & Control Engineering, 8(1), pp.22-34.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, ST=0.8, PD=0.2, SD=0.1, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            ST (float): ST in [0.5, 1.0], safety threshold value, default = 0.8
+            PD (float): number of producers (percentage), default = 0.2
+            SD (float): number of sparrows who perceive the danger, default = 0.1
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.ST = self.validator.check_float("ST", ST, (0, 1.0))
+        self.PD = self.validator.check_float("PD", PD, (0, 1.0))
+        self.SD = self.validator.check_float("SD", SD, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "ST", "PD", "SD"])
+        self.n1 = int(self.PD * self.pop_size)
+        self.n2 = int(self.SD * self.pop_size)
+        self.sort_flag = True
+
+    def amend_position(self, position=None, lb=None, ub=None):
+        """
+        Args:
+            position: vector position (location) of the solution.
+            lb: list of lower bound values
+            ub: list of upper bound values
+
+        Returns:
+            Amended position (make the position is in bound)
+        """
+        condition = np.logical_and(lb <= position, position <= ub)
+        pos_rand = np.random.uniform(lb, ub)
+        return np.where(condition, position, pos_rand)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        r2 = np.random.uniform()  # R2 in [0, 1], the alarm value, random value
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            # Using equation (3) update the sparrowâs location;
+            if idx < self.n1:
+                if r2 < self.ST:
+                    des = (epoch + 1) / (np.random.uniform() * self.epoch + self.EPSILON)
+                    if des > 5:
+                        des = np.random.normal()
+                    x_new = self.pop[idx][self.ID_POS] * np.exp(des)
+                else:
+                    x_new = self.pop[idx][self.ID_POS] + np.random.normal() * np.ones(self.problem.n_dims)
+            else:
+                # Using equation (4) update the sparrowâs location;
+                _, x_p, worst = self.get_special_solutions(self.pop, best=1, worst=1)
+                g_best = x_p[0], g_worst = worst[0]
+                if idx > int(self.pop_size / 2):
+                    x_new = np.random.normal() * np.exp((g_worst[self.ID_POS] - self.pop[idx][self.ID_POS]) / (idx + 1) ** 2)
+                else:
+                    x_new = g_best[self.ID_POS] + np.abs(self.pop[idx][self.ID_POS] - g_best[self.ID_POS]) * np.random.normal()
+            pos_new = self.amend_position(x_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+        self.pop, best, worst = self.get_special_solutions(self.pop, best=1, worst=1)
+        g_best, g_worst = best[0], worst[0]
+        pop2 = deepcopy(self.pop[self.n2:])
+        child = []
+        for idx in range(0, len(pop2)):
+            #  Using equation (5) update the sparrowâs location;
+            if self.compare_agent(self.pop[idx], g_best):
+                x_new = pop2[idx][self.ID_POS] + np.random.uniform(-1, 1) * (np.abs(pop2[idx][self.ID_POS] - g_worst[self.ID_POS]) /
+                        (pop2[idx][self.ID_TAR][self.ID_FIT] - g_worst[self.ID_TAR][self.ID_FIT] + self.EPSILON))
+            else:
+                x_new = g_best[self.ID_POS] + np.random.normal() * np.abs(pop2[idx][self.ID_POS] - g_best[self.ID_POS])
+            pos_new = self.amend_position(x_new, self.problem.lb, self.problem.ub)
+            child.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                pop2[idx] = self.get_better_solution(pop2[idx], [pos_new, target])
+        if self.mode in self.AVAILABLE_MODES:
+            child = self.update_target_wrapper_population(child)
+            pop2 = self.greedy_selection_population(pop2, child)
+        self.pop = self.pop[:self.n2] + pop2
+
+
+class OriginalSSA(BaseSSA):
+    """
+    The original version of: Sparrow Search Algorithm (SSA)
+
+    Links:
+        1. https://doi.org/10.1080/21642583.2019.1708830
+
+    Notes
+    ~~~~~
+    + The paper contains some unclear equations and symbol
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + ST (float): ST in [0.5, 1.0], safety threshold value, default = 0.8
+        + PD (float): number of producers (percentage), default = 0.2
+        + SD (float): number of sparrows who perceive the danger, default = 0.1
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.SSA import OriginalSSA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> ST = 0.8
+    >>> PD = 0.2
+    >>> SD = 0.1
+    >>> model = OriginalSSA(epoch, pop_size, ST, PD, SD)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Xue, J. and Shen, B., 2020. A novel swarm intelligence optimization approach:
+    sparrow search algorithm. Systems Science & Control Engineering, 8(1), pp.22-34.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, ST=0.8, PD=0.2, SD=0.1, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            ST (float): ST in [0.5, 1.0], safety threshold value, default = 0.8
+            PD (float): number of producers (percentage), default = 0.2
+            SD (float): number of sparrows who perceive the danger, default = 0.1
+        """
+        super().__init__(epoch, pop_size, ST, PD, SD, **kwargs)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        r2 = np.random.uniform()  # R2 in [0, 1], the alarm value, random value
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            # Using equation (3) update the sparrowâs location;
+            if idx < self.n1:
+                if r2 < self.ST:
+                    des = (idx + 1) / (np.random.uniform() * self.epoch + self.EPSILON)
+                    if des > 5:
+                        des = np.random.uniform()
+                    x_new = self.pop[idx][self.ID_POS] * np.exp(des)
+                else:
+                    x_new = self.pop[idx][self.ID_POS] + np.random.normal() * np.ones(self.problem.n_dims)
+            else:
+                # Using equation (4) update the sparrowâs location;
+                _, x_p, worst = self.get_special_solutions(self.pop, best=1, worst=1)
+                g_best, g_worst = x_p[0], worst[0]
+                if idx > int(self.pop_size / 2):
+                    x_new = np.random.normal() * np.exp((g_worst[self.ID_POS] - self.pop[idx][self.ID_POS]) / (idx + 1) ** 2)
+                else:
+                    L = np.ones((1, self.problem.n_dims))
+                    A = np.sign(np.random.uniform(-1, 1, (1, self.problem.n_dims)))
+                    A1 = A.T * np.linalg.inv(np.matmul(A, A.T)) * L
+                    x_new = g_best[self.ID_POS] + np.matmul(np.abs(self.pop[idx][self.ID_POS] - g_best[self.ID_POS]), A1)
+            pos_new = self.amend_position(x_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+        self.pop, best, worst = self.get_special_solutions(self.pop, best=1, worst=1)
+        g_best, g_worst = best[0], worst[0]
+        pop2 = self.pop[self.n2:]
+        child = []
+        for idx in range(0, len(pop2)):
+            #  Using equation (5) update the sparrowâs location;
+            if self.compare_agent(self.pop[idx], g_best):
+                x_new = pop2[idx][self.ID_POS] + np.random.uniform(-1, 1) * (np.abs(pop2[idx][self.ID_POS] - g_worst[self.ID_POS]) /
+                    (pop2[idx][self.ID_TAR][self.ID_FIT] - g_worst[self.ID_TAR][self.ID_FIT] + self.EPSILON))
+            else:
+                x_new = g_best[self.ID_POS] + np.random.normal() * np.abs(pop2[idx][self.ID_POS] - g_best[self.ID_POS])
+            pos_new = self.amend_position(x_new, self.problem.lb, self.problem.ub)
+            child.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                pop2[idx] = self.get_better_solution(pop2[idx], [pos_new, target])
+        if self.mode in self.AVAILABLE_MODES:
+            child = self.update_target_wrapper_population(child)
+            pop2 = self.greedy_selection_population(pop2, child)
+        self.pop = self.pop[:self.n2] + pop2
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/SSO.py` & `mealpy-2.5.3a1/mealpy/swarm_based/SSO.py`

 * *Ordering differences only*

 * *Files 8% similar despite different names*

```diff
@@ -1,87 +1,87 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 11:38, 02/03/2021 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalSSO(Optimizer):
-    """
-    The original version of: Salp Swarm Optimization (SSO)
-
-    Links:
-        1. https://doi.org/10.1016/j.advengsoft.2017.07.002
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.SSO import OriginalSSO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalSSO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Mirjalili, S., Gandomi, A.H., Mirjalili, S.Z., Saremi, S., Faris, H. and Mirjalili, S.M., 2017.
-    Salp Swarm Algorithm: A bio-inspired optimizer for engineering design problems. Advances in
-    Engineering Software, 114, pp.163-191.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = True
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        ## Eq. (3.2) in the paper
-        c1 = 2 * np.exp(-((4 * (epoch + 1) / self.epoch) ** 2))
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            if idx < self.pop_size / 2:
-                c2_list = np.random.random(self.problem.n_dims)
-                c3_list = np.random.random(self.problem.n_dims)
-                pos_new_1 = self.g_best[self.ID_POS] + c1 * ((self.problem.ub - self.problem.lb) * c2_list + self.problem.lb)
-                pos_new_2 = self.g_best[self.ID_POS] - c1 * ((self.problem.ub - self.problem.lb) * c2_list + self.problem.lb)
-                pos_new = np.where(c3_list < 0.5, pos_new_1, pos_new_2)
-            else:
-                # Eq. (3.4) in the paper
-                pos_new = (self.pop[idx][self.ID_POS] + self.pop[idx - 1][self.ID_POS]) / 2
-
-            # Check if salps go out of the search space and bring it back then re-calculate its fitness value
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 11:38, 02/03/2021 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalSSO(Optimizer):
+    """
+    The original version of: Salp Swarm Optimization (SSO)
+
+    Links:
+        1. https://doi.org/10.1016/j.advengsoft.2017.07.002
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.SSO import OriginalSSO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalSSO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Mirjalili, S., Gandomi, A.H., Mirjalili, S.Z., Saremi, S., Faris, H. and Mirjalili, S.M., 2017.
+    Salp Swarm Algorithm: A bio-inspired optimizer for engineering design problems. Advances in
+    Engineering Software, 114, pp.163-191.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = True
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        ## Eq. (3.2) in the paper
+        c1 = 2 * np.exp(-((4 * (epoch + 1) / self.epoch) ** 2))
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            if idx < self.pop_size / 2:
+                c2_list = np.random.random(self.problem.n_dims)
+                c3_list = np.random.random(self.problem.n_dims)
+                pos_new_1 = self.g_best[self.ID_POS] + c1 * ((self.problem.ub - self.problem.lb) * c2_list + self.problem.lb)
+                pos_new_2 = self.g_best[self.ID_POS] - c1 * ((self.problem.ub - self.problem.lb) * c2_list + self.problem.lb)
+                pos_new = np.where(c3_list < 0.5, pos_new_1, pos_new_2)
+            else:
+                # Eq. (3.4) in the paper
+                pos_new = (self.pop[idx][self.ID_POS] + self.pop[idx - 1][self.ID_POS]) / 2
+
+            # Check if salps go out of the search space and bring it back then re-calculate its fitness value
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/SSpiderA.py` & `mealpy-2.5.3a1/mealpy/swarm_based/SSpiderA.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,150 +1,151 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 11:59, 17/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from scipy.spatial.distance import cdist
-from mealpy.optimizer import Optimizer
-
-
-class OriginalSSpiderA(Optimizer):
-    """
-    The developed version of: Social Spider Algorithm (OriginalSSpiderA)
-
-    Links:
-        1. https://doi.org/10.1016/j.asoc.2015.02.014
-        2. https://github.com/James-Yu/SocialSpiderAlgorithm  (Modified this version)
-
-    Notes:
-        + The version of the algorithm available on the GitHub repository has a slow convergence rate.
-        + Changes the idea of intensity, which one has better intensity, others will move toward to it
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + r_a (float): the rate of vibration attenuation when propagating over the spider web, default=1.0
-        + p_c (float): controls the probability of the spiders changing their dimension mask in the random walk step, default=0.7
-        + p_m (float): the probability of each value in a dimension mask to be one, default=0.1
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.SSpiderA import OriginalSSpiderA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> r_a = 1.0
-    >>> p_c = 0.7
-    >>> p_m = 0.1
-    >>> model = OriginalSSpiderA(epoch, pop_size, r_a, p_c, p_m)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] James, J.Q. and Li, V.O., 2015. A social spider algorithm for global optimization.
-    Applied soft computing, 30, pp.614-627.
-    """
-
-    ID_POS = 0
-    ID_TAR = 1
-    ID_INT = 2
-    ID_TARGET_POS = 3
-    ID_PREV_MOVE_VEC = 4
-    ID_MASK = 5
-
-    def __init__(self, epoch=10000, pop_size=100, r_a=1.0, p_c=0.7, p_m=0.1, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            r_a (float): the rate of vibration attenuation when propagating over the spider web, default=1.0
-            p_c (float): controls the probability of the spiders changing their dimension mask in the random walk step, default=0.7
-            p_m (float): the probability of each value in a dimension mask to be one, default=0.1
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.r_a = self.validator.check_float("r_a", r_a, (0, 5.0))
-        self.p_c = self.validator.check_float("p_c", p_c, (0, 1.0))
-        self.p_m = self.validator.check_float("p_m", p_m, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "r_a", "p_c", "p_m"])
-        self.sort_flag = False
-
-    def create_solution(self, lb=None, ub=None, pos=None):
-        """
-        Overriding method in Optimizer class
-        + x: The position of s on the web.
-        + train: The fitness of the current position of s
-        + target_vibration: The target vibration of s in the previous iteration.
-        + intensity_vibration: intensity of vibration
-        + movement_vector: The movement that s performed in the previous iteration
-        + dimension_mask: The dimension mask 1 that s employed to guide movement in the previous iteration
-        + The dimension mask is a 0-1 binary vector of length problem size
-        + n_changed: The number of iterations since s has last changed its target vibration. (No need)
-
-        Returns:
-            list: wrapper of solution with format [position, target, intensity, target_position, previous_movement_vector, dimension_mask]
-        """
-        if pos is None:
-            pos = self.generate_position(lb, ub)
-        position = self.amend_position(pos, lb, ub)
-        target = self.get_target_wrapper(position)
-        intensity = np.log(1. / (abs(target[self.ID_FIT]) + self.EPSILON) + 1)
-        target_position = deepcopy(position)
-        previous_movement_vector = np.zeros(self.problem.n_dims)
-        dimension_mask = np.zeros(self.problem.n_dims)
-        return [position, target, intensity, target_position, previous_movement_vector, dimension_mask]
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        all_pos = np.array([it[self.ID_POS] for it in self.pop])  ## Matrix (pop_size, problem_size)
-        base_distance = np.mean(np.std(all_pos, axis=0))  ## Number
-        dist = cdist(all_pos, all_pos, 'euclidean')
-
-        intensity_source = np.array([it[self.ID_INT] for it in self.pop])
-        intensity_attenuation = np.exp(-dist / (base_distance * self.r_a))  ## vector (pop_size)
-        intensity_receive = np.dot(np.reshape(intensity_source, (1, self.pop_size)), intensity_attenuation)  ## vector (1, pop_size)
-        id_best_intennsity = np.argmax(intensity_receive)
-
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            agent = deepcopy(self.pop[idx])
-            if self.pop[id_best_intennsity][self.ID_INT] > self.pop[idx][self.ID_INT]:
-                agent[self.ID_TARGET_POS] = self.pop[id_best_intennsity][self.ID_TARGET_POS]
-            if np.random.uniform() > self.p_c:  ## changing mask
-                agent[self.ID_MASK] = np.where(np.random.uniform(0, 1, self.problem.n_dims) < self.p_m, 0, 1)
-            pos_new = np.where(self.pop[idx][self.ID_MASK] == 0, self.pop[idx][self.ID_TARGET_POS],
-                               self.pop[np.random.randint(0, self.pop_size)][self.ID_POS])
-            ## Perform random walk
-            pos_new = self.pop[idx][self.ID_POS] + np.random.normal() * \
-                      (self.pop[idx][self.ID_POS] - self.pop[idx][self.ID_PREV_MOVE_VEC]) + \
-                      (pos_new - self.pop[idx][self.ID_POS]) * np.random.normal()
-            agent[self.ID_POS] = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            if self.mode not in self.AVAILABLE_MODES:
-                agent[self.ID_TAR] = self.get_target_wrapper(agent[self.ID_POS])
-                pop_new.append(agent)
-        pop_new = self.update_target_wrapper_population(pop_new)
-
-        for idx in range(0, self.pop_size):
-            if self.compare_agent(pop_new[idx], self.pop[idx]):
-                self.pop[idx][self.ID_PREV_MOVE_VEC] = pop_new[idx][self.ID_POS] - self.pop[idx][self.ID_POS]
-                self.pop[idx][self.ID_INT] = np.log(1. / (abs(pop_new[idx][self.ID_TAR][self.ID_FIT]) + self.EPSILON) + 1)
-                self.pop[idx][self.ID_POS] = pop_new[idx][self.ID_POS]
-                self.pop[idx][self.ID_TAR] = pop_new[idx][self.ID_TAR]
+#!/usr/bin/env python
+# Created by "Thieu" at 11:59, 17/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from scipy.spatial.distance import cdist
+from mealpy.optimizer import Optimizer
+
+
+class OriginalSSpiderA(Optimizer):
+    """
+    The developed version of: Social Spider Algorithm (OriginalSSpiderA)
+
+    Links:
+        1. https://doi.org/10.1016/j.asoc.2015.02.014
+        2. https://github.com/James-Yu/SocialSpiderAlgorithm  (Modified this version)
+
+    Notes
+    ~~~~~
+    + The version on above github is very slow convergence
+    + Changes the idea of intensity, which one has better intensity, others will move toward to it
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + r_a (float): the rate of vibration attenuation when propagating over the spider web, default=1.0
+        + p_c (float): controls the probability of the spiders changing their dimension mask in the random walk step, default=0.7
+        + p_m (float): the probability of each value in a dimension mask to be one, default=0.1
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.SSpiderA import OriginalSSpiderA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> r_a = 1.0
+    >>> p_c = 0.7
+    >>> p_m = 0.1
+    >>> model = OriginalSSpiderA(epoch, pop_size, r_a, p_c, p_m)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] James, J.Q. and Li, V.O., 2015. A social spider algorithm for global optimization.
+    Applied soft computing, 30, pp.614-627.
+    """
+
+    ID_POS = 0
+    ID_TAR = 1
+    ID_INT = 2
+    ID_TARGET_POS = 3
+    ID_PREV_MOVE_VEC = 4
+    ID_MASK = 5
+
+    def __init__(self, epoch=10000, pop_size=100, r_a=1.0, p_c=0.7, p_m=0.1, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            r_a (float): the rate of vibration attenuation when propagating over the spider web, default=1.0
+            p_c (float): controls the probability of the spiders changing their dimension mask in the random walk step, default=0.7
+            p_m (float): the probability of each value in a dimension mask to be one, default=0.1
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.r_a = self.validator.check_float("r_a", r_a, (0, 5.0))
+        self.p_c = self.validator.check_float("p_c", p_c, (0, 1.0))
+        self.p_m = self.validator.check_float("p_m", p_m, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "r_a", "p_c", "p_m"])
+        self.sort_flag = False
+
+    def create_solution(self, lb=None, ub=None, pos=None):
+        """
+        Overriding method in Optimizer class
+        + x: The position of s on the web.
+        + train: The fitness of the current position of s
+        + target_vibration: The target vibration of s in the previous iteration.
+        + intensity_vibration: intensity of vibration
+        + movement_vector: The movement that s performed in the previous iteration
+        + dimension_mask: The dimension mask 1 that s employed to guide movement in the previous iteration
+        + The dimension mask is a 0-1 binary vector of length problem size
+        + n_changed: The number of iterations since s has last changed its target vibration. (No need)
+
+        Returns:
+            list: wrapper of solution with format [position, target, intensity, target_position, previous_movement_vector, dimension_mask]
+        """
+        if pos is None:
+            pos = self.generate_position(lb, ub)
+        position = self.amend_position(pos, lb, ub)
+        target = self.get_target_wrapper(position)
+        intensity = np.log(1. / (abs(target[self.ID_FIT]) + self.EPSILON) + 1)
+        target_position = deepcopy(position)
+        previous_movement_vector = np.zeros(self.problem.n_dims)
+        dimension_mask = np.zeros(self.problem.n_dims)
+        return [position, target, intensity, target_position, previous_movement_vector, dimension_mask]
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        all_pos = np.array([it[self.ID_POS] for it in self.pop])  ## Matrix (pop_size, problem_size)
+        base_distance = np.mean(np.std(all_pos, axis=0))  ## Number
+        dist = cdist(all_pos, all_pos, 'euclidean')
+
+        intensity_source = np.array([it[self.ID_INT] for it in self.pop])
+        intensity_attenuation = np.exp(-dist / (base_distance * self.r_a))  ## vector (pop_size)
+        intensity_receive = np.dot(np.reshape(intensity_source, (1, self.pop_size)), intensity_attenuation)  ## vector (1, pop_size)
+        id_best_intennsity = np.argmax(intensity_receive)
+
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            agent = deepcopy(self.pop[idx])
+            if self.pop[id_best_intennsity][self.ID_INT] > self.pop[idx][self.ID_INT]:
+                agent[self.ID_TARGET_POS] = self.pop[id_best_intennsity][self.ID_TARGET_POS]
+            if np.random.uniform() > self.p_c:  ## changing mask
+                agent[self.ID_MASK] = np.where(np.random.uniform(0, 1, self.problem.n_dims) < self.p_m, 0, 1)
+            pos_new = np.where(self.pop[idx][self.ID_MASK] == 0, self.pop[idx][self.ID_TARGET_POS],
+                               self.pop[np.random.randint(0, self.pop_size)][self.ID_POS])
+            ## Perform random walk
+            pos_new = self.pop[idx][self.ID_POS] + np.random.normal() * \
+                      (self.pop[idx][self.ID_POS] - self.pop[idx][self.ID_PREV_MOVE_VEC]) + \
+                      (pos_new - self.pop[idx][self.ID_POS]) * np.random.normal()
+            agent[self.ID_POS] = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            if self.mode not in self.AVAILABLE_MODES:
+                agent[self.ID_TAR] = self.get_target_wrapper(agent[self.ID_POS])
+                pop_new.append(agent)
+        pop_new = self.update_target_wrapper_population(pop_new)
+
+        for idx in range(0, self.pop_size):
+            if self.compare_agent(pop_new[idx], self.pop[idx]):
+                self.pop[idx][self.ID_PREV_MOVE_VEC] = pop_new[idx][self.ID_POS] - self.pop[idx][self.ID_POS]
+                self.pop[idx][self.ID_INT] = np.log(1. / (abs(pop_new[idx][self.ID_TAR][self.ID_FIT]) + self.EPSILON) + 1)
+                self.pop[idx][self.ID_POS] = pop_new[idx][self.ID_POS]
+                self.pop[idx][self.ID_TAR] = pop_new[idx][self.ID_TAR]
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/STO.py` & `mealpy-2.5.3a1/mealpy/swarm_based/STO.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,102 +1,106 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 22:00, 11/03/2023 ----------%
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalSTO(Optimizer):
-    """
-    The original version of: Siberian Tiger Optimization (STO)
-
-    Links:
-        1. https://ieeexplore.ieee.org/abstract/document/9989374
-        2. https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9989374
-
-    Notes:
-        1. This is somewhat concerning, as there appears to be a high degree of similarity between the source code for this algorithm and the Osprey Optimization Algorithm (OOA)
-        2. Algorithm design is similar to Zebra Optimization Algorithm (ZOA), Osprey Optimization Algorithm (OOA), Coati Optimization Algorithm (CoatiOA), Northern Goshawk Optimization (NGO), Language Education Optimization (LEO), Serval Optimization Algorithm (SOA), Walrus Optimization Algorithm (WOA), Fennec Fox Optimization (FFO), Three-periods optimization algorithm (TPOA), Teamwork optimization algorithm (TOA), Pelican Optimization Algorithm (POA), Tasmanian devil optimization (TDO), Archery algorithm (AA), Cat and mouse based optimizer (CMBO)
-        3. It may be useful to compare the Matlab code of this algorithm with those of the similar algorithms to ensure its accuracy and completeness.
-        4. The article may share some similarities with previous work by the same authors, further investigation may be warranted to verify the benchmark results reported in the papers and ensure their reliability and accuracy.
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.STO import OriginalSTO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalSTO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] TrojovskÃ½, P., Dehghani, M., & HanuÅ¡, P. (2022). Siberian Tiger Optimization: A New Bio-Inspired
-    Metaheuristic Algorithm for Solving Engineering Optimization Problems. IEEE Access, 10, 132396-132431.
-    """
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.support_parallel_modes = False
-        self.sort_flag = False
-
-    def get_indexes_better__(self, pop, idx):
-        fits = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in self.pop])
-        if self.problem.minmax == "min":
-            idxs = np.where(fits < pop[idx][self.ID_TAR][self.ID_FIT])
-        else:
-            idxs = np.where(fits > pop[idx][self.ID_TAR][self.ID_FIT])
-        return idxs[0]
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        for idx in range(0, self.pop_size):
-            # PHASE 1: PREY HUNTING
-            idxs = self.get_indexes_better__(self.pop, idx)
-            if len(idxs) == 0:
-                sf = self.g_best
-            else:
-                if np.random.rand() < 0.5:
-                    sf = self.g_best
-                else:
-                    kk = np.random.permutation(idxs)[0]
-                    sf = self.pop[kk]
-            r1 = np.random.randint(1, 3)
-            pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (sf[self.ID_POS] - r1 * self.pop[idx][self.ID_POS])     # Eq. 5
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            tar_new = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
-                self.pop[idx] = [pos_new, tar_new]
-
-            # PHASE 2: CARRYING THE FISH TO THE SUITABLE POSITION (EXPLOITATION)
-            pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (self.problem.ub - self.problem.lb) / (epoch+1)     # Eq. 7
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            tar_new = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
-                self.pop[idx] = [pos_new, tar_new]
+#!/usr/bin/env python
+# Created by "Thieu" at 22:00, 11/03/2023 ----------%
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalSTO(Optimizer):
+    """
+    The original version of: Siberian Tiger Optimization (STO)
+
+    Links:
+        1. https://ieeexplore.ieee.org/abstract/document/9989374
+        2. https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9989374
+
+    Notes (Plagiarism):
+        0. This is really disgusting, because the source code for this algorithm is exact the same as the source code for Osprey Optimization Algorithm (OOA)
+        1. Algorithm design is very similar to Zebra Optimization Algorithm (ZOA), Osprey Optimization Algorithm (OOA), Coati Optimization Algorithm (CoatiOA),
+        Northern Goshawk Optimization (NGO), Language Education Optimization (LEO), Serval Optimization Algorithm (SOA), Walrus Optimization Algorithm (WOA),
+        Fennec Fox Optimization (FFO), Three-periods optimization algorithm (TPOA), Teamwork optimization algorithm (TOA), Pelican Optimization Algorithm (POA),
+        Tasmanian devil optimization (TDO), Archery algorithm (AA), Cat and mouse based optimizer (CMBO)
+        2. Check the matlab code of all above algorithms
+        2. Same authors, self-plagiarized article with kinda same algorithm with different meta-metaphors
+        4. Check the results of benchmark functions in the papers, they are mostly make up results
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.STO import OriginalSTO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalSTO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] TrojovskÃ½, P., Dehghani, M., & HanuÅ¡, P. (2022). Siberian Tiger Optimization: A New Bio-Inspired
+    Metaheuristic Algorithm for Solving Engineering Optimization Problems. IEEE Access, 10, 132396-132431.
+    """
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.support_parallel_modes = False
+        self.sort_flag = False
+
+    def get_indexes_better__(self, pop, idx):
+        fits = np.array([agent[self.ID_TAR][self.ID_FIT] for agent in self.pop])
+        if self.problem.minmax == "min":
+            idxs = np.where(fits < pop[idx][self.ID_TAR][self.ID_FIT])
+        else:
+            idxs = np.where(fits > pop[idx][self.ID_TAR][self.ID_FIT])
+        return idxs[0]
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        for idx in range(0, self.pop_size):
+            # PHASE 1: PREY HUNTING
+            idxs = self.get_indexes_better__(self.pop, idx)
+            if len(idxs) == 0:
+                sf = self.g_best
+            else:
+                if np.random.rand() < 0.5:
+                    sf = self.g_best
+                else:
+                    kk = np.random.permutation(idxs)[0]
+                    sf = self.pop[kk]
+            r1 = np.random.randint(1, 3)
+            pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (sf[self.ID_POS] - r1 * self.pop[idx][self.ID_POS])     # Eq. 5
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            tar_new = self.get_target_wrapper(pos_new)
+            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
+                self.pop[idx] = [pos_new, tar_new]
+
+            # PHASE 2: CARRYING THE FISH TO THE SUITABLE POSITION (EXPLOITATION)
+            pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (self.problem.ub - self.problem.lb) / (epoch+1)     # Eq. 7
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            tar_new = self.get_target_wrapper(pos_new)
+            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
+                self.pop[idx] = [pos_new, tar_new]
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/SeaHO.py` & `mealpy-2.5.3a1/mealpy/swarm_based/SeaHO.py`

 * *Ordering differences only*

 * *Files 17% similar despite different names*

```diff
@@ -1,129 +1,129 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 13:42, 06/03/2023 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-from math import gamma
-
-
-class OriginalSeaHO(Optimizer):
-    """
-    The original version of: Sea-Horse Optimization (SeaHO)
-
-    Links:
-        1. https://link.springer.com/article/10.1007/s10489-022-03994-3
-        2. https://www.mathworks.com/matlabcentral/fileexchange/115945-sea-horse-optimizer
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.SeaHO import OriginalSeaHO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalSeaHO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Zhao, S., Zhang, T., Ma, S., & Wang, M. (2022). Sea-horse optimizer: a novel nature-inspired
-    meta-heuristic for global optimization problems. Applied Intelligence, 1-28.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def initialize_variables(self):
-        self.uu = 0.05
-        self.vv = 0.05
-        self.ll = 0.05
-
-    def levy__(self, omega, size):
-        num = gamma(1 + omega) * np.sin(np.pi * omega/2)
-        den = gamma((1 + omega)/2) * omega* 2**((omega - 1) / 2)
-        sigma_u = (num / den) ** (1 / omega)
-        uu = np.random.normal(0, sigma_u, size)
-        vv = np.random.normal(0, 1, size)
-        zz = uu / (np.abs(vv) ** (1 / omega))
-        return zz
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # The motor behavior of sea horses
-        step_length = self.levy__(1.5, (self.pop_size, self.problem.n_dims))
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            beta = np.random.normal(0, 1, self.problem.n_dims)
-            theta = 2 * np.pi * np.random.rand(self.problem.n_dims)
-            row = self.uu * np.exp(theta * self.vv)
-            xx, yy, zz = row * np.cos(theta), row * np.sin(theta), row * theta
-            if np.random.normal(0, 1) > 0:      # Eq. 4
-                pos_new = self.pop[idx][self.ID_POS] + step_length[idx] * ((self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) * xx * yy * zz + self.g_best[self.ID_POS])
-            else:                               # Eq. 7
-                pos_new = self.pop[idx][self.ID_POS] + np.random.rand(self.problem.n_dims) * self.ll * beta * (self.g_best[self.ID_POS] - beta * self.g_best[self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-
-        # The predation behavior of sea horses
-        pop_child = []
-        alpha = (1 - (epoch+1)/self.epoch) ** (2 * (epoch+1) / self.epoch)
-        for idx in range(0, self.pop_size):
-            r1 = np.random.rand(self.problem.n_dims)
-            if np.random.rand() >= 0.1:
-                pos_new = alpha * (self.g_best[self.ID_POS] - np.random.rand(self.problem.n_dims) * pop_new[idx][self.ID_POS]) + \
-                          (1 - alpha) * self.g_best[self.ID_POS]        # Eq. 10
-            else:
-                pos_new = (1 - alpha) * (pop_new[idx][self.ID_POS] - np.random.rand(self.problem.n_dims) * self.g_best[self.ID_POS])  + \
-                        alpha * pop_new[idx][self.ID_POS]               # Eq. 11
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_child.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_child[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        if self.mode in self.AVAILABLE_MODES:
-            pop_child = self.update_target_wrapper_population(pop_child)
-        pop_child, _ = self.get_global_best_solution(pop_child)         # Sorted population
-
-        # The reproductive behavior of sea horses
-        dads = pop_child[:int(self.pop_size/2)]
-        moms = pop_child[int(self.pop_size/2):]
-        pop_offspring = []
-        for kdx in range(0, int(self.pop_size/2)):
-            r3 = np.random.rand()
-            pos_new = r3 * dads[kdx][self.ID_POS] + (1 - r3) * moms[kdx][self.ID_POS]       # Eq. 13
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_offspring.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_offspring[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        if self.mode in self.AVAILABLE_MODES:
-            pop_offspring = self.update_target_wrapper_population(pop_offspring)
-
-        # Sea horses selection
-        self.pop = self.get_sorted_strim_population(pop_child + pop_offspring, self.pop_size)
+#!/usr/bin/env python
+# Created by "Thieu" at 13:42, 06/03/2023 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+from math import gamma
+
+
+class OriginalSeaHO(Optimizer):
+    """
+    The original version of: Sea-Horse Optimization (SeaHO)
+
+    Links:
+        1. https://link.springer.com/article/10.1007/s10489-022-03994-3
+        2. https://www.mathworks.com/matlabcentral/fileexchange/115945-sea-horse-optimizer
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.SeaHO import OriginalSeaHO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalSeaHO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Zhao, S., Zhang, T., Ma, S., & Wang, M. (2022). Sea-horse optimizer: a novel nature-inspired
+    meta-heuristic for global optimization problems. Applied Intelligence, 1-28.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def initialize_variables(self):
+        self.uu = 0.05
+        self.vv = 0.05
+        self.ll = 0.05
+
+    def levy__(self, omega, size):
+        num = gamma(1 + omega) * np.sin(np.pi * omega/2)
+        den = gamma((1 + omega)/2) * omega* 2**((omega - 1) / 2)
+        sigma_u = (num / den) ** (1 / omega)
+        uu = np.random.normal(0, sigma_u, size)
+        vv = np.random.normal(0, 1, size)
+        zz = uu / (np.abs(vv) ** (1 / omega))
+        return zz
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # The motor behavior of sea horses
+        step_length = self.levy__(1.5, (self.pop_size, self.problem.n_dims))
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            beta = np.random.normal(0, 1, self.problem.n_dims)
+            theta = 2 * np.pi * np.random.rand(self.problem.n_dims)
+            row = self.uu * np.exp(theta * self.vv)
+            xx, yy, zz = row * np.cos(theta), row * np.sin(theta), row * theta
+            if np.random.normal(0, 1) > 0:      # Eq. 4
+                pos_new = self.pop[idx][self.ID_POS] + step_length[idx] * ((self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) * xx * yy * zz + self.g_best[self.ID_POS])
+            else:                               # Eq. 7
+                pos_new = self.pop[idx][self.ID_POS] + np.random.rand(self.problem.n_dims) * self.ll * beta * (self.g_best[self.ID_POS] - beta * self.g_best[self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+
+        # The predation behavior of sea horses
+        pop_child = []
+        alpha = (1 - (epoch+1)/self.epoch) ** (2 * (epoch+1) / self.epoch)
+        for idx in range(0, self.pop_size):
+            r1 = np.random.rand(self.problem.n_dims)
+            if np.random.rand() >= 0.1:
+                pos_new = alpha * (self.g_best[self.ID_POS] - np.random.rand(self.problem.n_dims) * pop_new[idx][self.ID_POS]) + \
+                          (1 - alpha) * self.g_best[self.ID_POS]        # Eq. 10
+            else:
+                pos_new = (1 - alpha) * (pop_new[idx][self.ID_POS] - np.random.rand(self.problem.n_dims) * self.g_best[self.ID_POS])  + \
+                        alpha * pop_new[idx][self.ID_POS]               # Eq. 11
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_child.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_child[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        if self.mode in self.AVAILABLE_MODES:
+            pop_child = self.update_target_wrapper_population(pop_child)
+        pop_child, _ = self.get_global_best_solution(pop_child)         # Sorted population
+
+        # The reproductive behavior of sea horses
+        dads = pop_child[:int(self.pop_size/2)]
+        moms = pop_child[int(self.pop_size/2):]
+        pop_offspring = []
+        for kdx in range(0, int(self.pop_size/2)):
+            r3 = np.random.rand()
+            pos_new = r3 * dads[kdx][self.ID_POS] + (1 - r3) * moms[kdx][self.ID_POS]       # Eq. 13
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_offspring.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_offspring[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        if self.mode in self.AVAILABLE_MODES:
+            pop_offspring = self.update_target_wrapper_population(pop_offspring)
+
+        # Sea horses selection
+        self.pop = self.get_sorted_strim_population(pop_child + pop_offspring, self.pop_size)
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/ServalOA.py` & `mealpy-2.5.3a1/mealpy/swarm_based/WaOA.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,85 +1,91 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 21:34, 11/03/2023 ----------%
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalServalOA(Optimizer):
-    """
-    The original version of: Serval Optimization Algorithm (ServalOA)
-
-    Links:
-        1. https://www.mdpi.com/2313-7673/7/4/204
-
-    Notes:
-        0. It's concerning that the author seems to be reusing the same algorithms with minor variations.
-        1. Algorithm design is similar to Zebra Optimization Algorithm (ZOA), Osprey Optimization Algorithm (OOA), Coati Optimization Algorithm (CoatiOA), Siberian Tiger Optimization (STO), Language Education Optimization (LEO), Pelican Optimization Algorithm (POA), Walrus Optimization Algorithm (WOA), Fennec Fox Optimization (FFO), Three-periods optimization algorithm (TPOA), Teamwork optimization algorithm (TOA), Northern goshawk optimization (NGO), Tasmanian devil optimization (TDO), Archery algorithm (AA), Cat and mouse based optimizer (CMBO)
-        3. It may be useful to compare the Matlab code of this algorithm with those of the similar algorithms to ensure its accuracy and completeness.
-        4. The article may share some similarities with previous work by the same authors, further investigation may be warranted to verify the benchmark results reported in the papers and ensure their reliability and accuracy.
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.ServalOA import OriginalServalOA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalServalOA(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Dehghani, M., & TrojovskÃ½, P. (2022). Serval Optimization Algorithm: A New Bio-Inspired
-    Approach for Solving Optimization Problems. Biomimetics, 7(4), 204.
-    """
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.support_parallel_modes = False
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        kk = np.random.permutation(self.pop_size)[0]
-        for idx in range(0, self.pop_size):
-            # Phase 1: Prey Selection and Attacking (Exploration)
-            pos_new = self.pop[idx][self.ID_POS] + np.random.rand(self.problem.n_dims) * \
-                      (self.pop[kk][self.ID_POS] - np.random.randint(1, 3, self.problem.n_dims) * self.pop[idx][self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            tar_new = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
-                self.pop[idx] = [pos_new, tar_new]
-
-            # Phase 2: Chase Process (Exploitation)
-            pos_new = self.pop[idx][self.ID_POS] + np.random.randint(1, 3, self.problem.n_dims) * (self.problem.ub - self.problem.lb) / (epoch+1)   # Eq. 6
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            tar_new = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
-                self.pop[idx] = [pos_new, tar_new]
+#!/usr/bin/env python
+# Created by "Thieu" at 23:18, 11/03/2023 ----------%
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalWaOA(Optimizer):
+    """
+    The original version of: Walrus Optimization Algorithm (WaOA)
+
+    Links:
+        1. https://www.researchgate.net/publication/364684780_Walrus_Optimization_Algorithm_A_New_Bio-Inspired_Metaheuristic_Algorithm
+
+    Notes (Plagiarism):
+        0. This is really disgusting, because the source code for this algorithm is exactly the same as the source code of Northern Goshawk Optimization (NGO)
+        1. Algorithm design is very similar to Zebra Optimization Algorithm (ZOA), Osprey Optimization Algorithm (OOA), Coati Optimization Algorithm (CoatiOA),
+        Siberian Tiger Optimization (STO), Language Education Optimization (LEO), Serval Optimization Algorithm (SOA), Northern Goshawk Optimization (NGO),
+        Fennec Fox Optimization (FFO), Three-periods optimization algorithm (TPOA), Teamwork optimization algorithm (TOA), Pelican Optimization Algorithm (POA),
+        Tasmanian devil optimization (TDO), Archery algorithm (AA), Cat and mouse based optimizer (CMBO)
+        2. Check the matlab code of all above algorithms
+        2. Same authors, self-plagiarized article with kinda same algorithm with different meta-metaphors
+        4. Check the results of benchmark functions in the papers, they are mostly make up results
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.WaOA import OriginalWaOA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalWaOA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] TrojovskÃ½, P., & Dehghani, M. (2022). Walrus Optimization Algorithm: A New Bio-Inspired Metaheuristic Algorithm.
+    """
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.support_parallel_modes = False
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        for idx in range(0, self.pop_size):
+            # Phase 1: Feeding strategy (exploration)
+            kk = np.random.permutation(self.pop_size)[0]
+            if self.compare_agent(self.pop[kk], self.pop[idx]):     # Eq. 4
+                pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (self.pop[kk][self.ID_POS] - np.random.randint(1, 3) * self.pop[idx][self.ID_POS])
+            else:
+                pos_new = self.pop[idx][self.ID_POS] + np.random.rand() * (self.pop[idx][self.ID_POS] - self.pop[kk][self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            tar_new = self.get_target_wrapper(pos_new)
+            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
+                self.pop[idx] = [pos_new, tar_new]
+
+            # PHASE 2 Exploitation
+            LB, UB = self.problem.lb / (epoch+1), self.problem.ub / (epoch + 1)
+            pos_new = self.pop[idx][self.ID_POS] + LB + (UB - np.random.rand() * LB)     # Eq. 7
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            tar_new = self.get_target_wrapper(pos_new)
+            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
+                self.pop[idx] = [pos_new, tar_new]
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/TDO.py` & `mealpy-2.5.3a1/mealpy/swarm_based/ZOA.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,104 +1,106 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 00:08, 27/10/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalTDO(Optimizer):
-    """
-    The original version of: Tasmanian Devil Optimization (TDO)
-
-    Links:
-        1. https://www.mathworks.com/matlabcentral/fileexchange/111380-tasmanian-devil-optimization-tdo
-        2. https://ieeexplore.ieee.org/abstract/document/9714388
-
-    Notes:
-        1. This is somewhat concerning, as there appears to be a high degree of similarity between the source code for this algorithm and the Osprey Optimization Algorithm (OOA)
-        2. Algorithm design is similar to Zebra Optimization Algorithm (ZOA), Osprey Optimization Algorithm (OOA), Pelican optimization algorithm (POA), Siberian Tiger Optimization (STO), Language Education Optimization (LEO), Serval Optimization Algorithm (SOA), Walrus Optimization Algorithm (WOA), Fennec Fox Optimization (FFO), Three-periods optimization algorithm (TPOA), Teamwork optimization algorithm (TOA), Northern goshawk optimization (NGO), Osprey Optimization Algorithm (OOA), Archery algorithm (AA), Cat and mouse based optimizer (CMBO)
-        3. It may be useful to compare the Matlab code of this algorithm with those of the similar algorithms to ensure its accuracy and completeness.
-        4. The article may share some similarities with previous work by the same authors, further investigation may be warranted to verify the benchmark results reported in the papers and ensure their reliability and accuracy.
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.TDO import OriginalTDO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalTDO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Dehghani, M., HubÃ¡lovskÃ½, Å ., & TrojovskÃ½, P. (2022). Tasmanian devil optimization: a new bio-inspired
-    optimization algorithm for solving optimization algorithm. IEEE Access, 10, 19599-19620.
-    """
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.support_parallel_modes = False
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        for idx in range(0, self.pop_size):
-            # PHASE1: Hunting Feeding
-            if np.random.rand() > 0.5:
-                # STRATEGY 1: FEEDING BY EATING CARRION (EXPLORATION PHASE)
-                # CARRION selection using (3)
-                kk = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
-                if self.compare_agent(self.pop[kk], self.pop[idx]):
-                    pos_new = self.pop[idx][self.ID_POS] + np.random.rand(self.problem.n_dims) * (self.pop[kk][self.ID_POS] - np.random.randint(1, 3)*self.pop[idx][self.ID_POS])
-                else:
-                    pos_new = self.pop[idx][self.ID_POS] + np.random.rand(self.problem.n_dims) * (self.pop[idx][self.ID_POS] - self.pop[kk][self.ID_POS])
-                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                tar_new = self.get_target_wrapper(pos_new)
-                if self.compare_agent([pos_new, tar_new], self.pop[idx]):
-                    self.pop[idx] = [pos_new, tar_new]
-            else:
-            # STRATEGY 2: FEEDING BY EATING PREY (EXPLOITATION PHASE)
-            # stage1: prey selection and attack it
-                kk = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
-                if self.compare_agent(self.pop[kk], self.pop[idx]):
-                    pos_new = self.pop[idx][self.ID_POS] + np.random.rand(self.problem.n_dims) * (self.pop[kk][self.ID_POS] - np.random.randint(1, 3) * self.pop[idx][self.ID_POS])
-                else:
-                    pos_new = self.pop[idx][self.ID_POS] + np.random.rand(self.problem.n_dims) * (self.pop[idx][self.ID_POS] - self.pop[kk][self.ID_POS])
-                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                tar_new = self.get_target_wrapper(pos_new)
-                if self.compare_agent([pos_new, tar_new], self.pop[idx]):
-                    self.pop[idx] = [pos_new, tar_new]
-
-            # stage2: prey chasing
-            rr = 0.01 * (1 - (epoch+1)/self.epoch)      # Calculating the neighborhood radius using(9)
-            pos_new = self.pop[idx][self.ID_POS] + (-rr + 2 * rr * np.random.rand(self.problem.n_dims)) * self.pop[idx][self.ID_POS]
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            tar_new = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, tar_new], self.pop[idx]):
-                self.pop[idx] = [pos_new, tar_new]
+#!/usr/bin/env python
+# Created by "Thieu" at 00:08, 27/10/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalZOA(Optimizer):
+    """
+    The original version of: Zebra Optimization Algorithm (ZOA)
+
+    Links:
+        1. https://ieeexplore.ieee.org/document/9768820
+        2. https://www.mathworks.com/matlabcentral/fileexchange/122942-zebra-optimization-algorithm-zoa
+
+    Notes (Plagiarism):
+        1. Algorithm design is very similar to Zebra Optimization Algorithm (ZOA), Osprey Optimization Algorithm (OOA), Pelican optimization algorithm (POA),
+        Siberian Tiger Optimization (STO), Language Education Optimization (LEO), Serval Optimization Algorithm (SOA), Walrus Optimization Algorithm (WOA),
+        Fennec Fox Optimization (FFO), Three-periods optimization algorithm (TPOA), Teamwork optimization algorithm (TOA), Northern goshawk optimization (NGO),
+        Tasmanian devil optimization (TDO), Archery algorithm (AA), Cat and mouse based optimizer (CMBO)
+        2. Check the matlab code of all above algorithms
+        2. Same authors, self-plagiarized article with kinda same algorithm with different meta-metaphors
+        4. Check the results of benchmark functions in the papers, they are mostly make up results
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.ZOA import OriginalZOA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalZOA(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] TrojovskÃ¡, E., Dehghani, M., & TrojovskÃ½, P. (2022). Zebra optimization algorithm: A new bio-inspired
+    optimization algorithm for solving optimization algorithm. IEEE Access, 10, 49445-49473.
+    """
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # PHASE1: Foraging Behaviour
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            r1 = np.round(1 + np.random.rand())
+            pos_new = self.pop[idx][self.ID_POS] + np.random.rand(self.problem.n_dims) * (self.g_best[self.ID_POS] - r1 * self.pop[idx][self.ID_POS])   # Eq. 3
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+        # PHASE2: defense strategies against predators
+        kk = np.random.permutation(self.pop_size)[0]
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            if np.random.rand() < 0.5:
+                # S1: the lion attacks the zebra and thus the zebra chooses an escape strategy
+                r2 = 0.1
+                pos_new = self.pop[idx][self.ID_POS] + r2 * (2 + np.random.rand(self.problem.n_dims) - 1) * (1 - (epoch+1)/self.epoch)*self.pop[idx][self.ID_POS]
+            else:
+                # S2: other predators attack the zebra and the zebra will choose the offensive strategy
+                r2 = np.random.randint(1, 3)
+                pos_new = self.pop[idx][self.ID_POS] + np.random.rand(self.problem.n_dims) * (self.pop[kk][self.ID_POS] - r2 * self.pop[idx][self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/TSO.py` & `mealpy-2.5.3a1/mealpy/swarm_based/TSO.py`

 * *Ordering differences only*

 * *Files 9% similar despite different names*

```diff
@@ -1,129 +1,129 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 17:52, 21/05/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalTSO(Optimizer):
-    """
-    The original version of: Tuna Swarm Optimization (TSO)
-
-    Links:
-        1. https://www.hindawi.com/journals/cin/2021/9210050/
-        2. https://www.mathworks.com/matlabcentral/fileexchange/101734-tuna-swarm-optimization
-
-    Notes:
-        1. Two variables that authors consider it as a constants (aa = 0.7 and zz = 0.05)
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.TSO import OriginalTSO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalTSO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Xie, L., Han, T., Zhou, H., Zhang, Z. R., Han, B., & Tang, A. (2021). Tuna swarm optimization: a novel swarm-based
-    metaheuristic algorithm for global optimization. Computational intelligence and Neuroscience, 2021.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.P = np.arange(1, 361)
-        self.sort_flag = True
-
-    def initialize_variables(self):
-        self.aa = 0.7
-        self.zz = 0.05
-
-    def get_new_local_pos__(self, C, a1, a2, t, epoch):
-        if np.random.rand() < self.zz:
-            local_pos = self.generate_position(self.problem.lb, self.problem.ub)
-        else:
-            if np.random.rand() < 0.5:
-                r1 = np.random.rand()
-                beta = np.exp(r1 * np.exp(3*np.cos(np.pi*((self.epoch - epoch) / self.epoch)))) * np.cos(2*np.pi*r1)
-                if np.random.rand() < C:
-                    local_pos = a1*(self.g_best[self.ID_POS] + beta * np.abs(self.g_best[self.ID_POS] - self.pop[0][self.ID_POS])) + \
-                        a2 * self.pop[0][self.ID_POS]       # Equation (8.3)
-                else:
-                    rand_pos = self.generate_position(self.problem.lb, self.problem.ub)
-                    local_pos = a1 * (rand_pos + beta*np.abs(rand_pos - self.pop[0][self.ID_POS])) + a2 * self.pop[0][self.ID_POS]  # Equation (8.1)
-            else:
-                tf = np.random.choice([-1, 1])
-                if np.random.rand() < 0.5:
-                    local_pos = tf * t**2 * self.pop[0][self.ID_POS]        # Eq 9.2
-                else:
-                    local_pos = self.g_best[self.ID_POS] + np.random.rand(self.problem.n_dims) * (self.g_best[self.ID_POS] - self.pop[0][self.ID_POS]) + \
-                        tf * t**2 * (self.g_best[self.ID_POS] - self.pop[0][self.ID_POS])
-        return local_pos
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        C = (epoch + 1) / self.epoch
-        a1 = self.aa + (1 - self.aa) * C
-        a2 = (1 - self.aa) - (1 - self.aa) * C
-        t = (1 - (epoch+1) / self.epoch) ** ((epoch+1) / self.epoch)
-
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            if idx == 0:
-                pos_new = self.get_new_local_pos__(C, a1, a2, t, epoch)
-            else:
-                if np.random.rand() < self.zz:
-                    pos_new = self.generate_position(self.problem.lb, self.problem.ub)
-                else:
-                    if np.random.rand() > 0.5:
-                        r1 = np.random.rand()
-                        beta = np.exp(r1 * np.exp(3*np.cos(np.pi * (self.epoch - epoch)/self.epoch))) * np.cos(2*np.pi*r1)
-                        if np.random.rand() < C:
-                            pos_new = a1 * (self.g_best[self.ID_POS] + beta*np.abs(self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])) + \
-                                a2 * self.pop[idx-1][self.ID_POS]       # Eq. 8.4
-                        else:
-                            rand_pos = self.generate_position(self.problem.lb, self.problem.ub)
-                            pos_new = a1 * (rand_pos + beta*np.abs(rand_pos - self.pop[idx][self.ID_POS])) + a2 * self.pop[idx-1][self.ID_POS]  # Eq 8.2
-                    else:
-                        tf = np.random.choice([-1, 1])
-                        if np.random.rand() < 0.5:
-                            pos_new = self.g_best[self.ID_POS] + \
-                                      np.random.rand(self.problem.n_dims) * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) +\
-                                      tf * t**2 * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])       # Eq 9.1
-                        else:
-                            pos_new = tf * t**2 * self.pop[idx][self.ID_POS]        # Eq 9.2
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        self.pop = self.update_target_wrapper_population(pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 17:52, 21/05/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalTSO(Optimizer):
+    """
+    The original version of: Tuna Swarm Optimization (TSO)
+
+    Links:
+        1. https://www.hindawi.com/journals/cin/2021/9210050/
+        2. https://www.mathworks.com/matlabcentral/fileexchange/101734-tuna-swarm-optimization
+
+    Notes:
+        1. Two variables that authors consider it as a constants (aa = 0.7 and zz = 0.05)
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.TSO import OriginalTSO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalTSO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Xie, L., Han, T., Zhou, H., Zhang, Z. R., Han, B., & Tang, A. (2021). Tuna swarm optimization: a novel swarm-based
+    metaheuristic algorithm for global optimization. Computational intelligence and Neuroscience, 2021.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.P = np.arange(1, 361)
+        self.sort_flag = True
+
+    def initialize_variables(self):
+        self.aa = 0.7
+        self.zz = 0.05
+
+    def get_new_local_pos__(self, C, a1, a2, t, epoch):
+        if np.random.rand() < self.zz:
+            local_pos = self.generate_position(self.problem.lb, self.problem.ub)
+        else:
+            if np.random.rand() < 0.5:
+                r1 = np.random.rand()
+                beta = np.exp(r1 * np.exp(3*np.cos(np.pi*((self.epoch - epoch) / self.epoch)))) * np.cos(2*np.pi*r1)
+                if np.random.rand() < C:
+                    local_pos = a1*(self.g_best[self.ID_POS] + beta * np.abs(self.g_best[self.ID_POS] - self.pop[0][self.ID_POS])) + \
+                        a2 * self.pop[0][self.ID_POS]       # Equation (8.3)
+                else:
+                    rand_pos = self.generate_position(self.problem.lb, self.problem.ub)
+                    local_pos = a1 * (rand_pos + beta*np.abs(rand_pos - self.pop[0][self.ID_POS])) + a2 * self.pop[0][self.ID_POS]  # Equation (8.1)
+            else:
+                tf = np.random.choice([-1, 1])
+                if np.random.rand() < 0.5:
+                    local_pos = tf * t**2 * self.pop[0][self.ID_POS]        # Eq 9.2
+                else:
+                    local_pos = self.g_best[self.ID_POS] + np.random.rand(self.problem.n_dims) * (self.g_best[self.ID_POS] - self.pop[0][self.ID_POS]) + \
+                        tf * t**2 * (self.g_best[self.ID_POS] - self.pop[0][self.ID_POS])
+        return local_pos
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        C = (epoch + 1) / self.epoch
+        a1 = self.aa + (1 - self.aa) * C
+        a2 = (1 - self.aa) - (1 - self.aa) * C
+        t = (1 - (epoch+1) / self.epoch) ** ((epoch+1) / self.epoch)
+
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            if idx == 0:
+                pos_new = self.get_new_local_pos__(C, a1, a2, t, epoch)
+            else:
+                if np.random.rand() < self.zz:
+                    pos_new = self.generate_position(self.problem.lb, self.problem.ub)
+                else:
+                    if np.random.rand() > 0.5:
+                        r1 = np.random.rand()
+                        beta = np.exp(r1 * np.exp(3*np.cos(np.pi * (self.epoch - epoch)/self.epoch))) * np.cos(2*np.pi*r1)
+                        if np.random.rand() < C:
+                            pos_new = a1 * (self.g_best[self.ID_POS] + beta*np.abs(self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])) + \
+                                a2 * self.pop[idx-1][self.ID_POS]       # Eq. 8.4
+                        else:
+                            rand_pos = self.generate_position(self.problem.lb, self.problem.ub)
+                            pos_new = a1 * (rand_pos + beta*np.abs(rand_pos - self.pop[idx][self.ID_POS])) + a2 * self.pop[idx-1][self.ID_POS]  # Eq 8.2
+                    else:
+                        tf = np.random.choice([-1, 1])
+                        if np.random.rand() < 0.5:
+                            pos_new = self.g_best[self.ID_POS] + \
+                                      np.random.rand(self.problem.n_dims) * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) +\
+                                      tf * t**2 * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])       # Eq 9.1
+                        else:
+                            pos_new = tf * t**2 * self.pop[idx][self.ID_POS]        # Eq 9.2
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        self.pop = self.update_target_wrapper_population(pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/WOA.py` & `mealpy-2.5.3a1/mealpy/physics_based/MVO.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,201 +1,223 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 10:06, 17/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalWOA(Optimizer):
-    """
-    The original version of: Whale Optimization Algorithm (WOA)
-
-    Links:
-        1. https://doi.org/10.1016/j.advengsoft.2016.01.008
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.WOA import OriginalWOA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalWOA(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Mirjalili, S. and Lewis, A., 2016. The whale optimization algorithm.
-    Advances in engineering software, 95, pp.51-67.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        a = 2 - 2 * epoch / (self.epoch - 1)  # linearly decreased from 2 to 0
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            r = np.random.rand()
-            A = 2 * a * r - a
-            C = 2 * r
-            l = np.random.uniform(-1, 1)
-            p = 0.5
-            b = 1
-            if np.random.uniform() < p:
-                if np.abs(A) < 1:
-                    D = np.abs(C * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-                    pos_new = self.g_best[self.ID_POS] - A * D
-                else:
-                    # x_rand = pop[np.random.np.random.randint(self.pop_size)]         # select random 1 position in pop
-                    x_rand = self.create_solution(self.problem.lb, self.problem.ub)
-                    D = np.abs(C * x_rand[self.ID_POS] - self.pop[idx][self.ID_POS])
-                    pos_new = x_rand[self.ID_POS] - A * D
-            else:
-                D1 = np.abs(self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-                pos_new = self.g_best[self.ID_POS] + np.exp(b * l) * np.cos(2 * np.pi * l) * D1
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            print(len(pop_new))
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-
-class HI_WOA(Optimizer):
-    """
-    The original version of: Hybrid Improved Whale Optimization Algorithm (HI-WOA)
-
-    Links:
-        1. https://ieenp.explore.ieee.org/document/8900003
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + feedback_max (int): maximum iterations of each feedback, default = 10
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.WOA import HI_WOA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> feedback_max = 10
-    >>> model = HI_WOA(epoch, pop_size, feedback_max)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Tang, C., Sun, W., Wu, W. and Xue, M., 2019, July. A hybrid improved whale optimization algorithm.
-    In 2019 IEEE 15th International Conference on Control and Automation (ICCA) (pp. 362-367). IEEE.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, feedback_max=10, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            feedback_max (int): maximum iterations of each feedback, default = 10
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.feedback_max = self.validator.check_int("feedback_max", feedback_max, [2, 2+int(self.epoch/2)])
-        # The maximum of times g_best doesn't change -> need to change half of population
-        self.set_parameters(["epoch", "pop_size", "feedback_max"])
-        self.sort_flag = True
-
-    def initialize_variables(self):
-        self.n_changes = int(self.pop_size / 2)
-        self.dyn_feedback_count = 0
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        a = 2 + 2 * np.cos(np.pi / 2 * (1 + epoch / self.epoch))  # Eq. 8
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            r = np.random.rand()
-            A = 2 * a * r - a
-            C = 2 * r
-            l = np.random.uniform(-1, 1)
-            p = 0.5
-            b = 1
-            if np.random.uniform() < p:
-                if np.abs(A) < 1:
-                    D = np.abs(C * self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-                    pos_new = self.g_best[self.ID_POS] - A * D
-                else:
-                    # x_rand = pop[np.random.np.random.randint(self.pop_size)]         # select random 1 position in pop
-                    x_rand = self.create_solution(self.problem.lb, self.problem.ub)
-                    D = np.abs(C * x_rand[self.ID_POS] - self.pop[idx][self.ID_POS])
-                    pos_new = x_rand[self.ID_POS] - A * D
-            else:
-                D1 = np.abs(self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
-                pos_new = self.g_best[self.ID_POS] + np.exp(b * l) * np.cos(2 * np.pi * l) * D1
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution(self.pop[idx], [pos_new, target])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-        ## Feedback Mechanism
-        _, current_best = self.get_global_best_solution(self.pop)
-        if current_best[self.ID_TAR][self.ID_FIT] == self.g_best[self.ID_TAR][self.ID_FIT]:
-            self.dyn_feedback_count += 1
-        else:
-            self.dyn_feedback_count = 0
-
-        if self.dyn_feedback_count >= self.feedback_max:
-            idx_list = np.random.choice(range(0, self.pop_size), self.n_changes, replace=False)
-            pop_child = self.create_population(self.n_changes)
-            for idx_counter, idx in enumerate(idx_list):
-                self.pop[idx] = pop_child[idx_counter]
+#!/usr/bin/env python
+# Created by "Thieu" at 21:19, 17/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class BaseMVO(Optimizer):
+    """
+    The developed version: Multi-Verse Optimizer (MVO)
+
+    Notes
+    ~~~~~
+    + New routtele wheel selection can handle negative values
+    + Removed condition when np.random.normalize fitness. So the chance to choose while whole higher --> better
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + wep_min (float): [0.05, 0.3], Wormhole Existence Probability (min in Eq.(3.3) paper, default = 0.2
+        + wep_max (float: [0.75, 1.0], Wormhole Existence Probability (max in Eq.(3.3) paper, default = 1.0
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.physics_based.MVO import BaseMVO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> wep_min = 0.2
+    >>> wep_max = 1.0
+    >>> model = BaseMVO(epoch, pop_size, wep_min, wep_max)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, wep_min=0.2, wep_max=1.0, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            wep_min (float): Wormhole Existence Probability (min in Eq.(3.3) paper, default = 0.2
+            wep_max (float: Wormhole Existence Probability (max in Eq.(3.3) paper, default = 1.0
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.wep_min = self.validator.check_float("wep_min", wep_min, (0, 0.5))
+        self.wep_max = self.validator.check_float("wep_max", wep_max, [0.5, 3.0])
+        self.set_parameters(["epoch", "pop_size", "wep_min", "wep_max"])
+        self.sort_flag = True
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # Eq. (3.3) in the paper
+        wep = self.wep_max - (epoch + 1) * ((self.wep_max - self.wep_min) / self.epoch)
+
+        # Travelling Distance Rate (Formula): Eq. (3.4) in the paper
+        tdr = 1 - (epoch + 1) ** (1.0 / 6) / self.epoch ** (1.0 / 6)
+
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            if np.random.uniform() < wep:
+                list_fitness = np.array([item[self.ID_TAR][self.ID_FIT] for item in self.pop])
+                white_hole_id = self.get_index_roulette_wheel_selection(list_fitness)
+                black_hole_pos_1 = self.pop[idx][self.ID_POS] + tdr * np.random.normal(0, 1) * \
+                                   (self.pop[white_hole_id][self.ID_POS] - self.pop[idx][self.ID_POS])
+                black_hole_pos_2 = self.g_best[self.ID_POS] + tdr * np.random.normal(0, 1) * (self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS])
+                black_hole_pos = np.where(np.random.random(self.problem.n_dims) < 0.5, black_hole_pos_1, black_hole_pos_2)
+            else:
+                black_hole_pos = self.generate_position(self.problem.lb, self.problem.ub)
+            pos_new = self.amend_position(black_hole_pos, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+
+
+class OriginalMVO(BaseMVO):
+    """
+    The original version of: Multi-Verse Optimizer (MVO)
+
+    Links:
+        1. https://dx.doi.org/10.1007/s00521-015-1870-7
+        2. https://www.mathworks.com/matlabcentral/fileexchange/50112-multi-verse-optimizer-mvo
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + wep_min (float): [0.05, 0.3], Wormhole Existence Probability (min in Eq.(3.3) paper, default = 0.2
+        + wep_max (float: [0.75, 1.0], Wormhole Existence Probability (max in Eq.(3.3) paper, default = 1.0
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.physics_based.MVO import OriginalMVO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> wep_min = 0.2
+    >>> wep_max = 1.0
+    >>> model = OriginalMVO(epoch, pop_size, wep_min, wep_max)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Mirjalili, S., Mirjalili, S.M. and Hatamlou, A., 2016. Multi-verse optimizer: a nature-inspired
+    algorithm for global optimization. Neural Computing and Applications, 27(2), pp.495-513.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, wep_min=0.2, wep_max=1.0, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            wep_min (float): Wormhole Existence Probability (min in Eq.(3.3) paper, default = 0.2
+            wep_max (float: Wormhole Existence Probability (max in Eq.(3.3) paper, default = 1.0
+        """
+        super().__init__(epoch, pop_size, wep_min, wep_max, **kwargs)
+
+    # sorted_inflation_rates
+    def roulette_wheel_selection__(self, weights=None):
+        accumulation = np.cumsum(weights)
+        p = np.random.uniform() * accumulation[-1]
+        chosen_idx = None
+        for idx in range(len(accumulation)):
+            if accumulation[idx] > p:
+                chosen_idx = idx
+                break
+        return chosen_idx
+
+    def normalize__(self, d, to_sum=True):
+        # d is a (n x dimension) np np.array
+        d -= np.min(d, axis=0)
+        if to_sum:
+            total_vector = np.sum(d, axis=0)
+            if 0 in total_vector:
+                return np.random.uniform(0.2, 0.8, self.pop_size)
+            return d / np.sum(d, axis=0)
+        else:
+            ptp_vector = np.ptp(d, axis=0)
+            if 0 in ptp_vector:
+                return np.random.uniform(0.2, 0.8, self.pop_size)
+            return d / np.ptp(d, axis=0)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # Eq. (3.3) in the paper
+        wep = self.wep_min + (epoch + 1) * ((self.wep_max - self.wep_min) / self.epoch)
+
+        # Travelling Distance Rate (Formula): Eq. (3.4) in the paper
+        tdr = 1 - (epoch + 1) ** (1.0 / 6) / self.epoch ** (1.0 / 6)
+
+        list_fitness_raw = np.array([item[self.ID_TAR][self.ID_FIT] for item in self.pop])
+        maxx = max(list_fitness_raw)
+        if maxx > (2 ** 64 - 1):
+            list_fitness_normalized = np.random.uniform(0, 0.1, self.pop_size)
+        else:
+            ### Normalize inflation rates (NI in Eq. (3.1) in the paper)
+            list_fitness_normalized = np.reshape(self.normalize__(np.array([list_fitness_raw])), self.pop_size)  # Matrix
+
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            black_hole_pos = deepcopy(self.pop[idx][self.ID_POS])
+            for j in range(0, self.problem.n_dims):
+                r1 = np.random.uniform()
+                if r1 < list_fitness_normalized[idx]:
+                    white_hole_id = self.roulette_wheel_selection__((-1 * list_fitness_raw))
+                    if white_hole_id == None or white_hole_id == -1:
+                        white_hole_id = 0
+                    # Eq. (3.1) in the paper
+                    black_hole_pos[j] = self.pop[white_hole_id][self.ID_POS][j]
+
+                # Eq. (3.2) in the paper if the boundaries are all the same
+                r2 = np.random.uniform()
+                if r2 < wep:
+                    r3 = np.random.uniform()
+                    if r3 < 0.5:
+                        black_hole_pos[j] = self.g_best[self.ID_POS][j] + tdr * np.random.uniform(self.problem.lb[j], self.problem.ub[j])
+                    else:
+                        black_hole_pos[j] = self.g_best[self.ID_POS][j] - tdr * np.random.uniform(self.problem.lb[j], self.problem.ub[j])
+            pos_new = self.amend_position(black_hole_pos, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/swarm_based/ZOA.py` & `mealpy-2.5.3a1/mealpy/swarm_based/AGTO.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,103 +1,121 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 00:08, 27/10/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalZOA(Optimizer):
-    """
-    The original version of: Zebra Optimization Algorithm (ZOA)
-
-    Links:
-        1. https://ieeexplore.ieee.org/document/9768820
-        2. https://www.mathworks.com/matlabcentral/fileexchange/122942-zebra-optimization-algorithm-zoa
-
-    Notes:
-		1. It's concerning that the author seems to be reusing the same algorithms with minor variations.
-        2. Algorithm design is similar to Zebra Optimization Algorithm (ZOA), Osprey Optimization Algorithm (OOA), Pelican optimization algorithm (POA), Siberian Tiger Optimization (STO), Language Education Optimization (LEO), Serval Optimization Algorithm (SOA), Walrus Optimization Algorithm (WOA), Fennec Fox Optimization (FFO), Three-periods optimization algorithm (TPOA), Teamwork optimization algorithm (TOA), Northern goshawk optimization (NGO), Tasmanian devil optimization (TDO), Archery algorithm (AA), Cat and mouse based optimizer (CMBO).
-        3. It may be useful to compare the Matlab code of this algorithm with those of the similar algorithms to ensure its accuracy and completeness.
-        4. The article may share some similarities with previous work by the same authors, further investigation may be warranted to verify the benchmark results reported in the papers and ensure their reliability and accuracy.
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.ZOA import OriginalZOA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalZOA(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] TrojovskÃ¡, E., Dehghani, M., & TrojovskÃ½, P. (2022). Zebra optimization algorithm: A new bio-inspired
-    optimization algorithm for solving optimization algorithm. IEEE Access, 10, 49445-49473.
-    """
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # PHASE1: Foraging Behaviour
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            r1 = np.round(1 + np.random.rand())
-            pos_new = self.pop[idx][self.ID_POS] + np.random.rand(self.problem.n_dims) * (self.g_best[self.ID_POS] - r1 * self.pop[idx][self.ID_POS])   # Eq. 3
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
-
-        # PHASE2: defense strategies against predators
-        kk = np.random.permutation(self.pop_size)[0]
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            if np.random.rand() < 0.5:
-                # S1: the lion attacks the zebra and thus the zebra chooses an escape strategy
-                r2 = 0.1
-                pos_new = self.pop[idx][self.ID_POS] + r2 * (2 + np.random.rand(self.problem.n_dims) - 1) * (1 - (epoch+1)/self.epoch)*self.pop[idx][self.ID_POS]
-            else:
-                # S2: other predators attack the zebra and the zebra will choose the offensive strategy
-                r2 = np.random.randint(1, 3)
-                pos_new = self.pop[idx][self.ID_POS] + np.random.rand(self.problem.n_dims) * (self.pop[kk][self.ID_POS] - r2 * self.pop[idx][self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop = self.greedy_selection_population(self.pop, pop_new)
+#!/usr/bin/env python
+# Created by "Thieu" at 00:08, 27/10/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalAGTO(Optimizer):
+    """
+    The original version of: Artificial Gorilla Troops Optimization (AGTO)
+
+    Links:
+        1. https://doi.org/10.1002/int.22535
+        2. https://www.mathworks.com/matlabcentral/fileexchange/95953-artificial-gorilla-troops-optimizer
+
+    Notes (parameters):
+        1. p1 (float): the probability of transition in exploration phase (p in the paper), default = 0.03
+        2. p2 (float): the probability of transition in exploitation phase (w in the paper), default = 0.8
+        3. beta (float): coefficient in updating equation, should be in [-5.0, 5.0], default = 3.0
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.AGTO import OriginalAGTO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalAGTO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Abdollahzadeh, B., Soleimanian Gharehchopogh, F., & Mirjalili, S. (2021). Artificial gorilla troops optimizer: a new
+    natureâinspired metaheuristic algorithm for global optimization problems. International Journal of Intelligent Systems, 36(10), 5887-5958.
+    """
+    def __init__(self, epoch=10000, pop_size=100, p1=0.03, p2=0.8, beta=3.0, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.p1 = self.validator.check_float("p1", p1, (0, 1))      # p in the paper
+        self.p2 = self.validator.check_float("p2", p2, (0, 1))      # w in the paper
+        self.beta = self.validator.check_float("beta", beta, [-10.0, 10.0])
+        self.set_parameters(["epoch", "pop_size", "p1", "p2", "beta"])
+        self.sort_flag = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        a = (np.cos(2*np.random.rand())+1) * (1 - (epoch+1)/self.epoch)
+        c = a * (2 * np.random.rand() - 1)
+
+        ## Exploration
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            if np.random.rand() < self.p1:
+                pos_new = self.generate_position(self.problem.lb, self.problem.ub)
+            else:
+                if np.random.rand() >= 0.5:
+                    z = np.random.uniform(-a, a, self.problem.n_dims)
+                    rand_idx = np.random.randint(0, self.pop_size)
+                    pos_new = (np.random.rand() - a) * self.pop[rand_idx][self.ID_POS] + c * z * self.pop[idx][self.ID_POS]
+                else:
+                    id1, id2 = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 2, replace=False)
+                    pos_new = self.pop[idx][self.ID_POS] - c*(c*self.pop[idx][self.ID_POS] - self.pop[id1][self.ID_POS]) + \
+                        np.random.rand() * (self.pop[idx][self.ID_POS] - self.pop[id2][self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
+        _, self.g_best = self.update_global_best_solution(self.pop, save=False)
+
+        pos_list = np.array([agent[self.ID_POS] for agent in self.pop])
+        ## Exploitation
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            if a >= self.p2:
+                g = 2 ** c
+                delta = (np.abs(np.mean(pos_list, axis=0)) ** g) ** (1.0 / g)
+                pos_new = c*delta*(self.pop[idx][self.ID_POS] - self.g_best[self.ID_POS]) + self.pop[idx][self.ID_POS]
+            else:
+                if np.random.rand() >= 0.5:
+                    h = np.random.normal(0, 1, self.problem.n_dims)
+                else:
+                    h = np.random.normal(0, 1)
+                r1 = np.random.rand()
+                pos_new = self.g_best[self.ID_POS] - (2*r1-1)*(self.g_best[self.ID_POS] - self.pop[idx][self.ID_POS]) * (self.beta * h)
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop = self.greedy_selection_population(self.pop, pop_new)
```

### Comparing `mealpy-2.5.3/mealpy/system_based/AEO.py` & `mealpy-2.5.3a1/mealpy/system_based/AEO.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,620 +1,620 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 16:44, 18/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.optimizer import Optimizer
-
-
-class OriginalAEO(Optimizer):
-    """
-    The original version of: Artificial Ecosystem-based Optimization (AEO)
-
-    Links:
-        1. https://doi.org/10.1007/s00521-019-04452-x
-        2. https://www.mathworks.com/matlabcentral/fileexchange/72685-artificial-ecosystem-based-optimization-aeo
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.system_based.AEO import OriginalAEO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = OriginalAEO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Zhao, W., Wang, L. and Zhang, Z., 2020. Artificial ecosystem-based optimization: a novel
-    nature-inspired meta-heuristic algorithm. Neural Computing and Applications, 32(13), pp.9383-9425.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = True
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        ## Production   - Update the worst agent
-        # Eq. 2, 3, 1
-        a = (1.0 - epoch / self.epoch) * np.random.uniform()
-        x1 = (1 - a) * self.pop[-1][self.ID_POS] + a * np.random.uniform(self.problem.lb, self.problem.ub)
-        pos_new = self.amend_position(x1, self.problem.lb, self.problem.ub)
-        target = self.get_target_wrapper(pos_new)
-        self.pop[-1] = [pos_new, target]
-
-        ## Consumption - Update the whole population left
-        pop_new = []
-        for idx in range(0, self.pop_size - 1):
-            rand = np.random.random()
-            # Eq. 4, 5, 6
-            v1 = np.random.normal(0, 1)
-            v2 = np.random.normal(0, 1)
-            c = 0.5 * v1 / abs(v2)  # Consumption factor
-            j = 1 if idx == 0 else np.random.randint(0, idx)
-            ### Herbivore
-            if rand < 1.0 / 3:
-                x_t1 = self.pop[idx][self.ID_POS] + c * (self.pop[idx][self.ID_POS] - self.pop[0][self.ID_POS])  # Eq. 6
-            ### Carnivore
-            elif 1.0 / 3 <= rand and rand <= 2.0 / 3:
-                x_t1 = self.pop[idx][self.ID_POS] + c * (self.pop[idx][self.ID_POS] - self.pop[j][self.ID_POS])  # Eq. 7
-            ### Omnivore
-            else:
-                r2 = np.random.uniform()
-                x_t1 = self.pop[idx][self.ID_POS] + c * (r2 * (self.pop[idx][self.ID_POS] - self.pop[0][self.ID_POS])
-                                                         + (1 - r2) * (self.pop[idx][self.ID_POS] - self.pop[j][self.ID_POS]))
-            pos_new = self.amend_position(x_t1, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop[:-1] = self.greedy_selection_population(self.pop[:-1], pop_new)
-
-        ## find current best used in decomposition
-        _, best = self.get_global_best_solution(self.pop)
-
-        ## Decomposition
-        ### Eq. 10, 11, 12, 9
-        pop_child = []
-        for idx in range(0, self.pop_size):
-            r3 = np.random.uniform()
-            d = 3 * np.random.normal(0, 1)
-            e = r3 * np.random.randint(1, 3) - 1
-            h = 2 * r3 - 1
-            x_t1 = best[self.ID_POS] + d * (e * best[self.ID_POS] - h * self.pop[idx][self.ID_POS])
-            pos_new = self.amend_position(x_t1, self.problem.lb, self.problem.ub)
-            pop_child.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_child = self.update_target_wrapper_population(pop_child)
-            self.pop = self.greedy_selection_population(pop_child, self.pop)
-
-
-class ImprovedAEO(OriginalAEO):
-    """
-    The original version of: Improved Artificial Ecosystem-based Optimization (ImprovedAEO)
-
-    Links:
-        1. https://doi.org/10.1016/j.ijhydene.2020.06.256
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.system_based.AEO import ImprovedAEO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = ImprovedAEO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Rizk-Allah, R.M. and El-Fergany, A.A., 2021. Artificial ecosystem optimizer
-    for parameters identification of proton exchange membrane fuel cells model.
-    International Journal of Hydrogen Energy, 46(75), pp.37612-37627.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(epoch, pop_size, **kwargs)
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        ## Production   - Update the worst agent
-        # Eq. 2, 3, 1
-        a = (1.0 - epoch / self.epoch) * np.random.uniform()
-        x1 = (1 - a) * self.pop[-1][self.ID_POS] + a * np.random.uniform(self.problem.lb, self.problem.ub)
-        pos_new = self.amend_position(x1, self.problem.lb, self.problem.ub)
-        target = self.get_target_wrapper(pos_new)
-        self.pop[-1] = [pos_new, target]
-
-        ## Consumption - Update the whole population left
-        pop_new = []
-        for idx in range(0, self.pop_size - 1):
-            rand = np.random.random()
-            # Eq. 4, 5, 6
-            v1 = np.random.normal(0, 1)
-            v2 = np.random.normal(0, 1)
-            c = 0.5 * v1 / abs(v2)  # Consumption factor
-            j = 1 if idx == 0 else np.random.randint(0, idx)
-            ### Herbivore
-            if rand < 1.0 / 3:
-                x_t1 = self.pop[idx][self.ID_POS] + c * (self.pop[idx][self.ID_POS] - self.pop[0][self.ID_POS])  # Eq. 6
-            ### Carnivore
-            elif 1.0 / 3 <= rand and rand <= 2.0 / 3:
-                x_t1 = self.pop[idx][self.ID_POS] + c * (self.pop[idx][self.ID_POS] - self.pop[j][self.ID_POS])  # Eq. 7
-            ### Omnivore
-            else:
-                r2 = np.random.uniform()
-                x_t1 = self.pop[idx][self.ID_POS] + c * (r2 * (self.pop[idx][self.ID_POS] - self.pop[0][self.ID_POS])
-                                                         + (1 - r2) * (self.pop[idx][self.ID_POS] - self.pop[j][self.ID_POS]))
-            pos_new = self.amend_position(x_t1, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop[:-1] = self.greedy_selection_population(self.pop[:-1], pop_new)
-
-        ## find current best used in decomposition
-        _, best = self.get_global_best_solution(self.pop)
-
-        ## Decomposition
-        ### Eq. 10, 11, 12, 9
-        pop_child = []
-        for idx in range(0, self.pop_size):
-            r3 = np.random.uniform()
-            d = 3 * np.random.normal(0, 1)
-            e = r3 * np.random.randint(1, 3) - 1
-            h = 2 * r3 - 1
-
-            x_new = best[self.ID_POS] + d * (e * best[self.ID_POS] - h * self.pop[idx][self.ID_POS])
-            if np.random.random() < 0.5:
-                beta = 1 - (1 - 0) * ((epoch + 1) / self.epoch)  # Eq. 21
-                x_r = self.pop[np.random.randint(0, self.pop_size - 1)][self.ID_POS]
-                if np.random.random() < 0.5:
-                    x_new = beta * x_r + (1 - beta) * self.pop[idx][self.ID_POS]
-                else:
-                    x_new = beta * self.pop[idx][self.ID_POS] + (1 - beta) * x_r
-            else:
-                best[self.ID_POS] = best[self.ID_POS] + np.random.normal() * best[self.ID_POS]
-            pos_new = self.amend_position(x_new, self.problem.lb, self.problem.ub)
-            pop_child.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_child = self.update_target_wrapper_population(pop_child)
-            self.pop = self.greedy_selection_population(pop_child, self.pop)
-
-
-class EnhancedAEO(Optimizer):
-    """
-    The original version of: Enhanced Artificial Ecosystem-Based Optimization (EAEO)
-
-    Links:
-        1. https://doi.org/10.1109/ACCESS.2020.3027654
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.system_based.AEO import EnhancedAEO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = EnhancedAEO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Eid, A., Kamel, S., Korashy, A. and Khurshaid, T., 2020. An enhanced artificial ecosystem-based
-    optimization for optimal allocation of multiple distributed generations. IEEE Access, 8, pp.178493-178513.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = True
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        ## Production - Update the worst agent
-        # Eq. 13
-        a = 2 * (1 - (epoch + 1) / self.epoch)
-        x1 = (1 - a) * self.pop[-1][self.ID_POS] + a * np.random.uniform(self.problem.lb, self.problem.ub)
-        pos_new = self.amend_position(x1, self.problem.lb, self.problem.ub)
-        target = self.get_target_wrapper(pos_new)
-        self.pop[-1] = [pos_new, target]
-
-        ## Consumption - Update the whole population left
-        pop_new = []
-        for idx in range(0, self.pop_size - 1):
-            rand = np.random.random()
-            # Eq. 4, 5, 6
-            v1 = np.random.normal(0, 1)
-            v2 = np.random.normal(0, 1)
-            c = 0.5 * v1 / abs(v2)  # Consumption factor
-
-            r3 = 2 * np.pi * np.random.random()
-            r4 = np.random.random()
-            j = 1 if idx == 0 else np.random.randint(0, idx)
-            ### Herbivore
-            if rand <= 1.0 / 3:  # Eq. 15
-                if r4 <= 0.5:
-                    x_t1 = self.pop[idx][self.ID_POS] + np.sin(r3) * c * (self.pop[idx][self.ID_POS] - self.pop[0][self.ID_POS])
-                else:
-                    x_t1 = self.pop[idx][self.ID_POS] + np.cos(r3) * c * (self.pop[idx][self.ID_POS] - self.pop[0][self.ID_POS])
-            ### Carnivore
-            elif 1.0 / 3 <= rand and rand <= 2.0 / 3:  # Eq. 16
-                if r4 <= 0.5:
-                    x_t1 = self.pop[idx][self.ID_POS] + np.sin(r3) * c * (self.pop[idx][self.ID_POS] - self.pop[j][self.ID_POS])
-                else:
-                    x_t1 = self.pop[idx][self.ID_POS] + np.cos(r3) * c * (self.pop[idx][self.ID_POS] - self.pop[j][self.ID_POS])
-            ### Omnivore
-            else:  # Eq. 17
-                r5 = np.random.random()
-                if r4 <= 0.5:
-                    x_t1 = self.pop[idx][self.ID_POS] + np.sin(r5) * c * (r5 * (self.pop[idx][self.ID_POS] - self.pop[0][self.ID_POS]) +
-                                                                          (1 - r5) * (self.pop[idx][self.ID_POS] - self.pop[j][self.ID_POS]))
-                else:
-                    x_t1 = self.pop[idx][self.ID_POS] + np.cos(r5) * c * (r5 * (self.pop[idx][self.ID_POS] - self.pop[0][self.ID_POS]) +
-                                                                          (1 - r5) * (self.pop[idx][self.ID_POS] - self.pop[j][self.ID_POS]))
-            pos_new = self.amend_position(x_t1, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop[:-1] = self.greedy_selection_population(self.pop[:-1], pop_new)
-
-        ## find current best used in decomposition
-        _, best = self.get_global_best_solution(self.pop)
-
-        ## Decomposition
-        ### Eq. 10, 11, 12, 9
-        pop_child = []
-        for idx in range(0, self.pop_size):
-            r3 = np.random.uniform()
-            d = 3 * np.random.normal(0, 1)
-            e = r3 * np.random.randint(1, 3) - 1
-            h = 2 * r3 - 1
-            # x_new = best[self.ID_POS] + d * (e * best[self.ID_POS] - h * agent_i[self.ID_POS])
-            if np.random.random() < 0.5:
-                beta = 1 - (1 - 0) * ((epoch + 1) / self.epoch)  # Eq. 21
-                r_idx = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
-                x_r = self.pop[r_idx][self.ID_POS]
-                # x_r = pop[np.random.randint(0, self.pop_size-1)][self.ID_POS]
-                if np.random.random() < 0.5:
-                    x_new = beta * x_r + (1 - beta) * self.pop[idx][self.ID_POS]
-                else:
-                    x_new = (1 - beta) * x_r + beta * self.pop[idx][self.ID_POS]
-            else:
-                x_new = best[self.ID_POS] + d * (e * best[self.ID_POS] - h * self.pop[idx][self.ID_POS])
-                # x_new = best[self.ID_POS] + np.random.normal() * best[self.ID_POS]
-            pos_new = self.amend_position(x_new, self.problem.lb, self.problem.ub)
-            pop_child.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_child = self.update_target_wrapper_population(pop_child)
-            self.pop = self.greedy_selection_population(pop_child, self.pop)
-
-
-class ModifiedAEO(Optimizer):
-    """
-    The original version of: Modified Artificial Ecosystem-Based Optimization (MAEO)
-
-    Links:
-        1. https://doi.org/10.1109/ACCESS.2020.2973351
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.system_based.AEO import ModifiedAEO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = ModifiedAEO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Menesy, A.S., Sultan, H.M., Korashy, A., Banakhr, F.A., Ashmawy, M.G. and Kamel, S., 2020. Effective
-    parameter extraction of different polymer electrolyte membrane fuel cell stack models using a
-    modified artificial ecosystem optimization algorithm. IEEE Access, 8, pp.31892-31909.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = True
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        ## Production
-        # Eq. 22
-        H = 2 * (1 - (epoch + 1) / self.epoch)
-        a = (1 - (epoch + 1) / self.epoch) * np.random.random()
-        x1 = (1 - a) * self.pop[-1][self.ID_POS] + a * np.random.uniform(self.problem.lb, self.problem.ub)
-        pos_new = self.amend_position(x1, self.problem.lb, self.problem.ub)
-        target = self.get_target_wrapper(pos_new)
-        self.pop[-1] = [pos_new, target]
-
-        ## Consumption - Update the whole population left
-        pop_new = []
-        for idx in range(0, self.pop_size - 1):
-            rand = np.random.random()
-            # Eq. 4, 5, 6
-            v1 = np.random.normal(0, 1)
-            v2 = np.random.normal(0, 1)
-            c = 0.5 * v1 / abs(v2)  # Consumption factor
-            j = 1 if idx == 0 else np.random.randint(0, idx)
-            ### Herbivore
-            if rand <= 1.0 / 3:  # Eq. 23
-                pos_new = self.pop[idx][self.ID_POS] + H * c * (self.pop[idx][self.ID_POS] - self.pop[0][self.ID_POS])
-            ### Carnivore
-            elif 1.0 / 3 <= rand and rand <= 2.0 / 3:  # Eq. 24
-                pos_new = self.pop[idx][self.ID_POS] + H * c * (self.pop[idx][self.ID_POS] - self.pop[j][self.ID_POS])
-            ### Omnivore
-            else:  # Eq. 25
-                r5 = np.random.random()
-                pos_new = self.pop[idx][self.ID_POS] + H * c * (r5 * (self.pop[idx][self.ID_POS] - self.pop[0][self.ID_POS]) +
-                                                                (1 - r5) * (self.pop[idx][self.ID_POS] - self.pop[j][self.ID_POS]))
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop[:-1] = self.greedy_selection_population(self.pop[:-1], pop_new)
-
-        ## find current best used in decomposition
-        _, best = self.get_global_best_solution(self.pop)
-
-        ## Decomposition
-        ### Eq. 10, 11, 12, 9
-        pop_child = []
-        for idx in range(0, self.pop_size):
-            r3 = np.random.uniform()
-            d = 3 * np.random.normal(0, 1)
-            e = r3 * np.random.randint(1, 3) - 1
-            h = 2 * r3 - 1
-            # x_new = best[self.ID_POS] + d * (e * best[self.ID_POS] - h * agent_i[self.ID_POS])
-            if np.random.random() < 0.5:
-                beta = 1 - (1 - 0) * ((epoch + 1) / self.epoch)  # Eq. 21
-                r_idx = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
-                x_r = self.pop[r_idx][self.ID_POS]
-                # x_r = pop[np.random.randint(0, self.pop_size-1)][self.ID_POS]
-                if np.random.random() < 0.5:
-                    x_new = beta * x_r + (1 - beta) * self.pop[idx][self.ID_POS]
-                else:
-                    x_new = (1 - beta) * x_r + beta * self.pop[idx][self.ID_POS]
-            else:
-                x_new = best[self.ID_POS] + d * (e * best[self.ID_POS] - h * self.pop[idx][self.ID_POS])
-                # x_new = best[self.ID_POS] + np.random.normal() * best[self.ID_POS]
-            pos_new = self.amend_position(x_new, self.problem.lb, self.problem.ub)
-            pop_child.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_child = self.update_target_wrapper_population(pop_child)
-            self.pop = self.greedy_selection_population(pop_child, self.pop)
-
-
-class AugmentedAEO(Optimizer):
-    """
-    The original version of: Adaptive Artificial Ecosystem Optimization (AAEO)
-
-    Notes
-    ~~~~~
-    + Used linear weight factor reduce from 2 to 0 through time
-    + Applied Levy-flight technique and the global best solution
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.system_based.AEO import AugmentedAEO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> model = AugmentedAEO(epoch, pop_size)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Van Thieu, N., Barma, S. D., Van Lam, T., Kisi, O., & Mahesha, A. (2022). Groundwater level modeling
-    using Augmented Artificial Ecosystem Optimization. Journal of Hydrology, 129034.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.set_parameters(["epoch", "pop_size"])
-        self.sort_flag = True
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        ## Production - Update the worst agent
-        # Eq. 2, 3, 1
-        wf = 2 * (1 - (epoch + 1) / self.epoch)  # Weight factor
-        a = (1.0 - epoch / self.epoch) * np.random.random()
-        x1 = (1 - a) * self.pop[-1][self.ID_POS] + a * np.random.uniform(self.problem.lb, self.problem.ub)
-        pos_new = self.amend_position(x1, self.problem.lb, self.problem.ub)
-        target = self.get_target_wrapper(pos_new)
-        self.pop[-1] = [pos_new, target]
-
-        ## Consumption - Update the whole population left
-        pop_new = []
-        for idx in range(0, self.pop_size - 1):
-            if np.random.random() < 0.5:
-                rand = np.random.random()
-                # Eq. 4, 5, 6
-                c = 0.5 * np.random.normal(0, 1) / abs(np.random.normal(0, 1))  # Consumption factor
-                j = 1 if idx == 0 else np.random.randint(0, idx)
-                ### Herbivore
-                if rand < 1.0 / 3:
-                    pos_new = self.pop[idx][self.ID_POS] + wf * c * (self.pop[idx][self.ID_POS] - self.pop[0][self.ID_POS])  # Eq. 6
-                ### Omnivore
-                elif 1.0 / 3 <= rand <= 2.0 / 3:
-                    pos_new = self.pop[idx][self.ID_POS] + wf * c * (self.pop[idx][self.ID_POS] - self.pop[j][self.ID_POS])  # Eq. 7
-                ### Carnivore
-                else:
-                    r2 = np.random.uniform()
-                    pos_new = self.pop[idx][self.ID_POS] + wf * c * (r2 * (self.pop[idx][self.ID_POS] - self.pop[0][self.ID_POS]) +
-                                                                     (1 - r2) * (self.pop[idx][self.ID_POS] - self.pop[j][self.ID_POS]))
-            else:
-                pos_new = self.pop[idx][self.ID_POS] + self.get_levy_flight_step(1., 0.0001, case=-1) * \
-                          (1.0 / np.sqrt(epoch + 1)) * np.sign(np.random.random() - 0.5) * (self.pop[idx][self.ID_POS] - self.g_best[self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_new = self.update_target_wrapper_population(pop_new)
-            self.pop[:-1] = self.greedy_selection_population(self.pop[:-1], pop_new)
-
-        ## find current best used in decomposition
-        _, best = self.get_global_best_solution(self.pop)
-
-        ## Decomposition
-        ### Eq. 10, 11, 12, 9   idx, pop, g_best, local_best
-        pop_child = []
-        for idx in range(0, self.pop_size):
-            if np.random.random() < 0.5:
-                pos_new = best[self.ID_POS] + np.random.normal(0, 1, self.problem.n_dims) * (best[self.ID_POS] - self.pop[idx][self.ID_POS])
-            else:
-                pos_new = best[self.ID_POS] + self.get_levy_flight_step(0.75, 0.001, case=-1) * \
-                          1.0 / np.sqrt(epoch + 1) * np.sign(np.random.random() - 0.5) * (best[self.ID_POS] - self.pop[idx][self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_child.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                target = self.get_target_wrapper(pos_new)
-                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
-        if self.mode in self.AVAILABLE_MODES:
-            pop_child = self.update_target_wrapper_population(pop_child)
-            self.pop = self.greedy_selection_population(pop_child, self.pop)
+#!/usr/bin/env python
+# Created by "Thieu" at 16:44, 18/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.optimizer import Optimizer
+
+
+class OriginalAEO(Optimizer):
+    """
+    The original version of: Artificial Ecosystem-based Optimization (AEO)
+
+    Links:
+        1. https://doi.org/10.1007/s00521-019-04452-x
+        2. https://www.mathworks.com/matlabcentral/fileexchange/72685-artificial-ecosystem-based-optimization-aeo
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.system_based.AEO import OriginalAEO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = OriginalAEO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Zhao, W., Wang, L. and Zhang, Z., 2020. Artificial ecosystem-based optimization: a novel
+    nature-inspired meta-heuristic algorithm. Neural Computing and Applications, 32(13), pp.9383-9425.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = True
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        ## Production   - Update the worst agent
+        # Eq. 2, 3, 1
+        a = (1.0 - epoch / self.epoch) * np.random.uniform()
+        x1 = (1 - a) * self.pop[-1][self.ID_POS] + a * np.random.uniform(self.problem.lb, self.problem.ub)
+        pos_new = self.amend_position(x1, self.problem.lb, self.problem.ub)
+        target = self.get_target_wrapper(pos_new)
+        self.pop[-1] = [pos_new, target]
+
+        ## Consumption - Update the whole population left
+        pop_new = []
+        for idx in range(0, self.pop_size - 1):
+            rand = np.random.random()
+            # Eq. 4, 5, 6
+            v1 = np.random.normal(0, 1)
+            v2 = np.random.normal(0, 1)
+            c = 0.5 * v1 / abs(v2)  # Consumption factor
+            j = 1 if idx == 0 else np.random.randint(0, idx)
+            ### Herbivore
+            if rand < 1.0 / 3:
+                x_t1 = self.pop[idx][self.ID_POS] + c * (self.pop[idx][self.ID_POS] - self.pop[0][self.ID_POS])  # Eq. 6
+            ### Carnivore
+            elif 1.0 / 3 <= rand and rand <= 2.0 / 3:
+                x_t1 = self.pop[idx][self.ID_POS] + c * (self.pop[idx][self.ID_POS] - self.pop[j][self.ID_POS])  # Eq. 7
+            ### Omnivore
+            else:
+                r2 = np.random.uniform()
+                x_t1 = self.pop[idx][self.ID_POS] + c * (r2 * (self.pop[idx][self.ID_POS] - self.pop[0][self.ID_POS])
+                                                         + (1 - r2) * (self.pop[idx][self.ID_POS] - self.pop[j][self.ID_POS]))
+            pos_new = self.amend_position(x_t1, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop[:-1] = self.greedy_selection_population(self.pop[:-1], pop_new)
+
+        ## find current best used in decomposition
+        _, best = self.get_global_best_solution(self.pop)
+
+        ## Decomposition
+        ### Eq. 10, 11, 12, 9
+        pop_child = []
+        for idx in range(0, self.pop_size):
+            r3 = np.random.uniform()
+            d = 3 * np.random.normal(0, 1)
+            e = r3 * np.random.randint(1, 3) - 1
+            h = 2 * r3 - 1
+            x_t1 = best[self.ID_POS] + d * (e * best[self.ID_POS] - h * self.pop[idx][self.ID_POS])
+            pos_new = self.amend_position(x_t1, self.problem.lb, self.problem.ub)
+            pop_child.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_child = self.update_target_wrapper_population(pop_child)
+            self.pop = self.greedy_selection_population(pop_child, self.pop)
+
+
+class ImprovedAEO(OriginalAEO):
+    """
+    The original version of: Improved Artificial Ecosystem-based Optimization (ImprovedAEO)
+
+    Links:
+        1. https://doi.org/10.1016/j.ijhydene.2020.06.256
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.system_based.AEO import ImprovedAEO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = ImprovedAEO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Rizk-Allah, R.M. and El-Fergany, A.A., 2021. Artificial ecosystem optimizer
+    for parameters identification of proton exchange membrane fuel cells model.
+    International Journal of Hydrogen Energy, 46(75), pp.37612-37627.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(epoch, pop_size, **kwargs)
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        ## Production   - Update the worst agent
+        # Eq. 2, 3, 1
+        a = (1.0 - epoch / self.epoch) * np.random.uniform()
+        x1 = (1 - a) * self.pop[-1][self.ID_POS] + a * np.random.uniform(self.problem.lb, self.problem.ub)
+        pos_new = self.amend_position(x1, self.problem.lb, self.problem.ub)
+        target = self.get_target_wrapper(pos_new)
+        self.pop[-1] = [pos_new, target]
+
+        ## Consumption - Update the whole population left
+        pop_new = []
+        for idx in range(0, self.pop_size - 1):
+            rand = np.random.random()
+            # Eq. 4, 5, 6
+            v1 = np.random.normal(0, 1)
+            v2 = np.random.normal(0, 1)
+            c = 0.5 * v1 / abs(v2)  # Consumption factor
+            j = 1 if idx == 0 else np.random.randint(0, idx)
+            ### Herbivore
+            if rand < 1.0 / 3:
+                x_t1 = self.pop[idx][self.ID_POS] + c * (self.pop[idx][self.ID_POS] - self.pop[0][self.ID_POS])  # Eq. 6
+            ### Carnivore
+            elif 1.0 / 3 <= rand and rand <= 2.0 / 3:
+                x_t1 = self.pop[idx][self.ID_POS] + c * (self.pop[idx][self.ID_POS] - self.pop[j][self.ID_POS])  # Eq. 7
+            ### Omnivore
+            else:
+                r2 = np.random.uniform()
+                x_t1 = self.pop[idx][self.ID_POS] + c * (r2 * (self.pop[idx][self.ID_POS] - self.pop[0][self.ID_POS])
+                                                         + (1 - r2) * (self.pop[idx][self.ID_POS] - self.pop[j][self.ID_POS]))
+            pos_new = self.amend_position(x_t1, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop[:-1] = self.greedy_selection_population(self.pop[:-1], pop_new)
+
+        ## find current best used in decomposition
+        _, best = self.get_global_best_solution(self.pop)
+
+        ## Decomposition
+        ### Eq. 10, 11, 12, 9
+        pop_child = []
+        for idx in range(0, self.pop_size):
+            r3 = np.random.uniform()
+            d = 3 * np.random.normal(0, 1)
+            e = r3 * np.random.randint(1, 3) - 1
+            h = 2 * r3 - 1
+
+            x_new = best[self.ID_POS] + d * (e * best[self.ID_POS] - h * self.pop[idx][self.ID_POS])
+            if np.random.random() < 0.5:
+                beta = 1 - (1 - 0) * ((epoch + 1) / self.epoch)  # Eq. 21
+                x_r = self.pop[np.random.randint(0, self.pop_size - 1)][self.ID_POS]
+                if np.random.random() < 0.5:
+                    x_new = beta * x_r + (1 - beta) * self.pop[idx][self.ID_POS]
+                else:
+                    x_new = beta * self.pop[idx][self.ID_POS] + (1 - beta) * x_r
+            else:
+                best[self.ID_POS] = best[self.ID_POS] + np.random.normal() * best[self.ID_POS]
+            pos_new = self.amend_position(x_new, self.problem.lb, self.problem.ub)
+            pop_child.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_child = self.update_target_wrapper_population(pop_child)
+            self.pop = self.greedy_selection_population(pop_child, self.pop)
+
+
+class EnhancedAEO(Optimizer):
+    """
+    The original version of: Enhanced Artificial Ecosystem-Based Optimization (EAEO)
+
+    Links:
+        1. https://doi.org/10.1109/ACCESS.2020.3027654
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.system_based.AEO import EnhancedAEO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = EnhancedAEO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Eid, A., Kamel, S., Korashy, A. and Khurshaid, T., 2020. An enhanced artificial ecosystem-based
+    optimization for optimal allocation of multiple distributed generations. IEEE Access, 8, pp.178493-178513.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = True
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        ## Production - Update the worst agent
+        # Eq. 13
+        a = 2 * (1 - (epoch + 1) / self.epoch)
+        x1 = (1 - a) * self.pop[-1][self.ID_POS] + a * np.random.uniform(self.problem.lb, self.problem.ub)
+        pos_new = self.amend_position(x1, self.problem.lb, self.problem.ub)
+        target = self.get_target_wrapper(pos_new)
+        self.pop[-1] = [pos_new, target]
+
+        ## Consumption - Update the whole population left
+        pop_new = []
+        for idx in range(0, self.pop_size - 1):
+            rand = np.random.random()
+            # Eq. 4, 5, 6
+            v1 = np.random.normal(0, 1)
+            v2 = np.random.normal(0, 1)
+            c = 0.5 * v1 / abs(v2)  # Consumption factor
+
+            r3 = 2 * np.pi * np.random.random()
+            r4 = np.random.random()
+            j = 1 if idx == 0 else np.random.randint(0, idx)
+            ### Herbivore
+            if rand <= 1.0 / 3:  # Eq. 15
+                if r4 <= 0.5:
+                    x_t1 = self.pop[idx][self.ID_POS] + np.sin(r3) * c * (self.pop[idx][self.ID_POS] - self.pop[0][self.ID_POS])
+                else:
+                    x_t1 = self.pop[idx][self.ID_POS] + np.cos(r3) * c * (self.pop[idx][self.ID_POS] - self.pop[0][self.ID_POS])
+            ### Carnivore
+            elif 1.0 / 3 <= rand and rand <= 2.0 / 3:  # Eq. 16
+                if r4 <= 0.5:
+                    x_t1 = self.pop[idx][self.ID_POS] + np.sin(r3) * c * (self.pop[idx][self.ID_POS] - self.pop[j][self.ID_POS])
+                else:
+                    x_t1 = self.pop[idx][self.ID_POS] + np.cos(r3) * c * (self.pop[idx][self.ID_POS] - self.pop[j][self.ID_POS])
+            ### Omnivore
+            else:  # Eq. 17
+                r5 = np.random.random()
+                if r4 <= 0.5:
+                    x_t1 = self.pop[idx][self.ID_POS] + np.sin(r5) * c * (r5 * (self.pop[idx][self.ID_POS] - self.pop[0][self.ID_POS]) +
+                                                                          (1 - r5) * (self.pop[idx][self.ID_POS] - self.pop[j][self.ID_POS]))
+                else:
+                    x_t1 = self.pop[idx][self.ID_POS] + np.cos(r5) * c * (r5 * (self.pop[idx][self.ID_POS] - self.pop[0][self.ID_POS]) +
+                                                                          (1 - r5) * (self.pop[idx][self.ID_POS] - self.pop[j][self.ID_POS]))
+            pos_new = self.amend_position(x_t1, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop[:-1] = self.greedy_selection_population(self.pop[:-1], pop_new)
+
+        ## find current best used in decomposition
+        _, best = self.get_global_best_solution(self.pop)
+
+        ## Decomposition
+        ### Eq. 10, 11, 12, 9
+        pop_child = []
+        for idx in range(0, self.pop_size):
+            r3 = np.random.uniform()
+            d = 3 * np.random.normal(0, 1)
+            e = r3 * np.random.randint(1, 3) - 1
+            h = 2 * r3 - 1
+            # x_new = best[self.ID_POS] + d * (e * best[self.ID_POS] - h * agent_i[self.ID_POS])
+            if np.random.random() < 0.5:
+                beta = 1 - (1 - 0) * ((epoch + 1) / self.epoch)  # Eq. 21
+                r_idx = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
+                x_r = self.pop[r_idx][self.ID_POS]
+                # x_r = pop[np.random.randint(0, self.pop_size-1)][self.ID_POS]
+                if np.random.random() < 0.5:
+                    x_new = beta * x_r + (1 - beta) * self.pop[idx][self.ID_POS]
+                else:
+                    x_new = (1 - beta) * x_r + beta * self.pop[idx][self.ID_POS]
+            else:
+                x_new = best[self.ID_POS] + d * (e * best[self.ID_POS] - h * self.pop[idx][self.ID_POS])
+                # x_new = best[self.ID_POS] + np.random.normal() * best[self.ID_POS]
+            pos_new = self.amend_position(x_new, self.problem.lb, self.problem.ub)
+            pop_child.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_child = self.update_target_wrapper_population(pop_child)
+            self.pop = self.greedy_selection_population(pop_child, self.pop)
+
+
+class ModifiedAEO(Optimizer):
+    """
+    The original version of: Modified Artificial Ecosystem-Based Optimization (MAEO)
+
+    Links:
+        1. https://doi.org/10.1109/ACCESS.2020.2973351
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.system_based.AEO import ModifiedAEO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = ModifiedAEO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Menesy, A.S., Sultan, H.M., Korashy, A., Banakhr, F.A., Ashmawy, M.G. and Kamel, S., 2020. Effective
+    parameter extraction of different polymer electrolyte membrane fuel cell stack models using a
+    modified artificial ecosystem optimization algorithm. IEEE Access, 8, pp.31892-31909.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = True
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        ## Production
+        # Eq. 22
+        H = 2 * (1 - (epoch + 1) / self.epoch)
+        a = (1 - (epoch + 1) / self.epoch) * np.random.random()
+        x1 = (1 - a) * self.pop[-1][self.ID_POS] + a * np.random.uniform(self.problem.lb, self.problem.ub)
+        pos_new = self.amend_position(x1, self.problem.lb, self.problem.ub)
+        target = self.get_target_wrapper(pos_new)
+        self.pop[-1] = [pos_new, target]
+
+        ## Consumption - Update the whole population left
+        pop_new = []
+        for idx in range(0, self.pop_size - 1):
+            rand = np.random.random()
+            # Eq. 4, 5, 6
+            v1 = np.random.normal(0, 1)
+            v2 = np.random.normal(0, 1)
+            c = 0.5 * v1 / abs(v2)  # Consumption factor
+            j = 1 if idx == 0 else np.random.randint(0, idx)
+            ### Herbivore
+            if rand <= 1.0 / 3:  # Eq. 23
+                pos_new = self.pop[idx][self.ID_POS] + H * c * (self.pop[idx][self.ID_POS] - self.pop[0][self.ID_POS])
+            ### Carnivore
+            elif 1.0 / 3 <= rand and rand <= 2.0 / 3:  # Eq. 24
+                pos_new = self.pop[idx][self.ID_POS] + H * c * (self.pop[idx][self.ID_POS] - self.pop[j][self.ID_POS])
+            ### Omnivore
+            else:  # Eq. 25
+                r5 = np.random.random()
+                pos_new = self.pop[idx][self.ID_POS] + H * c * (r5 * (self.pop[idx][self.ID_POS] - self.pop[0][self.ID_POS]) +
+                                                                (1 - r5) * (self.pop[idx][self.ID_POS] - self.pop[j][self.ID_POS]))
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop[:-1] = self.greedy_selection_population(self.pop[:-1], pop_new)
+
+        ## find current best used in decomposition
+        _, best = self.get_global_best_solution(self.pop)
+
+        ## Decomposition
+        ### Eq. 10, 11, 12, 9
+        pop_child = []
+        for idx in range(0, self.pop_size):
+            r3 = np.random.uniform()
+            d = 3 * np.random.normal(0, 1)
+            e = r3 * np.random.randint(1, 3) - 1
+            h = 2 * r3 - 1
+            # x_new = best[self.ID_POS] + d * (e * best[self.ID_POS] - h * agent_i[self.ID_POS])
+            if np.random.random() < 0.5:
+                beta = 1 - (1 - 0) * ((epoch + 1) / self.epoch)  # Eq. 21
+                r_idx = np.random.choice(list(set(range(0, self.pop_size)) - {idx}))
+                x_r = self.pop[r_idx][self.ID_POS]
+                # x_r = pop[np.random.randint(0, self.pop_size-1)][self.ID_POS]
+                if np.random.random() < 0.5:
+                    x_new = beta * x_r + (1 - beta) * self.pop[idx][self.ID_POS]
+                else:
+                    x_new = (1 - beta) * x_r + beta * self.pop[idx][self.ID_POS]
+            else:
+                x_new = best[self.ID_POS] + d * (e * best[self.ID_POS] - h * self.pop[idx][self.ID_POS])
+                # x_new = best[self.ID_POS] + np.random.normal() * best[self.ID_POS]
+            pos_new = self.amend_position(x_new, self.problem.lb, self.problem.ub)
+            pop_child.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_child = self.update_target_wrapper_population(pop_child)
+            self.pop = self.greedy_selection_population(pop_child, self.pop)
+
+
+class AugmentedAEO(Optimizer):
+    """
+    The original version of: Adaptive Artificial Ecosystem Optimization (AAEO)
+
+    Notes
+    ~~~~~
+    + Used linear weight factor reduce from 2 to 0 through time
+    + Applied Levy-flight technique and the global best solution
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.system_based.AEO import AugmentedAEO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> model = AugmentedAEO(epoch, pop_size)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Van Thieu, N., Barma, S. D., Van Lam, T., Kisi, O., & Mahesha, A. (2022). Groundwater level modeling
+    using Augmented Artificial Ecosystem Optimization. Journal of Hydrology, 129034.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.set_parameters(["epoch", "pop_size"])
+        self.sort_flag = True
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        ## Production - Update the worst agent
+        # Eq. 2, 3, 1
+        wf = 2 * (1 - (epoch + 1) / self.epoch)  # Weight factor
+        a = (1.0 - epoch / self.epoch) * np.random.random()
+        x1 = (1 - a) * self.pop[-1][self.ID_POS] + a * np.random.uniform(self.problem.lb, self.problem.ub)
+        pos_new = self.amend_position(x1, self.problem.lb, self.problem.ub)
+        target = self.get_target_wrapper(pos_new)
+        self.pop[-1] = [pos_new, target]
+
+        ## Consumption - Update the whole population left
+        pop_new = []
+        for idx in range(0, self.pop_size - 1):
+            if np.random.random() < 0.5:
+                rand = np.random.random()
+                # Eq. 4, 5, 6
+                c = 0.5 * np.random.normal(0, 1) / abs(np.random.normal(0, 1))  # Consumption factor
+                j = 1 if idx == 0 else np.random.randint(0, idx)
+                ### Herbivore
+                if rand < 1.0 / 3:
+                    pos_new = self.pop[idx][self.ID_POS] + wf * c * (self.pop[idx][self.ID_POS] - self.pop[0][self.ID_POS])  # Eq. 6
+                ### Omnivore
+                elif 1.0 / 3 <= rand <= 2.0 / 3:
+                    pos_new = self.pop[idx][self.ID_POS] + wf * c * (self.pop[idx][self.ID_POS] - self.pop[j][self.ID_POS])  # Eq. 7
+                ### Carnivore
+                else:
+                    r2 = np.random.uniform()
+                    pos_new = self.pop[idx][self.ID_POS] + wf * c * (r2 * (self.pop[idx][self.ID_POS] - self.pop[0][self.ID_POS]) +
+                                                                     (1 - r2) * (self.pop[idx][self.ID_POS] - self.pop[j][self.ID_POS]))
+            else:
+                pos_new = self.pop[idx][self.ID_POS] + self.get_levy_flight_step(1., 0.0001, case=-1) * \
+                          (1.0 / np.sqrt(epoch + 1)) * np.sign(np.random.random() - 0.5) * (self.pop[idx][self.ID_POS] - self.g_best[self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_new = self.update_target_wrapper_population(pop_new)
+            self.pop[:-1] = self.greedy_selection_population(self.pop[:-1], pop_new)
+
+        ## find current best used in decomposition
+        _, best = self.get_global_best_solution(self.pop)
+
+        ## Decomposition
+        ### Eq. 10, 11, 12, 9   idx, pop, g_best, local_best
+        pop_child = []
+        for idx in range(0, self.pop_size):
+            if np.random.random() < 0.5:
+                pos_new = best[self.ID_POS] + np.random.normal(0, 1, self.problem.n_dims) * (best[self.ID_POS] - self.pop[idx][self.ID_POS])
+            else:
+                pos_new = best[self.ID_POS] + self.get_levy_flight_step(0.75, 0.001, case=-1) * \
+                          1.0 / np.sqrt(epoch + 1) * np.sign(np.random.random() - 0.5) * (best[self.ID_POS] - self.pop[idx][self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_child.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                target = self.get_target_wrapper(pos_new)
+                self.pop[idx] = self.get_better_solution([pos_new, target], self.pop[idx])
+        if self.mode in self.AVAILABLE_MODES:
+            pop_child = self.update_target_wrapper_population(pop_child)
+            self.pop = self.greedy_selection_population(pop_child, self.pop)
```

### Comparing `mealpy-2.5.3/mealpy/system_based/GCO.py` & `mealpy-2.5.3a1/mealpy/system_based/GCO.py`

 * *Ordering differences only*

 * *Files 20% similar despite different names*

```diff
@@ -1,194 +1,194 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 16:44, 18/03/2020 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class BaseGCO(Optimizer):
-    """
-    The developed version: Germinal Center Optimization (GCO)
-
-    Notes
-    ~~~~~
-    + The global best solution and 2 random solutions are used instead of randomizing 3 solutions
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + cr (float): [0.5, 0.95], crossover rate, default = 0.7 (Same as DE algorithm)
-        + wf (float): [1.0, 2.0], weighting factor (f in the paper), default = 1.25 (Same as DE algorithm)
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.system_based.GCO import BaseGCO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> cr = 0.7
-    >>> wf = 1.25
-    >>> model = BaseGCO(epoch, pop_size, cr, wf)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, cr=0.7, wf=1.25, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            cr (float): crossover rate, default = 0.7 (Same as DE algorithm)
-            wf (float): weighting factor (f in the paper), default = 1.25 (Same as DE algorithm)
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.cr = self.validator.check_float("cr", cr, (0, 1.0))
-        self.wf = self.validator.check_float("wf", wf, (0, 3.0))
-        self.set_parameters(["epoch", "pop_size", "cr", "wf"])
-        self.sort_flag = False
-
-    def initialize_variables(self):
-        self.dyn_list_cell_counter = np.ones(self.pop_size)  # CEll Counter
-        self.dyn_list_life_signal = 70 * np.ones(self.pop_size)  # 70% to duplicate, and 30% to die  # LIfe-Signal
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        ## Dark-zone process    (can be parallelization)
-        pop_new = []
-        for idx in range(0, self.pop_size):
-            if np.random.uniform(0, 100) < self.dyn_list_life_signal[idx]:
-                self.dyn_list_cell_counter[idx] += 1
-            else:
-                self.dyn_list_cell_counter[idx] = 1
-
-            # Mutate process
-            r1, r2 = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 2, replace=False)
-            pos_new = self.g_best[self.ID_POS] + self.wf * (self.pop[r2][self.ID_POS] - self.pop[r1][self.ID_POS])
-            condition = np.random.random(self.problem.n_dims) < self.cr
-            pos_new = np.where(condition, pos_new, self.pop[idx][self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            pop_new.append([pos_new, None])
-            if self.mode not in self.AVAILABLE_MODES:
-                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-        pop_new = self.update_target_wrapper_population(pop_new)
-        for idx in range(0, self.pop_size):
-            if self.compare_agent(pop_new[idx], self.pop[idx]):
-                self.dyn_list_cell_counter[idx] += 10
-                self.pop[idx] = deepcopy(pop_new[idx])
-
-        ## Light-zone process   (no needs parallelization)
-        for i in range(0, self.pop_size):
-            self.dyn_list_cell_counter[i] = 10
-            fit_list = np.array([item[self.ID_TAR][self.ID_FIT] for item in self.pop])
-            fit_max = max(fit_list)
-            fit_min = min(fit_list)
-            self.dyn_list_cell_counter[i] += 10 * (self.pop[i][self.ID_TAR][self.ID_FIT] - fit_max) / (fit_min - fit_max + self.EPSILON)
-
-
-class OriginalGCO(BaseGCO):
-    """
-    The original version of: Germinal Center Optimization (GCO)
-
-    Links:
-        1. https://doi.org/10.2991/ijcis.2018.25905179
-        2. https://www.atlantis-press.com/journals/ijcis/25905179/view
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + cr (float): [0.5, 0.95], crossover rate, default = 0.7 (Same as DE algorithm)
-        + wf (float): [1.0, 2.0], weighting factor (f in the paper), default = 1.25 (Same as DE algorithm)
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.system_based.GCO import OriginalGCO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> cr = 0.7
-    >>> wf = 1.25
-    >>> model = OriginalGCO(epoch, pop_size, cr, wf)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] VillaseÃ±or, C., Arana-Daniel, N., Alanis, A.Y., LÃ³pez-Franco, C. and Hernandez-Vargas, E.A., 2018.
-    Germinal center optimization algorithm. International Journal of Computational Intelligence Systems, 12(1), p.13.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, cr=0.7, wf=1.25, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            cr (float): crossover rate, default = 0.7 (Same as DE algorithm)
-            wf (float): weighting factor (f in the paper), default = 1.25 (Same as DE algorithm)
-        """
-        super().__init__(epoch, pop_size, cr, wf, **kwargs)
-        self.support_parallel_modes = False
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        ## Dark-zone process    (can be parallelization)
-        for idx in range(0, self.pop_size):
-            if np.random.uniform(0, 100) < self.dyn_list_life_signal[idx]:
-                self.dyn_list_cell_counter[idx] += 1
-            elif self.dyn_list_cell_counter[idx] > 1:
-                self.dyn_list_cell_counter[idx] -= 1
-
-            # Mutate process
-            p = self.dyn_list_cell_counter / np.sum(self.dyn_list_cell_counter)
-            r1, r2, r3 = np.random.choice(list(set(range(0, self.pop_size))), 3, replace=False, p=p)
-            pos_new = self.pop[r1][self.ID_POS] + self.wf * (self.pop[r2][self.ID_POS] - self.pop[r3][self.ID_POS])
-            condition = np.random.random(self.problem.n_dims) < self.cr
-            pos_new = np.where(condition, pos_new, self.pop[idx][self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            # for each pos_new, generate the fitness
-            target = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, target], self.pop[idx]):
-                self.pop[idx] = [pos_new, target]
-                self.dyn_list_life_signal[idx] += 10
-
-        ## Light-zone process   (no needs parallelization)
-        self.dyn_list_life_signal -= 10
-        fit_list = np.array([item[self.ID_TAR][self.ID_FIT] for item in self.pop])
-        fit_max = np.max(fit_list)
-        fit_min = np.min(fit_list)
-        fit = (fit_list - fit_max) / (fit_min - fit_max)
-        if self.problem.minmax != 'min':
-            fit = 1 - fit
-        self.dyn_list_life_signal += 10 * fit
+#!/usr/bin/env python
+# Created by "Thieu" at 16:44, 18/03/2020 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class BaseGCO(Optimizer):
+    """
+    The developed version: Germinal Center Optimization (GCO)
+
+    Notes
+    ~~~~~
+    + The global best solution and 2 random solutions are used instead of randomizing 3 solutions
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + cr (float): [0.5, 0.95], crossover rate, default = 0.7 (Same as DE algorithm)
+        + wf (float): [1.0, 2.0], weighting factor (f in the paper), default = 1.25 (Same as DE algorithm)
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.system_based.GCO import BaseGCO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> cr = 0.7
+    >>> wf = 1.25
+    >>> model = BaseGCO(epoch, pop_size, cr, wf)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, cr=0.7, wf=1.25, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            cr (float): crossover rate, default = 0.7 (Same as DE algorithm)
+            wf (float): weighting factor (f in the paper), default = 1.25 (Same as DE algorithm)
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.cr = self.validator.check_float("cr", cr, (0, 1.0))
+        self.wf = self.validator.check_float("wf", wf, (0, 3.0))
+        self.set_parameters(["epoch", "pop_size", "cr", "wf"])
+        self.sort_flag = False
+
+    def initialize_variables(self):
+        self.dyn_list_cell_counter = np.ones(self.pop_size)  # CEll Counter
+        self.dyn_list_life_signal = 70 * np.ones(self.pop_size)  # 70% to duplicate, and 30% to die  # LIfe-Signal
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        ## Dark-zone process    (can be parallelization)
+        pop_new = []
+        for idx in range(0, self.pop_size):
+            if np.random.uniform(0, 100) < self.dyn_list_life_signal[idx]:
+                self.dyn_list_cell_counter[idx] += 1
+            else:
+                self.dyn_list_cell_counter[idx] = 1
+
+            # Mutate process
+            r1, r2 = np.random.choice(list(set(range(0, self.pop_size)) - {idx}), 2, replace=False)
+            pos_new = self.g_best[self.ID_POS] + self.wf * (self.pop[r2][self.ID_POS] - self.pop[r1][self.ID_POS])
+            condition = np.random.random(self.problem.n_dims) < self.cr
+            pos_new = np.where(condition, pos_new, self.pop[idx][self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            pop_new.append([pos_new, None])
+            if self.mode not in self.AVAILABLE_MODES:
+                pop_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+        pop_new = self.update_target_wrapper_population(pop_new)
+        for idx in range(0, self.pop_size):
+            if self.compare_agent(pop_new[idx], self.pop[idx]):
+                self.dyn_list_cell_counter[idx] += 10
+                self.pop[idx] = deepcopy(pop_new[idx])
+
+        ## Light-zone process   (no needs parallelization)
+        for i in range(0, self.pop_size):
+            self.dyn_list_cell_counter[i] = 10
+            fit_list = np.array([item[self.ID_TAR][self.ID_FIT] for item in self.pop])
+            fit_max = max(fit_list)
+            fit_min = min(fit_list)
+            self.dyn_list_cell_counter[i] += 10 * (self.pop[i][self.ID_TAR][self.ID_FIT] - fit_max) / (fit_min - fit_max + self.EPSILON)
+
+
+class OriginalGCO(BaseGCO):
+    """
+    The original version of: Germinal Center Optimization (GCO)
+
+    Links:
+        1. https://doi.org/10.2991/ijcis.2018.25905179
+        2. https://www.atlantis-press.com/journals/ijcis/25905179/view
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + cr (float): [0.5, 0.95], crossover rate, default = 0.7 (Same as DE algorithm)
+        + wf (float): [1.0, 2.0], weighting factor (f in the paper), default = 1.25 (Same as DE algorithm)
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.system_based.GCO import OriginalGCO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> cr = 0.7
+    >>> wf = 1.25
+    >>> model = OriginalGCO(epoch, pop_size, cr, wf)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] VillaseÃ±or, C., Arana-Daniel, N., Alanis, A.Y., LÃ³pez-Franco, C. and Hernandez-Vargas, E.A., 2018.
+    Germinal center optimization algorithm. International Journal of Computational Intelligence Systems, 12(1), p.13.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, cr=0.7, wf=1.25, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            cr (float): crossover rate, default = 0.7 (Same as DE algorithm)
+            wf (float): weighting factor (f in the paper), default = 1.25 (Same as DE algorithm)
+        """
+        super().__init__(epoch, pop_size, cr, wf, **kwargs)
+        self.support_parallel_modes = False
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        ## Dark-zone process    (can be parallelization)
+        for idx in range(0, self.pop_size):
+            if np.random.uniform(0, 100) < self.dyn_list_life_signal[idx]:
+                self.dyn_list_cell_counter[idx] += 1
+            elif self.dyn_list_cell_counter[idx] > 1:
+                self.dyn_list_cell_counter[idx] -= 1
+
+            # Mutate process
+            p = self.dyn_list_cell_counter / np.sum(self.dyn_list_cell_counter)
+            r1, r2, r3 = np.random.choice(list(set(range(0, self.pop_size))), 3, replace=False, p=p)
+            pos_new = self.pop[r1][self.ID_POS] + self.wf * (self.pop[r2][self.ID_POS] - self.pop[r3][self.ID_POS])
+            condition = np.random.random(self.problem.n_dims) < self.cr
+            pos_new = np.where(condition, pos_new, self.pop[idx][self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            # for each pos_new, generate the fitness
+            target = self.get_target_wrapper(pos_new)
+            if self.compare_agent([pos_new, target], self.pop[idx]):
+                self.pop[idx] = [pos_new, target]
+                self.dyn_list_life_signal[idx] += 10
+
+        ## Light-zone process   (no needs parallelization)
+        self.dyn_list_life_signal -= 10
+        fit_list = np.array([item[self.ID_TAR][self.ID_FIT] for item in self.pop])
+        fit_max = np.max(fit_list)
+        fit_min = np.min(fit_list)
+        fit = (fit_list - fit_max) / (fit_min - fit_max)
+        if self.problem.minmax != 'min':
+            fit = 1 - fit
+        self.dyn_list_life_signal += 10 * fit
```

### Comparing `mealpy-2.5.3/mealpy/system_based/WCA.py` & `mealpy-2.5.3a1/mealpy/system_based/WCA.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,150 +1,150 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 09:55, 02/03/2021 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.optimizer import Optimizer
-
-
-class OriginalWCA(Optimizer):
-    """
-    The original version of: Water Cycle Algorithm (WCA)
-
-    Links:
-        1. https://doi.org/10.1016/j.compstruc.2012.07.010
-
-    Notes
-    ~~~~~
-    The ideas are (almost the same as ICO algorithm):
-        + 1 sea is global best solution
-        + a few river which are second, third, ...
-        + other left are stream (will flow directed to sea or river)
-
-    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
-        + nsr (int): [4, 10], Number of rivers + sea (sea = 1), default = 4
-        + wc (float): [1.0, 3.0], Weighting coefficient (C in the paper), default = 2
-        + dmax (float): [1e-6], fixed parameter, Evaporation condition constant, default=1e-6
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.system_based.WCA import OriginalWCA
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict1 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>> }
-    >>>
-    >>> epoch = 1000
-    >>> pop_size = 50
-    >>> nsr = 4
-    >>> wc = 2.0
-    >>> dmax = 1e-6
-    >>> model = OriginalWCA(epoch, pop_size, nsr, wc, dmax)
-    >>> best_position, best_fitness = model.solve(problem_dict1)
-    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
-
-    References
-    ~~~~~~~~~~
-    [1] Eskandar, H., Sadollah, A., Bahreininejad, A. and Hamdi, M., 2012. Water cycle algorithmâA novel metaheuristic
-    optimization method for solving constrained engineering optimization problems. Computers & Structures, 110, pp.151-166.
-    """
-
-    def __init__(self, epoch=10000, pop_size=100, nsr=4, wc=2.0, dmax=1e-6, **kwargs):
-        """
-        Args:
-            epoch (int): maximum number of iterations, default = 10000
-            pop_size (int): number of population size, default = 100
-            nsr (int): Number of rivers + sea (sea = 1), default = 4
-            wc (float): Weighting coefficient (C in the paper), default = 2.0
-            dmax (float): Evaporation condition constant, default=1e-6
-        """
-        super().__init__(**kwargs)
-        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
-        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
-        self.nsr = self.validator.check_int("nsr", nsr, [2, int(self.pop_size/2)])
-        self.wc = self.validator.check_float("wc", wc, (1.0, 3.0))
-        self.dmax = self.validator.check_float("dmax", dmax, (0, 1.0))
-        self.set_parameters(["epoch", "pop_size", "nsr", "wc", "dmax"])
-        self.sort_flag = True
-
-    def initialization(self):
-        if self.pop is None:
-            self.pop = self.create_population(self.pop_size)
-        self.pop, self.g_best = self.get_global_best_solution(self.pop)
-        self.ecc = self.dmax  # Evaporation condition constant - variable
-        n_stream = self.pop_size - self.nsr
-        g_best = deepcopy(self.pop[0])  # Global best solution (sea)
-        self.pop_best = deepcopy(self.pop[:self.nsr])  # Including sea and river (1st solution is sea)
-        self.pop_stream = deepcopy(self.pop[self.nsr:])  # Forming Stream
-
-        # Designate streams to rivers and sea
-        cost_river_list = np.array([solution[self.ID_TAR][self.ID_FIT] for solution in self.pop_best])
-        num_child_in_river_list = np.round(np.abs(cost_river_list / np.sum(cost_river_list)) * n_stream).astype(int)
-        if np.sum(num_child_in_river_list) < n_stream:
-            num_child_in_river_list[-1] += n_stream - np.sum(num_child_in_river_list)
-        streams = {}
-        idx_already_selected = []
-        for i in range(0, self.nsr - 1):
-            streams[i] = []
-            idx_list = np.random.choice(list(set(range(0, n_stream)) - set(idx_already_selected)), num_child_in_river_list[i], replace=False).tolist()
-            idx_already_selected += idx_list
-            for idx in idx_list:
-                streams[i].append(self.pop_stream[idx])
-        idx_last = list(set(range(0, n_stream)) - set(idx_already_selected))
-        streams[self.nsr - 1] = []
-        for idx in idx_last:
-            streams[self.nsr - 1].append(self.pop_stream[idx])
-        self.streams = streams
-
-    def evolve(self, epoch):
-        """
-        The main operations (equations) of algorithm. Inherit from Optimizer class
-
-        Args:
-            epoch (int): The current iteration
-        """
-        # Update stream and river
-        for idx, stream_list in self.streams.items():
-            # Update stream
-            stream_new = []
-            for idx_stream, stream in enumerate(stream_list):
-                pos_new = stream[self.ID_POS] + np.random.uniform() * self.wc * (self.pop_best[idx][self.ID_POS] - stream[self.ID_POS])
-                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-                stream_new.append([pos_new, None])
-                if self.mode not in self.AVAILABLE_MODES:
-                    stream_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
-            stream_new = self.update_target_wrapper_population(stream_new)
-            stream_new, stream_best = self.get_global_best_solution(stream_new)
-            self.streams[idx] = stream_new
-            if self.compare_agent(stream_best, self.pop_best[idx]):
-                self.pop_best[idx] = deepcopy(stream_best)
-
-            # Update river
-            pos_new = self.pop_best[idx][self.ID_POS] + np.random.uniform() * self.wc * (self.g_best[self.ID_POS] - self.pop_best[idx][self.ID_POS])
-            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
-            target = self.get_target_wrapper(pos_new)
-            if self.compare_agent([pos_new, target], self.pop_best[idx]):
-                self.pop_best[idx] = [pos_new, target]
-
-        # Evaporation
-        for i in range(1, self.nsr):
-            distance = np.sqrt(np.sum((self.g_best[self.ID_POS] - self.pop_best[i][self.ID_POS]) ** 2))
-            if distance < self.ecc or np.random.rand() < 0.1:
-                child = self.create_solution(self.problem.lb, self.problem.ub)
-                pop_current_best, _ = self.get_global_best_solution(self.streams[i] + [child])
-                self.pop_best[i] = pop_current_best.pop(0)
-                self.streams[i] = pop_current_best
-        self.pop = deepcopy(self.pop_best)
-        for idx, stream_list in self.streams.items():
-            self.pop += stream_list
-        # Reduce the ecc
-        self.ecc = self.ecc - self.ecc / self.epoch
+#!/usr/bin/env python
+# Created by "Thieu" at 09:55, 02/03/2021 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.optimizer import Optimizer
+
+
+class OriginalWCA(Optimizer):
+    """
+    The original version of: Water Cycle Algorithm (WCA)
+
+    Links:
+        1. https://doi.org/10.1016/j.compstruc.2012.07.010
+
+    Notes
+    ~~~~~
+    The ideas are (almost the same as ICO algorithm):
+        + 1 sea is global best solution
+        + a few river which are second, third, ...
+        + other left are stream (will flow directed to sea or river)
+
+    Hyper-parameters should fine-tune in approximate range to get faster convergence toward the global optimum:
+        + nsr (int): [4, 10], Number of rivers + sea (sea = 1), default = 4
+        + wc (float): [1.0, 3.0], Weighting coefficient (C in the paper), default = 2
+        + dmax (float): [1e-6], fixed parameter, Evaporation condition constant, default=1e-6
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.system_based.WCA import OriginalWCA
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict1 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>> }
+    >>>
+    >>> epoch = 1000
+    >>> pop_size = 50
+    >>> nsr = 4
+    >>> wc = 2.0
+    >>> dmax = 1e-6
+    >>> model = OriginalWCA(epoch, pop_size, nsr, wc, dmax)
+    >>> best_position, best_fitness = model.solve(problem_dict1)
+    >>> print(f"Solution: {best_position}, Fitness: {best_fitness}")
+
+    References
+    ~~~~~~~~~~
+    [1] Eskandar, H., Sadollah, A., Bahreininejad, A. and Hamdi, M., 2012. Water cycle algorithmâA novel metaheuristic
+    optimization method for solving constrained engineering optimization problems. Computers & Structures, 110, pp.151-166.
+    """
+
+    def __init__(self, epoch=10000, pop_size=100, nsr=4, wc=2.0, dmax=1e-6, **kwargs):
+        """
+        Args:
+            epoch (int): maximum number of iterations, default = 10000
+            pop_size (int): number of population size, default = 100
+            nsr (int): Number of rivers + sea (sea = 1), default = 4
+            wc (float): Weighting coefficient (C in the paper), default = 2.0
+            dmax (float): Evaporation condition constant, default=1e-6
+        """
+        super().__init__(**kwargs)
+        self.epoch = self.validator.check_int("epoch", epoch, [1, 100000])
+        self.pop_size = self.validator.check_int("pop_size", pop_size, [10, 10000])
+        self.nsr = self.validator.check_int("nsr", nsr, [2, int(self.pop_size/2)])
+        self.wc = self.validator.check_float("wc", wc, (1.0, 3.0))
+        self.dmax = self.validator.check_float("dmax", dmax, (0, 1.0))
+        self.set_parameters(["epoch", "pop_size", "nsr", "wc", "dmax"])
+        self.sort_flag = True
+
+    def initialization(self):
+        if self.pop is None:
+            self.pop = self.create_population(self.pop_size)
+        self.pop, self.g_best = self.get_global_best_solution(self.pop)
+        self.ecc = self.dmax  # Evaporation condition constant - variable
+        n_stream = self.pop_size - self.nsr
+        g_best = deepcopy(self.pop[0])  # Global best solution (sea)
+        self.pop_best = deepcopy(self.pop[:self.nsr])  # Including sea and river (1st solution is sea)
+        self.pop_stream = deepcopy(self.pop[self.nsr:])  # Forming Stream
+
+        # Designate streams to rivers and sea
+        cost_river_list = np.array([solution[self.ID_TAR][self.ID_FIT] for solution in self.pop_best])
+        num_child_in_river_list = np.round(np.abs(cost_river_list / np.sum(cost_river_list)) * n_stream).astype(int)
+        if np.sum(num_child_in_river_list) < n_stream:
+            num_child_in_river_list[-1] += n_stream - np.sum(num_child_in_river_list)
+        streams = {}
+        idx_already_selected = []
+        for i in range(0, self.nsr - 1):
+            streams[i] = []
+            idx_list = np.random.choice(list(set(range(0, n_stream)) - set(idx_already_selected)), num_child_in_river_list[i], replace=False).tolist()
+            idx_already_selected += idx_list
+            for idx in idx_list:
+                streams[i].append(self.pop_stream[idx])
+        idx_last = list(set(range(0, n_stream)) - set(idx_already_selected))
+        streams[self.nsr - 1] = []
+        for idx in idx_last:
+            streams[self.nsr - 1].append(self.pop_stream[idx])
+        self.streams = streams
+
+    def evolve(self, epoch):
+        """
+        The main operations (equations) of algorithm. Inherit from Optimizer class
+
+        Args:
+            epoch (int): The current iteration
+        """
+        # Update stream and river
+        for idx, stream_list in self.streams.items():
+            # Update stream
+            stream_new = []
+            for idx_stream, stream in enumerate(stream_list):
+                pos_new = stream[self.ID_POS] + np.random.uniform() * self.wc * (self.pop_best[idx][self.ID_POS] - stream[self.ID_POS])
+                pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+                stream_new.append([pos_new, None])
+                if self.mode not in self.AVAILABLE_MODES:
+                    stream_new[-1][self.ID_TAR] = self.get_target_wrapper(pos_new)
+            stream_new = self.update_target_wrapper_population(stream_new)
+            stream_new, stream_best = self.get_global_best_solution(stream_new)
+            self.streams[idx] = stream_new
+            if self.compare_agent(stream_best, self.pop_best[idx]):
+                self.pop_best[idx] = deepcopy(stream_best)
+
+            # Update river
+            pos_new = self.pop_best[idx][self.ID_POS] + np.random.uniform() * self.wc * (self.g_best[self.ID_POS] - self.pop_best[idx][self.ID_POS])
+            pos_new = self.amend_position(pos_new, self.problem.lb, self.problem.ub)
+            target = self.get_target_wrapper(pos_new)
+            if self.compare_agent([pos_new, target], self.pop_best[idx]):
+                self.pop_best[idx] = [pos_new, target]
+
+        # Evaporation
+        for i in range(1, self.nsr):
+            distance = np.sqrt(np.sum((self.g_best[self.ID_POS] - self.pop_best[i][self.ID_POS]) ** 2))
+            if distance < self.ecc or np.random.rand() < 0.1:
+                child = self.create_solution(self.problem.lb, self.problem.ub)
+                pop_current_best, _ = self.get_global_best_solution(self.streams[i] + [child])
+                self.pop_best[i] = pop_current_best.pop(0)
+                self.streams[i] = pop_current_best
+        self.pop = deepcopy(self.pop_best)
+        for idx, stream_list in self.streams.items():
+            self.pop += stream_list
+        # Reduce the ecc
+        self.ecc = self.ecc - self.ecc / self.epoch
```

### Comparing `mealpy-2.5.3/mealpy/utils/history.py` & `mealpy-2.5.3a1/mealpy/utils/history.py`

 * *Ordering differences only*

 * *Files 25% similar despite different names*

```diff
@@ -1,213 +1,213 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 14:51, 13/10/2021 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-import numpy as np
-from copy import deepcopy
-from mealpy.utils import visualize
-from mealpy.utils.logger import Logger
-
-
-class History:
-    """
-    A History class is responsible for saving each iteration's output.
-
-    Notes
-    ~~~~~
-    + Access to variables in this class:
-        + list_global_best: List of global best SOLUTION found so far in all previous generations
-        + list_current_best: List of current best SOLUTION in each previous generations
-        + list_epoch_time: List of runtime for each generation
-        + list_global_best_fit: List of global best FITNESS found so far in all previous generations
-        + list_current_best_fit: List of current best FITNESS in each previous generations
-        + list_diversity: List of DIVERSITY of swarm in all generations
-        + list_exploitation: List of EXPLOITATION percentages for all generations
-        + list_exploration: List of EXPLORATION percentages for all generations
-        + list_global_worst: List of global worst SOLUTION found so far in all previous generations
-        + list_current_worst: List of current worst SOLUTION in each previous generations
-        + list_population: List of POPULATION in each generations
-        + **Warning**, the last variable 'list_population' can cause the error related to 'memory' when saving model.
-            Better to set parameter 'save_population' to False in the input problem dictionary to not using it.
-
-    + There are 8 methods to draw available in this class:
-        + save_global_best_fitness_chart()
-        + save_local_best_fitness_chart()
-        + save_global_objectives_chart()
-        + save_local_objectives_chart()
-        + save_exploration_exploitation_chart()
-        + save_diversity_chart()
-        + save_runtime_chart()
-        + save_trajectory_chart()
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.PSO import OriginalPSO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>>     "verbose": True,
-    >>>     "save_population": True        # To be able to draw the trajectory figure
-    >>> }
-    >>> model = OriginalPSO(epoch=1000, pop_size=50)
-    >>> model.solve(problem_dict)
-    >>>
-    >>> model.history.save_global_objectives_chart(filename="hello/goc")
-    >>> model.history.save_local_objectives_chart(filename="hello/loc")
-    >>> model.history.save_global_best_fitness_chart(filename="hello/gbfc")
-    >>> model.history.save_local_best_fitness_chart(filename="hello/lbfc")
-    >>> model.history.save_runtime_chart(filename="hello/rtc")
-    >>> model.history.save_exploration_exploitation_chart(filename="hello/eec")
-    >>> model.history.save_diversity_chart(filename="hello/dc")
-    >>> model.history.save_trajectory_chart(list_agent_idx=[3, 5], selected_dimensions=[3], filename="hello/tc")
-    >>>
-    >>> ## Get list of global best solution after all generations
-    >>> print(model.history.list_global_best)
-    """
-
-    def __init__(self, **kwargs):
-        self.list_global_best = []  # List of global best solution found so far in all previous generations
-        self.list_current_best = []  # List of current best solution in each previous generations
-        self.list_epoch_time = []  # List of runtime for each generation
-        self.list_global_best_fit = []  # List of global best fitness found so far in all previous generations
-        self.list_current_best_fit = []  # List of current best fitness in each previous generations
-        self.list_population = []  # List of population in each generation
-        self.list_diversity = []  # List of diversity of swarm in all generations
-        self.list_exploitation = []  # List of exploitation percentages for all generations
-        self.list_exploration = []  # List of exploration percentages for all generations
-        self.list_global_worst = [] # List of global worst solution found so far in all previous generations
-        self.list_current_worst = [] # List of current worst solution in each previous generations
-        self.epoch, self.log_to, self.log_file = None, None, None
-        self.__set_keyword_arguments(kwargs)
-        self.logger = Logger(self.log_to, log_file=self.log_file).create_logger(name=f"{__name__}.{__class__.__name__}",
-            format_str='%(asctime)s, %(levelname)s, %(name)s [line: %(lineno)d]: %(message)s')
-
-    def __set_keyword_arguments(self, kwargs):
-        for key, value in kwargs.items():
-            setattr(self, key, value)
-
-    def store_initial_best_worst(self, best_agent, worst_agent):
-        self.list_global_best = [deepcopy(best_agent)]
-        self.list_current_best = [deepcopy(best_agent)]
-        self.list_global_worst = [deepcopy(worst_agent)]
-        self.list_current_worst = [deepcopy(worst_agent)]
-
-    def get_global_repeated_times(self, id_fitness, id_target, epsilon):
-        count = 0
-        for i in range(0, len(self.list_global_best) - 1):
-            temp = np.abs(self.list_global_best[i][id_fitness][id_target] - self.list_global_best[i + 1][id_fitness][id_target])
-            if temp <= epsilon:
-                count += 1
-            else:
-                count = 0
-        return count
-
-    def save_global_best_fitness_chart(self, title='Global Best Fitness', legend=None, linestyle='-', color='b', x_label="#Iteration",
-                                       y_label="Function Value", filename="global-best-fitness-chart", exts=(".png", ".pdf"), verbose=True):
-        # Draw global best fitness found so far in previous generations
-        visualize.export_convergence_chart(data=self.list_global_best_fit, title=title, legend=legend, linestyle=linestyle,
-                                 color=color, x_label=x_label, y_label=y_label, filename=filename, exts=exts, verbose=verbose)
-
-    def save_local_best_fitness_chart(self, title='Local Best Fitness', legend=None, linestyle='-', color='b', x_label="#Iteration",
-                                      y_label="Function Value", filename="local-best-fitness-chart", exts=(".png", ".pdf"), verbose=True):
-        # Draw current best fitness in each previous generation
-        visualize.export_convergence_chart(self.list_current_best_fit, title=title, legend=legend, linestyle=linestyle, color=color,
-                                 x_label=x_label, y_label=y_label, filename=filename, exts=exts, verbose=verbose)
-
-    def save_runtime_chart(self, title='Runtime chart', legend=None, linestyle='-', color='b', x_label="#Iteration",
-                           y_label='Second', filename="runtime-chart", exts=(".png", ".pdf"), verbose=True):
-        # Draw runtime for each generation
-        visualize.export_convergence_chart(self.list_epoch_time, title=title, legend=legend, linestyle=linestyle, color=color,
-                                 x_label=x_label, y_label=y_label, filename=filename, exts=exts, verbose=verbose)
-
-    ## The paper: On the exploration and exploitation in popular swarm-based metaheuristic algorithms
-    def save_exploration_exploitation_chart(self, title="Exploration vs Exploitation Percentages", list_colors=('blue', 'orange'),
-                                            filename="exploration-exploitation-chart", verbose=True):
-        # This exploration/exploitation chart should draws for single algorithm and single fitness function
-        # Draw exploration and exploitation chart
-        visualize.export_explore_exploit_chart(data=[self.list_exploration, self.list_exploitation], title=title,
-                                     list_colors=list_colors, filename=filename, verbose=verbose)
-
-    def save_diversity_chart(self, title='Diversity Measurement Chart', algorithm_name='Algorithm',
-                             filename="diversity-chart", verbose=True):
-        # This diversity chart should draws for multiple algorithms for a single fitness function at the same time
-        # to compare the diversity spreading
-        visualize.export_diversity_chart(data=[self.list_diversity], title=title, list_legends=[algorithm_name],
-                               filename=filename, verbose=verbose)
-
-    ## Because convergence chart is formulated from objective values and weights,
-    ## thus we also want to draw objective charts to understand the convergence
-    ## Need a little bit more pre-processing
-
-    def save_global_objectives_chart(self, title='Global Objectives Chart', x_label="#Iteration", y_labels=None,
-                                     filename="global-objectives-chart", verbose=True):
-        # 2D array / matrix 2D
-        global_obj_list = np.array([agent[1][-1] for agent in self.list_global_best])
-        # Make each obj_list as a element in array for drawing
-        global_obj_list = [global_obj_list[:, idx] for idx in range(0, len(global_obj_list[0]))]
-        visualize.export_objectives_chart(global_obj_list, title=title, x_label=x_label, y_labels=y_labels, filename=filename, verbose=verbose)
-
-    def save_local_objectives_chart(self, title='Local Objectives Chart', x_label="#Iteration", y_labels=None,
-                                    filename="local-objectives-chart", verbose=True):
-        current_obj_list = np.array([agent[1][-1] for agent in self.list_current_best])
-        # Make each obj_list as a element in array for drawing
-        current_obj_list = [current_obj_list[:, idx] for idx in range(0, len(current_obj_list[0]))]
-        visualize.export_objectives_chart(current_obj_list, title=title, x_label=x_label, y_labels=y_labels,
-                                filename=filename, verbose=verbose)
-
-    def save_trajectory_chart(self, title="Trajectory of some agents",
-                              list_agent_idx=(1, 2, 3), selected_dimensions=(1, 2),
-                              filename="trajectory-chart", verbose=True):
-        if len(self.list_population) < 2:
-            raise ValueError(f"Can't draw the trajectory because 'save_population' is set to False or the number of epochs is too small.")
-        ## Drawing trajectory of some agents in the first and second dimensions
-        # Need a little bit more pre-processing
-        list_agent_idx = set(list_agent_idx)
-        selected_dimensions = set(selected_dimensions)
-        list_agent_idx = sorted(list_agent_idx)
-        selected_dimensions = sorted(selected_dimensions)
-        n_dim = len(selected_dimensions)
-
-        if n_dim not in [1, 2]:
-            raise ValueError(f"Trajectory chart for more than 2 dimensions is not supported.")
-        if len(list_agent_idx) < 1 or len(list_agent_idx) > 10:
-            raise ValueError(f"Trajectory chart for more than 10 agents is not supported.")
-        if list_agent_idx[-1] > len(self.list_population[0]) or list_agent_idx[0] < 1:
-            raise ValueError(f"Can't draw trajectory chart, the index of selected agents should be in range of [1, {len(self.list_population[0])}]")
-        if selected_dimensions[-1] > len(self.list_population[0][0][0]) or selected_dimensions[0] < 1:
-            raise ValueError(f"Can't draw trajectory chart, the index of selected dimensions should be in range of [1, {len(self.list_population[0][0][0])}]")
-
-        pos_list = []
-        list_legends = []
-
-        # pop[0]: Get the first solution
-        # pop[0][0]: Get the position of the first solution
-        # pop[0][0][0]: Get the first dimension of the position of the first solution
-        if n_dim == 1:
-            y_label = f"x{selected_dimensions[0]}"
-            for idx, id_agent in enumerate(list_agent_idx):
-                x = [pop[id_agent - 1][0][selected_dimensions[0] - 1] for pop in self.list_population]
-                pos_list.append(x)
-                list_legends.append(f"Agent {id_agent}")
-            visualize.export_trajectory_chart(pos_list, n_dimensions=n_dim, title=title, list_legends=list_legends,
-                                    y_label=y_label, filename=filename, verbose=verbose)
-        elif n_dim == 2:
-            x_label = f"x{selected_dimensions[0]}"
-            y_label = f"x{selected_dimensions[1]}"
-            for idx1, id_agent in enumerate(list_agent_idx):
-                pos_temp = []
-                for idx2, id_dim in enumerate(selected_dimensions):
-                    x = [pop[id_agent - 1][0][id_dim - 1] for pop in self.list_population]
-                    pos_temp.append(x)
-                pos_list.append(pos_temp)
-                list_legends.append(f"Agent {id_agent}")
-            visualize.export_trajectory_chart(pos_list, n_dimensions=n_dim, title=title, list_legends=list_legends, x_label=x_label,
-                                    y_label=y_label, filename=filename, verbose=verbose)
+#!/usr/bin/env python
+# Created by "Thieu" at 14:51, 13/10/2021 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+import numpy as np
+from copy import deepcopy
+from mealpy.utils import visualize
+from mealpy.utils.logger import Logger
+
+
+class History:
+    """
+    A History class is responsible for saving each iteration's output.
+
+    Notes
+    ~~~~~
+    + Access to variables in this class:
+        + list_global_best: List of global best SOLUTION found so far in all previous generations
+        + list_current_best: List of current best SOLUTION in each previous generations
+        + list_epoch_time: List of runtime for each generation
+        + list_global_best_fit: List of global best FITNESS found so far in all previous generations
+        + list_current_best_fit: List of current best FITNESS in each previous generations
+        + list_diversity: List of DIVERSITY of swarm in all generations
+        + list_exploitation: List of EXPLOITATION percentages for all generations
+        + list_exploration: List of EXPLORATION percentages for all generations
+        + list_global_worst: List of global worst SOLUTION found so far in all previous generations
+        + list_current_worst: List of current worst SOLUTION in each previous generations
+        + list_population: List of POPULATION in each generations
+        + **Warning**, the last variable 'list_population' can cause the error related to 'memory' when saving model.
+            Better to set parameter 'save_population' to False in the input problem dictionary to not using it.
+
+    + There are 8 methods to draw available in this class:
+        + save_global_best_fitness_chart()
+        + save_local_best_fitness_chart()
+        + save_global_objectives_chart()
+        + save_local_objectives_chart()
+        + save_exploration_exploitation_chart()
+        + save_diversity_chart()
+        + save_runtime_chart()
+        + save_trajectory_chart()
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.PSO import OriginalPSO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>>     "verbose": True,
+    >>>     "save_population": True        # To be able to draw the trajectory figure
+    >>> }
+    >>> model = OriginalPSO(epoch=1000, pop_size=50)
+    >>> model.solve(problem_dict)
+    >>>
+    >>> model.history.save_global_objectives_chart(filename="hello/goc")
+    >>> model.history.save_local_objectives_chart(filename="hello/loc")
+    >>> model.history.save_global_best_fitness_chart(filename="hello/gbfc")
+    >>> model.history.save_local_best_fitness_chart(filename="hello/lbfc")
+    >>> model.history.save_runtime_chart(filename="hello/rtc")
+    >>> model.history.save_exploration_exploitation_chart(filename="hello/eec")
+    >>> model.history.save_diversity_chart(filename="hello/dc")
+    >>> model.history.save_trajectory_chart(list_agent_idx=[3, 5], selected_dimensions=[3], filename="hello/tc")
+    >>>
+    >>> ## Get list of global best solution after all generations
+    >>> print(model.history.list_global_best)
+    """
+
+    def __init__(self, **kwargs):
+        self.list_global_best = []  # List of global best solution found so far in all previous generations
+        self.list_current_best = []  # List of current best solution in each previous generations
+        self.list_epoch_time = []  # List of runtime for each generation
+        self.list_global_best_fit = []  # List of global best fitness found so far in all previous generations
+        self.list_current_best_fit = []  # List of current best fitness in each previous generations
+        self.list_population = []  # List of population in each generation
+        self.list_diversity = []  # List of diversity of swarm in all generations
+        self.list_exploitation = []  # List of exploitation percentages for all generations
+        self.list_exploration = []  # List of exploration percentages for all generations
+        self.list_global_worst = [] # List of global worst solution found so far in all previous generations
+        self.list_current_worst = [] # List of current worst solution in each previous generations
+        self.epoch, self.log_to, self.log_file = None, None, None
+        self.__set_keyword_arguments(kwargs)
+        self.logger = Logger(self.log_to, log_file=self.log_file).create_logger(name=f"{__name__}.{__class__.__name__}",
+            format_str='%(asctime)s, %(levelname)s, %(name)s [line: %(lineno)d]: %(message)s')
+
+    def __set_keyword_arguments(self, kwargs):
+        for key, value in kwargs.items():
+            setattr(self, key, value)
+
+    def store_initial_best_worst(self, best_agent, worst_agent):
+        self.list_global_best = [deepcopy(best_agent)]
+        self.list_current_best = [deepcopy(best_agent)]
+        self.list_global_worst = [deepcopy(worst_agent)]
+        self.list_current_worst = [deepcopy(worst_agent)]
+
+    def get_global_repeated_times(self, id_fitness, id_target, epsilon):
+        count = 0
+        for i in range(0, len(self.list_global_best) - 1):
+            temp = np.abs(self.list_global_best[i][id_fitness][id_target] - self.list_global_best[i + 1][id_fitness][id_target])
+            if temp <= epsilon:
+                count += 1
+            else:
+                count = 0
+        return count
+
+    def save_global_best_fitness_chart(self, title='Global Best Fitness', legend=None, linestyle='-', color='b', x_label="#Iteration",
+                                       y_label="Function Value", filename="global-best-fitness-chart", exts=(".png", ".pdf"), verbose=True):
+        # Draw global best fitness found so far in previous generations
+        visualize.export_convergence_chart(data=self.list_global_best_fit, title=title, legend=legend, linestyle=linestyle,
+                                 color=color, x_label=x_label, y_label=y_label, filename=filename, exts=exts, verbose=verbose)
+
+    def save_local_best_fitness_chart(self, title='Local Best Fitness', legend=None, linestyle='-', color='b', x_label="#Iteration",
+                                      y_label="Function Value", filename="local-best-fitness-chart", exts=(".png", ".pdf"), verbose=True):
+        # Draw current best fitness in each previous generation
+        visualize.export_convergence_chart(self.list_current_best_fit, title=title, legend=legend, linestyle=linestyle, color=color,
+                                 x_label=x_label, y_label=y_label, filename=filename, exts=exts, verbose=verbose)
+
+    def save_runtime_chart(self, title='Runtime chart', legend=None, linestyle='-', color='b', x_label="#Iteration",
+                           y_label='Second', filename="runtime-chart", exts=(".png", ".pdf"), verbose=True):
+        # Draw runtime for each generation
+        visualize.export_convergence_chart(self.list_epoch_time, title=title, legend=legend, linestyle=linestyle, color=color,
+                                 x_label=x_label, y_label=y_label, filename=filename, exts=exts, verbose=verbose)
+
+    ## The paper: On the exploration and exploitation in popular swarm-based metaheuristic algorithms
+    def save_exploration_exploitation_chart(self, title="Exploration vs Exploitation Percentages", list_colors=('blue', 'orange'),
+                                            filename="exploration-exploitation-chart", verbose=True):
+        # This exploration/exploitation chart should draws for single algorithm and single fitness function
+        # Draw exploration and exploitation chart
+        visualize.export_explore_exploit_chart(data=[self.list_exploration, self.list_exploitation], title=title,
+                                     list_colors=list_colors, filename=filename, verbose=verbose)
+
+    def save_diversity_chart(self, title='Diversity Measurement Chart', algorithm_name='Algorithm',
+                             filename="diversity-chart", verbose=True):
+        # This diversity chart should draws for multiple algorithms for a single fitness function at the same time
+        # to compare the diversity spreading
+        visualize.export_diversity_chart(data=[self.list_diversity], title=title, list_legends=[algorithm_name],
+                               filename=filename, verbose=verbose)
+
+    ## Because convergence chart is formulated from objective values and weights,
+    ## thus we also want to draw objective charts to understand the convergence
+    ## Need a little bit more pre-processing
+
+    def save_global_objectives_chart(self, title='Global Objectives Chart', x_label="#Iteration", y_labels=None,
+                                     filename="global-objectives-chart", verbose=True):
+        # 2D array / matrix 2D
+        global_obj_list = np.array([agent[1][-1] for agent in self.list_global_best])
+        # Make each obj_list as a element in array for drawing
+        global_obj_list = [global_obj_list[:, idx] for idx in range(0, len(global_obj_list[0]))]
+        visualize.export_objectives_chart(global_obj_list, title=title, x_label=x_label, y_labels=y_labels, filename=filename, verbose=verbose)
+
+    def save_local_objectives_chart(self, title='Local Objectives Chart', x_label="#Iteration", y_labels=None,
+                                    filename="local-objectives-chart", verbose=True):
+        current_obj_list = np.array([agent[1][-1] for agent in self.list_current_best])
+        # Make each obj_list as a element in array for drawing
+        current_obj_list = [current_obj_list[:, idx] for idx in range(0, len(current_obj_list[0]))]
+        visualize.export_objectives_chart(current_obj_list, title=title, x_label=x_label, y_labels=y_labels,
+                                filename=filename, verbose=verbose)
+
+    def save_trajectory_chart(self, title="Trajectory of some agents",
+                              list_agent_idx=(1, 2, 3), selected_dimensions=(1, 2),
+                              filename="trajectory-chart", verbose=True):
+        if len(self.list_population) < 2:
+            raise ValueError(f"Can't draw the trajectory because 'save_population' is set to False or the number of epochs is too small.")
+        ## Drawing trajectory of some agents in the first and second dimensions
+        # Need a little bit more pre-processing
+        list_agent_idx = set(list_agent_idx)
+        selected_dimensions = set(selected_dimensions)
+        list_agent_idx = sorted(list_agent_idx)
+        selected_dimensions = sorted(selected_dimensions)
+        n_dim = len(selected_dimensions)
+
+        if n_dim not in [1, 2]:
+            raise ValueError(f"Trajectory chart for more than 2 dimensions is not supported.")
+        if len(list_agent_idx) < 1 or len(list_agent_idx) > 10:
+            raise ValueError(f"Trajectory chart for more than 10 agents is not supported.")
+        if list_agent_idx[-1] > len(self.list_population[0]) or list_agent_idx[0] < 1:
+            raise ValueError(f"Can't draw trajectory chart, the index of selected agents should be in range of [1, {len(self.list_population[0])}]")
+        if selected_dimensions[-1] > len(self.list_population[0][0][0]) or selected_dimensions[0] < 1:
+            raise ValueError(f"Can't draw trajectory chart, the index of selected dimensions should be in range of [1, {len(self.list_population[0][0][0])}]")
+
+        pos_list = []
+        list_legends = []
+
+        # pop[0]: Get the first solution
+        # pop[0][0]: Get the position of the first solution
+        # pop[0][0][0]: Get the first dimension of the position of the first solution
+        if n_dim == 1:
+            y_label = f"x{selected_dimensions[0]}"
+            for idx, id_agent in enumerate(list_agent_idx):
+                x = [pop[id_agent - 1][0][selected_dimensions[0] - 1] for pop in self.list_population]
+                pos_list.append(x)
+                list_legends.append(f"Agent {id_agent}")
+            visualize.export_trajectory_chart(pos_list, n_dimensions=n_dim, title=title, list_legends=list_legends,
+                                    y_label=y_label, filename=filename, verbose=verbose)
+        elif n_dim == 2:
+            x_label = f"x{selected_dimensions[0]}"
+            y_label = f"x{selected_dimensions[1]}"
+            for idx1, id_agent in enumerate(list_agent_idx):
+                pos_temp = []
+                for idx2, id_dim in enumerate(selected_dimensions):
+                    x = [pop[id_agent - 1][0][id_dim - 1] for pop in self.list_population]
+                    pos_temp.append(x)
+                pos_list.append(pos_temp)
+                list_legends.append(f"Agent {id_agent}")
+            visualize.export_trajectory_chart(pos_list, n_dimensions=n_dim, title=title, list_legends=list_legends, x_label=x_label,
+                                    y_label=y_label, filename=filename, verbose=verbose)
```

### Comparing `mealpy-2.5.3/mealpy/utils/io.py` & `mealpy-2.5.3a1/mealpy/utils/io.py`

 * *Ordering differences only*

 * *Files 24% similar despite different names*

```diff
@@ -1,25 +1,25 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 20:08, 27/08/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import pickle
-
-
-def save_model(model, path_save:str):
-    if path_save is None:
-        path_save = "model.pkl"
-    else:
-        if path_save[-4:] != ".pkl":
-            path_save += ".pkl"
-    pickle.dump(model, open(path_save, 'wb'))
-
-
-def load_model(path_load:str):
-    if path_load is None:
-        path_load = "model.pkl"
-    else:
-        if path_load[-4:] != ".pkl":
-            path_load += ".pkl"
-    return pickle.load(open(path_load, 'rb'))
+#!/usr/bin/env python
+# Created by "Thieu" at 20:08, 27/08/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import pickle
+
+
+def save_model(model, path_save:str):
+    if path_save is None:
+        path_save = "model.pkl"
+    else:
+        if path_save[-4:] != ".pkl":
+            path_save += ".pkl"
+    pickle.dump(model, open(path_save, 'wb'))
+
+
+def load_model(path_load:str):
+    if path_load is None:
+        path_load = "model.pkl"
+    else:
+        if path_load[-4:] != ".pkl":
+            path_load += ".pkl"
+    return pickle.load(open(path_load, 'rb'))
```

### Comparing `mealpy-2.5.3/mealpy/utils/logger.py` & `mealpy-2.5.3a1/mealpy/utils/logger.py`

 * *Ordering differences only*

 * *Files 23% similar despite different names*

```diff
@@ -1,53 +1,53 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 14:57, 12/03/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import logging
-
-
-class Logger:
-
-    def __init__(self, log_to="console", **kwargs):
-        self.log_to = log_to
-        self.log_file = None
-        self.__set_keyword_arguments(kwargs)
-        self.default_formatter = logging.Formatter('%(asctime)s, %(levelname)s, %(name)s: %(message)s', datefmt="%Y/%m/%d %I:%M:%S %p")
-        self.default_logfile = "mealpy.log"
-
-    def __set_keyword_arguments(self, kwargs):
-        for key, value in kwargs.items():
-            setattr(self, key, value)
-
-    def create_logger(self, name=__name__, format_str=None):
-        logger = logging.getLogger(name)
-        if self.log_to == "console":
-            logger.setLevel(logging.INFO)
-            if format_str is None:
-                formatter = logging.Formatter('%(asctime)s, %(levelname)s, %(name)s: %(message)s', datefmt="%Y/%m/%d %I:%M:%S %p")
-            else:
-                formatter = logging.Formatter(format_str, datefmt="%Y/%m/%d %I:%M:%S %p")
-            handler = logging.StreamHandler()
-            handler.setFormatter(formatter)
-        elif self.log_to == "file":
-            logger.setLevel(logging.DEBUG)
-            if format_str is None:
-                formatter = logging.Formatter('%(asctime)s, %(levelname)s, %(name)s: %(message)s', datefmt="%Y/%m/%d %I:%M:%S %p")
-            else:
-                formatter = logging.Formatter(format_str, datefmt="%Y/%m/%d %I:%M:%S %p")
-            if self.log_file is None:
-                self.log_file = self.default_logfile
-            handler = logging.FileHandler(self.log_file)
-            handler.setFormatter(formatter)
-        else:
-            logger.setLevel(logging.ERROR)
-            if format_str is None:
-                formatter = logging.Formatter('%(asctime)s, %(levelname)s, %(name)s [line: %(lineno)d]: %(message)s', datefmt="%Y/%m/%d %I:%M:%S %p")
-            else:
-                formatter = logging.Formatter(format_str, datefmt="%Y/%m/%d %I:%M:%S %p")
-            handler = logging.StreamHandler()
-            handler.setFormatter(formatter)
-        if not logger.hasHandlers():
-            logger.addHandler(handler)
-        return logger
+#!/usr/bin/env python
+# Created by "Thieu" at 14:57, 12/03/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import logging
+
+
+class Logger:
+
+    def __init__(self, log_to="console", **kwargs):
+        self.log_to = log_to
+        self.log_file = None
+        self.__set_keyword_arguments(kwargs)
+        self.default_formatter = logging.Formatter('%(asctime)s, %(levelname)s, %(name)s: %(message)s', datefmt="%Y/%m/%d %I:%M:%S %p")
+        self.default_logfile = "mealpy.log"
+
+    def __set_keyword_arguments(self, kwargs):
+        for key, value in kwargs.items():
+            setattr(self, key, value)
+
+    def create_logger(self, name=__name__, format_str=None):
+        logger = logging.getLogger(name)
+        if self.log_to == "console":
+            logger.setLevel(logging.INFO)
+            if format_str is None:
+                formatter = logging.Formatter('%(asctime)s, %(levelname)s, %(name)s: %(message)s', datefmt="%Y/%m/%d %I:%M:%S %p")
+            else:
+                formatter = logging.Formatter(format_str, datefmt="%Y/%m/%d %I:%M:%S %p")
+            handler = logging.StreamHandler()
+            handler.setFormatter(formatter)
+        elif self.log_to == "file":
+            logger.setLevel(logging.DEBUG)
+            if format_str is None:
+                formatter = logging.Formatter('%(asctime)s, %(levelname)s, %(name)s: %(message)s', datefmt="%Y/%m/%d %I:%M:%S %p")
+            else:
+                formatter = logging.Formatter(format_str, datefmt="%Y/%m/%d %I:%M:%S %p")
+            if self.log_file is None:
+                self.log_file = self.default_logfile
+            handler = logging.FileHandler(self.log_file)
+            handler.setFormatter(formatter)
+        else:
+            logger.setLevel(logging.ERROR)
+            if format_str is None:
+                formatter = logging.Formatter('%(asctime)s, %(levelname)s, %(name)s [line: %(lineno)d]: %(message)s', datefmt="%Y/%m/%d %I:%M:%S %p")
+            else:
+                formatter = logging.Formatter(format_str, datefmt="%Y/%m/%d %I:%M:%S %p")
+            handler = logging.StreamHandler()
+            handler.setFormatter(formatter)
+        if not logger.hasHandlers():
+            logger.addHandler(handler)
+        return logger
```

### Comparing `mealpy-2.5.3/mealpy/utils/problem.py` & `mealpy-2.5.3a1/mealpy/utils/problem.py`

 * *Ordering differences only*

 * *Files 11% similar despite different names*

```diff
@@ -1,200 +1,200 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 17:28, 13/10/2021 ----------%
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-from mealpy.utils.logger import Logger
-
-
-class Problem:
-    """Class representing the mathematical form of the optimization problem.
-
-    Attributes:
-        lb (numpy.ndarray, list, tuple): Lower bounds of the problem.
-        ub (numpy.ndarray, list, tuple): Upper bounds of the problem.
-        minmax (str): Minimization or maximization problem (min, max), default = "min"
-
-    Notes
-    ~~~~~
-    + fit_func (callable): your fitness function
-    + lb (list, int, float): lower bound, should be list of values
-    + ub (list, int, float): upper bound, should be list of values
-    + minmax (str): "min" or "max" problem (Optional, default = "min")
-    + obj_weights: list weights for all your objectives (Optional, default = [1, 1, ...1])
-    + save_population (bool): save history of population or not, default = True (Optional). **Warning**:
-        + this parameter can save you from error related to 'memory' when your model is too big (i.e, training neural network, ...)
-        + when set to False, you can't use the function draw trajectory chart in history object (model.history.save_trajectory_chart)
-    + amend_position(callable): Depend on your problem, may need to design an amend_position function (Optional for continuous domain, Required for discrete domain)
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.PSO import OriginalPSO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>>     "minmax": "min",
-    >>>     "log_to": None,
-    >>>     "save_population": False,
-    >>> }
-    >>> model1 = OriginalPSO(epoch=1000, pop_size=50)
-    >>> model1.solve(problem_dict)
-    >>>
-    >>> ## For discrete problem, you need to design an amend_position function that can (1) bring your solution back to the valid range,
-    >>> ##    (2) can convert float number into integer number (combinatorial or permutation).
-    >>>
-    >>> def amend_position(solution, lb, ub):
-    >>>     ## Bring them back to valid range
-    >>>     solution = np.clip(solution, lb, ub)
-    >>>     ## Convert float to integer number
-    >>>     solution_int = solution.astype(int)
-    >>>     ## If the designed solution is permutation, then need an extra step here
-    >>>     ## .... Do it here and then return the valid solution
-    >>>     return solution_int
-    >>>
-    >>> problem_dict2 = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-100, ] * 30,
-    >>>     "ub": [100, ] * 30,
-    >>>     "minmax": "min",
-    >>>     "log_to": "file",
-    >>>     "log_file": "records.log",
-    >>>     "amend_position": amend_position
-    >>> }
-    >>> model2 = OriginalPSO(epoch=1000, pop_size=50)
-    >>> best_position, best_fitness = model2.solve(problem_dict2)
-    >>> print(f"Best solution: {best_position}, Best fitness: {best_fitness}")
-    """
-
-    SUPPORTED_ARRAY = (list, tuple, np.ndarray)
-
-    def __init__(self, lb=None, ub=None, minmax="min", **kwargs):
-        r"""Initialize Problem.
-
-        Args:
-            lb (numpy.ndarray, list, tuple): Lower bounds of the problem.
-            ub (numpy.ndarray, list, tuple): Upper bounds of the problem.
-            minmax (str): Minimization or maximization problem (min, max)
-            name (str): Name for this particular problem
-        """
-        self.name, self.log_to, self.log_file = "P", "console", "history.txt"
-        self.n_objs, self.obj_is_list, self.multi_objs, self.obj_weights = 1, False, False, None
-        self.n_dims, self.lb, self.ub, self.save_population = None, None, None, False
-
-        self.__set_keyword_arguments(kwargs)
-        self.__set_domain_range(lb, ub)
-        self.__set_functions(kwargs)
-        self.logger = Logger(self.log_to, log_file=self.log_file).create_logger(name=f"{__name__}.{__class__.__name__}",
-                                    format_str='%(asctime)s, %(levelname)s, %(name)s [line: %(lineno)d]: %(message)s')
-        self.minmax = minmax
-
-    def __set_keyword_arguments(self, kwargs):
-        for key, value in kwargs.items():
-            setattr(self, key, value)
-
-    def __set_domain_range(self, lb, ub):
-        if type(lb) in self.SUPPORTED_ARRAY and type(ub) in self.SUPPORTED_ARRAY:
-            self.lb = np.array(lb).flatten()
-            self.ub = np.array(ub).flatten()
-            if len(self.lb) == len(self.ub):
-                self.n_dims = len(self.lb)
-                if len(self.lb) < 1:
-                    raise ValueError(f'Dimensions do not qualify. Length(lb) = {len(self.lb)} < 1.')
-            else:
-                raise ValueError(f"Length of lb and ub do not match. {len(self.lb)} != {len(self.ub)}.")
-        else:
-            raise ValueError(f"lb and ub need to be a list, tuple or np.array.")
-
-    def __set_functions(self, kwargs):
-        tested_solution = self.generate_position(self.lb, self.ub)
-        if "amend_position" in kwargs:
-            if not callable(self.amend_position):
-                raise ValueError(f"Use default 'amend_position()' or passed a callable function. {type(self.amend_position)} != function")
-            else:
-                tested_solution = self.amend_position(tested_solution, self.lb, self.ub)
-        result = self.fit_func(tested_solution)
-        if type(result) in self.SUPPORTED_ARRAY:
-            result = np.array(result).flatten()
-            self.n_objs = len(result)
-            self.obj_is_list = True
-            if self.n_objs > 1:
-                self.multi_objs = True
-                if type(self.obj_weights) in self.SUPPORTED_ARRAY:
-                    self.obj_weights = np.array(self.obj_weights).flatten()
-                    if self.n_objs != len(self.obj_weights):
-                        raise ValueError(f"{self.n_objs}-objective problem, but N weights = {len(self.obj_weights)}.")
-                    self.msg = f"Solving {self.n_objs}-objective optimization problem with weights: {self.obj_weights}."
-                else:
-                    raise ValueError(f"Solving {self.n_objs}-objective optimization, need to set obj_weights list with length: {self.n_objs}")
-            elif self.n_objs == 1:
-                self.multi_objs = False
-                self.obj_weights = np.ones(1)
-                self.msg = f"Solving single objective optimization problem."
-            else:
-                raise ValueError(f"fit_func needs to return a single value or a list of values list")
-        elif type(result) in (int, float) or isinstance(result, np.floating) or isinstance(result, np.integer):
-            self.multi_objs = False
-            self.obj_is_list = False
-            self.obj_weights = np.ones(1)
-            self.msg = f"Solving single objective optimization problem."
-        else:
-            raise ValueError(f"fit_func needs to return a single value or a list of values list")
-
-    def fit_func(self, x):
-        """Fitness function
-
-        Args:
-            x (numpy.ndarray): Solution.
-
-        Returns:
-            float: Function value of `x`.
-        """
-        raise NotImplementedError
-
-    def get_name(self):
-        """
-        Returns:
-            string: The name of the problem
-        """
-        return self.name
-
-    def get_class_name(self):
-        """Get class name."""
-        return self.__class__.__name__
-
-    def generate_position(self, lb=None, ub=None):
-        """
-        Generate the position depends on the problem. For discrete problem such as permutation, this method can be override.
-
-        Args:
-            lb: list of lower bound values
-            ub: list of upper bound values
-
-        Returns:
-            np.array: the position (the solution for the problem)
-        """
-        return np.random.uniform(lb, ub)
-
-    def amend_position(self, position=None, lb=None, ub=None):
-        """
-        This is default function in most algorithms. Otherwise, there will be an overridden function
-        in child of Optimizer class for this function. Depend on what kind of problem are we trying to solve,
-        there will be a different amend_position function to rebound the position of agent into the valid range.
-
-        Args:
-            position: vector position (location) of the solution.
-            lb: list of lower bound values
-            ub: list of upper bound values
-
-        Returns:
-            Amended position (make the position is in bound)
-        """
-        # return np.maximum(self.problem.lb, np.minimum(self.problem.ub, position))
-        return np.clip(position, lb, ub)
+#!/usr/bin/env python
+# Created by "Thieu" at 17:28, 13/10/2021 ----------%
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+from mealpy.utils.logger import Logger
+
+
+class Problem:
+    """Class representing the mathematical form of the optimization problem.
+
+    Attributes:
+        lb (numpy.ndarray, list, tuple): Lower bounds of the problem.
+        ub (numpy.ndarray, list, tuple): Upper bounds of the problem.
+        minmax (str): Minimization or maximization problem (min, max), default = "min"
+
+    Notes
+    ~~~~~
+    + fit_func (callable): your fitness function
+    + lb (list, int, float): lower bound, should be list of values
+    + ub (list, int, float): upper bound, should be list of values
+    + minmax (str): "min" or "max" problem (Optional, default = "min")
+    + obj_weights: list weights for all your objectives (Optional, default = [1, 1, ...1])
+    + save_population (bool): save history of population or not, default = True (Optional). **Warning**:
+        + this parameter can save you from error related to 'memory' when your model is too big (i.e, training neural network, ...)
+        + when set to False, you can't use the function draw trajectory chart in history object (model.history.save_trajectory_chart)
+    + amend_position(callable): Depend on your problem, may need to design an amend_position function (Optional for continuous domain, Required for discrete domain)
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.PSO import OriginalPSO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>>     "minmax": "min",
+    >>>     "log_to": None,
+    >>>     "save_population": False,
+    >>> }
+    >>> model1 = OriginalPSO(epoch=1000, pop_size=50)
+    >>> model1.solve(problem_dict)
+    >>>
+    >>> ## For discrete problem, you need to design an amend_position function that can (1) bring your solution back to the valid range,
+    >>> ##    (2) can convert float number into integer number (combinatorial or permutation).
+    >>>
+    >>> def amend_position(solution, lb, ub):
+    >>>     ## Bring them back to valid range
+    >>>     solution = np.clip(solution, lb, ub)
+    >>>     ## Convert float to integer number
+    >>>     solution_int = solution.astype(int)
+    >>>     ## If the designed solution is permutation, then need an extra step here
+    >>>     ## .... Do it here and then return the valid solution
+    >>>     return solution_int
+    >>>
+    >>> problem_dict2 = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-100, ] * 30,
+    >>>     "ub": [100, ] * 30,
+    >>>     "minmax": "min",
+    >>>     "log_to": "file",
+    >>>     "log_file": "records.log",
+    >>>     "amend_position": amend_position
+    >>> }
+    >>> model2 = OriginalPSO(epoch=1000, pop_size=50)
+    >>> best_position, best_fitness = model2.solve(problem_dict2)
+    >>> print(f"Best solution: {best_position}, Best fitness: {best_fitness}")
+    """
+
+    SUPPORTED_ARRAY = (list, tuple, np.ndarray)
+
+    def __init__(self, lb=None, ub=None, minmax="min", **kwargs):
+        r"""Initialize Problem.
+
+        Args:
+            lb (numpy.ndarray, list, tuple): Lower bounds of the problem.
+            ub (numpy.ndarray, list, tuple): Upper bounds of the problem.
+            minmax (str): Minimization or maximization problem (min, max)
+            name (str): Name for this particular problem
+        """
+        self.name, self.log_to, self.log_file = "P", "console", "history.txt"
+        self.n_objs, self.obj_is_list, self.multi_objs, self.obj_weights = 1, False, False, None
+        self.n_dims, self.lb, self.ub, self.save_population = None, None, None, False
+
+        self.__set_keyword_arguments(kwargs)
+        self.__set_domain_range(lb, ub)
+        self.__set_functions(kwargs)
+        self.logger = Logger(self.log_to, log_file=self.log_file).create_logger(name=f"{__name__}.{__class__.__name__}",
+                                    format_str='%(asctime)s, %(levelname)s, %(name)s [line: %(lineno)d]: %(message)s')
+        self.minmax = minmax
+
+    def __set_keyword_arguments(self, kwargs):
+        for key, value in kwargs.items():
+            setattr(self, key, value)
+
+    def __set_domain_range(self, lb, ub):
+        if type(lb) in self.SUPPORTED_ARRAY and type(ub) in self.SUPPORTED_ARRAY:
+            self.lb = np.array(lb).flatten()
+            self.ub = np.array(ub).flatten()
+            if len(self.lb) == len(self.ub):
+                self.n_dims = len(self.lb)
+                if len(self.lb) < 1:
+                    raise ValueError(f'Dimensions do not qualify. Length(lb) = {len(self.lb)} < 1.')
+            else:
+                raise ValueError(f"Length of lb and ub do not match. {len(self.lb)} != {len(self.ub)}.")
+        else:
+            raise ValueError(f"lb and ub need to be a list, tuple or np.array.")
+
+    def __set_functions(self, kwargs):
+        tested_solution = self.generate_position(self.lb, self.ub)
+        if "amend_position" in kwargs:
+            if not callable(self.amend_position):
+                raise ValueError(f"Use default 'amend_position()' or passed a callable function. {type(self.amend_position)} != function")
+            else:
+                tested_solution = self.amend_position(tested_solution, self.lb, self.ub)
+        result = self.fit_func(tested_solution)
+        if type(result) in self.SUPPORTED_ARRAY:
+            result = np.array(result).flatten()
+            self.n_objs = len(result)
+            self.obj_is_list = True
+            if self.n_objs > 1:
+                self.multi_objs = True
+                if type(self.obj_weights) in self.SUPPORTED_ARRAY:
+                    self.obj_weights = np.array(self.obj_weights).flatten()
+                    if self.n_objs != len(self.obj_weights):
+                        raise ValueError(f"{self.n_objs}-objective problem, but N weights = {len(self.obj_weights)}.")
+                    self.msg = f"Solving {self.n_objs}-objective optimization problem with weights: {self.obj_weights}."
+                else:
+                    raise ValueError(f"Solving {self.n_objs}-objective optimization, need to set obj_weights list with length: {self.n_objs}")
+            elif self.n_objs == 1:
+                self.multi_objs = False
+                self.obj_weights = np.ones(1)
+                self.msg = f"Solving single objective optimization problem."
+            else:
+                raise ValueError(f"fit_func needs to return a single value or a list of values list")
+        elif type(result) in (int, float) or isinstance(result, np.floating) or isinstance(result, np.integer):
+            self.multi_objs = False
+            self.obj_is_list = False
+            self.obj_weights = np.ones(1)
+            self.msg = f"Solving single objective optimization problem."
+        else:
+            raise ValueError(f"fit_func needs to return a single value or a list of values list")
+
+    def fit_func(self, x):
+        """Fitness function
+
+        Args:
+            x (numpy.ndarray): Solution.
+
+        Returns:
+            float: Function value of `x`.
+        """
+        raise NotImplementedError
+
+    def get_name(self):
+        """
+        Returns:
+            string: The name of the problem
+        """
+        return self.name
+
+    def get_class_name(self):
+        """Get class name."""
+        return self.__class__.__name__
+
+    def generate_position(self, lb=None, ub=None):
+        """
+        Generate the position depends on the problem. For discrete problem such as permutation, this method can be override.
+
+        Args:
+            lb: list of lower bound values
+            ub: list of upper bound values
+
+        Returns:
+            np.array: the position (the solution for the problem)
+        """
+        return np.random.uniform(lb, ub)
+
+    def amend_position(self, position=None, lb=None, ub=None):
+        """
+        This is default function in most algorithms. Otherwise, there will be an overridden function
+        in child of Optimizer class for this function. Depend on what kind of problem are we trying to solve,
+        there will be a different amend_position function to rebound the position of agent into the valid range.
+
+        Args:
+            position: vector position (location) of the solution.
+            lb: list of lower bound values
+            ub: list of upper bound values
+
+        Returns:
+            Amended position (make the position is in bound)
+        """
+        # return np.maximum(self.problem.lb, np.minimum(self.problem.ub, position))
+        return np.clip(position, lb, ub)
```

### Comparing `mealpy-2.5.3/mealpy/utils/termination.py` & `mealpy-2.5.3a1/mealpy/utils/termination.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,119 +1,119 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 22:23, 17/03/2023 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-from mealpy.utils.logger import Logger
-from mealpy.utils.validator import Validator
-
-
-class Termination:
-    """
-    Define custom single/multiple Stopping Conditions (termination criteria) for the Optimizer.
-
-    Notes
-    ~~~~~
-    + By default, the stopping condition in the Optimizer class is based on the maximum number of generations (epochs/iterations).
-    + Using this class allows you to override the default termination criteria. If multiple stopping conditions are specified, the first one that occurs will be used.
-
-    + In general, there are four types of termination criteria: FE, MG, TB, and ES.
-        + MG: Maximum Generations / Epochs / Iterations
-        + FE: Maximum Number of Function Evaluations
-        + TB: Time Bound - If you want your algorithm to run for a fixed amount of time (e.g., K seconds), especially when comparing different algorithms.
-        + ES: Early Stopping -  Similar to the idea in training neural networks (stop the program if the global best solution has not improved by epsilon after K epochs).
-
-    + Parameters for Termination class, set it to None if you don't want to use it
-        + max_epoch (int): Indicates the maximum number of generations for the MG type.
-        + max_fe (int): Indicates the maximum number of function evaluations for the FE type.
-        + max_time (float): Indicates the maximum amount of time for the TB type.
-        + max_early_stop (int): Indicates the maximum number of epochs for the ES type.
-            + epsilon (float): (Optional) This is used for the ES termination type (default value: 1e-10).
-        + termination (dict): (Optional) A dictionary of termination criteria.
-
-    Examples
-    ~~~~~~~~
-    >>> import numpy as np
-    >>> from mealpy.swarm_based.PSO import OriginalPSO
-    >>>
-    >>> def fitness_function(solution):
-    >>>     return np.sum(solution**2)
-    >>>
-    >>> problem_dict = {
-    >>>     "fit_func": fitness_function,
-    >>>     "lb": [-10, -15, -4, -2, -8],
-    >>>     "ub": [10, 15, 12, 8, 20],
-    >>> }
-    >>>
-    >>> term_dict = {
-    >>>     "max_epoch": 1000,
-    >>>     "max_fe": 100000,  # 100000 number of function evaluation
-    >>>     "max_time": 10,     # 10 seconds to run the program
-    >>>     "max_early_stop": 15    # 15 epochs if the best fitness is not getting better we stop the program
-    >>> }
-    >>> model1 = OriginalPSO(epoch=1000, pop_size=50)
-    >>> model1.solve(problem_dict, termination=term_dict)
-    """
-
-    def __init__(self, max_epoch=None, max_fe=None, max_time=None, max_early_stop=None, **kwargs):
-        self.max_epoch = max_epoch
-        self.max_fe = max_fe
-        self.max_time = max_time
-        self.max_early_stop = max_early_stop
-        self.epsilon = 1e-10
-        self.__set_keyword_arguments(kwargs)
-        self.validator = Validator(log_to="console", log_file=None)
-        self.name, self.message, self.log_to, self.log_file = "Termination", "", None, None
-        self.__set_condition(self.max_epoch, self.max_fe, self.max_time, self.max_early_stop)
-        self.logger = Logger(self.log_to, log_file=self.log_file).create_logger(name=f"{__name__}.{__class__.__name__}",
-                                    format_str='%(asctime)s, %(levelname)s, %(name)s [line: %(lineno)d]: %(message)s')
-        self.logger.propagate = False
-
-    def __set_keyword_arguments(self, kwargs):
-        if type(kwargs) == dict:
-            if type(kwargs.get("termination")) == dict:
-                for key, value in kwargs.items():
-                    setattr(self, key, value)
-            for key, value in kwargs.items():
-                setattr(self, key, value)
-
-    def __set_condition(self, max_epoch, max_fe, max_time, max_early_stop):
-        if (max_epoch is None) and (max_fe is None) and (max_time is None) and (max_early_stop is None):
-            raise ValueError("Please set at least one stopping condition with parameter 'max_epoch' or 'max_fe' or 'max_time' or 'max_early_stop'")
-        else:
-            if max_epoch is not None:
-                self.max_epoch = self.validator.check_int("max_epoch", max_epoch, [1, 10000000])
-            if max_fe is not None:
-                self.max_fe = self.validator.check_int("max_fe", max_fe, [10, 1000000000])
-            if max_time is not None:
-                self.max_time = self.validator.check_float("max_time", max_time, [0.1, 1000000])
-            if max_early_stop is not None:
-                self.max_early_stop = self.validator.check_int("max_early_stop", max_early_stop, [1, 100000])
-
-    def get_name(self):
-        return self.name
-
-    def set_start_values(self, start_epoch, start_fe, start_time, start_threshold):
-        self.start_epoch = start_epoch
-        self.start_fe = start_fe
-        self.start_time = start_time
-        self.start_threshold = start_threshold
-
-    def should_terminate(self, current_epoch, current_fe, current_time, current_threshold):
-        # Check maximum number of generations
-        if self.max_epoch is not None and current_epoch >= self.max_epoch:
-            self.message = "Stopping criterion with maximum number of epochs/generations/iterations (MG) occurred. End program!"
-            return True
-        # Check maximum number of function evaluations
-        if self.max_fe is not None and current_fe >= self.max_fe:
-            self.message = "Stopping criterion with maximum number of function evaluations (FE) occurred. End program!"
-            return True
-        # Check maximum time
-        if self.max_time is not None and current_time >= self.max_time:
-            self.message = "Stopping criterion with maximum running time/time bound (TB) (seconds) occurred. End program!"
-            return True
-        # Check early stopping
-        if self.max_early_stop is not None and current_threshold >= self.max_early_stop:
-            self.message = "Stopping criterion with early stopping (ES) (fitness-based) occurred. End program!"
-            return True
-        return False
+#!/usr/bin/env python
+# Created by "Thieu" at 22:23, 17/03/2023 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+from mealpy.utils.logger import Logger
+from mealpy.utils.validator import Validator
+
+
+class Termination:
+    """
+    Define custom single/multiple Stopping Conditions (termination criteria) for the Optimizer.
+
+    Notes
+    ~~~~~
+    + By default, the stopping condition in the Optimizer class is based on the maximum number of generations (epochs/iterations).
+    + Using this class allows you to override the default termination criteria. If multiple stopping conditions are specified, the first one that occurs will be used.
+
+    + In general, there are four types of termination criteria: FE, MG, TB, and ES.
+        + MG: Maximum Generations / Epochs / Iterations
+        + FE: Maximum Number of Function Evaluations
+        + TB: Time Bound - If you want your algorithm to run for a fixed amount of time (e.g., K seconds), especially when comparing different algorithms.
+        + ES: Early Stopping -  Similar to the idea in training neural networks (stop the program if the global best solution has not improved by epsilon after K epochs).
+
+    + Parameters for Termination class, set it to None if you don't want to use it
+        + max_epoch (int): Indicates the maximum number of generations for the MG type.
+        + max_fe (int): Indicates the maximum number of function evaluations for the FE type.
+        + max_time (float): Indicates the maximum amount of time for the TB type.
+        + max_early_stop (int): Indicates the maximum number of epochs for the ES type.
+            + epsilon (float): (Optional) This is used for the ES termination type (default value: 1e-10).
+        + termination (dict): (Optional) A dictionary of termination criteria.
+
+    Examples
+    ~~~~~~~~
+    >>> import numpy as np
+    >>> from mealpy.swarm_based.PSO import OriginalPSO
+    >>>
+    >>> def fitness_function(solution):
+    >>>     return np.sum(solution**2)
+    >>>
+    >>> problem_dict = {
+    >>>     "fit_func": fitness_function,
+    >>>     "lb": [-10, -15, -4, -2, -8],
+    >>>     "ub": [10, 15, 12, 8, 20],
+    >>> }
+    >>>
+    >>> term_dict = {
+    >>>     "max_epoch": 1000,
+    >>>     "max_fe": 100000,  # 100000 number of function evaluation
+    >>>     "max_time": 10,     # 10 seconds to run the program
+    >>>     "max_early_stop": 15    # 15 epochs if the best fitness is not getting better we stop the program
+    >>> }
+    >>> model1 = OriginalPSO(epoch=1000, pop_size=50)
+    >>> model1.solve(problem_dict, termination=term_dict)
+    """
+
+    def __init__(self, max_epoch=None, max_fe=None, max_time=None, max_early_stop=None, **kwargs):
+        self.max_epoch = max_epoch
+        self.max_fe = max_fe
+        self.max_time = max_time
+        self.max_early_stop = max_early_stop
+        self.epsilon = 1e-10
+        self.__set_keyword_arguments(kwargs)
+        self.validator = Validator(log_to="console", log_file=None)
+        self.name, self.message, self.log_to, self.log_file = "Termination", "", None, None
+        self.__set_condition(self.max_epoch, self.max_fe, self.max_time, self.max_early_stop)
+        self.logger = Logger(self.log_to, log_file=self.log_file).create_logger(name=f"{__name__}.{__class__.__name__}",
+                                    format_str='%(asctime)s, %(levelname)s, %(name)s [line: %(lineno)d]: %(message)s')
+        self.logger.propagate = False
+
+    def __set_keyword_arguments(self, kwargs):
+        if type(kwargs) == dict:
+            if type(kwargs.get("termination")) == dict:
+                for key, value in kwargs.items():
+                    setattr(self, key, value)
+            for key, value in kwargs.items():
+                setattr(self, key, value)
+
+    def __set_condition(self, max_epoch, max_fe, max_time, max_early_stop):
+        if (max_epoch is None) and (max_fe is None) and (max_time is None) and (max_early_stop is None):
+            raise ValueError("Please set at least one stopping condition with parameter 'max_epoch' or 'max_fe' or 'max_time' or 'max_early_stop'")
+        else:
+            if max_epoch is not None:
+                self.max_epoch = self.validator.check_int("max_epoch", max_epoch, [1, 10000000])
+            if max_fe is not None:
+                self.max_fe = self.validator.check_int("max_fe", max_fe, [10, 1000000000])
+            if max_time is not None:
+                self.max_time = self.validator.check_float("max_time", max_time, [0.1, 1000000])
+            if max_early_stop is not None:
+                self.max_early_stop = self.validator.check_int("max_early_stop", max_early_stop, [1, 100000])
+
+    def get_name(self):
+        return self.name
+
+    def set_start_values(self, start_epoch, start_fe, start_time, start_threshold):
+        self.start_epoch = start_epoch
+        self.start_fe = start_fe
+        self.start_time = start_time
+        self.start_threshold = start_threshold
+
+    def should_terminate(self, current_epoch, current_fe, current_time, current_threshold):
+        # Check maximum number of generations
+        if self.max_epoch is not None and current_epoch >= self.max_epoch:
+            self.message = "Stopping criterion with maximum number of epochs/generations/iterations (MG) occurred. End program!"
+            return True
+        # Check maximum number of function evaluations
+        if self.max_fe is not None and current_fe >= self.max_fe:
+            self.message = "Stopping criterion with maximum number of function evaluations (FE) occurred. End program!"
+            return True
+        # Check maximum time
+        if self.max_time is not None and current_time >= self.max_time:
+            self.message = "Stopping criterion with maximum running time/time bound (TB) (seconds) occurred. End program!"
+            return True
+        # Check early stopping
+        if self.max_early_stop is not None and current_threshold >= self.max_early_stop:
+            self.message = "Stopping criterion with early stopping (ES) (fitness-based) occurred. End program!"
+            return True
+        return False
```

### Comparing `mealpy-2.5.3/mealpy/utils/validator.py` & `mealpy-2.5.3a1/mealpy/utils/validator.py`

 * *Ordering differences only*

 * *Files 19% similar despite different names*

```diff
@@ -1,125 +1,125 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 21:32, 14/03/2022 ----------%                                                                               
-#       Email: nguyenthieu2102@gmail.com            %                                                    
-#       Github: https://github.com/thieu1995        %                         
-# --------------------------------------------------%
-
-import numpy as np
-import operator
-from mealpy.utils.logger import Logger
-
-
-def is_in_bound(value, bound):
-    ops = None
-    if type(bound) is tuple:
-        ops = operator.lt
-    elif type(bound) is list:
-        ops = operator.le
-    if bound[0] == float("-inf") and bound[1] == float("inf"):
-        return True
-    elif bound[0] == float("-inf") and ops(value, bound[1]):
-        return True
-    elif ops(bound[0], value) and bound[1] == float("inf"):
-        return True
-    elif ops(bound[0], value) and ops(value, bound[1]):
-        return True
-    return False
-
-
-def is_str_in_list(value: str, my_list: list):
-    if type(value) == str and my_list is not None:
-        return True if value in my_list else False
-    return False
-
-
-class Validator:
-    def __init__(self, **kwargs):
-        self.log_to, self.log_file = None, None
-        self.__set_keyword_arguments(kwargs)
-        self.logger = Logger(self.log_to, log_file=self.log_file).create_logger(name=f"{__name__}.{__class__.__name__}",
-            format_str='%(asctime)s, %(levelname)s, %(name)s [line: %(lineno)d]: %(message)s')
-        self.logger.propagate = False
-
-    def __set_keyword_arguments(self, kwargs):
-        for key, value in kwargs.items():
-            setattr(self, key, value)
-
-    def check_int(self, name:str, value:int, bound=None):
-        if type(value) in [int, float]:
-            if bound is None:
-                return int(value)
-            elif is_in_bound(value, bound):
-                return int(value)
-        bound = "" if bound is None else f"and value should be in range: {bound}"
-        raise ValueError(f"'{name}' is an integer {bound}.")
-
-    def check_float(self, name: str, value: int, bound=None):
-        if type(value) in [int, float]:
-            if bound is None:
-                return float(value)
-            elif is_in_bound(value, bound):
-                return float(value)
-        bound = "" if bound is None else f"and value should be in range: {bound}"
-        raise ValueError(f"'{name}' is a float {bound}.")
-
-    def check_str(self, name: str, value: str, bound=None):
-        if type(value) is str:
-            if bound is None or is_str_in_list(value, bound):
-                return value
-        bound = "" if bound is None else f"and value should be one of this: {bound}"
-        raise ValueError(f"'{name}' is a string {bound}.")
-
-    def check_bool(self, name: str, value: bool, bound=(True, False)):
-        if type(value) is bool:
-            if value in bound:
-                return value
-        bound = "" if bound is None else f"and value should be one of this: {bound}"
-        raise ValueError(f"'{name}' is a boolean {bound}.")
-
-    def check_tuple_int(self, name: str, values: tuple, bounds=None):
-        if type(values) in [tuple, list] and len(values) > 1:
-            value_flag = [type(item) == int for item in values]
-            if np.all(value_flag):
-                if bounds is not None and len(bounds) == len(values):
-                    value_flag = [is_in_bound(item, bound) for item, bound in zip(values, bounds)]
-                    if np.all(value_flag):
-                        return values
-                else:
-                    return values
-        bounds = "" if bounds is None else f"and values should be in range: {bounds}"
-        raise ValueError(f"'{name}' are integer {bounds}.")
-
-    def check_tuple_float(self, name: str, values: tuple, bounds=None):
-        if type(values) in [tuple, list] and len(values) > 1:
-            value_flag = [type(item) in [int, float] for item in values]
-            if np.all(value_flag):
-                if bounds is not None and len(bounds) == len(values):
-                    value_flag = [is_in_bound(item, bound) for item, bound in zip(values, bounds)]
-                    if np.all(value_flag):
-                        return values
-                else:
-                    return values
-        bounds = "" if bounds is None else f"and values should be in range: {bounds}"
-        raise ValueError(f"'{name}' are float {bounds}.")
-
-    def check_list_tuple(self, name: str, value: any, data_type: str):
-        if type(value) in (tuple, list) and len(value) >= 1:
-            return list(value)
-        raise ValueError(f"'{name}' should be a list or tuple of {data_type}, and length >= 1.")
-
-    def check_is_instance(self, name: str, value: any, class_type: any):
-        if isinstance(value, class_type):
-            return value
-        raise ValueError(f"'{name}' should be an instance of {class_type} class.")
-
-    def check_is_int_and_float(self, name: str, value: any, bound_int=None, bound_float=None):
-        if type(value) is int:
-            if bound_int is None or is_in_bound(value, bound_int):
-                return int(value)
-        bound_int_str = "" if bound_int is None else f"and value in range: {bound_int}"
-        if type(value) is float:
-            if bound_float is None or is_in_bound(value, bound_float):
-                return float(value)
-        bound_float_str = "" if bound_float is None else f"and value in range: {bound_float}"
-        raise ValueError(f"'{name}' can be int {bound_int_str}, or float {bound_float_str}.")
-
+#!/usr/bin/env python
+# Created by "Thieu" at 21:32, 14/03/2022 ----------%                                                                               
+#       Email: nguyenthieu2102@gmail.com            %                                                    
+#       Github: https://github.com/thieu1995        %                         
+# --------------------------------------------------%
+
+import numpy as np
+import operator
+from mealpy.utils.logger import Logger
+
+
+def is_in_bound(value, bound):
+    ops = None
+    if type(bound) is tuple:
+        ops = operator.lt
+    elif type(bound) is list:
+        ops = operator.le
+    if bound[0] == float("-inf") and bound[1] == float("inf"):
+        return True
+    elif bound[0] == float("-inf") and ops(value, bound[1]):
+        return True
+    elif ops(bound[0], value) and bound[1] == float("inf"):
+        return True
+    elif ops(bound[0], value) and ops(value, bound[1]):
+        return True
+    return False
+
+
+def is_str_in_list(value: str, my_list: list):
+    if type(value) == str and my_list is not None:
+        return True if value in my_list else False
+    return False
+
+
+class Validator:
+    def __init__(self, **kwargs):
+        self.log_to, self.log_file = None, None
+        self.__set_keyword_arguments(kwargs)
+        self.logger = Logger(self.log_to, log_file=self.log_file).create_logger(name=f"{__name__}.{__class__.__name__}",
+            format_str='%(asctime)s, %(levelname)s, %(name)s [line: %(lineno)d]: %(message)s')
+        self.logger.propagate = False
+
+    def __set_keyword_arguments(self, kwargs):
+        for key, value in kwargs.items():
+            setattr(self, key, value)
+
+    def check_int(self, name:str, value:int, bound=None):
+        if type(value) in [int, float]:
+            if bound is None:
+                return int(value)
+            elif is_in_bound(value, bound):
+                return int(value)
+        bound = "" if bound is None else f"and value should be in range: {bound}"
+        raise ValueError(f"'{name}' is an integer {bound}.")
+
+    def check_float(self, name: str, value: int, bound=None):
+        if type(value) in [int, float]:
+            if bound is None:
+                return float(value)
+            elif is_in_bound(value, bound):
+                return float(value)
+        bound = "" if bound is None else f"and value should be in range: {bound}"
+        raise ValueError(f"'{name}' is a float {bound}.")
+
+    def check_str(self, name: str, value: str, bound=None):
+        if type(value) is str:
+            if bound is None or is_str_in_list(value, bound):
+                return value
+        bound = "" if bound is None else f"and value should be one of this: {bound}"
+        raise ValueError(f"'{name}' is a string {bound}.")
+
+    def check_bool(self, name: str, value: bool, bound=(True, False)):
+        if type(value) is bool:
+            if value in bound:
+                return value
+        bound = "" if bound is None else f"and value should be one of this: {bound}"
+        raise ValueError(f"'{name}' is a boolean {bound}.")
+
+    def check_tuple_int(self, name: str, values: tuple, bounds=None):
+        if type(values) in [tuple, list] and len(values) > 1:
+            value_flag = [type(item) == int for item in values]
+            if np.all(value_flag):
+                if bounds is not None and len(bounds) == len(values):
+                    value_flag = [is_in_bound(item, bound) for item, bound in zip(values, bounds)]
+                    if np.all(value_flag):
+                        return values
+                else:
+                    return values
+        bounds = "" if bounds is None else f"and values should be in range: {bounds}"
+        raise ValueError(f"'{name}' are integer {bounds}.")
+
+    def check_tuple_float(self, name: str, values: tuple, bounds=None):
+        if type(values) in [tuple, list] and len(values) > 1:
+            value_flag = [type(item) in [int, float] for item in values]
+            if np.all(value_flag):
+                if bounds is not None and len(bounds) == len(values):
+                    value_flag = [is_in_bound(item, bound) for item, bound in zip(values, bounds)]
+                    if np.all(value_flag):
+                        return values
+                else:
+                    return values
+        bounds = "" if bounds is None else f"and values should be in range: {bounds}"
+        raise ValueError(f"'{name}' are float {bounds}.")
+
+    def check_list_tuple(self, name: str, value: any, data_type: str):
+        if type(value) in (tuple, list) and len(value) >= 1:
+            return list(value)
+        raise ValueError(f"'{name}' should be a list or tuple of {data_type}, and length >= 1.")
+
+    def check_is_instance(self, name: str, value: any, class_type: any):
+        if isinstance(value, class_type):
+            return value
+        raise ValueError(f"'{name}' should be an instance of {class_type} class.")
+
+    def check_is_int_and_float(self, name: str, value: any, bound_int=None, bound_float=None):
+        if type(value) is int:
+            if bound_int is None or is_in_bound(value, bound_int):
+                return int(value)
+        bound_int_str = "" if bound_int is None else f"and value in range: {bound_int}"
+        if type(value) is float:
+            if bound_float is None or is_in_bound(value, bound_float):
+                return float(value)
+        bound_float_str = "" if bound_float is None else f"and value in range: {bound_float}"
+        raise ValueError(f"'{name}' can be int {bound_int_str}, or float {bound_float_str}.")
+
```

### Comparing `mealpy-2.5.3/mealpy/utils/visualize/linechart.py` & `mealpy-2.5.3a1/mealpy/utils/visualize/linechart.py`

 * *Ordering differences only*

 * *Files 19% similar despite different names*

```diff
@@ -1,212 +1,212 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 17:12, 09/07/2021 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-from pathlib import Path
-import numpy as np
-import re
-from matplotlib import pyplot as plt
-import platform
-
-
-LIST_LINESTYLES = [
-    '-',        # solid line style
-    '--',       # dashed line style
-    '-.',       # dash-dot line style
-
-    ':',        # point marker
-    '-',        # solid line style
-    '--',       # dashed line style
-    '-.',       # dash-dot line style
-    ':',        # point marker
-
-    '-',        # solid line style
-    '--',       # dashed line style
-    '-.',       # dash-dot line style
-    ':',        # point marker
-]
-
-LIST_MARKERS = [
-    's',  # square marker
-    '*',  # star marker
-    'p',  # pentagon marker
-    '+',  # plus marker
-    'x',  # x marker
-    'd',  # thin diamond marker
-    '^',  # triangle-up
-    'v',  # triangle-down
-    'o',  # circle
-    '8',  # octagon
-]
-
-LIST_COLORS = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728',
-              '#9467bd', '#8c564b', '#e377c2', '#7f7f7f',
-              '#bcbd22', '#17becf']
-
-
-def __clean_filename__(filename):
-    chars_to_remove = ["`", "~", "!", "@", "#", "$", "%", "^", "&", "*", ":", ",", "<", ">", ";", "+", "|"]
-    regular_expression = '[' + re.escape(''.join(chars_to_remove)) + ']'
-
-    temp = filename.encode("ascii", "ignore")
-    fname = temp.decode()                           # Removed all non-ascii characters
-    fname = re.sub(regular_expression, '', fname)   # Removed all special characters
-    fname.replace("_", "-")                         # Replaced _ by -
-    return fname
-
-
-def __check_filepath__(filename):
-    filename.replace("\\", "/")                     # For better handling the parent folder
-    if "/" in filename:
-        list_names = filename.split("/")[:-1]       # Remove last element because it is filename
-        filepath = "/".join(list_names)
-        Path(filepath).mkdir(parents=True, exist_ok=True)
-    return filename
-
-
-def _draw_line_(data=None, title=None, legend=None, linestyle='-', color='b', x_label="#Iteration",
-                y_label="Function Value", filename=None, exts=(".png", ".pdf"), verbose=True):
-    x = np.arange(0, len(data))
-    y = data
-    plt.title(title)
-    plt.xlabel(x_label)
-    plt.ylabel(y_label)
-    if legend is None:
-        plt.plot(x, y, linestyle=linestyle, color=color)
-    else:
-        plt.plot(x, y, linestyle=linestyle, color=color, label=legend)
-        plt.legend()  # show a legend on the plot
-    if filename is not None:
-        filepath = __check_filepath__(__clean_filename__(filename))
-        for idx, ext in enumerate(exts):
-            plt.savefig(f"{filepath}{ext}", bbox_inches='tight')
-    if platform.system() != "Linux" and verbose:
-        plt.show()
-    plt.close()
-
-
-def _draw_multi_line_(data=None, title=None, list_legends=None, list_styles=None, list_colors=None,
-                      x_label="#Iteration", y_label="Function Value", filename=None, exts=(".png", ".pdf"), verbose=True):
-    x = np.arange(0, len(data[0]))
-    for idx, y in enumerate(data):
-        plt.plot(x, y, label=list_legends[idx], markerfacecolor=list_colors[idx], linestyle=list_styles[idx])
-
-    plt.title(title)
-    plt.xlabel(x_label)
-    plt.ylabel(y_label)
-    plt.legend()  # show a legend on the plot
-    if filename is not None:
-        filepath = __check_filepath__(__clean_filename__(filename))
-        for idx, ext in enumerate(exts):
-            plt.savefig(f"{filepath}{ext}", bbox_inches='tight')
-    if platform.system() != "Linux" and verbose:
-        plt.show()
-    plt.close()
-
-
-def _draw_multi_subplots_in_same_figure_(data=None, title=None, list_legends=None, list_styles=None, list_colors=None,
-                                     x_label="#Iteration", y_labels=None, filename=None, exts=(".png", ".pdf"), verbose=True):
-    n_lines = len(data)
-    len_lines = len(data[0])
-    x = np.arange(0, len_lines)
-
-    if n_lines == 1:
-        fig, ax = plt.subplots()
-        if list_legends is None:
-            ax.plot(x, data[0])
-        else:
-            ax.plot(x, data[0], label=list_legends[0])
-        ax.set_xlabel(x_label)
-        if y_labels is None:
-            ax.set_ylabel("Objective Value")
-        else:
-            ax.set_ylabel(y_labels[0])
-        ax.set_title(title)
-    elif n_lines > 1:
-        fig, ax_list = plt.subplots(n_lines, sharex=True)
-        fig.suptitle(title)
-        for idx, ax in enumerate(ax_list):
-            if list_legends is None:
-                ax.plot(x, data[idx], markerfacecolor=list_colors[idx], linestyle=list_styles[idx])
-            else:
-                ax.plot(x, data[idx], label=list_legends[idx], markerfacecolor=list_colors[idx], linestyle=list_styles[idx])
-            if y_labels is None:
-                ax.set_ylabel(f"Objective {idx + 1}")
-            else:
-                ax.set_ylabel(y_labels[idx])
-            if idx == (n_lines - 1):
-                ax.set_xlabel(x_label)
-
-    if filename is not None:
-        filepath = __check_filepath__(__clean_filename__(filename))
-        for idx, ext in enumerate(exts):
-            plt.savefig(f"{filepath}{ext}", bbox_inches='tight')
-    if platform.system() != "Linux" and verbose:
-        plt.show()
-    plt.close()
-
-
-def export_convergence_chart(data=None, title="Convergence Chart", legend=None, linestyle='-', color='b', x_label="#Iteration",
-                            y_label="Function Value", filename="convergence_chart", exts=(".png", ".pdf"), verbose=True):
-    _draw_line_(data, title=title, legend=legend, linestyle=linestyle, color=color,
-                x_label=x_label, y_label=y_label, filename=filename, exts=exts, verbose=verbose)
-
-
-def export_explore_exploit_chart(data=None, title="Exploration vs Exploitation Percentages", list_legends=("Exploration %", "Exploitation %"),
-                                 list_styles=('-', '-'), list_colors=('blue', 'orange'), x_label="#Iteration", y_label="Percentage",
-                                 filename="explore_exploit_chart", exts=(".png", ".pdf"), verbose=True):
-    _draw_multi_line_(data=data, title=title, list_legends=list_legends, list_styles=list_styles, list_colors=list_colors,
-                      x_label=x_label, y_label=y_label, filename=filename, exts=exts, verbose=verbose)
-
-
-def export_diversity_chart(data=None, title='Diversity Measurement Chart', list_legends=None,
-                           list_styles=None, list_colors=None, x_label="#Iteration", y_label="Diversity Measurement",
-                           filename="diversity_chart", exts=(".png", ".pdf"), verbose=True):
-    if list_styles is None:
-        list_styles = LIST_LINESTYLES[:len(data)]
-    if list_colors is None:
-        list_colors = LIST_COLORS[:len(data)]
-    _draw_multi_line_(data=data, title=title, list_legends=list_legends, list_styles=list_styles, list_colors=list_colors,
-                      x_label=x_label, y_label=y_label, filename=filename, exts=exts, verbose=verbose)
-
-
-def export_objectives_chart(data=None, title="Objectives chart", list_legends=None, list_styles=None, list_colors=None,
-            x_label="#Iteration", y_labels=None, filename="Objective-chart", exts=(".png", ".pdf"), verbose=True):
-    if list_styles is None:
-        list_styles = LIST_LINESTYLES[:len(data)]
-    if list_colors is None:
-        list_colors = LIST_COLORS[:len(data)]
-    _draw_multi_subplots_in_same_figure_(data=data, title=title, list_legends=list_legends, list_styles=list_styles, list_colors=list_colors,
-                                     x_label=x_label, y_labels=y_labels, filename=filename, exts=exts, verbose=verbose)
-
-
-def export_trajectory_chart(data=None, n_dimensions=1, title="Trajectory of some agents after generations", list_legends=None,
-                                 list_styles=None, list_colors=None, x_label="#Iteration", y_label="X1",
-                                 filename="1d_trajectory", exts=(".png", ".pdf"), verbose=True):
-    if list_styles is None:
-        list_styles = LIST_LINESTYLES[:len(data)]
-    if list_colors is None:
-        list_colors = LIST_COLORS[:len(data)]
-
-    if n_dimensions == 1:
-        x = np.arange(0, len(data[0]))
-        for idx, y in enumerate(data):
-            plt.plot(x, y, label=list_legends[idx], markerfacecolor=list_colors[idx], linestyle=list_styles[idx])
-    elif n_dimensions == 2:
-        for idx, point in enumerate(data):
-            plt.plot(point[0], point[1], label=list_legends[idx], markerfacecolor=list_colors[idx], linestyle=list_styles[idx])
-
-    plt.title(title)
-    plt.xlabel(x_label)
-    plt.ylabel(y_label)
-    plt.legend()  # show a legend on the plot
-    if filename is not None:
-        filepath = __check_filepath__(__clean_filename__(filename))
-        for idx, ext in enumerate(exts):
-            plt.savefig(f"{filepath}{ext}", bbox_inches='tight')
-    if platform.system() != "Linux" and verbose:
-        plt.show()
-    plt.close()
-
+#!/usr/bin/env python
+# Created by "Thieu" at 17:12, 09/07/2021 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+from pathlib import Path
+import numpy as np
+import re
+from matplotlib import pyplot as plt
+import platform
+
+
+LIST_LINESTYLES = [
+    '-',        # solid line style
+    '--',       # dashed line style
+    '-.',       # dash-dot line style
+
+    ':',        # point marker
+    '-',        # solid line style
+    '--',       # dashed line style
+    '-.',       # dash-dot line style
+    ':',        # point marker
+
+    '-',        # solid line style
+    '--',       # dashed line style
+    '-.',       # dash-dot line style
+    ':',        # point marker
+]
+
+LIST_MARKERS = [
+    's',  # square marker
+    '*',  # star marker
+    'p',  # pentagon marker
+    '+',  # plus marker
+    'x',  # x marker
+    'd',  # thin diamond marker
+    '^',  # triangle-up
+    'v',  # triangle-down
+    'o',  # circle
+    '8',  # octagon
+]
+
+LIST_COLORS = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728',
+              '#9467bd', '#8c564b', '#e377c2', '#7f7f7f',
+              '#bcbd22', '#17becf']
+
+
+def __clean_filename__(filename):
+    chars_to_remove = ["`", "~", "!", "@", "#", "$", "%", "^", "&", "*", ":", ",", "<", ">", ";", "+", "|"]
+    regular_expression = '[' + re.escape(''.join(chars_to_remove)) + ']'
+
+    temp = filename.encode("ascii", "ignore")
+    fname = temp.decode()                           # Removed all non-ascii characters
+    fname = re.sub(regular_expression, '', fname)   # Removed all special characters
+    fname.replace("_", "-")                         # Replaced _ by -
+    return fname
+
+
+def __check_filepath__(filename):
+    filename.replace("\\", "/")                     # For better handling the parent folder
+    if "/" in filename:
+        list_names = filename.split("/")[:-1]       # Remove last element because it is filename
+        filepath = "/".join(list_names)
+        Path(filepath).mkdir(parents=True, exist_ok=True)
+    return filename
+
+
+def _draw_line_(data=None, title=None, legend=None, linestyle='-', color='b', x_label="#Iteration",
+                y_label="Function Value", filename=None, exts=(".png", ".pdf"), verbose=True):
+    x = np.arange(0, len(data))
+    y = data
+    plt.title(title)
+    plt.xlabel(x_label)
+    plt.ylabel(y_label)
+    if legend is None:
+        plt.plot(x, y, linestyle=linestyle, color=color)
+    else:
+        plt.plot(x, y, linestyle=linestyle, color=color, label=legend)
+        plt.legend()  # show a legend on the plot
+    if filename is not None:
+        filepath = __check_filepath__(__clean_filename__(filename))
+        for idx, ext in enumerate(exts):
+            plt.savefig(f"{filepath}{ext}", bbox_inches='tight')
+    if platform.system() != "Linux" and verbose:
+        plt.show()
+    plt.close()
+
+
+def _draw_multi_line_(data=None, title=None, list_legends=None, list_styles=None, list_colors=None,
+                      x_label="#Iteration", y_label="Function Value", filename=None, exts=(".png", ".pdf"), verbose=True):
+    x = np.arange(0, len(data[0]))
+    for idx, y in enumerate(data):
+        plt.plot(x, y, label=list_legends[idx], markerfacecolor=list_colors[idx], linestyle=list_styles[idx])
+
+    plt.title(title)
+    plt.xlabel(x_label)
+    plt.ylabel(y_label)
+    plt.legend()  # show a legend on the plot
+    if filename is not None:
+        filepath = __check_filepath__(__clean_filename__(filename))
+        for idx, ext in enumerate(exts):
+            plt.savefig(f"{filepath}{ext}", bbox_inches='tight')
+    if platform.system() != "Linux" and verbose:
+        plt.show()
+    plt.close()
+
+
+def _draw_multi_subplots_in_same_figure_(data=None, title=None, list_legends=None, list_styles=None, list_colors=None,
+                                     x_label="#Iteration", y_labels=None, filename=None, exts=(".png", ".pdf"), verbose=True):
+    n_lines = len(data)
+    len_lines = len(data[0])
+    x = np.arange(0, len_lines)
+
+    if n_lines == 1:
+        fig, ax = plt.subplots()
+        if list_legends is None:
+            ax.plot(x, data[0])
+        else:
+            ax.plot(x, data[0], label=list_legends[0])
+        ax.set_xlabel(x_label)
+        if y_labels is None:
+            ax.set_ylabel("Objective Value")
+        else:
+            ax.set_ylabel(y_labels[0])
+        ax.set_title(title)
+    elif n_lines > 1:
+        fig, ax_list = plt.subplots(n_lines, sharex=True)
+        fig.suptitle(title)
+        for idx, ax in enumerate(ax_list):
+            if list_legends is None:
+                ax.plot(x, data[idx], markerfacecolor=list_colors[idx], linestyle=list_styles[idx])
+            else:
+                ax.plot(x, data[idx], label=list_legends[idx], markerfacecolor=list_colors[idx], linestyle=list_styles[idx])
+            if y_labels is None:
+                ax.set_ylabel(f"Objective {idx + 1}")
+            else:
+                ax.set_ylabel(y_labels[idx])
+            if idx == (n_lines - 1):
+                ax.set_xlabel(x_label)
+
+    if filename is not None:
+        filepath = __check_filepath__(__clean_filename__(filename))
+        for idx, ext in enumerate(exts):
+            plt.savefig(f"{filepath}{ext}", bbox_inches='tight')
+    if platform.system() != "Linux" and verbose:
+        plt.show()
+    plt.close()
+
+
+def export_convergence_chart(data=None, title="Convergence Chart", legend=None, linestyle='-', color='b', x_label="#Iteration",
+                            y_label="Function Value", filename="convergence_chart", exts=(".png", ".pdf"), verbose=True):
+    _draw_line_(data, title=title, legend=legend, linestyle=linestyle, color=color,
+                x_label=x_label, y_label=y_label, filename=filename, exts=exts, verbose=verbose)
+
+
+def export_explore_exploit_chart(data=None, title="Exploration vs Exploitation Percentages", list_legends=("Exploration %", "Exploitation %"),
+                                 list_styles=('-', '-'), list_colors=('blue', 'orange'), x_label="#Iteration", y_label="Percentage",
+                                 filename="explore_exploit_chart", exts=(".png", ".pdf"), verbose=True):
+    _draw_multi_line_(data=data, title=title, list_legends=list_legends, list_styles=list_styles, list_colors=list_colors,
+                      x_label=x_label, y_label=y_label, filename=filename, exts=exts, verbose=verbose)
+
+
+def export_diversity_chart(data=None, title='Diversity Measurement Chart', list_legends=None,
+                           list_styles=None, list_colors=None, x_label="#Iteration", y_label="Diversity Measurement",
+                           filename="diversity_chart", exts=(".png", ".pdf"), verbose=True):
+    if list_styles is None:
+        list_styles = LIST_LINESTYLES[:len(data)]
+    if list_colors is None:
+        list_colors = LIST_COLORS[:len(data)]
+    _draw_multi_line_(data=data, title=title, list_legends=list_legends, list_styles=list_styles, list_colors=list_colors,
+                      x_label=x_label, y_label=y_label, filename=filename, exts=exts, verbose=verbose)
+
+
+def export_objectives_chart(data=None, title="Objectives chart", list_legends=None, list_styles=None, list_colors=None,
+            x_label="#Iteration", y_labels=None, filename="Objective-chart", exts=(".png", ".pdf"), verbose=True):
+    if list_styles is None:
+        list_styles = LIST_LINESTYLES[:len(data)]
+    if list_colors is None:
+        list_colors = LIST_COLORS[:len(data)]
+    _draw_multi_subplots_in_same_figure_(data=data, title=title, list_legends=list_legends, list_styles=list_styles, list_colors=list_colors,
+                                     x_label=x_label, y_labels=y_labels, filename=filename, exts=exts, verbose=verbose)
+
+
+def export_trajectory_chart(data=None, n_dimensions=1, title="Trajectory of some agents after generations", list_legends=None,
+                                 list_styles=None, list_colors=None, x_label="#Iteration", y_label="X1",
+                                 filename="1d_trajectory", exts=(".png", ".pdf"), verbose=True):
+    if list_styles is None:
+        list_styles = LIST_LINESTYLES[:len(data)]
+    if list_colors is None:
+        list_colors = LIST_COLORS[:len(data)]
+
+    if n_dimensions == 1:
+        x = np.arange(0, len(data[0]))
+        for idx, y in enumerate(data):
+            plt.plot(x, y, label=list_legends[idx], markerfacecolor=list_colors[idx], linestyle=list_styles[idx])
+    elif n_dimensions == 2:
+        for idx, point in enumerate(data):
+            plt.plot(point[0], point[1], label=list_legends[idx], markerfacecolor=list_colors[idx], linestyle=list_styles[idx])
+
+    plt.title(title)
+    plt.xlabel(x_label)
+    plt.ylabel(y_label)
+    plt.legend()  # show a legend on the plot
+    if filename is not None:
+        filepath = __check_filepath__(__clean_filename__(filename))
+        for idx, ext in enumerate(exts):
+            plt.savefig(f"{filepath}{ext}", bbox_inches='tight')
+    if platform.system() != "Linux" and verbose:
+        plt.show()
+    plt.close()
+
```

### Comparing `mealpy-2.5.3/mealpy.egg-info/PKG-INFO` & `mealpy-2.5.3a1/mealpy.egg-info/PKG-INFO`

 * *Files 20% similar despite different names*

```diff
@@ -1,1147 +1,1136 @@
-Metadata-Version: 2.1
-Name: mealpy
-Version: 2.5.3
-Summary: MEALPY: An Open-source Library for Latest Meta-heuristic Algorithms in Python
-Home-page: https://github.com/thieu1995/mealpy
-Author: Thieu
-Author-email: nguyenthieu2102@gmail.com
-License: GPLv3
-Project-URL: Documentation, https://mealpy.readthedocs.io/
-Project-URL: Source Code, https://github.com/thieu1995/mealpy
-Project-URL: Bug Tracker, https://github.com/thieu1995/mealpy/issues
-Project-URL: Change Log, https://github.com/thieu1995/mealpy/blob/master/ChangeLog.md
-Project-URL: Forum, https://t.me/+fRVCJGuGJg1mNDg1
-Description: 
-        <p align="center">
-        <img style="height:400px;" 
-        src="https://thieu1995.github.io/post/2022-04/19-mealpy-tutorials/mealpy5-nobg.png" 
-        alt="MEALPY"/>
-        </p>
-        
-        ---
-        
-        
-        [![GitHub release](https://img.shields.io/badge/release-2.5.3-yellow.svg)](https://github.com/thieu1995/mealpy/releases)
-        [![Wheel](https://img.shields.io/pypi/wheel/gensim.svg)](https://pypi.python.org/pypi/mealpy) 
-        [![PyPI version](https://badge.fury.io/py/mealpy.svg)](https://badge.fury.io/py/mealpy)
-        ![PyPI - Python Version](https://img.shields.io/pypi/pyversions/mealpy.svg)
-        ![PyPI - Status](https://img.shields.io/pypi/status/mealpy.svg)
-        ![PyPI - Downloads](https://img.shields.io/pypi/dm/mealpy.svg)
-        [![Downloads](https://pepy.tech/badge/mealpy)](https://pepy.tech/project/mealpy)
-        [![Tests & Publishes to PyPI](https://github.com/thieu1995/mealpy/actions/workflows/publish-package.yaml/badge.svg)](https://github.com/thieu1995/mealpy/actions/workflows/publish-package.yaml)
-        ![GitHub Release Date](https://img.shields.io/github/release-date/thieu1995/mealpy.svg)
-        [![Documentation Status](https://readthedocs.org/projects/mealpy/badge/?version=latest)](https://mealpy.readthedocs.io/en/latest/?badge=latest)
-        [![Chat](https://img.shields.io/badge/Chat-on%20Telegram-blue)](https://t.me/+fRVCJGuGJg1mNDg1)
-        [![Average time to resolve an issue](http://isitmaintained.com/badge/resolution/thieu1995/mealpy.svg)](http://isitmaintained.com/project/thieu1995/mealpy "Average time to resolve an issue")
-        [![Percentage of issues still open](http://isitmaintained.com/badge/open/thieu1995/mealpy.svg)](http://isitmaintained.com/project/thieu1995/mealpy "Percentage of issues still open")
-        ![GitHub contributors](https://img.shields.io/github/contributors/thieu1995/mealpy.svg)
-        [![GitTutorial](https://img.shields.io/badge/PR-Welcome-%23FF8300.svg?)](https://git-scm.com/book/en/v2/GitHub-Contributing-to-a-Project)
-        [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3711948.svg)](https://doi.org/10.5281/zenodo.3711948)
-        [![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)
-        
-        
-        MEALPY is the largest python library for most of the cutting-edge nature-inspired meta-heuristic algorithms (population-based). Population meta-heuristic algorithms (PMA) are the most popular algorithms in the field of 
-        approximate optimization.
-        
-        * **Free software:** GNU General Public License (GPL) V3 license
-        * **Total algorithms**: 174 (102 original, 45 official variants, 27 developed variants)
-        * **Documentation:** https://mealpy.readthedocs.io/en/latest/
-        * **Python versions:** 3.7.x, 3.8.x, 3.9.x, 3.10.x, 3.11.x
-        * **Dependencies:** numpy, scipy, pandas, matplotlib
-        
-        
-        # Goals
-        
-        Our goals are to implement all of the classical as well as the state-of-the-art nature-inspired algorithms, create a simple interface that helps researchers access optimization algorithms as quickly as possible, and share knowledge of the optimization field with everyone without a fee. What you can do with mealpy:
-        
-        - Analyse parameters of meta-heuristic algorithms.
-        - Perform Qualitative and Quantitative Analysis of algorithms.
-        - Analyse rate of convergence of algorithms.
-        - Test and Analyse the scalability and the robustness of algorithms.
-        - Save results in various formats (csv, json, pickle, png, pdf, jpeg)
-        - Export and import models can also be done with Mealpy.
-        
-        
-        
-        # Installation
-        
-        ### Install with pip
-        Install the [current PyPI release](https://pypi.python.org/pypi/mealpy):
-        ```sh 
-        $ pip install mealpy==2.5.3
-        ```
-        
-        ### Install from source
-        In case you want to install directly from the source code, use:
-        ```sh 
-        $ git clone https://github.com/thieu1995/mealpy.git
-        $ cd mealpy
-        $ python setup.py install
-        ```
-        
-        
-        # Usage
-        
-        After installation, you can import Mealpy as any other Python module:
-        
-        ```sh
-        $ python
-        >>> import mealpy
-        >>> mealpy.__version__
-        ```
-        
-        Let's go through a basic and advanced example.
-        
-        
-        ## Examples
-        
-        ### Simple Benchmark Function
-        
-        ```python 
-        from mealpy.bio_based import SMA
-        import numpy as np
-        
-        def fitness_function(solution):
-            return np.sum(solution**2)
-        
-        problem = {
-            "fit_func": fitness_function,
-            "lb": [-100, ] * 30,
-            "ub": [100, ] * 30,
-            "minmax": "min",
-            "log_to": None,
-            "save_population": False,
-        }
-        
-        ## Run the algorithm
-        model = SMA.BaseSMA(epoch=100, pop_size=50, pr=0.03)
-        best_position, best_fitness = model.solve(problem)
-        print(f"Best solution: {best_position}, Best fitness: {best_fitness}")
-        ```
-        
-        ### Constrained Benchmark Function
-        * [The Constrained Benchmark Function](https://github.com/thieu1995/mealpy/tree/master/examples/applications/run_constraint_functions.py)
-        
-        
-        ### Multi-objective Benchmark Function
-        * [Multi-objective benchmark functions](https://github.com/thieu1995/mealpy/tree/master/examples/applications/run_multi_objective_functions.py)
-        
-        
-        ### Custom Problem 
-        
-        For our custom problem, we can create a class and inherit from the Problem class, named the child class the  
-        'Squared' class. In the initialization method of the 'Squared' class, we have to set the *lb*, *ub*, and *minmax*  
-        of the problem (lb: a list of lower bound values, ub: a list of upper bound values, and minmax: a string specifying 
-        whether the problem is a 'min' or 'max' problem). 
-        
-        Afterwards, we have to override the abstract method 'fit_func()', which takes a parameter 'solution' (the solution 
-        to be evaluated) and returns the function value. The resulting code should look something like the code snippet 
-        below. 'Name' is an additional parameter we want to include in this class, and you can include any other additional 
-        parameters you need.
-        
-        
-        ```python 
-        import numpy as np
-        from mealpy.bio_based import BBO
-        from mealpy.utils.problem import Problem
-        
-        # Our custom problem class
-        class Squared(Problem):
-            def __init__(self, lb=(-5, -5, -5, -5, -5, -5), ub=(5, 5, 5, 5, 5, 5), minmax="min", name="Squared", **kwargs):
-                super().__init__(lb, ub, minmax, **kwargs)
-                self.name = name
-        
-            def fit_func(self, solution):
-                return np.sum(solution ** 2)
-        ```
-        
-        Now, we define an algorithm, and pass an instance of our *Squared* class as the problem argument. 
-        
-        ```python
-        problem = Squared(lb=[-10] * 20, ub=[10] * 20, minmax="min")
-        model = BBO.BaseBBO(epoch=10, pop_size=50)
-        best_position, best_fitness = model.solve(problem)
-        
-        print(best_position)
-        print(best_fitness)
-        print(model.get_parameters())
-        print(model.get_name())
-        print(model.get_attributes()["solution"])
-        print(model.problem.get_name())
-        print(model.problem.n_dims)
-        ```
-        
-        
-        ### Tuner class (GridSearchCV/ParameterSearch, Hyper-parameter tuning)
-        
-        We build a dedicated class, Tuner, that can help you tune your algorithm's parameters.
-        
-        ```python
-        import numpy as np
-        from mealpy.bio_based import BBO
-        from mealpy.tuner import Tuner          # Remember this
-        
-        
-        def fitness(solution):
-            return np.sum(solution**2)
-        
-        problem = {
-            "lb": [-100, ]*50,
-            "ub": [100, ]*50,
-            "minmax": "min",
-            "fit_func": fitness,
-            "name": "Squared Problem",
-            "log_to": None,
-        }
-        
-        paras_bbo_grid = {
-            "epoch": [100],
-            "pop_size": [50],
-            "elites": [2, 3, 4, 5],
-            "p_m": [0.01, 0.02, 0.05, 0.1, 0.15, 0.2]
-        }
-        
-        term = {
-          "max_fe": 10000
-        }
-        
-        if __name__ == "__main__":
-            model = BBO.BaseBBO()
-        
-            tuner = Tuner(model, paras_bbo_grid)
-            tuner.execute(problem=problem, termination=term, n_trials=5, n_jobs=5, mode="thread", n_workers=4, verbose=True)
-            ## Solve this problem 5 times (n_trials) using 5 processes (n_jobs), each process will handle 1 trial. 
-            ## The mode to run the solver is thread (mode), we will calculate the fitness of 4 solutions (n_workers) at the same time 
-        
-            print(tuner.best_score)
-            print(tuner.best_params)
-            print(tuner.best_algorithm)
-            print(tuner.best_algorithm.get_name())
-            
-            ## Save results to csv file 
-            tuner.export_results(save_path="history/tuning", save_as="csv")
-            
-            ## Re-solve the best model on your problem 
-            best_position, best_fitness = tuner.resolve()
-        
-            print(best_position, best_fitness)
-            print(tuner.problem.get_name())
-        ```
-        
-        
-        ### Multitask class (Multitask solving)
-        
-        We also build a dedicated class, Multitask, that can help you run several scenarios. For example:
-        
-        1. Run 1 algorithm with 1 problem, and multiple trials
-        2. Run 1 algorithm with multiple problems, and multiple trials
-        3. Run multiple algorithms with 1 problem, and multiple trials
-        4. Run multiple algorithms with multiple problems, and multiple trials
-        
-        
-        ```python
-        #### Using multiple algorithm to solve multiple problems with multiple trials
-        
-        ## Import libraries
-        ## For example, we want to solve F5, F10, F29 problem in CEC-2017
-        from opfunu.cec_based.cec2017 import F52017, F102017, F292017
-        
-        from mealpy.bio_based import BBO
-        from mealpy.evolutionary_based import DE
-        from mealpy.multitask import Multitask          # Remember this
-        
-        
-        ## You can define your own problems
-        
-        f1 = F52017(30, f_bias=0)
-        f2 = F102017(30, f_bias=0)
-        f3 = F292017(30, f_bias=0)
-        
-        p1 = {
-            "lb": f1.lb.tolist(),
-            "ub": f1.ub.tolist(),
-            "minmax": "min",
-            "fit_func": f1.evaluate,
-            "name": "F5-CEC2017",
-            "log_to": None,
-        }
-        
-        p2 = {
-            "lb": f2.lb.tolist(),
-            "ub": f2.ub.tolist(),
-            "minmax": "min",
-            "fit_func": f2.evaluate,
-            "name": "F10-CEC2017",
-            "log_to": None,
-        }
-        
-        p3 = {
-            "lb": f3.lb.tolist(),
-            "ub": f3.ub.tolist(),
-            "minmax": "min",
-            "fit_func": f3.evaluate,
-            "name": "F29-CEC2017",
-            "log_to": None,
-        }
-        
-        ## Define models
-        
-        model1 = BBO.BaseBBO(epoch=10, pop_size=50)
-        model2 = BBO.OriginalBBO(epoch=10, pop_size=50)
-        model3 = DE.BaseDE(epoch=10, pop_size=50)
-        
-        ## Define termination if needed
-        term = {
-            "max_fe": 10000
-        }
-        
-        ## Define and run Multitask
-        if __name__ == "__main__":
-            multitask = Multitask(algorithms=(model1, model2, model3), problems=(p1, p2, p3), terminations=(term, ), modes=("thread", ))
-            # default modes = "single", default termination = epoch (as defined in problem dictionary)
-            multitask.execute(n_trials=5, n_jobs=5, save_path="history", save_as="csv", save_convergence=False, verbose=False)
-            
-            ## Check the directory: history/, you will see list of .csv result files
-        ```
-        
-        For more usage examples please look at [examples](/examples) folder.
-        
-        More advanced examples can also be found in the [Mealpy-examples repository](https://github.com/thieu1995/mealpy_examples).
-        
-        
-        ### Get Visualize Figures
-        
-        
-        * [Tutorials](/examples/utils/visualize/all_charts.py)
-        
-        <p align="center"><img src="https://thieu1995.github.io/post/2022-04/19-mealpy-tutorials/mealpy2.png" alt="MEALPY"/>
-        </p>
-        
-        
-        ## Mealpy Application
-        
-        ### Mealpy + Neural Network (Replace the Gradient Descent Optimizer)
-        
-        * Time-series Problem:
-          * Traditional MLP
-            code: [Link](https://github.com/thieu1995/mealpy/tree/master/examples/applications/keras/traditional-mlp-time-series.py)
-          * Hybrid code (Mealpy +
-            MLP): [Link](https://github.com/thieu1995/mealpy/tree/master/examples/applications/keras/mha-hybrid-mlp-time-series.py)
-        * Classification Problem:
-          * Traditional MLP
-            code: [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/keras/traditional-mlp-classification.py)
-          * Hybrid code (Mealpy +
-            MLP): [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/keras/mha-hybrid-mlp-classification.py)
-        
-        ### Mealpy + Neural Network (Optimize Neural Network Hyper-parameter)
-        
-        Code: [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/keras/mha-hyper-parameter-mlp-time-series.py)
-        
-        ### Other Applications
-        
-        * Solving Knapsack Problem (Discrete
-          problems): [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/discrete-problems/knapsack-problem.py)
-        
-        * Optimize SVM (SVC)
-          model: [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/sklearn/svm_classification.py)
-        
-        * Optimize Linear Regression
-          Model: [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/pytorch/linear_regression.py)
-        
-        * Travelling Salesman Problem: https://github.com/thieu1995/MHA-TSP 
-        
-        * Feature selection problem: https://github.com/thieu1995/MHA-FS
-        
-        
-        
-        ## Tutorial Videos
-        
-        All tutorial videos: [Link](https://mealpy.readthedocs.io/en/latest/pages/general/video_tutorials.html)
-        
-        All code examples: [Link](https://github.com/thieu1995/mealpy/tree/master/examples)
-        
-        All visualization examples: [Link](https://mealpy.readthedocs.io/en/latest/pages/visualization.html)
-        
-        
-        
-        ### Get helps (questions, problems)
-        
-        * Official source code repo: https://github.com/thieu1995/mealpy
-        * Official document: https://mealpy.readthedocs.io/
-        * Download releases: https://pypi.org/project/mealpy/
-        * Issue tracker: https://github.com/thieu1995/mealpy/issues
-        * Notable changes log: https://github.com/thieu1995/mealpy/blob/master/ChangeLog.md
-        * Examples with different meapy version: https://github.com/thieu1995/mealpy/blob/master/EXAMPLES.md
-        
-        * This project also related to our another projects which are "meta-heuristics" and "neural-network", check it here
-            * https://github.com/thieu1995/opfunu
-            * https://github.com/thieu1995/metaheuristics
-            * https://github.com/aiir-team
-        
-        **Want to have an instant assistant? Join our telegram community at [link](https://t.me/+fRVCJGuGJg1mNDg1)**
-        We share lots of information, questions, and answers there. You will get more support and knowledge there.
-        
-        ### Cite Us
-        
-        If you are using mealpy in your project, we would appreciate citations:
-        
-        ```bibtex 
-        @article{van2023mealpy,
-          title={MEALPY: An open-source library for latest meta-heuristic algorithms in Python},
-          author={Van Thieu, Nguyen and Mirjalili, Seyedali},
-          journal={Journal of Systems Architecture},
-          year={2023},
-          publisher={Elsevier}
-        }
-        
-        @article{van2023groundwater,
-          title={Groundwater level modeling using Augmented Artificial Ecosystem Optimization},
-          author={Van Thieu, Nguyen and Barma, Surajit Deb and Van Lam, To and Kisi, Ozgur and Mahesha, Amai},
-          journal={Journal of Hydrology},
-          volume={617},
-          pages={129034},
-          year={2023},
-          publisher={Elsevier}
-        }
-        ```
-        
-        
-        
-        # List of papers used MEALPY
-        
-        - Min, J., Oh, M., Kim, W., Seo, H., & Paek, J. (2022, October). Evaluation of Metaheuristic Algorithms for TAS Scheduling in Time-Sensitive Networking. In 2022 13th International Conference on Information and Communication Technology Convergence (ICTC) (pp. 809-812). IEEE.
-        - Khozeimeh, F., Sharifrazi, D., Izadi, N. H., Joloudari, J. H., Shoeibi, A., Alizadehsani, R., ... & Islam, S. M. S. (2021). Combining a convolutional neural network with autoencoders to predict the survival chance of COVID-19 patients. Scientific Reports, 11(1), 15343.
-        - Rajesh, K., Jain, E., & Kotecha, P. (2022). A Multi-Objective approach to the Electric Vehicle Routing Problem. arXiv preprint arXiv:2208.12440.
-        - SÃ¡nchez, A. J. H., & Upegui, F. R. (2022). Una herramienta para el diseÃ±o de redes MSMN de banda ancha en lÃ­neas de transmisiÃ³n basada en algoritmos heurÃ­sticos de optimizaciÃ³n comparados. Revista IngenierÃ­a UC, 29(2), 106-123.
-        - Khanmohammadi, M., Armaghani, D. J., & Sabri Sabri, M. M. (2022). Prediction and Optimization of Pile Bearing Capacity Considering Effects of Time. Mathematics, 10(19), 3563.
-        - Kudela, J. (2023). The Evolutionary Computation Methods No One Should Use. arXiv preprint arXiv:2301.01984.
-        - Vieira, M., Faia, R., Pinto, T., & Vale, Z. (2022, September). Schedule Peer-to-Peer Transactions of an Energy Community Using Particle Swarm. In 2022 18th International Conference on the European Energy Market (EEM) (pp. 1-6). IEEE.
-        - Bui, X. N., Nguyen, H., Le, Q. T., & Le, T. N. Forecasting PM. MINING SCIENCE ANDTECHNOLOGY (Russia), 111.
-        - Bui, X. N., Nguyen, H., Le, Q. T., & Le, T. N. (2022). Forecasting PM 2.5 emissions in open-pit minesusing a functional link neural network optimized by various optimization algorithms. Gornye nauki i tekhnologii= Mining Science and Technology (Russia), 7(2), 111-125.
-        - DoÄan, E., & YÃ¶rÃ¼keren, N. (2022). Enhancement of Transmission System Security with Archimedes Optimization Algorithm.
-        - Ayub, N., Aurangzeb, K., Awais, M., & Ali, U. (2020, November). Electricity theft detection using CNN-GRU and manta ray foraging optimization algorithm. In 2020 IEEE 23Rd international multitopic conference (INMIC) (pp. 1-6). IEEE.
-        - Pintilie, L., Nechita, M. T., Suditu, G. D., Dafinescu, V., & DrÄgoi, E. N. (2022). Photo-decolorization of Eriochrome Black T: process optimization with Differential Evolution algorithm. In PASEW-22, MESSH-22 & CABES-22 April 19â21, 2022 Paris (France). Eminent Association of Pioneers.
-        - LaTorre, A., Molina, D., Osaba, E., Poyatos, J., Del Ser, J., & Herrera, F. (2021). A prescription of methodological guidelines for comparing bio-inspired optimization algorithms. Swarm and Evolutionary Computation, 67, 100973.
-        - Gottam, S., Nanda, S. J., & Maddila, R. K. (2021, December). A CNN-LSTM Model Trained with Grey Wolf Optimizer for Prediction of Household Power Consumption. In 2021 IEEE International Symposium on Smart Electronic Systems (iSES)(Formerly iNiS) (pp. 355-360). IEEE.
-        - Darius, P. S., Devadason, J., & Solomon, D. G. (2022, December). Prospects of Ant Colony Optimization (ACO) in Various Domains. In 2022 4th International Conference on Circuits, Control, Communication and Computing (I4C) (pp. 79-84). IEEE.
-        - Ayub, N., Irfan, M., Awais, M., Ali, U., Ali, T., Hamdi, M., ... & Muhammad, F. (2020). Big data analytics for short and medium-term electricity load forecasting using an AI techniques ensembler. Energies, 13(19), 5193.
-        - Biundini, I. Z., Melo, A. G., Coelho, F. O., HonÃ³rio, L. M., Marcato, A. L., & Pinto, M. F. (2022). Experimentation and Simulation with Autonomous Coverage Path Planning for UAVs. Journal of Intelligent & Robotic Systems, 105(2), 46.
-        - Yousaf, I., Anwar, F., Imtiaz, S., Almadhor, A. S., Ishmanov, F., & Kim, S. W. (2022). An Optimized Hyperparameter of Convolutional Neural Network Algorithm for Bug Severity Prediction in Alzheimerâs-Based IoT System. Computational Intelligence and Neuroscience, 2022.
-        - Xu, L., Yan, W., & Ji, J. (2023). The research of a novel WOG-YOLO algorithm for autonomous driving object detection. Scientific reports, 13(1), 3699.
-        - Costache, R. D., Arabameri, A., Islam, A. R. M. T., Abba, S. I., Pandey, M., Ajin, R. S., & Pham, B. T. (2022). Flood susceptibility computation using state-of-the-art machine learning and optimization algorithms.
-        - Del Ser, J., Osaba, E., Martinez, A. D., Bilbao, M. N., Poyatos, J., Molina, D., & Herrera, F. (2021, December). More is not always better: insights from a massive comparison of meta-heuristic algorithms over real-parameter optimization problems. In 2021 IEEE Symposium Series on Computational Intelligence (SSCI) (pp. 1-7). IEEE.
-        - Rustam, F., Aslam, N., De La Torre DÃ­ez, I., Khan, Y. D., MazÃ³n, J. L. V., RodrÃ­guez, C. L., & Ashraf, I. (2022, November). White Blood Cell Classification Using Texture and RGB Features of Oversampled Microscopic Images. In Healthcare (Vol. 10, No. 11, p. 2230). MDPI.
-        - Neupane, D., Kafle, S., Gurung, S., Neupane, S., & Bhattarai, N. (2021). Optimal sizing and financial analysis of a stand-alone SPV-micro-hydropower hybrid system considering generation uncertainty. International Journal of Low-Carbon Technologies, 16(4), 1479-1491.
-        - Liang, R., Le-Hung, T., & Nguyen-Thoi, T. (2022). Energy consumption prediction of air-conditioning systems in eco-buildings using hunger games search optimization-based artificial neural network model. Journal of Building Engineering, 59, 105087.
-        - He, Z., Nguyen, H., Vu, T. H., Zhou, J., Asteris, P. G., & Mammou, A. (2022). Novel integrated approaches for predicting the compressibility of clay using cascade forward neural networks optimized by swarm-and evolution-based algorithms. Acta Geotechnica, 1-16.
-        - Xu, L., Yan, W., & Ji, J. (2022). The research of a novel WOG-YOLO algorithm forautonomous driving object detection.
-        - Nasir Ayub, M. I., Awais, M., Ali, U., Ali, T., Hamdi, M., Alghamdi, A., & Muhammad, F. Big Data Analytics for Short and Medium Term Electricity Load Forecasting using AI Techniques Ensembler.
-        - Xie, C., Nguyen, H., Choi, Y., & Armaghani, D. J. (2022). Optimized functional linked neural network for predicting diaphragm wall deflection induced by braced excavations in clays. Geoscience Frontiers, 13(2), 101313.
-        - Hakemi, S., Houshmand, M., & Hosseini, S. A. (2022). A Dynamic Quantum-Inspired Genetic Algorithm with Lengthening Chromosome Size.
-        - Kashifi, M. T. City-Wide Crash Risk Prediction and Interpretation Using Deep Learning Model with Multi-Source Big Data. Available at SSRN 4329686.
-        - Nguyen, H., & Hoang, N. D. (2022). Computer vision-based classification of concrete spall severity using metaheuristic-optimized Extreme Gradient Boosting Machine and Deep Convolutional Neural Network. Automation in Construction, 140, 104371.
-        - Zheng, J., Lu, Z., Wu, K., Ning, G. H., & Li, D. (2020). Coinage-metal-based cyclic trinuclear complexes with metalâmetal interactions: Theories to experiments and structures to functions. Chemical Reviews, 120(17), 9675-9742.
-        - Van Thieu, N., Barma, S. D., Van Lam, T., Kisi, O., & Mahesha, A. (2023). Groundwater level modeling using Augmented Artificial Ecosystem Optimization. Journal of Hydrology, 617, 129034.
-        - Mo, Z., Zhang, Z., Miao, Q., & Tsui, K. L. (2022). Intelligent Informative Frequency Band Searching Assisted by a Dynamic Bandit Tree Method for Machine Fault Diagnosis. IEEE/ASME Transactions on Mechatronics.
-        - Dangi, D., Chandel, S. T., Dixit, D. K., Sharma, S., & Bhagat, A. (2023). An Efficient Model for Sentiment Analysis using Artificial Rabbits Optimized Vector Functional Link Network. Expert Systems with Applications, 119849.
-        - Dey, S., Roychoudhury, R., Malakar, S., & Sarkar, R. (2022). An optimized fuzzy ensemble of convolutional neural networks for detecting tuberculosis from Chest X-ray images. Applied Soft Computing, 114, 108094.
-        - Mousavirad, S. J., & Alexandre, L. A. (2022). Population-based JPEG Image Compression: Problem Re-Formulation. arXiv preprint arXiv:2212.06313.
-        - Tsui, K. L. Intelligent Informative Frequency Band Searching Assisted by A Dynamic Bandit Tree Method for Machine Fault Diagnosis.
-        - Neupane, D. (2020). Optimal Sizing and Performance Analysis of Solar PV-Micro hydropower Hybrid System in the Context of Rural Area of Nepal (Doctoral dissertation, Pulchowk Campus).
-        - LaTorre, A., Molina, D., Osaba, E., Poyatos, J., Del Ser, J., & Herrera, F. Swarm and Evolutionary Computation.
-        - Vieira, M. A. (2022). OtimizaÃ§Ã£o dos custos operacionais de uma comunidade energÃ©tica considerando transaÃ§Ãµes locais em âpeer-to-peerâ (Doctoral dissertation).
-        - ToÄaÃ§ar, M. (2022). Using DarkNet models and metaheuristic optimization methods together to detect weeds growing along with seedlings. Ecological Informatics, 68, 101519.
-        - ToÄaÃ§ar, M. (2021). Detection of segmented uterine cancer images by Hotspot Detection method using deep learning models, Pigeon-Inspired Optimization, types-based dominant activation selection approaches. Computers in Biology and Medicine, 136, 104659.
-        - Khan, N. A Short Term Electricity Load and Price Forecasting Model Based on BAT Algorithm in Logistic Regression and CNN-GRU with WOA.
-        - Yelisetti, S., Saini, V. K., Kumar, R., & Lamba, R. (2022, May). Energy Consumption Cost Benefits through Smart Home Energy Management in Residential Buildings: An Indian Case Study. In 2022 IEEE IAS Global Conference on Emerging Technologies (GlobConET) (pp. 930-935). IEEE.
-        - Nguyen, H., Cao, M. T., Tran, X. L., Tran, T. H., & Hoang, N. D. (2022). A novel whale optimization algorithm optimized XGBoost regression for estimating bearing capacity of concrete piles. Neural Computing and Applications, 1-28.
-        - Hirsching, C., de Jongh, S., Eser, D., Suriyah, M., & Leibfried, T. (2022). Meta-heuristic optimization of control structure and design for MMC-HVdc applications. Electric Power Systems Research, 213, 108371.
-        - Amelin, V., Gatiyatullin, E., Romanov, N., Samarkhanov, R., Vasilyev, R., & Yanovich, Y. (2022). Black-Box for Blockchain Parameters Adjustment. IEEE Access, 10, 101795-101802.
-        - Ngo, T. Q., Nguyen, L. Q., & Tran, V. Q. (2022). Novel hybrid machine learning models including support vector machine with meta-heuristic algorithms in predicting unconfined compressive strength of organic soils stabilised with cement and lime. International Journal of Pavement Engineering, 1-18.
-        - Zhu, Y., & Iiduka, H. (2021). Unified Algorithm Framework for Nonconvex Stochastic Optimization in Deep Neural Networks. IEEE Access, 9, 143807-143823.
-        - Hakemi, S., Houshmand, M., KheirKhah, E., & Hosseini, S. A. (2022). A review of recent advances in quantum-inspired metaheuristics. Evolutionary Intelligence, 1-16.
-        - Das, A., Das, S. R., Panda, J. P., Dey, A., Gajrani, K. K., Somani, N., & Gupta, N. (2022). Machine learning based modelling and optimization in hard turning of AISI D6 steel with newly developed AlTiSiN coated carbide tool. arXiv preprint arXiv:2202.00596.
-        - Yelisetti, S., Saini, V. K., Kumar, R., Lamba, R., & Saxena, A. (2022). Optimal energy management system for residential buildings considering the time of use price with swarm intelligence algorithms. Journal of Building Engineering, 59, 105062.
-        - ValdÃ©s, G. T. (2022). Algoritmo para la detecciÃ³n de vehÃ­culos y peatones combinando CNNÂ´ sy tÃ©cnicas de bÃºsqueda.
-        - Sallam, N. M., Saleh, A. I., Ali, H. A., & Abdelsalam, M. M. (2023). An efficient EGWO algorithm as feature selection for B-ALL diagnoses and its subtypes classification using peripheral blood smear images. Alexandria Engineering Journal, 68, 39-66.
-        
-        
-        
-        
-        # Documents
-        
-        * Meta-heuristic Categories: (Based on this article: [link](https://doi.org/10.1016/j.procs.2020.09.075))
-            + Evolutionary-based: Idea from Darwin's law of natural selection, evolutionary computing 
-            + Swarm-based: Idea from movement, interaction of birds, organization of social ...
-            + Physics-based: Idea from physics law such as Newton's law of universal gravitation, black hole, multiverse 
-            + Human-based: Idea from human interaction such as queuing search, teaching learning, ... 
-            + Biology-based: Idea from biology creature (or microorganism),...
-            + System-based: Idea from eco-system, immune-system, network-system, ...
-            + Math-based: Idea from mathematical form or mathematical law such as sin-cosin 
-            + Music-based: Idea from music instrument
-        
-        * Difficulty - Difficulty Level (Personal Opinion): **Objective observation from author**. Depend on the number of 
-          parameters, number of equations, the original ideas, time spend for coding, source lines of code (SLOC).
-            + Easy: A few paras, few equations, SLOC very short
-            + Medium: more equations than Easy level, SLOC longer than Easy level
-            + Hard: Lots of equations, SLOC longer than Medium level, the paper hard to read.
-            + Hard* - Very hard: Lots of equations, SLOC too long, the paper is very hard to read.
-            
-        ** For newbie, we recommend to read the paper of algorithms which difficulty is "easy" or "medium" difficulty level.
-        
-        
-        | **Group**    | **Name**                                        | **Module** | **Class**        | **Year** | **Paras** | **Difficulty** |
-        |--------------|-------------------------------------------------|------------|------------------|----------|-----------|----------------|
-        | Evolutionary | Evolutionary Programming                        | EP         | OriginalEP       | 1964     | 3         | easy           |
-        | Evolutionary | -                                               | -          | LevyEP           | -        | 3         | easy           |
-        | Evolutionary | Evolution Strategies                            | ES         | OriginalES       | 1971     | 3         | easy           |
-        | Evolutionary | -                                               | -          | LevyES           | -        | 3         | easy           |
-        | Evolutionary | Memetic Algorithm                               | MA         | OriginalMA       | 1989     | 7         | easy           |
-        | Evolutionary | Genetic Algorithm                               | GA         | BaseGA           | 1992     | 4         | easy           |
-        | Evolutionary | -                                               | -          | SingleGA         | -        | 7         | easy           |
-        | Evolutionary | -                                               | -          | MultiGA          | -        | 7         | easy           |
-        | Evolutionary | -                                               | -          | EliteSingleGA    | -        | 10        | easy           |
-        | Evolutionary | -                                               | -          | EliteMultiGA     | -        | 10        | easy           |
-        | Evolutionary | Differential Evolution                          | DE         | BaseDE           | 1997     | 5         | easy           |
-        | Evolutionary | -                                               | -          | JADE             | 2009     | 6         | medium         |
-        | Evolutionary | -                                               | -          | SADE             | 2005     | 2         | medium         |
-        | Evolutionary | -                                               | -          | SHADE            | 2013     | 4         | medium         |
-        | Evolutionary | -                                               | -          | L_SHADE          | 2014     | 4         | medium         |
-        | Evolutionary | -                                               | -          | SAP_DE           | 2006     | 3         | medium         |
-        | Evolutionary | Flower Pollination Algorithm                    | FPA        | OriginalFPA      | 2014     | 4         | medium         |
-        | Evolutionary | Coral Reefs Optimization                        | CRO        | OriginalCRO      | 2014     | 11        | medium         |
-        | Evolutionary | -                                               | -          | OCRO             | 2019     | 12        | medium         |
-        | -            | -                                               | -          | -                | -        | -         | -              |
-        | Swarm        | Particle Swarm Optimization                     | PSO        | OriginalPSO      | 1995     | 6         | easy           |
-        | Swarm        | -                                               | -          | PPSO             | 2019     | 2         | medium         |
-        | Swarm        | -                                               | -          | HPSO_TVAC        | 2017     | 4         | medium         |
-        | Swarm        | -                                               | -          | C_PSO            | 2015     | 6         | medium         |
-        | Swarm        | -                                               | -          | CL_PSO           | 2006     | 6         | medium         |
-        | Swarm        | Bacterial Foraging Optimization                 | BFO        | OriginalBFO      | 2002     | 10        | hard           |
-        | Swarm        | -                                               | -          | ABFO             | 2019     | 8         | medium         |
-        | Swarm        | Bees Algorithm                                  | BeesA      | OriginalBeesA    | 2005     | 8         | medium         |
-        | Swarm        | -                                               | -          | ProbBeesA        | 2015     | 5         | medium         |
-        | Swarm        | Cat Swarm Optimization                          | CSO        | OriginalCSO      | 2006     | 11        | hard           |
-        | Swarm        | Artificial Bee Colony                           | ABC        | OriginalABC      | 2007     | 8         | medium         |
-        | Swarm        | Ant Colony Optimization                         | ACO-R      | OriginalACOR     | 2008     | 5         | easy           |
-        | Swarm        | Cuckoo Search Algorithm                         | CSA        | OriginalCSA      | 2009     | 3         | medium         |
-        | Swarm        | Firefly Algorithm                               | FFA        | OriginalFFA      | 2009     | 8         | easy           |
-        | Swarm        | Fireworks Algorithm                             | FA         | OriginalFA       | 2010     | 7         | medium         |
-        | Swarm        | Bat Algorithm                                   | BA         | OriginalBA       | 2010     | 6         | medium         |
-        | Swarm        | -                                               | -          | AdaptiveBA       | -        | 8         | medium         |
-        | Swarm        | -                                               | -          | ModifiedBA       | -        | 5         | medium         |
-        | Swarm        | Fruit-fly Optimization Algorithm                | FOA        | OriginalFOA      | 2012     | 2         | easy           |
-        | Swarm        | -                                               | -          | BaseFOA          | -        | 2         | easy           |
-        | Swarm        | -                                               | -          | WhaleFOA         | 2020     | 2         | medium         |
-        | Swarm        | Social Spider Optimization                      | SSpiderO   | OriginalSSpiderO | 2018     | 4         | hard*          |
-        | Swarm        | Grey Wolf Optimizer                             | GWO        | OriginalGWO      | 2014     | 2         | easy           |
-        | Swarm        | -                                               | -          | RW_GWO           | 2019     | 2         | easy           |
-        | Swarm        | Social Spider Algorithm                         | SSpiderA   | OriginalSSpiderA | 2015     | 5         | medium         |
-        | Swarm        | Ant Lion Optimizer                              | ALO        | OriginalALO      | 2015     | 2         | easy           |
-        | Swarm        | -                                               | -          | BaseALO          | -        | 2         | easy           |
-        | Swarm        | Moth Flame Optimization                         | MFO        | OriginalMFO      | 2015     | 2         | easy           |
-        | Swarm        | -                                               | -          | BaseMFO          | -        | 2         | easy           |
-        | Swarm        | Elephant Herding Optimization                   | EHO        | OriginalEHO      | 2015     | 5         | easy           |
-        | Swarm        | Jaya Algorithm                                  | JA         | OriginalJA       | 2016     | 2         | easy           |
-        | Swarm        | -                                               | -          | BaseJA           | -        | 2         | easy           |
-        | Swarm        | -                                               | -          | LevyJA           | 2021     | 2         | easy           |
-        | Swarm        | Whale Optimization Algorithm                    | WOA        | OriginalWOA      | 2016     | 2         | medium         |
-        | Swarm        | -                                               | -          | HI_WOA           | 2019     | 3         | medium         |
-        | Swarm        | Dragonfly Optimization                          | DO         | OriginalDO       | 2016     | 2         | medium         |
-        | Swarm        | Bird Swarm Algorithm                            | BSA        | OriginalBSA      | 2016     | 9         | medium         |
-        | Swarm        | Spotted Hyena Optimizer                         | SHO        | OriginalSHO      | 2017     | 4         | medium         |
-        | Swarm        | Salp Swarm Optimization                         | SSO        | OriginalSSO      | 2017     | 2         | easy           |
-        | Swarm        | Swarm Robotics Search And Rescue                | SRSR       | OriginalSRSR     | 2017     | 2         | hard*          |
-        | Swarm        | Grasshopper Optimisation Algorithm              | GOA        | OriginalGOA      | 2017     | 4         | easy           |
-        | Swarm        | Coyote Optimization Algorithm                   | COA        | OriginalCOA      | 2018     | 3         | medium         |
-        | Swarm        | Moth Search Algorithm                           | MSA        | OriginalMSA      | 2018     | 5         | easy           |
-        | Swarm        | Sea Lion Optimization                           | SLO        | OriginalSLO      | 2019     | 2         | medium         |
-        | Swarm        | -                                               | -          | ModifiedSLO      | -        | 2         | medium         |
-        | Swarm        | -                                               | -          | ImprovedSLO      | -        | 4         | medium         |
-        | Swarm        | Nake Mole-Rat Algorithm                         | NMRA       | OriginalNMRA     | 2019     | 3         | easy           |
-        | Swarm        | -                                               | -          | ImprovedNMRA     | -        | 4         | medium         |
-        | Swarm        | Pathfinder Algorithm                            | PFA        | OriginalPFA      | 2019     | 2         | medium         |
-        | Swarm        | Sailfish Optimizer                              | SFO        | OriginalSFO      | 2019     | 5         | easy           |
-        | Swarm        | -                                               | -          | ImprovedSFO      | -        | 3         | medium         |
-        | Swarm        | Harris Hawks Optimization                       | HHO        | OriginalHHO      | 2019     | 2         | medium         |
-        | Swarm        | Manta Ray Foraging Optimization                 | MRFO       | OriginalMRFO     | 2020     | 3         | medium         |
-        | Swarm        | Bald Eagle Search                               | BES        | OriginalBES      | 2020     | 7         | easy           |
-        | Swarm        | Sparrow Search Algorithm                        | SSA        | OriginalSSA      | 2020     | 5         | medium         |
-        | Swarm        | -                                               | -          | BaseSSA          | -        | 5         | medium         |
-        | Swarm        | Hunger Games Search                             | HGS        | OriginalHGS      | 2021     | 4         | medium         |
-        | Swarm        | Aquila Optimizer                                | AO         | OriginalAO       | 2021     | 2         | easy           |
-        | Swarm        | Hybrid Grey Wolf - Whale Optimization Algorithm | GWO        | GWO_WOA          | 2022     | 2         | easy           |
-        | Swarm        | Marine Predators Algorithm                      | MPA        | OriginalMPA      | 2020     | 2         | medium         |
-        | Swarm        | Honey Badger Algorithm                          | HBA        | OriginalHBA      | 2022     | 2         | easy           |
-        | Swarm        | Sand Cat Swarm Optimization                     | SCSO       | OriginalSCSO     | 2022     | 2         | easy           |
-        | Swarm        | Tuna Swarm Optimization                         | TSO        | OriginalTSO      | 2021     | 2         | medium         |
-        | Swarm        | African Vultures Optimization Algorithm         | AVOA       | OriginalAVOA     | 2022     | 7         | medium         |
-        | Swarm        | Artificial Gorilla Troops Optimization          | AGTO       | OriginalAGTO     | 2021     | 5         | medium         |
-        | Swarm        | Artificial Rabbits Optimization                 | ARO        | OriginalARO      | 2022     | 2         | easy           |
-        | Swarm        | Dwarf Mongoose Optimization Algorithm           | DMOA       | OriginalDMOA     | 2022     | 4         | medium         |
-        | Swarm        | -                                               | -          | DevDMOA          | -        | 3         | medium         |
-        | -            | -                                               | -          | -                | -        | -         | -              |
-        | Physics      | Simulated Annealling                            | SA         | OriginalSA       | 1987     | 9         | medium         |
-        | Physics      | Wind Driven Optimization                        | WDO        | OriginalWDO      | 2013     | 7         | easy           |
-        | Physics      | Multi-Verse Optimizer                           | MVO        | OriginalMVO      | 2016     | 4         | easy           |
-        | Physics      | -                                               | -          | BaseMVO          | -        | 4         | easy           |
-        | Physics      | Tug of War Optimization                         | TWO        | OriginalTWO      | 2016     | 2         | easy           |
-        | Physics      | -                                               | -          | OppoTWO          | -        | 2         | medium         |
-        | Physics      | -                                               | -          | LevyTWO          | -        | 2         | medium         |
-        | Physics      | -                                               | -          | EnhancedTWO      | 2020     | 2         | medium         |
-        | Physics      | Electromagnetic Field Optimization              | EFO        | OriginalEFO      | 2016     | 6         | easy           |
-        | Physics      | -                                               | -          | BaseEFO          | -        | 6         | medium         |
-        | Physics      | Nuclear Reaction Optimization                   | NRO        | OriginalNRO      | 2019     | 2         | hard*          |
-        | Physics      | Henry Gas Solubility Optimization               | HGSO       | OriginalHGSO     | 2019     | 3         | medium         |
-        | Physics      | Atom Search Optimization                        | ASO        | OriginalASO      | 2019     | 4         | medium         |
-        | Physics      | Equilibrium Optimizer                           | EO         | OriginalEO       | 2019     | 2         | easy           |
-        | Physics      | -                                               | -          | ModifiedEO       | 2020     | 2         | medium         |
-        | Physics      | -                                               | -          | AdaptiveEO       | 2020     | 2         | medium         |
-        | Physics      | Archimedes Optimization Algorithm               | ArchOA     | OriginalArchOA   | 2021     | 8         | medium         |
-        | -            | -                                               | -          | -                | -        | -         | -              |
-        | Human        | Culture Algorithm                               | CA         | OriginalCA       | 1994     | 3         | easy           |
-        | Human        | Imperialist Competitive Algorithm               | ICA        | OriginalICA      | 2007     | 8         | hard*          |
-        | Human        | Teaching Learning-based Optimization            | TLO        | OriginalTLO      | 2011     | 2         | easy           |
-        | Human        | -                                               | -          | BaseTLO          | 2012     | 2         | easy           |
-        | Human        | -                                               | -          | ITLO             | 2013     | 3         | medium         |
-        | Human        | Brain Storm Optimization                        | BSO        | OriginalBSO      | 2011     | 8         | medium         |
-        | Human        | -                                               | -          | ImprovedBSO      | 2017     | 7         | medium         |
-        | Human        | Queuing Search Algorithm                        | QSA        | OriginalQSA      | 2019     | 2         | hard           |
-        | Human        | -                                               | -          | BaseQSA          | -        | 2         | hard           |
-        | Human        | -                                               | -          | OppoQSA          | -        | 2         | hard           |
-        | Human        | -                                               | -          | LevyQSA          | -        | 2         | hard           |
-        | Human        | -                                               | -          | ImprovedQSA      | 2021     | 2         | hard           |
-        | Human        | Search And Rescue Optimization                  | SARO       | OriginalSARO     | 2019     | 4         | medium         |
-        | Human        | -                                               | -          | BaseSARO         | -        | 4         | medium         |
-        | Human        | Life Choice-Based Optimization                  | LCO        | OriginalLCO      | 2019     | 3         | easy           |
-        | Human        | -                                               | -          | BaseLCO          | -        | 3         | easy           |
-        | Human        | -                                               | -          | ImprovedLCO      | -        | 2         | easy           |
-        | Human        | Social Ski-Driver Optimization                  | SSDO       | OriginalSSDO     | 2019     | 2         | easy           |
-        | Human        | Gaining Sharing Knowledge-based Algorithm       | GSKA       | OriginalGSKA     | 2019     | 6         | medium         |
-        | Human        | -                                               | -          | BaseGSKA         | -        | 4         | medium         |
-        | Human        | Coronavirus Herd Immunity Optimization          | CHIO       | OriginalCHIO     | 2020     | 4         | medium         |
-        | Human        | -                                               | -          | BaseCHIO         | -        | 4         | medium         |
-        | Human        | Forensic-Based Investigation Optimization       | FBIO       | OriginalFBIO     | 2020     | 2         | medium         |
-        | Human        | -                                               | -          | BaseFBIO         | -        | 2         | medium         |
-        | Human        | Battle Royale Optimization                      | BRO        | OriginalBRO      | 2020     | 3         | medium         |
-        | Human        | -                                               | -          | BaseBRO          | -        | 3         | medium         |
-        | Human        | Student Psychology Based Optimization           | SPBO       | OriginalSPBO     | 2020     | 2         | medium         |
-        | Human        | -                                               | -          | DevSPBO          |          | 2         | medium         |
-        | -            | -                                               | -          | -                | -        | -         | -              |
-        | Bio          | Invasive Weed Optimization                      | IWO        | OriginalIWO      | 2006     | 7         | easy           |
-        | Bio          | Biogeography-Based Optimization                 | BBO        | OriginalBBO      | 2008     | 4         | easy           |
-        | Bio          | -                                               | -          | BaseBBO          | -        | 4         | easy           |
-        | Bio          | Virus Colony Search                             | VCS        | OriginalVCS      | 2016     | 4         | hard*          |
-        | Bio          | -                                               | -          | BaseVCS          | -        | 4         | hard*          |
-        | Bio          | Satin Bowerbird Optimizer                       | SBO        | OriginalSBO      | 2017     | 5         | easy           |
-        | Bio          | -                                               | -          | BaseSBO          | -        | 5         | easy           |
-        | Bio          | Earthworm Optimisation Algorithm                | EOA        | OriginalEOA      | 2018     | 8         | medium         |
-        | Bio          | Wildebeest Herd Optimization                    | WHO        | OriginalWHO      | 2019     | 12        | hard           |
-        | Bio          | Slime Mould Algorithm                           | SMA        | OriginalSMA      | 2020     | 3         | easy           |
-        | Bio          | -                                               | -          | BaseSMA          | -        | 3         | easy           |
-        | Bio          | Barnacles Mating Optimizer                      | BMO        | OriginalBMO      | 2018     | 3         | easy           |
-        | Bio          | Tunicate Swarm Algorithm                        | TSA        | OriginalTSA      | 2020     | 2         | easy           |
-        | Bio          | Symbiotic Organisms Search                      | SOS        | OriginalSOS      | 2014     | 2         | medium         |
-        | Bio          | Seagull Optimization Algorithm                  | SOA        | OriginalSOA      | 2019     | 3         | easy           |
-        | Bio          | -                                               | -          | DevSOA           | -        | 3         | easy           |
-        | -            | -                                               | -          | -                | -        | -         | -              |
-        | System       | Germinal Center Optimization                    | GCO        | OriginalGCO      | 2018     | 4         | medium         |
-        | System       | -                                               | -          | BaseGCO          | -        | 4         | medium         |
-        | System       | Water Cycle Algorithm                           | WCA        | OriginalWCA      | 2012     | 5         | medium         |
-        | System       | Artificial Ecosystem-based Optimization         | AEO        | OriginalAEO      | 2019     | 2         | easy           |
-        | System       | -                                               | -          | EnhancedAEO      | 2020     | 2         | medium         |
-        | System       | -                                               | -          | ModifiedAEO      | 2020     | 2         | medium         |
-        | System       | -                                               | -          | ImprovedAEO      | 2021     | 2         | medium         |
-        | System       | -                                               | -          | AugmentedAEO     | 2022     | 2         | medium         |
-        | -            | -                                               | -          | -                | -        | -         | -              |
-        | Math         | Hill Climbing                                   | HC         | OriginalHC       | 1993     | 3         | easy           |
-        | Math         | -                                               | -          | SwarmHC          | -        | 3         | easy           |
-        | Math         | Cross-Entropy Method                            | CEM        | OriginalCEM      | 1997     | 4         | easy           |
-        | Math         | Sine Cosine Algorithm                           | SCA        | OriginalSCA      | 2016     | 2         | easy           |
-        | Math         | -                                               | -          | BaseSCA          | -        | 2         | easy           |
-        | Math         | Gradient-Based Optimizer                        | GBO        | OriginalGBO      | 2020     | 5         | medium         |
-        | Math         | Arithmetic Optimization Algorithm               | AOA        | OrginalAOA       | 2021     | 6         | easy           |
-        | Math         | Chaos Game Optimization                         | CGO        | OriginalCGO      | 2021     | 2         | easy           |
-        | Math         | Pareto-like Sequential Sampling                 | PSS        | OriginalPSS      | 2021     | 4         | medium         |
-        | Math         | weIghted meaN oF vectOrs                        | INFO       | OriginalINFO     | 2022     | 2         | medium         |
-        | Math         | RUNge Kutta optimizer                           | RUN        | OriginalRUN      | 2021     | 2         | hard           |
-        | Math         | Circle Search Algorithm                         | CircleSA   | OriginalCircleSA | 2022     | 3         | easy           |
-        | -            | -                                               | -          | -                | -        | -         | -              |
-        | Music        | Harmony Search                                  | HS         | OriginalHS       | 2001     | 4         | easy           |
-        | Music        | -                                               | -          | BaseHS           | -        | 4         | easy           |
-        
-        
-        
-        
-        
-        ### A
-        
-        * **ABC - Artificial Bee Colony**
-          * **OriginalABC**: Karaboga, D. (2005). An idea based on honey bee swarm for numerical optimization (Vol. 200, pp. 1-10). Technical report-tr06, Erciyes university, engineering faculty, computer engineering department.
-        
-        * **ACOR - Ant Colony Optimization**. 
-          * **OriginalACOR**: Socha, K., & Dorigo, M. (2008). Ant colony optimization for continuous domains. European journal of operational research, 185(3), 1155-1173.
-        
-        * **ALO - Ant Lion Optimizer** 
-          * **OriginalALO**: Mirjalili S (2015). âThe Ant Lion Optimizer.â Advances in Engineering Software, 83, 80-98. doi: [10.1016/j.advengsoft.2015.01.010](https://doi.org/10.1016/j.advengsoft.2015.01.010)
-          * **BaseALO**: The developed version
-        
-        * **AEO - Artificial Ecosystem-based Optimization** 
-          * **OriginalAEO**: Zhao, W., Wang, L., & Zhang, Z. (2019). Artificial ecosystem-based optimization: a novel nature-inspired meta-heuristic algorithm. Neural Computing and Applications, 1-43.
-          * **AugmentedAEO**: Van Thieu, N., Barma, S. D., Van Lam, T., Kisi, O., & Mahesha, A. (2022). Groundwater level modeling using Augmented Artificial Ecosystem Optimization. Journal of Hydrology, 129034.
-          * **ImprovedAEO**: Rizk-Allah, R. M., & El-Fergany, A. A. (2020). Artificial ecosystem optimizer for parameters identification of proton exchange membrane fuel cells model. International Journal of Hydrogen Energy.
-          * **EnhancedAEO**: Eid, A., Kamel, S., Korashy, A., & Khurshaid, T. (2020). An Enhanced Artificial Ecosystem-Based Optimization for Optimal Allocation of Multiple Distributed Generations. IEEE Access, 8, 178493-178513.
-          * **ModifiedAEO**: Menesy, A. S., Sultan, H. M., Korashy, A., Banakhr, F. A., Ashmawy, M. G., & Kamel, S. (2020). Effective parameter extraction of different polymer electrolyte membrane fuel cell stack models using a modified artificial ecosystem optimization algorithm. IEEE Access, 8, 31892-31909.
-          
-        * **ASO - Atom Search Optimization**   
-          * **OriginalASO**: Zhao, W., Wang, L., & Zhang, Z. (2019). Atom search optimization and its application to solve a hydrogeologic parameter estimation problem. Knowledge-Based Systems, 163, 283-304.
-        
-        * **ArchOA - Archimedes Optimization Algorithm**
-          * **OriginalArchOA**: Hashim, F. A., Hussain, K., Houssein, E. H., Mabrouk, M. S., & Al-Atabany, W. (2021). Archimedes optimization algorithm: a new metaheuristic algorithm for solving optimization problems. Applied Intelligence, 51(3), 1531-1551.
-        
-        * **AOA - Arithmetic Optimization Algorithm**
-          * **OriginalAOA**: Abualigah, L., Diabat, A., Mirjalili, S., Abd Elaziz, M., & Gandomi, A. H. (2021). The arithmetic optimization algorithm. Computer methods in applied mechanics and engineering, 376, 113609.
-        
-        * **AO - Aquila Optimizer**
-          * **OriginalAO**: Abualigah, L., Yousri, D., Abd Elaziz, M., Ewees, A. A., Al-qaness, M. A., & Gandomi, A. H. (2021). Aquila Optimizer: A novel meta-heuristic optimization Algorithm. Computers & Industrial Engineering, 157, 107250.
-        
-        * **AVOA - African Vultures Optimization Algorithm**
-          * **OriginalAVOA**: Abdollahzadeh, B., Gharehchopogh, F. S., & Mirjalili, S. (2021). African vultures optimization algorithm: A new nature-inspired metaheuristic algorithm for global optimization problems. Computers & Industrial Engineering, 158, 107408.
-        
-        * **AGTO - Artificial Gorilla Troops Optimization**
-          * **OriginalAGTO**: Abdollahzadeh, B., Soleimanian Gharehchopogh, F., & Mirjalili, S. (2021). Artificial gorilla troops optimizer: a new natureâinspired metaheuristic algorithm for global optimization problems. International Journal of Intelligent Systems, 36(10), 5887-5958.
-        
-        * **ARO - Artificial Rabbits Optimization**:
-          * **OriginalARO**: Wang, L., Cao, Q., Zhang, Z., Mirjalili, S., & Zhao, W. (2022). Artificial rabbits optimization: A new bio-inspired meta-heuristic algorithm for solving engineering optimization problems. Engineering Applications of Artificial Intelligence, 114, 105082.
-        
-        
-        
-        ### B
-        
-        
-        * **BFO - Bacterial Foraging Optimization** 
-          * **OriginalBFO**: Passino, K. M. (2002). Biomimicry of bacterial foraging for distributed optimization and control. IEEE control systems magazine, 22(3), 52-67.
-          * **ABFO**: Nguyen, T., Nguyen, B. M., & Nguyen, G. (2019, April). Building resource auto-scaler with functional-link neural network and adaptive bacterial foraging optimization. In International Conference on Theory and Applications of Models of Computation (pp. 501-517). Springer, Cham.
-        
-        * **BeesA - Bees Algorithm** 
-          * **OriginalBeesA**: Pham, D. T., Ghanbarzadeh, A., Koc, E., Otri, S., Rahim, S., & Zaidi, M. (2005). The bees algorithm. Technical Note, Manufacturing Engineering Centre, Cardiff University, UK.
-          * **ProbBeesA**: The probabilitic version of: Pham, D. T., Ghanbarzadeh, A., KoÃ§, E., Otri, S., Rahim, S., & Zaidi, M. (2006). The bees algorithmâa novel tool for complex optimisation problems. In Intelligent production machines and systems (pp. 454-459). Elsevier Science Ltd.
-          
-        * **BBO - Biogeography-Based Optimization** 
-          * **OriginalBBO**: Simon, D. (2008). Biogeography-based optimization. IEEE transactions on evolutionary computation, 12(6), 702-713.
-          * **BaseBBO**: The developed version
-          
-        * **BA - Bat Algorithm** 
-          * **OriginalBA**: Yang, X. S. (2010). A new metaheuristic bat-inspired algorithm. In Nature inspired cooperative strategies for optimization (NICSO 2010) (pp. 65-74). Springer, Berlin, Heidelberg.
-          * **AdaptiveBA**: Wang, X., Wang, W. and Wang, Y., 2013, July. An adaptive bat algorithm. In International Conference on Intelligent Computing(pp. 216-223). Springer, Berlin, Heidelberg.
-          * **ModifiedBA**: Dong, H., Li, T., Ding, R. and Sun, J., 2018. A novel hybrid genetic algorithm with granular information for feature selection and optimization. Applied Soft Computing, 65, pp.33-46.
-        
-        * **BSO - Brain Storm Optimization** 
-          * **OriginalBSO**: . Shi, Y. (2011, June). Brain storm optimization algorithm. In International conference in swarm intelligence (pp. 303-309). Springer, Berlin, Heidelberg.
-          * **ImprovedBSO**: El-Abd, M., 2017. Global-best brain storm optimization algorithm. Swarm and evolutionary computation, 37, pp.27-44.
-        
-        * **BSA - Bird Swarm Algorithm** 
-          * **OriginalBSA**: Meng, X. B., Gao, X. Z., Lu, L., Liu, Y., & Zhang, H. (2016). A new bio-inspired optimisation algorithm:Bird Swarm Algorithm. Journal of Experimental & Theoretical Artificial Intelligence, 28(4), 673-687.
-        
-        * **BMO - Barnacles Mating Optimizer**:
-          * **OriginalBMO**: Sulaiman, M. H., Mustaffa, Z., Saari, M. M., Daniyal, H., Daud, M. R., Razali, S., & Mohamed, A. I. (2018, June). Barnacles mating optimizer: a bio-inspired algorithm for solving optimization problems. In 2018 19th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD) (pp. 265-270). IEEE.
-        
-        * **BES - Bald Eagle Search** 
-          * **OriginalBES**: Alsattar, H. A., Zaidan, A. A., & Zaidan, B. B. (2019). Novel meta-heuristic bald eagle search optimisation algorithm. Artificial Intelligence Review, 1-28.
-          
-        * **BRO - Battle Royale Optimization**
-          * **OriginalBRO**: Rahkar Farshi, T. (2020). Battle royale optimization algorithm. Neural Computing and Applications, 1-19.
-          * **BaseBRO**: The developed version
-        
-        ### C
-        
-        * **CA - Culture Algorithm** 
-          * **OriginalCA**: Reynolds, R.G., 1994, February. An introduction to cultural algorithms. In Proceedings of the third annual conference on evolutionary programming (Vol. 24, pp. 131-139). River Edge, NJ: World Scientific.
-        
-        * **CEM - Cross Entropy Method**
-          * **OriginalCEM**: Rubinstein, R. (1999). The cross-entropy method for combinatorial and continuous optimization. Methodology and computing in applied probability, 1(2), 127-190.
-          
-        * **CSO - Cat Swarm Optimization** 
-          * **OriginalCSO**: Chu, S. C., Tsai, P. W., & Pan, J. S. (2006, August). Cat swarm optimization. In Pacific Rim international conference on artificial intelligence (pp. 854-858). Springer, Berlin, Heidelberg.
-        
-        * **CSA - Cuckoo Search Algorithm** 
-          * **OriginalCSA**: Yang, X. S., & Deb, S. (2009, December). Cuckoo search via LÃ©vy flights. In 2009 World congress on nature & biologically inspired computing (NaBIC) (pp. 210-214). Ieee.
-        
-        * **CRO - Coral Reefs Optimization** 
-          * **OriginalCRO**: Salcedo-Sanz, S., Del Ser, J., Landa-Torres, I., Gil-LÃ³pez, S., & Portilla-Figueras, J. A. (2014). The coral reefs optimization algorithm: a novel metaheuristic for efficiently solving optimization problems. The Scientific World Journal, 2014.
-          * **OCRO**: Nguyen, T., Nguyen, T., Nguyen, B. M., & Nguyen, G. (2019). Efficient time-series forecasting using neural network and opposition-based coral reefs optimization. International Journal of Computational Intelligence Systems, 12(2), 1144-1161.
-        
-        * **COA - Coyote Optimization Algorithm**
-          * **OriginalCOA**: Pierezan, J., & Coelho, L. D. S. (2018, July). Coyote optimization algorithm: a new metaheuristic for global optimization problems. In 2018 IEEE congress on evolutionary computation (CEC) (pp. 1-8). IEEE.
-        
-        * **CHIO - Coronavirus Herd Immunity Optimization**
-          * **OriginalCHIO**: Al-Betar, M. A., Alyasseri, Z. A. A., Awadallah, M. A., & Abu Doush, I. (2021). Coronavirus herd immunity optimizer (CHIO). Neural Computing and Applications, 33(10), 5011-5042.
-          * **BaseCHIO**: The developed version
-        
-        * **CGO - Chaos Game Optimization** 
-          * **OriginalCGO**: Talatahari, S., & Azizi, M. (2021). Chaos Game Optimization: a novel metaheuristic algorithm. Artificial Intelligence Review, 54(2), 917-1004.
-        
-        * **CSA - Circle Search Algorithm**
-          * **OriginalCSA**: Qais, M. H., Hasanien, H. M., Turky, R. A., Alghuwainem, S., Tostado-VÃ©liz, M., & Jurado, F. (2022). Circle Search Algorithm: A Geometry-Based Metaheuristic Optimization Algorithm. Mathematics, 10(10), 1626.
-        
-        ### D
-        
-        * **DE - Differential Evolution** 
-          * **BaseDE**: Storn, R., & Price, K. (1997). Differential evolutionâa simple and efficient heuristic for global optimization over continuous spaces. Journal of global optimization, 11(4), 341-359.
-          * **JADE**: Zhang, J., & Sanderson, A. C. (2009). JADE: adaptive differential evolution with optional external archive. IEEE Transactions on evolutionary computation, 13(5), 945-958.
-          * **SADE**: Qin, A. K., & Suganthan, P. N. (2005, September). Self-adaptive differential evolution algorithm for numerical optimization. In 2005 IEEE congress on evolutionary computation (Vol. 2, pp. 1785-1791). IEEE.
-          * **SHADE**: Tanabe, R., & Fukunaga, A. (2013, June). Success-history based parameter adaptation for differential evolution. In 2013 IEEE congress on evolutionary computation (pp. 71-78). IEEE.
-          * **L_SHADE**: Tanabe, R., & Fukunaga, A. S. (2014, July). Improving the search performance of SHADE using linear population size reduction. In 2014 IEEE congress on evolutionary computation (CEC) (pp. 1658-1665). IEEE.
-          * **SAP_DE**: Teo, J. (2006). Exploring dynamic self-adaptive populations in differential evolution. Soft Computing, 10(8), 673-686.
-          
-        * **DSA - Differential Search Algorithm (not done)** 
-          * **BaseDSA**: Civicioglu, P. (2012). Transforming geocentric cartesian coordinates to geodetic coordinates by using differential search algorithm. Computers & Geosciences, 46, 229-247.
-          
-        * **DO - Dragonfly Optimization** 
-          * **OriginalDO**: Mirjalili, S. (2016). Dragonfly algorithm: a new meta-heuristic optimization technique for solving single-objective, discrete, and multi-objective problems. Neural Computing and Applications, 27(4), 1053-1073.
-        
-        * **DMOA - Dwarf Mongoose Optimization Algorithm**
-          * **OriginalDMOA**: Agushaka, J. O., Ezugwu, A. E., & Abualigah, L. (2022). Dwarf mongoose optimization algorithm. Computer methods in applied mechanics and engineering, 391, 114570.
-          * **DevDMOA**: The developed version
-        
-        ### E
-        
-        * **ES - Evolution Strategies** . 
-          * **OriginalES**: Schwefel, H. P. (1984). Evolution strategies: A family of non-linear optimization techniques based on imitating some principles of organic evolution. Annals of Operations Research, 1(2), 165-167.
-          * **LevyES**: Zhang, S., & Salari, E. (2005). Competitive learning vector quantization with evolution strategies for image compression. Optical Engineering, 44(2), 027006.
-        
-        * **EP - Evolutionary programming** . 
-          * **OriginalEP**: Fogel, L. J. (1994). Evolutionary programming in perspective: The top-down view. Computational intelligence: Imitating life.
-          * **LevyEP**: Lee, C.Y. and Yao, X., 2001, May. Evolutionary algorithms with adaptive lÃ©vy mutations. In Proceedings of the 2001 congress on evolutionary computation (IEEE Cat. No. 01TH8546) (Vol. 1, pp. 568-575). IEEE.
-        
-        * **EHO - Elephant Herding Optimization** . 
-          * **OriginalEHO**: Wang, G. G., Deb, S., & Coelho, L. D. S. (2015, December). Elephant herding optimization. In 2015 3rd International Symposium on Computational and Business Intelligence (ISCBI) (pp. 1-5). IEEE.
-        
-        * **EFO - Electromagnetic Field Optimization** . 
-          * **OriginalEFO**:Abedinpourshotorban, H., Shamsuddin, S. M., Beheshti, Z., & Jawawi, D. N. (2016). Electromagnetic field optimization: A physics-inspired metaheuristic optimization algorithm. Swarm and Evolutionary Computation, 26, 8-22.
-          * **BaseEFO**: The developed version
-        
-        * **EOA - Earthworm Optimisation Algorithm** . 
-          * **OriginalEOA**: Wang, G. G., Deb, S., & dos Santos Coelho, L. (2018). Earthworm optimisation algorithm: a bio-inspired metaheuristic algorithm for global optimisation problems. IJBIC, 12(1), 1-22.
-        
-        * **EO - Equilibrium Optimizer** . 
-          * **OriginalEO**: Faramarzi, A., Heidarinejad, M., Stephens, B., & Mirjalili, S. (2019). Equilibrium optimizer: A novel optimization algorithm. Knowledge-Based Systems.
-          * **ModifiedEO**: Gupta, S., Deep, K., & Mirjalili, S. (2020). An efficient equilibrium optimizer with mutation strategy for numerical optimization. Applied Soft Computing, 96, 106542.
-          * **AdaptiveEO**: Wunnava, A., Naik, M. K., Panda, R., Jena, B., & Abraham, A. (2020). A novel interdependence based multilevel thresholding technique using adaptive equilibrium optimizer. Engineering Applications of Artificial Intelligence, 94, 103836.
-        
-        ### F
-        
-        * **FFA - Firefly Algorithm** 
-          * **OriginalFFA**: Åukasik, S., & Å»ak, S. (2009, October). Firefly algorithm for continuous constrained optimization tasks. In International conference on computational collective intelligence (pp. 97-106). Springer, Berlin, Heidelberg.
-          
-        * **FA - Fireworks algorithm** 
-          * **OriginalFA**: Tan, Y., & Zhu, Y. (2010, June). Fireworks algorithm for optimization. In International conference in swarm intelligence (pp. 355-364). Springer, Berlin, Heidelberg.
-        
-        * **FPA - Flower Pollination Algorithm** 
-          * **OriginalFPA**: Yang, X. S. (2012, September). Flower pollination algorithm for global optimization. In International conference on unconventional computing and natural computation (pp. 240-249). Springer, Berlin, Heidelberg.
-        
-        * **FOA - Fruit-fly Optimization Algorithm**
-          * **OriginalFOA**: Pan, W. T. (2012). A new fruit fly optimization algorithm: taking the financial distress model as an example. Knowledge-Based Systems, 26, 69-74.
-          * **BaseFOA**: The developed version
-          * **WhaleFOA**: Fan, Y., Wang, P., Heidari, A. A., Wang, M., Zhao, X., Chen, H., & Li, C. (2020). Boosted hunting-based fruit fly optimization and advances in real-world problems. Expert Systems with Applications, 159, 113502.
-        
-        * **FBIO - Forensic-Based Investigation Optimization** 
-          * **OriginalFBIO**: Chou, J.S. and Nguyen, N.M., 2020. FBI inspired meta-optimization. Applied Soft Computing, p.106339.
-          * **BaseFBIO**: Fathy, A., Rezk, H. and Alanazi, T.M., 2021. Recent approach of forensic-based investigation algorithm for optimizing fractional order PID-based MPPT with proton exchange membrane fuel cell.IEEE Access,9, pp.18974-18992.
-        
-        * **FHO - Fire Hawk Optimization**
-          * **OriginalFHO**: Azizi, M., Talatahari, S., & Gandomi, A. H. (2022). Fire Hawk Optimizer: a novel metaheuristic algorithm. Artificial Intelligence Review, 1-77.
-        
-        ### G
-        
-        * **GA - Genetic Algorithm** 
-          * **BaseGA**: Holland, J. H. (1992). Genetic algorithms. Scientific american, 267(1), 66-73.
-          * **SingleGA**: De Falco, I., Della Cioppa, A. and Tarantino, E., 2002. Mutation-based genetic algorithm: performance evaluation.Â Applied Soft Computing,Â 1(4), pp.285-299.
-          * **MultiGA**: De Jong, K.A. and Spears, W.M., 1992. A formal analysis of the role of multi-point crossover in genetic algorithms.Â Annals of mathematics and Artificial intelligence,Â 5(1), pp.1-26.
-          * **EliteSingleGA**: Elite version of Single-point mutation GA
-          * **EliteMultiGA**: Elite version of Multiple-point mutation GA
-        
-        * **GWO - Grey Wolf Optimizer** 
-          * **OriginalGWO**: Mirjalili, S., Mirjalili, S. M., & Lewis, A. (2014). Grey wolf optimizer. Advances in engineering software, 69, 46-61.
-          * **RW_GWO**: Gupta, S., & Deep, K. (2019). A novel random walk grey wolf optimizer. Swarm and evolutionary computation, 44, 101-112.
-          * **GWO_WOA**: Obadina, O. O., Thaha, M. A., Althoefer, K., & Shaheed, M. H. (2022). Dynamic characterization of a masterâslave robotic manipulator using a hybrid grey wolfâwhale optimization algorithm. Journal of Vibration and Control, 28(15-16), 1992-2003.
-        
-        * **GOA - Grasshopper Optimisation Algorithm** 
-          * **OriginalGOA**: Saremi, S., Mirjalili, S., & Lewis, A. (2017). Grasshopper optimisation algorithm: theory and application. Advances in Engineering Software, 105, 30-47.
-        
-        * **GCO - Germinal Center Optimization** 
-          * **OriginalGCO**: VillaseÃ±or, C., Arana-Daniel, N., Alanis, A. Y., LÃ³pez-Franco, C., & Hernandez-Vargas, E. A. (2018). Germinal center optimization algorithm. International Journal of Computational Intelligence Systems, 12(1), 13-27.
-          * **BaseGCO**: The developed version
-        
-        * **GSKA - Gaining Sharing Knowledge-based Algorithm** 
-          * **OriginalGSKA**: Mohamed, A. W., Hadi, A. A., & Mohamed, A. K. (2019). Gaining-sharing knowledge based algorithm for solving optimization problems: a novel nature-inspired algorithm. International Journal of Machine Learning and Cybernetics, 1-29.
-          * **BaseGSKA**: Mohamed, A.W., Hadi, A.A., Mohamed, A.K. and Awad, N.H., 2020, July. Evaluating the performance of adaptive GainingSharing knowledge based algorithm on CEC 2020 benchmark problems. InÂ 2020 IEEE Congress on Evolutionary Computation (CEC)Â (pp. 1-8). IEEE.
-        
-        * **GBO - Gradient-Based Optimizer**
-          * **OriginalGBO**: Ahmadianfar, I., Bozorg-Haddad, O., & Chu, X. (2020). Gradient-based optimizer: A new metaheuristic optimization algorithm. Information Sciences, 540, 131-159.
-        
-        ### H
-        
-        * **HC - Hill Climbing** . 
-          * **OriginalHC**: Talbi, E. G., & Muntean, T. (1993, January). Hill-climbing, simulated annealing and genetic algorithms: a comparative study and application to the mapping problem. In [1993] Proceedings of the Twenty-sixth Hawaii International Conference on System Sciences (Vol. 2, pp. 565-573). IEEE.
-          * **SwarmHC**: The developed version based on swarm-based idea (Original is single-solution based method)
-        
-        * **HS - Harmony Search** . 
-          * **OriginalHS**: Geem, Z. W., Kim, J. H., & Loganathan, G. V. (2001). A new heuristic optimization algorithm:harmony search. simulation, 76(2), 60-68.
-          * **BaseHS**: The developed version
-        
-        * **HHO - Harris Hawks Optimization** . 
-          * **OriginalHHO**: Heidari, A. A., Mirjalili, S., Faris, H., Aljarah, I., Mafarja, M., & Chen, H. (2019). Harris hawks optimization: Algorithm and applications. Future Generation Computer Systems, 97, 849-872.
-        
-        * **HGSO - Henry Gas Solubility Optimization** . 
-          * **OriginalHGSO**: Hashim, F. A., Houssein, E. H., Mabrouk, M. S., Al-Atabany, W., & Mirjalili, S. (2019). Henry gas solubility optimization: A novel physics-based algorithm. Future Generation Computer Systems, 101, 646-667.
-        
-        * **HGS - Hunger Games Search** . 
-          * **OriginalHGS**: Yang, Y., Chen, H., Heidari, A. A., & Gandomi, A. H. (2021). Hunger games search:Visions, conception, implementation, deep analysis, perspectives, and towards performance shifts. Expert Systems with Applications, 177, 114864.
-          
-        * **HHOA - Horse Herd Optimization Algorithm (not done)** . 
-          * **BaseHHOA**: MiarNaeimi, F., Azizyan, G., & Rashki, M. (2021). Horse herd optimization algorithm: A nature-inspired algorithm for high-dimensional optimization problems. Knowledge-Based Systems, 213, 106711.
-          
-        * **HBA - Honey Badger Algorithm**:
-          * **OriginalHBA**: Hashim, F. A., Houssein, E. H., Hussain, K., Mabrouk, M. S., & Al-Atabany, W. (2022). Honey Badger Algorithm: New metaheuristic algorithm for solving optimization problems. Mathematics and Computers in Simulation, 192, 84-110.
-        
-        
-        ### I
-        
-        * **IWO - Invasive Weed Optimization** . 
-          * **OriginalIWO**: Mehrabian, A. R., & Lucas, C. (2006). A novel numerical optimization algorithm inspired from weed colonization. Ecological informatics, 1(4), 355-366.
-        
-        * **ICA - Imperialist Competitive Algorithm** 
-          * **OriginalICA**: Atashpaz-Gargari, E., & Lucas, C. (2007, September). Imperialist competitive algorithm: an algorithm for optimization inspired by imperialistic competition. In 2007 IEEE congress on evolutionary computation (pp. 4661-4667). Ieee.
-        
-        * **INFO - weIghted meaN oF vectOrs**:
-          * **OriginalINFO**: Ahmadianfar, I., Heidari, A. A., Gandomi, A. H., Chu, X., & Chen, H. (2021). RUN beyond the metaphor: An efficient     optimization algorithm based on Runge Kutta method. Expert Systems with Applications, 181, 115079.
-        
-        ### J
-        
-        * **JA - Jaya Algorithm** 
-          * **OriginalJA**: Rao, R. (2016). Jaya: A simple and new optimization algorithm for solving constrained and unconstrained optimization problems. International Journal of Industrial Engineering Computations, 7(1), 19-34.
-          * **BaseJA**: The developed version
-          * **LevyJA**: Iacca, G., dos Santos Junior, V. C., & de Melo, V. V. (2021). An improved Jaya optimization algorithm with Levy flight. Expert Systems with Applications, 165, 113902.
-        
-        ### K
-        
-        ### L
-        
-        * **LCO - Life Choice-based Optimization** 
-          * **OriginalLCO**: Khatri, A., Gaba, A., Rana, K. P. S., & Kumar, V. (2019). A novel life choice-based optimizer. Soft Computing, 1-21.
-          * **BaseLCO**: The developed version
-          * **ImprovedLCO**: The improved version using Gaussian distribution and Mutation Mechanism
-        
-        
-        ### M
-        
-        * **MA - Memetic Algorithm**
-          * **OriginalMA**: Moscato, P. (1989). On evolution, search, optimization, genetic algorithms and martial arts: Towards memetic algorithms. Caltech concurrent computation program, C3P Report, 826, 1989.
-        
-        * **MFO - Moth Flame Optimization** 
-          * **OriginalMFO**: Mirjalili, S. (2015). Moth-flame optimization algorithm: A novel nature-inspired heuristic paradigm. Knowledge-based systems, 89, 228-249.
-          * **BaseMFO**: The developed version
-        
-        * **MVO - Multi-Verse Optimizer** 
-          * **OriginalMVO**: Mirjalili, S., Mirjalili, S. M., & Hatamlou, A. (2016). Multi-verse optimizer: a nature-inspired algorithm for global optimization. Neural Computing and Applications, 27(2), 495-513.
-          * **BaseMVO**: The developed version
-        
-        * **MSA - Moth Search Algorithm** 
-          * **OriginalMSA**: Wang, G. G. (2018). Moth search algorithm: a bio-inspired metaheuristic algorithm for global optimization problems. Memetic Computing, 10(2), 151-164.
-          
-        * **MRFO - Manta Ray Foraging Optimization** 
-          * **OriginalMRFO**: Zhao, W., Zhang, Z., & Wang, L. (2020). Manta ray foraging optimization: An effective bio-inspired optimizer for engineering applications. Engineering Applications of Artificial Intelligence, 87, 103300.
-        
-        * **MPA - Marine Predators Algorithm**:
-          * **OriginalMPA**: Faramarzi, A., Heidarinejad, M., Mirjalili, S., & Gandomi, A. H. (2020). Marine Predators Algorithm: A nature-inspired metaheuristic. Expert systems with applications, 152, 113377.
-        
-        
-        ### N
-        
-        
-        * **NRO - Nuclear Reaction Optimization** 
-          * **OriginalNRO**: Wei, Z., Huang, C., Wang, X., Han, T., & Li, Y. (2019). Nuclear Reaction Optimization: A novel and powerful physics-based algorithm for global optimization. IEEE Access. 
-        
-        * **NMRA - Nake Mole-Rat Algorithm**
-          * **OriginalNMRA**: Salgotra, R., & Singh, U. (2019). The naked mole-rat algorithm. Neural Computing and Applications, 31(12), 8837-8857.
-          * **ImprovedNMRA**: Singh, P., Mittal, N., Singh, U. and Salgotra, R., 2021. Naked mole-rat algorithm with improved exploration and exploitation capabilities to determine 2D and 3D coordinates of sensor nodes in WSNs.Â Arabian Journal for Science and Engineering,Â 46(2), pp.1155-1178.
-        
-        
-        ### O
-        
-        ### P
-        
-        * **PSO - Particle Swarm Optimization** 
-          * **OriginalPSO**: Eberhart, R., & Kennedy, J. (1995, October). A new optimizer using particle swarm theory. In MHS'95. Proceedings of the Sixth International Symposium on Micro Machine and Human Science (pp. 39-43). Ieee.
-          * **PPSO**: Ghasemi, M., Akbari, E., Rahimnejad, A., Razavi, S. E., Ghavidel, S., & Li, L. (2019). Phasor particle swarm optimization: a simple and efficient variant of PSO. Soft Computing, 23(19), 9701-9718.
-          * **HPSO_TVAC**: Ghasemi, M., Aghaei, J., & Hadipour, M. (2017). New self-organising hierarchical PSO with jumping time-varying acceleration coefficients. Electronics Letters, 53(20), 1360-1362.
-          * **C_PSO**: Liu, B., Wang, L., Jin, Y. H., Tang, F., & Huang, D. X. (2005). Improved particle swarm optimization combined with chaos. Chaos, Solitons & Fractals, 25(5), 1261-1271.
-          * **CL_PSO**: Liang, J. J., Qin, A. K., Suganthan, P. N., & Baskar, S. (2006). Comprehensive learning particle swarm optimizer for global optimization of multimodal functions. IEEE transactions on evolutionary computation, 10(3), 281-295.
-        
-        * **PFA - Pathfinder Algorithm** 
-          * **OriginalPFA**: Yapici, H., & Cetinkaya, N. (2019). A new meta-heuristic optimizer: Pathfinder algorithm. Applied Soft Computing, 78, 545-568.
-        
-        * **PSS - Pareto-like Sequential Sampling**
-          * **OriginalPSS**: Shaqfa, M., & Beyer, K. (2021). Pareto-like sequential sampling heuristic for global optimisation. Soft Computing, 25(14), 9077-9096.
-        
-        
-        ### Q
-        
-        * **QSA - Queuing Search Algorithm** 
-          * **OriginalQSA**: Zhang, J., Xiao, M., Gao, L., & Pan, Q. (2018). Queuing search algorithm: A novel metaheuristic algorithm for solving engineering optimization problems. Applied Mathematical Modelling, 63, 464-490.
-          * **BaseQSA**: The developed version
-          * **OppoQSA**: Zheng, X. and Nguyen, H., 2022. A novel artificial intelligent model for predicting water treatment efficiency of various biochar systems based on artificial neural network and queuing search algorithm. Chemosphere, 287, p.132251.
-          * **LevyQSA**: Abderazek, H., Hamza, F., Yildiz, A.R., Gao, L. and Sait, S.M., 2021. A comparative analysis of the queuing search algorithm, the sine-cosine algorithm, the ant lion algorithm to determine the optimal weight design problem of a spur gear drive system. Materials Testing, 63(5), pp.442-447.
-          * **ImprovedQSA**: Nguyen, B.M., Hoang, B., Nguyen, T. and Nguyen, G., 2021. nQSV-Net: a novel queuing search variant for global space search and workload modeling.Â Journal of Ambient Intelligence and Humanized Computing,Â 12(1), pp.27-46.
-        
-        ### R
-        
-        * **RUN - RUNge Kutta optimizer**:
-          * **OriginalRUN**: Ahmadianfar, I., Heidari, A. A., Gandomi, A. H., Chu, X., & Chen, H. (2021). RUN beyond the metaphor: An efficient optimization algorithm based on Runge Kutta method. Expert Systems with Applications, 181, 115079.
-        
-        ### S
-        
-        * **SA - Simulated Annealling** 
-          * **OriginalSA**: . Van Laarhoven, P. J., & Aarts, E. H. (1987). Simulated annealing. In Simulated annealing: Theory and applications (pp. 7-15). Springer, Dordrecht.
-        
-        * **SSpiderO - Social Spider Optimization** 
-          * **OriginalSSpiderO**: Cuevas, E., Cienfuegos, M., ZaldÃ­Var, D., & PÃ©rez-Cisneros, M. (2013). A swarm optimization algorithm inspired in the behavior of the social-spider. Expert Systems with Applications, 40(16), 6374-6384.
-        
-        * **SOS - Symbiotic Organisms Search**:
-          * **OriginalSOS**: Cheng, M. Y., & Prayogo, D. (2014). Symbiotic organisms search: a new metaheuristic optimization algorithm. Computers & Structures, 139, 98-112.
-        
-        * **SSpiderA - Social Spider Algorithm** 
-          * **OriginalSSpiderA**: James, J. Q., & Li, V. O. (2015). A social spider algorithm for global optimization. Applied Soft Computing, 30, 614-627.
-        
-        * **SCA - Sine Cosine Algorithm** 
-          * **OriginalSCA**: Mirjalili, S. (2016). SCA: a sine cosine algorithm for solving optimization problems. Knowledge-Based Systems, 96, 120-133.
-          * **BaseSCA**: Attia, A.F., El Sehiemy, R.A. and Hasanien, H.M., 2018. Optimal power flow solution in power systems using a novel Sine-Cosine algorithm.Â International Journal of Electrical Power & Energy Systems,Â 99, pp.331-343.
-        
-        * **SRSR - Swarm Robotics Search And Rescue** 
-          * **OriginalSRSR**: Bakhshipour, M., Ghadi, M. J., & Namdari, F. (2017). Swarm robotics search & rescue: A novel artificial intelligence-inspired optimization approach. Applied Soft Computing, 57, 708-726.
-        
-        * **SBO - Satin Bowerbird Optimizer** 
-          * **OriginalSBO**: Moosavi, S. H. S., & Bardsiri, V. K. (2017). Satin bowerbird optimizer: a new optimization algorithm to optimize ANFIS for software development effort estimation. Engineering Applications of Artificial Intelligence, 60, 1-15.
-          * **BaseSBO**: The developed version
-        
-        * **SHO - Spotted Hyena Optimizer**
-          * **OriginalSHO**: Dhiman, G., & Kumar, V. (2017). Spotted hyena optimizer: a novel bio-inspired based metaheuristic technique for engineering applications. Advances in Engineering Software, 114, 48-70.
-        
-        * **SSO - Salp Swarm Optimization**
-          * **OriginalSSO**: Mirjalili, S., Gandomi, A. H., Mirjalili, S. Z., Saremi, S., Faris, H., & Mirjalili, S. M. (2017). Salp Swarm Algorithm: A bio-inspired optimizer for engineering design problems. Advances in Engineering Software, 114, 163-191.
-        
-        * **SFO - Sailfish Optimizer** 
-          * **OriginalSFO**: Shadravan, S., Naji, H. R., & Bardsiri, V. K. (2019). The Sailfish Optimizer: A novel nature-inspired metaheuristic algorithm for solving constrained engineering optimization problems. Engineering Applications of Artificial Intelligence, 80, 20-34.
-          * **ImprovedSFO**: Li, L.L., Shen, Q., Tseng, M.L. and Luo, S., 2021. Power system hybrid dynamic economic emission dispatch with wind energy based on improved sailfish algorithm.Â Journal of Cleaner Production,Â 316, p.128318.
-        
-        * **SARO - Search And Rescue Optimization** 
-          * **OriginalSARO**: Shabani, A., Asgarian, B., Gharebaghi, S. A., Salido, M. A., & Giret, A. (2019). A New Optimization Algorithm Based on Search and Rescue Operations. Mathematical Problems in Engineering, 2019.
-          * **BaseSARO**: The developed version using Levy-flight
-        
-        * **SSDO - Social Ski-Driver Optimization** 
-          * **OriginalSSDO**: Tharwat, A., & Gabel, T. (2019). Parameters optimization of support vector machines for imbalanced data using social ski driver algorithm. Neural Computing and Applications, 1-14.
-        
-        * **SLO - Sea Lion Optimization**
-          * **OriginalSLO**: Masadeh, R., Mahafzah, B. A., & Sharieh, A. (2019). Sea Lion Optimization Algorithm. Sea, 10(5).
-          * **ImprovedSLO**: The developed version
-          * **ModifiedSLO**: Masadeh, R., Alsharman, N., Sharieh, A., Mahafzah, B.A. and Abdulrahman, A., 2021. Task scheduling on cloud computing based on sea lion optimization algorithm.Â International Journal of Web Information Systems.
-        
-        * **Seagull Optimization Algorithm**
-          * **OriginalSOA**: Dhiman, G., & Kumar, V. (2019). Seagull optimization algorithm: Theory and its applications for large-scale industrial engineering problems. Knowledge-based systems, 165, 169-196.
-          * **DevSOA**: The developed version
-        
-        * **SMA - Slime Mould Algorithm**
-          * **OriginalSMA**: Li, S., Chen, H., Wang, M., Heidari, A. A., & Mirjalili, S. (2020). Slime mould algorithm: A new method for stochastic optimization. Future Generation Computer Systems.
-          * **BaseSMA**: The developed version
-        
-        * **SSA - Sparrow Search Algorithm** 
-          * **OriginalSSA**: Jiankai Xue & Bo Shen (2020) A novel swarm intelligence optimization approach: sparrow search algorithm, Systems Science & Control Engineering, 8:1, 22-34, DOI: 10.1080/21642583.2019.1708830
-          * **BaseSSA**: The developed version
-        
-        * **SPBO - Student Psychology Based Optimization**
-          * **OriginalSPBO**: Das, B., Mukherjee, V., & Das, D. (2020). Student psychology based optimization algorithm: A new population based optimization algorithm for solving optimization problems. Advances in Engineering software, 146, 102804.
-          * **DevSPBO**: The developed version
-        
-        * **SCSO - Sand Cat Swarm Optimization**
-          * **OriginalSCSO**: Seyyedabbasi, A., & Kiani, F. (2022). Sand Cat swarm optimization: a nature-inspired algorithm to solve global optimization problems. Engineering with Computers, 1-25.
-        
-        ### T
-        
-        * **TLO - Teaching Learning Optimization** 
-          * **OriginalTLO**: Rao, R. V., Savsani, V. J., & Vakharia, D. P. (2011). Teachingâlearning-based optimization: a novel method for constrained mechanical design optimization problems. Computer-Aided Design, 43(3), 303-315.
-          * **BaseTLO**: Rao, R., & Patel, V. (2012). An elitist teaching-learning-based optimization algorithm for solving complex constrained optimization problems. International Journal of Industrial Engineering Computations, 3(4), 535-560.
-          * **ImprovedTLO**: Rao, R. V., & Patel, V. (2013). An improved teaching-learning-based optimization algorithm for solving unconstrained optimization problems. Scientia Iranica, 20(3), 710-720.
-        
-        * **TWO - Tug of War Optimization** 
-          * **OriginalTWO**: Kaveh, A., & Zolghadr, A. (2016). A novel meta-heuristic algorithm: tug of war optimization. Iran University of Science & Technology, 6(4), 469-492.
-          * **OppoTWO**: Kaveh, A., Almasi, P. and Khodagholi, A., 2022. Optimum Design of Castellated Beams Using Four Recently Developed Meta-heuristic Algorithms.Â Iranian Journal of Science and Technology, Transactions of Civil Engineering, pp.1-13.
-          * **LevyTWO**: The developed version using Levy-flight
-          * **ImprovedTWO**: Nguyen, T., Hoang, B., Nguyen, G., & Nguyen, B. M. (2020). A new workload prediction model using extreme learning machine and enhanced tug of war optimization. Procedia Computer Science, 170, 362-369.
-        
-        * **TSA - Tunicate Swarm Algorithm**
-          * **OriginalTSA**: Kaur, S., Awasthi, L. K., Sangal, A. L., & Dhiman, G. (2020). Tunicate Swarm Algorithm: A new bio-inspired based metaheuristic paradigm for global optimization. Engineering Applications of Artificial Intelligence, 90, 103541.
-        
-        * **TSO - Tuna Swarm Optimization**
-          * **OriginalTSO**: Xie, L., Han, T., Zhou, H., Zhang, Z. R., Han, B., & Tang, A. (2021). Tuna swarm optimization: a novel swarm-based metaheuristic algorithm for global optimization. Computational intelligence and Neuroscience, 2021.
-        
-        
-        ### U
-        
-        ### V
-        
-        * **VCS - Virus Colony Search** 
-          * **OriginalVCS**: Li, M. D., Zhao, H., Weng, X. W., & Han, T. (2016). A novel nature-inspired algorithm for optimization: Virus colony search. Advances in Engineering Software, 92, 65-88.
-          * **BaseVCS**: The developed version
-        
-        ### W
-        
-        * **WCA - Water Cycle Algorithm** 
-          * **OriginalWCA**: Eskandar, H., Sadollah, A., Bahreininejad, A., & Hamdi, M. (2012). Water cycle algorithmâA novel metaheuristic optimization method for solving constrained engineering optimization problems. Computers & Structures, 110, 151-166.
-          
-        * **WOA - Whale Optimization Algorithm** 
-          * **OriginalWOA**: Mirjalili, S., & Lewis, A. (2016). The whale optimization algorithm. Advances in engineering software, 95, 51-67.
-          * **HI_WOA**: Tang, C., Sun, W., Wu, W., & Xue, M. (2019, July). A hybrid improved whale optimization algorithm. In 2019 IEEE 15th International Conference on Control and Automation (ICCA) (pp. 362-367). IEEE.
-        
-        * **WHO - Wildebeest Herd Optimization** 
-          * **OriginalWHO**: Amali, D., & Dinakaran, M. (2019). Wildebeest herd optimization: A new global optimization algorithm inspired by wildebeest herding behaviour. Journal of Intelligent & Fuzzy Systems, (Preprint), 1-14.
-        
-        * **WDO - Wind Driven Optimization** 
-          * **OriginalWDO**: Bayraktar, Z., Komurcu, M., Bossard, J.A. and Werner, D.H., 2013. The wind driven optimization technique and its application in electromagnetics. IEEE transactions on antennas and propagation, 61(5), pp.2745-2757.
-        
-        
-        ### X
-        
-        ### Y
-        
-        ### Z
-        
-Keywords: optimization,metaheuristics,MHA,mathematical optimization,nature-inspired algorithms,evolutionary computation,soft computing,population-based algorithms,Stochastic optimization,Global optimization,Convergence analysis,Search space exploration,Local search,Computational intelligence,Black-box optimization,Robust optimization,Hybrid algorithms,Benchmark functions,Metaheuristic design,Performance analysis,Exploration versus exploitation,Self-adaptation,Constrained optimization,Intelligent optimization,Adaptive search,Simulations,Algorithm selection
-Platform: UNKNOWN
-Classifier: Development Status :: 5 - Production/Stable
-Classifier: Intended Audience :: Developers
-Classifier: Intended Audience :: Education
-Classifier: Intended Audience :: Information Technology
-Classifier: Intended Audience :: Science/Research
-Classifier: License :: OSI Approved :: GNU General Public License v3 (GPLv3)
-Classifier: Natural Language :: English
-Classifier: Programming Language :: Python :: 3
-Classifier: Programming Language :: Python :: 3.7
-Classifier: Programming Language :: Python :: 3.8
-Classifier: Programming Language :: Python :: 3.9
-Classifier: Programming Language :: Python :: 3.10
-Classifier: Programming Language :: Python :: 3.11
-Classifier: Topic :: System :: Benchmark
-Classifier: Topic :: Scientific/Engineering
-Classifier: Topic :: Scientific/Engineering :: Mathematics
-Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
-Classifier: Topic :: Scientific/Engineering :: Information Analysis
-Classifier: Topic :: Scientific/Engineering :: Visualization
-Classifier: Topic :: Scientific/Engineering :: Bio-Informatics
-Classifier: Topic :: Software Development :: Build Tools
-Classifier: Topic :: Software Development :: Libraries
-Classifier: Topic :: Software Development :: Libraries :: Python Modules
-Classifier: Topic :: Utilities
-Requires-Python: >=3.7
-Description-Content-Type: text/markdown
-Provides-Extra: dev
+Metadata-Version: 2.1
+Name: mealpy
+Version: 2.5.3a1
+Summary: MEALPY: A Framework Of The State-Of-The-Art Meta-Heuristic Algorithms In Python
+Home-page: https://github.com/thieu1995/mealpy
+Author: Thieu
+Author-email: nguyenthieu2102@gmail.com
+License: GPLv3
+Project-URL: Documentation, https://mealpy.readthedocs.io/
+Project-URL: Source Code, https://github.com/thieu1995/mealpy
+Project-URL: Bug Tracker, https://github.com/thieu1995/mealpy/issues
+Project-URL: Change Log, https://github.com/thieu1995/mealpy/blob/master/ChangeLog.md
+Project-URL: Forum, https://t.me/+fRVCJGuGJg1mNDg1
+Keywords: optimization,metaheuristics,MHA,mathematical optimization,nature-inspired algorithms,evolutionary computation,soft computing,population-based algorithms,Stochastic optimization,Global optimization,Convergence analysis,Search space exploration,Local search,Computational intelligence,Black-box optimization,Robust optimization,Hybrid algorithms,Benchmark functions,Metaheuristic design,Performance analysis,Exploration versus exploitation,Self-adaptation,Constrained optimization,Intelligent optimization,Adaptive search,Simulations,Algorithm selection
+Classifier: Development Status :: 5 - Production/Stable
+Classifier: Intended Audience :: Developers
+Classifier: Intended Audience :: Education
+Classifier: Intended Audience :: Information Technology
+Classifier: Intended Audience :: Science/Research
+Classifier: License :: OSI Approved :: GNU General Public License v3 (GPLv3)
+Classifier: Natural Language :: English
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3.7
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3.9
+Classifier: Programming Language :: Python :: 3.10
+Classifier: Programming Language :: Python :: 3.11
+Classifier: Topic :: System :: Benchmark
+Classifier: Topic :: Scientific/Engineering
+Classifier: Topic :: Scientific/Engineering :: Mathematics
+Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
+Classifier: Topic :: Scientific/Engineering :: Information Analysis
+Classifier: Topic :: Scientific/Engineering :: Visualization
+Classifier: Topic :: Scientific/Engineering :: Bio-Informatics
+Classifier: Topic :: Software Development :: Build Tools
+Classifier: Topic :: Software Development :: Libraries
+Classifier: Topic :: Software Development :: Libraries :: Python Modules
+Classifier: Topic :: Utilities
+Requires-Python: >=3.7
+Description-Content-Type: text/markdown
+Provides-Extra: dev
+License-File: LICENSE
+
+
+<p align="center"><img src="https://thieu1995.github.io/post/2022-04/19-mealpy-tutorials/mealpy1.png" alt="MEALPY"/></p>
+
+---
+
+
+[![GitHub release](https://img.shields.io/badge/release-2.5.2-yellow.svg)](https://github.com/thieu1995/mealpy/releases)
+[![Wheel](https://img.shields.io/pypi/wheel/gensim.svg)](https://pypi.python.org/pypi/mealpy) 
+[![PyPI version](https://badge.fury.io/py/mealpy.svg)](https://badge.fury.io/py/mealpy)
+![PyPI - Python Version](https://img.shields.io/pypi/pyversions/mealpy.svg)
+![PyPI - Status](https://img.shields.io/pypi/status/mealpy.svg)
+![PyPI - Downloads](https://img.shields.io/pypi/dm/mealpy.svg)
+[![Downloads](https://pepy.tech/badge/mealpy)](https://pepy.tech/project/mealpy)
+[![Tests & Publishes to PyPI](https://github.com/thieu1995/mealpy/actions/workflows/publish-package.yaml/badge.svg)](https://github.com/thieu1995/mealpy/actions/workflows/publish-package.yaml)
+![GitHub Release Date](https://img.shields.io/github/release-date/thieu1995/mealpy.svg)
+[![Documentation Status](https://readthedocs.org/projects/mealpy/badge/?version=latest)](https://mealpy.readthedocs.io/en/latest/?badge=latest)
+[![Chat](https://img.shields.io/badge/Chat-on%20Telegram-blue)](https://t.me/+fRVCJGuGJg1mNDg1)
+[![Average time to resolve an issue](http://isitmaintained.com/badge/resolution/thieu1995/mealpy.svg)](http://isitmaintained.com/project/thieu1995/mealpy "Average time to resolve an issue")
+[![Percentage of issues still open](http://isitmaintained.com/badge/open/thieu1995/mealpy.svg)](http://isitmaintained.com/project/thieu1995/mealpy "Percentage of issues still open")
+![GitHub contributors](https://img.shields.io/github/contributors/thieu1995/mealpy.svg)
+[![GitTutorial](https://img.shields.io/badge/PR-Welcome-%23FF8300.svg?)](https://git-scm.com/book/en/v2/GitHub-Contributing-to-a-Project)
+[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3711948.svg)](https://doi.org/10.5281/zenodo.3711948)
+[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)
+
+
+MEALPY is the largest python library for most of the cutting-edge nature-inspired meta-heuristic algorithms (population-based). Population meta-heuristic algorithms (PMA) are the most popular algorithms in the field of 
+approximate optimization.
+
+* **Free software:** GNU General Public License (GPL) V3 license
+* **Total algorithms**: 172 (102 original, 45 official variants, 25 developed variants)
+* **Documentation:** https://mealpy.readthedocs.io/en/latest/
+* **Python versions:** 3.7.x, 3.8.x, 3.9.x, 3.10.x, 3.11.x
+* **Dependencies:** numpy, scipy, pandas, matplotlib
+
+
+# Goals
+
+Our goals are to implement all of the classical as well as the state-of-the-art nature-inspired algorithms, create a simple interface that helps researchers access optimization algorithms as quickly as possible, and share knowledge of the optimization field with everyone without a fee. What you can do with mealpy:
+
+- Analyse parameters of meta-heuristic algorithms.
+- Perform Qualitative and Quantitative Analysis of algorithms.
+- Analyse rate of convergence of algorithms.
+- Test and Analyse the scalability and the robustness of algorithms.
+- Save results in various formats (csv, json, pickle, png, pdf, jpeg)
+- Export and import models can also be done with Mealpy.
+
+
+
+# Installation
+
+### Install with pip
+Install the [current PyPI release](https://pypi.python.org/pypi/mealpy):
+```sh 
+$ pip install mealpy==2.5.2
+```
+
+### Install from source
+In case you want to install directly from the source code, use:
+```sh 
+$ git clone https://github.com/thieu1995/mealpy.git
+$ cd mealpy
+$ python setup.py install
+```
+
+
+# Usage
+
+After installation, you can import Mealpy as any other Python module:
+
+```sh
+$ python
+>>> import mealpy
+>>> mealpy.__version__
+```
+
+Let's go through a basic and advanced example.
+
+
+## Examples
+
+### Simple Benchmark Function
+
+```python 
+from mealpy.bio_based import SMA
+import numpy as np
+
+def fitness_function(solution):
+    return np.sum(solution**2)
+
+problem = {
+    "fit_func": fitness_function,
+    "lb": [-100, ] * 30,
+    "ub": [100, ] * 30,
+    "minmax": "min",
+    "log_to": None,
+    "save_population": False,
+}
+
+## Run the algorithm
+model = SMA.BaseSMA(epoch=100, pop_size=50, pr=0.03)
+best_position, best_fitness = model.solve(problem)
+print(f"Best solution: {best_position}, Best fitness: {best_fitness}")
+```
+
+### Constrained Benchmark Function
+* [The Constrained Benchmark Function](https://github.com/thieu1995/mealpy/tree/master/examples/applications/run_constraint_functions.py)
+
+
+### Multi-objective Benchmark Function
+* [Multi-objective benchmark functions](https://github.com/thieu1995/mealpy/tree/master/examples/applications/run_multi_objective_functions.py)
+
+
+### Custom Problem 
+
+For our custom problem, we can create a class and inherit from the Problem class, named the child class the  
+'Squared' class. In the initialization method of the 'Squared' class, we have to set the *lb*, *ub*, and *minmax*  
+of the problem (lb: a list of lower bound values, ub: a list of upper bound values, and minmax: a string specifying 
+whether the problem is a 'min' or 'max' problem). 
+
+Afterwards, we have to override the abstract method 'fit_func()', which takes a parameter 'solution' (the solution 
+to be evaluated) and returns the function value. The resulting code should look something like the code snippet 
+below. 'Name' is an additional parameter we want to include in this class, and you can include any other additional 
+parameters you need.
+
+
+```python 
+import numpy as np
+from mealpy.bio_based import BBO
+from mealpy.utils.problem import Problem
+
+# Our custom problem class
+class Squared(Problem):
+    def __init__(self, lb=(-5, -5, -5, -5, -5, -5), ub=(5, 5, 5, 5, 5, 5), minmax="min", name="Squared", **kwargs):
+        super().__init__(lb, ub, minmax, **kwargs)
+        self.name = name
+
+    def fit_func(self, solution):
+        return np.sum(solution ** 2)
+```
+
+Now, we define an algorithm, and pass an instance of our *Squared* class as the problem argument. 
+
+```python
+problem = Squared(lb=[-10] * 20, ub=[10] * 20, minmax="min")
+model = BBO.BaseBBO(epoch=10, pop_size=50)
+best_position, best_fitness = model.solve(problem)
+
+print(best_position)
+print(best_fitness)
+print(model.get_parameters())
+print(model.get_name())
+print(model.get_attributes()["solution"])
+print(model.problem.get_name())
+print(model.problem.n_dims)
+```
+
+
+### Tuner class (GridSearchCV/ParameterSearch, Hyper-parameter tuning)
+
+We build a dedicated class, Tuner, that can help you tune your algorithm's parameters.
+
+```python
+import numpy as np
+from mealpy.bio_based import BBO
+from mealpy.tuner import Tuner          # Remember this
+
+
+def fitness(solution):
+    return np.sum(solution**2)
+
+problem = {
+    "lb": [-100, ]*50,
+    "ub": [100, ]*50,
+    "minmax": "min",
+    "fit_func": fitness,
+    "name": "Squared Problem",
+    "log_to": None,
+}
+
+paras_bbo_grid = {
+    "epoch": [100],
+    "pop_size": [50],
+    "elites": [2, 3, 4, 5],
+    "p_m": [0.01, 0.02, 0.05, 0.1, 0.15, 0.2]
+}
+
+if __name__ == "__main__":
+    model = BBO.BaseBBO()
+
+    tuner = Tuner(model, paras_bbo_grid)
+    tuner.execute(problem=problem, n_trials=10, mode="parallel", n_workers=4)
+
+    print(tuner.best_score)
+    print(tuner.best_params)
+    print(tuner.best_algorithm)
+    print(tuner.best_algorithm.get_name())
+    
+    ## Save results to csv file 
+    tuner.export_results(save_path="history/tuning", save_as="csv")
+    
+    ## Re-solve the best model on your problem 
+    best_position, best_fitness = tuner.resolve()
+
+    print(best_position, best_fitness)
+    print(tuner.problem.get_name())
+```
+
+
+### Multitask class (Multitask solving)
+
+We also build a dedicated class, Multitask, that can help you run several scenarios. For example:
+
+1. Run 1 algorithm with 1 problem, and multiple trials
+2. Run 1 algorithm with multiple problems, and multiple trials
+3. Run multiple algorithms with 1 problem, and multiple trials
+4. Run multiple algorithms with multiple problems, and multiple trials
+
+
+```python
+#### Using multiple algorithm to solve multiple problems with multiple trials
+
+## Import libraries
+## For example, we want to solve F5, F10, F29 problem in CEC-2017
+from opfunu.cec_based.cec2017 import F52017, F102017, F292017
+
+from mealpy.bio_based import BBO
+from mealpy.evolutionary_based import DE
+from mealpy.multitask import Multitask          # Remember this
+
+
+## You can define your own problems
+
+f1 = F52017(30, f_bias=0)
+f2 = F102017(30, f_bias=0)
+f3 = F292017(30, f_bias=0)
+
+p1 = {
+    "lb": f1.lb.tolist(),
+    "ub": f1.ub.tolist(),
+    "minmax": "min",
+    "fit_func": f1.evaluate,
+    "name": "F5-CEC2017",
+    "log_to": None,
+}
+
+p2 = {
+    "lb": f2.lb.tolist(),
+    "ub": f2.ub.tolist(),
+    "minmax": "min",
+    "fit_func": f2.evaluate,
+    "name": "F10-CEC2017",
+    "log_to": None,
+}
+
+p3 = {
+    "lb": f3.lb.tolist(),
+    "ub": f3.ub.tolist(),
+    "minmax": "min",
+    "fit_func": f3.evaluate,
+    "name": "F29-CEC2017",
+    "log_to": None,
+}
+
+## Define models
+
+model1 = BBO.BaseBBO(epoch=10, pop_size=50)
+model2 = BBO.OriginalBBO(epoch=10, pop_size=50)
+model3 = DE.BaseDE(epoch=10, pop_size=50)
+
+
+## Define and run Multitask
+
+if __name__ == "__main__":
+    multitask = Multitask(algorithms=(model1, model2, model3), problems=(p1, p2, p3))
+    multitask.execute(n_trials=3, mode="parallel", n_workers=6, save_path="history", save_as="csv", save_convergence=True, verbose=True)
+    
+    ## Check the directory: history/, you will see list of .csv result files
+```
+
+For more usage examples please look at [examples](/examples) folder.
+
+More advanced examples can also be found in the [Mealpy-examples repository](https://github.com/thieu1995/mealpy_examples).
+
+
+### Get Visualize Figures
+
+
+* [Tutorials](/examples/utils/visualize/all_charts.py)
+
+<p align="center"><img src="https://thieu1995.github.io/post/2022-04/19-mealpy-tutorials/mealpy2.png" alt="MEALPY"/>
+</p>
+
+
+## Mealpy Application
+
+### Mealpy + Neural Network (Replace the Gradient Descent Optimizer)
+
+* Time-series Problem:
+  * Traditional MLP
+    code: [Link](https://github.com/thieu1995/mealpy/tree/master/examples/applications/keras/traditional-mlp-time-series.py)
+  * Hybrid code (Mealpy +
+    MLP): [Link](https://github.com/thieu1995/mealpy/tree/master/examples/applications/keras/mha-hybrid-mlp-time-series.py)
+* Classification Problem:
+  * Traditional MLP
+    code: [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/keras/traditional-mlp-classification.py)
+  * Hybrid code (Mealpy +
+    MLP): [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/keras/mha-hybrid-mlp-classification.py)
+
+### Mealpy + Neural Network (Optimize Neural Network Hyper-parameter)
+
+Code: [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/keras/mha-hyper-parameter-mlp-time-series.py)
+
+### Other Applications
+
+* Solving Knapsack Problem (Discrete
+  problems): [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/discrete-problems/knapsack-problem.py)
+
+* Optimize SVM (SVC)
+  model: [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/sklearn/svm_classification.py)
+
+* Optimize Linear Regression
+  Model: [Link](https://github.com/thieu1995/mealpy/blob/master/examples/applications/pytorch/linear_regression.py)
+
+* Travelling Salesman Problem: https://github.com/thieu1995/MHA-TSP 
+
+* Feature selection problem: https://github.com/thieu1995/MHA-FS
+
+
+
+## Tutorial Videos
+
+All tutorial videos: [Link](https://mealpy.readthedocs.io/en/latest/pages/general/video_tutorials.html)
+
+All code examples: [Link](https://github.com/thieu1995/mealpy/tree/master/examples)
+
+All visualization examples: [Link](https://mealpy.readthedocs.io/en/latest/pages/visualization.html)
+
+
+
+### Get helps (questions, problems)
+
+* Official source code repo: https://github.com/thieu1995/mealpy
+* Official document: https://mealpy.readthedocs.io/
+* Download releases: https://pypi.org/project/mealpy/
+* Issue tracker: https://github.com/thieu1995/mealpy/issues
+* Notable changes log: https://github.com/thieu1995/mealpy/blob/master/ChangeLog.md
+* Examples with different meapy version: https://github.com/thieu1995/mealpy/blob/master/EXAMPLES.md
+
+* This project also related to our another projects which are "meta-heuristics" and "neural-network", check it here
+    * https://github.com/thieu1995/opfunu
+    * https://github.com/thieu1995/metaheuristics
+    * https://github.com/aiir-team
+
+**Want to have an instant assistant? Join our telegram community at [link](https://t.me/+fRVCJGuGJg1mNDg1)**
+We share lots of information, questions, and answers there. You will get more support and knowledge there.
+
+### Cite Us
+
+If you are using mealpy in your project, we would appreciate citations:
+
+```bibtex 
+@software{nguyen_van_thieu_2022_6684223,
+  author       = {Nguyen Van Thieu and Seyedali Mirjalili},
+  title        = {{MEALPY: a Framework of The State-of-The-Art Meta-Heuristic Algorithms in Python}},
+  month        = jun,
+  year         = 2022,
+  publisher    = {Zenodo},
+  version      = {v2.4.2},
+  doi          = {10.5281/zenodo.6684223},
+  url          = {https://doi.org/10.5281/zenodo.6684223}
+}
+
+@article{van2023groundwater,
+  title={Groundwater level modeling using Augmented Artificial Ecosystem Optimization},
+  author={Van Thieu, Nguyen and Barma, Surajit Deb and Van Lam, To and Kisi, Ozgur and Mahesha, Amai},
+  journal={Journal of Hydrology},
+  volume={617},
+  pages={129034},
+  year={2023},
+  publisher={Elsevier}
+}
+```
+
+
+
+# List of papers used MEALPY
+
+- Min, J., Oh, M., Kim, W., Seo, H., & Paek, J. (2022, October). Evaluation of Metaheuristic Algorithms for TAS Scheduling in Time-Sensitive Networking. In 2022 13th International Conference on Information and Communication Technology Convergence (ICTC) (pp. 809-812). IEEE.
+- Khozeimeh, F., Sharifrazi, D., Izadi, N. H., Joloudari, J. H., Shoeibi, A., Alizadehsani, R., ... & Islam, S. M. S. (2021). Combining a convolutional neural network with autoencoders to predict the survival chance of COVID-19 patients. Scientific Reports, 11(1), 15343.
+- Rajesh, K., Jain, E., & Kotecha, P. (2022). A Multi-Objective approach to the Electric Vehicle Routing Problem. arXiv preprint arXiv:2208.12440.
+- SÃ¡nchez, A. J. H., & Upegui, F. R. (2022). Una herramienta para el diseÃ±o de redes MSMN de banda ancha en lÃ­neas de transmisiÃ³n basada en algoritmos heurÃ­sticos de optimizaciÃ³n comparados. Revista IngenierÃ­a UC, 29(2), 106-123.
+- Khanmohammadi, M., Armaghani, D. J., & Sabri Sabri, M. M. (2022). Prediction and Optimization of Pile Bearing Capacity Considering Effects of Time. Mathematics, 10(19), 3563.
+- Kudela, J. (2023). The Evolutionary Computation Methods No One Should Use. arXiv preprint arXiv:2301.01984.
+- Vieira, M., Faia, R., Pinto, T., & Vale, Z. (2022, September). Schedule Peer-to-Peer Transactions of an Energy Community Using Particle Swarm. In 2022 18th International Conference on the European Energy Market (EEM) (pp. 1-6). IEEE.
+- Bui, X. N., Nguyen, H., Le, Q. T., & Le, T. N. Forecasting PM. MINING SCIENCE ANDTECHNOLOGY (Russia), 111.
+- Bui, X. N., Nguyen, H., Le, Q. T., & Le, T. N. (2022). Forecasting PM 2.5 emissions in open-pit minesusing a functional link neural network optimized by various optimization algorithms. Gornye nauki i tekhnologii= Mining Science and Technology (Russia), 7(2), 111-125.
+- DoÄan, E., & YÃ¶rÃ¼keren, N. (2022). Enhancement of Transmission System Security with Archimedes Optimization Algorithm.
+- Ayub, N., Aurangzeb, K., Awais, M., & Ali, U. (2020, November). Electricity theft detection using CNN-GRU and manta ray foraging optimization algorithm. In 2020 IEEE 23Rd international multitopic conference (INMIC) (pp. 1-6). IEEE.
+- Pintilie, L., Nechita, M. T., Suditu, G. D., Dafinescu, V., & DrÄgoi, E. N. (2022). Photo-decolorization of Eriochrome Black T: process optimization with Differential Evolution algorithm. In PASEW-22, MESSH-22 & CABES-22 April 19â21, 2022 Paris (France). Eminent Association of Pioneers.
+- LaTorre, A., Molina, D., Osaba, E., Poyatos, J., Del Ser, J., & Herrera, F. (2021). A prescription of methodological guidelines for comparing bio-inspired optimization algorithms. Swarm and Evolutionary Computation, 67, 100973.
+- Gottam, S., Nanda, S. J., & Maddila, R. K. (2021, December). A CNN-LSTM Model Trained with Grey Wolf Optimizer for Prediction of Household Power Consumption. In 2021 IEEE International Symposium on Smart Electronic Systems (iSES)(Formerly iNiS) (pp. 355-360). IEEE.
+- Darius, P. S., Devadason, J., & Solomon, D. G. (2022, December). Prospects of Ant Colony Optimization (ACO) in Various Domains. In 2022 4th International Conference on Circuits, Control, Communication and Computing (I4C) (pp. 79-84). IEEE.
+- Ayub, N., Irfan, M., Awais, M., Ali, U., Ali, T., Hamdi, M., ... & Muhammad, F. (2020). Big data analytics for short and medium-term electricity load forecasting using an AI techniques ensembler. Energies, 13(19), 5193.
+- Biundini, I. Z., Melo, A. G., Coelho, F. O., HonÃ³rio, L. M., Marcato, A. L., & Pinto, M. F. (2022). Experimentation and Simulation with Autonomous Coverage Path Planning for UAVs. Journal of Intelligent & Robotic Systems, 105(2), 46.
+- Yousaf, I., Anwar, F., Imtiaz, S., Almadhor, A. S., Ishmanov, F., & Kim, S. W. (2022). An Optimized Hyperparameter of Convolutional Neural Network Algorithm for Bug Severity Prediction in Alzheimerâs-Based IoT System. Computational Intelligence and Neuroscience, 2022.
+- Xu, L., Yan, W., & Ji, J. (2023). The research of a novel WOG-YOLO algorithm for autonomous driving object detection. Scientific reports, 13(1), 3699.
+- Costache, R. D., Arabameri, A., Islam, A. R. M. T., Abba, S. I., Pandey, M., Ajin, R. S., & Pham, B. T. (2022). Flood susceptibility computation using state-of-the-art machine learning and optimization algorithms.
+- Del Ser, J., Osaba, E., Martinez, A. D., Bilbao, M. N., Poyatos, J., Molina, D., & Herrera, F. (2021, December). More is not always better: insights from a massive comparison of meta-heuristic algorithms over real-parameter optimization problems. In 2021 IEEE Symposium Series on Computational Intelligence (SSCI) (pp. 1-7). IEEE.
+- Rustam, F., Aslam, N., De La Torre DÃ­ez, I., Khan, Y. D., MazÃ³n, J. L. V., RodrÃ­guez, C. L., & Ashraf, I. (2022, November). White Blood Cell Classification Using Texture and RGB Features of Oversampled Microscopic Images. In Healthcare (Vol. 10, No. 11, p. 2230). MDPI.
+- Neupane, D., Kafle, S., Gurung, S., Neupane, S., & Bhattarai, N. (2021). Optimal sizing and financial analysis of a stand-alone SPV-micro-hydropower hybrid system considering generation uncertainty. International Journal of Low-Carbon Technologies, 16(4), 1479-1491.
+- Liang, R., Le-Hung, T., & Nguyen-Thoi, T. (2022). Energy consumption prediction of air-conditioning systems in eco-buildings using hunger games search optimization-based artificial neural network model. Journal of Building Engineering, 59, 105087.
+- He, Z., Nguyen, H., Vu, T. H., Zhou, J., Asteris, P. G., & Mammou, A. (2022). Novel integrated approaches for predicting the compressibility of clay using cascade forward neural networks optimized by swarm-and evolution-based algorithms. Acta Geotechnica, 1-16.
+- Xu, L., Yan, W., & Ji, J. (2022). The research of a novel WOG-YOLO algorithm forautonomous driving object detection.
+- Nasir Ayub, M. I., Awais, M., Ali, U., Ali, T., Hamdi, M., Alghamdi, A., & Muhammad, F. Big Data Analytics for Short and Medium Term Electricity Load Forecasting using AI Techniques Ensembler.
+- Xie, C., Nguyen, H., Choi, Y., & Armaghani, D. J. (2022). Optimized functional linked neural network for predicting diaphragm wall deflection induced by braced excavations in clays. Geoscience Frontiers, 13(2), 101313.
+- Hakemi, S., Houshmand, M., & Hosseini, S. A. (2022). A Dynamic Quantum-Inspired Genetic Algorithm with Lengthening Chromosome Size.
+- Kashifi, M. T. City-Wide Crash Risk Prediction and Interpretation Using Deep Learning Model with Multi-Source Big Data. Available at SSRN 4329686.
+- Nguyen, H., & Hoang, N. D. (2022). Computer vision-based classification of concrete spall severity using metaheuristic-optimized Extreme Gradient Boosting Machine and Deep Convolutional Neural Network. Automation in Construction, 140, 104371.
+- Zheng, J., Lu, Z., Wu, K., Ning, G. H., & Li, D. (2020). Coinage-metal-based cyclic trinuclear complexes with metalâmetal interactions: Theories to experiments and structures to functions. Chemical Reviews, 120(17), 9675-9742.
+- Van Thieu, N., Barma, S. D., Van Lam, T., Kisi, O., & Mahesha, A. (2023). Groundwater level modeling using Augmented Artificial Ecosystem Optimization. Journal of Hydrology, 617, 129034.
+- Mo, Z., Zhang, Z., Miao, Q., & Tsui, K. L. (2022). Intelligent Informative Frequency Band Searching Assisted by a Dynamic Bandit Tree Method for Machine Fault Diagnosis. IEEE/ASME Transactions on Mechatronics.
+- Dangi, D., Chandel, S. T., Dixit, D. K., Sharma, S., & Bhagat, A. (2023). An Efficient Model for Sentiment Analysis using Artificial Rabbits Optimized Vector Functional Link Network. Expert Systems with Applications, 119849.
+- Dey, S., Roychoudhury, R., Malakar, S., & Sarkar, R. (2022). An optimized fuzzy ensemble of convolutional neural networks for detecting tuberculosis from Chest X-ray images. Applied Soft Computing, 114, 108094.
+- Mousavirad, S. J., & Alexandre, L. A. (2022). Population-based JPEG Image Compression: Problem Re-Formulation. arXiv preprint arXiv:2212.06313.
+- Tsui, K. L. Intelligent Informative Frequency Band Searching Assisted by A Dynamic Bandit Tree Method for Machine Fault Diagnosis.
+- Neupane, D. (2020). Optimal Sizing and Performance Analysis of Solar PV-Micro hydropower Hybrid System in the Context of Rural Area of Nepal (Doctoral dissertation, Pulchowk Campus).
+- LaTorre, A., Molina, D., Osaba, E., Poyatos, J., Del Ser, J., & Herrera, F. Swarm and Evolutionary Computation.
+- Vieira, M. A. (2022). OtimizaÃ§Ã£o dos custos operacionais de uma comunidade energÃ©tica considerando transaÃ§Ãµes locais em âpeer-to-peerâ (Doctoral dissertation).
+- ToÄaÃ§ar, M. (2022). Using DarkNet models and metaheuristic optimization methods together to detect weeds growing along with seedlings. Ecological Informatics, 68, 101519.
+- ToÄaÃ§ar, M. (2021). Detection of segmented uterine cancer images by Hotspot Detection method using deep learning models, Pigeon-Inspired Optimization, types-based dominant activation selection approaches. Computers in Biology and Medicine, 136, 104659.
+- Khan, N. A Short Term Electricity Load and Price Forecasting Model Based on BAT Algorithm in Logistic Regression and CNN-GRU with WOA.
+- Yelisetti, S., Saini, V. K., Kumar, R., & Lamba, R. (2022, May). Energy Consumption Cost Benefits through Smart Home Energy Management in Residential Buildings: An Indian Case Study. In 2022 IEEE IAS Global Conference on Emerging Technologies (GlobConET) (pp. 930-935). IEEE.
+- Nguyen, H., Cao, M. T., Tran, X. L., Tran, T. H., & Hoang, N. D. (2022). A novel whale optimization algorithm optimized XGBoost regression for estimating bearing capacity of concrete piles. Neural Computing and Applications, 1-28.
+- Hirsching, C., de Jongh, S., Eser, D., Suriyah, M., & Leibfried, T. (2022). Meta-heuristic optimization of control structure and design for MMC-HVdc applications. Electric Power Systems Research, 213, 108371.
+- Amelin, V., Gatiyatullin, E., Romanov, N., Samarkhanov, R., Vasilyev, R., & Yanovich, Y. (2022). Black-Box for Blockchain Parameters Adjustment. IEEE Access, 10, 101795-101802.
+- Ngo, T. Q., Nguyen, L. Q., & Tran, V. Q. (2022). Novel hybrid machine learning models including support vector machine with meta-heuristic algorithms in predicting unconfined compressive strength of organic soils stabilised with cement and lime. International Journal of Pavement Engineering, 1-18.
+- Zhu, Y., & Iiduka, H. (2021). Unified Algorithm Framework for Nonconvex Stochastic Optimization in Deep Neural Networks. IEEE Access, 9, 143807-143823.
+- Hakemi, S., Houshmand, M., KheirKhah, E., & Hosseini, S. A. (2022). A review of recent advances in quantum-inspired metaheuristics. Evolutionary Intelligence, 1-16.
+- Das, A., Das, S. R., Panda, J. P., Dey, A., Gajrani, K. K., Somani, N., & Gupta, N. (2022). Machine learning based modelling and optimization in hard turning of AISI D6 steel with newly developed AlTiSiN coated carbide tool. arXiv preprint arXiv:2202.00596.
+- Yelisetti, S., Saini, V. K., Kumar, R., Lamba, R., & Saxena, A. (2022). Optimal energy management system for residential buildings considering the time of use price with swarm intelligence algorithms. Journal of Building Engineering, 59, 105062.
+- ValdÃ©s, G. T. (2022). Algoritmo para la detecciÃ³n de vehÃ­culos y peatones combinando CNNÂ´ sy tÃ©cnicas de bÃºsqueda.
+- Sallam, N. M., Saleh, A. I., Ali, H. A., & Abdelsalam, M. M. (2023). An efficient EGWO algorithm as feature selection for B-ALL diagnoses and its subtypes classification using peripheral blood smear images. Alexandria Engineering Journal, 68, 39-66.
+
+
+
+
+# Documents
+
+* Meta-heuristic Categories: (Based on this article: [link](https://doi.org/10.1016/j.procs.2020.09.075))
+    + Evolutionary-based: Idea from Darwin's law of natural selection, evolutionary computing 
+    + Swarm-based: Idea from movement, interaction of birds, organization of social ...
+    + Physics-based: Idea from physics law such as Newton's law of universal gravitation, black hole, multiverse 
+    + Human-based: Idea from human interaction such as queuing search, teaching learning, ... 
+    + Biology-based: Idea from biology creature (or microorganism),...
+    + System-based: Idea from eco-system, immune-system, network-system, ...
+    + Math-based: Idea from mathematical form or mathematical law such as sin-cosin 
+    + Music-based: Idea from music instrument
+
+* Difficulty - Difficulty Level (Personal Opinion): Objective observation from author. Depend on the number of 
+  parameters, number of equations, the original ideas, time spend for coding, source lines of code (SLOC).
+    + Easy: A few paras, few equations, SLOC very short
+    + Medium: more equations than Easy level, SLOC longer than Easy level
+    + Hard: Lots of equations, SLOC longer than Medium level, the paper hard to read.
+    + Hard* - Very hard: Lots of equations, SLOC too long, the paper is very hard to read.
+    
+** For newbie, we recommend to read the paper of algorithms which difficulty is "easy" or "medium" difficulty level.
+
+
+| **Group**    | **Name**                                        | **Module** | **Class**        | **Year** | **Paras** | **Difficulty** |
+|--------------|-------------------------------------------------|------------|------------------|----------|-----------|----------------|
+| Evolutionary | Evolutionary Programming                        | EP         | OriginalEP       | 1964     | 3         | easy           |
+| Evolutionary | -                                               | -          | LevyEP           | -        | 3         | easy           |
+| Evolutionary | Evolution Strategies                            | ES         | OriginalES       | 1971     | 3         | easy           |
+| Evolutionary | -                                               | -          | LevyES           | -        | 3         | easy           |
+| Evolutionary | Memetic Algorithm                               | MA         | OriginalMA       | 1989     | 7         | easy           |
+| Evolutionary | Genetic Algorithm                               | GA         | BaseGA           | 1992     | 4         | easy           |
+| Evolutionary | -                                               | -          | SingleGA         | -        | 7         | easy           |
+| Evolutionary | -                                               | -          | MultiGA          | -        | 7         | easy           |
+| Evolutionary | -                                               | -          | EliteSingleGA    | -        | 10        | easy           |
+| Evolutionary | -                                               | -          | EliteMultiGA     | -        | 10        | easy           |
+| Evolutionary | Differential Evolution                          | DE         | BaseDE           | 1997     | 5         | easy           |
+| Evolutionary | -                                               | -          | JADE             | 2009     | 6         | medium         |
+| Evolutionary | -                                               | -          | SADE             | 2005     | 2         | medium         |
+| Evolutionary | -                                               | -          | SHADE            | 2013     | 4         | medium         |
+| Evolutionary | -                                               | -          | L_SHADE          | 2014     | 4         | medium         |
+| Evolutionary | -                                               | -          | SAP_DE           | 2006     | 3         | medium         |
+| Evolutionary | Flower Pollination Algorithm                    | FPA        | OriginalFPA      | 2014     | 4         | medium         |
+| Evolutionary | Coral Reefs Optimization                        | CRO        | OriginalCRO      | 2014     | 11        | medium         |
+| Evolutionary | -                                               | -          | OCRO             | 2019     | 12        | medium         |
+| -            | -                                               | -          | -                | -        | -         | -              |
+| Swarm        | Particle Swarm Optimization                     | PSO        | OriginalPSO      | 1995     | 6         | easy           |
+| Swarm        | -                                               | -          | PPSO             | 2019     | 2         | medium         |
+| Swarm        | -                                               | -          | HPSO_TVAC        | 2017     | 4         | medium         |
+| Swarm        | -                                               | -          | C_PSO            | 2015     | 6         | medium         |
+| Swarm        | -                                               | -          | CL_PSO           | 2006     | 6         | medium         |
+| Swarm        | Bacterial Foraging Optimization                 | BFO        | OriginalBFO      | 2002     | 10        | hard           |
+| Swarm        | -                                               | -          | ABFO             | 2019     | 8         | medium         |
+| Swarm        | Bees Algorithm                                  | BeesA      | OriginalBeesA    | 2005     | 8         | medium         |
+| Swarm        | -                                               | -          | ProbBeesA        | 2015     | 5         | medium         |
+| Swarm        | Cat Swarm Optimization                          | CSO        | OriginalCSO      | 2006     | 11        | hard           |
+| Swarm        | Artificial Bee Colony                           | ABC        | OriginalABC      | 2007     | 8         | medium         |
+| Swarm        | Ant Colony Optimization                         | ACO-R      | OriginalACOR     | 2008     | 5         | easy           |
+| Swarm        | Cuckoo Search Algorithm                         | CSA        | OriginalCSA      | 2009     | 3         | medium         |
+| Swarm        | Firefly Algorithm                               | FFA        | OriginalFFA      | 2009     | 8         | easy           |
+| Swarm        | Fireworks Algorithm                             | FA         | OriginalFA       | 2010     | 7         | medium         |
+| Swarm        | Bat Algorithm                                   | BA         | OriginalBA       | 2010     | 6         | medium         |
+| Swarm        | -                                               | -          | AdaptiveBA       | -        | 8         | medium         |
+| Swarm        | -                                               | -          | ModifiedBA       | -        | 5         | medium         |
+| Swarm        | Fruit-fly Optimization Algorithm                | FOA        | OriginalFOA      | 2012     | 2         | easy           |
+| Swarm        | -                                               | -          | BaseFOA          | -        | 2         | easy           |
+| Swarm        | -                                               | -          | WhaleFOA         | 2020     | 2         | medium         |
+| Swarm        | Social Spider Optimization                      | SSpiderO   | OriginalSSpiderO | 2018     | 4         | hard*          |
+| Swarm        | Grey Wolf Optimizer                             | GWO        | OriginalGWO      | 2014     | 2         | easy           |
+| Swarm        | -                                               | -          | RW_GWO           | 2019     | 2         | easy           |
+| Swarm        | Social Spider Algorithm                         | SSpiderA   | OriginalSSpiderA | 2015     | 5         | medium         |
+| Swarm        | Ant Lion Optimizer                              | ALO        | OriginalALO      | 2015     | 2         | easy           |
+| Swarm        | -                                               | -          | BaseALO          | -        | 2         | easy           |
+| Swarm        | Moth Flame Optimization                         | MFO        | OriginalMFO      | 2015     | 2         | easy           |
+| Swarm        | -                                               | -          | BaseMFO          | -        | 2         | easy           |
+| Swarm        | Elephant Herding Optimization                   | EHO        | OriginalEHO      | 2015     | 5         | easy           |
+| Swarm        | Jaya Algorithm                                  | JA         | OriginalJA       | 2016     | 2         | easy           |
+| Swarm        | -                                               | -          | BaseJA           | -        | 2         | easy           |
+| Swarm        | -                                               | -          | LevyJA           | 2021     | 2         | easy           |
+| Swarm        | Whale Optimization Algorithm                    | WOA        | OriginalWOA      | 2016     | 2         | medium         |
+| Swarm        | -                                               | -          | HI_WOA           | 2019     | 3         | medium         |
+| Swarm        | Dragonfly Optimization                          | DO         | OriginalDO       | 2016     | 2         | medium         |
+| Swarm        | Bird Swarm Algorithm                            | BSA        | OriginalBSA      | 2016     | 9         | medium         |
+| Swarm        | Spotted Hyena Optimizer                         | SHO        | OriginalSHO      | 2017     | 4         | medium         |
+| Swarm        | Salp Swarm Optimization                         | SSO        | OriginalSSO      | 2017     | 2         | easy           |
+| Swarm        | Swarm Robotics Search And Rescue                | SRSR       | OriginalSRSR     | 2017     | 2         | hard*          |
+| Swarm        | Grasshopper Optimisation Algorithm              | GOA        | OriginalGOA      | 2017     | 4         | easy           |
+| Swarm        | Coyote Optimization Algorithm                   | COA        | OriginalCOA      | 2018     | 3         | medium         |
+| Swarm        | Moth Search Algorithm                           | MSA        | OriginalMSA      | 2018     | 5         | easy           |
+| Swarm        | Sea Lion Optimization                           | SLO        | OriginalSLO      | 2019     | 2         | medium         |
+| Swarm        | -                                               | -          | ModifiedSLO      | -        | 2         | medium         |
+| Swarm        | -                                               | -          | ImprovedSLO      | -        | 4         | medium         |
+| Swarm        | Nake Mole-Rat Algorithm                         | NMRA       | OriginalNMRA     | 2019     | 3         | easy           |
+| Swarm        | -                                               | -          | ImprovedNMRA     | -        | 4         | medium         |
+| Swarm        | Pathfinder Algorithm                            | PFA        | OriginalPFA      | 2019     | 2         | medium         |
+| Swarm        | Sailfish Optimizer                              | SFO        | OriginalSFO      | 2019     | 5         | easy           |
+| Swarm        | -                                               | -          | ImprovedSFO      | -        | 3         | medium         |
+| Swarm        | Harris Hawks Optimization                       | HHO        | OriginalHHO      | 2019     | 2         | medium         |
+| Swarm        | Manta Ray Foraging Optimization                 | MRFO       | OriginalMRFO     | 2020     | 3         | medium         |
+| Swarm        | Bald Eagle Search                               | BES        | OriginalBES      | 2020     | 7         | easy           |
+| Swarm        | Sparrow Search Algorithm                        | SSA        | OriginalSSA      | 2020     | 5         | medium         |
+| Swarm        | -                                               | -          | BaseSSA          | -        | 5         | medium         |
+| Swarm        | Hunger Games Search                             | HGS        | OriginalHGS      | 2021     | 4         | medium         |
+| Swarm        | Aquila Optimizer                                | AO         | OriginalAO       | 2021     | 2         | easy           |
+| Swarm        | Hybrid Grey Wolf - Whale Optimization Algorithm | GWO        | GWO_WOA          | 2022     | 2         | easy           |
+| Swarm        | Marine Predators Algorithm                      | MPA        | OriginalMPA      | 2020     | 2         | medium         |
+| Swarm        | Honey Badger Algorithm                          | HBA        | OriginalHBA      | 2022     | 2         | easy           |
+| Swarm        | Sand Cat Swarm Optimization                     | SCSO       | OriginalSCSO     | 2022     | 2         | easy           |
+| Swarm        | Tuna Swarm Optimization                         | TSO        | OriginalTSO      | 2021     | 2         | medium         |
+| Swarm        | African Vultures Optimization Algorithm         | AVOA       | OriginalAVOA     | 2022     | 7         | medium         |
+| Swarm        | Artificial Gorilla Troops Optimization          | AGTO       | OriginalAGTO     | 2021     | 5         | medium         |
+| Swarm        | Artificial Rabbits Optimization                 | ARO        | OriginalARO      | 2022     | 2         | easy           |
+| Swarm        | Dwarf Mongoose Optimization Algorithm           | DMOA       | OriginalDMOA     | 2022     | 4         | medium         |
+| Swarm        | -                                               | -          | DevDMOA          | -        | 3         | medium         |
+| -            | -                                               | -          | -                | -        | -         | -              |
+| Physics      | Simulated Annealling                            | SA         | OriginalSA       | 1987     | 9         | medium         |
+| Physics      | Wind Driven Optimization                        | WDO        | OriginalWDO      | 2013     | 7         | easy           |
+| Physics      | Multi-Verse Optimizer                           | MVO        | OriginalMVO      | 2016     | 4         | easy           |
+| Physics      | -                                               | -          | BaseMVO          | -        | 4         | easy           |
+| Physics      | Tug of War Optimization                         | TWO        | OriginalTWO      | 2016     | 2         | easy           |
+| Physics      | -                                               | -          | OppoTWO          | -        | 2         | medium         |
+| Physics      | -                                               | -          | LevyTWO          | -        | 2         | medium         |
+| Physics      | -                                               | -          | EnhancedTWO      | 2020     | 2         | medium         |
+| Physics      | Electromagnetic Field Optimization              | EFO        | OriginalEFO      | 2016     | 6         | easy           |
+| Physics      | -                                               | -          | BaseEFO          | -        | 6         | medium         |
+| Physics      | Nuclear Reaction Optimization                   | NRO        | OriginalNRO      | 2019     | 2         | hard*          |
+| Physics      | Henry Gas Solubility Optimization               | HGSO       | OriginalHGSO     | 2019     | 3         | medium         |
+| Physics      | Atom Search Optimization                        | ASO        | OriginalASO      | 2019     | 4         | medium         |
+| Physics      | Equilibrium Optimizer                           | EO         | OriginalEO       | 2019     | 2         | easy           |
+| Physics      | -                                               | -          | ModifiedEO       | 2020     | 2         | medium         |
+| Physics      | -                                               | -          | AdaptiveEO       | 2020     | 2         | medium         |
+| Physics      | Archimedes Optimization Algorithm               | ArchOA     | OriginalArchOA   | 2021     | 8         | medium         |
+| -            | -                                               | -          | -                | -        | -         | -              |
+| Human        | Culture Algorithm                               | CA         | OriginalCA       | 1994     | 3         | easy           |
+| Human        | Imperialist Competitive Algorithm               | ICA        | OriginalICA      | 2007     | 8         | hard*          |
+| Human        | Teaching Learning-based Optimization            | TLO        | OriginalTLO      | 2011     | 2         | easy           |
+| Human        | -                                               | -          | BaseTLO          | 2012     | 2         | easy           |
+| Human        | -                                               | -          | ITLO             | 2013     | 3         | medium         |
+| Human        | Brain Storm Optimization                        | BSO        | OriginalBSO      | 2011     | 8         | medium         |
+| Human        | -                                               | -          | ImprovedBSO      | 2017     | 7         | medium         |
+| Human        | Queuing Search Algorithm                        | QSA        | OriginalQSA      | 2019     | 2         | hard           |
+| Human        | -                                               | -          | BaseQSA          | -        | 2         | hard           |
+| Human        | -                                               | -          | OppoQSA          | -        | 2         | hard           |
+| Human        | -                                               | -          | LevyQSA          | -        | 2         | hard           |
+| Human        | -                                               | -          | ImprovedQSA      | 2021     | 2         | hard           |
+| Human        | Search And Rescue Optimization                  | SARO       | OriginalSARO     | 2019     | 4         | medium         |
+| Human        | -                                               | -          | BaseSARO         | -        | 4         | medium         |
+| Human        | Life Choice-Based Optimization                  | LCO        | OriginalLCO      | 2019     | 3         | easy           |
+| Human        | -                                               | -          | BaseLCO          | -        | 3         | easy           |
+| Human        | -                                               | -          | ImprovedLCO      | -        | 2         | easy           |
+| Human        | Social Ski-Driver Optimization                  | SSDO       | OriginalSSDO     | 2019     | 2         | easy           |
+| Human        | Gaining Sharing Knowledge-based Algorithm       | GSKA       | OriginalGSKA     | 2019     | 6         | medium         |
+| Human        | -                                               | -          | BaseGSKA         | -        | 4         | medium         |
+| Human        | Coronavirus Herd Immunity Optimization          | CHIO       | OriginalCHIO     | 2020     | 4         | medium         |
+| Human        | -                                               | -          | BaseCHIO         | -        | 4         | medium         |
+| Human        | Forensic-Based Investigation Optimization       | FBIO       | OriginalFBIO     | 2020     | 2         | medium         |
+| Human        | -                                               | -          | BaseFBIO         | -        | 2         | medium         |
+| Human        | Battle Royale Optimization                      | BRO        | OriginalBRO      | 2020     | 3         | medium         |
+| Human        | -                                               | -          | BaseBRO          | -        | 3         | medium         |
+| Human        | Student Psychology Based Optimization           | SPBO       | OriginalSPBO     | 2020     | 2         | medium         |
+| Human        | -                                               | -          | DevSPBO          |          | 2         | medium         |
+| -            | -                                               | -          | -                | -        | -         | -              |
+| Bio          | Invasive Weed Optimization                      | IWO        | OriginalIWO      | 2006     | 7         | easy           |
+| Bio          | Biogeography-Based Optimization                 | BBO        | OriginalBBO      | 2008     | 4         | easy           |
+| Bio          | -                                               | -          | BaseBBO          | -        | 4         | easy           |
+| Bio          | Virus Colony Search                             | VCS        | OriginalVCS      | 2016     | 4         | hard*          |
+| Bio          | -                                               | -          | BaseVCS          | -        | 4         | hard*          |
+| Bio          | Satin Bowerbird Optimizer                       | SBO        | OriginalSBO      | 2017     | 5         | easy           |
+| Bio          | -                                               | -          | BaseSBO          | -        | 5         | easy           |
+| Bio          | Earthworm Optimisation Algorithm                | EOA        | OriginalEOA      | 2018     | 8         | medium         |
+| Bio          | Wildebeest Herd Optimization                    | WHO        | OriginalWHO      | 2019     | 12        | hard           |
+| Bio          | Slime Mould Algorithm                           | SMA        | OriginalSMA      | 2020     | 3         | easy           |
+| Bio          | -                                               | -          | BaseSMA          | -        | 3         | easy           |
+| Bio          | Barnacles Mating Optimizer                      | BMO        | OriginalBMO      | 2018     | 3         | easy           |
+| Bio          | Tunicate Swarm Algorithm                        | TSA        | OriginalTSA      | 2020     | 2         | easy           |
+| Bio          | Symbiotic Organisms Search                      | SOS        | OriginalSOS      | 2014     | 2         | medium         |
+| Bio          | Seagull Optimization Algorithm                  | SOA        | OriginalSOA      | 2019     | 3         | easy           |
+| Bio          | -                                               | -          | DevSOA           | -        | 3         | easy           |
+| -            | -                                               | -          | -                | -        | -         | -              |
+| System       | Germinal Center Optimization                    | GCO        | OriginalGCO      | 2018     | 4         | medium         |
+| System       | -                                               | -          | BaseGCO          | -        | 4         | medium         |
+| System       | Water Cycle Algorithm                           | WCA        | OriginalWCA      | 2012     | 5         | medium         |
+| System       | Artificial Ecosystem-based Optimization         | AEO        | OriginalAEO      | 2019     | 2         | easy           |
+| System       | -                                               | -          | EnhancedAEO      | 2020     | 2         | medium         |
+| System       | -                                               | -          | ModifiedAEO      | 2020     | 2         | medium         |
+| System       | -                                               | -          | ImprovedAEO      | 2021     | 2         | medium         |
+| System       | -                                               | -          | AugmentedAEO     | 2022     | 2         | medium         |
+| -            | -                                               | -          | -                | -        | -         | -              |
+| Math         | Hill Climbing                                   | HC         | OriginalHC       | 1993     | 3         | easy           |
+| Math         | -                                               | -          | SwarmHC          | -        | 3         | easy           |
+| Math         | Cross-Entropy Method                            | CEM        | OriginalCEM      | 1997     | 4         | easy           |
+| Math         | Sine Cosine Algorithm                           | SCA        | OriginalSCA      | 2016     | 2         | easy           |
+| Math         | -                                               | -          | BaseSCA          | -        | 2         | easy           |
+| Math         | Gradient-Based Optimizer                        | GBO        | OriginalGBO      | 2020     | 5         | medium         |
+| Math         | Arithmetic Optimization Algorithm               | AOA        | OrginalAOA       | 2021     | 6         | easy           |
+| Math         | Chaos Game Optimization                         | CGO        | OriginalCGO      | 2021     | 2         | easy           |
+| Math         | Pareto-like Sequential Sampling                 | PSS        | OriginalPSS      | 2021     | 4         | medium         |
+| Math         | weIghted meaN oF vectOrs                        | INFO       | OriginalINFO     | 2022     | 2         | medium         |
+| Math         | RUNge Kutta optimizer                           | RUN        | OriginalRUN      | 2021     | 2         | hard           |
+| Math         | Circle Search Algorithm                         | CircleSA   | OriginalCircleSA | 2022     | 3         | easy           |
+| -            | -                                               | -          | -                | -        | -         | -              |
+| Music        | Harmony Search                                  | HS         | OriginalHS       | 2001     | 4         | easy           |
+| Music        | -                                               | -          | BaseHS           | -        | 4         | easy           |
+
+
+
+
+
+### A
+
+* **ABC - Artificial Bee Colony**
+  * **OriginalABC**: Karaboga, D. (2005). An idea based on honey bee swarm for numerical optimization (Vol. 200, pp. 1-10). Technical report-tr06, Erciyes university, engineering faculty, computer engineering department.
+
+* **ACOR - Ant Colony Optimization**. 
+  * **OriginalACOR**: Socha, K., & Dorigo, M. (2008). Ant colony optimization for continuous domains. European journal of operational research, 185(3), 1155-1173.
+
+* **ALO - Ant Lion Optimizer** 
+  * **OriginalALO**: Mirjalili S (2015). âThe Ant Lion Optimizer.â Advances in Engineering Software, 83, 80-98. doi: [10.1016/j.advengsoft.2015.01.010](https://doi.org/10.1016/j.advengsoft.2015.01.010)
+  * **BaseALO**: The developed version
+
+* **AEO - Artificial Ecosystem-based Optimization** 
+  * **OriginalAEO**: Zhao, W., Wang, L., & Zhang, Z. (2019). Artificial ecosystem-based optimization: a novel nature-inspired meta-heuristic algorithm. Neural Computing and Applications, 1-43.
+  * **AugmentedAEO**: Van Thieu, N., Barma, S. D., Van Lam, T., Kisi, O., & Mahesha, A. (2022). Groundwater level modeling using Augmented Artificial Ecosystem Optimization. Journal of Hydrology, 129034.
+  * **ImprovedAEO**: Rizk-Allah, R. M., & El-Fergany, A. A. (2020). Artificial ecosystem optimizer for parameters identification of proton exchange membrane fuel cells model. International Journal of Hydrogen Energy.
+  * **EnhancedAEO**: Eid, A., Kamel, S., Korashy, A., & Khurshaid, T. (2020). An Enhanced Artificial Ecosystem-Based Optimization for Optimal Allocation of Multiple Distributed Generations. IEEE Access, 8, 178493-178513.
+  * **ModifiedAEO**: Menesy, A. S., Sultan, H. M., Korashy, A., Banakhr, F. A., Ashmawy, M. G., & Kamel, S. (2020). Effective parameter extraction of different polymer electrolyte membrane fuel cell stack models using a modified artificial ecosystem optimization algorithm. IEEE Access, 8, 31892-31909.
+  
+* **ASO - Atom Search Optimization**   
+  * **OriginalASO**: Zhao, W., Wang, L., & Zhang, Z. (2019). Atom search optimization and its application to solve a hydrogeologic parameter estimation problem. Knowledge-Based Systems, 163, 283-304.
+
+* **ArchOA - Archimedes Optimization Algorithm**
+  * **OriginalArchOA**: Hashim, F. A., Hussain, K., Houssein, E. H., Mabrouk, M. S., & Al-Atabany, W. (2021). Archimedes optimization algorithm: a new metaheuristic algorithm for solving optimization problems. Applied Intelligence, 51(3), 1531-1551.
+
+* **AOA - Arithmetic Optimization Algorithm**
+  * **OriginalAOA**: Abualigah, L., Diabat, A., Mirjalili, S., Abd Elaziz, M., & Gandomi, A. H. (2021). The arithmetic optimization algorithm. Computer methods in applied mechanics and engineering, 376, 113609.
+
+* **AO - Aquila Optimizer**
+  * **OriginalAO**: Abualigah, L., Yousri, D., Abd Elaziz, M., Ewees, A. A., Al-qaness, M. A., & Gandomi, A. H. (2021). Aquila Optimizer: A novel meta-heuristic optimization Algorithm. Computers & Industrial Engineering, 157, 107250.
+
+* **AVOA - African Vultures Optimization Algorithm**
+  * **OriginalAVOA**: Abdollahzadeh, B., Gharehchopogh, F. S., & Mirjalili, S. (2021). African vultures optimization algorithm: A new nature-inspired metaheuristic algorithm for global optimization problems. Computers & Industrial Engineering, 158, 107408.
+
+* **AGTO - Artificial Gorilla Troops Optimization**
+  * **OriginalAGTO**: Abdollahzadeh, B., Soleimanian Gharehchopogh, F., & Mirjalili, S. (2021). Artificial gorilla troops optimizer: a new natureâinspired metaheuristic algorithm for global optimization problems. International Journal of Intelligent Systems, 36(10), 5887-5958.
+
+* **ARO - Artificial Rabbits Optimization**:
+  * **OriginalARO**: Wang, L., Cao, Q., Zhang, Z., Mirjalili, S., & Zhao, W. (2022). Artificial rabbits optimization: A new bio-inspired meta-heuristic algorithm for solving engineering optimization problems. Engineering Applications of Artificial Intelligence, 114, 105082.
+
+
+
+### B
+
+
+* **BFO - Bacterial Foraging Optimization** 
+  * **OriginalBFO**: Passino, K. M. (2002). Biomimicry of bacterial foraging for distributed optimization and control. IEEE control systems magazine, 22(3), 52-67.
+  * **ABFO**: Nguyen, T., Nguyen, B. M., & Nguyen, G. (2019, April). Building resource auto-scaler with functional-link neural network and adaptive bacterial foraging optimization. In International Conference on Theory and Applications of Models of Computation (pp. 501-517). Springer, Cham.
+
+* **BeesA - Bees Algorithm** 
+  * **OriginalBeesA**: Pham, D. T., Ghanbarzadeh, A., Koc, E., Otri, S., Rahim, S., & Zaidi, M. (2005). The bees algorithm. Technical Note, Manufacturing Engineering Centre, Cardiff University, UK.
+  * **ProbBeesA**: The probabilitic version of: Pham, D. T., Ghanbarzadeh, A., KoÃ§, E., Otri, S., Rahim, S., & Zaidi, M. (2006). The bees algorithmâa novel tool for complex optimisation problems. In Intelligent production machines and systems (pp. 454-459). Elsevier Science Ltd.
+  
+* **BBO - Biogeography-Based Optimization** 
+  * **OriginalBBO**: Simon, D. (2008). Biogeography-based optimization. IEEE transactions on evolutionary computation, 12(6), 702-713.
+  * **BaseBBO**: The developed version
+  
+* **BA - Bat Algorithm** 
+  * **OriginalBA**: Yang, X. S. (2010). A new metaheuristic bat-inspired algorithm. In Nature inspired cooperative strategies for optimization (NICSO 2010) (pp. 65-74). Springer, Berlin, Heidelberg.
+  * **AdaptiveBA**: Wang, X., Wang, W. and Wang, Y., 2013, July. An adaptive bat algorithm. In International Conference on Intelligent Computing(pp. 216-223). Springer, Berlin, Heidelberg.
+  * **ModifiedBA**: Dong, H., Li, T., Ding, R. and Sun, J., 2018. A novel hybrid genetic algorithm with granular information for feature selection and optimization. Applied Soft Computing, 65, pp.33-46.
+
+* **BSO - Brain Storm Optimization** 
+  * **OriginalBSO**: . Shi, Y. (2011, June). Brain storm optimization algorithm. In International conference in swarm intelligence (pp. 303-309). Springer, Berlin, Heidelberg.
+  * **ImprovedBSO**: El-Abd, M., 2017. Global-best brain storm optimization algorithm. Swarm and evolutionary computation, 37, pp.27-44.
+
+* **BSA - Bird Swarm Algorithm** 
+  * **OriginalBSA**: Meng, X. B., Gao, X. Z., Lu, L., Liu, Y., & Zhang, H. (2016). A new bio-inspired optimisation algorithm:Bird Swarm Algorithm. Journal of Experimental & Theoretical Artificial Intelligence, 28(4), 673-687.
+
+* **BMO - Barnacles Mating Optimizer**:
+  * **OriginalBMO**: Sulaiman, M. H., Mustaffa, Z., Saari, M. M., Daniyal, H., Daud, M. R., Razali, S., & Mohamed, A. I. (2018, June). Barnacles mating optimizer: a bio-inspired algorithm for solving optimization problems. In 2018 19th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD) (pp. 265-270). IEEE.
+
+* **BES - Bald Eagle Search** 
+  * **OriginalBES**: Alsattar, H. A., Zaidan, A. A., & Zaidan, B. B. (2019). Novel meta-heuristic bald eagle search optimisation algorithm. Artificial Intelligence Review, 1-28.
+  
+* **BRO - Battle Royale Optimization**
+  * **OriginalBRO**: Rahkar Farshi, T. (2020). Battle royale optimization algorithm. Neural Computing and Applications, 1-19.
+  * **BaseBRO**: The developed version
+
+### C
+
+* **CA - Culture Algorithm** 
+  * **OriginalCA**: Reynolds, R.G., 1994, February. An introduction to cultural algorithms. In Proceedings of the third annual conference on evolutionary programming (Vol. 24, pp. 131-139). River Edge, NJ: World Scientific.
+
+* **CEM - Cross Entropy Method**
+  * **OriginalCEM**: Rubinstein, R. (1999). The cross-entropy method for combinatorial and continuous optimization. Methodology and computing in applied probability, 1(2), 127-190.
+  
+* **CSO - Cat Swarm Optimization** 
+  * **OriginalCSO**: Chu, S. C., Tsai, P. W., & Pan, J. S. (2006, August). Cat swarm optimization. In Pacific Rim international conference on artificial intelligence (pp. 854-858). Springer, Berlin, Heidelberg.
+
+* **CSA - Cuckoo Search Algorithm** 
+  * **OriginalCSA**: Yang, X. S., & Deb, S. (2009, December). Cuckoo search via LÃ©vy flights. In 2009 World congress on nature & biologically inspired computing (NaBIC) (pp. 210-214). Ieee.
+
+* **CRO - Coral Reefs Optimization** 
+  * **OriginalCRO**: Salcedo-Sanz, S., Del Ser, J., Landa-Torres, I., Gil-LÃ³pez, S., & Portilla-Figueras, J. A. (2014). The coral reefs optimization algorithm: a novel metaheuristic for efficiently solving optimization problems. The Scientific World Journal, 2014.
+  * **OCRO**: Nguyen, T., Nguyen, T., Nguyen, B. M., & Nguyen, G. (2019). Efficient time-series forecasting using neural network and opposition-based coral reefs optimization. International Journal of Computational Intelligence Systems, 12(2), 1144-1161.
+
+* **COA - Coyote Optimization Algorithm**
+  * **OriginalCOA**: Pierezan, J., & Coelho, L. D. S. (2018, July). Coyote optimization algorithm: a new metaheuristic for global optimization problems. In 2018 IEEE congress on evolutionary computation (CEC) (pp. 1-8). IEEE.
+
+* **CHIO - Coronavirus Herd Immunity Optimization**
+  * **OriginalCHIO**: Al-Betar, M. A., Alyasseri, Z. A. A., Awadallah, M. A., & Abu Doush, I. (2021). Coronavirus herd immunity optimizer (CHIO). Neural Computing and Applications, 33(10), 5011-5042.
+  * **BaseCHIO**: The developed version
+
+* **CGO - Chaos Game Optimization** 
+  * **OriginalCGO**: Talatahari, S., & Azizi, M. (2021). Chaos Game Optimization: a novel metaheuristic algorithm. Artificial Intelligence Review, 54(2), 917-1004.
+
+* **CSA - Circle Search Algorithm**
+  * **OriginalCSA**: Qais, M. H., Hasanien, H. M., Turky, R. A., Alghuwainem, S., Tostado-VÃ©liz, M., & Jurado, F. (2022). Circle Search Algorithm: A Geometry-Based Metaheuristic Optimization Algorithm. Mathematics, 10(10), 1626.
+
+### D
+
+* **DE - Differential Evolution** 
+  * **BaseDE**: Storn, R., & Price, K. (1997). Differential evolutionâa simple and efficient heuristic for global optimization over continuous spaces. Journal of global optimization, 11(4), 341-359.
+  * **JADE**: Zhang, J., & Sanderson, A. C. (2009). JADE: adaptive differential evolution with optional external archive. IEEE Transactions on evolutionary computation, 13(5), 945-958.
+  * **SADE**: Qin, A. K., & Suganthan, P. N. (2005, September). Self-adaptive differential evolution algorithm for numerical optimization. In 2005 IEEE congress on evolutionary computation (Vol. 2, pp. 1785-1791). IEEE.
+  * **SHADE**: Tanabe, R., & Fukunaga, A. (2013, June). Success-history based parameter adaptation for differential evolution. In 2013 IEEE congress on evolutionary computation (pp. 71-78). IEEE.
+  * **L_SHADE**: Tanabe, R., & Fukunaga, A. S. (2014, July). Improving the search performance of SHADE using linear population size reduction. In 2014 IEEE congress on evolutionary computation (CEC) (pp. 1658-1665). IEEE.
+  * **SAP_DE**: Teo, J. (2006). Exploring dynamic self-adaptive populations in differential evolution. Soft Computing, 10(8), 673-686.
+  
+* **DSA - Differential Search Algorithm (not done)** 
+  * **BaseDSA**: Civicioglu, P. (2012). Transforming geocentric cartesian coordinates to geodetic coordinates by using differential search algorithm. Computers & Geosciences, 46, 229-247.
+  
+* **DO - Dragonfly Optimization** 
+  * **OriginalDO**: Mirjalili, S. (2016). Dragonfly algorithm: a new meta-heuristic optimization technique for solving single-objective, discrete, and multi-objective problems. Neural Computing and Applications, 27(4), 1053-1073.
+
+* **DMOA - Dwarf Mongoose Optimization Algorithm**
+  * **OriginalDMOA**: Agushaka, J. O., Ezugwu, A. E., & Abualigah, L. (2022). Dwarf mongoose optimization algorithm. Computer methods in applied mechanics and engineering, 391, 114570.
+  * **DevDMOA**: The developed version
+
+### E
+
+* **ES - Evolution Strategies** . 
+  * **OriginalES**: Schwefel, H. P. (1984). Evolution strategies: A family of non-linear optimization techniques based on imitating some principles of organic evolution. Annals of Operations Research, 1(2), 165-167.
+  * **LevyES**: Zhang, S., & Salari, E. (2005). Competitive learning vector quantization with evolution strategies for image compression. Optical Engineering, 44(2), 027006.
+
+* **EP - Evolutionary programming** . 
+  * **OriginalEP**: Fogel, L. J. (1994). Evolutionary programming in perspective: The top-down view. Computational intelligence: Imitating life.
+  * **LevyEP**: Lee, C.Y. and Yao, X., 2001, May. Evolutionary algorithms with adaptive lÃ©vy mutations. In Proceedings of the 2001 congress on evolutionary computation (IEEE Cat. No. 01TH8546) (Vol. 1, pp. 568-575). IEEE.
+
+* **EHO - Elephant Herding Optimization** . 
+  * **OriginalEHO**: Wang, G. G., Deb, S., & Coelho, L. D. S. (2015, December). Elephant herding optimization. In 2015 3rd International Symposium on Computational and Business Intelligence (ISCBI) (pp. 1-5). IEEE.
+
+* **EFO - Electromagnetic Field Optimization** . 
+  * **OriginalEFO**:Abedinpourshotorban, H., Shamsuddin, S. M., Beheshti, Z., & Jawawi, D. N. (2016). Electromagnetic field optimization: A physics-inspired metaheuristic optimization algorithm. Swarm and Evolutionary Computation, 26, 8-22.
+  * **BaseEFO**: The developed version
+
+* **EOA - Earthworm Optimisation Algorithm** . 
+  * **OriginalEOA**: Wang, G. G., Deb, S., & dos Santos Coelho, L. (2018). Earthworm optimisation algorithm: a bio-inspired metaheuristic algorithm for global optimisation problems. IJBIC, 12(1), 1-22.
+
+* **EO - Equilibrium Optimizer** . 
+  * **OriginalEO**: Faramarzi, A., Heidarinejad, M., Stephens, B., & Mirjalili, S. (2019). Equilibrium optimizer: A novel optimization algorithm. Knowledge-Based Systems.
+  * **ModifiedEO**: Gupta, S., Deep, K., & Mirjalili, S. (2020). An efficient equilibrium optimizer with mutation strategy for numerical optimization. Applied Soft Computing, 96, 106542.
+  * **AdaptiveEO**: Wunnava, A., Naik, M. K., Panda, R., Jena, B., & Abraham, A. (2020). A novel interdependence based multilevel thresholding technique using adaptive equilibrium optimizer. Engineering Applications of Artificial Intelligence, 94, 103836.
+
+### F
+
+* **FFA - Firefly Algorithm** 
+  * **OriginalFFA**: Åukasik, S., & Å»ak, S. (2009, October). Firefly algorithm for continuous constrained optimization tasks. In International conference on computational collective intelligence (pp. 97-106). Springer, Berlin, Heidelberg.
+  
+* **FA - Fireworks algorithm** 
+  * **OriginalFA**: Tan, Y., & Zhu, Y. (2010, June). Fireworks algorithm for optimization. In International conference in swarm intelligence (pp. 355-364). Springer, Berlin, Heidelberg.
+
+* **FPA - Flower Pollination Algorithm** 
+  * **OriginalFPA**: Yang, X. S. (2012, September). Flower pollination algorithm for global optimization. In International conference on unconventional computing and natural computation (pp. 240-249). Springer, Berlin, Heidelberg.
+
+* **FOA - Fruit-fly Optimization Algorithm**
+  * **OriginalFOA**: Pan, W. T. (2012). A new fruit fly optimization algorithm: taking the financial distress model as an example. Knowledge-Based Systems, 26, 69-74.
+  * **BaseFOA**: The developed version
+  * **WhaleFOA**: Fan, Y., Wang, P., Heidari, A. A., Wang, M., Zhao, X., Chen, H., & Li, C. (2020). Boosted hunting-based fruit fly optimization and advances in real-world problems. Expert Systems with Applications, 159, 113502.
+
+* **FBIO - Forensic-Based Investigation Optimization** 
+  * **OriginalFBIO**: Chou, J.S. and Nguyen, N.M., 2020. FBI inspired meta-optimization. Applied Soft Computing, p.106339.
+  * **BaseFBIO**: Fathy, A., Rezk, H. and Alanazi, T.M., 2021. Recent approach of forensic-based investigation algorithm for optimizing fractional order PID-based MPPT with proton exchange membrane fuel cell.IEEE Access,9, pp.18974-18992.
+
+* **FHO - Fire Hawk Optimization**
+  * **OriginalFHO**: Azizi, M., Talatahari, S., & Gandomi, A. H. (2022). Fire Hawk Optimizer: a novel metaheuristic algorithm. Artificial Intelligence Review, 1-77.
+
+### G
+
+* **GA - Genetic Algorithm** 
+  * **BaseGA**: Holland, J. H. (1992). Genetic algorithms. Scientific american, 267(1), 66-73.
+  * **SingleGA**: De Falco, I., Della Cioppa, A. and Tarantino, E., 2002. Mutation-based genetic algorithm: performance evaluation.Â Applied Soft Computing,Â 1(4), pp.285-299.
+  * **MultiGA**: De Jong, K.A. and Spears, W.M., 1992. A formal analysis of the role of multi-point crossover in genetic algorithms.Â Annals of mathematics and Artificial intelligence,Â 5(1), pp.1-26.
+  * **EliteSingleGA**: Elite version of Single-point mutation GA
+  * **EliteMultiGA**: Elite version of Multiple-point mutation GA
+
+* **GWO - Grey Wolf Optimizer** 
+  * **OriginalGWO**: Mirjalili, S., Mirjalili, S. M., & Lewis, A. (2014). Grey wolf optimizer. Advances in engineering software, 69, 46-61.
+  * **RW_GWO**: Gupta, S., & Deep, K. (2019). A novel random walk grey wolf optimizer. Swarm and evolutionary computation, 44, 101-112.
+  * **GWO_WOA**: Obadina, O. O., Thaha, M. A., Althoefer, K., & Shaheed, M. H. (2022). Dynamic characterization of a masterâslave robotic manipulator using a hybrid grey wolfâwhale optimization algorithm. Journal of Vibration and Control, 28(15-16), 1992-2003.
+
+* **GOA - Grasshopper Optimisation Algorithm** 
+  * **OriginalGOA**: Saremi, S., Mirjalili, S., & Lewis, A. (2017). Grasshopper optimisation algorithm: theory and application. Advances in Engineering Software, 105, 30-47.
+
+* **GCO - Germinal Center Optimization** 
+  * **OriginalGCO**: VillaseÃ±or, C., Arana-Daniel, N., Alanis, A. Y., LÃ³pez-Franco, C., & Hernandez-Vargas, E. A. (2018). Germinal center optimization algorithm. International Journal of Computational Intelligence Systems, 12(1), 13-27.
+  * **BaseGCO**: The developed version
+
+* **GSKA - Gaining Sharing Knowledge-based Algorithm** 
+  * **OriginalGSKA**: Mohamed, A. W., Hadi, A. A., & Mohamed, A. K. (2019). Gaining-sharing knowledge based algorithm for solving optimization problems: a novel nature-inspired algorithm. International Journal of Machine Learning and Cybernetics, 1-29.
+  * **BaseGSKA**: Mohamed, A.W., Hadi, A.A., Mohamed, A.K. and Awad, N.H., 2020, July. Evaluating the performance of adaptive GainingSharing knowledge based algorithm on CEC 2020 benchmark problems. InÂ 2020 IEEE Congress on Evolutionary Computation (CEC)Â (pp. 1-8). IEEE.
+
+* **GBO - Gradient-Based Optimizer**
+  * **OriginalGBO**: Ahmadianfar, I., Bozorg-Haddad, O., & Chu, X. (2020). Gradient-based optimizer: A new metaheuristic optimization algorithm. Information Sciences, 540, 131-159.
+
+### H
+
+* **HC - Hill Climbing** . 
+  * **OriginalHC**: Talbi, E. G., & Muntean, T. (1993, January). Hill-climbing, simulated annealing and genetic algorithms: a comparative study and application to the mapping problem. In [1993] Proceedings of the Twenty-sixth Hawaii International Conference on System Sciences (Vol. 2, pp. 565-573). IEEE.
+  * **SwarmHC**: The developed version based on swarm-based idea (Original is single-solution based method)
+
+* **HS - Harmony Search** . 
+  * **OriginalHS**: Geem, Z. W., Kim, J. H., & Loganathan, G. V. (2001). A new heuristic optimization algorithm:harmony search. simulation, 76(2), 60-68.
+  * **BaseHS**: The developed version
+
+* **HHO - Harris Hawks Optimization** . 
+  * **OriginalHHO**: Heidari, A. A., Mirjalili, S., Faris, H., Aljarah, I., Mafarja, M., & Chen, H. (2019). Harris hawks optimization: Algorithm and applications. Future Generation Computer Systems, 97, 849-872.
+
+* **HGSO - Henry Gas Solubility Optimization** . 
+  * **OriginalHGSO**: Hashim, F. A., Houssein, E. H., Mabrouk, M. S., Al-Atabany, W., & Mirjalili, S. (2019). Henry gas solubility optimization: A novel physics-based algorithm. Future Generation Computer Systems, 101, 646-667.
+
+* **HGS - Hunger Games Search** . 
+  * **OriginalHGS**: Yang, Y., Chen, H., Heidari, A. A., & Gandomi, A. H. (2021). Hunger games search:Visions, conception, implementation, deep analysis, perspectives, and towards performance shifts. Expert Systems with Applications, 177, 114864.
+  
+* **HHOA - Horse Herd Optimization Algorithm (not done)** . 
+  * **BaseHHOA**: MiarNaeimi, F., Azizyan, G., & Rashki, M. (2021). Horse herd optimization algorithm: A nature-inspired algorithm for high-dimensional optimization problems. Knowledge-Based Systems, 213, 106711.
+  
+* **HBA - Honey Badger Algorithm**:
+  * **OriginalHBA**: Hashim, F. A., Houssein, E. H., Hussain, K., Mabrouk, M. S., & Al-Atabany, W. (2022). Honey Badger Algorithm: New metaheuristic algorithm for solving optimization problems. Mathematics and Computers in Simulation, 192, 84-110.
+
+
+### I
+
+* **IWO - Invasive Weed Optimization** . 
+  * **OriginalIWO**: Mehrabian, A. R., & Lucas, C. (2006). A novel numerical optimization algorithm inspired from weed colonization. Ecological informatics, 1(4), 355-366.
+
+* **ICA - Imperialist Competitive Algorithm** 
+  * **OriginalICA**: Atashpaz-Gargari, E., & Lucas, C. (2007, September). Imperialist competitive algorithm: an algorithm for optimization inspired by imperialistic competition. In 2007 IEEE congress on evolutionary computation (pp. 4661-4667). Ieee.
+
+* **INFO - weIghted meaN oF vectOrs**:
+  * **OriginalINFO**: Ahmadianfar, I., Heidari, A. A., Gandomi, A. H., Chu, X., & Chen, H. (2021). RUN beyond the metaphor: An efficient     optimization algorithm based on Runge Kutta method. Expert Systems with Applications, 181, 115079.
+
+### J
+
+* **JA - Jaya Algorithm** 
+  * **OriginalJA**: Rao, R. (2016). Jaya: A simple and new optimization algorithm for solving constrained and unconstrained optimization problems. International Journal of Industrial Engineering Computations, 7(1), 19-34.
+  * **BaseJA**: The developed version
+  * **LevyJA**: Iacca, G., dos Santos Junior, V. C., & de Melo, V. V. (2021). An improved Jaya optimization algorithm with Levy flight. Expert Systems with Applications, 165, 113902.
+
+### K
+
+### L
+
+* **LCO - Life Choice-based Optimization** 
+  * **OriginalLCO**: Khatri, A., Gaba, A., Rana, K. P. S., & Kumar, V. (2019). A novel life choice-based optimizer. Soft Computing, 1-21.
+  * **BaseLCO**: The developed version
+  * **ImprovedLCO**: The improved version using Gaussian distribution and Mutation Mechanism
+
+
+### M
+
+* **MA - Memetic Algorithm**
+  * **OriginalMA**: Moscato, P. (1989). On evolution, search, optimization, genetic algorithms and martial arts: Towards memetic algorithms. Caltech concurrent computation program, C3P Report, 826, 1989.
+
+* **MFO - Moth Flame Optimization** 
+  * **OriginalMFO**: Mirjalili, S. (2015). Moth-flame optimization algorithm: A novel nature-inspired heuristic paradigm. Knowledge-based systems, 89, 228-249.
+  * **BaseMFO**: The developed version
+
+* **MVO - Multi-Verse Optimizer** 
+  * **OriginalMVO**: Mirjalili, S., Mirjalili, S. M., & Hatamlou, A. (2016). Multi-verse optimizer: a nature-inspired algorithm for global optimization. Neural Computing and Applications, 27(2), 495-513.
+  * **BaseMVO**: The developed version
+
+* **MSA - Moth Search Algorithm** 
+  * **OriginalMSA**: Wang, G. G. (2018). Moth search algorithm: a bio-inspired metaheuristic algorithm for global optimization problems. Memetic Computing, 10(2), 151-164.
+  
+* **MRFO - Manta Ray Foraging Optimization** 
+  * **OriginalMRFO**: Zhao, W., Zhang, Z., & Wang, L. (2020). Manta ray foraging optimization: An effective bio-inspired optimizer for engineering applications. Engineering Applications of Artificial Intelligence, 87, 103300.
+
+* **MPA - Marine Predators Algorithm**:
+  * **OriginalMPA**: Faramarzi, A., Heidarinejad, M., Mirjalili, S., & Gandomi, A. H. (2020). Marine Predators Algorithm: A nature-inspired metaheuristic. Expert systems with applications, 152, 113377.
+
+
+### N
+
+
+* **NRO - Nuclear Reaction Optimization** 
+  * **OriginalNRO**: Wei, Z., Huang, C., Wang, X., Han, T., & Li, Y. (2019). Nuclear Reaction Optimization: A novel and powerful physics-based algorithm for global optimization. IEEE Access. 
+
+* **NMRA - Nake Mole-Rat Algorithm**
+  * **OriginalNMRA**: Salgotra, R., & Singh, U. (2019). The naked mole-rat algorithm. Neural Computing and Applications, 31(12), 8837-8857.
+  * **ImprovedNMRA**: Singh, P., Mittal, N., Singh, U. and Salgotra, R., 2021. Naked mole-rat algorithm with improved exploration and exploitation capabilities to determine 2D and 3D coordinates of sensor nodes in WSNs.Â Arabian Journal for Science and Engineering,Â 46(2), pp.1155-1178.
+
+
+### O
+
+### P
+
+* **PSO - Particle Swarm Optimization** 
+  * **OriginalPSO**: Eberhart, R., & Kennedy, J. (1995, October). A new optimizer using particle swarm theory. In MHS'95. Proceedings of the Sixth International Symposium on Micro Machine and Human Science (pp. 39-43). Ieee.
+  * **PPSO**: Ghasemi, M., Akbari, E., Rahimnejad, A., Razavi, S. E., Ghavidel, S., & Li, L. (2019). Phasor particle swarm optimization: a simple and efficient variant of PSO. Soft Computing, 23(19), 9701-9718.
+  * **HPSO_TVAC**: Ghasemi, M., Aghaei, J., & Hadipour, M. (2017). New self-organising hierarchical PSO with jumping time-varying acceleration coefficients. Electronics Letters, 53(20), 1360-1362.
+  * **C_PSO**: Liu, B., Wang, L., Jin, Y. H., Tang, F., & Huang, D. X. (2005). Improved particle swarm optimization combined with chaos. Chaos, Solitons & Fractals, 25(5), 1261-1271.
+  * **CL_PSO**: Liang, J. J., Qin, A. K., Suganthan, P. N., & Baskar, S. (2006). Comprehensive learning particle swarm optimizer for global optimization of multimodal functions. IEEE transactions on evolutionary computation, 10(3), 281-295.
+
+* **PFA - Pathfinder Algorithm** 
+  * **OriginalPFA**: Yapici, H., & Cetinkaya, N. (2019). A new meta-heuristic optimizer: Pathfinder algorithm. Applied Soft Computing, 78, 545-568.
+
+* **PSS - Pareto-like Sequential Sampling**
+  * **OriginalPSS**: Shaqfa, M., & Beyer, K. (2021). Pareto-like sequential sampling heuristic for global optimisation. Soft Computing, 25(14), 9077-9096.
+
+
+### Q
+
+* **QSA - Queuing Search Algorithm** 
+  * **OriginalQSA**: Zhang, J., Xiao, M., Gao, L., & Pan, Q. (2018). Queuing search algorithm: A novel metaheuristic algorithm for solving engineering optimization problems. Applied Mathematical Modelling, 63, 464-490.
+  * **BaseQSA**: The developed version
+  * **OppoQSA**: Zheng, X. and Nguyen, H., 2022. A novel artificial intelligent model for predicting water treatment efficiency of various biochar systems based on artificial neural network and queuing search algorithm. Chemosphere, 287, p.132251.
+  * **LevyQSA**: Abderazek, H., Hamza, F., Yildiz, A.R., Gao, L. and Sait, S.M., 2021. A comparative analysis of the queuing search algorithm, the sine-cosine algorithm, the ant lion algorithm to determine the optimal weight design problem of a spur gear drive system. Materials Testing, 63(5), pp.442-447.
+  * **ImprovedQSA**: Nguyen, B.M., Hoang, B., Nguyen, T. and Nguyen, G., 2021. nQSV-Net: a novel queuing search variant for global space search and workload modeling.Â Journal of Ambient Intelligence and Humanized Computing,Â 12(1), pp.27-46.
+
+### R
+
+* **RUN - RUNge Kutta optimizer**:
+  * **OriginalRUN**: Ahmadianfar, I., Heidari, A. A., Gandomi, A. H., Chu, X., & Chen, H. (2021). RUN beyond the metaphor: An efficient optimization algorithm based on Runge Kutta method. Expert Systems with Applications, 181, 115079.
+
+### S
+
+* **SA - Simulated Annealling** 
+  * **OriginalSA**: . Van Laarhoven, P. J., & Aarts, E. H. (1987). Simulated annealing. In Simulated annealing: Theory and applications (pp. 7-15). Springer, Dordrecht.
+
+* **SSpiderO - Social Spider Optimization** 
+  * **OriginalSSpiderO**: Cuevas, E., Cienfuegos, M., ZaldÃ­Var, D., & PÃ©rez-Cisneros, M. (2013). A swarm optimization algorithm inspired in the behavior of the social-spider. Expert Systems with Applications, 40(16), 6374-6384.
+
+* **SOS - Symbiotic Organisms Search**:
+  * **OriginalSOS**: Cheng, M. Y., & Prayogo, D. (2014). Symbiotic organisms search: a new metaheuristic optimization algorithm. Computers & Structures, 139, 98-112.
+
+* **SSpiderA - Social Spider Algorithm** 
+  * **OriginalSSpiderA**: James, J. Q., & Li, V. O. (2015). A social spider algorithm for global optimization. Applied Soft Computing, 30, 614-627.
+
+* **SCA - Sine Cosine Algorithm** 
+  * **OriginalSCA**: Mirjalili, S. (2016). SCA: a sine cosine algorithm for solving optimization problems. Knowledge-Based Systems, 96, 120-133.
+  * **BaseSCA**: Attia, A.F., El Sehiemy, R.A. and Hasanien, H.M., 2018. Optimal power flow solution in power systems using a novel Sine-Cosine algorithm.Â International Journal of Electrical Power & Energy Systems,Â 99, pp.331-343.
+
+* **SRSR - Swarm Robotics Search And Rescue** 
+  * **OriginalSRSR**: Bakhshipour, M., Ghadi, M. J., & Namdari, F. (2017). Swarm robotics search & rescue: A novel artificial intelligence-inspired optimization approach. Applied Soft Computing, 57, 708-726.
+
+* **SBO - Satin Bowerbird Optimizer** 
+  * **OriginalSBO**: Moosavi, S. H. S., & Bardsiri, V. K. (2017). Satin bowerbird optimizer: a new optimization algorithm to optimize ANFIS for software development effort estimation. Engineering Applications of Artificial Intelligence, 60, 1-15.
+  * **BaseSBO**: The developed version
+
+* **SHO - Spotted Hyena Optimizer**
+  * **OriginalSHO**: Dhiman, G., & Kumar, V. (2017). Spotted hyena optimizer: a novel bio-inspired based metaheuristic technique for engineering applications. Advances in Engineering Software, 114, 48-70.
+
+* **SSO - Salp Swarm Optimization**
+  * **OriginalSSO**: Mirjalili, S., Gandomi, A. H., Mirjalili, S. Z., Saremi, S., Faris, H., & Mirjalili, S. M. (2017). Salp Swarm Algorithm: A bio-inspired optimizer for engineering design problems. Advances in Engineering Software, 114, 163-191.
+
+* **SFO - Sailfish Optimizer** 
+  * **OriginalSFO**: Shadravan, S., Naji, H. R., & Bardsiri, V. K. (2019). The Sailfish Optimizer: A novel nature-inspired metaheuristic algorithm for solving constrained engineering optimization problems. Engineering Applications of Artificial Intelligence, 80, 20-34.
+  * **ImprovedSFO**: Li, L.L., Shen, Q., Tseng, M.L. and Luo, S., 2021. Power system hybrid dynamic economic emission dispatch with wind energy based on improved sailfish algorithm.Â Journal of Cleaner Production,Â 316, p.128318.
+
+* **SARO - Search And Rescue Optimization** 
+  * **OriginalSARO**: Shabani, A., Asgarian, B., Gharebaghi, S. A., Salido, M. A., & Giret, A. (2019). A New Optimization Algorithm Based on Search and Rescue Operations. Mathematical Problems in Engineering, 2019.
+  * **BaseSARO**: The developed version using Levy-flight
+
+* **SSDO - Social Ski-Driver Optimization** 
+  * **OriginalSSDO**: Tharwat, A., & Gabel, T. (2019). Parameters optimization of support vector machines for imbalanced data using social ski driver algorithm. Neural Computing and Applications, 1-14.
+
+* **SLO - Sea Lion Optimization**
+  * **OriginalSLO**: Masadeh, R., Mahafzah, B. A., & Sharieh, A. (2019). Sea Lion Optimization Algorithm. Sea, 10(5).
+  * **ImprovedSLO**: The developed version
+  * **ModifiedSLO**: Masadeh, R., Alsharman, N., Sharieh, A., Mahafzah, B.A. and Abdulrahman, A., 2021. Task scheduling on cloud computing based on sea lion optimization algorithm.Â International Journal of Web Information Systems.
+
+* **Seagull Optimization Algorithm**
+  * **OriginalSOA**: Dhiman, G., & Kumar, V. (2019). Seagull optimization algorithm: Theory and its applications for large-scale industrial engineering problems. Knowledge-based systems, 165, 169-196.
+  * **DevSOA**: The developed version
+
+* **SMA - Slime Mould Algorithm**
+  * **OriginalSMA**: Li, S., Chen, H., Wang, M., Heidari, A. A., & Mirjalili, S. (2020). Slime mould algorithm: A new method for stochastic optimization. Future Generation Computer Systems.
+  * **BaseSMA**: The developed version
+
+* **SSA - Sparrow Search Algorithm** 
+  * **OriginalSSA**: Jiankai Xue & Bo Shen (2020) A novel swarm intelligence optimization approach: sparrow search algorithm, Systems Science & Control Engineering, 8:1, 22-34, DOI: 10.1080/21642583.2019.1708830
+  * **BaseSSA**: The developed version
+
+* **SPBO - Student Psychology Based Optimization**
+  * **OriginalSPBO**: Das, B., Mukherjee, V., & Das, D. (2020). Student psychology based optimization algorithm: A new population based optimization algorithm for solving optimization problems. Advances in Engineering software, 146, 102804.
+  * **DevSPBO**: The developed version
+
+* **SCSO - Sand Cat Swarm Optimization**
+  * **OriginalSCSO**: Seyyedabbasi, A., & Kiani, F. (2022). Sand Cat swarm optimization: a nature-inspired algorithm to solve global optimization problems. Engineering with Computers, 1-25.
+
+### T
+
+* **TLO - Teaching Learning Optimization** 
+  * **OriginalTLO**: Rao, R. V., Savsani, V. J., & Vakharia, D. P. (2011). Teachingâlearning-based optimization: a novel method for constrained mechanical design optimization problems. Computer-Aided Design, 43(3), 303-315.
+  * **BaseTLO**: Rao, R., & Patel, V. (2012). An elitist teaching-learning-based optimization algorithm for solving complex constrained optimization problems. International Journal of Industrial Engineering Computations, 3(4), 535-560.
+  * **ImprovedTLO**: Rao, R. V., & Patel, V. (2013). An improved teaching-learning-based optimization algorithm for solving unconstrained optimization problems. Scientia Iranica, 20(3), 710-720.
+
+* **TWO - Tug of War Optimization** 
+  * **OriginalTWO**: Kaveh, A., & Zolghadr, A. (2016). A novel meta-heuristic algorithm: tug of war optimization. Iran University of Science & Technology, 6(4), 469-492.
+  * **OppoTWO**: Kaveh, A., Almasi, P. and Khodagholi, A., 2022. Optimum Design of Castellated Beams Using Four Recently Developed Meta-heuristic Algorithms.Â Iranian Journal of Science and Technology, Transactions of Civil Engineering, pp.1-13.
+  * **LevyTWO**: The developed version using Levy-flight
+  * **ImprovedTWO**: Nguyen, T., Hoang, B., Nguyen, G., & Nguyen, B. M. (2020). A new workload prediction model using extreme learning machine and enhanced tug of war optimization. Procedia Computer Science, 170, 362-369.
+
+* **TSA - Tunicate Swarm Algorithm**
+  * **OriginalTSA**: Kaur, S., Awasthi, L. K., Sangal, A. L., & Dhiman, G. (2020). Tunicate Swarm Algorithm: A new bio-inspired based metaheuristic paradigm for global optimization. Engineering Applications of Artificial Intelligence, 90, 103541.
+
+* **TSO - Tuna Swarm Optimization**
+  * **OriginalTSO**: Xie, L., Han, T., Zhou, H., Zhang, Z. R., Han, B., & Tang, A. (2021). Tuna swarm optimization: a novel swarm-based metaheuristic algorithm for global optimization. Computational intelligence and Neuroscience, 2021.
+
+
+### U
+
+### V
+
+* **VCS - Virus Colony Search** 
+  * **OriginalVCS**: Li, M. D., Zhao, H., Weng, X. W., & Han, T. (2016). A novel nature-inspired algorithm for optimization: Virus colony search. Advances in Engineering Software, 92, 65-88.
+  * **BaseVCS**: The developed version
+
+### W
+
+* **WCA - Water Cycle Algorithm** 
+  * **OriginalWCA**: Eskandar, H., Sadollah, A., Bahreininejad, A., & Hamdi, M. (2012). Water cycle algorithmâA novel metaheuristic optimization method for solving constrained engineering optimization problems. Computers & Structures, 110, 151-166.
+  
+* **WOA - Whale Optimization Algorithm** 
+  * **OriginalWOA**: Mirjalili, S., & Lewis, A. (2016). The whale optimization algorithm. Advances in engineering software, 95, 51-67.
+  * **HI_WOA**: Tang, C., Sun, W., Wu, W., & Xue, M. (2019, July). A hybrid improved whale optimization algorithm. In 2019 IEEE 15th International Conference on Control and Automation (ICCA) (pp. 362-367). IEEE.
+
+* **WHO - Wildebeest Herd Optimization** 
+  * **OriginalWHO**: Amali, D., & Dinakaran, M. (2019). Wildebeest herd optimization: A new global optimization algorithm inspired by wildebeest herding behaviour. Journal of Intelligent & Fuzzy Systems, (Preprint), 1-14.
+
+* **WDO - Wind Driven Optimization** 
+  * **OriginalWDO**: Bayraktar, Z., Komurcu, M., & Werner, D. H. (2010, July). Wind Driven Optimization (WDO): A novel nature-inspired optimization algorithm and its application to electromagnetics. In 2010 IEEE antennas and propagation society international symposium (pp. 1-4). IEEE.
+
+
+### X
+
+### Y
+
+### Z
```

### Comparing `mealpy-2.5.3/mealpy.egg-info/SOURCES.txt` & `mealpy-2.5.3a1/mealpy.egg-info/SOURCES.txt`

 * *Files 2% similar despite different names*

```diff
@@ -39,17 +39,15 @@
 mealpy/human_based/CA.py
 mealpy/human_based/CHIO.py
 mealpy/human_based/FBIO.py
 mealpy/human_based/GSKA.py
 mealpy/human_based/HBO.py
 mealpy/human_based/HCO.py
 mealpy/human_based/ICA.py
-mealpy/human_based/ILA.py
 mealpy/human_based/LCO.py
-mealpy/human_based/PO.py
 mealpy/human_based/QSA.py
 mealpy/human_based/SARO.py
 mealpy/human_based/SPBO.py
 mealpy/human_based/SSDO.py
 mealpy/human_based/TLO.py
 mealpy/human_based/TOA.py
 mealpy/human_based/WarSO.py
@@ -94,24 +92,22 @@
 mealpy/swarm_based/BES.py
 mealpy/swarm_based/BFO.py
 mealpy/swarm_based/BSA.py
 mealpy/swarm_based/BeesA.py
 mealpy/swarm_based/COA.py
 mealpy/swarm_based/CSA.py
 mealpy/swarm_based/CSO.py
-mealpy/swarm_based/ChOA.py
 mealpy/swarm_based/CoatiOA.py
 mealpy/swarm_based/DMOA.py
 mealpy/swarm_based/DO.py
 mealpy/swarm_based/EHO.py
 mealpy/swarm_based/ESOA.py
 mealpy/swarm_based/FA.py
 mealpy/swarm_based/FFA.py
 mealpy/swarm_based/FFO.py
-mealpy/swarm_based/FHO.py
 mealpy/swarm_based/FOA.py
 mealpy/swarm_based/FOX.py
 mealpy/swarm_based/GJO.py
 mealpy/swarm_based/GOA.py
 mealpy/swarm_based/GTO.py
 mealpy/swarm_based/GWO.py
 mealpy/swarm_based/HBA.py
@@ -122,15 +118,14 @@
 mealpy/swarm_based/MGO.py
 mealpy/swarm_based/MPA.py
 mealpy/swarm_based/MRFO.py
 mealpy/swarm_based/MSA.py
 mealpy/swarm_based/NGO.py
 mealpy/swarm_based/NMRA.py
 mealpy/swarm_based/OOA.py
-mealpy/swarm_based/OPA.py
 mealpy/swarm_based/PFA.py
 mealpy/swarm_based/POA.py
 mealpy/swarm_based/PSO.py
 mealpy/swarm_based/SCSO.py
 mealpy/swarm_based/SFO.py
 mealpy/swarm_based/SHO.py
 mealpy/swarm_based/SLO.py
@@ -141,15 +136,14 @@
 mealpy/swarm_based/SSpiderO.py
 mealpy/swarm_based/STO.py
 mealpy/swarm_based/SeaHO.py
 mealpy/swarm_based/ServalOA.py
 mealpy/swarm_based/TDO.py
 mealpy/swarm_based/TSO.py
 mealpy/swarm_based/WOA.py
-mealpy/swarm_based/WSO.py
 mealpy/swarm_based/WaOA.py
 mealpy/swarm_based/ZOA.py
 mealpy/swarm_based/__init__.py
 mealpy/system_based/AEO.py
 mealpy/system_based/GCO.py
 mealpy/system_based/WCA.py
 mealpy/system_based/__init__.py
@@ -157,8 +151,9 @@
 mealpy/utils/history.py
 mealpy/utils/io.py
 mealpy/utils/logger.py
 mealpy/utils/problem.py
 mealpy/utils/termination.py
 mealpy/utils/validator.py
 mealpy/utils/visualize/__init__.py
-mealpy/utils/visualize/linechart.py
+mealpy/utils/visualize/linechart.py
+tests/test_optimizer.py
```

### Comparing `mealpy-2.5.3/setup.py` & `mealpy-2.5.3a1/setup.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,73 +1,73 @@
-#!/usr/bin/env python
-# Created by "Thieu" at 13:24, 27/02/2022 ----------%
-#       Email: nguyenthieu2102@gmail.com            %
-#       Github: https://github.com/thieu1995        %
-# --------------------------------------------------%
-
-from setuptools import setup, find_packages
-
-
-def readme():
-    with open('README.md', encoding='utf-8') as f:
-        README = f.read()
-    return README
-
-
-setup(
-    name="mealpy",
-    version="2.5.3",
-    author="Thieu",
-    author_email="nguyenthieu2102@gmail.com",
-    description="MEALPY: An Open-source Library for Latest Meta-heuristic Algorithms in Python",
-    long_description=readme(),
-    long_description_content_type="text/markdown",
-    keywords=["optimization", "metaheuristics", "MHA", "mathematical optimization", "nature-inspired algorithms",
-              "evolutionary computation", "soft computing", "population-based algorithms",
-              "Stochastic optimization", "Global optimization", "Convergence analysis", "Search space exploration",
-              "Local search", "Computational intelligence", "Black-box optimization", "Robust optimization",
-              "Hybrid algorithms", "Benchmark functions", "Metaheuristic design", "Performance analysis",
-              "Exploration versus exploitation", "Self-adaptation", "Constrained optimization",
-              "Intelligent optimization", "Adaptive search", "Simulations", "Algorithm selection"],
-    url="https://github.com/thieu1995/mealpy",
-    project_urls={
-        'Documentation': 'https://mealpy.readthedocs.io/',
-        'Source Code': 'https://github.com/thieu1995/mealpy',
-        'Bug Tracker': 'https://github.com/thieu1995/mealpy/issues',
-        'Change Log': 'https://github.com/thieu1995/mealpy/blob/master/ChangeLog.md',
-        'Forum': 'https://t.me/+fRVCJGuGJg1mNDg1',
-    },
-    packages=find_packages(exclude=['tests*', 'examples*']),
-    include_package_data=True,
-    license="GPLv3",
-    classifiers=[
-        "Development Status :: 5 - Production/Stable",
-        "Intended Audience :: Developers",
-        "Intended Audience :: Education",
-        "Intended Audience :: Information Technology",
-        "Intended Audience :: Science/Research",
-        "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
-        "Natural Language :: English",
-        "Programming Language :: Python :: 3",
-        "Programming Language :: Python :: 3.7",
-        "Programming Language :: Python :: 3.8",
-        "Programming Language :: Python :: 3.9",
-        "Programming Language :: Python :: 3.10",
-        "Programming Language :: Python :: 3.11",
-        "Topic :: System :: Benchmark",
-        "Topic :: Scientific/Engineering",
-        "Topic :: Scientific/Engineering :: Mathematics",
-        "Topic :: Scientific/Engineering :: Artificial Intelligence",
-        "Topic :: Scientific/Engineering :: Information Analysis",    
-        "Topic :: Scientific/Engineering :: Visualization",
-        "Topic :: Scientific/Engineering :: Bio-Informatics",
-        "Topic :: Software Development :: Build Tools",
-        "Topic :: Software Development :: Libraries",
-        "Topic :: Software Development :: Libraries :: Python Modules",
-        "Topic :: Utilities",
-    ],
-    install_requires=["numpy>=1.16.5", "matplotlib>=3.3.0", "scipy>=1.7.1", "pandas>=1.2.0", "opfunu>=1.0.0"],
-    extras_require={
-        "dev": ["pytest>=7.0", "twine>=4.0.1"],
-    },
-    python_requires='>=3.7',
-)
+#!/usr/bin/env python
+# Created by "Thieu" at 13:24, 27/02/2022 ----------%
+#       Email: nguyenthieu2102@gmail.com            %
+#       Github: https://github.com/thieu1995        %
+# --------------------------------------------------%
+
+from setuptools import setup, find_packages
+
+
+def readme():
+    with open('README.md', encoding='utf-8') as f:
+        README = f.read()
+    return README
+
+
+setup(
+    name="mealpy",
+    version="2.5.3-alpha.1",
+    author="Thieu",
+    author_email="nguyenthieu2102@gmail.com",
+    description="MEALPY: A Framework Of The State-Of-The-Art Meta-Heuristic Algorithms In Python",
+    long_description=readme(),
+    long_description_content_type="text/markdown",
+    keywords=["optimization", "metaheuristics", "MHA", "mathematical optimization", "nature-inspired algorithms",
+              "evolutionary computation", "soft computing", "population-based algorithms",
+              "Stochastic optimization", "Global optimization", "Convergence analysis", "Search space exploration",
+              "Local search", "Computational intelligence", "Black-box optimization", "Robust optimization",
+              "Hybrid algorithms", "Benchmark functions", "Metaheuristic design", "Performance analysis",
+              "Exploration versus exploitation", "Self-adaptation", "Constrained optimization",
+              "Intelligent optimization", "Adaptive search", "Simulations", "Algorithm selection"],
+    url="https://github.com/thieu1995/mealpy",
+    project_urls={
+        'Documentation': 'https://mealpy.readthedocs.io/',
+        'Source Code': 'https://github.com/thieu1995/mealpy',
+        'Bug Tracker': 'https://github.com/thieu1995/mealpy/issues',
+        'Change Log': 'https://github.com/thieu1995/mealpy/blob/master/ChangeLog.md',
+        'Forum': 'https://t.me/+fRVCJGuGJg1mNDg1',
+    },
+    packages=find_packages(exclude=['tests*', 'examples*']),
+    include_package_data=True,
+    license="GPLv3",
+    classifiers=[
+        "Development Status :: 5 - Production/Stable",
+        "Intended Audience :: Developers",
+        "Intended Audience :: Education",
+        "Intended Audience :: Information Technology",
+        "Intended Audience :: Science/Research",
+        "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
+        "Natural Language :: English",
+        "Programming Language :: Python :: 3",
+        "Programming Language :: Python :: 3.7",
+        "Programming Language :: Python :: 3.8",
+        "Programming Language :: Python :: 3.9",
+        "Programming Language :: Python :: 3.10",
+        "Programming Language :: Python :: 3.11",
+        "Topic :: System :: Benchmark",
+        "Topic :: Scientific/Engineering",
+        "Topic :: Scientific/Engineering :: Mathematics",
+        "Topic :: Scientific/Engineering :: Artificial Intelligence",
+        "Topic :: Scientific/Engineering :: Information Analysis",    
+        "Topic :: Scientific/Engineering :: Visualization",
+        "Topic :: Scientific/Engineering :: Bio-Informatics",
+        "Topic :: Software Development :: Build Tools",
+        "Topic :: Software Development :: Libraries",
+        "Topic :: Software Development :: Libraries :: Python Modules",
+        "Topic :: Utilities",
+    ],
+    install_requires=["numpy>=1.16.5", "matplotlib>=3.3.0", "scipy>=1.7.1", "pandas>=1.2.0", "opfunu>=1.0.0"],
+    extras_require={
+        "dev": ["pytest>=7.0", "twine>=4.0.1"],
+    },
+    python_requires='>=3.7',
+)
```

