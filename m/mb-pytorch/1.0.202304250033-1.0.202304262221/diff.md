# Comparing `tmp/mb_pytorch-1.0.202304250033-py3-none-any.whl.zip` & `tmp/mb_pytorch-1.0.202304262221-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,18 +1,20 @@
-Zip file size: 32960 bytes, number of entries: 37
--rw-rw-r--  2.0 unx     6483 b- defN 23-Apr-24 00:14 mb_pytorch/classification/training.py
+Zip file size: 38116 bytes, number of entries: 39
+-rw-rw-r--  2.0 unx     6485 b- defN 23-Apr-26 22:13 mb_pytorch/classification/training.py
 -rw-rw-r--  2.0 unx       44 b- defN 23-Mar-16 11:39 mb_pytorch/dataloader/__init__.py
 -rw-rw-r--  2.0 unx    12981 b- defN 23-Apr-19 01:00 mb_pytorch/dataloader/loader.py
+-rw-rw-r--  2.0 unx     6476 b- defN 23-Apr-25 00:59 mb_pytorch/detection/training.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Feb-23 13:56 mb_pytorch/metalearning/__init__.py
 -rw-rw-r--  2.0 unx     1385 b- defN 23-Mar-02 03:28 mb_pytorch/metalearning/meta_utils.py
 -rw-rw-r--  2.0 unx     1030 b- defN 23-Mar-15 02:58 mb_pytorch/metalearning/proto_dataloader.py
 -rw-rw-r--  2.0 unx     2861 b- defN 23-Mar-03 23:55 mb_pytorch/metalearning/prototypical.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Mar-31 19:54 mb_pytorch/models/__init__.py
+-rw-rw-r--  2.0 unx    20215 b- defN 23-Apr-26 22:20 mb_pytorch/models/extra_models.py
 -rw-rw-r--  2.0 unx      920 b- defN 23-Mar-12 03:33 mb_pytorch/models/lenet.py
--rw-rw-r--  2.0 unx     4591 b- defN 23-Apr-21 01:06 mb_pytorch/models/modelloader.py
+-rw-rw-r--  2.0 unx     3675 b- defN 23-Apr-26 22:13 mb_pytorch/models/modelloader.py
 -rw-rw-r--  2.0 unx    10784 b- defN 23-Apr-01 03:27 mb_pytorch/models/unet_models.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Mar-31 19:54 mb_pytorch/models/blocks/__init__.py
 -rw-rw-r--  2.0 unx     2801 b- defN 23-Apr-01 00:43 mb_pytorch/models/blocks/attention_block.py
 -rw-rw-r--  2.0 unx     3629 b- defN 23-Mar-23 00:49 mb_pytorch/models/blocks/cnn.py
 -rw-rw-r--  2.0 unx     4783 b- defN 23-Mar-23 04:50 mb_pytorch/models/blocks/conv_block.py
 -rw-rw-r--  2.0 unx      920 b- defN 23-Mar-17 22:06 mb_pytorch/models/blocks/conv_with_relu.py
 -rw-rw-r--  2.0 unx     2256 b- defN 23-Mar-23 14:45 mb_pytorch/models/blocks/model_out.py
@@ -26,14 +28,14 @@
 -rw-rw-r--  2.0 unx      257 b- defN 23-Mar-01 22:55 mb_pytorch/utils/dist.py
 -rw-rw-r--  2.0 unx     3391 b- defN 23-Apr-11 23:28 mb_pytorch/utils/extra_utils.py
 -rw-rw-r--  2.0 unx     7178 b- defN 23-Mar-15 02:58 mb_pytorch/utils/generate_emb.py
 -rw-rw-r--  2.0 unx     2582 b- defN 23-Apr-03 19:30 mb_pytorch/utils/losses.py
 -rw-rw-r--  2.0 unx     1199 b- defN 23-Apr-04 20:14 mb_pytorch/utils/metrics.py
 -rw-rw-r--  2.0 unx    10502 b- defN 23-Apr-25 00:33 mb_pytorch/utils/viewer.py
 -rw-rw-r--  2.0 unx      994 b- defN 23-Mar-06 13:11 mb_pytorch/utils/yaml_reader.py
--rwxrwxr-x  2.0 unx     1304 b- defN 23-Apr-25 00:34 mb_pytorch-1.0.202304250033.data/scripts/dataload_results.py
--rwxrwxr-x  2.0 unx      980 b- defN 23-Mar-15 02:59 mb_pytorch-1.0.202304250033.data/scripts/emb.py
--rw-rw-r--  2.0 unx      329 b- defN 23-Apr-25 00:34 mb_pytorch-1.0.202304250033.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 23-Apr-25 00:34 mb_pytorch-1.0.202304250033.dist-info/WHEEL
--rw-rw-r--  2.0 unx       11 b- defN 23-Apr-25 00:34 mb_pytorch-1.0.202304250033.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     3349 b- defN 23-Apr-25 00:34 mb_pytorch-1.0.202304250033.dist-info/RECORD
-37 files, 97903 bytes uncompressed, 27494 bytes compressed:  71.9%
+-rwxrwxr-x  2.0 unx     1304 b- defN 23-Apr-26 22:22 mb_pytorch-1.0.202304262221.data/scripts/dataload_results.py
+-rwxrwxr-x  2.0 unx      980 b- defN 23-Mar-15 02:59 mb_pytorch-1.0.202304262221.data/scripts/emb.py
+-rw-rw-r--  2.0 unx      329 b- defN 23-Apr-26 22:22 mb_pytorch-1.0.202304262221.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 23-Apr-26 22:22 mb_pytorch-1.0.202304262221.dist-info/WHEEL
+-rw-rw-r--  2.0 unx       11 b- defN 23-Apr-26 22:22 mb_pytorch-1.0.202304262221.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     3529 b- defN 23-Apr-26 22:22 mb_pytorch-1.0.202304262221.dist-info/RECORD
+39 files, 123860 bytes uncompressed, 32368 bytes compressed:  73.9%
```

## zipnote {}

```diff
@@ -3,14 +3,17 @@
 
 Filename: mb_pytorch/dataloader/__init__.py
 Comment: 
 
 Filename: mb_pytorch/dataloader/loader.py
 Comment: 
 
+Filename: mb_pytorch/detection/training.py
+Comment: 
+
 Filename: mb_pytorch/metalearning/__init__.py
 Comment: 
 
 Filename: mb_pytorch/metalearning/meta_utils.py
 Comment: 
 
 Filename: mb_pytorch/metalearning/proto_dataloader.py
@@ -18,14 +21,17 @@
 
 Filename: mb_pytorch/metalearning/prototypical.py
 Comment: 
 
 Filename: mb_pytorch/models/__init__.py
 Comment: 
 
+Filename: mb_pytorch/models/extra_models.py
+Comment: 
+
 Filename: mb_pytorch/models/lenet.py
 Comment: 
 
 Filename: mb_pytorch/models/modelloader.py
 Comment: 
 
 Filename: mb_pytorch/models/unet_models.py
@@ -87,26 +93,26 @@
 
 Filename: mb_pytorch/utils/viewer.py
 Comment: 
 
 Filename: mb_pytorch/utils/yaml_reader.py
 Comment: 
 
-Filename: mb_pytorch-1.0.202304250033.data/scripts/dataload_results.py
+Filename: mb_pytorch-1.0.202304262221.data/scripts/dataload_results.py
 Comment: 
 
-Filename: mb_pytorch-1.0.202304250033.data/scripts/emb.py
+Filename: mb_pytorch-1.0.202304262221.data/scripts/emb.py
 Comment: 
 
-Filename: mb_pytorch-1.0.202304250033.dist-info/METADATA
+Filename: mb_pytorch-1.0.202304262221.dist-info/METADATA
 Comment: 
 
-Filename: mb_pytorch-1.0.202304250033.dist-info/WHEEL
+Filename: mb_pytorch-1.0.202304262221.dist-info/WHEEL
 Comment: 
 
-Filename: mb_pytorch-1.0.202304250033.dist-info/top_level.txt
+Filename: mb_pytorch-1.0.202304262221.dist-info/top_level.txt
 Comment: 
 
-Filename: mb_pytorch-1.0.202304250033.dist-info/RECORD
+Filename: mb_pytorch-1.0.202304262221.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## mb_pytorch/classification/training.py

```diff
@@ -85,34 +85,32 @@
                     if grad_img is not None:
                         grad_img = np.transpose(grad_img,(2,0,1))
                         writer.add_image(f'Gradcam training/{cam_layers}',grad_img,global_step=i)
                     if j == 0:
                         if grad_img is None:
                             if logger:
                                 logger.info(f'Gradcam not supported for {cam_layers}')            
-
-            
-            
+                        
         #validation loop
 
         val_loss = 0
         val_acc = 0
         new_val_loss = 0
     
         with torch.no_grad():
-            for x_val, y_val in val_loader:
+            for l,(x_val, y_val) in val_loader:
                 x_val, y_val = x_val.to(device), y_val.to(device)
                 output = model(x_val)
                 val_loss += loss_attr(output, y_val).item() * x_val.size(0)
                 _, preds = torch.max(output, 1) #no need of softmax. max returns the index of the max value
                 val_acc += torch.sum(preds == y_val.data)
                 new_val_loss = val_loss/x_val.size(0)
                 #num_samples += x_val.size(0)
                 if logger: 
-                    logger.info(f'Epoch {i+1} - Batch {j+1} - Val Loss: {new_val_loss:.3f}')
+                    logger.info(f'Epoch {i+1} - Batch {l+1} - Val Loss: {new_val_loss:.3f}')
             
             avg_val_loss = val_loss / len(val_loader.dataset)
             val_acc = val_acc/len(val_loader.dataset)
             #val_loss /= num_samples
             #val_acc = val_acc / num_samples
             if logger:
                 logger.info(f'Epoch {i+1} -Avg Val Loss: {avg_val_loss:.3f}')
```

## mb_pytorch/models/modelloader.py

```diff
@@ -6,15 +6,15 @@
 import torchvision.models as models
 import os
 import importlib
 
 __all__ = ['ModelLoader','ModelExtractor']
 
 
-def get_custome_model(data):
+def get_custom_model(data):
     """
     Function to get custom model from the models folder
     """
     model_name = data['model_name']
     model_custom = data['model_custom']
     model_module = importlib.import_module(model_custom)
     if model_name=='Unet':
@@ -27,86 +27,70 @@
 
 class ModelLoader(nn.Module):
     def __init__(self, data : dict,logger=None):
         super().__init__()
         self._data= data 
         self._use_torchvision_models=self._data['use_torchvision_models']
         self._model_name=self._data['model_name']
-        self._model_version=self._data['model_version']
         self._model_path=self._data['model_path']
         self._model_pretrained=self._data['model_pretrained']
         self._load_model = self._data['load_model']
         self._model_num_classes = self._data['model_num_classes']
         self._model_type=self._data['model_type']
-        if self._model_version==None:
-            self._model_version=''
-        self._model_final_name = self._model_name + self._model_version
 
     def model_type(self):
         """
         Function to get default model resnet, vgg, densenet, googlenet, inception, mobilenet, mnasnet, shufflenet_v2, squeezenet
         """
-        model_out = getattr(torchvision.models,self._model_final_name)(pretrained=self._model_pretrained)
+        model_out = getattr(torchvision.models,self._model_name)(pretrained=self._model_pretrained)
         if self._model_type=='classification':
             if hasattr(model_out,'fc'):
                 num_ftrs = model_out.fc.in_features
                 model_out.fc = nn.Linear(num_ftrs, self._model_num_classes)            
             if hasattr(model_out,'classifier'):
                 for module in list(model_out.modules()):
                     if isinstance(module, nn.Linear):
                         first_layer = module
                         num_ftrs = first_layer.in_features
                         model_out.classifier = nn.Linear(num_ftrs, self._model_num_classes)
                         break
-            #model_out.softmax = nn.Softmax(dim=1)
-        
-            
-        #     for module in reversed(list(model_out.modules())):
-        #         if isinstance(module, nn.Linear):
-        #             last_layer = module
-        #             num_ftrs = last_layer.in_features
-        #             model_out.classifier = nn.Linear(num_ftrs, self._model_num_classes)
-        #             break
+                    
         return model_out
 
     def model_params(self):
         """
         Function to pass the model params to custom model
         """        
         #check if model is available in the models list
-        model_out = get_custome_model(self._data)
+        model_out = get_custom_model(self._data)
         return model_out
         
 
     def get_model(self):
         """
         FUnction to get the model
         """
         # Check if the model is available in torchvision models
 
         if self._load_model:
             self.model = torch.load(self._data['load_model'])
             return self.model
 
-        if self._use_torchvision_models:
-            try:
-                # Try to load the model from the specified path
-                if hasattr(models, self._model_final_name):
-                    #model_class = getattr(models, self._model_name)
-                    #if self._model_name in ['resnet', 'vgg', 'densenet', 'googlenet', 'inception', 'mobilenet', 'mnasnet', 'shufflenet_v2', 'squeezenet']:
-                        # These models have pretrained weights available
-                    self.model = self.model_type() 
-                    if logger:
-                        logger.info(f"Model {self._model_name} loaded from torchvision.models.") 
-            except FileNotFoundError:
-                raise ValueError(f"Model {self._model_name} not found in torchvision.models.")
-
-        else:
-            self.model = self.model_params()
-        return self.model
+        try:
+            # Try to load the model from the specified path
+            if hasattr(models, self._model_final_name):
+                self.model = self.model_type() 
+                if logger:
+                    logger.info(f"Model {self._model_name} loaded from torchvision.models.") 
+                return self.model
+            else:
+                self.model = self.model_params()
+                return self.model
+        except FileNotFoundError:
+            raise ValueError(f"Model {self._model_name} not found in torchvision.models.")
     
     def forward(self,x):
         return self.model(x)
     
 
 class ModelExtractor(nn.Module):
     def __init__(self, model):
```

## Comparing `mb_pytorch-1.0.202304250033.data/scripts/dataload_results.py` & `mb_pytorch-1.0.202304262221.data/scripts/dataload_results.py`

 * *Files identical despite different names*

## Comparing `mb_pytorch-1.0.202304250033.data/scripts/emb.py` & `mb_pytorch-1.0.202304262221.data/scripts/emb.py`

 * *Files identical despite different names*

## Comparing `mb_pytorch-1.0.202304250033.dist-info/RECORD` & `mb_pytorch-1.0.202304262221.dist-info/RECORD`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,19 @@
-mb_pytorch/classification/training.py,sha256=jTGa-Adph4Ytik2dR90Iw2oUVSnpQ9hBzzrmiqyuZt8,6483
+mb_pytorch/classification/training.py,sha256=T2H4nGnnWicFDdWfm5RQKD_xKKAxbH0zXT7ocQR3OO8,6485
 mb_pytorch/dataloader/__init__.py,sha256=nB0xPAHbI91Ra1dDkWR1l4td5A4k9xko-I5Jdgv5apI,44
 mb_pytorch/dataloader/loader.py,sha256=Cn6N9MYVRxpm-fZznk6uu0nzdWCPQWKyK93DNVlKUvk,12981
+mb_pytorch/detection/training.py,sha256=7fyZGU-zgwULf51dOzDlmJQvqS1acUhkO7rknBpHUCU,6476
 mb_pytorch/metalearning/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mb_pytorch/metalearning/meta_utils.py,sha256=mgHYiQIIcYQ1pVTJcrjquSXpQstdYD1q8iXO09Zao1s,1385
 mb_pytorch/metalearning/proto_dataloader.py,sha256=WvrfZYkYMxorocCkR_zHS_AC8W_ML9YndB-P6evkdcc,1030
 mb_pytorch/metalearning/prototypical.py,sha256=qFVf6VF3s8zskGqbM3geJV-dfkdO3tRaf3P8U_KR-cE,2861
 mb_pytorch/models/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+mb_pytorch/models/extra_models.py,sha256=F1Owng-lMowbxHuQ4SP9D5nkuBuX6ksbXOvsxxlXgoo,20215
 mb_pytorch/models/lenet.py,sha256=vZpN0LsfVGNI6z91YO3GLPCVB9Sv0EAxaTwEavRSKKo,920
-mb_pytorch/models/modelloader.py,sha256=wDR0Od_-n-4qXC8Lqk2pigtQLWiBA40cQftG-S4GUT4,4591
+mb_pytorch/models/modelloader.py,sha256=ICniWVValIawrjdvMnscZv-WszTbBWrQnG04RbE-w4w,3675
 mb_pytorch/models/unet_models.py,sha256=8AYw1MaFRUPLkfyyPmAaVZol2lRY28oiTjZRgZVRa4s,10784
 mb_pytorch/models/blocks/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mb_pytorch/models/blocks/attention_block.py,sha256=jMkfI79upW-PDc28dQ17s34gUR0gCpMB0XIpGgFDE_Q,2801
 mb_pytorch/models/blocks/cnn.py,sha256=IFPDIkKb-LyfzqK9RshqzNidSDdfrRmMylADYvWGACE,3629
 mb_pytorch/models/blocks/conv_block.py,sha256=vlcJiBwkbbmhQMpGLzQA0S14Wkw1Ai9adSbOquFBk0c,4783
 mb_pytorch/models/blocks/conv_with_relu.py,sha256=WIwJBfzvp-kE8QY6Ts5wg0ioJAcJIvmqKLpSl46j_II,920
 mb_pytorch/models/blocks/model_out.py,sha256=JmtY1zHCtkj-RbEVhQ8e6EvXd5WWVLrP9Lb_FigO7rA,2256
@@ -25,13 +27,13 @@
 mb_pytorch/utils/dist.py,sha256=7-ZdntmiugRWYnT5wileo8mYTuV1dbjVl4ffJsfnfAw,257
 mb_pytorch/utils/extra_utils.py,sha256=-MaT-x3gwgEOVLpg-tWm5yLFtI0CxpV0QUlXx-rqu08,3391
 mb_pytorch/utils/generate_emb.py,sha256=2iK8wRIrYfaLpEgjdbFnDqGU5ux-1JhncQoeboW_6LQ,7178
 mb_pytorch/utils/losses.py,sha256=OLCPLkJH46IofSSVly2xdcklVv7Q5OFFEGtVrJcV7V0,2582
 mb_pytorch/utils/metrics.py,sha256=Kqmdu9llSjR8aRp3IVlmy6PqeQexf0ZXjTJUcEtvcfI,1199
 mb_pytorch/utils/viewer.py,sha256=oXOdgE7GNeg3aC6tTYq0-Lz47LO7ELWY-z-fQUgbUaE,10502
 mb_pytorch/utils/yaml_reader.py,sha256=Azgr_5qttsH_BBVsCtfccFMvK6IEjTRYhd5qp4S5uzk,994
-mb_pytorch-1.0.202304250033.data/scripts/dataload_results.py,sha256=8IFAH7WX-nSJ7V532rr3Cl7R37v0jhSakw0JCd9dalE,1304
-mb_pytorch-1.0.202304250033.data/scripts/emb.py,sha256=5jSbTGNOhusDTvHZeaTwk4pmJa4HIdkRGd98s0L4Rl0,980
-mb_pytorch-1.0.202304250033.dist-info/METADATA,sha256=ggc4cXga1fIJ_KX3a-dPFJ5zRh7ZWuAGgYQJdy0oY7Y,329
-mb_pytorch-1.0.202304250033.dist-info/WHEEL,sha256=g4nMs7d-Xl9-xC9XovUrsDHGXt-FT0E17Yqo92DEfvY,92
-mb_pytorch-1.0.202304250033.dist-info/top_level.txt,sha256=2m_aBiEfjq3pZM2NtYSlTqlgoQxH6WaK8_8SsRicIvg,11
-mb_pytorch-1.0.202304250033.dist-info/RECORD,,
+mb_pytorch-1.0.202304262221.data/scripts/dataload_results.py,sha256=8IFAH7WX-nSJ7V532rr3Cl7R37v0jhSakw0JCd9dalE,1304
+mb_pytorch-1.0.202304262221.data/scripts/emb.py,sha256=5jSbTGNOhusDTvHZeaTwk4pmJa4HIdkRGd98s0L4Rl0,980
+mb_pytorch-1.0.202304262221.dist-info/METADATA,sha256=E6bIeoZK9FTXB-5Hs1F5bqyFjuUbXDDzX0BgNJX9lIY,329
+mb_pytorch-1.0.202304262221.dist-info/WHEEL,sha256=g4nMs7d-Xl9-xC9XovUrsDHGXt-FT0E17Yqo92DEfvY,92
+mb_pytorch-1.0.202304262221.dist-info/top_level.txt,sha256=2m_aBiEfjq3pZM2NtYSlTqlgoQxH6WaK8_8SsRicIvg,11
+mb_pytorch-1.0.202304262221.dist-info/RECORD,,
```

