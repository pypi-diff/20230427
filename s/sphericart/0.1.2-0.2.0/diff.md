# Comparing `tmp/sphericart-0.1.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.zip` & `tmp/sphericart-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.zip`

## zipinfo {}

```diff
@@ -1,17 +1,17 @@
-Zip file size: 96853 bytes, number of entries: 15
-drwxr-xr-x  2.0 unx        0 b- stor 23-Feb-18 04:56 sphericart.libs/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Feb-18 04:56 sphericart-0.1.2.dist-info/
-drwxr-xr-x  2.0 unx        0 b- stor 23-Feb-18 04:56 sphericart/
--rwxr-xr-x  2.0 unx   168193 b- defN 23-Feb-18 04:56 sphericart.libs/libgomp-a34b3233.so.1.0.0
--rwxrwxrwx  2.0 unx       11 b- defN 23-Feb-18 04:56 sphericart-0.1.2.dist-info/top_level.txt
--rw-r--r--  2.0 unx    11357 b- defN 23-Feb-18 04:56 sphericart-0.1.2.dist-info/LICENSE
--rw-r--r--  2.0 unx      148 b- defN 23-Feb-18 04:56 sphericart-0.1.2.dist-info/WHEEL
--rw-r--r--  2.0 unx      792 b- defN 23-Feb-18 04:56 sphericart-0.1.2.dist-info/METADATA
--rw-rw-r--  2.0 unx      925 b- defN 23-Feb-18 04:56 sphericart-0.1.2.dist-info/RECORD
-drwxr-xr-x  2.0 unx        0 b- stor 23-Feb-18 04:56 sphericart/lib/
--rw-r--r--  2.0 unx       52 b- defN 23-Feb-18 04:56 sphericart/__init__.py
--rw-r--r--  2.0 unx     1033 b- defN 23-Feb-18 04:56 sphericart/wrappers.py
--rw-r--r--  2.0 unx      744 b- defN 23-Feb-18 04:56 sphericart/library.py
--rw-r--r--  2.0 unx     2391 b- defN 23-Feb-18 04:56 sphericart/spherical_harmonics.py
--rwxr-xr-x  2.0 unx    54929 b- defN 23-Feb-18 04:56 sphericart/lib/libsphericart.so
-15 files, 240575 bytes uncompressed, 94865 bytes compressed:  60.6%
+Zip file size: 104784 bytes, number of entries: 15
+drwxr-xr-x  2.0 unx        0 b- stor 23-Feb-20 13:23 sphericart.libs/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Feb-20 13:23 sphericart-0.2.0.dist-info/
+drwxr-xr-x  2.0 unx        0 b- stor 23-Feb-20 13:23 sphericart/
+-rwxr-xr-x  2.0 unx   168193 b- defN 23-Feb-20 13:23 sphericart.libs/libgomp-a34b3233.so.1.0.0
+-rwxrwxrwx  2.0 unx       11 b- defN 23-Feb-20 13:23 sphericart-0.2.0.dist-info/top_level.txt
+-rw-r--r--  2.0 unx    11357 b- defN 23-Feb-20 13:23 sphericart-0.2.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx      148 b- defN 23-Feb-20 13:23 sphericart-0.2.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx      792 b- defN 23-Feb-20 13:23 sphericart-0.2.0.dist-info/METADATA
+-rw-rw-r--  2.0 unx      925 b- defN 23-Feb-20 13:23 sphericart-0.2.0.dist-info/RECORD
+drwxr-xr-x  2.0 unx        0 b- stor 23-Feb-20 13:23 sphericart/lib/
+-rw-r--r--  2.0 unx       52 b- defN 23-Feb-20 13:23 sphericart/__init__.py
+-rw-r--r--  2.0 unx     1033 b- defN 23-Feb-20 13:23 sphericart/wrappers.py
+-rw-r--r--  2.0 unx      744 b- defN 23-Feb-20 13:23 sphericart/library.py
+-rw-r--r--  2.0 unx     2391 b- defN 23-Feb-20 13:23 sphericart/spherical_harmonics.py
+-rwxr-xr-x  2.0 unx    71545 b- defN 23-Feb-20 13:23 sphericart/lib/libsphericart.so
+15 files, 257191 bytes uncompressed, 102796 bytes compressed:  60.0%
```

## zipnote {}

```diff
@@ -1,32 +1,32 @@
 Filename: sphericart.libs/
 Comment: 
 
-Filename: sphericart-0.1.2.dist-info/
+Filename: sphericart-0.2.0.dist-info/
 Comment: 
 
 Filename: sphericart/
 Comment: 
 
 Filename: sphericart.libs/libgomp-a34b3233.so.1.0.0
 Comment: 
 
-Filename: sphericart-0.1.2.dist-info/top_level.txt
+Filename: sphericart-0.2.0.dist-info/top_level.txt
 Comment: 
 
-Filename: sphericart-0.1.2.dist-info/LICENSE
+Filename: sphericart-0.2.0.dist-info/LICENSE
 Comment: 
 
-Filename: sphericart-0.1.2.dist-info/WHEEL
+Filename: sphericart-0.2.0.dist-info/WHEEL
 Comment: 
 
-Filename: sphericart-0.1.2.dist-info/METADATA
+Filename: sphericart-0.2.0.dist-info/METADATA
 Comment: 
 
-Filename: sphericart-0.1.2.dist-info/RECORD
+Filename: sphericart-0.2.0.dist-info/RECORD
 Comment: 
 
 Filename: sphericart/lib/
 Comment: 
 
 Filename: sphericart/__init__.py
 Comment:
```

## sphericart/lib/libsphericart.so

### readelf --wide --file-header {}

```diff
@@ -4,17 +4,17 @@
   Data:                              2's complement, little endian
   Version:                           1 (current)
   OS/ABI:                            UNIX - System V
   ABI Version:                       0
   Type:                              DYN (Shared object file)
   Machine:                           Advanced Micro Devices X86-64
   Version:                           0x1
-  Entry point address:               0x1120
+  Entry point address:               0x1170
   Start of program headers:          64 (bytes into file)
-  Start of section headers:          44248 (bytes into file)
+  Start of section headers:          61056 (bytes into file)
   Flags:                             0x0
   Size of this header:               64 (bytes)
   Size of program headers:           56 (bytes)
   Number of program headers:         11
   Size of section headers:           64 (bytes)
   Number of section headers:         27
   Section header string table index: 21
```

### readelf --wide --program-header {}

```diff
@@ -1,25 +1,25 @@
 
 Elf file type is DYN (Shared object file)
-Entry point 0x1120
+Entry point 0x1170
 There are 11 program headers, starting at offset 64
 
 Program Headers:
   Type           Offset   VirtAddr           PhysAddr           FileSiz  MemSiz   Flg Align
-  LOAD           0x000000 0x0000000000000000 0x0000000000000000 0x0009a8 0x0009a8 R   0x1000
+  LOAD           0x000000 0x0000000000000000 0x0000000000000000 0x000b30 0x000b30 R   0x1000
   GNU_STACK      0x000000 0x0000000000000000 0x0000000000000000 0x000000 0x000000 RW  0x10
-  LOAD           0x001000 0x0000000000001000 0x0000000000001000 0x0079f1 0x0079f1 R E 0x1000
-  LOAD           0x009000 0x0000000000009000 0x0000000000009000 0x000a00 0x000a00 R   0x1000
-  GNU_EH_FRAME   0x009660 0x0000000000009660 0x0000000000009660 0x00009c 0x00009c R   0x4
-  LOAD           0x009dd8 0x000000000000add8 0x000000000000add8 0x0002b8 0x0002c0 RW  0x1000
-  GNU_RELRO      0x009dd8 0x000000000000add8 0x000000000000add8 0x000228 0x000228 R   0x1
-  NOTE           0x00c000 0x000000000000c000 0x000000000000c000 0x000024 0x000024 R   0x4
-  LOAD           0x00c000 0x000000000000c000 0x000000000000c000 0x0002c0 0x0002c0 RW  0x1000
-  LOAD           0x00d000 0x000000000000d000 0x000000000000d000 0x000690 0x000690 RW  0x1000
-  DYNAMIC        0x00d228 0x000000000000d228 0x000000000000d228 0x000200 0x000200 RW  0x8
+  LOAD           0x001000 0x0000000000001000 0x0000000000001000 0x00b2f1 0x00b2f1 R E 0x1000
+  LOAD           0x00d000 0x000000000000d000 0x000000000000d000 0x000d7c 0x000d7c R   0x1000
+  GNU_EH_FRAME   0x00d840 0x000000000000d840 0x000000000000d840 0x0000dc 0x0000dc R   0x4
+  LOAD           0x00ddd8 0x000000000000edd8 0x000000000000edd8 0x0002e0 0x0002e8 RW  0x1000
+  GNU_RELRO      0x00ddd8 0x000000000000edd8 0x000000000000edd8 0x000228 0x000228 R   0x1
+  NOTE           0x010000 0x0000000000010000 0x0000000000010000 0x000024 0x000024 R   0x4
+  LOAD           0x010000 0x0000000000010000 0x0000000000010000 0x000358 0x000358 RW  0x1000
+  LOAD           0x011000 0x0000000000011000 0x0000000000011000 0x000778 0x000778 RW  0x1000
+  DYNAMIC        0x0112a0 0x00000000000112a0 0x00000000000112a0 0x000200 0x000200 RW  0x8
 
  Section to Segment mapping:
   Segment Sections...
    00     .gnu.version .gnu.version_r .rela.dyn .rela.plt 
    01     
    02     .init .plt .text .fini 
    03     .rodata .eh_frame_hdr .eh_frame
```

### readelf --wide --sections {}

```diff
@@ -1,36 +1,36 @@
-There are 27 section headers, starting at offset 0xacd8:
+There are 27 section headers, starting at offset 0xee80:
 
 Section Headers:
   [Nr] Name              Type            Address          Off    Size   ES Flg Lk Inf Al
   [ 0]                   NULL            0000000000000000 000000 000000 00      0   0  0
-  [ 1] .gnu.version      VERSYM          0000000000000704 000704 00002e 02   A 24   0  2
-  [ 2] .gnu.version_r    VERNEED         0000000000000738 000738 000060 00   A 26   2  8
-  [ 3] .rela.dyn         RELA            0000000000000798 000798 0000a8 18   A 24   0  8
-  [ 4] .rela.plt         RELA            0000000000000840 000840 000168 18  AI 24  16  8
+  [ 1] .gnu.version      VERSYM          0000000000000810 000810 000038 02   A 24   0  2
+  [ 2] .gnu.version_r    VERNEED         0000000000000848 000848 000060 00   A 26   2  8
+  [ 3] .rela.dyn         RELA            00000000000008a8 0008a8 0000a8 18   A 24   0  8
+  [ 4] .rela.plt         RELA            0000000000000950 000950 0001e0 18  AI 24  16  8
   [ 5] .init             PROGBITS        0000000000001000 001000 00001a 00  AX  0   0  4
-  [ 6] .plt              PROGBITS        0000000000001020 001020 000100 10  AX  0   0 16
-  [ 7] .text             PROGBITS        0000000000001120 001120 0078c8 00  AX  0   0 16
-  [ 8] .fini             PROGBITS        00000000000089e8 0089e8 000009 00  AX  0   0  4
-  [ 9] .rodata           PROGBITS        0000000000009000 009000 000660 00   A  0   0 32
-  [10] .eh_frame_hdr     PROGBITS        0000000000009660 009660 00009c 00   A  0   0  4
-  [11] .eh_frame         PROGBITS        0000000000009700 009700 000300 00   A  0   0  8
-  [12] .init_array       INIT_ARRAY      000000000000add8 009dd8 000008 08  WA  0   0  8
-  [13] .fini_array       FINI_ARRAY      000000000000ade0 009de0 000008 08  WA  0   0  8
-  [14] .data.rel.ro      PROGBITS        000000000000ade8 009de8 000008 00  WA  0   0  8
-  [15] .got              PROGBITS        000000000000afe0 009fe0 000020 08  WA  0   0  8
-  [16] .got.plt          PROGBITS        000000000000b000 00a000 000090 08  WA  0   0  8
-  [17] .bss              NOBITS          000000000000b090 00a090 000008 00  WA  0   0  1
-  [18] .comment          PROGBITS        0000000000000000 00a090 00002f 01  MS  0   0  1
-  [19] .symtab           SYMTAB          0000000000000000 00a0c0 0006a8 18     20  49  8
-  [20] .strtab           STRTAB          0000000000000000 00a768 000476 00      0   0  1
-  [21] .shstrtab         STRTAB          0000000000000000 00abde 0000f4 00      0   0  1
-  [22] .note.gnu.build-id NOTE            000000000000c000 00c000 000024 00   A  0   0  4
-  [23] .gnu.hash         GNU_HASH        000000000000c028 00c028 000050 00   A 24   0  8
-  [24] .dynsym           DYNSYM          000000000000d000 00d000 000228 18   A 26   1  8
-  [25] .dynamic          DYNAMIC         000000000000d228 00d228 000200 10  WA 26   0  8
-  [26] .dynstr           STRTAB          000000000000d428 00d428 000263 00   A  0   0  8
+  [ 6] .plt              PROGBITS        0000000000001020 001020 000150 10  AX  0   0 16
+  [ 7] .text             PROGBITS        0000000000001170 001170 00b178 00  AX  0   0 16
+  [ 8] .fini             PROGBITS        000000000000c2e8 00c2e8 000009 00  AX  0   0  4
+  [ 9] .rodata           PROGBITS        000000000000d000 00d000 000840 00   A  0   0 32
+  [10] .eh_frame_hdr     PROGBITS        000000000000d840 00d840 0000dc 00   A  0   0  4
+  [11] .eh_frame         PROGBITS        000000000000d920 00d920 00045c 00   A  0   0  8
+  [12] .init_array       INIT_ARRAY      000000000000edd8 00ddd8 000008 08  WA  0   0  8
+  [13] .fini_array       FINI_ARRAY      000000000000ede0 00dde0 000008 08  WA  0   0  8
+  [14] .data.rel.ro      PROGBITS        000000000000ede8 00dde8 000008 00  WA  0   0  8
+  [15] .got              PROGBITS        000000000000efe0 00dfe0 000020 08  WA  0   0  8
+  [16] .got.plt          PROGBITS        000000000000f000 00e000 0000b8 08  WA  0   0  8
+  [17] .bss              NOBITS          000000000000f0b8 00e0b8 000008 00  WA  0   0  1
+  [18] .comment          PROGBITS        0000000000000000 00e0b8 00002f 01  MS  0   0  1
+  [19] .symtab           SYMTAB          0000000000000000 00e0e8 000768 18     20  52  8
+  [20] .strtab           STRTAB          0000000000000000 00e850 00053a 00      0   0  1
+  [21] .shstrtab         STRTAB          0000000000000000 00ed8a 0000f4 00      0   0  1
+  [22] .note.gnu.build-id NOTE            0000000000010000 010000 000024 00   A  0   0  4
+  [23] .gnu.hash         GNU_HASH        0000000000010028 010028 00006c 00   A 24   0  8
+  [24] .dynsym           DYNSYM          0000000000011000 011000 0002a0 18   A 26   1  8
+  [25] .dynamic          DYNAMIC         00000000000112a0 0112a0 000200 10  WA 26   0  8
+  [26] .dynstr           STRTAB          00000000000114a0 0114a0 0002d8 00   A  0   0  8
 Key to Flags:
   W (write), A (alloc), X (execute), M (merge), S (strings), I (info),
   L (link order), O (extra OS processing required), G (group), T (TLS),
   C (compressed), x (unknown), o (OS specific), E (exclude),
   D (mbind), l (large), p (processor specific)
```

### readelf --wide --symbols {}

```diff
@@ -1,100 +1,113 @@
 
-Symbol table '.symtab' contains 71 entries:
+Symbol table '.symtab' contains 79 entries:
    Num:    Value          Size Type    Bind   Vis      Ndx Name
      0: 0000000000000000     0 NOTYPE  LOCAL  DEFAULT  UND 
-     1: 000000000000c000     0 SECTION LOCAL  DEFAULT   22 .note.gnu.build-id
-     2: 000000000000c028     0 SECTION LOCAL  DEFAULT   23 .gnu.hash
-     3: 000000000000d000     0 SECTION LOCAL  DEFAULT   24 .dynsym
-     4: 000000000000d428     0 SECTION LOCAL  DEFAULT   26 .dynstr
-     5: 0000000000000704     0 SECTION LOCAL  DEFAULT    1 .gnu.version
-     6: 0000000000000738     0 SECTION LOCAL  DEFAULT    2 .gnu.version_r
-     7: 0000000000000798     0 SECTION LOCAL  DEFAULT    3 .rela.dyn
-     8: 0000000000000840     0 SECTION LOCAL  DEFAULT    4 .rela.plt
+     1: 0000000000010000     0 SECTION LOCAL  DEFAULT   22 .note.gnu.build-id
+     2: 0000000000010028     0 SECTION LOCAL  DEFAULT   23 .gnu.hash
+     3: 0000000000011000     0 SECTION LOCAL  DEFAULT   24 .dynsym
+     4: 00000000000114a0     0 SECTION LOCAL  DEFAULT   26 .dynstr
+     5: 0000000000000810     0 SECTION LOCAL  DEFAULT    1 .gnu.version
+     6: 0000000000000848     0 SECTION LOCAL  DEFAULT    2 .gnu.version_r
+     7: 00000000000008a8     0 SECTION LOCAL  DEFAULT    3 .rela.dyn
+     8: 0000000000000950     0 SECTION LOCAL  DEFAULT    4 .rela.plt
      9: 0000000000001000     0 SECTION LOCAL  DEFAULT    5 .init
     10: 0000000000001020     0 SECTION LOCAL  DEFAULT    6 .plt
-    11: 0000000000001120     0 SECTION LOCAL  DEFAULT    7 .text
-    12: 00000000000089e8     0 SECTION LOCAL  DEFAULT    8 .fini
-    13: 0000000000009000     0 SECTION LOCAL  DEFAULT    9 .rodata
-    14: 0000000000009660     0 SECTION LOCAL  DEFAULT   10 .eh_frame_hdr
-    15: 0000000000009700     0 SECTION LOCAL  DEFAULT   11 .eh_frame
-    16: 000000000000add8     0 SECTION LOCAL  DEFAULT   12 .init_array
-    17: 000000000000ade0     0 SECTION LOCAL  DEFAULT   13 .fini_array
-    18: 000000000000ade8     0 SECTION LOCAL  DEFAULT   14 .data.rel.ro
-    19: 000000000000d228     0 SECTION LOCAL  DEFAULT   25 .dynamic
-    20: 000000000000afe0     0 SECTION LOCAL  DEFAULT   15 .got
-    21: 000000000000b000     0 SECTION LOCAL  DEFAULT   16 .got.plt
-    22: 000000000000b090     0 SECTION LOCAL  DEFAULT   17 .bss
+    11: 0000000000001170     0 SECTION LOCAL  DEFAULT    7 .text
+    12: 000000000000c2e8     0 SECTION LOCAL  DEFAULT    8 .fini
+    13: 000000000000d000     0 SECTION LOCAL  DEFAULT    9 .rodata
+    14: 000000000000d840     0 SECTION LOCAL  DEFAULT   10 .eh_frame_hdr
+    15: 000000000000d920     0 SECTION LOCAL  DEFAULT   11 .eh_frame
+    16: 000000000000edd8     0 SECTION LOCAL  DEFAULT   12 .init_array
+    17: 000000000000ede0     0 SECTION LOCAL  DEFAULT   13 .fini_array
+    18: 000000000000ede8     0 SECTION LOCAL  DEFAULT   14 .data.rel.ro
+    19: 00000000000112a0     0 SECTION LOCAL  DEFAULT   25 .dynamic
+    20: 000000000000efe0     0 SECTION LOCAL  DEFAULT   15 .got
+    21: 000000000000f000     0 SECTION LOCAL  DEFAULT   16 .got.plt
+    22: 000000000000f0b8     0 SECTION LOCAL  DEFAULT   17 .bss
     23: 0000000000000000     0 SECTION LOCAL  DEFAULT   18 .comment
     24: 0000000000000000     0 FILE    LOCAL  DEFAULT  ABS crtstuff.c
-    25: 0000000000001120     0 FUNC    LOCAL  DEFAULT    7 deregister_tm_clones
-    26: 0000000000001150     0 FUNC    LOCAL  DEFAULT    7 register_tm_clones
-    27: 0000000000001190     0 FUNC    LOCAL  DEFAULT    7 __do_global_dtors_aux
-    28: 000000000000b090     1 OBJECT  LOCAL  DEFAULT   17 completed.0
-    29: 000000000000ade0     0 OBJECT  LOCAL  DEFAULT   13 __do_global_dtors_aux_fini_array_entry
-    30: 00000000000011d0     0 FUNC    LOCAL  DEFAULT    7 frame_dummy
-    31: 000000000000add8     0 OBJECT  LOCAL  DEFAULT   12 __frame_dummy_init_array_entry
+    25: 0000000000001170     0 FUNC    LOCAL  DEFAULT    7 deregister_tm_clones
+    26: 00000000000011a0     0 FUNC    LOCAL  DEFAULT    7 register_tm_clones
+    27: 00000000000011e0     0 FUNC    LOCAL  DEFAULT    7 __do_global_dtors_aux
+    28: 000000000000f0b8     1 OBJECT  LOCAL  DEFAULT   17 completed.0
+    29: 000000000000ede0     0 OBJECT  LOCAL  DEFAULT   13 __do_global_dtors_aux_fini_array_entry
+    30: 0000000000001220     0 FUNC    LOCAL  DEFAULT    7 frame_dummy
+    31: 000000000000edd8     0 OBJECT  LOCAL  DEFAULT   12 __frame_dummy_init_array_entry
     32: 0000000000000000     0 FILE    LOCAL  DEFAULT  ABS sphericart.c
-    33: 00000000000011e0   568 FUNC    LOCAL  DEFAULT    7 cartesian_spherical_harmonics_l0._omp_fn.0
-    34: 0000000000001420  2350 FUNC    LOCAL  DEFAULT    7 cartesian_spherical_harmonics_l1._omp_fn.0
-    35: 0000000000001d50   937 FUNC    LOCAL  DEFAULT    7 cartesian_spherical_harmonics_l2._omp_fn.0
-    36: 0000000000002100  3554 FUNC    LOCAL  DEFAULT    7 cartesian_spherical_harmonics_generic._omp_fn.0
-    37: 0000000000002ef0  4992 FUNC    LOCAL  DEFAULT    7 cartesian_spherical_harmonics_l3._omp_fn.0
-    38: 0000000000004270  8028 FUNC    LOCAL  DEFAULT    7 cartesian_spherical_harmonics._omp_fn.0
-    39: 00000000000061d0  3417 FUNC    LOCAL  DEFAULT    7 cartesian_spherical_harmonics_l4._omp_fn.0
-    40: 0000000000006f30  5561 FUNC    LOCAL  DEFAULT    7 cartesian_spherical_harmonics_l5._omp_fn.0
-    41: 0000000000000000     0 FILE    LOCAL  DEFAULT  ABS crtstuff.c
-    42: 00000000000099fc     0 OBJECT  LOCAL  DEFAULT   11 __FRAME_END__
-    43: 0000000000000000     0 FILE    LOCAL  DEFAULT  ABS 
-    44: 000000000000ade8     0 OBJECT  LOCAL  DEFAULT   14 __dso_handle
-    45: 000000000000adf0     0 OBJECT  LOCAL  DEFAULT   25 _DYNAMIC
-    46: 0000000000009660     0 NOTYPE  LOCAL  DEFAULT   10 __GNU_EH_FRAME_HDR
-    47: 000000000000b090     0 OBJECT  LOCAL  DEFAULT   16 __TMC_END__
-    48: 000000000000b000     0 OBJECT  LOCAL  DEFAULT   16 _GLOBAL_OFFSET_TABLE_
-    49: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND free@@GLIBC_2.2.5
-    50: 0000000000008900   232 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics
-    51: 0000000000000000     0 NOTYPE  WEAK   DEFAULT  UND _ITM_deregisterTMCloneTable
-    52: 0000000000008760    53 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_l1
-    53: 00000000000087e0    53 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_l3
-    54: 0000000000008860    53 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_l5
-    55: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND GOMP_barrier@@GOMP_1.0
-    56: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND omp_get_thread_num@@OMP_1.0
-    57: 00000000000084f0   573 FUNC    GLOBAL DEFAULT    7 compute_sph_prefactors
-    58: 00000000000089e8     0 FUNC    GLOBAL DEFAULT    8 _fini
-    59: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND omp_get_num_threads@@OMP_1.0
-    60: 0000000000000000     0 NOTYPE  WEAK   DEFAULT  UND __gmon_start__
-    61: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND malloc@@GLIBC_2.2.5
-    62: 0000000000008730    48 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_l0
-    63: 00000000000087a0    53 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_l2
-    64: 0000000000008820    53 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_l4
-    65: 0000000000000000     0 NOTYPE  GLOBAL DEFAULT  UND sqrt
-    66: 00000000000088a0    85 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_generic
-    67: 0000000000000000     0 NOTYPE  WEAK   DEFAULT  UND _ITM_registerTMCloneTable
-    68: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND GOMP_parallel@@GOMP_4.0
-    69: 0000000000000000     0 FUNC    WEAK   DEFAULT  UND __cxa_finalize@@GLIBC_2.2.5
-    70: 0000000000001000     0 FUNC    GLOBAL DEFAULT    5 _init
+    33: 0000000000001230   568 FUNC    LOCAL  DEFAULT    7 cartesian_spherical_harmonics_l0._omp_fn.0
+    34: 0000000000001470  2328 FUNC    LOCAL  DEFAULT    7 cartesian_spherical_harmonics_l1._omp_fn.0
+    35: 0000000000001d90   937 FUNC    LOCAL  DEFAULT    7 cartesian_spherical_harmonics_l2._omp_fn.0
+    36: 0000000000002140  4921 FUNC    LOCAL  DEFAULT    7 cartesian_spherical_harmonics_l3._omp_fn.0
+    37: 0000000000003480  3353 FUNC    LOCAL  DEFAULT    7 cartesian_spherical_harmonics_l4._omp_fn.0
+    38: 00000000000041a0  5417 FUNC    LOCAL  DEFAULT    7 cartesian_spherical_harmonics_l5._omp_fn.0
+    39: 00000000000056d0  8361 FUNC    LOCAL  DEFAULT    7 cartesian_spherical_harmonics_l6._omp_fn.0
+    40: 0000000000007780  1572 FUNC    LOCAL  DEFAULT    7 _compute_no_dsph._omp_fn.0
+    41: 0000000000007db0  3104 FUNC    LOCAL  DEFAULT    7 _compute_with_dsph._omp_fn.0
+    42: 00000000000089d0  3837 FUNC    LOCAL  DEFAULT    7 _compute_highl_no_dsph._omp_fn.0
+    43: 00000000000098d0  9185 FUNC    LOCAL  DEFAULT    7 _compute_highl_with_dsph._omp_fn.0
+    44: 0000000000000000     0 FILE    LOCAL  DEFAULT  ABS crtstuff.c
+    45: 000000000000dd78     0 OBJECT  LOCAL  DEFAULT   11 __FRAME_END__
+    46: 0000000000000000     0 FILE    LOCAL  DEFAULT  ABS 
+    47: 000000000000ede8     0 OBJECT  LOCAL  DEFAULT   14 __dso_handle
+    48: 000000000000edf0     0 OBJECT  LOCAL  DEFAULT   25 _DYNAMIC
+    49: 000000000000d840     0 NOTYPE  LOCAL  DEFAULT   10 __GNU_EH_FRAME_HDR
+    50: 000000000000f0b8     0 OBJECT  LOCAL  DEFAULT   16 __TMC_END__
+    51: 000000000000f000     0 OBJECT  LOCAL  DEFAULT   16 _GLOBAL_OFFSET_TABLE_
+    52: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND free@@GLIBC_2.2.5
+    53: 000000000000c230   184 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics
+    54: 0000000000000000     0 NOTYPE  WEAK   DEFAULT  UND _ITM_deregisterTMCloneTable
+    55: 000000000000bf30    53 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_l1
+    56: 000000000000bfb0    53 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_l3
+    57: 000000000000c030    53 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_l5
+    58: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND GOMP_barrier@@GOMP_1.0
+    59: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND omp_get_thread_num@@OMP_1.0
+    60: 000000000000bcc0   573 FUNC    GLOBAL DEFAULT    7 compute_sph_prefactors
+    61: 000000000000c2e8     0 FUNC    GLOBAL DEFAULT    8 _fini
+    62: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND omp_get_num_threads@@OMP_1.0
+    63: 000000000000c100    85 FUNC    GLOBAL DEFAULT    7 _compute_with_dsph
+    64: 000000000000c0b0    65 FUNC    GLOBAL DEFAULT    7 _compute_no_dsph
+    65: 0000000000000000     0 NOTYPE  WEAK   DEFAULT  UND __gmon_start__
+    66: 000000000000c180    65 FUNC    GLOBAL DEFAULT    7 _compute_highl_no_dsph
+    67: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND malloc@@GLIBC_2.2.5
+    68: 000000000000c1d0    85 FUNC    GLOBAL DEFAULT    7 _compute_highl_with_dsph
+    69: 000000000000bf00    48 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_l0
+    70: 000000000000bf70    53 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_l2
+    71: 000000000000bff0    53 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_l4
+    72: 000000000000c070    53 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_l6
+    73: 0000000000000000     0 NOTYPE  GLOBAL DEFAULT  UND sqrt
+    74: 000000000000c160    21 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_generic
+    75: 0000000000000000     0 NOTYPE  WEAK   DEFAULT  UND _ITM_registerTMCloneTable
+    76: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND GOMP_parallel@@GOMP_4.0
+    77: 0000000000000000     0 FUNC    WEAK   DEFAULT  UND __cxa_finalize@@GLIBC_2.2.5
+    78: 0000000000001000     0 FUNC    GLOBAL DEFAULT    5 _init
 
-Symbol table '.dynsym' contains 23 entries:
+Symbol table '.dynsym' contains 28 entries:
    Num:    Value          Size Type    Bind   Vis      Ndx Name
      0: 0000000000000000     0 NOTYPE  LOCAL  DEFAULT  UND 
      1: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND free@GLIBC_2.2.5 (2)
      2: 0000000000000000     0 NOTYPE  WEAK   DEFAULT  UND _ITM_deregisterTMCloneTable
      3: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND GOMP_barrier@GOMP_1.0 (3)
      4: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND omp_get_thread_num@OMP_1.0 (4)
      5: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND omp_get_num_threads@OMP_1.0 (4)
      6: 0000000000000000     0 NOTYPE  WEAK   DEFAULT  UND __gmon_start__
      7: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND malloc@GLIBC_2.2.5 (2)
      8: 0000000000000000     0 NOTYPE  GLOBAL DEFAULT  UND sqrt
      9: 0000000000000000     0 NOTYPE  WEAK   DEFAULT  UND _ITM_registerTMCloneTable
     10: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND GOMP_parallel@GOMP_4.0 (5)
     11: 0000000000000000     0 FUNC    WEAK   DEFAULT  UND __cxa_finalize@GLIBC_2.2.5 (2)
-    12: 0000000000008900   232 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics
-    13: 00000000000087e0    53 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_l3
-    14: 0000000000008730    48 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_l0
-    15: 0000000000008760    53 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_l1
-    16: 00000000000084f0   573 FUNC    GLOBAL DEFAULT    7 compute_sph_prefactors
-    17: 0000000000008820    53 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_l4
-    18: 00000000000088a0    85 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_generic
-    19: 0000000000001000     0 FUNC    GLOBAL DEFAULT    5 _init
-    20: 0000000000008860    53 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_l5
-    21: 00000000000089e8     0 FUNC    GLOBAL DEFAULT    8 _fini
-    22: 00000000000087a0    53 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_l2
+    12: 000000000000c230   184 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics
+    13: 000000000000bfb0    53 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_l3
+    14: 000000000000c100    85 FUNC    GLOBAL DEFAULT    7 _compute_with_dsph
+    15: 000000000000c180    65 FUNC    GLOBAL DEFAULT    7 _compute_highl_no_dsph
+    16: 000000000000bf00    48 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_l0
+    17: 000000000000c070    53 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_l6
+    18: 000000000000bf30    53 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_l1
+    19: 000000000000bcc0   573 FUNC    GLOBAL DEFAULT    7 compute_sph_prefactors
+    20: 000000000000c0b0    65 FUNC    GLOBAL DEFAULT    7 _compute_no_dsph
+    21: 000000000000c1d0    85 FUNC    GLOBAL DEFAULT    7 _compute_highl_with_dsph
+    22: 000000000000bff0    53 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_l4
+    23: 000000000000c160    21 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_generic
+    24: 0000000000001000     0 FUNC    GLOBAL DEFAULT    5 _init
+    25: 000000000000c030    53 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_l5
+    26: 000000000000c2e8     0 FUNC    GLOBAL DEFAULT    8 _fini
+    27: 000000000000bf70    53 FUNC    GLOBAL DEFAULT    7 cartesian_spherical_harmonics_l2
```

### readelf --wide --relocs {}

```diff
@@ -1,28 +1,33 @@
 
-Relocation section '.rela.dyn' at offset 0x798 contains 7 entries:
+Relocation section '.rela.dyn' at offset 0x8a8 contains 7 entries:
     Offset             Info             Type               Symbol's Value  Symbol's Name + Addend
-000000000000add8  0000000000000008 R_X86_64_RELATIVE                         11d0
-000000000000ade0  0000000000000008 R_X86_64_RELATIVE                         1190
-000000000000ade8  0000000000000008 R_X86_64_RELATIVE                         ade8
-000000000000afe0  0000000200000006 R_X86_64_GLOB_DAT      0000000000000000 _ITM_deregisterTMCloneTable + 0
-000000000000afe8  0000000600000006 R_X86_64_GLOB_DAT      0000000000000000 __gmon_start__ + 0
-000000000000aff0  0000000900000006 R_X86_64_GLOB_DAT      0000000000000000 _ITM_registerTMCloneTable + 0
-000000000000aff8  0000000b00000006 R_X86_64_GLOB_DAT      0000000000000000 __cxa_finalize@GLIBC_2.2.5 + 0
+000000000000edd8  0000000000000008 R_X86_64_RELATIVE                         1220
+000000000000ede0  0000000000000008 R_X86_64_RELATIVE                         11e0
+000000000000ede8  0000000000000008 R_X86_64_RELATIVE                         ede8
+000000000000efe0  0000000200000006 R_X86_64_GLOB_DAT      0000000000000000 _ITM_deregisterTMCloneTable + 0
+000000000000efe8  0000000600000006 R_X86_64_GLOB_DAT      0000000000000000 __gmon_start__ + 0
+000000000000eff0  0000000900000006 R_X86_64_GLOB_DAT      0000000000000000 _ITM_registerTMCloneTable + 0
+000000000000eff8  0000000b00000006 R_X86_64_GLOB_DAT      0000000000000000 __cxa_finalize@GLIBC_2.2.5 + 0
 
-Relocation section '.rela.plt' at offset 0x840 contains 15 entries:
+Relocation section '.rela.plt' at offset 0x950 contains 20 entries:
     Offset             Info             Type               Symbol's Value  Symbol's Name + Addend
-000000000000b018  0000000100000007 R_X86_64_JUMP_SLOT     0000000000000000 free@GLIBC_2.2.5 + 0
-000000000000b020  0000000f00000007 R_X86_64_JUMP_SLOT     0000000000008760 cartesian_spherical_harmonics_l1 + 0
-000000000000b028  0000000d00000007 R_X86_64_JUMP_SLOT     00000000000087e0 cartesian_spherical_harmonics_l3 + 0
-000000000000b030  0000001400000007 R_X86_64_JUMP_SLOT     0000000000008860 cartesian_spherical_harmonics_l5 + 0
-000000000000b038  0000000300000007 R_X86_64_JUMP_SLOT     0000000000000000 GOMP_barrier@GOMP_1.0 + 0
-000000000000b040  0000000400000007 R_X86_64_JUMP_SLOT     0000000000000000 omp_get_thread_num@OMP_1.0 + 0
-000000000000b048  0000000500000007 R_X86_64_JUMP_SLOT     0000000000000000 omp_get_num_threads@OMP_1.0 + 0
-000000000000b050  0000000600000007 R_X86_64_JUMP_SLOT     0000000000000000 __gmon_start__ + 0
-000000000000b058  0000000700000007 R_X86_64_JUMP_SLOT     0000000000000000 malloc@GLIBC_2.2.5 + 0
-000000000000b060  0000000e00000007 R_X86_64_JUMP_SLOT     0000000000008730 cartesian_spherical_harmonics_l0 + 0
-000000000000b068  0000001600000007 R_X86_64_JUMP_SLOT     00000000000087a0 cartesian_spherical_harmonics_l2 + 0
-000000000000b070  0000001100000007 R_X86_64_JUMP_SLOT     0000000000008820 cartesian_spherical_harmonics_l4 + 0
-000000000000b078  0000000800000007 R_X86_64_JUMP_SLOT     0000000000000000 sqrt + 0
-000000000000b080  0000000a00000007 R_X86_64_JUMP_SLOT     0000000000000000 GOMP_parallel@GOMP_4.0 + 0
-000000000000b088  0000000b00000007 R_X86_64_JUMP_SLOT     0000000000000000 __cxa_finalize@GLIBC_2.2.5 + 0
+000000000000f018  0000000100000007 R_X86_64_JUMP_SLOT     0000000000000000 free@GLIBC_2.2.5 + 0
+000000000000f020  0000001200000007 R_X86_64_JUMP_SLOT     000000000000bf30 cartesian_spherical_harmonics_l1 + 0
+000000000000f028  0000000d00000007 R_X86_64_JUMP_SLOT     000000000000bfb0 cartesian_spherical_harmonics_l3 + 0
+000000000000f030  0000001900000007 R_X86_64_JUMP_SLOT     000000000000c030 cartesian_spherical_harmonics_l5 + 0
+000000000000f038  0000000300000007 R_X86_64_JUMP_SLOT     0000000000000000 GOMP_barrier@GOMP_1.0 + 0
+000000000000f040  0000000400000007 R_X86_64_JUMP_SLOT     0000000000000000 omp_get_thread_num@OMP_1.0 + 0
+000000000000f048  0000000500000007 R_X86_64_JUMP_SLOT     0000000000000000 omp_get_num_threads@OMP_1.0 + 0
+000000000000f050  0000000e00000007 R_X86_64_JUMP_SLOT     000000000000c100 _compute_with_dsph + 0
+000000000000f058  0000001400000007 R_X86_64_JUMP_SLOT     000000000000c0b0 _compute_no_dsph + 0
+000000000000f060  0000000600000007 R_X86_64_JUMP_SLOT     0000000000000000 __gmon_start__ + 0
+000000000000f068  0000000f00000007 R_X86_64_JUMP_SLOT     000000000000c180 _compute_highl_no_dsph + 0
+000000000000f070  0000000700000007 R_X86_64_JUMP_SLOT     0000000000000000 malloc@GLIBC_2.2.5 + 0
+000000000000f078  0000001500000007 R_X86_64_JUMP_SLOT     000000000000c1d0 _compute_highl_with_dsph + 0
+000000000000f080  0000001000000007 R_X86_64_JUMP_SLOT     000000000000bf00 cartesian_spherical_harmonics_l0 + 0
+000000000000f088  0000001b00000007 R_X86_64_JUMP_SLOT     000000000000bf70 cartesian_spherical_harmonics_l2 + 0
+000000000000f090  0000001600000007 R_X86_64_JUMP_SLOT     000000000000bff0 cartesian_spherical_harmonics_l4 + 0
+000000000000f098  0000001100000007 R_X86_64_JUMP_SLOT     000000000000c070 cartesian_spherical_harmonics_l6 + 0
+000000000000f0a0  0000000800000007 R_X86_64_JUMP_SLOT     0000000000000000 sqrt + 0
+000000000000f0a8  0000000a00000007 R_X86_64_JUMP_SLOT     0000000000000000 GOMP_parallel@GOMP_4.0 + 0
+000000000000f0b0  0000000b00000007 R_X86_64_JUMP_SLOT     0000000000000000 __cxa_finalize@GLIBC_2.2.5 + 0
```

### readelf --wide --dynamic {}

```diff
@@ -1,31 +1,31 @@
 
-Dynamic section at offset 0xd228 contains 28 entries:
+Dynamic section at offset 0x112a0 contains 28 entries:
   Tag        Type                         Name/Value
  0x000000000000000f (RPATH)              Library rpath: [$ORIGIN/../../sphericart.libs]
  0x0000000000000001 (NEEDED)             Shared library: [libgomp-a34b3233.so.1.0.0]
  0x0000000000000001 (NEEDED)             Shared library: [libpthread.so.0]
  0x0000000000000001 (NEEDED)             Shared library: [libc.so.6]
  0x000000000000000e (SONAME)             Library soname: [libsphericart.so]
  0x000000000000000c (INIT)               0x1000
- 0x000000000000000d (FINI)               0x89e8
- 0x0000000000000019 (INIT_ARRAY)         0xadd8
+ 0x000000000000000d (FINI)               0xc2e8
+ 0x0000000000000019 (INIT_ARRAY)         0xedd8
  0x000000000000001b (INIT_ARRAYSZ)       8 (bytes)
- 0x000000000000001a (FINI_ARRAY)         0xade0
+ 0x000000000000001a (FINI_ARRAY)         0xede0
  0x000000000000001c (FINI_ARRAYSZ)       8 (bytes)
- 0x000000006ffffef5 (GNU_HASH)           0xc028
- 0x0000000000000005 (STRTAB)             0xd428
- 0x0000000000000006 (SYMTAB)             0xd000
- 0x000000000000000a (STRSZ)              611 (bytes)
+ 0x000000006ffffef5 (GNU_HASH)           0x10028
+ 0x0000000000000005 (STRTAB)             0x114a0
+ 0x0000000000000006 (SYMTAB)             0x11000
+ 0x000000000000000a (STRSZ)              728 (bytes)
  0x000000000000000b (SYMENT)             24 (bytes)
- 0x0000000000000003 (PLTGOT)             0xb000
- 0x0000000000000002 (PLTRELSZ)           360 (bytes)
+ 0x0000000000000003 (PLTGOT)             0xf000
+ 0x0000000000000002 (PLTRELSZ)           480 (bytes)
  0x0000000000000014 (PLTREL)             RELA
- 0x0000000000000017 (JMPREL)             0x840
- 0x0000000000000007 (RELA)               0x798
+ 0x0000000000000017 (JMPREL)             0x950
+ 0x0000000000000007 (RELA)               0x8a8
  0x0000000000000008 (RELASZ)             168 (bytes)
  0x0000000000000009 (RELAENT)            24 (bytes)
- 0x000000006ffffffe (VERNEED)            0x738
+ 0x000000006ffffffe (VERNEED)            0x848
  0x000000006fffffff (VERNEEDNUM)         2
- 0x000000006ffffff0 (VERSYM)             0x704
+ 0x000000006ffffff0 (VERSYM)             0x810
  0x000000006ffffff9 (RELACOUNT)          3
  0x0000000000000000 (NULL)               0x0
```

### readelf --wide --notes {}

```diff
@@ -1,4 +1,4 @@
 
 Displaying notes found in: .note.gnu.build-id
   Owner                Data size 	Description
-  GNU                  0x00000014	NT_GNU_BUILD_ID (unique build ID bitstring)	    Build ID: 6e0ad9c0699664ac6a843e11624ff664903d12db
+  GNU                  0x00000014	NT_GNU_BUILD_ID (unique build ID bitstring)	    Build ID: 21be971b720c79459e4dd241d81dd92b0a12d37a
```

### readelf --wide --version-info {}

```diff
@@ -1,18 +1,19 @@
 
-Version symbols section '.gnu.version' contains 23 entries:
- Addr: 0x0000000000000704  Offset: 0x00000704  Link: 24 (.dynsym)
+Version symbols section '.gnu.version' contains 28 entries:
+ Addr: 0x0000000000000810  Offset: 0x00000810  Link: 24 (.dynsym)
   000:   0 (*local*)       2 (GLIBC_2.2.5)   0 (*local*)       3 (GOMP_1.0)   
   004:   4 (OMP_1.0)       4 (OMP_1.0)       0 (*local*)       2 (GLIBC_2.2.5)
   008:   0 (*local*)       0 (*local*)       5 (GOMP_4.0)      2 (GLIBC_2.2.5)
   00c:   1 (*global*)      1 (*global*)      1 (*global*)      1 (*global*)   
   010:   1 (*global*)      1 (*global*)      1 (*global*)      1 (*global*)   
-  014:   1 (*global*)      1 (*global*)      1 (*global*)   
+  014:   1 (*global*)      1 (*global*)      1 (*global*)      1 (*global*)   
+  018:   1 (*global*)      1 (*global*)      1 (*global*)      1 (*global*)   
 
 Version needs section '.gnu.version_r' contains 2 entries:
- Addr: 0x0000000000000738  Offset: 0x00000738  Link: 26 (.dynstr)
+ Addr: 0x0000000000000848  Offset: 0x00000848  Link: 26 (.dynstr)
   000000: Version: 1  File: libgomp-a34b3233.so.1.0.0  Cnt: 3
   0x0010:   Name: GOMP_4.0  Flags: none  Version: 5
   0x0020:   Name: OMP_1.0  Flags: none  Version: 4
   0x0030:   Name: GOMP_1.0  Flags: none  Version: 3
   0x0040: Version: 1  File: libc.so.6  Cnt: 1
   0x0050:   Name: GLIBC_2.2.5  Flags: none  Version: 2
```

### readelf --wide --debug-dump=frames {}

```diff
@@ -9,311 +9,465 @@
   Return address column: 16
   Augmentation data:     1b
   DW_CFA_def_cfa: r7 (rsp) ofs 8
   DW_CFA_offset: r16 (rip) at cfa-8
   DW_CFA_nop
   DW_CFA_nop
 
-00000018 0000000000000024 0000001c FDE cie=00000000 pc=0000000000001020..0000000000001120
+00000018 0000000000000024 0000001c FDE cie=00000000 pc=0000000000001020..0000000000001170
   DW_CFA_def_cfa_offset: 16
   DW_CFA_advance_loc: 6 to 0000000000001026
   DW_CFA_def_cfa_offset: 24
   DW_CFA_advance_loc: 10 to 0000000000001030
   DW_CFA_def_cfa_expression (DW_OP_breg7 (rsp): 8; DW_OP_breg16 (rip): 0; DW_OP_lit15; DW_OP_and; DW_OP_lit11; DW_OP_ge; DW_OP_lit3; DW_OP_shl; DW_OP_plus)
   DW_CFA_nop
   DW_CFA_nop
   DW_CFA_nop
   DW_CFA_nop
 
-00000040 0000000000000028 00000044 FDE cie=00000000 pc=00000000000011e0..0000000000001418
-  DW_CFA_advance_loc: 1 to 00000000000011e1
+00000040 0000000000000028 00000044 FDE cie=00000000 pc=0000000000001230..0000000000001468
+  DW_CFA_advance_loc: 1 to 0000000000001231
   DW_CFA_def_cfa_offset: 16
   DW_CFA_offset: r6 (rbp) at cfa-16
-  DW_CFA_advance_loc: 3 to 00000000000011e4
+  DW_CFA_advance_loc: 3 to 0000000000001234
   DW_CFA_def_cfa_register: r6 (rbp)
-  DW_CFA_advance_loc: 4 to 00000000000011e8
+  DW_CFA_advance_loc: 4 to 0000000000001238
   DW_CFA_offset: r13 (r13) at cfa-24
   DW_CFA_offset: r12 (r12) at cfa-32
-  DW_CFA_advance_loc: 8 to 00000000000011f0
+  DW_CFA_advance_loc: 8 to 0000000000001240
   DW_CFA_offset: r3 (rbx) at cfa-40
-  DW_CFA_advance_loc2: 286 to 000000000000130e
+  DW_CFA_advance_loc2: 286 to 000000000000135e
   DW_CFA_remember_state
   DW_CFA_def_cfa: r7 (rsp) ofs 8
-  DW_CFA_advance_loc: 2 to 0000000000001310
+  DW_CFA_advance_loc: 2 to 0000000000001360
   DW_CFA_restore_state
   DW_CFA_nop
   DW_CFA_nop
 
-0000006c 000000000000003c 00000070 FDE cie=00000000 pc=0000000000001420..0000000000001d4e
-  DW_CFA_advance_loc: 1 to 0000000000001421
+0000006c 000000000000003c 00000070 FDE cie=00000000 pc=0000000000001470..0000000000001d88
+  DW_CFA_advance_loc: 1 to 0000000000001471
   DW_CFA_def_cfa_offset: 16
   DW_CFA_offset: r6 (rbp) at cfa-16
-  DW_CFA_advance_loc: 3 to 0000000000001424
+  DW_CFA_advance_loc: 3 to 0000000000001474
   DW_CFA_def_cfa_register: r6 (rbp)
-  DW_CFA_advance_loc: 4 to 0000000000001428
+  DW_CFA_advance_loc: 4 to 0000000000001478
   DW_CFA_offset: r15 (r15) at cfa-24
   DW_CFA_offset: r14 (r14) at cfa-32
-  DW_CFA_advance_loc: 16 to 0000000000001438
+  DW_CFA_advance_loc: 16 to 0000000000001488
   DW_CFA_offset: r13 (r13) at cfa-40
   DW_CFA_offset: r12 (r12) at cfa-48
   DW_CFA_offset: r3 (rbx) at cfa-56
-  DW_CFA_advance_loc2: 1251 to 000000000000191b
+  DW_CFA_advance_loc2: 1241 to 0000000000001961
   DW_CFA_remember_state
   DW_CFA_def_cfa: r7 (rsp) ofs 8
-  DW_CFA_advance_loc: 5 to 0000000000001920
+  DW_CFA_advance_loc: 15 to 0000000000001970
   DW_CFA_restore_state
-  DW_CFA_advance_loc1: 170 to 00000000000019ca
+  DW_CFA_advance_loc1: 163 to 0000000000001a13
   DW_CFA_remember_state
   DW_CFA_def_cfa: r7 (rsp) ofs 8
-  DW_CFA_advance_loc: 6 to 00000000000019d0
+  DW_CFA_advance_loc: 13 to 0000000000001a20
   DW_CFA_restore_state
-  DW_CFA_advance_loc2: 704 to 0000000000001c90
+  DW_CFA_advance_loc2: 695 to 0000000000001cd7
   DW_CFA_remember_state
   DW_CFA_def_cfa: r7 (rsp) ofs 8
-  DW_CFA_advance_loc: 16 to 0000000000001ca0
+  DW_CFA_advance_loc: 9 to 0000000000001ce0
   DW_CFA_restore_state
   DW_CFA_nop
 
-000000ac 0000000000000034 000000b0 FDE cie=00000000 pc=0000000000001d50..00000000000020f9
-  DW_CFA_advance_loc: 1 to 0000000000001d51
+000000ac 0000000000000034 000000b0 FDE cie=00000000 pc=0000000000001d90..0000000000002139
+  DW_CFA_advance_loc: 1 to 0000000000001d91
   DW_CFA_def_cfa_offset: 16
   DW_CFA_offset: r6 (rbp) at cfa-16
-  DW_CFA_advance_loc: 3 to 0000000000001d54
+  DW_CFA_advance_loc: 3 to 0000000000001d94
   DW_CFA_def_cfa_register: r6 (rbp)
-  DW_CFA_advance_loc: 4 to 0000000000001d58
+  DW_CFA_advance_loc: 4 to 0000000000001d98
   DW_CFA_offset: r15 (r15) at cfa-24
   DW_CFA_offset: r14 (r14) at cfa-32
-  DW_CFA_advance_loc: 12 to 0000000000001d64
+  DW_CFA_advance_loc: 12 to 0000000000001da4
   DW_CFA_offset: r13 (r13) at cfa-40
   DW_CFA_offset: r12 (r12) at cfa-48
   DW_CFA_offset: r3 (rbx) at cfa-56
-  DW_CFA_advance_loc2: 598 to 0000000000001fba
+  DW_CFA_advance_loc2: 591 to 0000000000001ff3
   DW_CFA_remember_state
   DW_CFA_def_cfa: r7 (rsp) ofs 8
-  DW_CFA_advance_loc: 6 to 0000000000001fc0
+  DW_CFA_advance_loc: 13 to 0000000000002000
   DW_CFA_restore_state
-  DW_CFA_advance_loc2: 282 to 00000000000020da
+  DW_CFA_advance_loc2: 272 to 0000000000002110
   DW_CFA_remember_state
   DW_CFA_def_cfa: r7 (rsp) ofs 8
-  DW_CFA_advance_loc: 6 to 00000000000020e0
+  DW_CFA_advance_loc: 16 to 0000000000002120
   DW_CFA_restore_state
   DW_CFA_nop
 
-000000e4 000000000000002c 000000e8 FDE cie=00000000 pc=0000000000002100..0000000000002ee2
-  DW_CFA_advance_loc: 1 to 0000000000002101
+000000e4 0000000000000034 000000e8 FDE cie=00000000 pc=0000000000002140..0000000000003479
+  DW_CFA_advance_loc: 1 to 0000000000002141
   DW_CFA_def_cfa_offset: 16
   DW_CFA_offset: r6 (rbp) at cfa-16
-  DW_CFA_advance_loc: 3 to 0000000000002104
+  DW_CFA_advance_loc: 3 to 0000000000002144
   DW_CFA_def_cfa_register: r6 (rbp)
-  DW_CFA_advance_loc: 20 to 0000000000002118
+  DW_CFA_advance_loc: 4 to 0000000000002148
   DW_CFA_offset: r15 (r15) at cfa-24
   DW_CFA_offset: r14 (r14) at cfa-32
+  DW_CFA_advance_loc: 19 to 000000000000215b
   DW_CFA_offset: r13 (r13) at cfa-40
   DW_CFA_offset: r12 (r12) at cfa-48
   DW_CFA_offset: r3 (rbx) at cfa-56
-  DW_CFA_advance_loc2: 1738 to 00000000000027e2
+  DW_CFA_advance_loc2: 1273 to 0000000000002654
   DW_CFA_remember_state
   DW_CFA_def_cfa: r7 (rsp) ofs 8
-  DW_CFA_advance_loc: 14 to 00000000000027f0
+  DW_CFA_advance_loc: 12 to 0000000000002660
+  DW_CFA_restore_state
+  DW_CFA_advance_loc2: 3045 to 0000000000003245
+  DW_CFA_remember_state
+  DW_CFA_def_cfa: r7 (rsp) ofs 8
+  DW_CFA_advance_loc: 11 to 0000000000003250
   DW_CFA_restore_state
-  DW_CFA_nop
-  DW_CFA_nop
   DW_CFA_nop
 
-00000114 0000000000000034 00000118 FDE cie=00000000 pc=0000000000002ef0..0000000000004270
-  DW_CFA_advance_loc: 1 to 0000000000002ef1
+0000011c 000000000000002c 00000120 FDE cie=00000000 pc=0000000000003480..0000000000004199
+  DW_CFA_advance_loc: 1 to 0000000000003481
   DW_CFA_def_cfa_offset: 16
   DW_CFA_offset: r6 (rbp) at cfa-16
-  DW_CFA_advance_loc: 3 to 0000000000002ef4
+  DW_CFA_advance_loc: 3 to 0000000000003484
   DW_CFA_def_cfa_register: r6 (rbp)
-  DW_CFA_advance_loc: 4 to 0000000000002ef8
+  DW_CFA_advance_loc: 4 to 0000000000003488
   DW_CFA_offset: r15 (r15) at cfa-24
   DW_CFA_offset: r14 (r14) at cfa-32
-  DW_CFA_advance_loc: 19 to 0000000000002f0b
+  DW_CFA_advance_loc: 15 to 0000000000003497
   DW_CFA_offset: r13 (r13) at cfa-40
   DW_CFA_offset: r12 (r12) at cfa-48
   DW_CFA_offset: r3 (rbx) at cfa-56
-  DW_CFA_advance_loc2: 1294 to 0000000000003419
-  DW_CFA_remember_state
-  DW_CFA_def_cfa: r7 (rsp) ofs 8
-  DW_CFA_advance_loc: 7 to 0000000000003420
-  DW_CFA_restore_state
-  DW_CFA_advance_loc2: 3075 to 0000000000004023
+  DW_CFA_advance_loc2: 2313 to 0000000000003da0
   DW_CFA_remember_state
   DW_CFA_def_cfa: r7 (rsp) ofs 8
-  DW_CFA_advance_loc: 13 to 0000000000004030
+  DW_CFA_advance_loc: 16 to 0000000000003db0
   DW_CFA_restore_state
   DW_CFA_nop
+  DW_CFA_nop
 
-0000014c 000000000000002c 00000150 FDE cie=00000000 pc=0000000000004270..00000000000061cc
-  DW_CFA_advance_loc: 1 to 0000000000004271
+0000014c 000000000000002c 00000150 FDE cie=00000000 pc=00000000000041a0..00000000000056c9
+  DW_CFA_advance_loc: 1 to 00000000000041a1
   DW_CFA_def_cfa_offset: 16
   DW_CFA_offset: r6 (rbp) at cfa-16
-  DW_CFA_advance_loc: 3 to 0000000000004274
+  DW_CFA_advance_loc: 3 to 00000000000041a4
   DW_CFA_def_cfa_register: r6 (rbp)
-  DW_CFA_advance_loc: 20 to 0000000000004288
+  DW_CFA_advance_loc: 4 to 00000000000041a8
   DW_CFA_offset: r15 (r15) at cfa-24
   DW_CFA_offset: r14 (r14) at cfa-32
+  DW_CFA_advance_loc: 15 to 00000000000041b7
   DW_CFA_offset: r13 (r13) at cfa-40
   DW_CFA_offset: r12 (r12) at cfa-48
   DW_CFA_offset: r3 (rbx) at cfa-56
-  DW_CFA_advance_loc2: 7908 to 000000000000616c
+  DW_CFA_advance_loc2: 3879 to 00000000000050de
   DW_CFA_remember_state
   DW_CFA_def_cfa: r7 (rsp) ofs 8
-  DW_CFA_advance_loc: 5 to 0000000000006171
+  DW_CFA_advance_loc: 2 to 00000000000050e0
   DW_CFA_restore_state
   DW_CFA_nop
   DW_CFA_nop
-  DW_CFA_nop
 
-0000017c 000000000000002c 00000180 FDE cie=00000000 pc=00000000000061d0..0000000000006f29
-  DW_CFA_advance_loc: 1 to 00000000000061d1
+0000017c 000000000000002c 00000180 FDE cie=00000000 pc=00000000000056d0..0000000000007779
+  DW_CFA_advance_loc: 1 to 00000000000056d1
   DW_CFA_def_cfa_offset: 16
   DW_CFA_offset: r6 (rbp) at cfa-16
-  DW_CFA_advance_loc: 3 to 00000000000061d4
+  DW_CFA_advance_loc: 3 to 00000000000056d4
   DW_CFA_def_cfa_register: r6 (rbp)
-  DW_CFA_advance_loc: 4 to 00000000000061d8
+  DW_CFA_advance_loc: 4 to 00000000000056d8
   DW_CFA_offset: r15 (r15) at cfa-24
   DW_CFA_offset: r14 (r14) at cfa-32
-  DW_CFA_advance_loc: 15 to 00000000000061e7
+  DW_CFA_advance_loc: 15 to 00000000000056e7
   DW_CFA_offset: r13 (r13) at cfa-40
   DW_CFA_offset: r12 (r12) at cfa-48
   DW_CFA_offset: r3 (rbx) at cfa-56
-  DW_CFA_advance_loc2: 2363 to 0000000000006b22
+  DW_CFA_advance_loc2: 6037 to 0000000000006e7c
   DW_CFA_remember_state
   DW_CFA_def_cfa: r7 (rsp) ofs 8
-  DW_CFA_advance_loc: 14 to 0000000000006b30
+  DW_CFA_advance_loc: 4 to 0000000000006e80
   DW_CFA_restore_state
   DW_CFA_nop
   DW_CFA_nop
 
-000001ac 000000000000002c 000001b0 FDE cie=00000000 pc=0000000000006f30..00000000000084e9
-  DW_CFA_advance_loc: 1 to 0000000000006f31
+000001ac 000000000000004c 000001b0 FDE cie=00000000 pc=0000000000007780..0000000000007da4
+  DW_CFA_advance_loc: 2 to 0000000000007782
+  DW_CFA_def_cfa_offset: 16
+  DW_CFA_offset: r15 (r15) at cfa-16
+  DW_CFA_advance_loc: 2 to 0000000000007784
+  DW_CFA_def_cfa_offset: 24
+  DW_CFA_offset: r14 (r14) at cfa-24
+  DW_CFA_advance_loc: 2 to 0000000000007786
+  DW_CFA_def_cfa_offset: 32
+  DW_CFA_offset: r13 (r13) at cfa-32
+  DW_CFA_advance_loc: 2 to 0000000000007788
+  DW_CFA_def_cfa_offset: 40
+  DW_CFA_offset: r12 (r12) at cfa-40
+  DW_CFA_advance_loc: 1 to 0000000000007789
+  DW_CFA_def_cfa_offset: 48
+  DW_CFA_offset: r6 (rbp) at cfa-48
+  DW_CFA_advance_loc: 1 to 000000000000778a
+  DW_CFA_def_cfa_offset: 56
+  DW_CFA_offset: r3 (rbx) at cfa-56
+  DW_CFA_advance_loc: 4 to 000000000000778e
+  DW_CFA_def_cfa_offset: 160
+  DW_CFA_advance_loc2: 1495 to 0000000000007d65
+  DW_CFA_remember_state
+  DW_CFA_def_cfa_offset: 56
+  DW_CFA_advance_loc: 4 to 0000000000007d69
+  DW_CFA_def_cfa_offset: 48
+  DW_CFA_advance_loc: 1 to 0000000000007d6a
+  DW_CFA_def_cfa_offset: 40
+  DW_CFA_advance_loc: 2 to 0000000000007d6c
+  DW_CFA_def_cfa_offset: 32
+  DW_CFA_advance_loc: 2 to 0000000000007d6e
+  DW_CFA_def_cfa_offset: 24
+  DW_CFA_advance_loc: 2 to 0000000000007d70
+  DW_CFA_def_cfa_offset: 16
+  DW_CFA_advance_loc: 2 to 0000000000007d72
+  DW_CFA_def_cfa_offset: 8
+  DW_CFA_advance_loc: 5 to 0000000000007d77
+  DW_CFA_restore_state
+  DW_CFA_nop
+  DW_CFA_nop
+  DW_CFA_nop
+
+000001fc 000000000000004c 00000200 FDE cie=00000000 pc=0000000000007db0..00000000000089d0
+  DW_CFA_advance_loc: 2 to 0000000000007db2
+  DW_CFA_def_cfa_offset: 16
+  DW_CFA_offset: r15 (r15) at cfa-16
+  DW_CFA_advance_loc: 2 to 0000000000007db4
+  DW_CFA_def_cfa_offset: 24
+  DW_CFA_offset: r14 (r14) at cfa-24
+  DW_CFA_advance_loc: 2 to 0000000000007db6
+  DW_CFA_def_cfa_offset: 32
+  DW_CFA_offset: r13 (r13) at cfa-32
+  DW_CFA_advance_loc: 2 to 0000000000007db8
+  DW_CFA_def_cfa_offset: 40
+  DW_CFA_offset: r12 (r12) at cfa-40
+  DW_CFA_advance_loc: 1 to 0000000000007db9
+  DW_CFA_def_cfa_offset: 48
+  DW_CFA_offset: r6 (rbp) at cfa-48
+  DW_CFA_advance_loc: 1 to 0000000000007dba
+  DW_CFA_def_cfa_offset: 56
+  DW_CFA_offset: r3 (rbx) at cfa-56
+  DW_CFA_advance_loc: 7 to 0000000000007dc1
+  DW_CFA_def_cfa_offset: 304
+  DW_CFA_advance_loc2: 2995 to 0000000000008974
+  DW_CFA_remember_state
+  DW_CFA_def_cfa_offset: 56
+  DW_CFA_advance_loc: 4 to 0000000000008978
+  DW_CFA_def_cfa_offset: 48
+  DW_CFA_advance_loc: 1 to 0000000000008979
+  DW_CFA_def_cfa_offset: 40
+  DW_CFA_advance_loc: 2 to 000000000000897b
+  DW_CFA_def_cfa_offset: 32
+  DW_CFA_advance_loc: 2 to 000000000000897d
+  DW_CFA_def_cfa_offset: 24
+  DW_CFA_advance_loc: 2 to 000000000000897f
+  DW_CFA_def_cfa_offset: 16
+  DW_CFA_advance_loc: 2 to 0000000000008981
+  DW_CFA_def_cfa_offset: 8
+  DW_CFA_advance_loc: 15 to 0000000000008990
+  DW_CFA_restore_state
+  DW_CFA_nop
+  DW_CFA_nop
+  DW_CFA_nop
+
+0000024c 000000000000004c 00000250 FDE cie=00000000 pc=00000000000089d0..00000000000098cd
+  DW_CFA_advance_loc: 2 to 00000000000089d2
+  DW_CFA_def_cfa_offset: 16
+  DW_CFA_offset: r15 (r15) at cfa-16
+  DW_CFA_advance_loc: 2 to 00000000000089d4
+  DW_CFA_def_cfa_offset: 24
+  DW_CFA_offset: r14 (r14) at cfa-24
+  DW_CFA_advance_loc: 2 to 00000000000089d6
+  DW_CFA_def_cfa_offset: 32
+  DW_CFA_offset: r13 (r13) at cfa-32
+  DW_CFA_advance_loc: 2 to 00000000000089d8
+  DW_CFA_def_cfa_offset: 40
+  DW_CFA_offset: r12 (r12) at cfa-40
+  DW_CFA_advance_loc: 1 to 00000000000089d9
+  DW_CFA_def_cfa_offset: 48
+  DW_CFA_offset: r6 (rbp) at cfa-48
+  DW_CFA_advance_loc: 1 to 00000000000089da
+  DW_CFA_def_cfa_offset: 56
+  DW_CFA_offset: r3 (rbx) at cfa-56
+  DW_CFA_advance_loc: 7 to 00000000000089e1
+  DW_CFA_def_cfa_offset: 224
+  DW_CFA_advance_loc2: 3726 to 000000000000986f
+  DW_CFA_remember_state
+  DW_CFA_def_cfa_offset: 56
+  DW_CFA_advance_loc: 4 to 0000000000009873
+  DW_CFA_def_cfa_offset: 48
+  DW_CFA_advance_loc: 1 to 0000000000009874
+  DW_CFA_def_cfa_offset: 40
+  DW_CFA_advance_loc: 2 to 0000000000009876
+  DW_CFA_def_cfa_offset: 32
+  DW_CFA_advance_loc: 2 to 0000000000009878
+  DW_CFA_def_cfa_offset: 24
+  DW_CFA_advance_loc: 2 to 000000000000987a
+  DW_CFA_def_cfa_offset: 16
+  DW_CFA_advance_loc: 2 to 000000000000987c
+  DW_CFA_def_cfa_offset: 8
+  DW_CFA_advance_loc: 5 to 0000000000009881
+  DW_CFA_restore_state
+  DW_CFA_nop
+  DW_CFA_nop
+  DW_CFA_nop
+
+0000029c 000000000000002c 000002a0 FDE cie=00000000 pc=00000000000098d0..000000000000bcb1
+  DW_CFA_advance_loc: 1 to 00000000000098d1
   DW_CFA_def_cfa_offset: 16
   DW_CFA_offset: r6 (rbp) at cfa-16
-  DW_CFA_advance_loc: 3 to 0000000000006f34
+  DW_CFA_advance_loc: 3 to 00000000000098d4
   DW_CFA_def_cfa_register: r6 (rbp)
-  DW_CFA_advance_loc: 4 to 0000000000006f38
+  DW_CFA_advance_loc: 16 to 00000000000098e4
   DW_CFA_offset: r15 (r15) at cfa-24
   DW_CFA_offset: r14 (r14) at cfa-32
-  DW_CFA_advance_loc: 15 to 0000000000006f47
   DW_CFA_offset: r13 (r13) at cfa-40
   DW_CFA_offset: r12 (r12) at cfa-48
   DW_CFA_offset: r3 (rbx) at cfa-56
-  DW_CFA_advance_loc2: 3973 to 0000000000007ecc
+  DW_CFA_advance_loc2: 9077 to 000000000000bc59
   DW_CFA_remember_state
   DW_CFA_def_cfa: r7 (rsp) ofs 8
-  DW_CFA_advance_loc: 4 to 0000000000007ed0
+  DW_CFA_advance_loc: 5 to 000000000000bc5e
   DW_CFA_restore_state
   DW_CFA_nop
   DW_CFA_nop
+  DW_CFA_nop
 
-000001dc 0000000000000048 000001e0 FDE cie=00000000 pc=00000000000084f0..000000000000872d
-  DW_CFA_advance_loc: 2 to 00000000000084f2
+000002cc 0000000000000048 000002d0 FDE cie=00000000 pc=000000000000bcc0..000000000000befd
+  DW_CFA_advance_loc: 2 to 000000000000bcc2
   DW_CFA_def_cfa_offset: 16
   DW_CFA_offset: r15 (r15) at cfa-16
-  DW_CFA_advance_loc: 2 to 00000000000084f4
+  DW_CFA_advance_loc: 2 to 000000000000bcc4
   DW_CFA_def_cfa_offset: 24
   DW_CFA_offset: r14 (r14) at cfa-24
-  DW_CFA_advance_loc: 8 to 00000000000084fc
+  DW_CFA_advance_loc: 8 to 000000000000bccc
   DW_CFA_def_cfa_offset: 32
   DW_CFA_offset: r13 (r13) at cfa-32
-  DW_CFA_advance_loc: 2 to 00000000000084fe
+  DW_CFA_advance_loc: 2 to 000000000000bcce
   DW_CFA_def_cfa_offset: 40
   DW_CFA_offset: r12 (r12) at cfa-40
-  DW_CFA_advance_loc: 7 to 0000000000008505
+  DW_CFA_advance_loc: 7 to 000000000000bcd5
   DW_CFA_def_cfa_offset: 48
   DW_CFA_offset: r6 (rbp) at cfa-48
-  DW_CFA_advance_loc: 1 to 0000000000008506
+  DW_CFA_advance_loc: 1 to 000000000000bcd6
   DW_CFA_def_cfa_offset: 56
   DW_CFA_offset: r3 (rbx) at cfa-56
-  DW_CFA_advance_loc: 14 to 0000000000008514
+  DW_CFA_advance_loc: 14 to 000000000000bce4
   DW_CFA_def_cfa_offset: 96
-  DW_CFA_advance_loc1: 224 to 00000000000085f4
+  DW_CFA_advance_loc1: 224 to 000000000000bdc4
   DW_CFA_remember_state
   DW_CFA_def_cfa_offset: 56
-  DW_CFA_advance_loc: 1 to 00000000000085f5
+  DW_CFA_advance_loc: 1 to 000000000000bdc5
   DW_CFA_def_cfa_offset: 48
-  DW_CFA_advance_loc: 1 to 00000000000085f6
+  DW_CFA_advance_loc: 1 to 000000000000bdc6
   DW_CFA_def_cfa_offset: 40
-  DW_CFA_advance_loc: 2 to 00000000000085f8
+  DW_CFA_advance_loc: 2 to 000000000000bdc8
   DW_CFA_def_cfa_offset: 32
-  DW_CFA_advance_loc: 2 to 00000000000085fa
+  DW_CFA_advance_loc: 2 to 000000000000bdca
   DW_CFA_def_cfa_offset: 24
-  DW_CFA_advance_loc: 2 to 00000000000085fc
+  DW_CFA_advance_loc: 2 to 000000000000bdcc
   DW_CFA_def_cfa_offset: 16
-  DW_CFA_advance_loc: 2 to 00000000000085fe
+  DW_CFA_advance_loc: 2 to 000000000000bdce
   DW_CFA_def_cfa_offset: 8
-  DW_CFA_advance_loc: 1 to 00000000000085ff
+  DW_CFA_advance_loc: 1 to 000000000000bdcf
   DW_CFA_restore_state
   DW_CFA_nop
 
-00000228 0000000000000014 0000022c FDE cie=00000000 pc=0000000000008730..0000000000008760
-  DW_CFA_advance_loc: 4 to 0000000000008734
+00000318 0000000000000014 0000031c FDE cie=00000000 pc=000000000000bf00..000000000000bf30
+  DW_CFA_advance_loc: 4 to 000000000000bf04
+  DW_CFA_def_cfa_offset: 48
+  DW_CFA_advance_loc: 43 to 000000000000bf2f
+  DW_CFA_def_cfa_offset: 8
+  DW_CFA_nop
+
+00000330 0000000000000014 00000334 FDE cie=00000000 pc=000000000000bf30..000000000000bf65
+  DW_CFA_advance_loc: 4 to 000000000000bf34
+  DW_CFA_def_cfa_offset: 48
+  DW_CFA_advance_loc: 48 to 000000000000bf64
+  DW_CFA_def_cfa_offset: 8
+  DW_CFA_nop
+
+00000348 0000000000000014 0000034c FDE cie=00000000 pc=000000000000bf70..000000000000bfa5
+  DW_CFA_advance_loc: 4 to 000000000000bf74
   DW_CFA_def_cfa_offset: 48
-  DW_CFA_advance_loc: 43 to 000000000000875f
+  DW_CFA_advance_loc: 48 to 000000000000bfa4
   DW_CFA_def_cfa_offset: 8
   DW_CFA_nop
 
-00000240 0000000000000014 00000244 FDE cie=00000000 pc=0000000000008760..0000000000008795
-  DW_CFA_advance_loc: 4 to 0000000000008764
+00000360 0000000000000014 00000364 FDE cie=00000000 pc=000000000000bfb0..000000000000bfe5
+  DW_CFA_advance_loc: 4 to 000000000000bfb4
   DW_CFA_def_cfa_offset: 48
-  DW_CFA_advance_loc: 48 to 0000000000008794
+  DW_CFA_advance_loc: 48 to 000000000000bfe4
   DW_CFA_def_cfa_offset: 8
   DW_CFA_nop
 
-00000258 0000000000000014 0000025c FDE cie=00000000 pc=00000000000087a0..00000000000087d5
-  DW_CFA_advance_loc: 4 to 00000000000087a4
+00000378 0000000000000014 0000037c FDE cie=00000000 pc=000000000000bff0..000000000000c025
+  DW_CFA_advance_loc: 4 to 000000000000bff4
   DW_CFA_def_cfa_offset: 48
-  DW_CFA_advance_loc: 48 to 00000000000087d4
+  DW_CFA_advance_loc: 48 to 000000000000c024
   DW_CFA_def_cfa_offset: 8
   DW_CFA_nop
 
-00000270 0000000000000014 00000274 FDE cie=00000000 pc=00000000000087e0..0000000000008815
-  DW_CFA_advance_loc: 4 to 00000000000087e4
+00000390 0000000000000014 00000394 FDE cie=00000000 pc=000000000000c030..000000000000c065
+  DW_CFA_advance_loc: 4 to 000000000000c034
   DW_CFA_def_cfa_offset: 48
-  DW_CFA_advance_loc: 48 to 0000000000008814
+  DW_CFA_advance_loc: 48 to 000000000000c064
   DW_CFA_def_cfa_offset: 8
   DW_CFA_nop
 
-00000288 0000000000000014 0000028c FDE cie=00000000 pc=0000000000008820..0000000000008855
-  DW_CFA_advance_loc: 4 to 0000000000008824
+000003a8 0000000000000014 000003ac FDE cie=00000000 pc=000000000000c070..000000000000c0a5
+  DW_CFA_advance_loc: 4 to 000000000000c074
   DW_CFA_def_cfa_offset: 48
-  DW_CFA_advance_loc: 48 to 0000000000008854
+  DW_CFA_advance_loc: 48 to 000000000000c0a4
   DW_CFA_def_cfa_offset: 8
   DW_CFA_nop
 
-000002a0 0000000000000014 000002a4 FDE cie=00000000 pc=0000000000008860..0000000000008895
-  DW_CFA_advance_loc: 4 to 0000000000008864
+000003c0 0000000000000014 000003c4 FDE cie=00000000 pc=000000000000c0b0..000000000000c0f1
+  DW_CFA_advance_loc: 9 to 000000000000c0b9
   DW_CFA_def_cfa_offset: 48
-  DW_CFA_advance_loc: 48 to 0000000000008894
+  DW_CFA_advance_loc: 55 to 000000000000c0f0
   DW_CFA_def_cfa_offset: 8
   DW_CFA_nop
 
-000002b8 000000000000001c 000002bc FDE cie=00000000 pc=00000000000088a0..00000000000088f5
-  DW_CFA_advance_loc: 1 to 00000000000088a1
+000003d8 000000000000001c 000003dc FDE cie=00000000 pc=000000000000c100..000000000000c155
+  DW_CFA_advance_loc: 1 to 000000000000c101
   DW_CFA_def_cfa_offset: 16
   DW_CFA_offset: r6 (rbp) at cfa-16
-  DW_CFA_advance_loc: 17 to 00000000000088b2
+  DW_CFA_advance_loc: 17 to 000000000000c112
   DW_CFA_def_cfa_register: r6 (rbp)
-  DW_CFA_advance_loc1: 66 to 00000000000088f4
+  DW_CFA_advance_loc1: 66 to 000000000000c154
   DW_CFA_def_cfa: r7 (rsp) ofs 8
   DW_CFA_nop
   DW_CFA_nop
 
-000002d8 0000000000000020 000002dc FDE cie=00000000 pc=0000000000008900..00000000000089e8
-  DW_CFA_advance_loc1: 65 to 0000000000008941
+000003f8 0000000000000010 000003fc FDE cie=00000000 pc=000000000000c160..000000000000c175
+  DW_CFA_nop
+  DW_CFA_nop
+  DW_CFA_nop
+
+0000040c 0000000000000014 00000410 FDE cie=00000000 pc=000000000000c180..000000000000c1c1
+  DW_CFA_advance_loc: 9 to 000000000000c189
+  DW_CFA_def_cfa_offset: 48
+  DW_CFA_advance_loc: 55 to 000000000000c1c0
+  DW_CFA_def_cfa_offset: 8
+  DW_CFA_nop
+
+00000424 000000000000001c 00000428 FDE cie=00000000 pc=000000000000c1d0..000000000000c225
+  DW_CFA_advance_loc: 1 to 000000000000c1d1
   DW_CFA_def_cfa_offset: 16
   DW_CFA_offset: r6 (rbp) at cfa-16
-  DW_CFA_advance_loc: 17 to 0000000000008952
+  DW_CFA_advance_loc: 17 to 000000000000c1e2
   DW_CFA_def_cfa_register: r6 (rbp)
-  DW_CFA_advance_loc1: 66 to 0000000000008994
+  DW_CFA_advance_loc1: 66 to 000000000000c224
   DW_CFA_def_cfa: r7 (rsp) ofs 8
-  DW_CFA_advance_loc: 12 to 00000000000089a0
-  DW_CFA_restore: r6 (rbp)
+  DW_CFA_nop
+  DW_CFA_nop
+
+00000444 0000000000000010 00000448 FDE cie=00000000 pc=000000000000c230..000000000000c2e8
   DW_CFA_nop
   DW_CFA_nop
   DW_CFA_nop
 
-000002fc ZERO terminator
+00000458 ZERO terminator
```

### strings --all --bytes=8 {}

```diff
@@ -1,42 +1,53 @@
-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
+XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
+XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
 [A\A]A^A_]
 [A\A]A^A_]
 [A\A]A^A_]
 [A\A]A^A_]
 [A\A]A^A_]
-AWAVAUATSH
-T$hH;D$P
 [A\A]A^A_]
-\$`HcD$\H
 [A\A]A^A_]
 [A\A]A^A_]
-AWAVAUATSH
 [A\A]A^A_]
 [A\A]A^A_]
+AWAVAUATUSH
+t$8H;D$H
+[]A\A]A^A_
+AWAVAUATUSH
+[]A\A]A^A_
+AWAVAUATUSH
+D$HH9D$Xt0
+[]A\A]A^A_
+AWAVAUATSH
+L$hH9L$8
 [A\A]A^A_]
 ([]A\A]A^A_
+]'@vTxKC#
 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
 GCC: (GNU) 10.2.1 20210130 (Red Hat 10.2.1-11)
 crtstuff.c
 deregister_tm_clones
 __do_global_dtors_aux
 completed.0
 __do_global_dtors_aux_fini_array_entry
 frame_dummy
 __frame_dummy_init_array_entry
 sphericart.c
 cartesian_spherical_harmonics_l0._omp_fn.0
 cartesian_spherical_harmonics_l1._omp_fn.0
 cartesian_spherical_harmonics_l2._omp_fn.0
-cartesian_spherical_harmonics_generic._omp_fn.0
 cartesian_spherical_harmonics_l3._omp_fn.0
-cartesian_spherical_harmonics._omp_fn.0
 cartesian_spherical_harmonics_l4._omp_fn.0
 cartesian_spherical_harmonics_l5._omp_fn.0
+cartesian_spherical_harmonics_l6._omp_fn.0
+_compute_no_dsph._omp_fn.0
+_compute_with_dsph._omp_fn.0
+_compute_highl_no_dsph._omp_fn.0
+_compute_highl_with_dsph._omp_fn.0
 __FRAME_END__
 __dso_handle
 _DYNAMIC
 __GNU_EH_FRAME_HDR
 __TMC_END__
 _GLOBAL_OFFSET_TABLE_
 free@@GLIBC_2.2.5
@@ -45,19 +56,24 @@
 cartesian_spherical_harmonics_l1
 cartesian_spherical_harmonics_l3
 cartesian_spherical_harmonics_l5
 GOMP_barrier@@GOMP_1.0
 omp_get_thread_num@@OMP_1.0
 compute_sph_prefactors
 omp_get_num_threads@@OMP_1.0
+_compute_with_dsph
+_compute_no_dsph
 __gmon_start__
+_compute_highl_no_dsph
 malloc@@GLIBC_2.2.5
+_compute_highl_with_dsph
 cartesian_spherical_harmonics_l0
 cartesian_spherical_harmonics_l2
 cartesian_spherical_harmonics_l4
+cartesian_spherical_harmonics_l6
 cartesian_spherical_harmonics_generic
 _ITM_registerTMCloneTable
 GOMP_parallel@@GOMP_4.0
 __cxa_finalize@@GLIBC_2.2.5
 .shstrtab
 .note.gnu.build-id
 .gnu.hash
@@ -69,16 +85,16 @@
 .eh_frame
 .init_array
 .fini_array
 .data.rel.ro
 .dynamic
 .got.plt
 .comment
-$:n<o7n<o8n<o
-9n<oXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
+6n<o=n<o8n<o
+XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
 __gmon_start__
 _ITM_deregisterTMCloneTable
 _ITM_registerTMCloneTable
 __cxa_finalize
 omp_get_num_threads
 omp_get_thread_num
 GOMP_barrier
@@ -86,15 +102,20 @@
 cartesian_spherical_harmonics_l0
 GOMP_parallel
 cartesian_spherical_harmonics_l1
 cartesian_spherical_harmonics_l2
 cartesian_spherical_harmonics_l3
 cartesian_spherical_harmonics_l4
 cartesian_spherical_harmonics_l5
+cartesian_spherical_harmonics_l6
+_compute_no_dsph
+_compute_with_dsph
 cartesian_spherical_harmonics_generic
+_compute_highl_no_dsph
+_compute_highl_with_dsph
 cartesian_spherical_harmonics
 libgomp.so.1
 libpthread.so.0
 libc.so.6
 libsphericart.so
 GOMP_4.0
 GOMP_1.0
```

### objdump --line-numbers --disassemble --demangle --reloc --no-show-raw-insn --section=.init {}

```diff
@@ -2,13 +2,13 @@
 
 
 Disassembly of section .init:
 
 0000000000001000 <_init>:
 _init():
 	sub    $0x8,%rsp
-	mov    0x9fdd(%rip),%rax        
+	mov    0xdfdd(%rip),%rax        
 	test   %rax,%rax
 	je     1015 <_init+0x15>
-	call   10a0 <__gmon_start__@plt>
+	call   10c0 <__gmon_start__@plt>
 	add    $0x8,%rsp
 	ret
```

### objdump --line-numbers --disassemble --demangle --reloc --no-show-raw-insn --section=.plt {}

```diff
@@ -1,84 +1,109 @@
 
 
 
 Disassembly of section .plt:
 
 0000000000001020 <.plt>:
-	push   0x9fe2(%rip)        
-	jmp    *0x9fe4(%rip)        
+	push   0xdfe2(%rip)        
+	jmp    *0xdfe4(%rip)        
 	nopl   0x0(%rax)
 
 0000000000001030 <free@plt>:
-	jmp    *0x9fe2(%rip)        
+	jmp    *0xdfe2(%rip)        
 	push   $0x0
 	jmp    1020 <.plt>
 
 0000000000001040 <cartesian_spherical_harmonics_l1@plt>:
-	jmp    *0x9fda(%rip)        
+	jmp    *0xdfda(%rip)        
 	push   $0x1
 	jmp    1020 <.plt>
 
 0000000000001050 <cartesian_spherical_harmonics_l3@plt>:
-	jmp    *0x9fd2(%rip)        
+	jmp    *0xdfd2(%rip)        
 	push   $0x2
 	jmp    1020 <.plt>
 
 0000000000001060 <cartesian_spherical_harmonics_l5@plt>:
-	jmp    *0x9fca(%rip)        
+	jmp    *0xdfca(%rip)        
 	push   $0x3
 	jmp    1020 <.plt>
 
 0000000000001070 <GOMP_barrier@plt>:
-	jmp    *0x9fc2(%rip)        
+	jmp    *0xdfc2(%rip)        
 	push   $0x4
 	jmp    1020 <.plt>
 
 0000000000001080 <omp_get_thread_num@plt>:
-	jmp    *0x9fba(%rip)        
+	jmp    *0xdfba(%rip)        
 	push   $0x5
 	jmp    1020 <.plt>
 
 0000000000001090 <omp_get_num_threads@plt>:
-	jmp    *0x9fb2(%rip)        
+	jmp    *0xdfb2(%rip)        
 	push   $0x6
 	jmp    1020 <.plt>
 
-00000000000010a0 <__gmon_start__@plt>:
-	jmp    *0x9faa(%rip)        
+00000000000010a0 <_compute_with_dsph@plt>:
+	jmp    *0xdfaa(%rip)        
 	push   $0x7
 	jmp    1020 <.plt>
 
-00000000000010b0 <malloc@plt>:
-	jmp    *0x9fa2(%rip)        
+00000000000010b0 <_compute_no_dsph@plt>:
+	jmp    *0xdfa2(%rip)        
 	push   $0x8
 	jmp    1020 <.plt>
 
-00000000000010c0 <cartesian_spherical_harmonics_l0@plt>:
-	jmp    *0x9f9a(%rip)        
+00000000000010c0 <__gmon_start__@plt>:
+	jmp    *0xdf9a(%rip)        
 	push   $0x9
 	jmp    1020 <.plt>
 
-00000000000010d0 <cartesian_spherical_harmonics_l2@plt>:
-	jmp    *0x9f92(%rip)        
+00000000000010d0 <_compute_highl_no_dsph@plt>:
+	jmp    *0xdf92(%rip)        
 	push   $0xa
 	jmp    1020 <.plt>
 
-00000000000010e0 <cartesian_spherical_harmonics_l4@plt>:
-	jmp    *0x9f8a(%rip)        
+00000000000010e0 <malloc@plt>:
+	jmp    *0xdf8a(%rip)        
 	push   $0xb
 	jmp    1020 <.plt>
 
-00000000000010f0 <sqrt@plt>:
-	jmp    *0x9f82(%rip)        
+00000000000010f0 <_compute_highl_with_dsph@plt>:
+	jmp    *0xdf82(%rip)        
 	push   $0xc
 	jmp    1020 <.plt>
 
-0000000000001100 <GOMP_parallel@plt>:
-	jmp    *0x9f7a(%rip)        
+0000000000001100 <cartesian_spherical_harmonics_l0@plt>:
+	jmp    *0xdf7a(%rip)        
 	push   $0xd
 	jmp    1020 <.plt>
 
-0000000000001110 <__cxa_finalize@plt>:
-	jmp    *0x9f72(%rip)        
+0000000000001110 <cartesian_spherical_harmonics_l2@plt>:
+	jmp    *0xdf72(%rip)        
 	push   $0xe
 	jmp    1020 <.plt>
+
+0000000000001120 <cartesian_spherical_harmonics_l4@plt>:
+	jmp    *0xdf6a(%rip)        
+	push   $0xf
+	jmp    1020 <.plt>
+
+0000000000001130 <cartesian_spherical_harmonics_l6@plt>:
+	jmp    *0xdf62(%rip)        
+	push   $0x10
+	jmp    1020 <.plt>
+
+0000000000001140 <sqrt@plt>:
+	jmp    *0xdf5a(%rip)        
+	push   $0x11
+	jmp    1020 <.plt>
+
+0000000000001150 <GOMP_parallel@plt>:
+	jmp    *0xdf52(%rip)        
+	push   $0x12
+	jmp    1020 <.plt>
+
+0000000000001160 <__cxa_finalize@plt>:
+	jmp    *0xdf4a(%rip)        
+	push   $0x13
+	jmp    1020 <.plt>
```

### objdump --line-numbers --disassemble --demangle --reloc --no-show-raw-insn --section=.text {}

```diff
@@ -1,70 +1,70 @@
 
 
 
 Disassembly of section .text:
 
-0000000000001120 <deregister_tm_clones>:
+0000000000001170 <deregister_tm_clones>:
 deregister_tm_clones():
-	lea    0x9f69(%rip),%rdi        
-	lea    0x9f62(%rip),%rax        
+	lea    0xdf41(%rip),%rdi        
+	lea    0xdf3a(%rip),%rax        
 	cmp    %rdi,%rax
-	je     1148 <deregister_tm_clones+0x28>
-	mov    0x9ea6(%rip),%rax        
+	je     1198 <deregister_tm_clones+0x28>
+	mov    0xde56(%rip),%rax        
 	test   %rax,%rax
-	je     1148 <deregister_tm_clones+0x28>
+	je     1198 <deregister_tm_clones+0x28>
 	jmp    *%rax
 	nopl   0x0(%rax)
 	ret
 	nopl   0x0(%rax)
 
-0000000000001150 <register_tm_clones>:
+00000000000011a0 <register_tm_clones>:
 register_tm_clones():
-	lea    0x9f39(%rip),%rdi        
-	lea    0x9f32(%rip),%rsi        
+	lea    0xdf11(%rip),%rdi        
+	lea    0xdf0a(%rip),%rsi        
 	sub    %rdi,%rsi
 	mov    %rsi,%rax
 	shr    $0x3f,%rsi
 	sar    $0x3,%rax
 	add    %rax,%rsi
 	sar    %rsi
-	je     1188 <register_tm_clones+0x38>
-	mov    0x9e75(%rip),%rax        
+	je     11d8 <register_tm_clones+0x38>
+	mov    0xde25(%rip),%rax        
 	test   %rax,%rax
-	je     1188 <register_tm_clones+0x38>
+	je     11d8 <register_tm_clones+0x38>
 	jmp    *%rax
 	nopw   0x0(%rax,%rax,1)
 	ret
 	nopl   0x0(%rax)
 
-0000000000001190 <__do_global_dtors_aux>:
+00000000000011e0 <__do_global_dtors_aux>:
 __do_global_dtors_aux():
-	cmpb   $0x0,0x9ef9(%rip)        
-	jne    11c8 <__do_global_dtors_aux+0x38>
+	cmpb   $0x0,0xded1(%rip)        
+	jne    1218 <__do_global_dtors_aux+0x38>
 	push   %rbp
-	cmpq   $0x0,0x9e56(%rip)        
+	cmpq   $0x0,0xde06(%rip)        
 	mov    %rsp,%rbp
-	je     11b3 <__do_global_dtors_aux+0x23>
-	lea    0x9c3a(%rip),%rdi        
-	call   1110 <__cxa_finalize@plt>
-	call   1120 <deregister_tm_clones>
-	movb   $0x1,0x9ed1(%rip)        
+	je     1203 <__do_global_dtors_aux+0x23>
+	lea    0xdbea(%rip),%rdi        
+	call   1160 <__cxa_finalize@plt>
+	call   1170 <deregister_tm_clones>
+	movb   $0x1,0xdea9(%rip)        
 	pop    %rbp
 	ret
 	nopl   0x0(%rax)
 	ret
 	nopl   0x0(%rax)
 
-00000000000011d0 <frame_dummy>:
+0000000000001220 <frame_dummy>:
 frame_dummy():
-	jmp    1150 <register_tm_clones>
+	jmp    11a0 <register_tm_clones>
 	cs nopw 0x0(%rax,%rax,1)
 	nop
 
-00000000000011e0 <cartesian_spherical_harmonics_l0._omp_fn.0>:
+0000000000001230 <cartesian_spherical_harmonics_l0._omp_fn.0>:
 cartesian_spherical_harmonics_l0._omp_fn.0():
 	push   %rbp
 	mov    %rsp,%rbp
 	push   %r13
 	push   %r12
 	mov    %rdi,%r13
 	push   %rbx
@@ -74,28 +74,28 @@
 	mov    %eax,%r12d
 	call   1080 <omp_get_thread_num@plt>
 	mov    %eax,%ecx
 	mov    0x10(%r13),%eax
 	cltd
 	idiv   %r12d
 	test   %rbx,%rbx
-	je     1310 <cartesian_spherical_harmonics_l0._omp_fn.0+0x130>
+	je     1360 <cartesian_spherical_harmonics_l0._omp_fn.0+0x130>
 	cmp    %edx,%ecx
-	jl     13b0 <cartesian_spherical_harmonics_l0._omp_fn.0+0x1d0>
+	jl     1400 <cartesian_spherical_harmonics_l0._omp_fn.0+0x1d0>
 	imul   %eax,%ecx
 	add    %ecx,%edx
 	lea    (%rax,%rdx,1),%r8d
 	cmp    %r8d,%edx
-	jge    1304 <cartesian_spherical_harmonics_l0._omp_fn.0+0x124>
+	jge    1354 <cartesian_spherical_harmonics_l0._omp_fn.0+0x124>
 	lea    (%rdx,%rdx,2),%esi
 	lea    -0x1(%rax),%edi
 	movslq %esi,%rsi
 	lea    0x0(,%rsi,8),%rcx
 	cmp    $0x6,%edi
-	jbe    13d0 <cartesian_spherical_harmonics_l0._omp_fn.0+0x1f0>
+	jbe    1420 <cartesian_spherical_harmonics_l0._omp_fn.0+0x1f0>
 	mov    %eax,%edi
 	lea    0x8(%rbx,%rsi,8),%rsi
 	add    %rbx,%rcx
 	vxorpd %xmm0,%xmm0,%xmm0
 	shr    $0x2,%edi
 	lea    (%rdi,%rdi,2),%rdi
 	shl    $0x5,%rdi
@@ -109,165 +109,165 @@
 	vmovupd %xmm0,-0x18(%rsi)
 	add    $0x60,%rcx
 	movq   $0x0,-0x60(%rcx)
 	movq   $0x0,-0x48(%rcx)
 	movq   $0x0,-0x30(%rcx)
 	movq   $0x0,-0x18(%rcx)
 	cmp    %rdi,%rsi
-	jne    1270 <cartesian_spherical_harmonics_l0._omp_fn.0+0x90>
+	jne    12c0 <cartesian_spherical_harmonics_l0._omp_fn.0+0x90>
 	mov    %eax,%ecx
 	and    $0xfffffffc,%ecx
 	add    %ecx,%edx
 	cmp    %ecx,%eax
-	je     1304 <cartesian_spherical_harmonics_l0._omp_fn.0+0x124>
+	je     1354 <cartesian_spherical_harmonics_l0._omp_fn.0+0x124>
 	lea    (%rdx,%rdx,2),%eax
 	cltq
 	movq   $0x0,0x10(%rbx,%rax,8)
 	vmovupd %xmm0,(%rbx,%rax,8)
 	lea    0x1(%rdx),%eax
 	cmp    %eax,%r8d
-	jle    1304 <cartesian_spherical_harmonics_l0._omp_fn.0+0x124>
+	jle    1354 <cartesian_spherical_harmonics_l0._omp_fn.0+0x124>
 	lea    (%rax,%rax,2),%eax
 	add    $0x2,%edx
 	cltq
 	movq   $0x0,0x10(%rbx,%rax,8)
 	vmovupd %xmm0,(%rbx,%rax,8)
 	cmp    %edx,%r8d
-	jle    1304 <cartesian_spherical_harmonics_l0._omp_fn.0+0x124>
+	jle    1354 <cartesian_spherical_harmonics_l0._omp_fn.0+0x124>
 	lea    (%rdx,%rdx,2),%eax
 	cltq
 	movq   $0x0,0x10(%rbx,%rax,8)
 	vmovupd %xmm0,(%rbx,%rax,8)
 	add    $0x8,%rsp
 	pop    %rbx
 	pop    %r12
 	pop    %r13
 	pop    %rbp
 	ret
 	nop
 	cmp    %edx,%ecx
-	jl     13c0 <cartesian_spherical_harmonics_l0._omp_fn.0+0x1e0>
+	jl     1410 <cartesian_spherical_harmonics_l0._omp_fn.0+0x1e0>
 	imul   %eax,%ecx
 	add    %ecx,%edx
 	lea    (%rax,%rdx,1),%edi
 	cmp    %edi,%edx
-	jge    1304 <cartesian_spherical_harmonics_l0._omp_fn.0+0x124>
+	jge    1354 <cartesian_spherical_harmonics_l0._omp_fn.0+0x124>
 	lea    -0x1(%rax),%ecx
 	mov    0x0(%r13),%r8
 	cmp    $0x2,%ecx
-	jbe    136f <cartesian_spherical_harmonics_l0._omp_fn.0+0x18f>
-	vmovapd 0x7cc8(%rip),%ymm0        
+	jbe    13bf <cartesian_spherical_harmonics_l0._omp_fn.0+0x18f>
+	vmovapd 0xbc78(%rip),%ymm0        
 	mov    %eax,%esi
 	movslq %edx,%rcx
 	shr    $0x2,%esi
 	lea    (%r8,%rcx,8),%rcx
 	shl    $0x5,%rsi
 	add    %rcx,%rsi
 	nopl   0x0(%rax,%rax,1)
 	vmovupd %ymm0,(%rcx)
 	add    $0x20,%rcx
 	cmp    %rcx,%rsi
-	jne    1350 <cartesian_spherical_harmonics_l0._omp_fn.0+0x170>
+	jne    13a0 <cartesian_spherical_harmonics_l0._omp_fn.0+0x170>
 	mov    %eax,%ecx
 	and    $0xfffffffc,%ecx
 	add    %ecx,%edx
 	cmp    %eax,%ecx
-	je     1410 <cartesian_spherical_harmonics_l0._omp_fn.0+0x230>
+	je     1460 <cartesian_spherical_harmonics_l0._omp_fn.0+0x230>
 	vzeroupper
-	vmovsd 0x7ec9(%rip),%xmm0        
+	vmovsd 0xbe79(%rip),%xmm0        
 	movslq %edx,%rax
 	vmovsd %xmm0,(%r8,%rax,8)
 	lea    0x1(%rdx),%eax
 	cmp    %edi,%eax
-	jge    1304 <cartesian_spherical_harmonics_l0._omp_fn.0+0x124>
+	jge    1354 <cartesian_spherical_harmonics_l0._omp_fn.0+0x124>
 	cltq
 	add    $0x2,%edx
 	vmovsd %xmm0,(%r8,%rax,8)
 	cmp    %edi,%edx
-	jge    1304 <cartesian_spherical_harmonics_l0._omp_fn.0+0x124>
+	jge    1354 <cartesian_spherical_harmonics_l0._omp_fn.0+0x124>
 	movslq %edx,%rdx
 	vmovsd %xmm0,(%r8,%rdx,8)
-	jmp    1304 <cartesian_spherical_harmonics_l0._omp_fn.0+0x124>
+	jmp    1354 <cartesian_spherical_harmonics_l0._omp_fn.0+0x124>
 	nopl   0x0(%rax)
 	inc    %eax
 	xor    %edx,%edx
-	jmp    121c <cartesian_spherical_harmonics_l0._omp_fn.0+0x3c>
+	jmp    126c <cartesian_spherical_harmonics_l0._omp_fn.0+0x3c>
 	nopl   0x0(%rax)
 	inc    %eax
 	xor    %edx,%edx
-	jmp    1318 <cartesian_spherical_harmonics_l0._omp_fn.0+0x138>
+	jmp    1368 <cartesian_spherical_harmonics_l0._omp_fn.0+0x138>
 	nopl   0x0(%rax)
 	movslq %edx,%rdx
 	add    %rbx,%rcx
 	vxorpd %xmm0,%xmm0,%xmm0
 	add    %rdi,%rdx
 	lea    (%rdx,%rdx,2),%rax
 	lea    0x18(%rbx,%rax,8),%rax
 	cs nopw 0x0(%rax,%rax,1)
 	movq   $0x0,0x10(%rcx)
 	vmovupd %xmm0,(%rcx)
 	add    $0x18,%rcx
 	cmp    %rax,%rcx
-	jne    13f0 <cartesian_spherical_harmonics_l0._omp_fn.0+0x210>
-	jmp    1304 <cartesian_spherical_harmonics_l0._omp_fn.0+0x124>
+	jne    1440 <cartesian_spherical_harmonics_l0._omp_fn.0+0x210>
+	jmp    1354 <cartesian_spherical_harmonics_l0._omp_fn.0+0x124>
 	nopw   0x0(%rax,%rax,1)
 	vzeroupper
-	jmp    1304 <cartesian_spherical_harmonics_l0._omp_fn.0+0x124>
+	jmp    1354 <cartesian_spherical_harmonics_l0._omp_fn.0+0x124>
 	nopl   0x0(%rax,%rax,1)
 
-0000000000001420 <cartesian_spherical_harmonics_l1._omp_fn.0>:
+0000000000001470 <cartesian_spherical_harmonics_l1._omp_fn.0>:
 cartesian_spherical_harmonics_l1._omp_fn.0():
 	push   %rbp
 	mov    %rsp,%rbp
 	push   %r15
 	push   %r14
 	mov    %rdi,%r15
 	push   %r13
 	push   %r12
 	push   %rbx
 	and    $0xffffffffffffffe0,%rsp
 	sub    $0x20,%rsp
 	mov    0x10(%rdi),%r13
-	mov    0x8(%rdi),%rbx
-	mov    (%rdi),%r12
+	mov    0x8(%rdi),%r12
+	mov    (%rdi),%rbx
 	call   1090 <omp_get_num_threads@plt>
 	mov    %eax,%r14d
 	call   1080 <omp_get_thread_num@plt>
 	mov    %eax,%ecx
 	mov    0x18(%r15),%eax
 	cltd
 	idiv   %r14d
 	test   %r13,%r13
-	je     19d0 <cartesian_spherical_harmonics_l1._omp_fn.0+0x5b0>
+	je     1a20 <cartesian_spherical_harmonics_l1._omp_fn.0+0x5b0>
 	cmp    %edx,%ecx
-	jl     1ca0 <cartesian_spherical_harmonics_l1._omp_fn.0+0x880>
+	jl     1ce0 <cartesian_spherical_harmonics_l1._omp_fn.0+0x870>
 	imul   %eax,%ecx
 	add    %ecx,%edx
 	lea    (%rax,%rdx,1),%r10d
 	cmp    %r10d,%edx
-	jge    190d <cartesian_spherical_harmonics_l1._omp_fn.0+0x4ed>
+	jge    1953 <cartesian_spherical_harmonics_l1._omp_fn.0+0x4e3>
 	lea    0x0(,%rdx,4),%r8d
 	mov    %eax,%ecx
 	lea    -0x1(%rax),%r15d
 	movslq %r8d,%r8
 	mov    %r15d,0x4(%rsp)
 	lea    (%rcx,%rcx,2),%r9
 	lea    (%r8,%rcx,4),%rsi
-	lea    (%rbx,%rsi,8),%rdi
+	lea    (%r12,%rsi,8),%rdi
 	mov    %rdi,%r15
 	lea    (%rdx,%rdx,2),%edi
 	movslq %edi,%r11
 	shl    $0x2,%edi
 	mov    %r15,0x8(%rsp)
 	lea    (%r9,%r11,1),%rcx
-	lea    (%r12,%r11,8),%rsi
+	lea    (%rbx,%r11,8),%rsi
 	movslq %edi,%rdi
-	lea    (%r12,%rcx,8),%r14
+	lea    (%rbx,%rcx,8),%r14
 	cmp    %rsi,%r15
-	lea    (%rbx,%r8,8),%rcx
+	lea    (%r12,%r8,8),%rcx
 	setbe  %r15b
 	mov    %rcx,0x18(%rsp)
 	cmp    0x18(%rsp),%r14
 	lea    (%rdi,%r9,4),%r9
 	lea    0x0(%r13,%r9,8),%r9
 	lea    0x0(%r13,%rdi,8),%rcx
 	mov    %r9,0x10(%rsp)
@@ -276,47 +276,48 @@
 	cmp    %rcx,%r14
 	setbe  %r14b
 	cmp    0x10(%rsp),%rsi
 	setae  %r15b
 	or     %r15d,%r14d
 	and    %r9d,%r14d
 	and    $0x1,%r14d
-	je     1920 <cartesian_spherical_harmonics_l1._omp_fn.0+0x500>
+	je     1970 <cartesian_spherical_harmonics_l1._omp_fn.0+0x500>
 	cmp    %rcx,0x8(%rsp)
 	mov    0x10(%rsp),%r15
 	setbe  %r9b
 	cmp    %r15,0x18(%rsp)
 	lea    -0x1(%rax),%r15d
 	setae  %r14b
 	or     %r14d,%r9d
 	cmp    $0x1,%r15d
 	seta   %r14b
 	and    %r14d,%r9d
 	and    $0x1,%r9d
-	je     1920 <cartesian_spherical_harmonics_l1._omp_fn.0+0x500>
+	je     1970 <cartesian_spherical_harmonics_l1._omp_fn.0+0x500>
 	cmp    $0x2,%r15d
-	je     1d2b <cartesian_spherical_harmonics_l1._omp_fn.0+0x90b>
-	vmovapd 0x7acd(%rip),%ymm6        
-	vmovapd 0x7aa5(%rip),%ymm7        
+	je     1d64 <cartesian_spherical_harmonics_l1._omp_fn.0+0x8f4>
+	vmovapd 0xba7d(%rip),%ymm6        
+	vmovapd 0xba55(%rip),%ymm7        
 	mov    %eax,%r14d
-	lea    (%rbx,%r8,8),%r9
-	vmovapd 0x7ad6(%rip),%ymm5        
-	vmovapd 0x7aee(%rip),%ymm4        
+	lea    (%r12,%r8,8),%r9
+	vmovapd 0xba86(%rip),%ymm5        
+	vmovapd 0xba9e(%rip),%ymm4        
 	shr    $0x2,%r14d
-	vmovapd 0x7b02(%rip),%ymm3        
+	vmovapd 0xbab2(%rip),%ymm3        
 	shl    $0x7,%r14
 	add    %r9,%r14
 	data16 cs nopw 0x0(%rax,%rax,1)
+	vmovupd (%rsi),%ymm2
 	vmovupd (%rsi),%ymm1
-	vpermilpd $0x2,0x40(%rsi),%ymm0
 	sub    $0xffffffffffffff80,%r9
 	add    $0x180,%rcx
-	vperm2f128 $0x30,0x20(%rsi),%ymm1,%ymm2
+	vperm2f128 $0x30,0x20(%rsi),%ymm2,%ymm2
 	vperm2f128 $0x2,0x20(%rsi),%ymm1,%ymm1
 	add    $0x60,%rsi
+	vpermilpd $0x2,-0x20(%rsi),%ymm0
 	vpermpd $0x4e,-0x60(%rsi),%ymm8
 	vmovupd -0x20(%rsi),%ymm11
 	vshufpd $0x5,%ymm1,%ymm2,%ymm1
 	vblendpd $0x8,%ymm0,%ymm1,%ymm1
 	vmovdqu -0x60(%rsi),%ymm0
 	vshufpd $0x2,%ymm8,%ymm2,%ymm2
 	vpalignr $0x8,-0x40(%rsi),%ymm0,%ymm0
@@ -363,42 +364,41 @@
 	vmovupd %ymm5,-0xc0(%rcx)
 	vmovupd %ymm4,-0xa0(%rcx)
 	vmovupd %ymm3,-0x80(%rcx)
 	vmovupd %ymm5,-0x60(%rcx)
 	vmovupd %ymm4,-0x40(%rcx)
 	vmovupd %ymm3,-0x20(%rcx)
 	cmp    %r9,%r14
-	jne    1590 <cartesian_spherical_harmonics_l1._omp_fn.0+0x170>
-	mov    %eax,%esi
-	and    $0xfffffffc,%esi
-	add    %esi,%edx
-	cmp    %esi,%eax
-	je     19b9 <cartesian_spherical_harmonics_l1._omp_fn.0+0x599>
-	mov    %esi,%r9d
+	jne    15e0 <cartesian_spherical_harmonics_l1._omp_fn.0+0x170>
+	mov    %eax,%r9d
+	and    $0xfffffffc,%r9d
+	add    %r9d,%edx
+	cmp    %r9d,%eax
+	je     1a02 <cartesian_spherical_harmonics_l1._omp_fn.0+0x592>
+	mov    %r9d,%esi
 	mov    %eax,%ecx
-	vmovsd 0x7b24(%rip),%xmm6        
-	not    %r9d
-	sub    %esi,%ecx
-	add    %r9d,%eax
+	vmovsd 0xbacc(%rip),%xmm6        
+	not    %esi
+	sub    %r9d,%ecx
+	add    %esi,%eax
 	cmp    $0x1,%eax
-	jbe    1849 <cartesian_spherical_harmonics_l1._omp_fn.0+0x429>
-	mov    %esi,%r9d
-	vmovapd 0x7e08(%rip),%xmm4        
-	vmovapd 0x7e10(%rip),%xmm7        
+	jbe    189d <cartesian_spherical_harmonics_l1._omp_fn.0+0x42d>
 	lea    (%r9,%r9,2),%rax
-	vmovsd 0x7af4(%rip),%xmm6        
+	vmovapd 0xbf90(%rip),%xmm4        
+	vmovapd 0xbf98(%rip),%xmm7        
 	lea    (%rdi,%rax,4),%rsi
 	add    %r11,%rax
-	lea    0x0(%r13,%rsi,8),%rdi
-	lea    (%r12,%rax,8),%rsi
+	vmovsd 0xba99(%rip),%xmm6        
+	lea    (%rbx,%rax,8),%rdi
 	lea    (%r8,%r9,4),%rax
-	vmovupd (%rsi),%xmm2
-	vmovupd 0x10(%rsi),%xmm3
-	lea    (%rbx,%rax,8),%rax
-	vmovupd 0x20(%rsi),%xmm0
+	lea    0x0(%r13,%rsi,8),%rsi
+	vmovupd (%rdi),%xmm2
+	vmovupd 0x10(%rdi),%xmm3
+	lea    (%r12,%rax,8),%rax
+	vmovupd 0x20(%rdi),%xmm0
 	vunpcklpd %xmm2,%xmm3,%xmm5
 	vpermilpd $0x1,%xmm2,%xmm1
 	vmovsd %xmm2,%xmm3,%xmm2
 	vunpcklpd %xmm0,%xmm1,%xmm1
 	vmulpd %xmm4,%xmm2,%xmm2
 	vmovsd %xmm5,%xmm0,%xmm0
 	vmulpd %xmm4,%xmm0,%xmm0
@@ -408,168 +408,162 @@
 	vunpcklpd %xmm2,%xmm1,%xmm4
 	vunpckhpd %xmm2,%xmm1,%xmm1
 	vunpcklpd %xmm4,%xmm3,%xmm2
 	vunpckhpd %xmm4,%xmm3,%xmm3
 	vmovupd %xmm2,(%rax)
 	vunpcklpd %xmm1,%xmm0,%xmm2
 	vunpckhpd %xmm1,%xmm0,%xmm0
-	vmovapd 0x7da0(%rip),%xmm1        
+	vmovapd 0xbf2c(%rip),%xmm1        
 	vmovupd %xmm2,0x20(%rax)
-	vmovq  0x7da3(%rip),%xmm2        
+	vmovq  0xbf2f(%rip),%xmm2        
 	vmovupd %xmm0,0x30(%rax)
 	vmovupd %xmm3,0x10(%rax)
 	mov    %ecx,%eax
 	vxorpd %xmm0,%xmm0,%xmm0
 	and    $0xfffffffe,%eax
-	vmovupd %xmm0,(%rdi)
-	vmovupd %xmm0,0x30(%rdi)
-	vmovupd %xmm0,0x40(%rdi)
-	vmovupd %xmm0,0x60(%rdi)
-	vmovupd %xmm0,0x90(%rdi)
-	vmovupd %xmm0,0xa0(%rdi)
+	vmovupd %xmm0,(%rsi)
+	vmovupd %xmm0,0x30(%rsi)
+	vmovupd %xmm0,0x40(%rsi)
+	vmovupd %xmm0,0x60(%rsi)
+	vmovupd %xmm0,0x90(%rsi)
+	vmovupd %xmm0,0xa0(%rsi)
 	add    %eax,%edx
-	vmovupd %xmm1,0x10(%rdi)
-	vmovupd %xmm1,0x20(%rdi)
-	vmovupd %xmm1,0x70(%rdi)
-	vmovupd %xmm2,0x50(%rdi)
-	vmovupd %xmm1,0x80(%rdi)
-	vmovupd %xmm2,0xb0(%rdi)
+	vmovupd %xmm1,0x10(%rsi)
+	vmovupd %xmm1,0x20(%rsi)
+	vmovupd %xmm1,0x70(%rsi)
+	vmovupd %xmm2,0x50(%rsi)
+	vmovupd %xmm1,0x80(%rsi)
+	vmovupd %xmm2,0xb0(%rsi)
 	cmp    %eax,%ecx
-	je     19b9 <cartesian_spherical_harmonics_l1._omp_fn.0+0x599>
-	vmovapd 0x7807(%rip),%ymm5        
-	vmovapd 0x781f(%rip),%ymm4        
-	vmovapd 0x7837(%rip),%ymm3        
-	lea    (%rdx,%rdx,2),%eax
+	je     1a02 <cartesian_spherical_harmonics_l1._omp_fn.0+0x592>
+	vmovapd 0xb7b3(%rip),%ymm5        
+	vmovapd 0xb7cb(%rip),%ymm4        
+	vmovapd 0xb7e3(%rip),%ymm3        
 	lea    0x0(,%rdx,4),%ecx
-	vmovsd 0x79ed(%rip),%xmm0        
+	lea    (%rdx,%rdx,2),%eax
+	vmovsd 0xb999(%rip),%xmm0        
 	inc    %edx
-	movslq %eax,%rdi
 	movslq %ecx,%rcx
+	movslq %eax,%rdi
 	shl    $0x2,%eax
-	shl    $0x3,%rdi
 	shl    $0x3,%rcx
 	cltq
-	lea    (%rbx,%rcx,1),%rsi
-	lea    (%r12,%rdi,1),%r8
+	lea    0x0(,%rdi,8),%r8
+	lea    (%r12,%rcx,1),%rsi
 	shl    $0x3,%rax
 	vmovsd %xmm6,(%rsi)
-	vmovsd 0x10(%r8),%xmm2
-	vmovsd (%r8),%xmm1
-	vmulsd 0x8(%r8),%xmm0,%xmm7
-	vmulsd %xmm0,%xmm2,%xmm2
-	vmulsd %xmm0,%xmm1,%xmm1
-	vmovsd %xmm7,0x8(%rsi)
-	vmovsd %xmm2,0x10(%rsi)
+	vmulsd 0x8(%rbx,%rdi,8),%xmm0,%xmm1
+	vmovsd %xmm1,0x8(%rsi)
+	vmulsd 0x10(%rbx,%rdi,8),%xmm0,%xmm1
+	vmovsd %xmm1,0x10(%rsi)
+	vmulsd (%rbx,%rdi,8),%xmm0,%xmm1
 	vmovsd %xmm1,0x18(%rsi)
 	lea    0x0(%r13,%rax,1),%rsi
 	vmovupd %ymm5,(%rsi)
 	vmovupd %ymm4,0x20(%rsi)
 	vmovupd %ymm3,0x40(%rsi)
 	cmp    %edx,%r10d
-	jle    19b9 <cartesian_spherical_harmonics_l1._omp_fn.0+0x599>
-	lea    0x20(%rbx,%rcx,1),%rdx
-	lea    0x18(%r12,%rdi,1),%rsi
+	jle    1a02 <cartesian_spherical_harmonics_l1._omp_fn.0+0x592>
+	lea    0x20(%r12,%rcx,1),%rdx
 	lea    0x60(%r13,%rax,1),%rax
 	vmovsd %xmm6,(%rdx)
-	vmovsd 0x10(%rsi),%xmm2
-	vmovsd (%rsi),%xmm1
-	vmulsd 0x8(%rsi),%xmm0,%xmm6
-	vmulsd %xmm0,%xmm2,%xmm2
-	vmulsd %xmm0,%xmm1,%xmm0
-	vmovsd %xmm6,0x8(%rdx)
-	vmovsd %xmm2,0x10(%rdx)
+	vmulsd 0x20(%rbx,%r8,1),%xmm0,%xmm1
+	vmovsd %xmm1,0x8(%rdx)
+	vmulsd 0x28(%rbx,%r8,1),%xmm0,%xmm1
+	vmovsd %xmm1,0x10(%rdx)
+	vmulsd 0x18(%rbx,%r8,1),%xmm0,%xmm0
 	vmovsd %xmm0,0x18(%rdx)
 	vmovupd %ymm5,(%rax)
 	vmovupd %ymm4,0x20(%rax)
 	vmovupd %ymm3,0x40(%rax)
 	vzeroupper
 	lea    -0x28(%rbp),%rsp
 	pop    %rbx
 	pop    %r12
 	pop    %r13
 	pop    %r14
 	pop    %r15
 	pop    %rbp
 	ret
-	nopl   0x0(%rax)
-	vmovapd 0x7718(%rip),%ymm5        
-	vmovapd 0x7730(%rip),%ymm4        
+	data16 cs nopw 0x0(%rax,%rax,1)
+	nopl   (%rax)
+	vmovapd 0xb6c8(%rip),%ymm5        
+	vmovapd 0xb6e0(%rip),%ymm4        
 	movslq %edx,%rdx
-	vmovapd 0x7745(%rip),%ymm3        
-	vmovsd 0x78fd(%rip),%xmm6        
-	mov    %rdx,%rdi
-	vmovsd 0x78fa(%rip),%xmm0        
-	mov    0x4(%rsp),%eax
-	shl    $0x5,%rdi
-	add    %rbx,%rdi
-	add    %rax,%rdx
+	vmovapd 0xb6f5(%rip),%ymm3        
+	vmovsd 0xb8ad(%rip),%xmm6        
+	mov    %rdx,%rax
+	vmovsd 0xb8aa(%rip),%xmm0        
+	mov    0x4(%rsp),%edi
+	shl    $0x5,%rax
+	add    %r12,%rax
+	add    %rdi,%rdx
 	shl    $0x5,%rdx
-	lea    0x20(%rbx,%rdx,1),%rax
+	lea    0x20(%r12,%rdx,1),%rdx
 	data16 cs nopw 0x0(%rax,%rax,1)
-	vmovsd %xmm6,(%rdi)
-	vmovsd 0x10(%rsi),%xmm2
-	vmovsd (%rsi),%xmm1
-	add    $0x20,%rdi
-	vmulsd 0x8(%rsi),%xmm0,%xmm7
-	add    $0x60,%rcx
+	vmovsd %xmm6,(%rax)
+	vmulsd 0x8(%rsi),%xmm0,%xmm1
+	add    $0x20,%rax
 	add    $0x18,%rsi
-	vmulsd %xmm0,%xmm2,%xmm2
-	vmulsd %xmm0,%xmm1,%xmm1
-	vmovsd %xmm7,-0x18(%rdi)
-	vmovsd %xmm2,-0x10(%rdi)
-	vmovsd %xmm1,-0x8(%rdi)
+	add    $0x60,%rcx
+	vmovsd %xmm1,-0x18(%rax)
+	vmulsd -0x8(%rsi),%xmm0,%xmm1
+	vmovsd %xmm1,-0x10(%rax)
+	vmulsd -0x18(%rsi),%xmm0,%xmm1
+	vmovsd %xmm1,-0x8(%rax)
 	vmovupd %ymm5,-0x60(%rcx)
 	vmovupd %ymm4,-0x40(%rcx)
 	vmovupd %ymm3,-0x20(%rcx)
-	cmp    %rdi,%rax
-	jne    1970 <cartesian_spherical_harmonics_l1._omp_fn.0+0x550>
+	cmp    %rdx,%rax
+	jne    19c0 <cartesian_spherical_harmonics_l1._omp_fn.0+0x550>
 	vzeroupper
 	lea    -0x28(%rbp),%rsp
 	pop    %rbx
 	pop    %r12
 	pop    %r13
 	pop    %r14
 	pop    %r15
 	pop    %rbp
 	ret
-	nopl   0x0(%rax,%rax,1)
+	data16 cs nopw 0x0(%rax,%rax,1)
+	nop
 	cmp    %edx,%ecx
-	jl     1cb0 <cartesian_spherical_harmonics_l1._omp_fn.0+0x890>
+	jl     1cf0 <cartesian_spherical_harmonics_l1._omp_fn.0+0x880>
 	imul   %eax,%ecx
 	add    %ecx,%edx
 	lea    (%rax,%rdx,1),%ecx
 	cmp    %ecx,%edx
-	jge    190d <cartesian_spherical_harmonics_l1._omp_fn.0+0x4ed>
+	jge    1953 <cartesian_spherical_harmonics_l1._omp_fn.0+0x4e3>
 	mov    %eax,%edi
 	lea    (%rdx,%rdx,2),%r9d
 	lea    0x0(,%rdx,4),%r8d
 	mov    %eax,%r10d
 	movslq %r9d,%r9
 	lea    (%rdi,%rdi,2),%r11
 	movslq %r8d,%r8
 	add    %r9,%r11
-	lea    (%rbx,%r8,8),%rcx
+	lea    (%r12,%r8,8),%rcx
 	lea    (%r8,%rdi,4),%rdi
-	lea    (%r12,%r9,8),%rsi
-	lea    (%r12,%r11,8),%r11
-	lea    (%rbx,%rdi,8),%rdi
+	lea    (%rbx,%r9,8),%rsi
+	lea    (%rbx,%r11,8),%r11
+	lea    (%r12,%rdi,8),%rdi
 	cmp    %r11,%rcx
 	setae  %r11b
 	cmp    %rdi,%rsi
 	setae  %dil
 	or     %r11d,%edi
 	and    $0x1,%edi
-	je     1cb9 <cartesian_spherical_harmonics_l1._omp_fn.0+0x899>
+	je     1cf9 <cartesian_spherical_harmonics_l1._omp_fn.0+0x889>
 	cmp    $0x1,%eax
-	je     1cb9 <cartesian_spherical_harmonics_l1._omp_fn.0+0x899>
+	je     1cf9 <cartesian_spherical_harmonics_l1._omp_fn.0+0x889>
 	lea    -0x1(%rax),%edi
 	cmp    $0x2,%edi
-	jbe    1d37 <cartesian_spherical_harmonics_l1._omp_fn.0+0x917>
-	vmovapd 0x75cf(%rip),%ymm6        
-	vmovapd 0x75a7(%rip),%ymm7        
+	jbe    1d71 <cartesian_spherical_harmonics_l1._omp_fn.0+0x901>
+	vmovapd 0xb57f(%rip),%ymm6        
+	vmovapd 0xb557(%rip),%ymm7        
 	mov    %eax,%edi
 	shr    $0x2,%edi
 	shl    $0x7,%rdi
 	add    %rcx,%rdi
 	data16 cs nopw 0x0(%rax,%rax,1)
 	vmovupd (%rsi),%ymm5
 	vpermilpd $0x2,0x40(%rsi),%ymm0
@@ -615,34 +609,34 @@
 	vpermpd $0x44,%ymm1,%ymm3
 	vpermpd $0xee,%ymm1,%ymm1
 	vshufpd $0xc,%ymm3,%ymm2,%ymm2
 	vshufpd $0xc,%ymm1,%ymm0,%ymm1
 	vmovupd %ymm2,-0x40(%rcx)
 	vmovupd %ymm1,-0x20(%rcx)
 	cmp    %rcx,%rdi
-	jne    1a70 <cartesian_spherical_harmonics_l1._omp_fn.0+0x650>
+	jne    1ac0 <cartesian_spherical_harmonics_l1._omp_fn.0+0x650>
 	mov    %eax,%ecx
 	and    $0xfffffffc,%ecx
 	add    %ecx,%edx
 	cmp    %ecx,%eax
-	je     19b9 <cartesian_spherical_harmonics_l1._omp_fn.0+0x599>
+	je     1a02 <cartesian_spherical_harmonics_l1._omp_fn.0+0x592>
 	sub    %ecx,%eax
 	mov    %eax,%r10d
 	cmp    $0x1,%eax
-	je     1d3e <cartesian_spherical_harmonics_l1._omp_fn.0+0x91e>
+	je     1d78 <cartesian_spherical_harmonics_l1._omp_fn.0+0x908>
 	vzeroupper
 	mov    %ecx,%eax
-	vmovapd 0x7999(%rip),%xmm3        
-	vmovapd 0x79a1(%rip),%xmm7        
+	vmovapd 0xbb29(%rip),%xmm3        
+	vmovapd 0xbb31(%rip),%xmm7        
 	lea    (%rax,%rax,2),%rcx
-	vmovsd 0x7685(%rip),%xmm6        
+	vmovsd 0xb635(%rip),%xmm6        
 	lea    (%r8,%rax,4),%rax
 	add    %rcx,%r9
-	lea    (%rbx,%rax,8),%rax
-	lea    (%r12,%r9,8),%rcx
+	lea    (%r12,%rax,8),%rax
+	lea    (%rbx,%r9,8),%rcx
 	vmovupd (%rcx),%xmm4
 	vmovupd 0x10(%rcx),%xmm2
 	vmovupd 0x20(%rcx),%xmm0
 	vunpcklpd %xmm4,%xmm2,%xmm5
 	vpermilpd $0x1,%xmm4,%xmm1
 	vmovsd %xmm4,%xmm2,%xmm2
 	vunpcklpd %xmm0,%xmm1,%xmm1
@@ -662,85 +656,79 @@
 	vmovupd %xmm3,0x10(%rax)
 	vmovupd %xmm2,0x20(%rax)
 	vmovupd %xmm0,0x30(%rax)
 	mov    %r10d,%eax
 	and    $0xfffffffe,%eax
 	add    %eax,%edx
 	cmp    %r10d,%eax
-	je     190d <cartesian_spherical_harmonics_l1._omp_fn.0+0x4ed>
+	je     1953 <cartesian_spherical_harmonics_l1._omp_fn.0+0x4e3>
 	lea    (%rdx,%rdx,2),%eax
 	shl    $0x2,%edx
-	vmovsd 0x75fc(%rip),%xmm1        
-	cltq
+	vmovsd 0xb5ac(%rip),%xmm0        
 	movslq %edx,%rdx
-	lea    (%r12,%rax,8),%rcx
-	lea    (%rbx,%rdx,8),%rax
-	vmovsd %xmm6,(%rax)
-	vmovsd 0x10(%rcx),%xmm2
-	vmovsd (%rcx),%xmm0
-	vmulsd 0x8(%rcx),%xmm1,%xmm3
-	vmulsd %xmm1,%xmm2,%xmm2
-	vmulsd %xmm1,%xmm0,%xmm0
-	vmovsd %xmm3,0x8(%rax)
-	vmovsd %xmm2,0x10(%rax)
-	vmovsd %xmm0,0x18(%rax)
+	cltq
+	lea    (%r12,%rdx,8),%rdx
+	vmovsd %xmm6,(%rdx)
+	vmulsd 0x8(%rbx,%rax,8),%xmm0,%xmm1
+	vmovsd %xmm1,0x8(%rdx)
+	vmulsd 0x10(%rbx,%rax,8),%xmm0,%xmm1
+	vmovsd %xmm1,0x10(%rdx)
+	vmulsd (%rbx,%rax,8),%xmm0,%xmm0
+	vmovsd %xmm0,0x18(%rdx)
 	lea    -0x28(%rbp),%rsp
 	pop    %rbx
 	pop    %r12
 	pop    %r13
 	pop    %r14
 	pop    %r15
 	pop    %rbp
 	ret
-	data16 cs nopw 0x0(%rax,%rax,1)
-	nopl   0x0(%rax)
+	nopl   0x0(%rax,%rax,1)
 	inc    %eax
 	xor    %edx,%edx
-	jmp    146b <cartesian_spherical_harmonics_l1._omp_fn.0+0x4b>
+	jmp    14bb <cartesian_spherical_harmonics_l1._omp_fn.0+0x4b>
 	nopl   0x0(%rax)
 	inc    %eax
 	xor    %edx,%edx
-	jmp    19d8 <cartesian_spherical_harmonics_l1._omp_fn.0+0x5b8>
-	vmovsd 0x757f(%rip),%xmm6        
-	vmovsd 0x757f(%rip),%xmm0        
+	jmp    1a28 <cartesian_spherical_harmonics_l1._omp_fn.0+0x5b8>
+	vmovsd 0xb53f(%rip),%xmm6        
+	vmovsd 0xb53f(%rip),%xmm0        
 	movslq %edx,%rdx
 	dec    %eax
 	mov    %rdx,%rcx
 	add    %rax,%rdx
 	shl    $0x5,%rcx
 	shl    $0x5,%rdx
-	add    %rbx,%rcx
-	lea    0x20(%rbx,%rdx,1),%rax
+	add    %r12,%rcx
+	lea    0x20(%r12,%rdx,1),%rax
 	data16 cs nopw 0x0(%rax,%rax,1)
 	nop
 	vmovsd %xmm6,(%rcx)
-	vmovsd 0x10(%rsi),%xmm2
-	vmovsd (%rsi),%xmm1
+	vmulsd 0x8(%rsi),%xmm0,%xmm1
 	add    $0x20,%rcx
-	vmulsd 0x8(%rsi),%xmm0,%xmm3
 	add    $0x18,%rsi
-	vmulsd %xmm0,%xmm2,%xmm2
-	vmulsd %xmm0,%xmm1,%xmm1
-	vmovsd %xmm3,-0x18(%rcx)
-	vmovsd %xmm2,-0x10(%rcx)
+	vmovsd %xmm1,-0x18(%rcx)
+	vmulsd -0x8(%rsi),%xmm0,%xmm1
+	vmovsd %xmm1,-0x10(%rcx)
+	vmulsd -0x18(%rsi),%xmm0,%xmm1
 	vmovsd %xmm1,-0x8(%rcx)
 	cmp    %rax,%rcx
-	jne    1cf0 <cartesian_spherical_harmonics_l1._omp_fn.0+0x8d0>
-	jmp    190d <cartesian_spherical_harmonics_l1._omp_fn.0+0x4ed>
+	jne    1d30 <cartesian_spherical_harmonics_l1._omp_fn.0+0x8c0>
+	jmp    1953 <cartesian_spherical_harmonics_l1._omp_fn.0+0x4e3>
 	mov    $0x3,%ecx
-	xor    %esi,%esi
-	jmp    172d <cartesian_spherical_harmonics_l1._omp_fn.0+0x30d>
+	xor    %r9d,%r9d
+	jmp    1784 <cartesian_spherical_harmonics_l1._omp_fn.0+0x314>
 	xor    %ecx,%ecx
-	jmp    1b9d <cartesian_spherical_harmonics_l1._omp_fn.0+0x77d>
-	vmovsd 0x74fa(%rip),%xmm6        
+	jmp    1bed <cartesian_spherical_harmonics_l1._omp_fn.0+0x77d>
+	vmovsd 0xb4c0(%rip),%xmm6        
 	vzeroupper
-	jmp    1c3e <cartesian_spherical_harmonics_l1._omp_fn.0+0x81e>
-	xchg   %ax,%ax
+	jmp    1c8e <cartesian_spherical_harmonics_l1._omp_fn.0+0x81e>
+	nopl   0x0(%rax,%rax,1)
 
-0000000000001d50 <cartesian_spherical_harmonics_l2._omp_fn.0>:
+0000000000001d90 <cartesian_spherical_harmonics_l2._omp_fn.0>:
 cartesian_spherical_harmonics_l2._omp_fn.0():
 	push   %rbp
 	mov    %rsp,%rbp
 	push   %r15
 	push   %r14
 	mov    %rdi,%r15
 	push   %r13
@@ -754,75 +742,73 @@
 	mov    %eax,%r13d
 	call   1080 <omp_get_thread_num@plt>
 	mov    %eax,%ecx
 	mov    0x18(%r15),%eax
 	cltd
 	idiv   %r13d
 	test   %r14,%r14
-	je     1fc0 <cartesian_spherical_harmonics_l2._omp_fn.0+0x270>
+	je     2000 <cartesian_spherical_harmonics_l2._omp_fn.0+0x270>
 	cmp    %edx,%ecx
-	jl     20e0 <cartesian_spherical_harmonics_l2._omp_fn.0+0x390>
+	jl     2120 <cartesian_spherical_harmonics_l2._omp_fn.0+0x390>
 	imul   %eax,%ecx
 	add    %ecx,%edx
 	lea    (%rax,%rdx,1),%ecx
 	cmp    %ecx,%edx
-	jge    1fac <cartesian_spherical_harmonics_l2._omp_fn.0+0x25c>
-	vmovsd 0x7491(%rip),%xmm14        
-	vmovsd 0x7491(%rip),%xmm2        
+	jge    1fe5 <cartesian_spherical_harmonics_l2._omp_fn.0+0x255>
+	vmovsd 0xb451(%rip),%xmm14        
+	vmovsd 0xb451(%rip),%xmm2        
+	lea    (%rdx,%rdx,2),%ecx
 	movslq %edx,%rdi
-	lea    (%rdx,%rdx,8),%ecx
-	vmovsd 0x748b(%rip),%xmm3        
-	vmovsd 0x748b(%rip),%xmm6        
-	lea    (%rdx,%rdx,2),%esi
+	vmovsd 0xb44b(%rip),%xmm3        
+	vmovsd 0xb44b(%rip),%xmm6        
+	movslq %ecx,%rcx
 	dec    %eax
-	vmovsd 0x7486(%rip),%xmm5        
-	vmovsd 0x7486(%rip),%xmm4        
+	vmovsd 0xb446(%rip),%xmm5        
+	vmovsd 0xb446(%rip),%xmm4        
+	lea    (%rbx,%rcx,8),%rsi
+	lea    (%rdx,%rdx,8),%ecx
+	vmovapd 0xb20f(%rip),%ymm12        
+	vmovq  0xb927(%rip),%xmm8        
 	imul   $0xd8,%rdi,%rdx
 	add    %rax,%rdi
-	vmovapd 0x724c(%rip),%ymm12        
-	vmovq  0x7784(%rip),%xmm8        
 	movslq %ecx,%rcx
-	movslq %esi,%rsi
 	lea    (%rdi,%rdi,8),%rax
 	lea    (%r12,%rcx,8),%rcx
-	lea    (%rbx,%rsi,8),%rsi
-	add    %r14,%rdx
 	lea    0x48(%r12,%rax,8),%rax
+	add    %r14,%rdx
 	cs nopw 0x0(%rax,%rax,1)
-	vmovsd %xmm14,(%rcx)
-	vmovsd 0x10(%rsi),%xmm9
-	vmovsd (%rsi),%xmm1
+	vmovsd 0x10(%rsi),%xmm1
+	vmovsd 0x8(%rsi),%xmm13
 	add    $0x48,%rcx
-	vmulsd 0x8(%rsi),%xmm2,%xmm7
-	add    $0xd8,%rdx
 	add    $0x18,%rsi
-	vmulsd %xmm2,%xmm9,%xmm9
-	vmulsd %xmm2,%xmm1,%xmm1
-	vmovsd %xmm7,-0x40(%rcx)
-	vmovsd %xmm9,-0x38(%rcx)
-	vmovsd %xmm1,-0x30(%rcx)
-	vmovsd -0x8(%rsi),%xmm1
-	vmovsd -0x10(%rsi),%xmm13
 	vmovsd -0x18(%rsi),%xmm0
+	vmovsd %xmm14,-0x48(%rcx)
+	add    $0xd8,%rdx
+	vmulsd %xmm13,%xmm13,%xmm7
 	vmulsd %xmm1,%xmm1,%xmm15
+	vmulsd %xmm2,%xmm13,%xmm13
+	vmulsd %xmm2,%xmm1,%xmm10
 	vmulsd %xmm3,%xmm1,%xmm1
-	vmulsd %xmm7,%xmm1,%xmm1
-	vmulsd %xmm13,%xmm13,%xmm13
+	vmulsd %xmm2,%xmm0,%xmm9
+	vmovsd %xmm13,-0x40(%rcx)
+	vmovsd %xmm10,-0x38(%rcx)
+	vmulsd %xmm13,%xmm1,%xmm1
+	vmovsd %xmm9,-0x30(%rcx)
+	vmulsd %xmm3,%xmm0,%xmm9
 	vmovsd %xmm1,-0x20(%rcx)
-	vmulsd %xmm3,%xmm0,%xmm10
 	vmovsd %xmm0,%xmm0,%xmm1
-	vfmadd132sd %xmm0,%xmm13,%xmm1
-	vfmsub132sd %xmm0,%xmm13,%xmm0
-	vmulsd %xmm7,%xmm10,%xmm11
+	vfmadd132sd %xmm0,%xmm7,%xmm1
+	vfmsub132sd %xmm0,%xmm7,%xmm0
+	vmovsd 0xb3a1(%rip),%xmm7        
+	vmulsd %xmm9,%xmm13,%xmm11
 	vmulsd %xmm9,%xmm10,%xmm9
-	vmovsd 0x73d0(%rip),%xmm7        
-	vfnmadd231sd %xmm6,%xmm15,%xmm1
 	vmovsd %xmm11,-0x28(%rcx)
-	vmovsd %xmm9,-0x10(%rcx)
+	vfnmadd231sd %xmm6,%xmm15,%xmm1
 	vmulsd %xmm4,%xmm0,%xmm0
+	vmovsd %xmm9,-0x10(%rcx)
 	vmovsd %xmm0,-0x8(%rcx)
 	vmulsd %xmm5,%xmm1,%xmm1
 	vmovsd %xmm1,-0x18(%rcx)
 	movq   $0x0,-0x48(%rdx)
 	movq   $0x0,-0x90(%rdx)
 	vmovupd %ymm12,-0xd8(%rdx)
 	vmovsd %xmm2,-0x88(%rdx)
@@ -833,835 +819,121 @@
 	movq   $0x0,-0x30(%rdx)
 	vmulsd -0x40(%rcx),%xmm3,%xmm13
 	movq   $0x0,-0xb0(%rdx)
 	vmovsd %xmm13,-0xb8(%rdx)
 	vmulsd -0x30(%rcx),%xmm7,%xmm0
 	vmovsd %xmm0,-0xa8(%rdx)
 	vmulsd -0x38(%rcx),%xmm3,%xmm1
+	vmulsd 0xb304(%rip),%xmm0,%xmm0        
 	vmovsd %xmm1,-0xa0(%rdx)
 	vmulsd -0x30(%rcx),%xmm3,%xmm15
-	vmulsd 0x7330(%rip),%xmm0,%xmm0        
+	vmovsd %xmm15,-0x98(%rdx)
+	vmovsd %xmm0,-0x70(%rdx)
+	vmulsd 0xb2ea(%rip),%xmm13,%xmm15        
 	vmovsd %xmm1,-0x68(%rdx)
 	movq   $0x0,-0x58(%rdx)
 	movq   $0x0,-0x8(%rdx)
 	movq   $0x0,-0x28(%rdx)
 	vmovsd %xmm13,-0x20(%rdx)
-	vmulsd 0x7316(%rip),%xmm1,%xmm1        
-	vmovsd %xmm15,-0x98(%rdx)
-	vmulsd 0x72fe(%rip),%xmm13,%xmm15        
-	vmovsd %xmm0,-0x70(%rdx)
 	vmovsd %xmm0,-0x10(%rdx)
-	vmovsd %xmm1,-0x18(%rdx)
+	vmulsd 0xb2c3(%rip),%xmm1,%xmm1        
 	vmovsd %xmm15,-0x60(%rdx)
 	vxorpd %xmm8,%xmm13,%xmm15
 	vmovsd %xmm15,-0x50(%rdx)
-	cmp    %rax,%rcx
-	jne    1e20 <cartesian_spherical_harmonics_l2._omp_fn.0+0xd0>
+	vmovsd %xmm1,-0x18(%rdx)
+	cmp    %rcx,%rax
+	jne    1e60 <cartesian_spherical_harmonics_l2._omp_fn.0+0xd0>
 	vzeroupper
 	add    $0x8,%rsp
 	pop    %rbx
 	pop    %r12
 	pop    %r13
 	pop    %r14
 	pop    %r15
 	pop    %rbp
 	ret
-	nopl   0x0(%rax,%rax,1)
+	data16 cs nopw 0x0(%rax,%rax,1)
+	nop
 	cmp    %edx,%ecx
-	jl     20f0 <cartesian_spherical_harmonics_l2._omp_fn.0+0x3a0>
+	jl     2130 <cartesian_spherical_harmonics_l2._omp_fn.0+0x3a0>
 	imul   %eax,%ecx
 	add    %ecx,%edx
 	lea    (%rax,%rdx,1),%ecx
 	cmp    %ecx,%edx
-	jge    1fac <cartesian_spherical_harmonics_l2._omp_fn.0+0x25c>
-	vmovsd 0x7264(%rip),%xmm14        
-	vmovsd 0x7264(%rip),%xmm2        
-	lea    (%rdx,%rdx,8),%ecx
-	lea    (%rdx,%rdx,2),%esi
-	vmovsd 0x725e(%rip),%xmm3        
-	vmovsd 0x725e(%rip),%xmm6        
+	jge    1fe5 <cartesian_spherical_harmonics_l2._omp_fn.0+0x255>
+	vmovsd 0xb224(%rip),%xmm14        
+	vmovsd 0xb224(%rip),%xmm2        
+	lea    (%rdx,%rdx,2),%ecx
 	dec    %eax
+	vmovsd 0xb21f(%rip),%xmm3        
+	vmovsd 0xb21f(%rip),%xmm6        
+	movslq %ecx,%rcx
+	vmovsd 0xb21c(%rip),%xmm5        
+	vmovsd 0xb21c(%rip),%xmm4        
+	lea    (%rbx,%rcx,8),%rsi
+	lea    (%rdx,%rdx,8),%ecx
 	movslq %edx,%rdx
-	vmovsd 0x7259(%rip),%xmm5        
-	vmovsd 0x7259(%rip),%xmm4        
-	add    %rax,%rdx
 	movslq %ecx,%rcx
-	movslq %esi,%rsi
-	lea    (%rdx,%rdx,8),%rax
+	add    %rax,%rdx
 	lea    (%r12,%rcx,8),%rcx
-	lea    (%rbx,%rsi,8),%rsi
+	lea    (%rdx,%rdx,8),%rax
 	lea    0x48(%r12,%rax,8),%rax
 	nopl   0x0(%rax)
-	vmovsd %xmm14,(%rcx)
-	vmovsd 0x10(%rsi),%xmm10
-	vmovsd (%rsi),%xmm0
+	vmovsd 0x10(%rsi),%xmm1
+	vmovsd 0x8(%rsi),%xmm7
 	add    $0x48,%rcx
-	vmulsd 0x8(%rsi),%xmm2,%xmm11
 	add    $0x18,%rsi
-	vmulsd %xmm2,%xmm10,%xmm10
-	vmulsd %xmm2,%xmm0,%xmm0
-	vmovsd %xmm11,-0x40(%rcx)
-	vmovsd %xmm10,-0x38(%rcx)
-	vmovsd %xmm0,-0x30(%rcx)
-	vmovsd -0x8(%rsi),%xmm1
-	vmovsd -0x10(%rsi),%xmm7
 	vmovsd -0x18(%rsi),%xmm0
+	vmovsd %xmm14,-0x48(%rcx)
+	vmulsd %xmm7,%xmm7,%xmm10
+	vmulsd %xmm2,%xmm1,%xmm9
+	vmulsd %xmm2,%xmm7,%xmm7
 	vmulsd %xmm1,%xmm1,%xmm8
+	vmovsd %xmm9,-0x38(%rcx)
 	vmulsd %xmm3,%xmm1,%xmm1
-	vmulsd %xmm11,%xmm1,%xmm1
-	vmulsd %xmm7,%xmm7,%xmm7
+	vmulsd %xmm2,%xmm0,%xmm11
+	vmovsd %xmm7,-0x40(%rcx)
+	vmulsd %xmm7,%xmm1,%xmm1
+	vmovsd %xmm11,-0x30(%rcx)
+	vmulsd %xmm3,%xmm0,%xmm11
 	vmovsd %xmm1,-0x20(%rcx)
-	vmulsd %xmm3,%xmm0,%xmm9
 	vmovsd %xmm0,%xmm0,%xmm1
-	vfmadd132sd %xmm0,%xmm7,%xmm1
-	vfmsub132sd %xmm0,%xmm7,%xmm0
-	vmulsd %xmm11,%xmm9,%xmm12
-	vmulsd %xmm10,%xmm9,%xmm9
-	vfnmadd231sd %xmm6,%xmm8,%xmm1
+	vfmadd132sd %xmm0,%xmm10,%xmm1
+	vfmsub132sd %xmm0,%xmm10,%xmm0
+	vmulsd %xmm11,%xmm7,%xmm12
+	vmulsd %xmm11,%xmm9,%xmm9
 	vmovsd %xmm12,-0x28(%rcx)
 	vmovsd %xmm9,-0x10(%rcx)
+	vfnmadd231sd %xmm6,%xmm8,%xmm1
 	vmulsd %xmm4,%xmm0,%xmm0
 	vmovsd %xmm0,-0x8(%rcx)
 	vmulsd %xmm5,%xmm1,%xmm1
 	vmovsd %xmm1,-0x18(%rcx)
 	cmp    %rcx,%rax
-	jne    2030 <cartesian_spherical_harmonics_l2._omp_fn.0+0x2e0>
+	jne    2070 <cartesian_spherical_harmonics_l2._omp_fn.0+0x2e0>
 	add    $0x8,%rsp
 	pop    %rbx
 	pop    %r12
 	pop    %r13
 	pop    %r14
 	pop    %r15
 	pop    %rbp
 	ret
-	nopl   0x0(%rax,%rax,1)
-	inc    %eax
-	xor    %edx,%edx
-	jmp    1d97 <cartesian_spherical_harmonics_l2._omp_fn.0+0x47>
+	data16 cs nopw 0x0(%rax,%rax,1)
 	nopl   0x0(%rax)
 	inc    %eax
 	xor    %edx,%edx
-	jmp    1fc8 <cartesian_spherical_harmonics_l2._omp_fn.0+0x278>
-	nopl   0x0(%rax)
-
-0000000000002100 <cartesian_spherical_harmonics_generic._omp_fn.0>:
-cartesian_spherical_harmonics_generic._omp_fn.0():
-	push   %rbp
-	mov    %rsp,%rbp
-	push   %r15
-	push   %r14
-	push   %r13
-	push   %r12
-	push   %rbx
-	and    $0xffffffffffffffe0,%rsp
-	sub    $0x100,%rsp
-	mov    0x18(%rdi),%rax
-	mov    0x20(%rdi),%r13d
-	mov    0x8(%rdi),%r14
-	mov    (%rdi),%r15
-	mov    %rax,0x60(%rsp)
-	mov    0x10(%rdi),%rax
-	mov    %rax,0xf0(%rsp)
-	mov    0x24(%rdi),%eax
-	lea    0x1(%rax),%r12d
-	lea    0x2(%rax),%edi
-	mov    %eax,0x84(%rsp)
-	imul   %r12,%rdi
-	mov    %r12d,0xbc(%rsp)
-	shl    $0x3,%r12
-	shl    $0x3,%rdi
-	shr    %rdi
-	call   10b0 <malloc@plt>
-	mov    %r12,%rdi
-	mov    %rax,0x38(%rsp)
-	call   10b0 <malloc@plt>
-	mov    %r12,%rdi
-	mov    %rax,0xf8(%rsp)
-	call   10b0 <malloc@plt>
-	mov    %rax,%rbx
-	call   1090 <omp_get_num_threads@plt>
-	mov    %eax,%r12d
-	call   1080 <omp_get_thread_num@plt>
-	mov    0xf8(%rsp),%r10
-	mov    %eax,%ecx
-	mov    %r13d,%eax
-	cltd
-	idiv   %r12d
-	cmp    %edx,%ecx
-	jl     2ed9 <cartesian_spherical_harmonics_generic._omp_fn.0+0xdd9>
-	imul   %eax,%ecx
-	add    %ecx,%edx
-	lea    (%rax,%rdx,1),%ecx
-	cmp    %ecx,%edx
-	jge    27aa <cartesian_spherical_harmonics_generic._omp_fn.0+0x6aa>
-	mov    0xbc(%rsp),%edi
-	dec    %eax
-	vmovsd 0x70c4(%rip),%xmm14        
-	vxorps %xmm0,%xmm0,%xmm0
-	vmovq  0x73a8(%rip),%xmm11        
-	mov    %r10,%r13
-	mov    %edi,%ecx
-	imul   %edi,%ecx
-	lea    (%rcx,%rcx,1),%r9d
-	movslq %ecx,%rdi
-	movslq %r9d,%r8
-	lea    0x0(,%rdi,8),%r11
-	lea    0x0(,%r8,8),%rsi
-	lea    0x8(%r11),%r12
-	mov    %r11,0xa0(%rsp)
-	add    $0x10,%r11
-	mov    %rsi,0x98(%rsp)
-	mov    %r12,0x90(%rsp)
-	lea    0x8(%rsi),%r12
-	add    $0x10,%rsi
-	mov    %rsi,0x28(%rsp)
-	lea    (%rdx,%rdx,2),%esi
-	mov    %r12,0x88(%rsp)
-	mov    %r11,0x30(%rsp)
-	movslq %esi,%rsi
-	mov    %r11,0x8(%rsp)
-	lea    (%r14,%rsi,8),%rsi
-	mov    0x38(%rsp),%r12
-	mov    %rsi,0x78(%rsp)
-	lea    (%r9,%rcx,1),%esi
-	imul   %edx,%ecx
-	movslq %edx,%rdx
-	mov    %esi,0x58(%rsp)
-	add    %rax,%rdx
-	lea    (%rdx,%rdx,2),%rax
-	lea    0x18(%r14,%rax,8),%rax
-	lea    (%rcx,%rcx,2),%esi
-	movslq %ecx,%rcx
-	mov    %rbx,%r14
-	mov    %rax,0x50(%rsp)
-	mov    0x84(%rsp),%eax
-	mov    %esi,0x5c(%rsp)
-	mov    0xf0(%rsp),%rsi
-	sub    $0x3,%eax
-	lea    0x8(%rsi,%rcx,8),%rcx
-	mov    %eax,0x4c(%rsp)
-	shr    %eax
-	mov    %rcx,0x68(%rsp)
-	lea    0x5(%rax,%rax,1),%rax
-	mov    %rax,0x40(%rsp)
-	lea    0x10(,%r8,8),%rax
-	mov    %rax,0x10(%rsp)
-	lea    0x18(,%rdi,8),%rax
-	mov    %rax,0x18(%rsp)
-	lea    0x18(,%r8,8),%rax
-	mov    %rax,0x20(%rsp)
+	jmp    1dd7 <cartesian_spherical_harmonics_l2._omp_fn.0+0x47>
 	nopl   0x0(%rax)
-	mov    0x78(%rsp),%rax
-	vmovsd %xmm14,(%r12)
-	cmpl   $0x1,0xbc(%rsp)
-	vmovsd (%r15),%xmm9
-	vmovsd 0x8(%rax),%xmm2
-	vmovsd (%rax),%xmm1
-	vmovsd 0x10(%rax),%xmm8
-	vmulsd %xmm2,%xmm2,%xmm7
-	vfmadd231sd %xmm1,%xmm1,%xmm7
-	vfmadd231sd %xmm8,%xmm8,%xmm7
-	jbe    2eaf <cartesian_spherical_harmonics_generic._omp_fn.0+0xdaf>
-	mov    0x6f87(%rip),%rax        
-	mov    0xbc(%rsp),%edi
-	vmovsd %xmm8,0x8(%r12)
-	vxorpd 0x7259(%rip),%xmm8,%xmm4        
-	mov    %rax,0x10(%r12)
-	cmp    $0x2,%edi
-	je     2411 <cartesian_spherical_harmonics_generic._omp_fn.0+0x311>
-	mov    $0xfffffffd,%esi
-	mov    $0x3,%edx
-	mov    $0x2,%eax
-	data16 cs nopw 0x0(%rax,%rax,1)
-	nop
-	movslq %edx,%rcx
-	vcvtsi2sd %esi,%xmm0,%xmm3
-	sub    $0x2,%esi
-	vmulsd -0x8(%r12,%rcx,8),%xmm3,%xmm3
-	lea    (%rdx,%rax,1),%ecx
-	movslq %ecx,%rcx
-	vmovsd %xmm3,(%r12,%rcx,8)
-	vmulsd %xmm4,%xmm3,%xmm3
-	lea    -0x1(%rax,%rdx,1),%ecx
-	inc    %eax
-	movslq %ecx,%rcx
-	add    %eax,%edx
-	vmovsd %xmm3,(%r12,%rcx,8)
-	cmp    %edi,%eax
-	jne    2350 <cartesian_spherical_harmonics_generic._omp_fn.0+0x250>
-	mov    0xbc(%rsp),%r10d
-	mov    $0xffffffffffffffe0,%rsi
-	mov    $0xfffffffffffffff0,%rcx
-	mov    $0x3,%r9d
-	mov    $0x2,%edi
-	mov    $0x3,%r8d
-	nopl   (%rax)
-	lea    -0x2(%rdi),%eax
-	vcvtsi2sd %r9d,%xmm0,%xmm6
-	vmulsd %xmm8,%xmm6,%xmm6
-	mov    %edi,%edx
-	vcvtsi2sd %eax,%xmm0,%xmm5
-	vmulsd %xmm7,%xmm5,%xmm5
-	movslq %r8d,%rax
-	lea    (%r12,%rax,8),%rax
-	xchg   %ax,%ax
-	vaddsd %xmm7,%xmm5,%xmm5
-	vmulsd 0x8(%rax,%rsi,1),%xmm5,%xmm3
-	vcvtsi2sd %edx,%xmm0,%xmm4
-	dec    %edx
-	add    $0x8,%rax
-	vfmsub231sd -0x8(%rax,%rcx,1),%xmm6,%xmm3
-	vdivsd %xmm4,%xmm3,%xmm3
-	vmovsd %xmm3,-0x8(%rax)
-	cmp    $0x1,%edx
-	jne    23d0 <cartesian_spherical_harmonics_generic._omp_fn.0+0x2d0>
-	lea    0x1(%r8,%rdi,1),%r8d
-	inc    %edi
-	add    $0x2,%r9d
-	sub    $0x8,%rcx
-	sub    $0x10,%rsi
-	cmp    %edi,%r10d
-	ja     23b0 <cartesian_spherical_harmonics_generic._omp_fn.0+0x2b0>
-	cmpl   $0xfffffffb,0x4c(%rsp)
-	vmovsd %xmm14,0x0(%r13)
-	movq   $0x0,(%r14)
-	ja     2ecf <cartesian_spherical_harmonics_generic._omp_fn.0+0xdcf>
-	vmovsd (%r14),%xmm3
-	vmovsd 0x0(%r13),%xmm4
-	mov    $0x3,%edx
-	movslq %edx,%rax
-	vmulsd %xmm3,%xmm2,%xmm5
-	vmulsd %xmm3,%xmm1,%xmm3
-	vfmadd231sd %xmm4,%xmm2,%xmm3
-	vfmsub231sd %xmm4,%xmm1,%xmm5
-	vmulsd %xmm3,%xmm2,%xmm4
-	vmovsd %xmm3,-0x10(%r14,%rdx,8)
-	vmulsd %xmm3,%xmm1,%xmm3
-	vfmsub231sd %xmm5,%xmm1,%xmm4
-	vfmadd231sd %xmm5,%xmm2,%xmm3
-	vunpcklpd %xmm4,%xmm5,%xmm6
-	vmovupd %xmm6,-0x10(%r13,%rdx,8)
-	vmovsd %xmm3,-0x8(%r14,%rdx,8)
-	add    $0x2,%rdx
-	cmp    %rdx,0x40(%rsp)
-	jne    2439 <cartesian_spherical_harmonics_generic._omp_fn.0+0x339>
-	mov    0xbc(%rsp),%edx
-	nopl   0x0(%rax,%rax,1)
-	vmovsd -0x8(%r14,%rax,8),%xmm4
-	vmovsd -0x8(%r13,%rax,8),%xmm3
-	vmulsd %xmm4,%xmm2,%xmm5
-	vmulsd %xmm4,%xmm1,%xmm4
-	vfmsub231sd %xmm3,%xmm1,%xmm5
-	vfmadd132sd %xmm2,%xmm4,%xmm3
-	vmovsd %xmm5,0x0(%r13,%rax,8)
-	vmovsd %xmm3,(%r14,%rax,8)
-	inc    %rax
-	cmp    %eax,%edx
-	ja     2490 <cartesian_spherical_harmonics_generic._omp_fn.0+0x390>
-	vmovsd (%r12),%xmm5
-	mov    0x68(%rsp),%rax
-	mov    $0x1,%r10d
-	movq   $0x18,0xd0(%rsp)
-	movq   $0x8,0xe8(%rsp)
-	movl   $0x1,0xf8(%rsp)
-	mov    %r10,%rbx
-	mov    %rax,%r11
-	vmulsd %xmm9,%xmm5,%xmm9
-	vmovsd %xmm9,-0x8(%rax)
-	nopl   0x0(%rax,%rax,1)
-	movslq 0xf8(%rsp),%rdi
-	mov    %ebx,0xf0(%rsp)
-	mov    %ebx,%eax
-	mov    0xe8(%rsp),%rdx
-	lea    0x0(,%rdi,8),%r8
-	lea    (%r12,%r8,1),%rcx
-	lea    (%r15,%r8,1),%r10
-	mov    %rdx,%r9
-	lea    (%r11,%rdx,1),%rsi
-	vmovsd (%rcx),%xmm3
-	mov    %r10,0xa8(%rsp)
-	add    $0x8,%rdx
-	mov    %rcx,0xb0(%rsp)
-	mov    %rdx,0xe8(%rsp)
-	lea    (%r11,%rdx,1),%rcx
-	lea    0x8(%r15,%r8,1),%rdx
-	vmulsd (%r10),%xmm3,%xmm3
-	lea    -0x8(%r9),%r10
-	mov    %r10,0xd8(%rsp)
-	lea    0x1(%rdi),%r10
-	lea    0x1(%rdi,%rbx,1),%rdi
-	lea    (%r15,%rdi,8),%rdi
-	mov    %r10,0xe0(%rsp)
-	lea    0x8(%r8),%r10
-	lea    0x10(%r15,%r8,1),%r8
-	cmp    %rdi,%r11
-	mov    %r10,0xc0(%rsp)
-	setae  0xc8(%rsp)
-	movzbl 0xc8(%rsp),%r10d
-	cmp    %rdx,%rsi
-	setbe  %dil
-	or     %r10d,%edi
-	mov    %rcx,%r10
-	sub    %r8,%r10
-	cmp    $0x10,%r10
-	vmovsd %xmm3,(%rsi)
-	seta   %r8b
-	and    %r8d,%edi
-	and    $0x1,%edi
-	je     27f0 <cartesian_spherical_harmonics_generic._omp_fn.0+0x6f0>
-	cmp    %r9,0xe8(%rsp)
-	setge  %dil
-	cmp    $0x1,%ebx
-	setne  %r8b
-	and    %r8d,%edi
-	and    $0x1,%edi
-	je     27f0 <cartesian_spherical_harmonics_generic._omp_fn.0+0x6f0>
-	lea    -0x1(%rbx),%esi
-	mov    %ebx,%edi
-	cmp    $0x2,%esi
-	jbe    2849 <cartesian_spherical_harmonics_generic._omp_fn.0+0x749>
-	mov    0xc0(%rsp),%r10
-	shr    $0x2,%edi
-	lea    -0x20(%r11,%r9,1),%r9
-	xor    %esi,%esi
-	mov    %edi,%r8d
-	shl    $0x5,%r8
-	add    %r12,%r10
-	data16 cs nopw 0x0(%rax,%rax,1)
-	vmovupd (%rdx,%rsi,1),%ymm7
-	mov    %rsi,%rdi
-	vmulpd (%r10,%rsi,1),%ymm7,%ymm3
-	neg    %rdi
-	vmulpd 0x8(%r14,%rsi,1),%ymm3,%ymm4
-	vmulpd 0x8(%r13,%rsi,1),%ymm3,%ymm3
-	vpermpd $0x1b,%ymm4,%ymm4
-	vmovupd %ymm4,(%r9,%rdi,1)
-	vmovupd %ymm3,(%rcx,%rsi,1)
-	add    $0x20,%rsi
-	cmp    %rsi,%r8
-	jne    2630 <cartesian_spherical_harmonics_generic._omp_fn.0+0x530>
-	mov    0xf0(%rsp),%esi
-	mov    %esi,%ecx
-	and    $0xfffffffc,%ecx
-	lea    0x1(%rcx),%edx
-	cmp    %esi,%ecx
-	je     272a <cartesian_spherical_harmonics_generic._omp_fn.0+0x62a>
-	mov    0xf0(%rsp),%esi
-	sub    %ecx,%esi
-	cmp    $0x1,%esi
-	je     26e9 <cartesian_spherical_harmonics_generic._omp_fn.0+0x5e9>
-	mov    0xe0(%rsp),%r8
-	mov    %ecx,%edi
-	inc    %ecx
-	mov    %rcx,%r9
-	neg    %r9
-	add    %rdi,%r8
-	vmovupd (%r15,%r8,8),%xmm7
-	vmulpd (%r12,%r8,8),%xmm7,%xmm3
-	mov    0xd8(%rsp),%r8
-	vmulpd (%r14,%rcx,8),%xmm3,%xmm4
-	vmulpd 0x0(%r13,%rcx,8),%xmm3,%xmm3
-	lea    0x1(%rdi,%rbx,1),%rcx
-	add    %r11,%r8
-	vpermilpd $0x1,%xmm4,%xmm4
-	vmovupd %xmm4,(%r8,%r9,8)
-	vmovupd %xmm3,(%r11,%rcx,8)
-	mov    %esi,%ecx
-	and    $0xfffffffe,%ecx
-	add    %ecx,%edx
-	cmp    %esi,%ecx
-	je     272a <cartesian_spherical_harmonics_generic._omp_fn.0+0x62a>
-	mov    0xf8(%rsp),%esi
-	lea    (%rsi,%rdx,1),%ecx
-	movslq %edx,%rsi
-	movslq %ecx,%rcx
-	vmovsd (%r15,%rcx,8),%xmm3
-	vmulsd (%r12,%rcx,8),%xmm3,%xmm3
-	mov    %eax,%ecx
-	sub    %edx,%ecx
-	add    %eax,%edx
-	movslq %ecx,%rcx
-	movslq %edx,%rdx
-	vmulsd (%r14,%rsi,8),%xmm3,%xmm4
-	vmulsd 0x0(%r13,%rsi,8),%xmm3,%xmm3
-	vmovsd %xmm4,(%r11,%rcx,8)
-	vmovsd %xmm3,(%r11,%rdx,8)
-	inc    %rbx
-	mov    0xf8(%rsp),%eax
-	mov    0xf0(%rsp),%esi
-	lea    0x1(%rax,%rsi,1),%eax
-	mov    %eax,0xf8(%rsp)
-	mov    0xd0(%rsp),%rax
-	add    %rax,%r11
-	add    $0x10,%rax
-	mov    %rax,0xd0(%rsp)
-	cmp    %ebx,0xbc(%rsp)
-	ja     2510 <cartesian_spherical_harmonics_generic._omp_fn.0+0x410>
-	cmpq   $0x0,0x60(%rsp)
-	jne    2855 <cartesian_spherical_harmonics_generic._omp_fn.0+0x755>
-	addq   $0x18,0x78(%rsp)
-	mov    0x58(%rsp),%edx
-	mov    0x78(%rsp),%rax
-	add    %edx,0x5c(%rsp)
-	mov    0xa0(%rsp),%rdx
-	add    %rdx,0x68(%rsp)
-	cmp    0x50(%rsp),%rax
-	jne    22d0 <cartesian_spherical_harmonics_generic._omp_fn.0+0x1d0>
-	mov    %r13,%r10
-	mov    %r14,%rbx
-	vzeroupper
-	mov    %r10,0xf8(%rsp)
-	call   1070 <GOMP_barrier@plt>
-	mov    0x38(%rsp),%rdi
-	call   1030 <free@plt>
-	mov    0xf8(%rsp),%r10
-	mov    %r10,%rdi
-	call   1030 <free@plt>
-	lea    -0x28(%rbp),%rsp
-	mov    %rbx,%rdi
-	pop    %rbx
-	pop    %r12
-	pop    %r13
-	pop    %r14
-	pop    %r15
-	pop    %rbp
-	jmp    1030 <free@plt>
-	nopw   0x0(%rax,%rax,1)
-	mov    0xb0(%rsp),%rcx
-	mov    0xa8(%rsp),%r10
-	mov    $0x8,%eax
-	data16 cs nopw 0x0(%rax,%rax,1)
-	vmovsd (%r10,%rax,1),%xmm3
-	mov    %rax,%rdx
-	vmulsd (%rcx,%rax,1),%xmm3,%xmm3
-	neg    %rdx
-	vmulsd (%r14,%rax,1),%xmm3,%xmm4
-	vmulsd 0x0(%r13,%rax,1),%xmm3,%xmm3
-	vmovsd %xmm4,(%rsi,%rdx,1)
-	mov    %rax,%rdx
-	vmovsd %xmm3,(%rsi,%rax,1)
-	add    $0x8,%rax
-	cmp    %rdx,%r9
-	jne    2810 <cartesian_spherical_harmonics_generic._omp_fn.0+0x710>
-	jmp    272a <cartesian_spherical_harmonics_generic._omp_fn.0+0x62a>
-	xor    %ecx,%ecx
-	mov    $0x1,%edx
-	jmp    2680 <cartesian_spherical_harmonics_generic._omp_fn.0+0x580>
-	mov    0x60(%rsp),%rbx
-	movslq 0x5c(%rsp),%rax
-	mov    0xa0(%rsp),%rdi
-	mov    0x90(%rsp),%rcx
-	vmovsd (%r14),%xmm12
-	vmovsd 0x0(%r13),%xmm13
-	cmpl   $0x2,0xbc(%rsp)
-	lea    (%rbx,%rax,8),%rax
-	mov    0x98(%rsp),%rbx
-	lea    0x20(%rax),%r9
-	movq   $0x0,(%rax,%rbx,1)
-	movq   $0x0,(%rax,%rdi,1)
-	movq   $0x0,(%rax)
-	movq   $0x0,0x8(%rax,%rcx,1)
-	movq   $0x0,0x10(%rax)
-	vmulsd 0x8(%r15),%xmm5,%xmm5
-	mov    0x88(%rsp),%rcx
-	vmovsd %xmm5,0x8(%rax,%rcx,1)
-	vmovsd 0x10(%r15),%xmm3
-	vmulsd 0x10(%r12),%xmm3,%xmm3
-	vmulsd %xmm12,%xmm3,%xmm4
-	vmovsd %xmm4,0x8(%rax)
-	vmulsd %xmm13,%xmm3,%xmm4
-	vxorpd %xmm11,%xmm3,%xmm3
-	vmulsd %xmm12,%xmm3,%xmm3
-	vmovsd %xmm4,0x18(%rax)
-	vmovsd %xmm4,0x8(%rax,%rdi,1)
-	mov    0x30(%rsp),%rdi
-	vmovsd %xmm3,0x8(%rax,%rdi,1)
-	movq   $0x0,0x8(%rax,%rbx,1)
-	mov    0x28(%rsp),%rbx
-	movq   $0x0,0x8(%rax,%rbx,1)
-	jbe    2776 <cartesian_spherical_harmonics_generic._omp_fn.0+0x676>
-	mov    0x20(%rsp),%rax
-	mov    %r15,0xe8(%rsp)
-	movl   $0x1,0xe0(%rsp)
-	mov    $0x2,%r11d
-	mov    $0x3,%r8d
-	mov    %r12,0xf8(%rsp)
-	mov    %rax,0xd8(%rsp)
-	mov    0x18(%rsp),%rax
-	mov    %rax,0xd0(%rsp)
-	mov    0x10(%rsp),%rax
-	mov    %rax,0xc8(%rsp)
-	mov    0x8(%rsp),%rax
-	mov    %rax,0xc0(%rsp)
-	mov    $0x10,%eax
-	mov    %rax,%r15
-	nopw   0x0(%rax,%rax,1)
-	mov    0xe8(%rsp),%rbx
-	movslq %r8d,%rax
-	mov    0xc0(%rsp),%rsi
-	vcvtsi2sd %r11d,%xmm0,%xmm8
-	mov    %r11d,%r10d
-	mov    %r11d,0xb0(%rsp)
-	lea    (%rbx,%rax,8),%rdi
-	mov    0xf8(%rsp),%rbx
-	mov    %r8d,%eax
-	lea    (%r9,%rsi,1),%rcx
-	sub    %r11d,%eax
-	vmulsd (%rdi),%xmm1,%xmm4
-	mov    0xc8(%rsp),%rsi
-	lea    0x1(%rax),%edx
-	cltq
-	movslq %edx,%rdx
-	vmovsd (%rbx,%rdx,8),%xmm5
-	lea    (%r9,%r15,1),%rdx
-	add    %r9,%rsi
-	cmpl   $0x1,0xe0(%rsp)
-	vmulsd %xmm5,%xmm4,%xmm4
-	vmovsd %xmm4,(%rdx)
-	vmulsd (%rdi),%xmm2,%xmm3
-	vmulsd %xmm5,%xmm3,%xmm3
-	vmovsd %xmm3,(%rcx)
-	vmulsd (%rdi),%xmm8,%xmm3
-	vmulsd (%rbx,%rax,8),%xmm3,%xmm3
-	lea    0x1(%r8),%eax
-	mov    %eax,0xf0(%rsp)
-	vmovsd %xmm3,(%rsi)
-	je     2cf6 <cartesian_spherical_harmonics_generic._omp_fn.0+0xbf6>
-	cmp    $0x4,%r11
-	jbe    2e9e <cartesian_spherical_harmonics_generic._omp_fn.0+0xd9e>
-	movslq 0xf0(%rsp),%rax
-	mov    %r15,0x70(%rsp)
-	mov    %r9,%r15
-	mov    0xe8(%rsp),%r9
-	add    $0x3,%r8d
-	vmovsd %xmm12,%xmm12,%xmm6
-	vmovsd %xmm13,%xmm13,%xmm3
-	mov    $0x1,%edi
-	movslq %r8d,%r8
-	sub    %r11,%rax
-	lea    (%rbx,%rax,8),%r12
-	lea    -0x5(%r11),%eax
-	xor    %ebx,%ebx
-	shr    %eax
-	lea    0x3(%rax,%rax,1),%rax
-	mov    %rax,0xa8(%rsp)
-	lea    0x1(%r11),%eax
-	mov    %eax,0xb8(%rsp)
-	mov    0xf8(%rsp),%rax
-	vcvtsi2sd %edi,%xmm0,%xmm7
-	mov    %r8d,0x80(%rsp)
-	add    $0x10,%r12
-	vmovsd -0x10(%r9,%r8,8),%xmm4
-	vmovsd -0x8(%r12),%xmm10
-	vmulsd -0x10(%rax,%r8,8),%xmm4,%xmm5
-	lea    (%r10,%rdi,1),%eax
-	vmulsd %xmm10,%xmm4,%xmm4
-	vmulsd %xmm4,%xmm1,%xmm15
-	vmulsd %xmm4,%xmm2,%xmm4
-	vmulsd %xmm7,%xmm5,%xmm5
-	vmovsd (%r14,%rdi,8),%xmm7
-	vmovsd %xmm15,%xmm15,%xmm9
-	vmulsd %xmm6,%xmm5,%xmm6
-	vmulsd %xmm3,%xmm5,%xmm3
-	vfmadd132sd %xmm7,%xmm6,%xmm9
-	vmovsd %xmm9,-0x8(%rdx,%rbx,1)
-	vmovsd 0x0(%r13,%rdi,8),%xmm9
-	vfmadd132sd %xmm9,%xmm3,%xmm15
-	vfmadd231sd %xmm4,%xmm7,%xmm3
-	vfmsub132sd %xmm9,%xmm6,%xmm4
-	vmovsd 0x8(%r14,%rdi,8),%xmm6
-	vmovsd %xmm15,(%rdx,%rdi,8)
-	vmovsd %xmm3,-0x8(%rcx,%rbx,1)
-	vcvtsi2sd %eax,%xmm0,%xmm3
-	lea    0x1(%rdi),%eax
-	vmovsd %xmm4,(%rcx,%rdi,8)
-	vmulsd -0x10(%r9,%r8,8),%xmm3,%xmm3
-	vmulsd -0x10(%r12),%xmm3,%xmm3
-	vmulsd %xmm3,%xmm7,%xmm4
-	vmulsd %xmm3,%xmm9,%xmm3
-	vmovsd %xmm4,-0x8(%rsi,%rbx,1)
-	vcvtsi2sd %eax,%xmm0,%xmm4
-	mov    0xf8(%rsp),%rax
-	vmovsd %xmm3,(%rsi,%rdi,8)
-	vmovsd -0x8(%r9,%r8,8),%xmm5
-	vmulsd -0x8(%rax,%r8,8),%xmm5,%xmm3
-	vmulsd (%r12),%xmm5,%xmm5
-	mov    0xb8(%rsp),%eax
-	add    %edi,%eax
-	vmulsd %xmm3,%xmm4,%xmm4
-	vmulsd %xmm5,%xmm1,%xmm15
-	vmovsd %xmm6,%xmm6,%xmm3
-	vmulsd %xmm4,%xmm7,%xmm7
-	vmulsd %xmm5,%xmm2,%xmm5
-	vfmadd132sd %xmm15,%xmm7,%xmm3
-	vmulsd %xmm4,%xmm9,%xmm4
-	vmovsd %xmm3,-0x10(%rdx,%rbx,1)
-	vmovsd 0x8(%r13,%rdi,8),%xmm3
-	vfmadd132sd %xmm3,%xmm4,%xmm15
-	vfmadd231sd %xmm6,%xmm5,%xmm4
-	vfmsub132sd %xmm3,%xmm7,%xmm5
-	vmovsd %xmm15,0x8(%rdx,%rdi,8)
-	vmovsd %xmm4,-0x10(%rcx,%rbx,1)
-	vcvtsi2sd %eax,%xmm0,%xmm4
-	lea    0x2(%rdi),%eax
-	vmovsd %xmm5,0x8(%rcx,%rdi,8)
-	vmulsd -0x8(%r9,%r8,8),%xmm4,%xmm4
-	add    $0x2,%r8
-	vmulsd %xmm10,%xmm4,%xmm10
-	vmulsd %xmm6,%xmm10,%xmm4
-	vmulsd %xmm3,%xmm10,%xmm10
-	vmovsd %xmm4,-0x10(%rsi,%rbx,1)
-	vmovsd %xmm10,0x8(%rsi,%rdi,8)
-	sub    $0x10,%rbx
-	add    $0x2,%rdi
-	cmp    %rdi,0xa8(%rsp)
-	jne    2a80 <cartesian_spherical_harmonics_generic._omp_fn.0+0x980>
-	mov    %r15,%r9
-	mov    0x70(%rsp),%r15
-	movslq 0x80(%rsp),%rdi
-	mov    0xe8(%rsp),%rbx
-	cltq
-	mov    %r9,0xa8(%rsp)
-	mov    0xf8(%rsp),%r8
-	mov    0xe0(%rsp),%r12d
-	lea    (%rbx,%rdi,8),%rbx
-	sub    %r11,%rdi
-	lea    (%r8,%rdi,8),%r8
-	nopw   0x0(%rax,%rax,1)
-	vmovsd (%rbx),%xmm3
-	vcvtsi2sd %eax,%xmm0,%xmm4
-	mov    %rax,%rdi
-	lea    (%r10,%rax,1),%r9d
-	vmulsd (%r8,%r11,8),%xmm3,%xmm6
-	vmulsd 0x8(%r8),%xmm3,%xmm3
-	neg    %rdi
-	add    $0x8,%rbx
-	shl    $0x3,%rdi
-	add    $0x8,%r8
-	vmulsd %xmm4,%xmm6,%xmm6
-	vmulsd -0x8(%r14,%rax,8),%xmm6,%xmm7
-	vmovsd (%r14,%rax,8),%xmm4
-	vmulsd -0x8(%r13,%rax,8),%xmm6,%xmm6
-	vmulsd %xmm3,%xmm1,%xmm9
-	vmulsd %xmm3,%xmm2,%xmm3
-	vmovsd %xmm4,%xmm4,%xmm5
-	vfmadd132sd %xmm9,%xmm7,%xmm5
-	vmovsd %xmm5,(%rdx,%rdi,1)
-	vmovsd 0x0(%r13,%rax,8),%xmm5
-	vfmadd132sd %xmm5,%xmm6,%xmm9
-	vfmadd231sd %xmm3,%xmm4,%xmm6
-	vfmsub132sd %xmm5,%xmm7,%xmm3
-	vmovsd %xmm9,(%rdx,%rax,8)
-	vmovsd %xmm6,(%rcx,%rdi,1)
-	vmovsd %xmm3,(%rcx,%rax,8)
-	vcvtsi2sd %r9d,%xmm0,%xmm3
-	vmulsd -0x8(%rbx),%xmm3,%xmm3
-	vmulsd -0x8(%r8),%xmm3,%xmm3
-	vmulsd %xmm3,%xmm4,%xmm4
-	vmulsd %xmm5,%xmm3,%xmm3
-	vmovsd %xmm4,(%rsi,%rdi,1)
-	vmovsd %xmm3,(%rsi,%rax,8)
-	inc    %rax
-	cmp    %eax,%r12d
-	jg     2c30 <cartesian_spherical_harmonics_generic._omp_fn.0+0xb30>
-	mov    0xf0(%rsp),%eax
-	mov    0xa8(%rsp),%r9
-	lea    -0x2(%rax,%r10,1),%eax
-	mov    %eax,0xf0(%rsp)
-	movslq 0xf0(%rsp),%rax
-	lea    (%r15,%r15,1),%rcx
-	inc    %r11
-	mov    0xf8(%rsp),%rdi
-	mov    0xe8(%rsp),%rsi
-	mov    0xe0(%rsp),%r12d
-	mov    0x90(%rsp),%r8
-	mov    %rax,%rbx
-	shl    $0x3,%rax
-	vmovsd (%rdi,%rax,1),%xmm3
-	add    %rax,%rsi
-	lea    -0x1(%r10,%r10,1),%edi
-	mov    0xe8(%rsp),%r10
-	vmulsd (%rsi),%xmm3,%xmm3
-	vcvtsi2sd %r12d,%xmm0,%xmm4
-	inc    %r12d
-	vmulsd %xmm4,%xmm3,%xmm3
-	vmovsd -0x10(%r14,%r15,1),%xmm4
-	vmulsd %xmm4,%xmm3,%xmm5
-	vmovsd %xmm5,0x8(%r9)
-	vmulsd -0x10(%r13,%r15,1),%xmm3,%xmm5
-	vxorpd %xmm11,%xmm3,%xmm3
-	vmulsd %xmm4,%xmm3,%xmm3
-	vmovsd -0x8(%r14,%r15,1),%xmm4
-	vmovsd %xmm5,-0x8(%r9,%rcx,1)
-	vmovsd %xmm5,(%r9,%r8,1)
-	mov    0xd0(%rsp),%r8
-	vmovsd %xmm3,(%r9,%r8,1)
-	vcvtsi2sd %edi,%xmm0,%xmm3
-	vmulsd (%rsi),%xmm3,%xmm3
-	mov    %ebx,%esi
-	sub    0xb0(%rsp),%esi
-	mov    0xf8(%rsp),%rdi
-	movslq %esi,%rsi
-	vmulsd (%rdi,%rsi,8),%xmm3,%xmm3
-	mov    0x88(%rsp),%rsi
-	vmulsd %xmm4,%xmm3,%xmm5
-	vmovsd %xmm5,(%r9,%rsi,1)
-	vmovsd -0x8(%r13,%r15,1),%xmm5
-	mov    0xd8(%rsp),%rsi
-	vmulsd %xmm5,%xmm3,%xmm3
-	vmovsd %xmm3,(%r9,%rsi,1)
-	vmovsd 0x8(%r10,%rax,1),%xmm3
-	vmulsd 0x8(%rdi,%rax,1),%xmm3,%xmm3
-	mov    0xa0(%rsp),%rax
-	vmulsd %xmm8,%xmm3,%xmm8
-	vmulsd %xmm8,%xmm5,%xmm5
-	vmulsd %xmm8,%xmm4,%xmm3
-	vxorpd %xmm11,%xmm8,%xmm8
-	vmulsd %xmm4,%xmm8,%xmm8
-	vmovsd %xmm3,(%r9)
-	vmovsd %xmm5,(%rdx,%r15,1)
-	vmovsd %xmm5,(%r9,%rax,1)
-	mov    %r8,%rax
-	add    $0x8,%r15
-	add    $0x10,%rax
-	vmovsd %xmm8,0x8(%r9,%r8,1)
-	mov    0x98(%rsp),%rdi
-	lea    0x2(%rbx),%r8d
-	addq   $0x8,0xc0(%rsp)
-	addq   $0x8,0xc8(%rsp)
-	mov    %r12d,0xe0(%rsp)
-	mov    %rax,0xd0(%rsp)
-	movq   $0x0,(%r9,%rdi,1)
-	movq   $0x0,0x8(%r9,%rsi,1)
-	add    $0x10,%rsi
-	lea    0x8(%r9,%rcx,1),%r9
-	mov    %rsi,0xd8(%rsp)
-	cmp    %r12d,0x84(%rsp)
-	jne    2990 <cartesian_spherical_harmonics_generic._omp_fn.0+0x890>
-	mov    0xf8(%rsp),%r12
-	mov    %r10,%r15
-	jmp    2776 <cartesian_spherical_harmonics_generic._omp_fn.0+0x676>
-	mov    %eax,0x80(%rsp)
-	mov    $0x1,%eax
-	jmp    2bf2 <cartesian_spherical_harmonics_generic._omp_fn.0+0xaf2>
-	mov    0x68(%rsp),%rax
-	vmovsd %xmm14,0x0(%r13)
-	movq   $0x0,(%r14)
-	vmovsd %xmm14,%xmm14,%xmm5
-	vmovsd %xmm9,-0x8(%rax)
-	jmp    276a <cartesian_spherical_harmonics_generic._omp_fn.0+0x66a>
-	mov    $0x1,%eax
-	jmp    2484 <cartesian_spherical_harmonics_generic._omp_fn.0+0x384>
 	inc    %eax
 	xor    %edx,%edx
-	jmp    21ab <cartesian_spherical_harmonics_generic._omp_fn.0+0xab>
-	data16 cs nopw 0x0(%rax,%rax,1)
-	nopl   (%rax)
+	jmp    2008 <cartesian_spherical_harmonics_l2._omp_fn.0+0x278>
+	nopl   0x0(%rax)
 
-0000000000002ef0 <cartesian_spherical_harmonics_l3._omp_fn.0>:
+0000000000002140 <cartesian_spherical_harmonics_l3._omp_fn.0>:
 cartesian_spherical_harmonics_l3._omp_fn.0():
 	push   %rbp
 	mov    %rsp,%rbp
 	push   %r15
 	push   %r14
 	mov    %rdi,%r15
 	push   %r13
@@ -1676,325 +948,320 @@
 	mov    %eax,%r13d
 	call   1080 <omp_get_thread_num@plt>
 	mov    %eax,%ecx
 	mov    0x18(%r15),%eax
 	cltd
 	idiv   %r13d
 	test   %r14,%r14
-	je     3420 <cartesian_spherical_harmonics_l3._omp_fn.0+0x530>
+	je     2660 <cartesian_spherical_harmonics_l3._omp_fn.0+0x520>
 	cmp    %edx,%ecx
-	jl     4030 <cartesian_spherical_harmonics_l3._omp_fn.0+0x1140>
+	jl     3250 <cartesian_spherical_harmonics_l3._omp_fn.0+0x1110>
 	imul   %eax,%ecx
 	add    %ecx,%edx
 	lea    (%rax,%rdx,1),%ecx
 	cmp    %ecx,%edx
-	jge    340b <cartesian_spherical_harmonics_l3._omp_fn.0+0x51b>
-	vmovsd 0x630a(%rip),%xmm7        
-	vmovsd 0x62fa(%rip),%xmm5        
+	jge    2646 <cartesian_spherical_harmonics_l3._omp_fn.0+0x506>
+	vmovsd 0xb102(%rip),%xmm7        
+	vmovsd 0xb0aa(%rip),%xmm6        
+	lea    (%rdx,%rdx,2),%ecx
 	movslq %edx,%rdi
+	vmovsd 0xb08c(%rip),%xmm4        
+	vmovsd 0xb08c(%rip),%xmm5        
+	movslq %ecx,%rcx
 	dec    %eax
-	vmovsd 0x62dd(%rip),%xmm3        
-	vmovsd 0x62dd(%rip),%xmm4        
+	vmovq  0xb58f(%rip),%xmm8        
+	lea    (%r12,%rcx,8),%rsi
 	mov    %edx,%ecx
-	lea    (%rdx,%rdx,2),%esi
 	lea    (%rdi,%rdi,2),%rdx
 	add    %rax,%rdi
-	mov    0x62ba(%rip),%rax        
 	shl    $0x4,%ecx
-	movslq %ecx,%rcx
-	movslq %esi,%rsi
 	shl    $0x7,%rdx
 	shl    $0x7,%rdi
-	lea    (%rbx,%rcx,8),%rcx
-	lea    (%r12,%rsi,8),%rsi
+	movslq %ecx,%rcx
 	lea    0x20(%r14,%rdx,1),%rdx
-	lea    0x80(%rbx,%rdi,1),%rdi
-	vmovsd %xmm7,0x10(%rsp)
-	vmovsd 0x62e6(%rip),%xmm7        
-	vmovsd %xmm5,0x18(%rsp)
-	vmovsd 0x62a0(%rip),%xmm5        
-	vmovsd %xmm7,0xa0(%rsp)
-	vmovsd 0x62df(%rip),%xmm7        
-	vmovsd %xmm5,0x8(%rsp)
-	vmovsd 0x62c1(%rip),%xmm5        
-	vmovsd %xmm7,0x60(%rsp)
-	vmovsd 0x62cb(%rip),%xmm7        
-	vmovsd %xmm5,0x80(%rsp)
-	vmovsd 0x62aa(%rip),%xmm5        
-	vmovsd %xmm7,0x40(%rsp)
-	vmovsd 0x62b4(%rip),%xmm7        
-	vmovsd %xmm7,0x38(%rsp)
-	vmovsd 0x62ae(%rip),%xmm7        
+	lea    0x80(%rbx,%rdi,1),%r8
+	mov    0xb040(%rip),%rdi        
+	lea    (%rbx,%rcx,8),%rcx
 	vmovsd %xmm7,0x30(%rsp)
-	vmovsd 0x62a8(%rip),%xmm7        
+	vmovsd 0xb09e(%rip),%xmm7        
+	vmovsd %xmm6,0x80(%rsp)
+	vmovsd 0xb03d(%rip),%xmm6        
 	vmovsd %xmm7,0x28(%rsp)
-	vmovsd 0x62a2(%rip),%xmm7        
+	vmovsd 0xb087(%rip),%xmm7        
+	vmovsd %xmm6,0x60(%rsp)
+	vmovsd 0xb029(%rip),%xmm6        
 	vmovsd %xmm7,0x20(%rsp)
-	vmovq  0x6534(%rip),%xmm7        
+	vmovsd 0xb073(%rip),%xmm7        
+	vmovsd %xmm6,0x40(%rsp)
+	vmovsd 0xb035(%rip),%xmm6        
+	vmovsd %xmm7,0x18(%rsp)
+	vmovsd 0xb05f(%rip),%xmm7        
+	vmovsd %xmm6,0xa0(%rsp)
+	vmovsd 0xb01e(%rip),%xmm6        
+	vmovsd %xmm7,0x10(%rsp)
+	vmovsd 0xb048(%rip),%xmm7        
+	vmovsd %xmm6,0x38(%rsp)
+	vmovsd 0xb00a(%rip),%xmm6        
+	vmovsd %xmm7,0x8(%rsp)
 	nopl   0x0(%rax)
-	mov    %rax,(%rcx)
-	vmovsd 0x10(%rsi),%xmm9
+	vmovsd (%rsi),%xmm2
 	sub    $0xffffffffffffff80,%rcx
 	add    $0x18,%rsi
-	vmovsd -0x18(%rsi),%xmm0
 	add    $0x180,%rdx
-	vmulsd -0x10(%rsi),%xmm3,%xmm8
-	vmovsd 0xa0(%rsp),%xmm12
-	vmulsd %xmm3,%xmm9,%xmm9
-	vmulsd %xmm3,%xmm0,%xmm0
-	vmovsd %xmm9,-0x70(%rcx)
-	vmovsd %xmm8,-0x78(%rcx)
-	vmovsd %xmm0,-0x68(%rcx)
-	vmovsd -0x18(%rsi),%xmm1
-	vmovsd -0x8(%rsi),%xmm2
-	vmovsd -0x10(%rsi),%xmm0
-	vmulsd %xmm1,%xmm1,%xmm14
-	vmulsd %xmm4,%xmm1,%xmm1
-	vmulsd %xmm2,%xmm2,%xmm6
-	vmulsd %xmm4,%xmm2,%xmm2
-	vmulsd %xmm8,%xmm1,%xmm11
-	vmulsd %xmm9,%xmm1,%xmm1
-	vmovsd 0x18(%rsp),%xmm9
-	vmulsd %xmm0,%xmm0,%xmm0
-	vmulsd %xmm8,%xmm2,%xmm2
-	vmovsd %xmm1,-0x48(%rcx)
-	vmovsd %xmm11,-0x60(%rcx)
-	vmovsd %xmm2,-0x58(%rcx)
-	vaddsd %xmm0,%xmm14,%xmm2
-	vsubsd %xmm0,%xmm14,%xmm15
-	vmulsd 0x8(%rsp),%xmm15,%xmm1
-	vfnmadd132sd %xmm14,%xmm0,%xmm12
-	vfnmadd132sd %xmm6,%xmm2,%xmm9
-	vmulsd 0x10(%rsp),%xmm9,%xmm9
-	vfnmadd231sd 0x60(%rsp),%xmm6,%xmm2
-	vmulsd 0x40(%rsp),%xmm2,%xmm2
-	vmovsd %xmm1,-0x40(%rcx)
-	vmovsd %xmm9,-0x50(%rcx)
-	vmovsd -0x18(%rsi),%xmm13
-	vmovsd -0x10(%rsi),%xmm10
-	vmulsd 0x80(%rsp),%xmm10,%xmm8
 	vmovsd -0x8(%rsi),%xmm1
-	vmulsd %xmm2,%xmm10,%xmm10
-	vmulsd %xmm2,%xmm13,%xmm2
-	vmovsd %xmm2,-0x18(%rcx)
-	vmulsd %xmm12,%xmm8,%xmm12
-	vmovsd %xmm9,%xmm9,%xmm2
-	vfnmadd132sd 0x38(%rsp),%xmm6,%xmm2
-	vmulsd 0x30(%rsp),%xmm1,%xmm9
-	vmovsd %xmm10,-0x28(%rcx)
-	vmovsd %xmm12,-0x38(%rcx)
-	vmulsd %xmm5,%xmm1,%xmm12
-	vmulsd %xmm11,%xmm12,%xmm11
-	vmovsd %xmm11,-0x30(%rcx)
-	vmulsd %xmm2,%xmm9,%xmm2
-	vmovsd %xmm2,-0x20(%rcx)
-	vmulsd 0x28(%rsp),%xmm1,%xmm1
-	vmovsd %xmm14,%xmm14,%xmm2
-	vfnmadd231sd 0xa0(%rsp),%xmm0,%xmm2
-	vsubsd %xmm6,%xmm0,%xmm0
+	vmovsd -0x10(%rsi),%xmm3
+	mov    %rdi,-0x80(%rcx)
+	vmovsd 0xa0(%rsp),%xmm13
+	vmulsd %xmm4,%xmm2,%xmm10
+	vmulsd %xmm2,%xmm2,%xmm14
+	vmulsd %xmm4,%xmm3,%xmm9
+	vmulsd %xmm4,%xmm1,%xmm11
+	vmovsd %xmm10,-0x68(%rcx)
+	vmulsd %xmm5,%xmm2,%xmm10
+	vmulsd %xmm3,%xmm3,%xmm7
+	vmovsd %xmm9,-0x78(%rcx)
+	vmovsd %xmm11,-0x70(%rcx)
+	vmulsd %xmm10,%xmm9,%xmm12
+	vmulsd %xmm10,%xmm11,%xmm10
+	vaddsd %xmm7,%xmm14,%xmm11
+	vsubsd %xmm7,%xmm14,%xmm15
+	vmulsd %xmm1,%xmm1,%xmm0
+	vfnmadd132sd %xmm14,%xmm7,%xmm13
+	vmovsd %xmm10,-0x48(%rcx)
+	vmovsd %xmm12,-0x60(%rcx)
+	vmulsd %xmm5,%xmm1,%xmm10
+	vmulsd %xmm9,%xmm10,%xmm9
+	vmovsd 0x80(%rsp),%xmm10
+	vmovsd %xmm9,-0x58(%rcx)
+	vmulsd 0x40(%rsp),%xmm15,%xmm9
+	vfnmadd132sd %xmm0,%xmm11,%xmm10
+	vfnmadd231sd 0x30(%rsp),%xmm0,%xmm11
+	vmulsd 0x60(%rsp),%xmm10,%xmm10
+	vmulsd 0x28(%rsp),%xmm11,%xmm11
+	vmovsd %xmm9,-0x40(%rcx)
+	vmulsd 0x38(%rsp),%xmm3,%xmm9
+	vmovsd %xmm10,-0x50(%rcx)
+	vmulsd %xmm11,%xmm3,%xmm3
+	vmulsd %xmm13,%xmm9,%xmm13
+	vmovsd %xmm3,-0x28(%rcx)
+	vmulsd %xmm11,%xmm2,%xmm3
+	vmovsd %xmm13,-0x38(%rcx)
+	vmulsd 0x8(%rsp),%xmm2,%xmm2
+	vmulsd %xmm6,%xmm1,%xmm13
+	vmovsd %xmm3,-0x18(%rcx)
+	vmovsd %xmm10,%xmm10,%xmm3
+	vmulsd 0x18(%rsp),%xmm1,%xmm10
+	vmulsd 0x10(%rsp),%xmm1,%xmm1
+	vfnmadd132sd 0x20(%rsp),%xmm0,%xmm3
+	vsubsd %xmm0,%xmm7,%xmm0
+	vmulsd %xmm12,%xmm13,%xmm12
+	vmovsd %xmm12,-0x30(%rcx)
 	vmulsd %xmm15,%xmm1,%xmm1
 	vmovsd %xmm1,-0x10(%rcx)
-	vmulsd 0x20(%rsp),%xmm13,%xmm1
-	vmulsd %xmm2,%xmm1,%xmm1
-	vmovsd %xmm1,-0x8(%rcx)
-	vmovapd 0x5e9e(%rip),%ymm1        
+	vmulsd %xmm3,%xmm10,%xmm3
+	vmovsd %xmm14,%xmm14,%xmm1
+	vfnmadd231sd 0xa0(%rsp),%xmm7,%xmm1
+	vmovsd %xmm3,-0x20(%rcx)
+	vmulsd %xmm1,%xmm2,%xmm2
+	vmovsd %xmm2,-0x8(%rcx)
 	movq   $0x0,-0xa0(%rdx)
 	movq   $0x0,-0x120(%rdx)
-	vmovsd %xmm3,-0x118(%rdx)
+	vmovapd 0xac50(%rip),%ymm1        
+	vmovsd %xmm4,-0x118(%rdx)
 	movq   $0x0,-0x110(%rdx)
 	movq   $0x0,-0x108(%rdx)
 	movq   $0x0,-0x98(%rdx)
-	vmovsd %xmm3,-0x90(%rdx)
+	vmovsd %xmm4,-0x90(%rdx)
 	movq   $0x0,-0x88(%rdx)
 	vmovupd %ymm1,-0x1a0(%rdx)
-	vmulsd -0x78(%rcx),%xmm4,%xmm13
-	vmovsd 0x6067(%rip),%xmm1        
+	vmulsd -0x78(%rcx),%xmm5,%xmm3
+	vmovsd 0xae2f(%rip),%xmm1        
 	movq   $0x0,-0x178(%rdx)
-	vmovsd %xmm13,-0x180(%rdx)
+	vmovsd %xmm3,-0x180(%rdx)
 	vmulsd -0x68(%rcx),%xmm1,%xmm1
 	vmovsd %xmm1,-0x170(%rdx)
-	vmulsd -0x70(%rcx),%xmm4,%xmm2
-	vmulsd 0x6042(%rip),%xmm1,%xmm1        
+	vmulsd -0x70(%rcx),%xmm5,%xmm2
+	vmulsd 0xae0a(%rip),%xmm1,%xmm1        
 	vmovsd %xmm2,-0x168(%rdx)
-	vmulsd -0x68(%rcx),%xmm4,%xmm14
-	vmovsd %xmm1,-0x100(%rdx)
+	vmulsd -0x68(%rcx),%xmm5,%xmm14
 	vmovsd %xmm2,-0xf8(%rdx)
+	vmulsd 0xadfd(%rip),%xmm2,%xmm2        
+	vmovsd %xmm3,-0x78(%rdx)
+	vmovsd %xmm1,-0x100(%rdx)
 	movq   $0x0,-0xe8(%rdx)
-	vmovsd %xmm14,-0x160(%rdx)
-	vmulsd 0x6012(%rip),%xmm13,%xmm14        
-	vmovsd %xmm14,-0xf0(%rdx)
-	vxorpd %xmm7,%xmm13,%xmm14
-	vmovsd %xmm14,-0xe0(%rdx)
-	movq   $0x0,-0x60(%rdx)
-	vmulsd 0x5ff6(%rip),%xmm2,%xmm2        
 	vmovsd %xmm1,-0x68(%rdx)
+	movq   $0x0,-0x60(%rdx)
 	movq   $0x0,-0x80(%rdx)
-	vmovsd %xmm13,-0x78(%rdx)
-	vmovsd 0x603c(%rip),%xmm1        
-	vmovsd 0x603c(%rip),%xmm15        
-	vmovsd 0x6044(%rip),%xmm6        
+	vmovsd %xmm14,-0x160(%rdx)
+	vmulsd 0xadb8(%rip),%xmm3,%xmm14        
 	vmovsd %xmm2,-0x70(%rdx)
-	vmulsd -0x60(%rcx),%xmm1,%xmm1
-	vmovsd %xmm1,-0x158(%rdx)
-	vmulsd -0x58(%rcx),%xmm5,%xmm2
-	vxorpd %xmm7,%xmm1,%xmm1
-	vmovsd %xmm2,-0x150(%rdx)
-	vmulsd -0x60(%rcx),%xmm15,%xmm13
-	vmovsd 0x600c(%rip),%xmm15        
-	vxorpd %xmm7,%xmm2,%xmm2
-	vmovsd %xmm13,-0x148(%rdx)
-	vmulsd -0x48(%rcx),%xmm15,%xmm13
-	vmovsd 0x5fe3(%rip),%xmm15        
-	vmovsd %xmm13,-0x140(%rdx)
-	vfmadd132sd -0x50(%rcx),%xmm0,%xmm6
-	vmulsd 0x5fed(%rip),%xmm6,%xmm6        
-	vmovsd %xmm6,-0x138(%rdx)
-	vmulsd -0x48(%rcx),%xmm5,%xmm6
-	vmovsd %xmm6,-0x130(%rdx)
-	vmulsd -0x40(%rcx),%xmm15,%xmm13
-	vmovsd %xmm6,-0xd0(%rdx)
-	vmovsd 0x5fcb(%rip),%xmm6        
-	vmovsd %xmm13,-0x128(%rdx)
-	vmovsd %xmm13,-0xd8(%rdx)
-	vfnmadd231sd -0x50(%rcx),%xmm6,%xmm0
-	vmovsd 0x5f95(%rip),%xmm6        
-	vmulsd 0x5fad(%rip),%xmm0,%xmm0        
+	vmovsd %xmm14,-0xf0(%rdx)
+	vxorpd %xmm8,%xmm3,%xmm14
+	vmovsd 0xadf6(%rip),%xmm3        
+	vmovsd %xmm14,-0xe0(%rdx)
+	vmulsd -0x60(%rcx),%xmm3,%xmm3
+	vmovsd 0xade9(%rip),%xmm2        
+	vmovsd 0xadd9(%rip),%xmm7        
+	vmovsd %xmm3,-0x158(%rdx)
+	vmulsd -0x58(%rcx),%xmm6,%xmm1
+	vxorpd %xmm8,%xmm3,%xmm3
+	vmovsd %xmm1,-0x150(%rdx)
+	vmulsd -0x60(%rcx),%xmm2,%xmm2
+	vxorpd %xmm8,%xmm1,%xmm1
+	vmovsd %xmm2,-0x148(%rdx)
+	vmovsd 0xadb5(%rip),%xmm2        
+	vmulsd -0x48(%rcx),%xmm2,%xmm2
+	vmovsd %xmm2,-0x140(%rdx)
+	vmovsd 0xada8(%rip),%xmm2        
+	vfmadd132sd -0x50(%rcx),%xmm0,%xmm2
+	vmulsd 0xada2(%rip),%xmm2,%xmm2        
+	vmovsd %xmm2,-0x138(%rdx)
+	vmulsd -0x48(%rcx),%xmm6,%xmm2
+	vmovsd %xmm2,-0x130(%rdx)
+	vmulsd -0x40(%rcx),%xmm7,%xmm7
+	vmovsd %xmm2,-0xd0(%rdx)
+	vmovsd %xmm7,-0x128(%rdx)
+	vmovsd %xmm7,-0xd8(%rdx)
+	vmovsd 0xad70(%rip),%xmm7        
+	vfnmadd231sd -0x50(%rcx),%xmm7,%xmm0
+	vmovsd 0xad4a(%rip),%xmm7        
+	vmulsd 0xad62(%rip),%xmm0,%xmm0        
 	vmovsd %xmm0,-0xc8(%rdx)
-	vmulsd -0x58(%rcx),%xmm6,%xmm0
-	vmovsd 0x5f70(%rip),%xmm6        
+	vmulsd -0x58(%rcx),%xmm7,%xmm0
+	vmovsd 0xad25(%rip),%xmm7        
 	vmovsd %xmm0,-0xc0(%rdx)
-	vmulsd -0x60(%rcx),%xmm6,%xmm0
-	vmovsd %xmm2,-0xb0(%rdx)
-	vmovsd %xmm1,-0xa8(%rdx)
-	movq   $0x0,-0x58(%rdx)
-	vmovsd 0x5f73(%rip),%xmm6        
+	vmulsd -0x60(%rcx),%xmm7,%xmm0
+	vmovsd %xmm1,-0xb0(%rdx)
 	vmovsd %xmm0,-0xb8(%rdx)
-	vmulsd -0x60(%rcx),%xmm5,%xmm0
+	vmovsd %xmm3,-0xa8(%rdx)
+	movq   $0x0,-0x58(%rdx)
+	vmulsd -0x60(%rcx),%xmm6,%xmm0
+	vmovsd 0xad1b(%rip),%xmm7        
 	vmovsd %xmm0,-0x50(%rdx)
-	vmulsd -0x58(%rcx),%xmm6,%xmm0
-	vmovsd 0x5f5c(%rip),%xmm6        
+	vmulsd -0x58(%rcx),%xmm7,%xmm0
+	vmovsd 0xad11(%rip),%xmm7        
 	vmovsd %xmm0,-0x48(%rdx)
-	vmulsd -0x50(%rcx),%xmm6,%xmm0
-	vmovsd 0x5f42(%rip),%xmm6        
+	vmulsd -0x50(%rcx),%xmm7,%xmm0
+	vmovsd 0xacf7(%rip),%xmm7        
 	vmovsd %xmm0,-0x40(%rdx)
-	vmulsd -0x48(%rcx),%xmm6,%xmm0
+	vmulsd -0x48(%rcx),%xmm7,%xmm0
 	vmovsd %xmm0,-0x38(%rdx)
-	vmulsd -0x40(%rcx),%xmm5,%xmm0
+	vmulsd -0x40(%rcx),%xmm6,%xmm0
 	movq   $0x0,-0x28(%rdx)
 	vmovsd %xmm0,-0x30(%rdx)
-	cmp    %rdi,%rcx
-	jne    3050 <cartesian_spherical_harmonics_l3._omp_fn.0+0x160>
+	cmp    %r8,%rcx
+	jne    22a0 <cartesian_spherical_harmonics_l3._omp_fn.0+0x160>
 	vzeroupper
 	lea    -0x28(%rbp),%rsp
 	pop    %rbx
 	pop    %r12
 	pop    %r13
 	pop    %r14
 	pop    %r15
 	pop    %rbp
 	ret
-	nopw   0x0(%rax,%rax,1)
+	data16 cs nopw 0x0(%rax,%rax,1)
 	cmp    %edx,%ecx
-	jl     4040 <cartesian_spherical_harmonics_l3._omp_fn.0+0x1150>
+	jl     3260 <cartesian_spherical_harmonics_l3._omp_fn.0+0x1120>
 	imul   %eax,%ecx
 	add    %ecx,%edx
 	lea    (%rax,%rdx,1),%ecx
 	cmp    %ecx,%edx
-	jge    340b <cartesian_spherical_harmonics_l3._omp_fn.0+0x51b>
-	mov    %eax,%esi
-	mov    %edx,%r9d
+	jge    2646 <cartesian_spherical_harmonics_l3._omp_fn.0+0x506>
+	mov    %eax,%edi
+	mov    %edx,%r8d
 	lea    (%rdx,%rdx,2),%r10d
-	mov    %eax,%r8d
-	shl    $0x4,%r9d
+	mov    %eax,%r9d
+	shl    $0x4,%r8d
+	mov    %rdi,%r11
 	movslq %r10d,%r10
-	lea    (%rsi,%rsi,2),%r11
-	movslq %r9d,%r9
-	add    %r10,%r11
-	lea    (%r12,%r10,8),%rdi
-	lea    (%r12,%r11,8),%r11
-	lea    (%rbx,%r9,8),%rcx
-	cmp    %r11,%rcx
+	lea    (%rdi,%rdi,2),%rdi
+	movslq %r8d,%r8
+	shl    $0x4,%r11
+	lea    (%r12,%r10,8),%rsi
+	add    %r8,%r11
+	lea    (%rbx,%r8,8),%rcx
+	lea    (%rbx,%r11,8),%r11
+	cmp    %r11,%rsi
 	setae  %r11b
-	shl    $0x4,%rsi
-	add    %r9,%rsi
-	lea    (%rbx,%rsi,8),%rsi
-	cmp    %rsi,%rdi
-	setae  %sil
-	or     %r11d,%esi
-	and    $0x1,%esi
-	je     4049 <cartesian_spherical_harmonics_l3._omp_fn.0+0x1159>
+	add    %r10,%rdi
+	lea    (%r12,%rdi,8),%rdi
+	cmp    %rdi,%rcx
+	setae  %dil
+	or     %r11d,%edi
+	and    $0x1,%edi
+	je     3269 <cartesian_spherical_harmonics_l3._omp_fn.0+0x1129>
 	cmp    $0x1,%eax
-	je     4049 <cartesian_spherical_harmonics_l3._omp_fn.0+0x1159>
-	lea    -0x1(%rax),%esi
-	cmp    $0x2,%esi
-	jbe    425a <cartesian_spherical_harmonics_l3._omp_fn.0+0x136a>
-	mov    %eax,%esi
-	shr    $0x2,%esi
-	lea    (%rsi,%rsi,2),%r8
-	xor    %esi,%esi
-	shl    $0x5,%r8
+	je     3269 <cartesian_spherical_harmonics_l3._omp_fn.0+0x1129>
+	lea    -0x1(%rax),%edi
+	cmp    $0x2,%edi
+	jbe    3463 <cartesian_spherical_harmonics_l3._omp_fn.0+0x1323>
+	mov    %eax,%edi
+	shr    $0x2,%edi
+	shl    $0x9,%rdi
+	add    %rcx,%rdi
 	cs nopw 0x0(%rax,%rax,1)
-	vmovupd (%rdi,%rsi,1),%ymm3
-	vmovupd 0x40(%rdi,%rsi,1),%ymm5
+	vmovupd (%rsi),%ymm5
+	vmovupd 0x40(%rsi),%ymm4
 	add    $0x200,%rcx
-	vperm2f128 $0x30,0x20(%rdi,%rsi,1),%ymm3,%ymm2
-	vpermpd $0x4e,%ymm3,%ymm1
+	add    $0x60,%rsi
+	vperm2f128 $0x30,-0x40(%rsi),%ymm5,%ymm2
+	vpermpd $0x4e,%ymm5,%ymm1
 	vshufpd $0x2,%ymm1,%ymm2,%ymm1
-	vperm2f128 $0x21,0x40(%rdi,%rsi,1),%ymm1,%ymm0
+	vperm2f128 $0x21,-0x20(%rsi),%ymm1,%ymm0
 	vblendpd $0x8,%ymm0,%ymm1,%ymm1
-	vperm2f128 $0x2,0x20(%rdi,%rsi,1),%ymm3,%ymm0
-	vmovdqu (%rdi,%rsi,1),%ymm3
-	vmulpd 0x5b28(%rip),%ymm1,%ymm15        
+	vperm2f128 $0x2,-0x40(%rsi),%ymm5,%ymm0
+	vmovdqu -0x60(%rsi),%ymm5
+	vmulpd 0xa969(%rip),%ymm1,%ymm3        
+	vmulpd 0xa8e1(%rip),%ymm1,%ymm15        
 	vmulpd %ymm1,%ymm1,%ymm11
-	vmovapd %ymm11,%ymm9
 	vshufpd $0x5,%ymm0,%ymm2,%ymm2
-	vpermilpd $0x2,0x40(%rdi,%rsi,1),%ymm0
+	vpermilpd $0x2,-0x20(%rsi),%ymm0
+	vmovapd %ymm11,%ymm9
 	vmovapd %ymm15,0xa0(%rsp)
 	vblendpd $0x8,%ymm0,%ymm2,%ymm2
-	vpalignr $0x8,0x20(%rdi,%rsi,1),%ymm3,%ymm0
+	vpalignr $0x8,-0x40(%rsi),%ymm5,%ymm0
 	vpermpd $0x53,%ymm0,%ymm0
-	vinsertf128 $0x1,0x40(%rdi,%rsi,1),%ymm0,%ymm0
-	vmulpd 0x5ae5(%rip),%ymm2,%ymm10        
-	vmulpd 0x5b5d(%rip),%ymm1,%ymm3        
-	add    $0x60,%rsi
+	vinsertf128 $0x1,-0x20(%rsi),%ymm0,%ymm0
+	vmulpd 0xa8a1(%rip),%ymm2,%ymm10        
 	vmulpd %ymm2,%ymm2,%ymm13
-	vfnmadd132pd 0x5bcc(%rip),%ymm13,%ymm9        
-	vblendpd $0x7,%ymm0,%ymm5,%ymm0
-	vmulpd 0x5abe(%rip),%ymm0,%ymm12        
-	vaddpd %ymm13,%ymm11,%ymm5
+	vfnmadd132pd 0xa994(%rip),%ymm13,%ymm9        
+	vaddpd %ymm11,%ymm13,%ymm5
 	vsubpd %ymm13,%ymm11,%ymm14
+	vfnmadd231pd 0xa981(%rip),%ymm13,%ymm11        
+	vblendpd $0x7,%ymm0,%ymm4,%ymm0
+	vmulpd 0xa873(%rip),%ymm0,%ymm12        
+	vmulpd 0xaa2b(%rip),%ymm0,%ymm15        
 	vmulpd %ymm0,%ymm0,%ymm7
-	vfnmadd231pd 0x5ba7(%rip),%ymm13,%ymm11        
-	vmulpd 0x5c5f(%rip),%ymm0,%ymm15        
-	vmovapd %ymm7,%ymm4
-	vfnmadd132pd 0x5b32(%rip),%ymm5,%ymm4        
-	vfnmadd231pd 0x5be9(%rip),%ymm7,%ymm5        
 	vmulpd %ymm3,%ymm10,%ymm6
-	vmulpd 0x5b3d(%rip),%ymm4,%ymm4        
-	vmulpd %ymm3,%ymm12,%ymm3
-	vmulpd 0x5bf1(%rip),%ymm5,%ymm5        
-	vfnmadd231pd 0x5c08(%rip),%ymm4,%ymm7        
-	vmovapd %ymm3,0x80(%rsp)
-	vmulpd 0x5ad7(%rip),%ymm0,%ymm3        
+	vmulpd %ymm3,%ymm12,%ymm4
+	vmulpd 0xa8d7(%rip),%ymm0,%ymm3        
+	vmovapd %ymm4,0x80(%rsp)
+	vmovapd %ymm7,%ymm4
+	vfnmadd132pd 0xa8e1(%rip),%ymm5,%ymm4        
+	vfnmadd231pd 0xa998(%rip),%ymm7,%ymm5        
+	vmulpd 0xa9b0(%rip),%ymm5,%ymm5        
+	vmulpd 0xa8e8(%rip),%ymm4,%ymm4        
+	vfnmadd231pd 0xa9bf(%rip),%ymm4,%ymm7        
 	vmulpd %ymm10,%ymm3,%ymm8
-	vmulpd 0x5b2a(%rip),%ymm14,%ymm3        
-	vmulpd %ymm7,%ymm15,%ymm7
+	vmulpd 0xa8f2(%rip),%ymm14,%ymm3        
 	vmovapd %ymm8,0x60(%rsp)
 	vmovapd %ymm9,%ymm8
-	vmulpd 0x5b53(%rip),%ymm2,%ymm9        
+	vmulpd 0xa91f(%rip),%ymm2,%ymm9        
 	vmulpd %ymm5,%ymm2,%ymm2
 	vmulpd %ymm5,%ymm1,%ymm5
-	vmulpd 0x5c23(%rip),%ymm1,%ymm1        
+	vmulpd 0xa9ef(%rip),%ymm1,%ymm1        
+	vmulpd %ymm7,%ymm15,%ymm7
 	vmulpd %ymm8,%ymm9,%ymm9
-	vmulpd 0x5b56(%rip),%ymm0,%ymm8        
-	vmulpd 0x5bee(%rip),%ymm0,%ymm0        
+	vmulpd 0xa91e(%rip),%ymm0,%ymm8        
+	vmulpd 0xa9b6(%rip),%ymm0,%ymm0        
 	vpermpd $0x44,%ymm9,%ymm15
 	vpermpd $0xee,%ymm9,%ymm9
 	vmulpd %ymm11,%ymm1,%ymm1
-	vmovapd 0x59d5(%rip),%ymm11        
+	vmovapd 0xa79d(%rip),%ymm11        
 	vmulpd %ymm6,%ymm8,%ymm8
 	vmulpd %ymm14,%ymm0,%ymm14
 	vpermpd $0x44,%ymm3,%ymm0
 	vpermpd $0xee,%ymm3,%ymm3
 	vshufpd $0xc,%ymm0,%ymm11,%ymm0
 	vshufpd $0xc,%ymm3,%ymm11,%ymm3
 	vpermpd $0x44,%ymm10,%ymm11
@@ -2058,20 +1325,19 @@
 	vpermpd $0xee,%ymm11,%ymm11
 	vpermpd $0x44,%ymm7,%ymm3
 	vpermpd $0xee,%ymm7,%ymm7
 	vshufpd $0xc,%ymm3,%ymm10,%ymm3
 	vshufpd $0xc,%ymm7,%ymm11,%ymm11
 	vpermpd $0x44,%ymm13,%ymm10
 	vpermpd $0x44,%ymm5,%ymm7
-	vshufpd $0xc,%ymm7,%ymm10,%ymm7
 	vpermpd $0xee,%ymm13,%ymm13
-	vmovapd 0xa0(%rsp),%ymm10
 	vpermpd $0xee,%ymm5,%ymm5
+	vshufpd $0xc,%ymm7,%ymm10,%ymm7
 	vshufpd $0xc,%ymm5,%ymm13,%ymm5
-	vmovapd 0x40(%rsp),%ymm13
+	vmovapd 0xa0(%rsp),%ymm13
 	vmovapd %ymm7,0x80(%rsp)
 	vpermpd $0x44,%ymm9,%ymm7
 	vmovapd %ymm5,0x60(%rsp)
 	vpermpd $0xee,%ymm9,%ymm9
 	vpermpd $0x44,%ymm8,%ymm5
 	vpermpd $0xee,%ymm8,%ymm8
 	vshufpd $0xc,%ymm5,%ymm7,%ymm5
@@ -2080,26 +1346,27 @@
 	vshufpd $0xc,%ymm8,%ymm9,%ymm9
 	vpermpd $0x44,%ymm12,%ymm8
 	vpermpd $0xee,%ymm12,%ymm12
 	vshufpd $0xc,%ymm7,%ymm8,%ymm7
 	vshufpd $0xc,%ymm4,%ymm12,%ymm12
 	vpermpd $0x44,%ymm14,%ymm4
 	vpermpd $0xee,%ymm14,%ymm14
-	vpermpd $0x44,%ymm10,%ymm8
-	vpermpd $0xee,%ymm10,%ymm10
+	vpermpd $0x44,%ymm13,%ymm8
+	vpermpd $0xee,%ymm13,%ymm10
+	vmovapd 0x40(%rsp),%ymm13
 	vshufpd $0xc,%ymm4,%ymm8,%ymm4
 	vshufpd $0xc,%ymm14,%ymm10,%ymm10
 	vpermpd $0x44,%ymm1,%ymm8
+	vpermpd $0xee,%ymm1,%ymm1
 	vpermpd $0x44,%ymm13,%ymm14
 	vshufpd $0xc,%ymm8,%ymm14,%ymm14
-	vpermpd $0xee,%ymm1,%ymm1
 	vpermpd $0xee,%ymm13,%ymm8
 	vpermpd $0x44,%ymm2,%ymm13
-	vshufpd $0xc,%ymm1,%ymm8,%ymm1
 	vpermpd $0xee,%ymm2,%ymm2
+	vshufpd $0xc,%ymm1,%ymm8,%ymm1
 	vpermpd $0x44,%ymm5,%ymm8
 	vpermpd $0xee,%ymm5,%ymm5
 	vshufpd $0xc,%ymm8,%ymm13,%ymm13
 	vshufpd $0xc,%ymm5,%ymm2,%ymm2
 	vpermpd $0x44,%ymm6,%ymm8
 	vpermpd $0x44,%ymm9,%ymm5
 	vpermpd $0xee,%ymm6,%ymm6
@@ -2160,137 +1427,138 @@
 	vmovupd %ymm13,-0x1e0(%rcx)
 	vshufpd $0xc,%ymm4,%ymm0,%ymm0
 	vshufpd $0xc,%ymm3,%ymm2,%ymm2
 	vmovupd %ymm0,-0x1c0(%rcx)
 	vmovupd %ymm2,-0x1a0(%rcx)
 	vpermpd $0x44,%ymm5,%ymm0
 	vpermpd $0x44,%ymm6,%ymm2
+	vpermpd $0xee,%ymm5,%ymm5
+	vpermpd $0xee,%ymm6,%ymm6
 	vshufpd $0xc,%ymm2,%ymm0,%ymm0
 	vpermpd $0x44,%ymm11,%ymm2
-	vpermpd $0xee,%ymm6,%ymm6
-	vpermpd $0xee,%ymm5,%ymm5
+	vshufpd $0xc,%ymm6,%ymm5,%ymm5
+	vmovapd 0xa0(%rsp),%ymm6
+	vmovapd 0x40(%rsp),%ymm4
 	vmovupd %ymm0,-0x180(%rcx)
 	vpermpd $0x44,%ymm9,%ymm0
-	vshufpd $0xc,%ymm6,%ymm5,%ymm5
-	vpermpd $0xee,%ymm9,%ymm9
+	vpermpd $0xee,%ymm11,%ymm11
 	vshufpd $0xc,%ymm2,%ymm0,%ymm0
 	vpermpd $0x44,%ymm12,%ymm2
 	vpermpd $0xee,%ymm12,%ymm12
-	vpermpd $0xee,%ymm11,%ymm11
+	vpermpd $0xee,%ymm9,%ymm9
 	vmovupd %ymm0,-0x140(%rcx)
 	vpermpd $0x44,%ymm8,%ymm0
 	vpermpd $0xee,%ymm8,%ymm8
 	vmovupd %ymm5,-0x160(%rcx)
 	vshufpd $0xc,%ymm2,%ymm0,%ymm0
 	vpermpd $0x44,%ymm14,%ymm2
 	vshufpd $0xc,%ymm12,%ymm8,%ymm8
 	vpermpd $0xee,%ymm14,%ymm14
 	vmovupd %ymm0,-0x100(%rcx)
 	vpermpd $0x44,%ymm7,%ymm0
 	vpermpd $0xee,%ymm7,%ymm7
 	vmovupd %ymm8,-0xe0(%rcx)
-	vshufpd $0xc,%ymm14,%ymm7,%ymm7
 	vshufpd $0xc,%ymm2,%ymm0,%ymm0
 	vpermpd $0x44,%ymm15,%ymm2
+	vshufpd $0xc,%ymm11,%ymm9,%ymm9
 	vpermpd $0xee,%ymm15,%ymm15
-	vmovupd %ymm7,-0xa0(%rcx)
-	vmovapd 0xa0(%rsp),%ymm7
 	vmovupd %ymm0,-0xc0(%rcx)
-	vshufpd $0xc,%ymm11,%ymm9,%ymm9
+	vshufpd $0xc,%ymm14,%ymm7,%ymm7
 	vmovupd %ymm9,-0x120(%rcx)
-	vpermpd $0x44,%ymm7,%ymm0
-	vpermpd $0xee,%ymm7,%ymm6
-	vmovapd 0x40(%rsp),%ymm7
+	vpermpd $0x44,%ymm6,%ymm0
+	vpermpd $0xee,%ymm4,%ymm12
+	vpermpd $0xee,%ymm6,%ymm6
+	vmovupd %ymm7,-0xa0(%rcx)
 	vshufpd $0xc,%ymm2,%ymm0,%ymm0
-	vshufpd $0xc,%ymm15,%ymm6,%ymm6
 	vpermpd $0x44,%ymm1,%ymm2
-	vmovupd %ymm0,-0x80(%rcx)
+	vshufpd $0xc,%ymm15,%ymm6,%ymm6
 	vpermpd $0xee,%ymm1,%ymm1
+	vmovupd %ymm0,-0x80(%rcx)
+	vpermpd $0x44,%ymm4,%ymm0
+	vshufpd $0xc,%ymm1,%ymm12,%ymm12
 	vmovupd %ymm6,-0x60(%rcx)
-	vpermpd $0x44,%ymm7,%ymm0
-	vpermpd $0xee,%ymm7,%ymm12
 	vshufpd $0xc,%ymm2,%ymm0,%ymm0
-	vshufpd $0xc,%ymm1,%ymm12,%ymm12
-	vmovupd %ymm0,-0x40(%rcx)
 	vmovupd %ymm12,-0x20(%rcx)
-	cmp    %r8,%rsi
-	jne    34b0 <cartesian_spherical_harmonics_l3._omp_fn.0+0x5c0>
+	vmovupd %ymm0,-0x40(%rcx)
+	cmp    %rdi,%rcx
+	jne    26f0 <cartesian_spherical_harmonics_l3._omp_fn.0+0x5b0>
 	mov    %eax,%ecx
 	and    $0xfffffffc,%ecx
 	add    %ecx,%edx
-	cmp    %ecx,%eax
-	je     3408 <cartesian_spherical_harmonics_l3._omp_fn.0+0x518>
+	cmp    %eax,%ecx
+	je     2643 <cartesian_spherical_harmonics_l3._omp_fn.0+0x503>
 	sub    %ecx,%eax
-	mov    %eax,%r8d
+	mov    %eax,%r9d
 	cmp    $0x1,%eax
-	je     4261 <cartesian_spherical_harmonics_l3._omp_fn.0+0x1371>
+	je     346a <cartesian_spherical_harmonics_l3._omp_fn.0+0x132a>
 	vzeroupper
 	mov    %ecx,%eax
-	vmovapd 0x5a06(%rip),%xmm6        
+	vmovapd 0xa9ae(%rip),%xmm6        
+	mov    0xa477(%rip),%rdi        
 	lea    (%rax,%rax,2),%rcx
 	shl    $0x4,%rax
 	add    %rcx,%r10
-	add    %r9,%rax
-	lea    (%r12,%r10,8),%rsi
-	lea    (%rbx,%rax,8),%rcx
-	mov    0x5699(%rip),%rax        
-	vmovupd (%rsi),%xmm2
-	vmovupd 0x10(%rsi),%xmm0
-	vmovupd 0x20(%rsi),%xmm1
+	add    %r8,%rax
+	lea    (%r12,%r10,8),%rcx
+	lea    (%rbx,%rax,8),%rax
+	vmovupd (%rcx),%xmm2
+	vmovupd 0x10(%rcx),%xmm0
+	vmovupd 0x20(%rcx),%xmm1
 	vmovsd %xmm2,%xmm0,%xmm4
-	vunpcklpd %xmm2,%xmm0,%xmm0
 	vpermilpd $0x1,%xmm2,%xmm11
+	vunpcklpd %xmm2,%xmm0,%xmm0
 	vmovsd %xmm0,%xmm1,%xmm2
-	vmovapd 0x5971(%rip),%xmm0        
+	vmulpd %xmm4,%xmm4,%xmm0
 	vunpcklpd %xmm1,%xmm11,%xmm11
-	vmulpd 0x5a05(%rip),%xmm11,%xmm8        
-	vmulpd %xmm6,%xmm4,%xmm1
-	vmulpd %xmm6,%xmm2,%xmm6
+	vmovapd 0xa911(%rip),%xmm1        
+	vmulpd 0xa9b9(%rip),%xmm2,%xmm14        
 	vmulpd %xmm11,%xmm11,%xmm10
+	vmovapd %xmm0,%xmm8
+	vfnmadd132pd 0xa987(%rip),%xmm10,%xmm8        
 	vmulpd %xmm2,%xmm2,%xmm3
-	vmulpd %xmm0,%xmm11,%xmm13
-	vmulpd %xmm0,%xmm2,%xmm15
+	vmulpd %xmm1,%xmm11,%xmm13
+	vmulpd %xmm1,%xmm2,%xmm15
 	vmovapd %xmm3,%xmm12
-	vmulpd %xmm0,%xmm4,%xmm7
-	vmulpd %xmm13,%xmm6,%xmm6
-	vmulpd %xmm4,%xmm4,%xmm0
+	vmulpd %xmm1,%xmm4,%xmm7
+	vmulpd %xmm6,%xmm4,%xmm1
+	vmulpd %xmm6,%xmm2,%xmm6
 	vmovapd %xmm7,0xa0(%rsp)
-	vmulpd 0x5a1a(%rip),%xmm2,%xmm7        
-	vmovapd %xmm6,0x60(%rsp)
-	vaddpd %xmm10,%xmm0,%xmm6
-	vfnmadd132pd 0x5976(%rip),%xmm6,%xmm12        
-	vmovapd %xmm0,%xmm14
-	vfnmadd231pd 0x59c9(%rip),%xmm3,%xmm6        
-	vfnmadd132pd 0x5990(%rip),%xmm10,%xmm14        
 	vmulpd %xmm1,%xmm15,%xmm5
-	vmulpd %xmm1,%xmm13,%xmm9
-	vmulpd 0x5960(%rip),%xmm12,%xmm12        
-	vmulpd 0x59b8(%rip),%xmm6,%xmm6        
+	vmovapd %xmm8,%xmm7
+	vmulpd 0xa962(%rip),%xmm11,%xmm8        
+	vmulpd %xmm13,%xmm6,%xmm6
 	vmovapd %xmm5,0x80(%rsp)
 	vsubpd %xmm10,%xmm0,%xmm5
-	vfnmadd231pd 0x59b1(%rip),%xmm12,%xmm3        
-	vfnmadd231pd 0x5958(%rip),%xmm10,%xmm0        
-	vmulpd 0x5940(%rip),%xmm5,%xmm1        
-	vmulpd %xmm14,%xmm8,%xmm8
-	vmulpd 0x5963(%rip),%xmm2,%xmm14        
-	vmulpd 0x59ab(%rip),%xmm2,%xmm2        
+	vmulpd %xmm1,%xmm13,%xmm9
+	vmulpd 0xa923(%rip),%xmm5,%xmm1        
+	vmovapd %xmm6,0x60(%rsp)
+	vaddpd %xmm10,%xmm0,%xmm6
+	vfnmadd132pd 0xa8ef(%rip),%xmm6,%xmm12        
+	vfnmadd231pd 0xa946(%rip),%xmm3,%xmm6        
+	vfnmadd231pd 0xa90d(%rip),%xmm10,%xmm0        
+	vmulpd %xmm9,%xmm14,%xmm14
+	vmulpd %xmm7,%xmm8,%xmm8
+	vmulpd 0xa8dc(%rip),%xmm12,%xmm12        
+	vmulpd 0xa934(%rip),%xmm6,%xmm6        
 	vunpcklpd %xmm8,%xmm13,%xmm10
 	vunpckhpd %xmm8,%xmm13,%xmm8
+	vfnmadd231pd 0xa931(%rip),%xmm12,%xmm3        
+	vunpcklpd %xmm14,%xmm15,%xmm13
+	vunpckhpd %xmm14,%xmm15,%xmm15
+	vmulpd 0xa92f(%rip),%xmm2,%xmm7        
+	vmulpd 0xa937(%rip),%xmm2,%xmm2        
 	vmulpd %xmm6,%xmm11,%xmm11
 	vmulpd %xmm6,%xmm4,%xmm6
-	vmulpd 0x59a1(%rip),%xmm4,%xmm4        
+	vmulpd 0xa937(%rip),%xmm4,%xmm4        
+	vmulpd %xmm5,%xmm2,%xmm5
+	vmovq  %rdi,%xmm2
 	vmulpd %xmm3,%xmm7,%xmm3
 	vmovapd 0xa0(%rsp),%xmm7
-	vmulpd %xmm9,%xmm14,%xmm14
-	vmulpd %xmm5,%xmm2,%xmm5
-	vmovq  %rax,%xmm2
-	vunpcklpd %xmm14,%xmm15,%xmm13
-	vunpckhpd %xmm14,%xmm15,%xmm15
 	vmulpd %xmm0,%xmm4,%xmm0
-	vmovapd 0x5870(%rip),%xmm4        
+	vmovapd 0xa815(%rip),%xmm4        
 	vunpcklpd %xmm11,%xmm7,%xmm14
 	vunpckhpd %xmm11,%xmm7,%xmm7
 	vmovapd 0x60(%rsp),%xmm11
 	vmovapd %xmm7,0xa0(%rsp)
 	vunpckhpd %xmm3,%xmm9,%xmm7
 	vunpcklpd %xmm1,%xmm4,%xmm4
 	vmovsd %xmm2,%xmm1,%xmm1
@@ -2338,1621 +1606,229 @@
 	vunpcklpd %xmm6,%xmm11,%xmm12
 	vunpckhpd %xmm6,%xmm11,%xmm6
 	vmovapd 0x60(%rsp),%xmm11
 	vunpcklpd %xmm0,%xmm11,%xmm1
 	vunpckhpd %xmm0,%xmm11,%xmm0
 	vunpcklpd %xmm14,%xmm15,%xmm11
 	vunpckhpd %xmm14,%xmm15,%xmm14
-	vmovupd %xmm14,0x10(%rcx)
+	vmovupd %xmm14,0x10(%rax)
 	vunpcklpd %xmm7,%xmm5,%xmm14
 	vunpckhpd %xmm7,%xmm5,%xmm5
-	vmovupd %xmm11,(%rcx)
-	vmovupd %xmm5,0x30(%rcx)
+	vmovupd %xmm11,(%rax)
+	vmovupd %xmm5,0x30(%rax)
 	vunpcklpd %xmm13,%xmm10,%xmm5
 	vunpckhpd %xmm13,%xmm10,%xmm10
-	vmovupd %xmm14,0x20(%rcx)
-	vmovupd %xmm5,0x40(%rcx)
+	vmovupd %xmm14,0x20(%rax)
+	vmovupd %xmm5,0x40(%rax)
 	vunpcklpd %xmm3,%xmm2,%xmm5
 	vunpckhpd %xmm3,%xmm2,%xmm2
-	vmovupd %xmm10,0x50(%rcx)
-	vmovupd %xmm2,0x70(%rcx)
+	vmovupd %xmm10,0x50(%rax)
+	vmovupd %xmm5,0x60(%rax)
+	vmovupd %xmm2,0x70(%rax)
 	vunpcklpd %xmm12,%xmm9,%xmm2
 	vunpckhpd %xmm12,%xmm9,%xmm9
-	vmovupd %xmm5,0x60(%rcx)
-	vmovupd %xmm2,0x80(%rcx)
+	vmovupd %xmm2,0x80(%rax)
 	vunpcklpd %xmm6,%xmm4,%xmm2
 	vunpckhpd %xmm6,%xmm4,%xmm4
-	vmovupd %xmm9,0x90(%rcx)
-	vmovupd %xmm2,0xa0(%rcx)
+	vmovupd %xmm9,0x90(%rax)
+	vmovupd %xmm2,0xa0(%rax)
 	vunpcklpd %xmm1,%xmm8,%xmm2
 	vunpckhpd %xmm1,%xmm8,%xmm8
-	vmovupd %xmm4,0xb0(%rcx)
-	vmovupd %xmm2,0xc0(%rcx)
-	vmovupd %xmm8,0xd0(%rcx)
-	vmovapd 0xa0(%rsp),%xmm3
-	vunpcklpd %xmm0,%xmm3,%xmm2
-	vunpckhpd %xmm0,%xmm3,%xmm0
-	vmovupd %xmm2,0xe0(%rcx)
-	vmovupd %xmm0,0xf0(%rcx)
-	mov    %r8d,%ecx
-	and    $0xfffffffe,%ecx
-	add    %ecx,%edx
-	cmp    %ecx,%r8d
-	je     340b <cartesian_spherical_harmonics_l3._omp_fn.0+0x51b>
-	lea    (%rdx,%rdx,2),%ecx
-	vmovsd 0x538a(%rip),%xmm1        
-	vmovsd 0x538a(%rip),%xmm6        
-	movslq %ecx,%rcx
-	vmovsd 0x53cf(%rip),%xmm7        
-	lea    (%r12,%rcx,8),%rsi
+	vmovupd %xmm4,0xb0(%rax)
+	vmovupd %xmm2,0xc0(%rax)
+	vmovupd %xmm8,0xd0(%rax)
+	vmovapd 0xa0(%rsp),%xmm5
+	vunpcklpd %xmm0,%xmm5,%xmm2
+	vunpckhpd %xmm0,%xmm5,%xmm0
+	vmovupd %xmm2,0xe0(%rax)
+	vmovupd %xmm0,0xf0(%rax)
+	mov    %r9d,%eax
+	and    $0xfffffffe,%eax
+	add    %eax,%edx
+	cmp    %eax,%r9d
+	je     2646 <cartesian_spherical_harmonics_l3._omp_fn.0+0x506>
+	lea    (%rdx,%rdx,2),%eax
+	vmovsd 0xa14f(%rip),%xmm7        
+	vmovsd 0xa14f(%rip),%xmm2        
 	mov    %edx,%ecx
+	cltq
 	shl    $0x4,%ecx
+	lea    (%r12,%rax,8),%rsi
 	movslq %ecx,%rcx
-	lea    (%rbx,%rcx,8),%rdx
-	mov    %rax,(%rdx)
-	vmovsd 0x10(%rsi),%xmm2
-	vmovsd (%rsi),%xmm0
-	vmulsd 0x8(%rsi),%xmm1,%xmm4
-	vmulsd %xmm1,%xmm2,%xmm2
-	vmulsd %xmm1,%xmm0,%xmm0
-	vmovsd %xmm4,0x8(%rdx)
-	vmovsd %xmm2,0x10(%rdx)
-	vmovsd %xmm0,0x18(%rdx)
-	vmovsd 0x10(%rsi),%xmm1
-	vmovsd (%rsi),%xmm3
-	vmovsd 0x8(%rsi),%xmm0
-	vmulsd %xmm1,%xmm1,%xmm8
-	vmulsd %xmm6,%xmm1,%xmm1
-	vmulsd %xmm3,%xmm3,%xmm5
-	vmulsd %xmm0,%xmm0,%xmm0
-	vmulsd %xmm6,%xmm3,%xmm3
+	vmovsd 0x10(%rsi),%xmm0
+	vmovsd (%rsi),%xmm1
+	lea    (%rbx,%rcx,8),%rax
+	vmovsd 0x8(%rsi),%xmm3
+	mov    %rdi,(%rax)
+	vmulsd 0xa16c(%rip),%xmm3,%xmm10        
+	vmulsd %xmm7,%xmm0,%xmm8
+	vmulsd %xmm1,%xmm1,%xmm6
+	vmulsd %xmm7,%xmm3,%xmm5
+	vmulsd %xmm7,%xmm1,%xmm7
+	vmovsd %xmm8,0x10(%rax)
+	vmulsd %xmm3,%xmm3,%xmm4
+	vmulsd %xmm0,%xmm0,%xmm9
+	vmovsd %xmm7,0x18(%rax)
+	vmovsd %xmm5,0x8(%rax)
+	vmulsd %xmm2,%xmm1,%xmm7
+	vmulsd %xmm2,%xmm0,%xmm2
+	vsubsd %xmm4,%xmm6,%xmm11
+	vmulsd %xmm7,%xmm5,%xmm12
+	vmulsd %xmm7,%xmm8,%xmm8
+	vmulsd 0xa0f9(%rip),%xmm11,%xmm7        
+	vmulsd %xmm5,%xmm2,%xmm2
+	vmovsd %xmm9,%xmm9,%xmm5
+	vmovsd %xmm8,0x38(%rax)
+	vmovsd %xmm6,%xmm6,%xmm8
+	vmovsd %xmm12,0x20(%rax)
+	vmovsd %xmm2,0x28(%rax)
+	vaddsd %xmm4,%xmm6,%xmm2
+	vfnmadd132sd 0xa0c1(%rip),%xmm2,%xmm5        
+	vfnmadd231sd 0xa108(%rip),%xmm9,%xmm2        
+	vmulsd 0xa108(%rip),%xmm2,%xmm2        
+	vmulsd 0xa0b0(%rip),%xmm5,%xmm5        
+	vmovsd %xmm7,0x40(%rax)
+	vmovsd 0xa0d3(%rip),%xmm7        
+	vfnmadd132sd %xmm7,%xmm4,%xmm8
+	vfnmadd132sd %xmm7,%xmm6,%xmm4
+	vmulsd %xmm2,%xmm3,%xmm3
+	vmulsd %xmm2,%xmm1,%xmm2
+	vmovsd %xmm5,0x30(%rax)
+	vfnmadd132sd 0xa0db(%rip),%xmm9,%xmm5        
+	vmulsd 0xa0eb(%rip),%xmm1,%xmm1        
+	vmovsd %xmm2,0x68(%rax)
+	vmulsd 0xa0ce(%rip),%xmm0,%xmm2        
+	vmovsd %xmm3,0x58(%rax)
+	vmulsd %xmm8,%xmm10,%xmm10
+	vmulsd 0xa09c(%rip),%xmm0,%xmm8        
+	vmulsd 0xa0bc(%rip),%xmm0,%xmm0        
+	vmovsd %xmm10,0x48(%rax)
 	vmulsd %xmm4,%xmm1,%xmm1
-	vsubsd %xmm0,%xmm5,%xmm11
-	vmovsd %xmm5,%xmm5,%xmm9
-	vmulsd %xmm3,%xmm4,%xmm12
-	vmulsd %xmm3,%xmm2,%xmm2
-	vmovsd %xmm1,0x28(%rdx)
-	vmovsd %xmm8,%xmm8,%xmm4
-	vaddsd %xmm0,%xmm5,%xmm1
-	vfnmadd132sd 0x5303(%rip),%xmm1,%xmm4        
-	vfnmadd231sd 0x535a(%rip),%xmm8,%xmm1        
-	vmovsd %xmm2,0x38(%rdx)
-	vmulsd 0x52fd(%rip),%xmm11,%xmm2        
-	vmovsd %xmm12,0x20(%rdx)
-	vfnmadd132sd %xmm7,%xmm0,%xmm9
-	vfnmadd132sd %xmm7,%xmm5,%xmm0
-	vmulsd 0x52de(%rip),%xmm4,%xmm4        
-	vmulsd 0x5336(%rip),%xmm1,%xmm1        
-	vmovsd %xmm2,0x40(%rdx)
-	vmovsd %xmm4,0x30(%rdx)
-	vmovsd 0x8(%rsi),%xmm6
-	vmovsd 0x10(%rsi),%xmm2
-	vmulsd 0x5302(%rip),%xmm6,%xmm10        
-	vmovsd (%rsi),%xmm3
-	vmulsd %xmm1,%xmm6,%xmm6
-	vmulsd %xmm1,%xmm3,%xmm1
-	vmulsd %xmm9,%xmm10,%xmm10
-	vmovsd %xmm6,0x58(%rdx)
-	vmulsd 0x52ec(%rip),%xmm2,%xmm9        
-	vmovsd %xmm1,0x68(%rdx)
-	vmovsd %xmm10,0x48(%rdx)
-	vmulsd %xmm12,%xmm9,%xmm9
-	vmovsd %xmm9,0x50(%rdx)
-	vfnmadd132sd 0x52e7(%rip),%xmm8,%xmm4        
-	vmulsd 0x52e7(%rip),%xmm2,%xmm1        
-	vmulsd 0x52ef(%rip),%xmm3,%xmm3        
-	vmulsd 0x52df(%rip),%xmm2,%xmm2        
-	vmulsd %xmm0,%xmm3,%xmm0
-	vmulsd %xmm4,%xmm1,%xmm4
-	vmulsd %xmm11,%xmm2,%xmm2
-	vmovsd %xmm0,0x78(%rdx)
-	vmovsd %xmm4,0x60(%rdx)
-	vmovsd %xmm2,0x70(%rdx)
+	vmulsd %xmm5,%xmm2,%xmm5
+	vmulsd %xmm12,%xmm8,%xmm8
+	vmovsd %xmm5,0x60(%rax)
+	vmulsd %xmm11,%xmm0,%xmm0
+	vmovsd %xmm8,0x50(%rax)
+	vmovsd %xmm0,0x70(%rax)
+	vmovsd %xmm1,0x78(%rax)
 	lea    -0x28(%rbp),%rsp
 	pop    %rbx
 	pop    %r12
 	pop    %r13
 	pop    %r14
 	pop    %r15
 	pop    %rbp
 	ret
-	data16 cs nopw 0x0(%rax,%rax,1)
-	nop
+	cs nopw 0x0(%rax,%rax,1)
 	inc    %eax
 	xor    %edx,%edx
-	jmp    2f3e <cartesian_spherical_harmonics_l3._omp_fn.0+0x4e>
+	jmp    218e <cartesian_spherical_harmonics_l3._omp_fn.0+0x4e>
 	nopl   0x0(%rax)
 	inc    %eax
 	xor    %edx,%edx
-	jmp    3428 <cartesian_spherical_harmonics_l3._omp_fn.0+0x538>
-	vmovsd 0x5267(%rip),%xmm7        
-	vmovsd 0x51ff(%rip),%xmm5        
-	movslq %edx,%rdx
+	jmp    2668 <cartesian_spherical_harmonics_l3._omp_fn.0+0x528>
+	vmovsd 0xa037(%rip),%xmm3        
+	vmovsd 0x9fdf(%rip),%xmm6        
 	dec    %eax
-	vmovsd 0x51e2(%rip),%xmm3        
-	vmovsd 0x51e2(%rip),%xmm4        
-	mov    %rdx,%rcx
+	movslq %edx,%rdx
+	vmovsd 0x9fc2(%rip),%xmm4        
+	vmovsd 0x9fc2(%rip),%xmm5        
 	add    %rax,%rdx
-	vmovsd 0x5224(%rip),%xmm6        
-	mov    0x51bd(%rip),%rax        
-	shl    $0x7,%rcx
+	vmovsd 0x9ff7(%rip),%xmm7        
+	mov    0x9fa0(%rip),%rdi        
 	shl    $0x7,%rdx
-	mov    %rdi,%rsi
-	add    %rbx,%rcx
-	lea    0x80(%rbx,%rdx,1),%rdx
-	vmovsd %xmm7,0x60(%rsp)
-	vmovsd 0x5219(%rip),%xmm7        
-	vmovsd %xmm5,0x18(%rsp)
-	vmovsd 0x51ab(%rip),%xmm5        
-	vmovsd %xmm7,0x40(%rsp)
-	vmovsd 0x5205(%rip),%xmm7        
-	vmovsd %xmm5,0x10(%rsp)
-	vmovsd 0x5197(%rip),%xmm5        
-	vmovsd %xmm7,0x38(%rsp)
-	vmovsd 0x51f1(%rip),%xmm7        
-	vmovsd %xmm5,0x8(%rsp)
-	vmovsd 0x51bb(%rip),%xmm5        
-	vmovsd %xmm7,0x30(%rsp)
-	vmovsd 0x51dd(%rip),%xmm7        
-	vmovsd %xmm5,0x80(%rsp)
-	vmovsd 0x51a4(%rip),%xmm5        
-	vmovsd %xmm7,0x28(%rsp)
-	vmovsd 0x51c6(%rip),%xmm7        
-	vmovsd %xmm7,0x20(%rsp)
-	mov    %rax,(%rcx)
-	vmovsd 0x10(%rsi),%xmm9
-	sub    $0xffffffffffffff80,%rcx
-	add    $0x18,%rsi
-	vmovsd -0x18(%rsi),%xmm0
-	vmulsd -0x10(%rsi),%xmm3,%xmm10
-	vmulsd %xmm3,%xmm9,%xmm9
-	vmulsd %xmm3,%xmm0,%xmm0
-	vmovsd %xmm9,-0x70(%rcx)
-	vmovsd %xmm10,-0x78(%rcx)
-	vmovsd %xmm0,-0x68(%rcx)
-	vmovsd -0x18(%rsi),%xmm2
-	vmovsd -0x8(%rsi),%xmm1
-	vmovsd -0x10(%rsi),%xmm0
-	vmulsd %xmm2,%xmm2,%xmm8
-	vmulsd %xmm4,%xmm2,%xmm2
-	vmulsd %xmm1,%xmm1,%xmm7
-	vmulsd %xmm4,%xmm1,%xmm1
-	vmovsd %xmm8,%xmm8,%xmm15
-	vmulsd %xmm2,%xmm10,%xmm12
-	vmulsd %xmm10,%xmm1,%xmm1
-	vmovsd 0x18(%rsp),%xmm10
-	vmulsd %xmm0,%xmm0,%xmm0
-	vmulsd %xmm2,%xmm9,%xmm9
-	vmovsd %xmm1,-0x58(%rcx)
-	vmovsd %xmm12,-0x60(%rcx)
-	vaddsd %xmm0,%xmm8,%xmm2
-	vsubsd %xmm0,%xmm8,%xmm11
-	vmulsd 0x8(%rsp),%xmm11,%xmm1
-	vmovsd %xmm9,-0x48(%rcx)
-	vfnmadd132sd %xmm6,%xmm0,%xmm15
-	vfnmadd132sd %xmm6,%xmm8,%xmm0
-	vfnmadd132sd %xmm7,%xmm2,%xmm10
-	vmulsd 0x10(%rsp),%xmm10,%xmm10
-	vfnmadd231sd 0x60(%rsp),%xmm7,%xmm2
-	vfnmadd231sd 0x38(%rsp),%xmm10,%xmm7
-	vmulsd 0x40(%rsp),%xmm2,%xmm2
-	vmovsd %xmm1,-0x40(%rcx)
-	vmovsd %xmm10,-0x50(%rcx)
-	vmovsd -0x10(%rsi),%xmm13
-	vmovsd -0x8(%rsi),%xmm1
-	vmulsd 0x80(%rsp),%xmm13,%xmm14
-	vmulsd 0x30(%rsp),%xmm1,%xmm10
-	vmovsd -0x18(%rsi),%xmm9
-	vmulsd %xmm2,%xmm13,%xmm13
-	vmulsd %xmm2,%xmm9,%xmm2
-	vmulsd %xmm15,%xmm14,%xmm14
-	vmovsd %xmm13,-0x28(%rcx)
-	vmulsd %xmm7,%xmm10,%xmm7
-	vmovsd %xmm2,-0x18(%rcx)
-	vmovsd %xmm14,-0x38(%rcx)
-	vmulsd %xmm5,%xmm1,%xmm14
-	vmulsd 0x28(%rsp),%xmm1,%xmm1
-	vmovsd %xmm7,-0x20(%rcx)
-	vmulsd %xmm12,%xmm14,%xmm12
-	vmovsd %xmm12,-0x30(%rcx)
-	vmulsd %xmm11,%xmm1,%xmm1
-	vmovsd %xmm1,-0x10(%rcx)
-	vmulsd 0x20(%rsp),%xmm9,%xmm9
-	vmulsd %xmm0,%xmm9,%xmm0
-	vmovsd %xmm0,-0x8(%rcx)
-	cmp    %rdx,%rcx
-	jne    4120 <cartesian_spherical_harmonics_l3._omp_fn.0+0x1230>
-	jmp    340b <cartesian_spherical_harmonics_l3._omp_fn.0+0x51b>
-	xor    %ecx,%ecx
-	jmp    3b80 <cartesian_spherical_harmonics_l3._omp_fn.0+0xc90>
-	mov    0x4fd8(%rip),%rax        
-	vzeroupper
-	jmp    3eb3 <cartesian_spherical_harmonics_l3._omp_fn.0+0xfc3>
-
-0000000000004270 <cartesian_spherical_harmonics._omp_fn.0>:
-cartesian_spherical_harmonics._omp_fn.0():
-	push   %rbp
-	mov    %rsp,%rbp
-	push   %r15
-	push   %r14
-	push   %r13
-	push   %r12
-	push   %rbx
-	and    $0xffffffffffffffe0,%rsp
-	sub    $0x140,%rsp
-	mov    0x18(%rdi),%rax
-	mov    0x24(%rdi),%r12d
-	mov    (%rdi),%r14
-	mov    %rax,0x30(%rsp)
-	mov    0x10(%rdi),%rax
-	lea    0x1(%r12),%ebx
-	mov    %ebx,0x108(%rsp)
-	mov    %rax,0x120(%rsp)
-	mov    0x8(%rdi),%rax
-	mov    %rax,0x118(%rsp)
-	mov    0x20(%rdi),%eax
-	lea    0x2(%r12),%edi
-	mov    %edi,0x130(%rsp)
-	imul   %rbx,%rdi
-	shl    $0x3,%rbx
-	shl    $0x3,%rdi
-	mov    %eax,0x138(%rsp)
-	shr    %rdi
-	call   10b0 <malloc@plt>
-	mov    %rbx,%rdi
-	mov    %rax,%r15
-	call   10b0 <malloc@plt>
-	mov    %rbx,%rdi
-	mov    %rax,%r13
-	call   10b0 <malloc@plt>
-	mov    0x130(%rsp),%edx
-	imul   0x108(%rsp),%edx
-	mov    %rax,%rbx
-	mov    %edx,%edi
-	shr    %edi
-	shl    $0x3,%rdi
-	call   10b0 <malloc@plt>
-	cmpl   $0x5,0x108(%rsp)
-	vxorps %xmm13,%xmm13,%xmm13
-	mov    %rax,0x28(%rsp)
-	jbe    6193 <cartesian_spherical_harmonics._omp_fn.0+0x1f23>
-	vmovsd 0x4f5d(%rip),%xmm1        
-	mov    %r14,0x130(%rsp)
-	mov    0x108(%rsp),%r11d
-	mov    $0x3,%r10d
-	mov    0x28(%rsp),%r14
-	mov    $0x5,%esi
-	mov    $0xf,%r9d
+	lea    0x80(%rbx,%rdx,1),%rax
+	vmovsd %xmm3,0x30(%rsp)
+	vmovsd 0x9ff6(%rip),%xmm3        
+	vmovsd %xmm6,0x80(%rsp)
+	vmovsd 0x9f95(%rip),%xmm6        
+	vmovsd %xmm3,0x28(%rsp)
+	vmovsd 0x9fdf(%rip),%xmm3        
+	vmovsd %xmm6,0x60(%rsp)
+	vmovsd 0x9f81(%rip),%xmm6        
+	vmovsd %xmm3,0x20(%rsp)
+	vmovsd 0x9fcb(%rip),%xmm3        
+	vmovsd %xmm6,0x40(%rsp)
+	vmovsd 0x9f95(%rip),%xmm6        
+	vmovsd %xmm3,0x18(%rsp)
+	vmovsd 0x9fb7(%rip),%xmm3        
+	vmovsd %xmm6,0x38(%rsp)
+	vmovsd 0x9f81(%rip),%xmm6        
+	vmovsd %xmm3,0x10(%rsp)
+	vmovsd 0x9fa3(%rip),%xmm3        
+	vmovsd %xmm3,0x8(%rsp)
 	data16 cs nopw 0x0(%rax,%rax,1)
-	nopl   0x0(%rax)
-	movslq %r9d,%rax
-	lea    0x1(%rsi),%edi
-	lea    (%r14,%rax,8),%r8
-	mov    %r10,%rax
-	nopl   (%rax)
-	mov    %esi,%ecx
-	lea    (%rdi,%rax,1),%edx
-	sub    %eax,%ecx
-	imul   %ecx,%edx
-	vcvtsi2sd %edx,%xmm13,%xmm0
-	vdivsd %xmm0,%xmm1,%xmm0
-	vmovsd %xmm0,(%r8,%rax,8)
-	dec    %rax
-	test   %eax,%eax
-	jns    4380 <cartesian_spherical_harmonics._omp_fn.0+0x110>
-	mov    %edi,%esi
-	add    %edi,%r9d
-	inc    %r10
-	cmp    %r11d,%edi
-	jne    4370 <cartesian_spherical_harmonics._omp_fn.0+0x100>
-	vmovsd 0x4edc(%rip),%xmm10        
-	mov    0x130(%rsp),%r14
-	vmovsd %xmm1,0x10(%r15)
-	vmovsd %xmm10,(%r15)
-	mov    0x108(%rsp),%r8d
-	mov    $0xfffffffd,%esi
-	mov    $0x3,%edx
-	mov    $0x2,%eax
-	xchg   %ax,%ax
-	movslq %edx,%rdi
-	vcvtsi2sd %esi,%xmm13,%xmm0
-	lea    (%rdx,%rax,1),%ecx
-	inc    %eax
-	vmulsd -0x8(%r15,%rdi,8),%xmm0,%xmm0
-	movslq %ecx,%rcx
-	add    %eax,%edx
-	sub    $0x2,%esi
-	vmovsd %xmm0,(%r15,%rcx,8)
-	cmp    %r8d,%eax
-	jne    43e0 <cartesian_spherical_harmonics._omp_fn.0+0x170>
-	movq   $0x0,(%rbx)
-	vmovsd %xmm10,0x0(%r13)
-	vmovsd %xmm10,0x128(%rsp)
-	call   1090 <omp_get_num_threads@plt>
-	mov    %eax,0x130(%rsp)
-	call   1080 <omp_get_thread_num@plt>
-	vmovsd 0x128(%rsp),%xmm10
-	vxorps %xmm13,%xmm13,%xmm13
-	mov    %eax,%ecx
-	mov    0x138(%rsp),%eax
-	cltd
-	idivl  0x130(%rsp)
-	cmp    %edx,%ecx
-	jl     618a <cartesian_spherical_harmonics._omp_fn.0+0x1f1a>
-	imul   %eax,%ecx
-	add    %ecx,%edx
-	lea    (%rax,%rdx,1),%ecx
-	cmp    %ecx,%edx
-	jge    6146 <cartesian_spherical_harmonics._omp_fn.0+0x1ed6>
-	mov    0x108(%rsp),%esi
-	dec    %eax
-	vxorpd %xmm9,%xmm9,%xmm9
-	vmovsd %xmm9,%xmm9,%xmm4
-	mov    %esi,%ecx
-	imul   %esi,%ecx
-	movslq %ecx,%rdi
-	lea    (%rcx,%rcx,1),%r9d
-	lea    0x0(,%rdi,8),%r11
-	movslq %r9d,%r8
-	mov    %r11,0xa0(%rsp)
-	add    $0x8,%r11
-	lea    0x0(,%r8,8),%rsi
-	mov    %r11,0x58(%rsp)
-	mov    0x118(%rsp),%r11
-	mov    %rsi,0x80(%rsp)
-	add    $0x8,%rsi
-	mov    %rsi,0x50(%rsp)
-	lea    (%rdx,%rdx,2),%esi
-	movslq %esi,%rsi
-	lea    (%r11,%rsi,8),%rsi
-	mov    %rsi,0x88(%rsp)
-	lea    (%r9,%rcx,1),%esi
-	imul   %edx,%ecx
-	movslq %edx,%rdx
-	mov    %esi,0x1c(%rsp)
-	add    %rax,%rdx
-	lea    (%rdx,%rdx,2),%rax
-	lea    (%r11,%rax,8),%rax
-	lea    (%rcx,%rcx,2),%esi
-	movslq %ecx,%rcx
-	mov    %rax,0x20(%rsp)
-	lea    -0x8(%r12),%eax
-	mov    %esi,0xa8(%rsp)
-	mov    0x120(%rsp),%rsi
-	mov    %eax,0x18(%rsp)
-	shr    %eax
-	add    $0x5,%eax
-	add    %rax,%rax
-	mov    %rax,0x10(%rsp)
-	lea    -0x6(%r12),%eax
-	lea    0x120(%rsi,%rcx,8),%rcx
-	mov    %rbx,%r12
-	lea    -0x10(,%rax,8),%rax
-	mov    %rcx,0x98(%rsp)
-	mov    %rax,0x100(%rsp)
-	lea    0x30(,%rdi,8),%rax
-	mov    %rax,0x8(%rsp)
-	lea    0x30(,%r8,8),%rax
-	mov    %rax,(%rsp)
-	mov    %r15,%rax
-	mov    %r14,%r15
-	mov    %rax,%r14
-	mov    0x88(%rsp),%rax
-	nopl   0x0(%rax)
-	vmovsd (%rax),%xmm1
-	vmovsd 0x8(%rax),%xmm0
-	vmovsd 0x10(%rax),%xmm3
-	cmpl   $0x6,0x108(%rsp)
-	vmulsd %xmm4,%xmm0,%xmm8
-	vmulsd %xmm4,%xmm1,%xmm4
-	vaddsd %xmm3,%xmm3,%xmm6
-	vfmadd231sd %xmm10,%xmm0,%xmm4
-	vmulsd %xmm1,%xmm1,%xmm7
-	vmulsd %xmm0,%xmm0,%xmm5
-	vmulsd %xmm3,%xmm3,%xmm2
-	vmovsd %xmm7,0xe8(%rsp)
-	vfmsub231sd %xmm10,%xmm1,%xmm8
-	vmovsd %xmm5,0xf8(%rsp)
-	vmovsd %xmm4,0x8(%r12)
-	vmovsd %xmm2,0xf0(%rsp)
-	vaddsd %xmm7,%xmm5,%xmm2
-	vmulsd %xmm4,%xmm0,%xmm7
-	vmulsd %xmm4,%xmm1,%xmm4
-	vfmsub231sd %xmm8,%xmm1,%xmm7
-	vmovsd %xmm8,0x8(%r13)
-	vfmadd132sd %xmm0,%xmm4,%xmm8
-	vmovsd %xmm7,0x10(%r13)
-	vmulsd %xmm8,%xmm0,%xmm5
-	vmovsd %xmm8,0x10(%r12)
-	vmulsd %xmm8,%xmm1,%xmm8
-	vfmsub231sd %xmm7,%xmm1,%xmm5
-	vfmadd132sd %xmm0,%xmm8,%xmm7
-	vmovsd %xmm5,0x18(%r13)
-	vmulsd %xmm7,%xmm0,%xmm4
-	vmovsd %xmm7,0x18(%r12)
-	vmulsd %xmm7,%xmm1,%xmm7
-	vfmsub231sd %xmm5,%xmm1,%xmm4
-	vfmadd132sd %xmm0,%xmm7,%xmm5
-	vmovsd %xmm4,0x20(%r13)
-	vmulsd %xmm5,%xmm0,%xmm7
-	vmovsd %xmm5,0x20(%r12)
-	vmulsd %xmm5,%xmm1,%xmm5
-	vfmsub231sd %xmm4,%xmm1,%xmm7
-	vfmadd132sd %xmm0,%xmm5,%xmm4
-	vmovsd %xmm7,0x28(%r13)
-	vmovsd %xmm4,0x28(%r12)
-	jbe    6171 <cartesian_spherical_harmonics._omp_fn.0+0x1f01>
-	cmpl   $0xfffffff6,0x18(%rsp)
-	ja     6180 <cartesian_spherical_harmonics._omp_fn.0+0x1f10>
-	mov    $0x8,%edx
-	vmulsd %xmm4,%xmm0,%xmm5
-	vmulsd %xmm4,%xmm1,%xmm4
-	movslq %edx,%rax
-	vfmadd231sd %xmm7,%xmm0,%xmm4
-	vfmsub231sd %xmm7,%xmm1,%xmm5
-	vmulsd %xmm4,%xmm0,%xmm7
-	vmovsd %xmm4,-0x10(%r12,%rdx,8)
-	vmulsd %xmm4,%xmm1,%xmm4
-	vfmsub231sd %xmm5,%xmm1,%xmm7
-	vfmadd231sd %xmm5,%xmm0,%xmm4
-	vunpcklpd %xmm7,%xmm5,%xmm8
-	vmovupd %xmm8,-0x10(%r13,%rdx,8)
-	vmovsd %xmm4,-0x8(%r12,%rdx,8)
-	add    $0x2,%rdx
-	cmp    %rdx,0x10(%rsp)
-	jne    4668 <cartesian_spherical_harmonics._omp_fn.0+0x3f8>
-	mov    0x108(%rsp),%edx
-	nopw   0x0(%rax,%rax,1)
-	vmovsd -0x8(%r12,%rax,8),%xmm5
-	vmovsd -0x8(%r13,%rax,8),%xmm4
-	vmulsd %xmm5,%xmm0,%xmm7
-	vmulsd %xmm5,%xmm1,%xmm5
-	vfmsub231sd %xmm4,%xmm1,%xmm7
-	vfmadd132sd %xmm0,%xmm5,%xmm4
-	vmovsd %xmm7,0x0(%r13,%rax,8)
-	vmovsd %xmm4,(%r12,%rax,8)
-	inc    %rax
-	cmp    %eax,%edx
-	ja     46c0 <cartesian_spherical_harmonics._omp_fn.0+0x450>
-	vxorpd 0x4e84(%rip),%xmm3,%xmm5        
-	mov    0x108(%rsp),%esi
-	mov    $0x5,%eax
-	mov    $0x14,%edx
-	nopl   (%rax)
-	movslq %edx,%rcx
-	lea    0x2(%rax,%rdx,1),%edx
-	inc    %eax
-	vmulsd (%r14,%rcx,8),%xmm5,%xmm4
-	vmovsd %xmm4,-0x8(%r14,%rcx,8)
-	cmp    %eax,%esi
-	ja     4710 <cartesian_spherical_harmonics._omp_fn.0+0x4a0>
-	mov    %r15,0x138(%rsp)
-	mov    %r12,0x130(%rsp)
-	mov    0x28(%rsp),%r15
-	mov    $0x1,%r9d
-	mov    $0x3,%r8d
-	mov    $0x5,%edi
-	mov    $0xf,%r11d
-	mov    0x108(%rsp),%r12d
 	xchg   %ax,%ax
-	movslq %r11d,%rdx
-	vcvtsi2sd %edi,%xmm13,%xmm5
-	vmulsd %xmm6,%xmm5,%xmm5
-	lea    -0x4(%r8),%r10
-	lea    (%r8,%rdx,1),%rax
-	lea    0x0(,%rdx,8),%rsi
-	mov    %r9,%rcx
-	lea    (%r14,%rax,8),%rax
-	lea    (%r15,%rsi,1),%rbx
-	add    %r14,%rsi
-	vmovsd 0x10(%rax),%xmm7
-	vmovsd 0x8(%rax),%xmm4
-	mov    %r9d,%eax
-	shr    %eax
-	add    %rax,%rax
-	sub    %rax,%r10
-	vsubsd %xmm6,%xmm5,%xmm5
-	vmulsd %xmm7,%xmm2,%xmm7
-	movslq %ecx,%rax
-	vfmadd231sd %xmm4,%xmm5,%xmm7
-	vmulsd 0x10(%rbx,%rcx,8),%xmm7,%xmm7
-	vsubsd %xmm6,%xmm5,%xmm5
-	vmulsd %xmm4,%xmm2,%xmm4
-	vfmadd231sd %xmm5,%xmm7,%xmm4
-	vmulsd 0x8(%rbx,%rcx,8),%xmm4,%xmm4
-	vmovsd %xmm7,0x10(%rsi,%rcx,8)
-	vmovsd %xmm4,0x8(%rsi,%rcx,8)
-	sub    $0x2,%rcx
-	cmp    %r10,%rcx
-	jne    479e <cartesian_spherical_harmonics._omp_fn.0+0x52e>
-	shl    $0x3,%rdx
-	lea    (%r15,%rdx,1),%rcx
-	add    %r14,%rdx
-	nopw   0x0(%rax,%rax,1)
-	vmulsd 0x10(%rdx,%rax,8),%xmm2,%xmm4
-	vsubsd %xmm6,%xmm5,%xmm5
-	vfmadd231sd 0x8(%rdx,%rax,8),%xmm5,%xmm4
-	vmulsd (%rcx,%rax,8),%xmm4,%xmm4
-	vmovsd %xmm4,(%rdx,%rax,8)
-	dec    %rax
-	test   %eax,%eax
-	jns    47f0 <cartesian_spherical_harmonics._omp_fn.0+0x580>
-	inc    %edi
-	inc    %r8
-	inc    %r9
-	add    %edi,%r11d
-	cmp    %edi,%r12d
-	ja     4760 <cartesian_spherical_harmonics._omp_fn.0+0x4f0>
-	mov    0x138(%rsp),%r15
-	mov    0x130(%rsp),%r12
-	vmulsd 0x4a0a(%rip),%xmm1,%xmm6        
-	mov    0x98(%rsp),%rax
-	vmulsd 0x49fa(%rip),%xmm0,%xmm4        
-	vmovsd 0xe8(%rsp),%xmm8
-	vmovsd 0xf8(%rsp),%xmm10
-	vmovsd 0xf0(%rsp),%xmm12
-	vmulsd 0x49df(%rip),%xmm1,%xmm14        
-	mov    0x49c8(%rip),%rbx        
-	vmulsd 0x4a28(%rip),%xmm0,%xmm9        
-	vmulsd 0x49c0(%rip),%xmm3,%xmm5        
-	mov    %rbx,-0x120(%rax)
-	mov    %rax,%rbx
-	vmovsd %xmm6,-0x108(%rax)
-	vmulsd 0x49ae(%rip),%xmm3,%xmm6        
-	vaddsd %xmm12,%xmm12,%xmm7
-	vmovsd %xmm4,-0x118(%rax)
-	vmulsd %xmm4,%xmm14,%xmm11
-	vmovsd %xmm7,0xe0(%rsp)
-	vmulsd %xmm5,%xmm14,%xmm14
-	vmovsd %xmm5,-0x110(%rax)
-	vsubsd %xmm7,%xmm2,%xmm5
-	vsubsd %xmm10,%xmm8,%xmm7
-	vmulsd 0x4987(%rip),%xmm5,%xmm5        
-	vmovsd %xmm11,-0x100(%rax)
-	vmulsd 0x497f(%rip),%xmm7,%xmm15        
-	vmovsd %xmm14,-0xe8(%rax)
-	vmulsd %xmm4,%xmm6,%xmm6
-	vmovsd 0x49a3(%rip),%xmm4        
-	vmovsd %xmm6,-0xf8(%rax)
-	vmovsd %xmm5,-0xf0(%rax)
-	vmovsd %xmm15,-0xe0(%rax)
-	vfnmadd132sd %xmm8,%xmm10,%xmm4
-	vmulsd 0x498e(%rip),%xmm3,%xmm10        
-	vmulsd %xmm4,%xmm9,%xmm4
-	vmovsd %xmm4,-0xd8(%rax)
-	vmovsd %xmm4,0x138(%rsp)
-	vmovsd 0x4979(%rip),%xmm4        
+	vmovsd (%rsi),%xmm1
+	sub    $0xffffffffffffff80,%rcx
+	add    $0x18,%rsi
+	vmovsd -0x8(%rsi),%xmm0
+	vmovsd -0x10(%rsi),%xmm2
+	mov    %rdi,-0x80(%rcx)
+	vmulsd 0x38(%rsp),%xmm2,%xmm14
+	vmulsd %xmm4,%xmm1,%xmm10
+	vmulsd %xmm1,%xmm1,%xmm3
+	vmulsd %xmm4,%xmm2,%xmm11
+	vmulsd %xmm4,%xmm0,%xmm12
+	vmovsd %xmm10,-0x68(%rcx)
+	vmulsd %xmm5,%xmm1,%xmm10
+	vmulsd %xmm2,%xmm2,%xmm9
+	vmovsd %xmm11,-0x78(%rcx)
+	vmovsd %xmm12,-0x70(%rcx)
+	vmulsd %xmm11,%xmm10,%xmm15
+	vmulsd %xmm12,%xmm10,%xmm10
+	vsubsd %xmm9,%xmm3,%xmm12
+	vmulsd 0x40(%rsp),%xmm12,%xmm13
+	vmulsd %xmm0,%xmm0,%xmm8
+	vmovsd %xmm10,-0x48(%rcx)
+	vmovsd %xmm15,-0x60(%rcx)
+	vmulsd %xmm5,%xmm0,%xmm10
 	vmulsd %xmm11,%xmm10,%xmm10
-	vmovsd %xmm10,-0xd0(%rax)
-	vfnmadd132sd %xmm12,%xmm2,%xmm4
-	vmulsd 0x4967(%rip),%xmm4,%xmm4        
-	vmulsd %xmm4,%xmm0,%xmm9
-	vmulsd %xmm4,%xmm1,%xmm4
-	vmovq  %xmm9,%rcx
-	vmovsd %xmm4,-0xb8(%rax)
-	vmovsd %xmm9,-0xc8(%rax)
-	vmovsd 0x494a(%rip),%xmm9        
-	vmulsd 0x4952(%rip),%xmm3,%xmm8        
-	vfnmadd132sd %xmm5,%xmm12,%xmm9
-	vmulsd 0x493d(%rip),%xmm3,%xmm12        
-	vmulsd %xmm9,%xmm12,%xmm12
-	vmulsd %xmm7,%xmm8,%xmm9
-	vmovsd 0xe8(%rsp),%xmm7
-	vmulsd 0x4933(%rip),%xmm1,%xmm8        
-	vmovsd %xmm12,-0xc0(%rax)
-	vmovq  %xmm9,%rax
-	vmovsd %xmm9,-0xb0(%rbx)
-	vmovsd 0x48d6(%rip),%xmm9        
-	vmulsd 0xf8(%rsp),%xmm9,%xmm9
-	vsubsd %xmm9,%xmm7,%xmm7
-	vmovsd %xmm9,0xd0(%rsp)
-	vmulsd 0x48b7(%rip),%xmm3,%xmm9        
-	vmulsd %xmm7,%xmm8,%xmm8
-	vmulsd 0x493b(%rip),%xmm11,%xmm7        
-	vmovsd %xmm8,-0xa8(%rbx)
-	vmovq  %xmm9,%rdx
-	vmulsd 0x138(%rsp),%xmm9,%xmm9
-	vmulsd %xmm15,%xmm7,%xmm7
-	vmovsd %xmm7,-0xa0(%rbx)
-	vmovsd %xmm9,-0x98(%rbx)
-	vmovsd 0x4910(%rip),%xmm9        
-	vfnmadd231sd 0xf0(%rsp),%xmm9,%xmm2
-	vmulsd 0x4906(%rip),%xmm2,%xmm2        
-	vmulsd %xmm2,%xmm11,%xmm11
-	vmulsd %xmm2,%xmm15,%xmm2
-	vmovsd %xmm2,-0x70(%rbx)
-	vmulsd 0x48f9(%rip),%xmm3,%xmm2        
-	vmovsd %xmm11,-0x90(%rbx)
-	vmovq  %rcx,%xmm11
-	vmulsd %xmm12,%xmm2,%xmm2
-	vfmsub231sd %xmm11,%xmm0,%xmm2
-	vfmadd132sd %xmm1,%xmm2,%xmm4
-	vmovsd 0x48e5(%rip),%xmm2        
-	vmulsd 0x48d5(%rip),%xmm4,%xmm4        
-	vfnmadd213sd 0xf0(%rsp),%xmm5,%xmm2
-	vmulsd 0x48d3(%rip),%xmm2,%xmm2        
-	vmovsd %xmm4,-0x80(%rbx)
-	vmulsd %xmm2,%xmm6,%xmm9
-	vmulsd %xmm2,%xmm14,%xmm14
-	vmovq  %rdx,%xmm6
-	vmulsd %xmm8,%xmm6,%xmm2
-	vmovq  %xmm9,%rcx
-	vmovsd %xmm9,-0x88(%rbx)
-	vmovsd %xmm14,-0x78(%rbx)
-	vmovsd %xmm2,-0x68(%rbx)
-	vmulsd %xmm8,%xmm1,%xmm2
-	vfmsub231sd 0x138(%rsp),%xmm0,%xmm2
-	vmulsd 0x4896(%rip),%xmm2,%xmm2        
-	vmovsd %xmm2,-0x60(%rbx)
-	vmovsd 0xe8(%rsp),%xmm9
-	vmovsd 0x4888(%rip),%xmm6        
-	vfnmadd132sd 0xf8(%rsp),%xmm9,%xmm6
-	vmulsd 0x487e(%rip),%xmm2,%xmm15        
-	cmpl   $0x6,0x108(%rsp)
-	vmovsd %xmm6,%xmm6,%xmm11
-	vfmadd132sd 0xf8(%rsp),%xmm15,%xmm11
-	vmulsd 0x4868(%rip),%xmm0,%xmm15        
-	vmovq  %rax,%xmm6
-	vmulsd %xmm11,%xmm15,%xmm11
-	vmovsd %xmm11,-0x58(%rbx)
-	vmulsd 0x4859(%rip),%xmm3,%xmm11        
-	vmulsd %xmm7,%xmm11,%xmm15
-	vmulsd %xmm2,%xmm11,%xmm11
-	vmovsd %xmm15,-0x50(%rbx)
-	vmovsd 0xf0(%rsp),%xmm15
-	vmulsd %xmm2,%xmm1,%xmm2
-	vmovsd %xmm11,-0x10(%rbx)
-	vmovsd 0x483a(%rip),%xmm11        
-	vfmsub132sd %xmm0,%xmm2,%xmm7
-	vmulsd 0x4865(%rip),%xmm7,%xmm7        
-	vfmadd132sd %xmm5,%xmm15,%xmm11
-	vmulsd 0x4828(%rip),%xmm11,%xmm11        
-	vmulsd 0x138(%rsp),%xmm11,%xmm9
-	vmovsd %xmm7,-0x8(%rbx)
+	vmovsd 0x80(%rsp),%xmm11
+	vmovsd %xmm10,-0x58(%rcx)
+	vaddsd %xmm3,%xmm9,%xmm10
+	vmovsd %xmm13,-0x40(%rcx)
+	vmovsd %xmm3,%xmm3,%xmm13
+	vfnmadd132sd %xmm7,%xmm9,%xmm13
+	vfnmadd231sd %xmm7,%xmm9,%xmm3
+	vfnmadd132sd %xmm8,%xmm10,%xmm11
+	vfnmadd231sd 0x30(%rsp),%xmm8,%xmm10
+	vmulsd 0x60(%rsp),%xmm11,%xmm11
+	vmulsd %xmm13,%xmm14,%xmm14
+	vfnmadd231sd 0x20(%rsp),%xmm11,%xmm8
+	vmulsd 0x28(%rsp),%xmm10,%xmm10
+	vmulsd %xmm6,%xmm0,%xmm13
+	vmovsd %xmm14,-0x38(%rcx)
+	vmulsd %xmm15,%xmm13,%xmm13
+	vmovsd %xmm11,-0x50(%rcx)
+	vmulsd 0x18(%rsp),%xmm0,%xmm11
+	vmulsd 0x10(%rsp),%xmm0,%xmm0
+	vmovsd %xmm13,-0x30(%rcx)
+	vmulsd %xmm2,%xmm10,%xmm2
+	vmulsd %xmm1,%xmm10,%xmm10
+	vmulsd 0x8(%rsp),%xmm1,%xmm1
+	vmovsd %xmm2,-0x28(%rcx)
+	vmovsd %xmm10,-0x18(%rcx)
 	vmulsd %xmm8,%xmm11,%xmm8
-	vmovsd %xmm8,-0x18(%rbx)
-	vmulsd 0x4810(%rip),%xmm5,%xmm8        
-	vmulsd 0x4820(%rip),%xmm5,%xmm5        
-	vmovsd %xmm9,-0x48(%rbx)
-	vmulsd %xmm10,%xmm8,%xmm10
-	vmulsd %xmm6,%xmm8,%xmm8
-	vmovq  %rcx,%xmm6
-	vmovsd %xmm8,-0x20(%rbx)
-	vmulsd 0x47f0(%rip),%xmm3,%xmm8        
-	vmovsd %xmm10,-0x40(%rbx)
-	vmulsd %xmm6,%xmm8,%xmm6
-	vmulsd %xmm14,%xmm8,%xmm14
-	vfmadd231sd %xmm4,%xmm0,%xmm6
-	vmulsd 0x47dd(%rip),%xmm6,%xmm6        
-	vfmadd132sd %xmm1,%xmm14,%xmm4
-	vmulsd 0x47d0(%rip),%xmm4,%xmm4        
-	vmovsd %xmm6,-0x38(%rbx)
-	vmulsd %xmm15,%xmm3,%xmm6
-	vmovsd %xmm4,-0x28(%rbx)
-	vmulsd %xmm6,%xmm15,%xmm4
-	vmovsd %xmm6,0xd8(%rsp)
-	vfmsub132sd %xmm5,%xmm4,%xmm12
-	vmulsd 0x47b7(%rip),%xmm12,%xmm12        
-	vmovsd %xmm12,-0x30(%rbx)
-	jbe    4f02 <cartesian_spherical_harmonics._omp_fn.0+0xc92>
-	vmovsd 0x8(%r12),%xmm14
-	mov    $0xffffffffffffffe8,%rcx
-	movq   $0x6,0x130(%rsp)
-	movq   $0x68,0x118(%rsp)
-	movl   $0x15,0x138(%rsp)
-	vmovsd 0x8(%r13),%xmm12
-	vmovsd 0x10(%r12),%xmm11
-	vmovsd 0x10(%r13),%xmm10
-	vmovsd 0x18(%r12),%xmm9
-	vmovsd 0x18(%r13),%xmm8
-	vmovsd 0x20(%r12),%xmm7
-	vmovsd 0x20(%r13),%xmm6
-	vmovsd 0x28(%r12),%xmm5
-	vmovsd 0x28(%r13),%xmm4
-	mov    0x98(%rsp),%rdx
-	nopw   0x0(%rax,%rax,1)
-	movslq 0x138(%rsp),%rax
-	mov    0x130(%rsp),%rdi
-	mov    %rax,0x120(%rsp)
-	shl    $0x3,%rax
-	mov    %edi,%esi
-	mov    %edi,0x10c(%rsp)
-	inc    %esi
-	mov    %edi,%ebx
-	vmovsd (%r14,%rax,1),%xmm2
-	mov    %esi,0x110(%rsp)
-	mov    %edi,%esi
-	vmulsd (%r15,%rax,1),%xmm2,%xmm2
-	sub    $0x5,%esi
-	mov    %esi,0x128(%rsp)
-	lea    -0x6(%rdi),%esi
-	vmovsd %xmm2,0x48(%rdx,%rcx,1)
-	vmovsd 0x8(%r14,%rax,1),%xmm2
-	vmulsd 0x8(%r15,%rax,1),%xmm2,%xmm2
-	vmulsd %xmm14,%xmm2,%xmm15
-	vmulsd %xmm12,%xmm2,%xmm2
-	vmovsd %xmm2,0x50(%rdx,%rcx,1)
-	vmovsd 0x10(%r14,%rax,1),%xmm2
-	vmovsd %xmm15,0x40(%rdx,%rcx,1)
-	vmulsd 0x10(%r15,%rax,1),%xmm2,%xmm2
-	vmulsd %xmm11,%xmm2,%xmm15
-	vmulsd %xmm10,%xmm2,%xmm2
-	vmovsd %xmm2,0x58(%rdx,%rcx,1)
-	vmovsd 0x18(%r14,%rax,1),%xmm2
-	vmovsd %xmm15,0x38(%rdx,%rcx,1)
-	vmulsd 0x18(%r15,%rax,1),%xmm2,%xmm2
-	vmulsd %xmm9,%xmm2,%xmm15
-	vmulsd %xmm8,%xmm2,%xmm2
-	vmovsd %xmm2,0x60(%rdx,%rcx,1)
-	vmovsd 0x20(%r14,%rax,1),%xmm2
-	vmovsd %xmm15,0x30(%rdx,%rcx,1)
-	vmulsd 0x20(%r15,%rax,1),%xmm2,%xmm2
-	vmulsd %xmm7,%xmm2,%xmm15
-	vmulsd %xmm6,%xmm2,%xmm2
-	vmovsd %xmm2,0x68(%rdx,%rcx,1)
-	vmovsd 0x28(%r14,%rax,1),%xmm2
-	vmovsd %xmm15,0x28(%rdx,%rcx,1)
-	vmulsd 0x28(%r15,%rax,1),%xmm2,%xmm2
-	vmulsd %xmm5,%xmm2,%xmm15
-	vmulsd %xmm4,%xmm2,%xmm2
-	vmovsd %xmm15,0x20(%rdx,%rcx,1)
-	vmovsd %xmm2,0x70(%rdx,%rcx,1)
-	cmp    $0x2,%esi
-	jbe    4f60 <cartesian_spherical_harmonics._omp_fn.0+0xcf0>
-	lea    0x30(%r14,%rax,1),%r11
-	lea    0x30(%r15,%rax,1),%r10
-	lea    (%rdx,%rcx,1),%r9
-	lea    0x78(%rdx,%rcx,1),%r8
-	mov    0x128(%rsp),%edi
-	xor    %eax,%eax
-	shr    $0x2,%edi
-	shl    $0x5,%rdi
-	nopl   (%rax)
-	vmovupd (%r10,%rax,1),%ymm2
-	mov    %rax,%rsi
-	vmulpd (%r11,%rax,1),%ymm2,%ymm2
-	neg    %rsi
-	vmulpd 0x30(%r12,%rax,1),%ymm2,%ymm15
-	vmulpd 0x30(%r13,%rax,1),%ymm2,%ymm2
-	vpermpd $0x1b,%ymm15,%ymm15
-	vmovupd %ymm15,(%r9,%rsi,1)
-	vmovupd %ymm2,(%r8,%rax,1)
-	add    $0x20,%rax
-	cmp    %rdi,%rax
-	jne    4dc0 <cartesian_spherical_harmonics._omp_fn.0+0xb50>
-	mov    0x128(%rsp),%edi
-	mov    %edi,%esi
-	and    $0xfffffffc,%esi
-	lea    0x6(%rsi),%eax
-	cmp    %edi,%esi
-	je     4ec3 <cartesian_spherical_harmonics._omp_fn.0+0xc53>
-	mov    0x10c(%rsp),%edi
-	sub    %esi,%edi
-	lea    -0x5(%rdi),%r9d
-	cmp    $0x6,%edi
-	je     4e85 <cartesian_spherical_harmonics._omp_fn.0+0xc15>
-	mov    0x120(%rsp),%rdi
-	mov    %esi,%r8d
-	lea    0x6(%rdi,%r8,1),%r10
-	lea    0x6(%rsi),%edi
-	inc    %esi
-	vmovupd (%r15,%r10,8),%xmm2
-	neg    %rsi
-	vmulpd (%r14,%r10,8),%xmm2,%xmm2
-	lea    (%rdx,%rcx,1),%r10
-	vmulpd (%r12,%rdi,8),%xmm2,%xmm15
-	vmulpd 0x0(%r13,%rdi,8),%xmm2,%xmm2
-	vpermilpd $0x1,%xmm15,%xmm15
-	vmovupd %xmm15,0x18(%r10,%rsi,8)
-	mov    0x130(%rsp),%rsi
-	lea    0x6(%rsi,%r8,1),%rsi
-	vmovupd %xmm2,(%rdx,%rsi,8)
-	mov    %r9d,%esi
-	and    $0xfffffffe,%esi
-	add    %esi,%eax
-	cmp    %r9d,%esi
-	je     4ec3 <cartesian_spherical_harmonics._omp_fn.0+0xc53>
-	mov    0x138(%rsp),%edi
-	lea    (%rdi,%rax,1),%esi
-	movslq %eax,%rdi
-	movslq %esi,%rsi
-	vmovsd (%r15,%rsi,8),%xmm2
-	vmulsd (%r14,%rsi,8),%xmm2,%xmm2
-	mov    %ebx,%esi
-	sub    %eax,%esi
-	add    %ebx,%eax
-	movslq %esi,%rsi
-	cltq
-	vmulsd (%r12,%rdi,8),%xmm2,%xmm15
-	vmulsd 0x0(%r13,%rdi,8),%xmm2,%xmm2
-	vmovsd %xmm15,(%rdx,%rsi,8)
-	vmovsd %xmm2,(%rdx,%rax,8)
-	add    $0x8,%rcx
-	mov    0x118(%rsp),%rax
-	mov    0x110(%rsp),%ebx
-	incq   0x130(%rsp)
-	add    %ebx,0x138(%rsp)
-	add    %rax,%rdx
-	add    $0x10,%rax
-	mov    %rax,0x118(%rsp)
-	cmp    0x100(%rsp),%rcx
-	jne    4c90 <cartesian_spherical_harmonics._omp_fn.0+0xa20>
-	cmpq   $0x0,0x30(%rsp)
-	jne    4f6c <cartesian_spherical_harmonics._omp_fn.0+0xcfc>
-	mov    0x1c(%rsp),%ebx
-	mov    0x88(%rsp),%rax
-	add    %ebx,0xa8(%rsp)
-	mov    0xa0(%rsp),%rbx
-	add    %rbx,0x98(%rsp)
-	mov    0x20(%rsp),%rbx
-	cmp    %rbx,%rax
-	je     613d <cartesian_spherical_harmonics._omp_fn.0+0x1ecd>
-	add    $0x18,%rax
-	vmovsd 0x0(%r13),%xmm10
-	vmovsd (%r12),%xmm4
-	mov    %rax,0x88(%rsp)
-	jmp    4570 <cartesian_spherical_harmonics._omp_fn.0+0x300>
-	nopl   0x0(%rax,%rax,1)
-	xor    %esi,%esi
-	mov    $0x6,%eax
-	jmp    4e12 <cartesian_spherical_harmonics._omp_fn.0+0xba2>
-	vmovapd 0x40cc(%rip),%ymm7        
-	mov    0x30(%rsp),%rbx
-	movslq 0xa8(%rsp),%rax
-	mov    0x80(%rsp),%rsi
-	mov    0xa0(%rsp),%rdi
-	lea    (%rbx,%rax,8),%rax
-	mov    0x42ac(%rip),%rbx        
-	lea    (%rax,%rdi,1),%rdx
-	lea    (%rax,%rsi,1),%rcx
-	movq   $0x0,(%rcx)
-	movq   $0x0,(%rdx)
-	vmovupd %ymm7,(%rax)
-	movq   $0x0,0x10(%rdx)
-	movq   $0x0,0x18(%rdx)
-	mov    %rbx,0x8(%rdx)
-	mov    %rbx,0x10(%rcx)
-	movq   $0x0,0x8(%rcx)
-	movq   $0x0,0x18(%rcx)
-	mov    0x98(%rsp),%rbx
-	vmovsd 0x4262(%rip),%xmm7        
-	vmulsd -0x118(%rbx),%xmm7,%xmm2
-	vmovsd 0x4272(%rip),%xmm7        
-	movq   $0x0,0x28(%rax)
-	vmovsd %xmm2,0x20(%rax)
-	vmulsd -0x108(%rbx),%xmm7,%xmm2
-	vmovsd 0x4235(%rip),%xmm7        
-	vmovsd %xmm2,0x30(%rax)
-	vmulsd -0x110(%rbx),%xmm7,%xmm4
-	vmulsd 0x4248(%rip),%xmm2,%xmm2        
-	vmovsd %xmm4,0x38(%rax)
-	vmulsd -0x108(%rbx),%xmm7,%xmm4
-	vmovsd %xmm4,0x40(%rax)
-	vmovsd %xmm2,0x20(%rdx)
-	vmovsd 0x38(%rax),%xmm2
-	vmovsd %xmm2,0x28(%rdx)
-	vmovsd 0x4227(%rip),%xmm7        
-	vmovsd 0x4287(%rip),%xmm4        
-	vmulsd 0x20(%rax),%xmm7,%xmm2
-	movq   $0x0,0x38(%rdx)
-	vmovsd 0x423a(%rip),%xmm7        
-	vmovsd 0x4272(%rip),%xmm5        
-	vmovsd 0x4272(%rip),%xmm6        
-	vmovsd 0xf0(%rsp),%xmm14
-	vmovsd 0xf8(%rsp),%xmm12
-	vmovsd %xmm2,0x30(%rdx)
-	vmovsd 0x20(%rax),%xmm2
-	vxorpd 0x44d6(%rip),%xmm2,%xmm2        
-	vmovsd %xmm2,0x40(%rdx)
-	movq   $0x0,0x40(%rcx)
-	movq   $0x0,0x20(%rcx)
-	vmovsd 0x20(%rax),%xmm2
-	vmovsd %xmm2,0x28(%rcx)
-	vmovsd 0x41b7(%rip),%xmm2        
-	vmulsd 0x38(%rax),%xmm2,%xmm2
-	vmovsd %xmm2,0x30(%rcx)
-	vmovsd 0x20(%rdx),%xmm2
-	vmovsd %xmm2,0x38(%rcx)
-	vmulsd -0x100(%rbx),%xmm4,%xmm2
-	vmovsd %xmm2,0x48(%rax)
-	vmulsd -0xf8(%rbx),%xmm7,%xmm2
-	vmovsd %xmm2,0x50(%rax)
-	vmulsd -0x100(%rbx),%xmm5,%xmm2
-	vmovsd %xmm2,0x58(%rax)
-	vmulsd -0xe8(%rbx),%xmm6,%xmm2
-	vmovsd %xmm2,0x60(%rax)
-	vmovsd -0xf0(%rbx),%xmm7
-	vsubsd %xmm14,%xmm12,%xmm2
-	vfmadd132sd 0x41d1(%rip),%xmm2,%xmm7        
-	vmulsd 0x41d1(%rip),%xmm7,%xmm7        
-	vmovsd %xmm7,0x68(%rax)
-	vmovsd 0x416c(%rip),%xmm7        
-	vmulsd -0xe8(%rbx),%xmm7,%xmm7
-	vmovsd %xmm7,0x70(%rax)
-	vmulsd -0xe0(%rbx),%xmm4,%xmm4
-	vmovsd 0x414f(%rip),%xmm7        
-	vmovsd %xmm4,0x78(%rax)
-	vmovsd %xmm4,0x48(%rdx)
-	vmovsd 0x70(%rax),%xmm4
-	vmovsd %xmm4,0x50(%rdx)
-	vmovsd -0xf0(%rbx),%xmm4
-	vfnmadd132sd 0x418a(%rip),%xmm2,%xmm4        
-	vmulsd 0x418a(%rip),%xmm4,%xmm4        
-	vmovsd %xmm4,0x58(%rdx)
-	vmulsd -0xf8(%rbx),%xmm6,%xmm6
-	vmovsd %xmm6,0x60(%rdx)
-	vmulsd -0x100(%rbx),%xmm5,%xmm5
-	vmovsd %xmm5,0x68(%rdx)
-	vmovsd 0x50(%rax),%xmm4
-	vxorpd 0x43c6(%rip),%xmm4,%xmm4        
-	vmovsd %xmm4,0x70(%rdx)
-	vmovsd 0x48(%rax),%xmm4
-	vxorpd 0x43b4(%rip),%xmm4,%xmm4        
-	vmovsd %xmm4,0x78(%rdx)
-	movq   $0x0,0x48(%rcx)
-	vmulsd -0x100(%rbx),%xmm7,%xmm4
-	vmovsd %xmm4,0x50(%rcx)
-	vmovsd 0x4132(%rip),%xmm4        
-	vmulsd -0xf8(%rbx),%xmm4,%xmm5
-	vmovsd %xmm5,0x58(%rcx)
-	vmovsd 0x4125(%rip),%xmm5        
-	vmulsd -0xf0(%rbx),%xmm5,%xmm5
-	vmovsd 0x41bd(%rip),%xmm6        
-	vmovsd 0x41bd(%rip),%xmm8        
-	vmovsd 0xd8(%rsp),%xmm10
-	vmovsd 0x4074(%rip),%xmm9        
-	vmovsd %xmm5,0x60(%rcx)
-	vmulsd -0xe8(%rbx),%xmm4,%xmm4
-	vmovsd 0x4117(%rip),%xmm5        
-	vmovsd %xmm4,0x68(%rcx)
-	vmulsd -0xe0(%rbx),%xmm7,%xmm4
-	movq   $0x0,0x78(%rcx)
-	vmovsd 0x4192(%rip),%xmm7        
-	vmovsd %xmm4,0x70(%rcx)
-	vmulsd -0xd8(%rbx),%xmm6,%xmm4
-	vmovsd %xmm4,0x80(%rax)
-	vmulsd -0xd0(%rbx),%xmm8,%xmm4
-	vmovsd %xmm4,0x88(%rax)
-	vfmadd132sd -0xf0(%rbx),%xmm12,%xmm5
-	vmulsd 0x414c(%rip),%xmm0,%xmm4        
-	vmulsd %xmm5,%xmm4,%xmm5
-	vmovsd %xmm5,0x90(%rax)
-	vmovsd 0x4140(%rip),%xmm5        
-	vmulsd -0xd0(%rbx),%xmm5,%xmm5
-	vmovsd %xmm5,0x98(%rax)
-	vmulsd -0xb8(%rbx),%xmm7,%xmm5
-	vmovsd %xmm5,0xa0(%rax)
-	vmulsd 0x4128(%rip),%xmm0,%xmm5        
-	vfnmadd132sd -0xf8(%rbx),%xmm10,%xmm5
-	vmovsd -0xc0(%rbx),%xmm10
-	vfnmadd231sd 0x4116(%rip),%xmm10,%xmm5        
-	vmovsd 0x4116(%rip),%xmm10        
-	vmulsd %xmm10,%xmm5,%xmm5
-	vmovsd %xmm5,0xa8(%rax)
-	vmulsd 0x4109(%rip),%xmm1,%xmm5        
-	vmovsd 0xe8(%rsp),%xmm15
-	vfnmadd132sd %xmm14,%xmm15,%xmm9
-	vmulsd %xmm9,%xmm5,%xmm9
-	vmovsd %xmm9,0xb0(%rax)
-	vmulsd -0xb0(%rbx),%xmm8,%xmm8
-	vmovsd %xmm8,0xb8(%rax)
-	vmulsd -0xa8(%rbx),%xmm6,%xmm6
-	vsubsd 0xe0(%rsp),%xmm12,%xmm8
-	vmovsd %xmm6,0xc0(%rax)
-	vmovsd %xmm6,0x80(%rdx)
-	vmovsd 0xb8(%rax),%xmm6
-	vmovsd %xmm6,0x88(%rdx)
-	vmovsd 0x40ad(%rip),%xmm6        
-	vfnmadd231sd -0xf0(%rbx),%xmm6,%xmm8
-	vmulsd %xmm8,%xmm5,%xmm5
-	vmovsd 0x409f(%rip),%xmm8        
-	vmovsd %xmm5,0x90(%rdx)
-	vmovsd 0xd0(%rsp),%xmm5
-	vmulsd -0xc0(%rbx),%xmm8,%xmm8
-	vsubsd %xmm14,%xmm5,%xmm5
-	vfmsub132sd %xmm3,%xmm8,%xmm5
-	vmulsd %xmm10,%xmm5,%xmm10
-	vmovsd %xmm10,0x98(%rdx)
-	vmulsd -0xc8(%rbx),%xmm7,%xmm7
-	vmovsd %xmm7,0xa0(%rdx)
-	vmovsd 0x98(%rax),%xmm5
-	vmovsd 0x3ecf(%rip),%xmm7        
-	vmovsd %xmm5,0xa8(%rdx)
-	vmovsd 0x3ebf(%rip),%xmm5        
-	vfnmadd132sd %xmm14,%xmm12,%xmm5
-	vmulsd %xmm5,%xmm4,%xmm4
-	vmovsd %xmm4,0xb0(%rdx)
-	vmovsd 0x88(%rax),%xmm4
-	vxorpd 0x417e(%rip),%xmm4,%xmm4        
-	vmovsd %xmm4,0xb8(%rdx)
-	vmovsd 0x80(%rax),%xmm4
-	vxorpd 0x4166(%rip),%xmm4,%xmm4        
-	vmovsd %xmm4,0xc0(%rdx)
-	movq   $0x0,0x80(%rcx)
-	vmulsd -0xd8(%rbx),%xmm7,%xmm4
-	vmovsd %xmm4,0x88(%rcx)
-	vmovsd 0x3fe3(%rip),%xmm4        
-	vmovsd 0x3ffb(%rip),%xmm8        
-	vmulsd -0xd0(%rbx),%xmm4,%xmm5
-	vmovsd 0x400b(%rip),%xmm9        
-	vmovsd %xmm5,0x90(%rcx)
-	vmovsd 0x3fc3(%rip),%xmm5        
-	vmulsd -0xc8(%rbx),%xmm5,%xmm7
-	vmovsd %xmm7,0x98(%rcx)
-	vmovsd 0x3fb3(%rip),%xmm7        
-	vmulsd -0xc0(%rbx),%xmm7,%xmm7
-	vmovsd %xmm7,0xa0(%rcx)
-	vmulsd -0xb8(%rbx),%xmm5,%xmm5
-	vmovsd 0x3dfb(%rip),%xmm7        
-	vmovsd %xmm5,0xa8(%rcx)
-	vmulsd -0xb0(%rbx),%xmm4,%xmm4
-	vmovsd 0x3f9b(%rip),%xmm5        
-	vmovsd %xmm4,0xb0(%rcx)
-	vmulsd -0xa8(%rbx),%xmm7,%xmm4
-	movq   $0x0,0xc0(%rcx)
-	vmovsd %xmm4,0xb8(%rcx)
-	vmovsd 0x3f58(%rip),%xmm4        
-	vmulsd -0xa0(%rbx),%xmm4,%xmm4
-	vmovsd %xmm4,0xc8(%rax)
-	vmulsd -0x98(%rbx),%xmm8,%xmm4
-	vmovsd %xmm4,0xd0(%rax)
-	vmulsd 0x3f40(%rip),%xmm1,%xmm4        
-	vmulsd -0xc8(%rbx),%xmm4,%xmm4
-	vfmadd231sd -0x100(%rbx),%xmm12,%xmm4
-	vmulsd %xmm5,%xmm4,%xmm4
-	vmovsd %xmm4,0xd8(%rax)
-	vmovsd -0xf8(%rbx),%xmm4
-	vmulsd %xmm14,%xmm4,%xmm7
-	vfmsub132sd %xmm12,%xmm7,%xmm4
-	vmovsd -0x98(%rbx),%xmm7
-	vfmadd231sd 0x3f10(%rip),%xmm7,%xmm4        
-	vmulsd %xmm9,%xmm4,%xmm4
-	vmovsd %xmm4,0xe0(%rax)
-	vmovsd 0x3f0b(%rip),%xmm4        
-	vmovsd 0x3f0b(%rip),%xmm7        
-	vmulsd -0x90(%rbx),%xmm4,%xmm4
-	vmovsd %xmm4,0xe8(%rax)
-	vmulsd -0x78(%rbx),%xmm7,%xmm4
-	vmovsd %xmm4,0xf0(%rax)
-	vmovsd -0xf8(%rbx),%xmm11
-	vmulsd 0x3ee6(%rip),%xmm14,%xmm4        
-	vmulsd 0x3ee6(%rip),%xmm11,%xmm10        
-	vmulsd %xmm11,%xmm10,%xmm10
-	vfmadd132sd %xmm14,%xmm10,%xmm4
-	vfmadd231sd -0xf0(%rbx),%xmm2,%xmm4
-	vmovsd -0x70(%rbx),%xmm10
-	vfmadd231sd 0x3ecd(%rip),%xmm10,%xmm4        
-	vmulsd 0x3ecd(%rip),%xmm4,%xmm4        
-	vmovsd %xmm4,0xf8(%rax)
-	vsubsd %xmm14,%xmm15,%xmm4
-	vmulsd %xmm9,%xmm4,%xmm9
-	vmulsd -0xe8(%rbx),%xmm9,%xmm9
-	vmulsd 0x3eb3(%rip),%xmm3,%xmm4        
-	vmovsd %xmm9,0x100(%rax)
-	vmulsd 0x3eab(%rip),%xmm0,%xmm9        
-	vmulsd -0xd8(%rbx),%xmm9,%xmm9
-	vfmsub132sd 0xb8(%rax),%xmm9,%xmm4
-	vsubsd -0x70(%rbx),%xmm4,%xmm4
-	vmulsd 0x3e95(%rip),%xmm4,%xmm4        
-	vmovsd %xmm4,0x108(%rax)
-	vmulsd -0x68(%rbx),%xmm8,%xmm8
-	vmovsd 0x3e88(%rip),%xmm4        
-	vmovsd %xmm8,0x110(%rax)
-	vmulsd -0x60(%rbx),%xmm4,%xmm4
-	vmovsd %xmm4,0x118(%rax)
-	vmovsd %xmm4,0xc8(%rdx)
-	vmovsd 0x110(%rax),%xmm4
-	vmovsd %xmm4,0xd0(%rdx)
-	vmulsd 0x3e5b(%rip),%xmm0,%xmm4        
-	vmulsd 0x3e5b(%rip),%xmm3,%xmm8        
-	vmulsd -0xb0(%rbx),%xmm8,%xmm8
-	vmulsd 0x3e73(%rip),%xmm3,%xmm3        
-	vfmsub132sd -0xd8(%rbx),%xmm8,%xmm4
-	vmulsd 0x3e72(%rip),%xmm2,%xmm2        
-	vsubsd -0x70(%rbx),%xmm4,%xmm4
-	vmulsd 0x3e35(%rip),%xmm4,%xmm4        
-	vmovsd %xmm4,0xd8(%rdx)
-	vmovsd %xmm12,%xmm12,%xmm4
-	vfnmadd231sd -0xf0(%rbx),%xmm6,%xmm4
-	vfnmadd231sd 0x3e4f(%rip),%xmm14,%xmm12        
-	vmulsd 0x3e17(%rip),%xmm4,%xmm4        
-	vmulsd -0xe8(%rbx),%xmm4,%xmm4
-	vmovsd %xmm4,0xe0(%rdx)
-	vmovsd 0x3e07(%rip),%xmm4        
-	vmovsd -0xd8(%rbx),%xmm9
-	vmulsd -0xc8(%rbx),%xmm4,%xmm4
-	vmulsd -0xc0(%rbx),%xmm3,%xmm3
-	vfmsub231sd 0x3dee(%rip),%xmm9,%xmm4        
-	vfmadd231sd %xmm4,%xmm0,%xmm3
-	vaddsd -0x60(%rbx),%xmm3,%xmm3
-	vmulsd 0x3dec(%rip),%xmm3,%xmm3        
-	vmovsd %xmm3,0xe8(%rdx)
-	vmulsd -0x88(%rbx),%xmm7,%xmm7
-	vmovsd %xmm7,0xf0(%rdx)
-	vmovsd 0xe8(%rax),%xmm3
-	vmovsd %xmm3,0xf8(%rdx)
-	vmulsd -0xf8(%rbx),%xmm2,%xmm2
-	vmovsd %xmm2,0x100(%rdx)
-	vfnmadd132sd -0xf0(%rbx),%xmm12,%xmm6
-	vmulsd -0x100(%rbx),%xmm5,%xmm5
-	vmulsd %xmm6,%xmm5,%xmm5
-	vmovsd %xmm5,0x108(%rdx)
-	vmovsd 0xd0(%rax),%xmm2
-	vxorpd 0x3e0f(%rip),%xmm2,%xmm2        
-	vmovsd %xmm2,0x110(%rdx)
-	vmovsd 0xc8(%rax),%xmm2
-	vmovsd 0x3bff(%rip),%xmm7        
-	vxorpd 0x3def(%rip),%xmm2,%xmm2        
-	cmpl   $0x6,0x108(%rsp)
-	vmovsd %xmm2,0x118(%rdx)
-	movq   $0x0,0xc8(%rcx)
-	vmulsd -0xa0(%rbx),%xmm7,%xmm2
-	vmovsd %xmm2,0xd0(%rcx)
-	vmovsd 0x3d4c(%rip),%xmm2        
-	vmulsd -0x98(%rbx),%xmm2,%xmm3
-	vmovsd %xmm3,0xd8(%rcx)
-	vmovsd 0x3d3c(%rip),%xmm3        
-	vmulsd -0x90(%rbx),%xmm3,%xmm4
-	vmovsd %xmm4,0xe0(%rcx)
-	vmovsd 0x3d2c(%rip),%xmm4        
-	vmulsd -0x88(%rbx),%xmm4,%xmm5
-	vmovsd %xmm5,0xe8(%rcx)
-	vmovsd 0x3d1c(%rip),%xmm5        
-	vmulsd -0x80(%rbx),%xmm5,%xmm5
-	vmovsd %xmm5,0xf0(%rcx)
-	vmulsd -0x78(%rbx),%xmm4,%xmm4
-	vmovsd %xmm4,0xf8(%rcx)
-	vmulsd -0x70(%rbx),%xmm3,%xmm3
-	vmovsd %xmm3,0x100(%rcx)
-	vmulsd -0x68(%rbx),%xmm2,%xmm2
-	vmovsd %xmm2,0x108(%rcx)
-	vmulsd -0x60(%rbx),%xmm7,%xmm2
-	movq   $0x0,0x118(%rcx)
-	lea    0x120(%rax),%rbx
-	vmovsd %xmm2,0x110(%rcx)
-	jbe    4f0a <cartesian_spherical_harmonics._omp_fn.0+0xc9a>
-	vmovsd (%r12),%xmm7
+	vmulsd %xmm12,%xmm0,%xmm0
+	vmovsd %xmm8,-0x20(%rcx)
+	vmovsd %xmm0,-0x10(%rcx)
+	vmulsd %xmm3,%xmm1,%xmm1
+	vmovsd %xmm1,-0x8(%rcx)
+	cmp    %rax,%rcx
+	jne    3340 <cartesian_spherical_harmonics_l3._omp_fn.0+0x1200>
+	jmp    2646 <cartesian_spherical_harmonics_l3._omp_fn.0+0x506>
 	xor    %ecx,%ecx
-	mov    %r15,0x130(%rsp)
-	mov    %rsi,0xb8(%rsp)
-	mov    %rdi,0xc0(%rsp)
-	mov    %rsi,0x118(%rsp)
-	mov    %rdi,0x120(%rsp)
-	mov    %rcx,%r15
-	movq   $0xffffffffffffffd0,0x90(%rsp)
-	movl   $0x5,0xf0(%rsp)
-	movq   $0x30,0xd8(%rsp)
-	movq   $0x6,0x110(%rsp)
-	movl   $0x15,0x138(%rsp)
-	mov    (%rsp),%rax
-	vmovsd 0x8(%r12),%xmm9
-	vmovsd 0x8(%r13),%xmm8
-	vmovsd 0x18(%r12),%xmm11
-	vmovsd 0x18(%r13),%xmm10
-	vmovsd %xmm7,0x78(%rsp)
-	vmovsd 0x0(%r13),%xmm7
-	mov    %rax,0xc8(%rsp)
-	mov    0x8(%rsp),%rax
-	mov    %rax,0xd0(%rsp)
-	mov    $0x6,%eax
-	vcvtsi2sd %eax,%xmm13,%xmm2
-	mov    %eax,0x10c(%rsp)
-	vmovsd %xmm2,0xf8(%rsp)
-	vmovsd %xmm7,0x70(%rsp)
-	vmovsd 0x10(%r12),%xmm7
-	vmovsd %xmm7,0x68(%rsp)
-	vmovsd 0x10(%r13),%xmm7
-	vmovsd %xmm7,0x60(%rsp)
-	nopl   0x0(%rax)
-	movslq 0x138(%rsp),%r10
-	mov    0x10c(%rsp),%r8d
-	mov    0x130(%rsp),%rdx
-	mov    0xd8(%rsp),%rcx
-	vmovsd 0xf8(%rsp),%xmm12
-	lea    0x0(,%r10,8),%r11
-	mov    %r10d,%edi
-	lea    (%rdx,%r11,1),%rsi
-	sub    %r8d,%edi
-	lea    0x8(%rdx,%r11,1),%r9
-	mov    %r8d,%edx
-	vmulsd (%rsi),%xmm1,%xmm3
-	lea    0x1(%rdi),%eax
-	movslq %edi,%rdi
-	cltq
-	vmovsd (%r14,%rax,8),%xmm4
-	lea    (%rbx,%rcx,1),%rax
-	mov    0xd0(%rsp),%rcx
-	add    %rbx,%rcx
-	mov    %rcx,0xe8(%rsp)
-	vmulsd %xmm4,%xmm3,%xmm3
-	vmovsd %xmm3,(%rax)
-	vmulsd (%rsi),%xmm0,%xmm2
-	vmulsd %xmm4,%xmm2,%xmm2
-	vmovsd %xmm2,(%rcx)
-	vmulsd (%rsi),%xmm12,%xmm2
-	mov    0xc8(%rsp),%rcx
-	vmulsd (%r14,%rdi,8),%xmm2,%xmm2
-	mov    0x138(%rsp),%edi
-	add    %rbx,%rcx
-	inc    %edi
-	sub    %r8d,%edi
-	lea    0x1(%rdi),%r8d
-	movslq %edi,%rdi
-	movslq %r8d,%r8
-	vmovsd %xmm2,(%rcx)
-	vmovsd (%r9),%xmm2
-	vmulsd 0x8(%r14,%r11,1),%xmm2,%xmm3
-	vmulsd (%r14,%r8,8),%xmm2,%xmm2
-	mov    %edx,%r8d
-	inc    %edx
-	mov    %edx,0x10c(%rsp)
-	mov    0x120(%rsp),%rdx
-	vmulsd 0x78(%rsp),%xmm3,%xmm5
-	vmulsd 0x70(%rsp),%xmm3,%xmm3
-	vmulsd %xmm2,%xmm1,%xmm4
-	vmulsd %xmm2,%xmm0,%xmm2
-	vmovsd %xmm4,%xmm4,%xmm6
-	vfmadd132sd %xmm8,%xmm3,%xmm4
-	vfmadd132sd %xmm9,%xmm5,%xmm6
-	vfmadd231sd %xmm2,%xmm9,%xmm3
-	vfmsub132sd %xmm8,%xmm5,%xmm2
-	vmovsd %xmm4,0x38(%rbx,%r15,1)
-	vmovsd %xmm6,0x28(%rbx,%r15,1)
-	vmovsd %xmm3,0x28(%rbx,%rdx,1)
-	vmovsd %xmm2,0x38(%rbx,%rdx,1)
-	vcvtsi2sdl 0x10c(%rsp),%xmm13,%xmm2
-	vmovsd %xmm2,0xf8(%rsp)
-	vmulsd (%r9),%xmm2,%xmm2
-	vmulsd (%r14,%rdi,8),%xmm2,%xmm2
-	mov    0x118(%rsp),%r9
-	mov    %r8d,0x128(%rsp)
-	mov    0x130(%rsp),%rdx
-	mov    0x138(%rsp),%edi
-	vmovsd 0x68(%rsp),%xmm7
-	vmovsd 0x60(%rsp),%xmm14
-	add    $0x2,%edi
-	sub    %r8d,%edi
-	lea    0x1(%rdi),%r8d
-	movslq %edi,%rdi
-	movslq %r8d,%r8
-	vmulsd %xmm2,%xmm9,%xmm3
-	vmulsd %xmm2,%xmm8,%xmm2
-	vmovsd %xmm7,%xmm7,%xmm6
-	vmovsd %xmm3,0x28(%rbx,%r9,1)
-	vmovsd %xmm2,0x38(%rbx,%r9,1)
-	lea    0x10(%rdx,%r11,1),%r9
-	mov    0x130(%rsp),%rdx
-	vmovsd (%r9),%xmm2
-	vmulsd 0x10(%r14,%r11,1),%xmm2,%xmm3
-	vmulsd (%r14,%r8,8),%xmm2,%xmm2
-	mov    0x120(%rsp),%r8
-	vaddsd %xmm3,%xmm3,%xmm3
-	vmulsd %xmm2,%xmm1,%xmm4
-	vmulsd %xmm2,%xmm0,%xmm2
-	vmulsd %xmm3,%xmm9,%xmm5
-	vmulsd %xmm3,%xmm8,%xmm3
-	vfmadd132sd %xmm4,%xmm5,%xmm6
-	vfmadd132sd %xmm14,%xmm3,%xmm4
-	vfmadd231sd %xmm7,%xmm2,%xmm3
-	vfmsub132sd %xmm14,%xmm5,%xmm2
-	vmovsd %xmm6,0x20(%rbx,%r15,1)
-	vmovsd %xmm4,0x40(%rbx,%r15,1)
-	vmovsd %xmm3,0x20(%rbx,%r8,1)
-	vmovsd %xmm2,0x40(%rbx,%r8,1)
-	mov    0x128(%rsp),%r8d
-	add    $0x2,%r8d
-	vcvtsi2sd %r8d,%xmm13,%xmm2
-	vmulsd (%r9),%xmm2,%xmm2
-	mov    0x118(%rsp),%r9
-	vmulsd (%r14,%rdi,8),%xmm2,%xmm2
-	mov    0x138(%rsp),%edi
-	add    $0x3,%edi
-	sub    0x128(%rsp),%edi
-	lea    0x1(%rdi),%r8d
-	movslq %edi,%rdi
-	vmulsd %xmm7,%xmm2,%xmm3
-	vmulsd %xmm14,%xmm2,%xmm2
-	movslq %r8d,%r8
-	vmovsd %xmm3,0x20(%rbx,%r9,1)
-	vmovsd %xmm2,0x40(%rbx,%r9,1)
-	lea    0x18(%rdx,%r11,1),%r9
-	vmovsd (%r9),%xmm2
-	vmulsd 0x18(%r14,%r11,1),%xmm2,%xmm3
-	vmulsd (%r14,%r8,8),%xmm2,%xmm2
-	mov    0x120(%rsp),%r8
-	vmulsd 0x36db(%rip),%xmm3,%xmm3        
-	vmulsd %xmm2,%xmm1,%xmm4
-	vmulsd %xmm2,%xmm0,%xmm2
-	vmulsd %xmm7,%xmm3,%xmm5
-	vmulsd %xmm14,%xmm3,%xmm3
-	vmovsd %xmm4,%xmm4,%xmm6
-	vfmadd132sd %xmm11,%xmm5,%xmm6
-	vfmadd132sd %xmm10,%xmm3,%xmm4
-	vfmadd231sd %xmm2,%xmm11,%xmm3
-	vfmsub132sd %xmm10,%xmm5,%xmm2
-	vmovsd %xmm6,0x18(%rbx,%r15,1)
-	vmovsd %xmm4,0x48(%rbx,%r15,1)
-	vmovsd %xmm3,0x18(%rbx,%r8,1)
-	vmovsd %xmm2,0x48(%rbx,%r8,1)
-	mov    0x128(%rsp),%r8d
-	add    $0x3,%r8d
-	cmpq   $0x7,0x110(%rsp)
-	vcvtsi2sd %r8d,%xmm13,%xmm2
-	vmulsd (%r9),%xmm2,%xmm2
-	mov    0x118(%rsp),%r9
-	vmulsd (%r14,%rdi,8),%xmm2,%xmm2
-	vmulsd %xmm2,%xmm11,%xmm3
-	vmulsd %xmm2,%xmm10,%xmm2
-	vmovsd %xmm3,0x18(%rbx,%r9,1)
-	vmovsd %xmm2,0x48(%rbx,%r9,1)
-	jbe    6129 <cartesian_spherical_harmonics._omp_fn.0+0x1eb9>
-	mov    %r10,%rdi
-	lea    (%r14,%r11,1),%r8
-	mov    %r11,0x40(%rsp)
-	mov    %rsi,0x38(%rsp)
-	vmovsd %xmm11,%xmm11,%xmm5
-	vmovsd %xmm10,%xmm10,%xmm2
-	mov    %r14,0x48(%rsp)
-	xor    %esi,%esi
-	mov    0x130(%rsp),%rdx
-	mov    0x128(%rsp),%r10d
-	lea    0x20(%rdx,%r11,1),%r9
-	mov    0x110(%rsp),%rdx
-	sub    %rdx,%rdi
-	inc    %edx
-	lea    0x20(%r14,%rdi,8),%rdi
-	mov    %edx,0xac(%rsp)
-	mov    0xe8(%rsp),%rdx
-	mov    %rdi,0xb0(%rsp)
-	lea    -0x8(%r10),%edi
-	mov    0xb0(%rsp),%r11
-	and    $0xfffffffe,%edi
-	lea    0x6(%rdi),%r10d
-	xor    %edi,%edi
-	mov    %r10d,0xe0(%rsp)
-	mov    $0x4,%r10d
-	vmovsd (%r9),%xmm3
-	vcvtsi2sd %r10d,%xmm13,%xmm6
-	add    $0x10,%r9
-	add    $0x10,%r11
-	vmulsd 0x20(%r8,%rdi,1),%xmm3,%xmm4
-	vmovsd 0x20(%r12,%rdi,1),%xmm7
-	mov    0x110(%rsp),%r14d
-	add    %r10d,%r14d
-	vmulsd %xmm6,%xmm4,%xmm4
-	vmovsd -0x8(%r11),%xmm6
-	vmulsd %xmm5,%xmm4,%xmm5
-	vmulsd %xmm2,%xmm4,%xmm2
-	vmulsd %xmm6,%xmm3,%xmm3
-	vmulsd %xmm3,%xmm1,%xmm15
-	vmulsd %xmm3,%xmm0,%xmm3
-	vmovsd %xmm15,%xmm15,%xmm14
-	vfmadd132sd %xmm7,%xmm5,%xmm14
-	vmovsd %xmm14,-0x20(%rax,%rsi,1)
-	vmovsd 0x20(%r13,%rdi,1),%xmm14
-	vfmadd132sd %xmm14,%xmm2,%xmm15
-	vfmsub231sd %xmm3,%xmm14,%xmm5
-	vfmadd231sd %xmm3,%xmm7,%xmm2
-	vmovsd %xmm15,0x20(%rax,%rdi,1)
-	vmovsd %xmm2,-0x20(%rdx,%rsi,1)
-	vmovsd %xmm5,0x20(%rdx,%rdi,1)
-	vcvtsi2sd %r14d,%xmm13,%xmm2
-	vmulsd -0x10(%r9),%xmm2,%xmm2
-	lea    0x1(%r10),%r14d
-	vmovsd 0x28(%r12,%rdi,1),%xmm5
-	vmulsd -0x10(%r11),%xmm2,%xmm2
-	vmulsd %xmm2,%xmm7,%xmm3
-	vmulsd %xmm2,%xmm14,%xmm2
-	vmovsd %xmm3,-0x20(%rcx,%rsi,1)
-	vmovsd %xmm2,0x20(%rcx,%rdi,1)
-	vmovsd -0x8(%r9),%xmm4
-	vcvtsi2sd %r14d,%xmm13,%xmm3
-	vmulsd 0x28(%r8,%rdi,1),%xmm4,%xmm2
-	vmulsd (%r11),%xmm4,%xmm4
-	mov    0xac(%rsp),%r14d
-	add    %r10d,%r14d
-	add    $0x2,%r10d
-	vmulsd %xmm2,%xmm3,%xmm3
-	vmulsd %xmm4,%xmm1,%xmm15
-	vmovsd %xmm5,%xmm5,%xmm2
-	vmulsd %xmm3,%xmm7,%xmm7
-	vmulsd %xmm4,%xmm0,%xmm4
-	vfmadd132sd %xmm15,%xmm7,%xmm2
-	vmulsd %xmm3,%xmm14,%xmm3
-	vmovsd %xmm2,-0x28(%rax,%rsi,1)
-	vmovsd 0x28(%r13,%rdi,1),%xmm2
-	vfmadd132sd %xmm2,%xmm3,%xmm15
-	vfmsub231sd %xmm2,%xmm4,%xmm7
-	vfmadd231sd %xmm5,%xmm4,%xmm3
-	vmovsd %xmm15,0x28(%rax,%rdi,1)
-	vmovsd %xmm3,-0x28(%rdx,%rsi,1)
-	vmovsd %xmm7,0x28(%rdx,%rdi,1)
-	vcvtsi2sd %r14d,%xmm13,%xmm3
-	vmulsd -0x8(%r9),%xmm3,%xmm3
-	vmulsd %xmm6,%xmm3,%xmm3
-	vmulsd %xmm5,%xmm3,%xmm4
-	vmulsd %xmm2,%xmm3,%xmm3
-	vmovsd %xmm4,-0x28(%rcx,%rsi,1)
-	vmovsd %xmm3,0x28(%rcx,%rdi,1)
-	sub    $0x10,%rsi
-	add    $0x10,%rdi
-	cmp    0xe0(%rsp),%r10d
-	jne    5cd4 <cartesian_spherical_harmonics._omp_fn.0+0x1a64>
-	mov    0x48(%rsp),%r14
-	mov    0x40(%rsp),%r11
-	mov    %rdx,0xe8(%rsp)
-	mov    0x38(%rsp),%rsi
-	mov    0x90(%rsp),%rdx
-	movslq 0xe0(%rsp),%rdi
-	mov    %r14,0xe0(%rsp)
-	lea    (%r11,%rdx,1),%r10
-	mov    0xe8(%rsp),%rdx
-	mov    %rbx,0xe8(%rsp)
-	mov    0x110(%rsp),%rbx
-	add    %r14,%r10
-	mov    0xf0(%rsp),%r14d
-	data16 cs nopw 0x0(%rax,%rax,1)
-	vmovsd (%rsi,%rdi,8),%xmm2
-	vcvtsi2sd %edi,%xmm13,%xmm4
-	mov    %rdi,%r9
-	lea    (%rdi,%rbx,1),%r11d
-	vmulsd (%r8,%rdi,8),%xmm2,%xmm3
-	vmulsd 0x8(%r10,%rdi,8),%xmm2,%xmm2
-	neg    %r9
-	shl    $0x3,%r9
-	vmulsd %xmm4,%xmm3,%xmm3
-	vmulsd -0x8(%r12,%rdi,8),%xmm3,%xmm7
-	vmovsd (%r12,%rdi,8),%xmm4
-	vmulsd -0x8(%r13,%rdi,8),%xmm3,%xmm3
-	vmulsd %xmm2,%xmm1,%xmm6
-	vmulsd %xmm2,%xmm0,%xmm2
-	vmovsd %xmm4,%xmm4,%xmm5
-	vfmadd132sd %xmm6,%xmm7,%xmm5
-	vmovsd %xmm5,(%rax,%r9,1)
-	vmovsd 0x0(%r13,%rdi,8),%xmm5
-	vfmadd132sd %xmm5,%xmm3,%xmm6
-	vfmadd231sd %xmm4,%xmm2,%xmm3
-	vfmsub132sd %xmm5,%xmm7,%xmm2
-	vmovsd %xmm6,(%rax,%rdi,8)
-	vmovsd %xmm3,(%rdx,%r9,1)
-	vmovsd %xmm2,(%rdx,%rdi,8)
-	vcvtsi2sd %r11d,%xmm13,%xmm2
-	vmulsd (%rsi,%rdi,8),%xmm2,%xmm2
-	vmulsd (%r10,%rdi,8),%xmm2,%xmm2
-	vmulsd %xmm4,%xmm2,%xmm4
-	vmulsd %xmm5,%xmm2,%xmm2
-	vmovsd %xmm4,(%rcx,%r9,1)
-	vmovsd %xmm2,(%rcx,%rdi,8)
-	inc    %rdi
-	cmp    %edi,%r14d
-	jg     5e90 <cartesian_spherical_harmonics._omp_fn.0+0x1c20>
-	mov    0x128(%rsp),%r8d
-	mov    0x138(%rsp),%eax
-	mov    0xe0(%rsp),%r14
-	mov    0x130(%rsp),%rcx
-	mov    0xf0(%rsp),%r9d
-	mov    0xe8(%rsp),%rbx
-	mov    0x110(%rsp),%r11
-	mov    0x58(%rsp),%rdi
-	add    %r8d,%eax
-	mov    0xc0(%rsp),%r10
-	movslq %eax,%rdx
-	dec    %eax
-	shl    $0x3,%rdx
-	vcvtsi2sd %r9d,%xmm13,%xmm3
-	sub    %r8d,%eax
-	mov    0x50(%rsp),%r8
-	lea    -0x8(%rcx,%rdx,1),%rsi
-	vmovsd -0x8(%r14,%rdx,1),%xmm2
-	mov    %r11,%rcx
-	cltq
-	vmulsd (%rsi),%xmm2,%xmm2
-	shl    $0x4,%rcx
-	inc    %r11
-	inc    %r9d
-	vmulsd %xmm3,%xmm2,%xmm2
-	vmovsd 0x20(%r12,%r15,1),%xmm3
-	vmulsd %xmm3,%xmm2,%xmm4
-	vmovsd %xmm4,0x8(%rbx)
-	vmulsd 0x20(%r13,%r15,1),%xmm2,%xmm4
-	vxorpd 0x35a9(%rip),%xmm2,%xmm2        
-	vmulsd %xmm3,%xmm2,%xmm2
-	vmovsd %xmm4,-0x8(%rbx,%rcx,1)
-	vmovsd %xmm4,(%rbx,%rdi,1)
-	mov    0x10c(%rsp),%edi
-	vmovsd %xmm2,0x58(%rbx,%r10,1)
-	lea    -0x3(%rdi,%rdi,1),%edi
-	vcvtsi2sd %edi,%xmm13,%xmm2
-	vmulsd (%rsi),%xmm2,%xmm2
-	mov    0xb8(%rsp),%rdi
-	vmulsd (%r14,%rax,8),%xmm2,%xmm4
-	vmovsd 0x28(%r12,%r15,1),%xmm2
-	mov    0x130(%rsp),%rax
-	vmulsd %xmm2,%xmm4,%xmm3
-	vmovsd %xmm3,(%rbx,%r8,1)
-	vmovsd 0x28(%r13,%r15,1),%xmm3
-	add    $0x8,%r15
-	vmulsd %xmm3,%xmm4,%xmm4
-	vmovsd %xmm4,0x58(%rbx,%rdi,1)
-	vmovsd (%rax,%rdx,1),%xmm4
-	vmulsd (%r14,%rdx,1),%xmm4,%xmm4
-	vmulsd %xmm12,%xmm4,%xmm12
-	vmulsd %xmm12,%xmm3,%xmm3
-	vmulsd %xmm12,%xmm2,%xmm4
-	vmovsd %xmm4,(%rbx)
-	vmovsd %xmm3,(%rbx,%rcx,1)
-	mov    0xa0(%rsp),%rax
-	vxorpd 0x3511(%rip),%xmm12,%xmm12        
-	mov    %r11,0x110(%rsp)
-	mov    %r9d,0xf0(%rsp)
-	mov    0x80(%rsp),%rdx
-	addq   $0x8,0xd8(%rsp)
-	vmovsd %xmm3,(%rbx,%rax,1)
-	mov    %r10,%rax
-	addq   $0x8,0xd0(%rsp)
-	addq   $0x8,0x120(%rsp)
-	add    $0x10,%rax
-	mov    %rax,0xc0(%rsp)
-	addq   $0x8,0xc8(%rsp)
-	vmulsd %xmm2,%xmm12,%xmm12
-	addq   $0x8,0x118(%rsp)
-	subq   $0x8,0x90(%rsp)
-	vmovsd %xmm12,0x60(%rbx,%r10,1)
-	movq   $0x0,(%rbx,%rdx,1)
-	mov    %rdi,%rdx
-	movq   $0x0,0x60(%rbx,%rdi,1)
-	add    $0x10,%rdx
-	lea    0x8(%rbx,%rcx,1),%rbx
-	mov    0x10c(%rsp),%edi
-	mov    %rdx,0xb8(%rsp)
-	add    %edi,0x138(%rsp)
-	cmp    0x108(%rsp),%edi
-	jne    5950 <cartesian_spherical_harmonics._omp_fn.0+0x16e0>
-	mov    0x130(%rsp),%r15
-	jmp    4f0a <cartesian_spherical_harmonics._omp_fn.0+0xc9a>
-	movl   $0x4,0xe0(%rsp)
-	lea    (%r14,%r11,1),%r8
-	jmp    5e46 <cartesian_spherical_harmonics._omp_fn.0+0x1bd6>
-	mov    %r14,%r15
-	mov    %r12,%rbx
+	jmp    2db8 <cartesian_spherical_harmonics_l3._omp_fn.0+0xc78>
+	mov    0x9dcf(%rip),%rdi        
 	vzeroupper
-	call   1070 <GOMP_barrier@plt>
-	mov    %r15,%rdi
-	call   1030 <free@plt>
-	mov    %r13,%rdi
-	call   1030 <free@plt>
-	lea    -0x28(%rbp),%rsp
-	mov    %rbx,%rdi
-	pop    %rbx
-	pop    %r12
-	pop    %r13
-	pop    %r14
-	pop    %r15
-	pop    %rbp
-	jmp    1030 <free@plt>
-	jne    4836 <cartesian_spherical_harmonics._omp_fn.0+0x5c6>
-	jmp    46f4 <cartesian_spherical_harmonics._omp_fn.0+0x484>
-	nopl   0x0(%rax)
-	mov    $0x6,%eax
-	jmp    46b3 <cartesian_spherical_harmonics._omp_fn.0+0x443>
-	inc    %eax
-	xor    %edx,%edx
-	jmp    4454 <cartesian_spherical_harmonics._omp_fn.0+0x1e4>
-	vmovsd 0x30f5(%rip),%xmm10        
-	cmpl   $0x1,0x108(%rsp)
-	vmovsd %xmm10,(%r15)
-	jbe    4406 <cartesian_spherical_harmonics._omp_fn.0+0x196>
-	cmpl   $0x2,0x108(%rsp)
-	mov    0x30db(%rip),%rax        
-	mov    %rax,0x10(%r15)
-	je     4406 <cartesian_spherical_harmonics._omp_fn.0+0x196>
-	jmp    43c7 <cartesian_spherical_harmonics._omp_fn.0+0x157>
+	jmp    30ee <cartesian_spherical_harmonics_l3._omp_fn.0+0xfae>
 	nopl   0x0(%rax)
 
-00000000000061d0 <cartesian_spherical_harmonics_l4._omp_fn.0>:
+0000000000003480 <cartesian_spherical_harmonics_l4._omp_fn.0>:
 cartesian_spherical_harmonics_l4._omp_fn.0():
 	push   %rbp
 	mov    %rsp,%rbp
 	push   %r15
 	push   %r14
 	mov    %rdi,%r15
 	push   %r13
@@ -3966,1735 +1842,6250 @@
 	mov    %eax,%r13d
 	call   1080 <omp_get_thread_num@plt>
 	mov    %eax,%ecx
 	mov    0x18(%r15),%eax
 	cltd
 	idiv   %r13d
 	test   %r14,%r14
-	je     6b30 <cartesian_spherical_harmonics_l4._omp_fn.0+0x960>
+	je     3db0 <cartesian_spherical_harmonics_l4._omp_fn.0+0x930>
 	cmp    %edx,%ecx
-	jl     6f10 <cartesian_spherical_harmonics_l4._omp_fn.0+0xd40>
+	jl     4180 <cartesian_spherical_harmonics_l4._omp_fn.0+0xd00>
 	imul   %eax,%ecx
 	add    %ecx,%edx
 	lea    (%rax,%rdx,1),%ecx
 	cmp    %ecx,%edx
-	jge    6b11 <cartesian_spherical_harmonics_l4._omp_fn.0+0x941>
-	vmovsd 0x3076(%rip),%xmm6        
-	vmovsd 0x301e(%rip),%xmm7        
-	movslq %edx,%rdi
+	jge    3d8f <cartesian_spherical_harmonics_l4._omp_fn.0+0x90f>
+	vmovsd 0x9d76(%rip),%xmm1        
+	vmovsd 0x9dbe(%rip),%xmm6        
+	lea    (%rdx,%rdx,2),%ecx
+	movslq %edx,%rsi
+	vmovsd 0x9e40(%rip),%xmm3        
+	vmovsd 0x9d48(%rip),%xmm11        
+	movslq %ecx,%rcx
 	dec    %eax
+	vmovsd 0x9d43(%rip),%xmm12        
+	vmovsd 0x9d7b(%rip),%xmm9        
+	lea    (%rbx,%rcx,8),%r10
 	lea    (%rdx,%rdx,4),%ecx
-	lea    (%rdx,%rdx,2),%esi
-	vmovsd 0x2ffb(%rip),%xmm11        
-	vmovsd 0x2ffb(%rip),%xmm12        
-	imul   $0x258,%rdi,%rdx
-	add    %rax,%rdi
+	vmovsd 0x9d7c(%rip),%xmm13        
+	mov    0x9d15(%rip),%r15        
+	imul   $0x258,%rsi,%rdx
+	add    %rax,%rsi
+	imul   $0xc8,%rsi,%rsi
 	lea    (%rcx,%rcx,4),%ecx
-	vmovsd 0x3046(%rip),%xmm13        
-	imul   $0xc8,%rdi,%rdi
 	movslq %ecx,%rcx
-	movslq %esi,%rsi
 	lea    (%r12,%rcx,8),%rcx
-	lea    (%rbx,%rsi,8),%rsi
 	add    %r14,%rdx
-	lea    0xc8(%r12,%rdi,1),%r10
-	mov    0x2faf(%rip),%r12        
+	lea    0xc8(%r12,%rsi,1),%r12
+	vmovsd %xmm1,0xa0(%rsp)
+	vmovsd 0x9cfe(%rip),%xmm1        
 	vmovsd %xmm6,0x88(%rsp)
-	vmovsd 0x3016(%rip),%xmm6        
-	vmovsd %xmm7,0xa8(%rsp)
-	vmovsd 0x2fad(%rip),%xmm7        
-	vmovsd %xmm6,0x80(%rsp)
-	vmovsd 0x2ffc(%rip),%xmm6        
-	vmovsd %xmm7,0x60(%rsp)
-	vmovsd 0x2f96(%rip),%xmm7        
+	vmovsd 0x9d45(%rip),%xmm6        
+	vmovsd %xmm1,0x58(%rsp)
+	vmovsd 0x9ce7(%rip),%xmm1        
 	vmovsd %xmm6,0x78(%rsp)
-	vmovsd 0x2fe8(%rip),%xmm6        
-	vmovsd %xmm7,0x58(%rsp)
-	vmovsd 0x2fb2(%rip),%xmm7        
-	vmovsd %xmm6,0x70(%rsp)
-	vmovsd 0x2fd4(%rip),%xmm6        
+	vmovsd 0x9d39(%rip),%xmm6        
+	vmovsd %xmm1,0x50(%rsp)
+	vmovsd 0x9cfb(%rip),%xmm1        
 	vmovsd %xmm6,0x68(%rsp)
-	vmovsd 0x2fce(%rip),%xmm6        
-	vmovsd %xmm6,0x98(%rsp)
-	vmovsd 0x2fc5(%rip),%xmm6        
-	vmovsd %xmm6,0x90(%rsp)
-	vmovsd 0x3004(%rip),%xmm6        
-	vmovsd %xmm6,0x28(%rsp)
-	vmovsd 0x2ffe(%rip),%xmm6        
-	vmovsd %xmm6,0x20(%rsp)
-	vmovsd 0x2ff8(%rip),%xmm6        
-	vmovsd %xmm6,0x18(%rsp)
-	vmovsd 0x2ff2(%rip),%xmm6        
-	vmovsd %xmm6,0x50(%rsp)
-	vmovsd 0x2fec(%rip),%xmm6        
-	vmovq  0x3214(%rip),%xmm14        
-	vmovsd %xmm6,0x48(%rsp)
-	vmovsd 0x2fde(%rip),%xmm6        
-	vmovsd %xmm6,0x40(%rsp)
-	vmovsd 0x2fd8(%rip),%xmm6        
+	vmovsd 0x9d75(%rip),%xmm6        
+	vmovsd %xmm1,0x90(%rsp)
+	vmovsd 0x9cf4(%rip),%xmm1        
 	vmovsd %xmm6,0x38(%rsp)
-	vmovsd 0x2fd2(%rip),%xmm6        
-	vmovsd %xmm6,0x30(%rsp)
-	nopl   0x0(%rax)
-	mov    %r12,(%rcx)
-	vmovsd 0x10(%rsi),%xmm2
+	vmovsd 0x9d66(%rip),%xmm6        
+	vmovsd %xmm1,0x80(%rsp)
+	vmovsd 0x9ce5(%rip),%xmm1        
+	vmovsd %xmm6,0x28(%rsp)
+	vmovsd %xmm1,0x70(%rsp)
+	vmovsd 0x9ce1(%rip),%xmm1        
+	vmovsd %xmm1,0x60(%rsp)
+	vmovsd 0x9d2b(%rip),%xmm1        
+	vmovsd %xmm1,0x30(%rsp)
+	vmovsd %xmm3,0x20(%rsp)
+	vmovsd 0x9d2f(%rip),%xmm1        
+	vmovsd 0x9d2f(%rip),%xmm6        
+	vmovsd %xmm11,0xa8(%rsp)
+	vmovsd 0x9d26(%rip),%xmm3        
+	vmovsd %xmm1,0x18(%rsp)
+	vmovsd 0x9d20(%rip),%xmm1        
+	vmovsd %xmm6,0x98(%rsp)
+	vmovsd %xmm3,0x48(%rsp)
+	vmovsd %xmm1,0x40(%rsp)
+	nopl   (%rax)
+	vmovsd 0x10(%r10),%xmm1
 	add    $0xc8,%rcx
-	add    $0x18,%rsi
-	vmovsd -0x18(%rsi),%xmm0
+	add    $0x18,%r10
 	add    $0x258,%rdx
-	vmulsd -0x10(%rsi),%xmm11,%xmm5
-	vmulsd %xmm11,%xmm2,%xmm2
-	vmulsd %xmm11,%xmm0,%xmm0
-	vmovsd %xmm2,-0xb8(%rcx)
-	vmovsd %xmm5,-0xc0(%rcx)
-	vmovsd %xmm0,-0xb0(%rcx)
-	vmovsd -0x18(%rsi),%xmm4
-	vmovsd -0x8(%rsi),%xmm3
-	vmovsd -0x10(%rsi),%xmm1
-	vmulsd %xmm4,%xmm4,%xmm6
-	vmulsd %xmm12,%xmm4,%xmm4
-	vmulsd %xmm3,%xmm3,%xmm0
+	vmovsd -0x18(%r10),%xmm2
+	vmovsd -0x10(%r10),%xmm0
+	mov    %r15,-0xc8(%rcx)
+	vmovsd 0xa8(%rsp),%xmm5
+	vmulsd %xmm1,%xmm1,%xmm3
+	vmulsd %xmm2,%xmm2,%xmm7
+	vmulsd %xmm5,%xmm0,%xmm4
+	vmulsd %xmm5,%xmm1,%xmm8
+	vmulsd %xmm5,%xmm2,%xmm5
+	vmovsd %xmm4,-0xc0(%rcx)
+	vmulsd %xmm0,%xmm0,%xmm6
+	vmovsd %xmm8,-0xb8(%rcx)
+	vmovsd %xmm5,-0xb0(%rcx)
+	vmulsd %xmm12,%xmm2,%xmm5
+	vsubsd %xmm6,%xmm7,%xmm15
+	vmulsd 0x50(%rsp),%xmm15,%xmm14
 	vmulsd %xmm5,%xmm4,%xmm10
-	vmovsd %xmm6,%xmm6,%xmm15
-	vmulsd %xmm2,%xmm4,%xmm4
-	vmulsd %xmm12,%xmm3,%xmm3
+	vmulsd %xmm5,%xmm8,%xmm5
+	vmulsd 0x90(%rsp),%xmm0,%xmm8
 	vmovsd %xmm10,-0xa8(%rcx)
-	vmovsd %xmm4,-0x90(%rcx)
-	vmulsd %xmm1,%xmm1,%xmm1
-	vmovq  %xmm4,%r9
-	vmulsd %xmm5,%xmm3,%xmm4
-	vaddsd %xmm1,%xmm6,%xmm9
-	vsubsd %xmm1,%xmm6,%xmm5
-	vmulsd 0x58(%rsp),%xmm5,%xmm2
-	vfnmadd132sd %xmm7,%xmm1,%xmm15
-	vmovsd %xmm4,-0xa0(%rcx)
-	vmovq  %xmm4,%r11
-	vmovsd 0xa8(%rsp),%xmm4
+	vmovsd %xmm5,-0x90(%rcx)
+	vmovq  %xmm5,%rdi
+	vmulsd %xmm12,%xmm1,%xmm5
+	vmovq  %xmm14,%r9
+	vmovsd %xmm14,-0x88(%rcx)
+	vmulsd %xmm4,%xmm5,%xmm5
+	vmovsd %xmm7,%xmm7,%xmm4
+	vfnmadd132sd %xmm9,%xmm6,%xmm4
+	vmovsd %xmm5,-0xa0(%rcx)
 	vmovq  %xmm5,%r8
-	vfnmadd132sd %xmm0,%xmm9,%xmm4
-	vmulsd 0x60(%rsp),%xmm4,%xmm4
-	vmovsd %xmm2,-0x88(%rcx)
-	vmovsd %xmm4,-0x98(%rcx)
-	mov    -0x10(%rsi),%rax
-	vmovsd -0x8(%rsi),%xmm8
-	mov    -0x18(%rsi),%rdi
-	vmovq  %rax,%xmm5
-	vmulsd 0x88(%rsp),%xmm5,%xmm3
-	vmulsd %xmm15,%xmm3,%xmm15
-	vmulsd %xmm13,%xmm8,%xmm3
-	vmulsd %xmm10,%xmm3,%xmm3
-	vmovsd %xmm15,-0x80(%rcx)
-	vmovsd %xmm3,-0x78(%rcx)
-	vmovsd 0x80(%rsp),%xmm3
-	vfnmadd132sd %xmm0,%xmm9,%xmm3
-	vmulsd 0x78(%rsp),%xmm3,%xmm3
-	vmulsd %xmm3,%xmm5,%xmm5
-	vmovsd %xmm5,-0x70(%rcx)
+	vaddsd %xmm6,%xmm7,%xmm5
+	vmulsd %xmm4,%xmm8,%xmm8
+	vmulsd %xmm13,%xmm1,%xmm4
 	vmovq  %xmm5,%rax
-	vmovq  %rdi,%xmm5
-	vmulsd %xmm3,%xmm5,%xmm3
-	vmovsd 0x70(%rsp),%xmm5
-	vmovsd %xmm3,-0x60(%rcx)
-	vmovsd %xmm3,0xa0(%rsp)
-	vfnmadd132sd %xmm4,%xmm0,%xmm5
-	vmovq  %xmm5,%rbx
-	vmulsd 0x68(%rsp),%xmm8,%xmm5
-	vmovq  %rbx,%xmm3
-	vmulsd %xmm3,%xmm5,%xmm5
-	vmovq  %r8,%xmm3
-	vmovsd %xmm5,-0x68(%rcx)
-	vmulsd 0x98(%rsp),%xmm8,%xmm8
-	vfnmadd231sd 0x20(%rsp),%xmm0,%xmm9
-	vmovq  %xmm5,%r14
-	vmulsd 0x28(%rsp),%xmm10,%xmm5
-	vmulsd 0x18(%rsp),%xmm9,%xmm9
-	vmulsd %xmm3,%xmm8,%xmm8
-	vmovq  %rdi,%xmm3
-	vmulsd 0x90(%rsp),%xmm3,%xmm3
-	vmulsd %xmm2,%xmm5,%xmm5
-	vmovsd %xmm8,-0x58(%rcx)
-	vmovsd %xmm1,%xmm1,%xmm8
-	vfnmadd132sd %xmm7,%xmm6,%xmm8
-	vmulsd %xmm9,%xmm10,%xmm10
-	vmulsd %xmm9,%xmm2,%xmm9
-	vmovq  %r11,%xmm2
-	vfnmadd231sd %xmm7,%xmm0,%xmm6
-	vmulsd %xmm8,%xmm3,%xmm8
-	vmovsd %xmm8,-0x50(%rcx)
-	mov    -0x10(%rsi),%rdi
-	mov    -0x18(%rsi),%rbx
-	mov    -0x8(%rsi),%r8
+	vfnmadd231sd 0xa0(%rsp),%xmm3,%xmm5
+	vmulsd %xmm10,%xmm4,%xmm4
+	vmovsd %xmm8,-0x80(%rcx)
+	vmovsd %xmm4,-0x78(%rcx)
+	vmovq  %rax,%xmm4
+	vfnmadd231sd 0x88(%rsp),%xmm3,%xmm4
+	vmulsd 0x58(%rsp),%xmm5,%xmm5
+	vmulsd 0x80(%rsp),%xmm4,%xmm4
+	vmovsd %xmm5,-0x98(%rcx)
+	vmulsd %xmm4,%xmm0,%xmm14
+	vmulsd %xmm4,%xmm2,%xmm4
+	vmovsd %xmm14,-0x70(%rcx)
+	vmovq  %xmm14,%rbx
+	vmovsd 0x78(%rsp),%xmm14
+	vmovsd %xmm4,-0x60(%rcx)
+	vfnmadd132sd %xmm5,%xmm3,%xmm14
+	vmovq  %xmm14,%rsi
+	vmulsd 0x70(%rsp),%xmm1,%xmm14
+	vmovq  %rsi,%xmm11
+	vmulsd %xmm11,%xmm14,%xmm14
+	vmulsd 0x68(%rsp),%xmm1,%xmm11
+	vmovsd %xmm14,-0x68(%rcx)
+	vmovq  %xmm14,%r13
+	vmovq  %r9,%xmm14
+	vmulsd %xmm15,%xmm11,%xmm15
+	vmulsd 0x60(%rsp),%xmm2,%xmm11
+	vmovsd %xmm15,-0x58(%rcx)
+	vmovsd %xmm6,%xmm6,%xmm15
+	vfnmadd132sd %xmm9,%xmm7,%xmm15
+	vfnmadd231sd %xmm9,%xmm3,%xmm7
+	vmulsd %xmm15,%xmm11,%xmm15
+	vmulsd 0x38(%rsp),%xmm10,%xmm11
+	vmovsd %xmm15,-0x50(%rcx)
+	vmulsd %xmm14,%xmm11,%xmm11
+	vmovq  %rax,%xmm14
+	vmovsd %xmm11,-0x48(%rcx)
+	vmulsd %xmm9,%xmm1,%xmm11
+	vmovq  %xmm11,%r11
+	vmulsd %xmm11,%xmm8,%xmm11
+	vmovsd %xmm11,-0x40(%rcx)
+	vfnmadd231sd 0x30(%rsp),%xmm3,%xmm14
+	vfnmadd132sd 0x98(%rsp),%xmm3,%xmm5
+	vmulsd 0x28(%rsp),%xmm14,%xmm11
+	vmovq  %r9,%xmm14
+	vmulsd 0x48(%rsp),%xmm5,%xmm5
+	vmulsd %xmm11,%xmm10,%xmm10
 	vmovsd %xmm10,-0x38(%rcx)
-	vmovsd %xmm9,-0x18(%rcx)
-	vmovsd %xmm5,-0x48(%rcx)
-	vmovsd 0x40(%rsp),%xmm10
-	vmovq  %r8,%xmm3
-	vmulsd 0x50(%rsp),%xmm3,%xmm9
-	vmulsd %xmm7,%xmm3,%xmm5
-	vmovq  %rdi,%xmm3
-	vmovq  %xmm5,%r13
-	vmulsd %xmm15,%xmm5,%xmm5
-	vfnmadd132sd %xmm10,%xmm0,%xmm4
-	vmulsd 0x38(%rsp),%xmm4,%xmm4
-	vmovsd %xmm5,-0x40(%rcx)
-	vmovq  %r14,%xmm5
-	vmulsd %xmm5,%xmm9,%xmm9
-	vmovq  %rax,%xmm5
-	vfmsub231sd %xmm5,%xmm3,%xmm9
-	vmovq  %rbx,%xmm3
-	vfmadd231sd 0xa0(%rsp),%xmm3,%xmm9
-	vmovq  %r13,%xmm3
-	vmulsd %xmm4,%xmm2,%xmm5
-	vmulsd %xmm8,%xmm3,%xmm2
-	vmovq  %rdi,%xmm3
-	vmulsd 0x48(%rsp),%xmm9,%xmm9
-	vmovsd %xmm5,-0x30(%rcx)
-	vmovq  %r9,%xmm5
-	vmovsd %xmm2,-0x10(%rcx)
-	vmulsd %xmm4,%xmm5,%xmm4
-	vmovq  %rbx,%xmm5
-	vmulsd %xmm8,%xmm5,%xmm8
-	vmovsd %xmm4,-0x20(%rcx)
-	vfmsub231sd %xmm15,%xmm3,%xmm8
-	vmulsd 0x30(%rsp),%xmm8,%xmm8
-	vmovapd 0x2a0f(%rip),%ymm3        
-	vmovsd %xmm9,-0x28(%rcx)
+	vmulsd %xmm11,%xmm14,%xmm10
+	vmovq  %r13,%xmm11
+	vmovq  %rbx,%xmm14
+	vmovsd %xmm10,-0x18(%rcx)
+	vmulsd 0x20(%rsp),%xmm1,%xmm10
+	vmulsd %xmm11,%xmm10,%xmm10
+	vmovq  %r8,%xmm11
+	vfmsub231sd %xmm14,%xmm0,%xmm10
+	vmovq  %rdi,%xmm14
+	vfmadd132sd %xmm2,%xmm10,%xmm4
+	vmulsd 0x18(%rsp),%xmm4,%xmm4
+	vmovsd %xmm4,-0x28(%rcx)
+	vmulsd %xmm5,%xmm11,%xmm4
+	vmulsd %xmm5,%xmm14,%xmm5
+	vmovsd %xmm4,-0x30(%rcx)
+	vmovsd %xmm5,-0x20(%rcx)
+	vmovq  %r11,%xmm5
+	vmulsd %xmm5,%xmm15,%xmm4
+	vmovapd 0x97b0(%rip),%ymm5        
+	vmovsd %xmm4,-0x10(%rcx)
+	vmulsd %xmm15,%xmm2,%xmm4
+	vfmsub132sd %xmm0,%xmm4,%xmm8
+	vmulsd 0x40(%rsp),%xmm8,%xmm8
 	vmovsd %xmm8,-0x8(%rcx)
-	vmovupd %ymm3,-0x258(%rdx)
+	vmovupd %ymm5,-0x258(%rdx)
+	vmovsd 0xa8(%rsp),%xmm5
 	movq   $0x0,-0xc8(%rdx)
 	movq   $0x0,-0x190(%rdx)
-	vmovsd %xmm11,-0x188(%rdx)
 	movq   $0x0,-0x180(%rdx)
 	movq   $0x0,-0x178(%rdx)
 	movq   $0x0,-0xc0(%rdx)
-	vmovsd %xmm11,-0xb8(%rdx)
 	movq   $0x0,-0xb0(%rdx)
-	vmulsd -0xc0(%rcx),%xmm12,%xmm4
+	vmovsd %xmm5,-0x188(%rdx)
+	vmovsd %xmm5,-0xb8(%rdx)
+	vmulsd -0xc0(%rcx),%xmm12,%xmm8
+	vmovsd 0x9953(%rip),%xmm5        
 	movq   $0x0,-0x230(%rdx)
-	vmovsd 0x2bc0(%rip),%xmm5        
-	vmovsd %xmm4,-0x238(%rdx)
-	vmulsd -0xb0(%rcx),%xmm5,%xmm2
-	vmovsd %xmm2,-0x228(%rdx)
-	vmulsd -0xb8(%rcx),%xmm12,%xmm3
-	vmulsd 0x2ba0(%rip),%xmm2,%xmm2        
-	vmovsd %xmm3,-0x220(%rdx)
-	vmulsd -0xb0(%rcx),%xmm12,%xmm5
-	vmovsd %xmm3,-0x168(%rdx)
-	vmulsd 0x2b90(%rip),%xmm3,%xmm3        
-	vmovsd %xmm2,-0x170(%rdx)
+	vmovsd %xmm8,-0x238(%rdx)
+	vmulsd -0xb0(%rcx),%xmm5,%xmm4
+	vmovsd %xmm4,-0x228(%rdx)
+	vmulsd -0xb8(%rcx),%xmm12,%xmm5
+	vmovsd %xmm5,-0x220(%rdx)
+	vmulsd -0xb0(%rcx),%xmm12,%xmm10
+	vmovsd %xmm5,-0x168(%rdx)
+	vmulsd 0x9920(%rip),%xmm5,%xmm5        
 	movq   $0x0,-0x158(%rdx)
 	movq   $0x0,-0x88(%rdx)
 	movq   $0x0,-0xa8(%rdx)
-	vmovsd %xmm4,-0xa0(%rdx)
-	vmovsd %xmm2,-0x90(%rdx)
-	vmovsd %xmm5,-0x218(%rdx)
-	vmulsd 0x2b3f(%rip),%xmm4,%xmm5        
-	vmovsd %xmm3,-0x98(%rdx)
-	vmovsd 0x2b97(%rip),%xmm3        
-	vmovsd %xmm5,-0x160(%rdx)
-	vxorpd %xmm14,%xmm4,%xmm5
-	vmovsd %xmm5,-0x150(%rdx)
-	vmulsd -0xa8(%rcx),%xmm3,%xmm3
-	vmovsd 0x2b7a(%rip),%xmm5        
-	vmovsd %xmm3,-0x210(%rdx)
-	vmulsd -0xa0(%rcx),%xmm13,%xmm4
-	vxorpd %xmm14,%xmm3,%xmm3
-	vmovsd %xmm4,-0x208(%rdx)
-	vmulsd -0xa8(%rcx),%xmm5,%xmm2
-	vxorpd %xmm14,%xmm4,%xmm4
-	vmovsd %xmm2,-0x200(%rdx)
-	vmovsd 0x2b48(%rip),%xmm5        
-	vmovsd 0x2b30(%rip),%xmm15        
-	vmulsd -0x90(%rcx),%xmm5,%xmm2
-	vmovsd 0x2b38(%rip),%xmm5        
-	vmovsd %xmm2,-0x1f8(%rdx)
-	vsubsd %xmm0,%xmm1,%xmm2
-	vfmadd132sd -0x98(%rcx),%xmm2,%xmm5
-	vmulsd 0x2b23(%rip),%xmm5,%xmm5        
-	vmovsd %xmm5,-0x1f0(%rdx)
-	vmulsd -0x90(%rcx),%xmm13,%xmm5
-	vmovsd %xmm5,-0x1e8(%rdx)
-	vmulsd -0x88(%rcx),%xmm15,%xmm8
-	vmovsd %xmm5,-0x140(%rdx)
-	vmovsd 0x2afb(%rip),%xmm5        
-	vmovsd %xmm8,-0x1e0(%rdx)
-	vmovsd %xmm8,-0x148(%rdx)
-	vfnmadd231sd -0x98(%rcx),%xmm5,%xmm2
-	vmovsd 0x2ac2(%rip),%xmm5        
-	vmulsd 0x2ada(%rip),%xmm2,%xmm2        
-	vmovsd %xmm2,-0x138(%rdx)
-	vmulsd -0xa0(%rcx),%xmm5,%xmm2
-	vmovsd 0x2a9a(%rip),%xmm5        
-	vmovsd %xmm2,-0x130(%rdx)
-	vmulsd -0xa8(%rcx),%xmm5,%xmm2
-	vmovsd %xmm4,-0x120(%rdx)
-	vmovsd %xmm3,-0x118(%rdx)
+	vmovsd %xmm8,-0xa0(%rdx)
+	vmulsd 0x98df(%rip),%xmm4,%xmm4        
+	vmovsd 0x993f(%rip),%xmm15        
+	vmovsd 0x9947(%rip),%xmm14        
+	vmovsd %xmm10,-0x218(%rdx)
+	vmulsd 0x98c7(%rip),%xmm8,%xmm10        
+	vmovsd %xmm5,-0x98(%rdx)
+	vmovsd 0x990f(%rip),%xmm5        
+	vmovsd %xmm4,-0x170(%rdx)
+	vmovsd %xmm4,-0x90(%rdx)
+	vmovsd %xmm10,-0x160(%rdx)
+	vxorpd 0x9d77(%rip),%xmm8,%xmm10        
+	vmovsd %xmm10,-0x150(%rdx)
+	vmulsd -0xa8(%rcx),%xmm5,%xmm5
+	vmovsd 0x98f7(%rip),%xmm10        
+	vmovsd %xmm5,-0x210(%rdx)
+	vmulsd -0xa0(%rcx),%xmm13,%xmm8
+	vmovsd %xmm8,-0x208(%rdx)
+	vmulsd -0xa8(%rcx),%xmm15,%xmm4
+	vmovsd 0x98bf(%rip),%xmm15        
+	vmovsd %xmm4,-0x200(%rdx)
+	vmulsd -0x90(%rcx),%xmm15,%xmm4
+	vmovsd %xmm4,-0x1f8(%rdx)
+	vsubsd %xmm3,%xmm6,%xmm4
+	vfmadd132sd -0x98(%rcx),%xmm4,%xmm14
+	vmulsd %xmm14,%xmm10,%xmm10
+	vmovsd %xmm10,-0x1f0(%rdx)
+	vmulsd -0x90(%rcx),%xmm13,%xmm10
+	vmovsd %xmm10,-0x1e8(%rdx)
+	vmovsd 0x9865(%rip),%xmm15        
+	vxorpd 0x9ce5(%rip),%xmm8,%xmm8        
+	vmulsd -0x88(%rcx),%xmm15,%xmm15
+	vmovsd %xmm10,-0x140(%rdx)
+	vxorpd 0x9ccd(%rip),%xmm5,%xmm5        
+	vmovsd %xmm15,-0x1e0(%rdx)
+	vmovsd %xmm15,-0x148(%rdx)
+	vmovsd 0x9855(%rip),%xmm15        
+	vfnmadd231sd -0x98(%rcx),%xmm15,%xmm4
+	vmovsd 0x982c(%rip),%xmm15        
+	vmulsd 0x9844(%rip),%xmm4,%xmm4        
+	vmovsd %xmm4,-0x138(%rdx)
+	vmulsd -0xa0(%rcx),%xmm15,%xmm4
+	vmovsd 0x9804(%rip),%xmm15        
+	vmovsd %xmm4,-0x130(%rdx)
+	vmulsd -0xa8(%rcx),%xmm15,%xmm4
+	vmovsd %xmm8,-0x120(%rdx)
+	vmovsd %xmm5,-0x118(%rdx)
 	movq   $0x0,-0x80(%rdx)
-	vmovsd 0x2a9a(%rip),%xmm3        
-	vmovsd %xmm2,-0x128(%rdx)
-	vmulsd -0xa8(%rcx),%xmm13,%xmm2
-	vmovsd %xmm2,-0x78(%rdx)
-	vmulsd -0xa0(%rcx),%xmm3,%xmm2
-	vmovsd %xmm2,-0x70(%rdx)
-	vmovsd 0x2a78(%rip),%xmm3        
-	vmovsd 0x2b18(%rip),%xmm5        
-	vmulsd -0x98(%rcx),%xmm3,%xmm2
-	vmovsd 0x2a58(%rip),%xmm3        
-	vmovsd 0x2b08(%rip),%xmm15        
-	vmovsd %xmm2,-0x68(%rdx)
-	vmulsd -0x90(%rcx),%xmm3,%xmm2
-	vmovsd %xmm2,-0x60(%rdx)
-	vmulsd -0x88(%rcx),%xmm13,%xmm2
+	vmovsd 0x9804(%rip),%xmm5        
+	vmovsd %xmm4,-0x128(%rdx)
+	vmulsd -0xa8(%rcx),%xmm13,%xmm4
+	vmovsd %xmm4,-0x78(%rdx)
+	vmulsd -0xa0(%rcx),%xmm5,%xmm4
+	vmovsd 0x97e7(%rip),%xmm5        
+	vmovsd %xmm4,-0x70(%rdx)
+	vmulsd -0x98(%rcx),%xmm5,%xmm4
+	vmovsd 0x97ca(%rip),%xmm5        
+	vmovsd %xmm4,-0x68(%rdx)
+	vmulsd -0x90(%rcx),%xmm5,%xmm4
+	vmovsd %xmm4,-0x60(%rdx)
+	vmulsd -0x88(%rcx),%xmm13,%xmm4
+	vmovsd %xmm4,-0x58(%rdx)
+	vmovsd 0x97f3(%rip),%xmm5        
 	movq   $0x0,-0x50(%rdx)
-	vmovsd %xmm2,-0x58(%rdx)
-	vmulsd -0x80(%rcx),%xmm5,%xmm5
-	vmovsd -0x8(%rsi),%xmm3
-	vmovsd -0x10(%rsi),%xmm2
-	vmulsd 0x2ad2(%rip),%xmm2,%xmm9        
-	vmovsd -0x18(%rsi),%xmm4
-	vmulsd 0x2add(%rip),%xmm2,%xmm2        
-	vmovsd %xmm5,-0x1d8(%rdx)
-	vmulsd -0x78(%rcx),%xmm15,%xmm8
-	vmovsd 0x2ab8(%rip),%xmm15        
-	vxorpd %xmm14,%xmm5,%xmm5
-	vmovsd %xmm8,-0x1d0(%rdx)
-	vfmadd132sd -0x98(%rcx),%xmm1,%xmm10
-	vxorpd %xmm14,%xmm8,%xmm8
-	vmulsd %xmm10,%xmm9,%xmm10
+	vmovsd 0x98(%rsp),%xmm10
+	vmulsd -0x80(%rcx),%xmm5,%xmm4
+	vmovsd 0x97dd(%rip),%xmm5        
+	vmulsd 0x97dd(%rip),%xmm0,%xmm8        
+	vmovsd 0x97dd(%rip),%xmm15        
+	vmulsd 0x97e5(%rip),%xmm0,%xmm0        
+	vmulsd 0x97f5(%rip),%xmm2,%xmm2        
+	vmovsd %xmm4,-0x1d8(%rdx)
+	vmulsd -0x78(%rcx),%xmm5,%xmm5
+	vmulsd %xmm7,%xmm2,%xmm7
+	vmovsd %xmm5,-0x1d0(%rdx)
+	vfmadd132sd -0x98(%rcx),%xmm6,%xmm10
+	vmulsd %xmm10,%xmm8,%xmm10
 	vmovsd %xmm10,-0x1c8(%rdx)
 	vmulsd -0x78(%rcx),%xmm15,%xmm10
-	vmovsd 0x2a8b(%rip),%xmm15        
+	vmovsd 0x9799(%rip),%xmm15        
 	vmovsd %xmm10,-0x1c0(%rdx)
 	vmulsd -0x60(%rcx),%xmm15,%xmm15
 	vmovsd %xmm15,-0x1b8(%rdx)
-	vmulsd -0xa0(%rcx),%xmm2,%xmm2
-	vmovsd 0x2a76(%rip),%xmm15        
-	vfmsub231sd %xmm3,%xmm0,%xmm2
-	vfnmadd231sd -0x68(%rcx),%xmm15,%xmm2
-	vmulsd 0x2a6b(%rip),%xmm2,%xmm2        
-	vmovsd %xmm2,-0x1b0(%rdx)
-	vmulsd 0x2a63(%rip),%xmm4,%xmm4        
-	vmulsd %xmm6,%xmm4,%xmm6
-	vmovsd %xmm6,-0x1a8(%rdx)
-	vmovsd 0x2a17(%rip),%xmm6        
-	vmulsd -0x58(%rcx),%xmm6,%xmm2
-	vmovsd 0x2a02(%rip),%xmm6        
-	vmovsd %xmm2,-0x1a0(%rdx)
-	vmulsd -0x50(%rcx),%xmm6,%xmm6
-	vmovsd %xmm2,-0x108(%rdx)
-	vmovsd 0xa8(%rsp),%xmm2
-	vfnmadd132sd %xmm0,%xmm1,%xmm2
-	vmovsd %xmm6,-0x198(%rdx)
-	vmovsd %xmm6,-0x110(%rdx)
-	vmovsd 0x2a0f(%rip),%xmm6        
-	vfnmadd231sd -0x98(%rcx),%xmm6,%xmm2
-	vmovsd 0x2a06(%rip),%xmm6        
-	vmulsd %xmm2,%xmm4,%xmm4
-	vmovsd %xmm4,-0x100(%rdx)
-	vmulsd -0x68(%rcx),%xmm6,%xmm2
-	vmovsd %xmm1,%xmm1,%xmm4
-	vmovsd 0x29b9(%rip),%xmm6        
-	vfmsub132sd %xmm7,%xmm0,%xmm4
-	vfnmadd132sd %xmm7,%xmm1,%xmm0
-	vmovsd 0x29df(%rip),%xmm1        
-	vmulsd %xmm0,%xmm9,%xmm0
-	vfmsub132sd %xmm4,%xmm2,%xmm3
-	vmulsd 0x29ae(%rip),%xmm3,%xmm3        
-	vmovsd %xmm3,-0xf8(%rdx)
-	vmulsd -0x70(%rcx),%xmm6,%xmm2
+	vmulsd -0xa0(%rcx),%xmm0,%xmm0
+	vmovsd 0x9784(%rip),%xmm15        
+	vfmsub231sd %xmm3,%xmm1,%xmm0
+	vfnmadd231sd -0x68(%rcx),%xmm15,%xmm0
+	vmovsd %xmm7,-0x1a8(%rdx)
+	vmovsd 0x9741(%rip),%xmm7        
+	vmulsd 0x9769(%rip),%xmm0,%xmm0        
+	vmovsd %xmm0,-0x1b0(%rdx)
+	vmulsd -0x58(%rcx),%xmm7,%xmm0
+	vmovsd 0x971c(%rip),%xmm7        
+	vmovsd %xmm0,-0x1a0(%rdx)
+	vmulsd -0x50(%rcx),%xmm7,%xmm7
+	vmovsd %xmm7,-0x198(%rdx)
+	vmovsd %xmm7,-0x110(%rdx)
+	vmovsd %xmm0,-0x108(%rdx)
+	vmovsd 0xa0(%rsp),%xmm0
+	vmovsd 0x972e(%rip),%xmm7        
+	vxorpd 0x9ade(%rip),%xmm5,%xmm5        
+	vxorpd 0x9ad6(%rip),%xmm4,%xmm4        
+	vfnmadd132sd %xmm3,%xmm6,%xmm0
+	vfnmadd231sd -0x98(%rcx),%xmm7,%xmm0
+	vmovsd 0x9710(%rip),%xmm7        
+	vmulsd %xmm0,%xmm2,%xmm2
+	vmovsd %xmm2,-0x100(%rdx)
+	vmulsd -0x68(%rcx),%xmm7,%xmm0
+	vmovsd %xmm6,%xmm6,%xmm2
+	vfmsub132sd %xmm9,%xmm3,%xmm2
+	vfnmadd132sd %xmm9,%xmm6,%xmm3
+	vmovsd 0x96f1(%rip),%xmm6        
+	vmulsd %xmm3,%xmm8,%xmm3
+	vfmsub132sd %xmm2,%xmm0,%xmm1
+	vmulsd 0x96c0(%rip),%xmm1,%xmm1        
+	vmovsd %xmm1,-0xf8(%rdx)
+	vmovsd 0x9698(%rip),%xmm1        
+	vmulsd -0x70(%rcx),%xmm1,%xmm0
+	vmovsd %xmm3,-0xe0(%rdx)
 	vmovsd %xmm10,-0xe8(%rdx)
-	vmovsd %xmm0,-0xe0(%rdx)
-	vmovsd %xmm8,-0xd8(%rdx)
-	vmovsd %xmm5,-0xd0(%rdx)
+	vmovsd %xmm5,-0xd8(%rdx)
+	vmovsd %xmm4,-0xd0(%rdx)
 	movq   $0x0,-0x48(%rdx)
-	vmovsd %xmm2,-0xf0(%rdx)
-	vmulsd -0x80(%rcx),%xmm7,%xmm0
+	vmovsd 0x96ab(%rip),%xmm3        
+	vmovsd %xmm0,-0xf0(%rdx)
+	vmulsd -0x80(%rcx),%xmm9,%xmm0
 	vmovsd %xmm0,-0x40(%rdx)
-	vmulsd -0x78(%rcx),%xmm1,%xmm0
-	vmovsd 0x2982(%rip),%xmm1        
+	vmulsd -0x78(%rcx),%xmm6,%xmm0
+	vmovsd 0x9684(%rip),%xmm6        
 	vmovsd %xmm0,-0x38(%rdx)
-	vmulsd -0x70(%rcx),%xmm1,%xmm0
-	vmovsd 0x2978(%rip),%xmm1        
-	vmovsd 0x2968(%rip),%xmm6        
+	vmulsd -0x70(%rcx),%xmm6,%xmm0
 	vmovsd %xmm0,-0x30(%rdx)
-	vmulsd -0x68(%rcx),%xmm1,%xmm0
-	vmovsd 0x294e(%rip),%xmm1        
+	vmulsd -0x68(%rcx),%xmm3,%xmm0
+	vmovsd 0x9660(%rip),%xmm3        
 	vmovsd %xmm0,-0x28(%rdx)
 	vmulsd -0x60(%rcx),%xmm6,%xmm0
 	vmovsd %xmm0,-0x20(%rdx)
-	vmulsd -0x58(%rcx),%xmm1,%xmm0
+	vmulsd -0x58(%rcx),%xmm3,%xmm0
 	vmovsd %xmm0,-0x18(%rdx)
-	vmulsd -0x50(%rcx),%xmm7,%xmm0
+	vmulsd -0x50(%rcx),%xmm9,%xmm0
 	movq   $0x0,-0x8(%rdx)
 	vmovsd %xmm0,-0x10(%rdx)
-	cmp    %r10,%rcx
-	jne    63a0 <cartesian_spherical_harmonics_l4._omp_fn.0+0x1d0>
+	cmp    %rcx,%r12
+	jne    3650 <cartesian_spherical_harmonics_l4._omp_fn.0+0x1d0>
 	vzeroupper
 	add    $0xb8,%rsp
 	pop    %rbx
 	pop    %r12
 	pop    %r13
 	pop    %r14
 	pop    %r15
 	pop    %rbp
 	ret
 	data16 cs nopw 0x0(%rax,%rax,1)
-	xchg   %ax,%ax
+	nopl   0x0(%rax)
 	cmp    %edx,%ecx
-	jl     6f20 <cartesian_spherical_harmonics_l4._omp_fn.0+0xd50>
+	jl     4190 <cartesian_spherical_harmonics_l4._omp_fn.0+0xd10>
 	imul   %eax,%ecx
 	add    %ecx,%edx
 	lea    (%rax,%rdx,1),%ecx
 	cmp    %ecx,%edx
-	jge    6b11 <cartesian_spherical_harmonics_l4._omp_fn.0+0x941>
-	vmovsd 0x275c(%rip),%xmm6        
-	vmovsd 0x2704(%rip),%xmm7        
-	lea    (%rdx,%rdx,4),%ecx
-	lea    (%rdx,%rdx,2),%esi
+	jge    3d8f <cartesian_spherical_harmonics_l4._omp_fn.0+0x90f>
+	vmovsd 0x948c(%rip),%xmm6        
+	vmovsd 0x9494(%rip),%xmm3        
+	lea    (%rdx,%rdx,2),%ecx
 	dec    %eax
+	vmovsd 0x94b7(%rip),%xmm1        
+	vmovsd 0x945f(%rip),%xmm11        
+	movslq %ecx,%rcx
+	vmovsd 0x945c(%rip),%xmm12        
+	vmovsd 0x9494(%rip),%xmm9        
+	lea    (%rbx,%rcx,8),%rdi
+	lea    (%rdx,%rdx,4),%ecx
+	vmovsd 0x9495(%rip),%xmm13        
+	mov    0x942e(%rip),%r15        
 	movslq %edx,%rdx
 	lea    (%rcx,%rcx,4),%ecx
-	vmovsd 0x26de(%rip),%xmm11        
 	add    %rax,%rdx
 	movslq %ecx,%rcx
-	vmovsd 0x26d8(%rip),%xmm12        
-	vmovsd 0x2730(%rip),%xmm13        
 	imul   $0xc8,%rdx,%rdx
 	lea    (%r12,%rcx,8),%rcx
-	movslq %esi,%rsi
-	lea    (%rbx,%rsi,8),%rsi
-	lea    0xc8(%r12,%rdx,1),%rdi
-	mov    0x269f(%rip),%r12        
+	mov    %r15,%rsi
+	vmovsd %xmm6,0xa0(%rsp)
+	vmovsd 0x9423(%rip),%xmm6        
+	vmovsd %xmm3,0x50(%rsp)
+	vmovsd 0x9465(%rip),%xmm3        
+	vmovsd %xmm1,0x90(%rsp)
+	lea    0xc8(%r12,%rdx,1),%r10
+	vmovsd 0x9454(%rip),%xmm1        
+	vmovsd %xmm6,0x58(%rsp)
+	vmovsd 0x9436(%rip),%xmm6        
+	vmovsd %xmm3,0x80(%rsp)
+	vmovsd 0x9445(%rip),%xmm3        
+	vmovsd %xmm1,0x78(%rsp)
+	vmovsd 0x943f(%rip),%xmm1        
 	vmovsd %xmm6,0x88(%rsp)
-	vmovsd 0x2706(%rip),%xmm6        
-	vmovsd %xmm7,0xa8(%rsp)
-	vmovsd 0x269d(%rip),%xmm7        
-	mov    %r12,%rbx
-	vmovsd %xmm6,0x80(%rsp)
-	vmovsd 0x26e9(%rip),%xmm6        
-	vmovsd %xmm7,0x60(%rsp)
-	vmovsd 0x2683(%rip),%xmm7        
-	vmovsd %xmm6,0x78(%rsp)
-	vmovsd 0x26d5(%rip),%xmm6        
-	vmovsd %xmm7,0x58(%rsp)
-	vmovsd 0x269f(%rip),%xmm7        
+	vmovsd 0x941e(%rip),%xmm6        
+	vmovsd %xmm3,0x68(%rsp)
+	vmovsd 0x9478(%rip),%xmm3        
+	vmovsd %xmm1,0x60(%rsp)
+	vmovsd 0x9472(%rip),%xmm1        
 	vmovsd %xmm6,0x70(%rsp)
-	vmovsd 0x26c1(%rip),%xmm6        
-	vmovsd %xmm6,0x68(%rsp)
-	vmovsd 0x26bb(%rip),%xmm6        
-	vmovsd %xmm6,0x98(%rsp)
-	vmovsd 0x26b2(%rip),%xmm6        
-	vmovsd %xmm6,0x90(%rsp)
-	vmovsd 0x26f1(%rip),%xmm6        
-	vmovsd %xmm6,0x28(%rsp)
-	vmovsd 0x26eb(%rip),%xmm6        
+	vmovsd 0x9454(%rip),%xmm6        
+	vmovsd %xmm3,0x30(%rsp)
+	vmovsd %xmm1,0x28(%rsp)
+	vmovsd %xmm6,0x38(%rsp)
+	vmovsd 0x9452(%rip),%xmm6        
 	vmovsd %xmm6,0x20(%rsp)
-	vmovsd 0x26e5(%rip),%xmm6        
-	vmovsd %xmm6,0x18(%rsp)
-	vmovsd 0x26df(%rip),%xmm6        
-	vmovsd %xmm6,0x50(%rsp)
-	vmovsd 0x26d9(%rip),%xmm6        
-	vmovsd %xmm7,0xa0(%rsp)
+	vmovsd 0x944c(%rip),%xmm3        
+	vmovsd 0x944c(%rip),%xmm1        
+	vmovsd %xmm9,0xa8(%rsp)
 	vmovsd %xmm13,0x10(%rsp)
 	vmovsd %xmm11,0x8(%rsp)
 	vmovsd %xmm12,(%rsp)
+	vmovsd 0x9432(%rip),%xmm6        
+	vmovsd %xmm3,0x18(%rsp)
+	vmovsd 0x942c(%rip),%xmm3        
+	vmovsd %xmm1,0x98(%rsp)
 	vmovsd %xmm6,0x48(%rsp)
-	vmovsd 0x26b9(%rip),%xmm6        
-	vmovsd %xmm6,0x40(%rsp)
-	vmovsd 0x26b3(%rip),%xmm6        
-	vmovsd %xmm6,0x38(%rsp)
-	vmovsd 0x26ad(%rip),%xmm6        
-	vmovsd %xmm6,0x30(%rsp)
+	vmovsd %xmm3,0x40(%rsp)
 	data16 cs nopw 0x0(%rax,%rax,1)
 	nopl   0x0(%rax)
-	mov    %rbx,(%rcx)
-	vmovsd 0x8(%rsp),%xmm7
+	vmovsd 0x10(%rdi),%xmm0
 	add    $0xc8,%rcx
-	add    $0x18,%rsi
-	vmovsd -0x8(%rsi),%xmm0
-	vmovsd -0x18(%rsi),%xmm1
-	vmulsd -0x10(%rsi),%xmm7,%xmm15
-	vmovsd 0xa8(%rsp),%xmm13
-	vmovsd 0xa0(%rsp),%xmm9
-	vmulsd %xmm7,%xmm0,%xmm0
-	vmulsd %xmm7,%xmm1,%xmm1
-	vmovsd (%rsp),%xmm7
+	add    $0x18,%rdi
+	vmovsd -0x18(%rdi),%xmm3
+	vmovsd -0x10(%rdi),%xmm1
+	mov    %rsi,-0xc8(%rcx)
+	vmovsd 0x8(%rsp),%xmm4
+	vmovsd (%rsp),%xmm12
+	vmovsd 0xa8(%rsp),%xmm10
+	vmovsd 0xa0(%rsp),%xmm13
+	vmulsd %xmm0,%xmm0,%xmm6
+	vmulsd %xmm3,%xmm3,%xmm7
+	vmulsd %xmm4,%xmm1,%xmm15
+	vmulsd %xmm4,%xmm0,%xmm2
+	vmulsd %xmm12,%xmm3,%xmm14
 	vmovsd %xmm15,-0xc0(%rcx)
-	vmovsd %xmm0,-0xb8(%rcx)
-	vmovsd %xmm1,-0xb0(%rcx)
-	vmovsd -0x18(%rsi),%xmm3
-	vmovsd -0x10(%rsi),%xmm2
-	vmovsd -0x8(%rsi),%xmm1
-	vmulsd %xmm3,%xmm3,%xmm6
-	vmulsd %xmm7,%xmm3,%xmm3
-	vmulsd %xmm2,%xmm2,%xmm2
+	vmulsd %xmm4,%xmm3,%xmm4
+	vmovsd %xmm2,-0xb8(%rcx)
 	vmulsd %xmm1,%xmm1,%xmm5
-	vmulsd %xmm7,%xmm1,%xmm1
-	vaddsd %xmm2,%xmm6,%xmm7
-	vsubsd %xmm2,%xmm6,%xmm14
-	vmulsd 0x58(%rsp),%xmm14,%xmm11
-	vfnmadd132sd %xmm5,%xmm7,%xmm13
-	vmulsd 0x60(%rsp),%xmm13,%xmm13
-	vmulsd %xmm15,%xmm3,%xmm4
-	vmulsd %xmm0,%xmm3,%xmm0
-	vmulsd %xmm15,%xmm1,%xmm15
+	vmovsd %xmm4,-0xb0(%rcx)
+	vmulsd %xmm14,%xmm15,%xmm4
+	vmulsd %xmm14,%xmm2,%xmm14
+	vaddsd %xmm5,%xmm7,%xmm9
+	vmulsd %xmm12,%xmm0,%xmm2
 	vmovsd %xmm4,-0xa8(%rcx)
-	vmovsd %xmm0,-0x90(%rcx)
+	vfnmadd132sd %xmm7,%xmm5,%xmm10
+	vmovsd %xmm14,-0x90(%rcx)
+	vfnmadd132sd %xmm6,%xmm9,%xmm13
+	vmulsd 0x58(%rsp),%xmm13,%xmm13
+	vmulsd %xmm15,%xmm2,%xmm15
+	vsubsd %xmm5,%xmm7,%xmm2
+	vmulsd 0x50(%rsp),%xmm2,%xmm11
+	vmovq  %xmm2,%r13
+	vmulsd 0x90(%rsp),%xmm1,%xmm2
 	vmovsd %xmm15,-0xa0(%rcx)
-	vmovsd %xmm11,-0x88(%rcx)
-	vmovq  %xmm0,%rax
-	vfnmadd132sd %xmm6,%xmm2,%xmm9
+	vmovq  %r13,%xmm8
 	vmovsd %xmm13,-0x98(%rcx)
-	vmovsd -0x10(%rsi),%xmm8
-	vmovsd -0x8(%rsi),%xmm3
-	vmulsd 0x88(%rsp),%xmm8,%xmm1
-	vmovsd -0x18(%rsi),%xmm10
-	vmulsd %xmm9,%xmm1,%xmm9
-	vmulsd 0x10(%rsp),%xmm3,%xmm1
-	vmovsd %xmm9,-0x80(%rcx)
-	vmulsd %xmm4,%xmm1,%xmm1
-	vmovsd %xmm1,-0x78(%rcx)
-	vmovsd 0x80(%rsp),%xmm1
-	vfnmadd132sd %xmm5,%xmm7,%xmm1
-	vmulsd 0x78(%rsp),%xmm1,%xmm1
-	vmulsd %xmm1,%xmm8,%xmm8
-	vmulsd %xmm1,%xmm10,%xmm1
-	vmovsd %xmm8,-0x70(%rcx)
-	vmovsd %xmm1,-0x60(%rcx)
-	vmovsd 0x70(%rsp),%xmm12
-	vmulsd 0x68(%rsp),%xmm3,%xmm0
-	vmulsd 0x98(%rsp),%xmm3,%xmm3
-	vfnmadd231sd 0x20(%rsp),%xmm5,%xmm7
-	vfnmadd132sd %xmm13,%xmm5,%xmm12
-	vfnmadd231sd 0x40(%rsp),%xmm13,%xmm5
-	vmulsd 0x18(%rsp),%xmm7,%xmm7
-	vmulsd %xmm14,%xmm3,%xmm3
-	vmulsd 0x28(%rsp),%xmm4,%xmm14
-	vmulsd 0x38(%rsp),%xmm5,%xmm5
-	vmovsd %xmm3,-0x58(%rcx)
-	vmulsd %xmm12,%xmm0,%xmm12
-	vmovsd 0xa0(%rsp),%xmm0
-	vmulsd %xmm7,%xmm4,%xmm4
+	vmovsd %xmm11,-0x88(%rcx)
+	vmulsd %xmm10,%xmm2,%xmm10
+	vmulsd 0x10(%rsp),%xmm0,%xmm2
+	vmovsd %xmm10,-0x80(%rcx)
+	vmulsd %xmm4,%xmm2,%xmm2
+	vmovsd %xmm2,-0x78(%rcx)
+	vmovsd 0x88(%rsp),%xmm2
+	vfnmadd132sd %xmm6,%xmm9,%xmm2
+	vmulsd 0x80(%rsp),%xmm2,%xmm2
+	vmulsd %xmm2,%xmm1,%xmm12
+	vmulsd %xmm2,%xmm3,%xmm2
+	vmovsd %xmm12,-0x70(%rcx)
+	vmovq  %xmm12,%rax
+	vmovsd 0x78(%rsp),%xmm12
+	vmovsd %xmm2,-0x60(%rcx)
+	vmovq  %xmm2,%rbx
+	vmulsd 0x70(%rsp),%xmm0,%xmm2
+	vfnmadd132sd %xmm13,%xmm6,%xmm12
+	vmulsd %xmm12,%xmm2,%xmm12
+	vmulsd 0x68(%rsp),%xmm0,%xmm2
 	vmovsd %xmm12,-0x68(%rcx)
-	vmulsd %xmm11,%xmm14,%xmm14
-	vfnmadd231sd %xmm0,%xmm2,%xmm6
-	vmulsd 0x90(%rsp),%xmm10,%xmm2
-	vmulsd %xmm6,%xmm2,%xmm2
-	vmovsd %xmm2,-0x50(%rcx)
-	vmovsd -0x8(%rsi),%xmm6
-	vmovsd -0x10(%rsi),%xmm3
-	vmovsd -0x18(%rsi),%xmm10
-	vmovsd %xmm14,-0x48(%rcx)
+	vmulsd %xmm8,%xmm2,%xmm2
+	vmovsd 0xa8(%rsp),%xmm8
+	vmovsd %xmm2,-0x58(%rcx)
+	vfnmadd132sd %xmm8,%xmm7,%xmm5
+	vmulsd 0x60(%rsp),%xmm3,%xmm7
+	vfnmadd231sd 0x30(%rsp),%xmm6,%xmm9
+	vfnmadd231sd 0x98(%rsp),%xmm13,%xmm6
+	vmulsd 0x28(%rsp),%xmm9,%xmm9
+	vmulsd 0x48(%rsp),%xmm6,%xmm6
+	vmulsd %xmm5,%xmm7,%xmm5
+	vmulsd 0x38(%rsp),%xmm4,%xmm7
+	vmovsd %xmm5,-0x50(%rcx)
+	vmulsd %xmm9,%xmm4,%xmm4
 	vmovsd %xmm4,-0x38(%rcx)
-	vmulsd %xmm7,%xmm11,%xmm4
-	vmovq  %rax,%xmm7
+	vmulsd %xmm9,%xmm11,%xmm4
+	vmulsd %xmm11,%xmm7,%xmm7
 	vmovsd %xmm4,-0x18(%rcx)
-	vmulsd %xmm0,%xmm6,%xmm14
-	vmulsd 0x50(%rsp),%xmm6,%xmm6
-	vmulsd %xmm9,%xmm14,%xmm0
-	vmovsd %xmm0,-0x40(%rcx)
-	vmulsd %xmm2,%xmm14,%xmm0
-	vmulsd %xmm2,%xmm10,%xmm2
-	vmovsd %xmm0,-0x10(%rcx)
-	vmulsd %xmm12,%xmm6,%xmm6
-	vfmsub231sd %xmm8,%xmm3,%xmm6
-	vfmsub132sd %xmm9,%xmm2,%xmm3
-	vmulsd 0x30(%rsp),%xmm3,%xmm3
-	vfmadd132sd %xmm10,%xmm6,%xmm1
-	vmulsd 0x48(%rsp),%xmm1,%xmm1
-	vmovsd %xmm3,-0x8(%rcx)
-	vmovsd %xmm1,-0x28(%rcx)
-	vmulsd %xmm5,%xmm15,%xmm1
-	vmulsd %xmm5,%xmm7,%xmm5
-	vmovsd %xmm1,-0x30(%rcx)
-	vmovsd %xmm5,-0x20(%rcx)
-	cmp    %rcx,%rdi
-	jne    6cd0 <cartesian_spherical_harmonics_l4._omp_fn.0+0xb00>
-	jmp    6b11 <cartesian_spherical_harmonics_l4._omp_fn.0+0x941>
-	cs nopw 0x0(%rax,%rax,1)
+	vmovsd %xmm7,-0x48(%rcx)
+	vmulsd %xmm8,%xmm0,%xmm7
+	vmulsd 0x20(%rsp),%xmm0,%xmm0
+	vmulsd %xmm7,%xmm10,%xmm2
+	vmulsd %xmm7,%xmm5,%xmm7
+	vmulsd %xmm5,%xmm3,%xmm5
+	vmovsd %xmm2,-0x40(%rcx)
+	vmovq  %rax,%xmm2
+	vmovsd %xmm7,-0x10(%rcx)
+	vmulsd %xmm12,%xmm0,%xmm0
+	vfmsub132sd %xmm1,%xmm0,%xmm2
+	vfmsub132sd %xmm10,%xmm5,%xmm1
+	vmulsd 0x40(%rsp),%xmm1,%xmm1
+	vmovsd %xmm2,%xmm2,%xmm0
+	vmovq  %rbx,%xmm2
+	vfmadd132sd %xmm3,%xmm0,%xmm2
+	vmulsd 0x18(%rsp),%xmm2,%xmm2
+	vmulsd %xmm6,%xmm15,%xmm0
+	vmulsd %xmm6,%xmm14,%xmm6
+	vmovsd %xmm0,-0x30(%rcx)
+	vmovsd %xmm1,-0x8(%rcx)
+	vmovsd %xmm6,-0x20(%rcx)
+	vmovsd %xmm2,-0x28(%rcx)
+	cmp    %rcx,%r10
+	jne    3f50 <cartesian_spherical_harmonics_l4._omp_fn.0+0xad0>
+	jmp    3d8f <cartesian_spherical_harmonics_l4._omp_fn.0+0x90f>
+	xchg   %ax,%ax
 	inc    %eax
 	xor    %edx,%edx
-	jmp    621a <cartesian_spherical_harmonics_l4._omp_fn.0+0x4a>
+	jmp    34ca <cartesian_spherical_harmonics_l4._omp_fn.0+0x4a>
 	nopl   0x0(%rax)
 	inc    %eax
 	xor    %edx,%edx
-	jmp    6b38 <cartesian_spherical_harmonics_l4._omp_fn.0+0x968>
+	jmp    3db8 <cartesian_spherical_harmonics_l4._omp_fn.0+0x938>
 	nopl   0x0(%rax)
 
-0000000000006f30 <cartesian_spherical_harmonics_l5._omp_fn.0>:
+00000000000041a0 <cartesian_spherical_harmonics_l5._omp_fn.0>:
 cartesian_spherical_harmonics_l5._omp_fn.0():
 	push   %rbp
 	mov    %rsp,%rbp
 	push   %r15
 	push   %r14
 	mov    %rdi,%r15
 	push   %r13
 	push   %r12
 	push   %rbx
-	sub    $0x128,%rsp
+	sub    $0x118,%rsp
 	mov    0x10(%rdi),%r14
 	mov    0x8(%rdi),%r12
 	mov    (%rdi),%rbx
 	call   1090 <omp_get_num_threads@plt>
 	mov    %eax,%r13d
 	call   1080 <omp_get_thread_num@plt>
 	mov    %eax,%esi
 	mov    0x18(%r15),%eax
 	cltd
 	idiv   %r13d
 	test   %r14,%r14
-	je     7ed0 <cartesian_spherical_harmonics_l5._omp_fn.0+0xfa0>
+	je     50e0 <cartesian_spherical_harmonics_l5._omp_fn.0+0xf40>
 	cmp    %edx,%esi
-	jl     84d0 <cartesian_spherical_harmonics_l5._omp_fn.0+0x15a0>
+	jl     56b0 <cartesian_spherical_harmonics_l5._omp_fn.0+0x1510>
 	imul   %eax,%esi
 	add    %esi,%edx
 	lea    (%rax,%rdx,1),%ecx
 	cmp    %ecx,%edx
-	jge    7ebb <cartesian_spherical_harmonics_l5._omp_fn.0+0xf8b>
-	vmovsd 0x22be(%rip),%xmm1        
+	jge    50cd <cartesian_spherical_harmonics_l5._omp_fn.0+0xf2d>
+	vmovsd 0x90a6(%rip),%xmm2        
+	vmovsd 0x9046(%rip),%xmm5        
 	lea    (%rdx,%rdx,2),%ecx
-	vmovsd 0x22ab(%rip),%xmm14        
-	movslq %edx,%rdi
+	movslq %edx,%rsi
+	vmovsd 0x9118(%rip),%xmm6        
+	vmovsd 0x9028(%rip),%xmm15        
 	movslq %ecx,%rcx
-	vmovsd 0x22f5(%rip),%xmm9        
 	dec    %eax
-	lea    (%rdi,%rdi,8),%rdx
-	lea    (%rbx,%rcx,8),%rsi
-	mov    0x2284(%rip),%rbx        
-	imul   $0x360,%rdi,%rcx
-	add    %rax,%rdi
-	lea    (%rdi,%rdi,8),%rax
+	vmovsd 0x9063(%rip),%xmm11        
+	mov    0x900c(%rip),%r13        
+	lea    (%rbx,%rcx,8),%r11
+	lea    (%rsi,%rsi,8),%rdx
+	imul   $0x360,%rsi,%rcx
+	add    %rax,%rsi
 	shl    $0x5,%rdx
-	shl    $0x5,%rax
+	lea    (%rsi,%rsi,8),%rax
 	lea    0x8(%r12,%rdx,1),%rdx
+	shl    $0x5,%rax
 	add    %r14,%rcx
-	lea    0x128(%r12,%rax,1),%r10
-	vmovsd %xmm1,0x110(%rsp)
-	vmovsd 0x2265(%rip),%xmm1        
-	vmovsd %xmm1,0xe8(%rsp)
-	vmovsd 0x225c(%rip),%xmm1        
+	lea    0x128(%r12,%rax,1),%rbx
+	vmovsd %xmm2,0xd0(%rsp)
+	vmovsd 0x903d(%rip),%xmm2        
+	vmovsd %xmm5,0x108(%rsp)
+	vmovsd 0x8fd4(%rip),%xmm5        
+	vmovsd %xmm6,0x50(%rsp)
+	vmovsd %xmm2,0xc8(%rsp)
+	vmovsd 0x901d(%rip),%xmm2        
+	vmovsd %xmm5,0xf0(%rsp)
+	vmovsd 0x8fb4(%rip),%xmm5        
+	vmovsd %xmm2,0xc0(%rsp)
+	vmovsd 0x9003(%rip),%xmm2        
+	vmovsd %xmm5,0x38(%rsp)
+	vmovsd 0x8f9d(%rip),%xmm5        
+	vmovsd %xmm2,0xb8(%rsp)
+	vmovsd 0x8fec(%rip),%xmm2        
+	vmovsd %xmm5,0x30(%rsp)
+	vmovsd 0x8fae(%rip),%xmm5        
+	vmovsd %xmm2,0xb0(%rsp)
+	vmovsd 0x8fd5(%rip),%xmm2        
+	vmovsd %xmm5,0xd8(%rsp)
+	vmovsd 0x8f94(%rip),%xmm5        
+	vmovsd %xmm2,0xa8(%rsp)
+	vmovsd 0x9003(%rip),%xmm2        
+	vmovsd %xmm2,0x60(%rsp)
+	vmovsd 0x8ffd(%rip),%xmm2        
+	vmovsd %xmm2,0x58(%rsp)
+	vmovsd 0x8fff(%rip),%xmm2        
+	vmovsd 0x8fff(%rip),%xmm1        
+	vmovsd 0x8fff(%rip),%xmm6        
+	vmovsd %xmm2,0x48(%rsp)
+	vmovsd 0x8ff9(%rip),%xmm2        
 	vmovsd %xmm1,0x40(%rsp)
-	vmovsd 0x2256(%rip),%xmm1        
-	vmovsd %xmm1,0x30(%rsp)
-	vmovsd 0x2288(%rip),%xmm1        
-	vmovsd %xmm1,0x88(%rsp)
-	vmovsd 0x227f(%rip),%xmm1        
-	vmovsd %xmm1,0xf0(%rsp)
-	vmovsd 0x2276(%rip),%xmm1        
+	vmovsd 0x8ff3(%rip),%xmm1        
+	vmovsd %xmm6,0xe8(%rsp)
+	vmovsd 0x905a(%rip),%xmm6        
+	vmovsd %xmm2,0x10(%rsp)
+	vmovsd 0x9054(%rip),%xmm2        
+	vmovsd %xmm1,0x8(%rsp)
+	vmovsd 0x904e(%rip),%xmm1        
+	vmovsd %xmm6,0x28(%rsp)
+	vmovsd 0x9048(%rip),%xmm6        
+	vmovsd %xmm2,0x20(%rsp)
+	vmovsd 0x9042(%rip),%xmm2        
+	vmovsd %xmm1,0x18(%rsp)
+	vmovsd 0x903c(%rip),%xmm1        
+	vmovsd %xmm6,0xf8(%rsp)
+	vmovsd 0x9033(%rip),%xmm6        
+	vmovsd %xmm2,0xa0(%rsp)
+	vmovsd 0x902a(%rip),%xmm2        
+	vmovsd %xmm1,0x98(%rsp)
+	vmovsd 0x9021(%rip),%xmm1        
+	vmovsd %xmm6,0x90(%rsp)
+	vmovsd 0x9018(%rip),%xmm6        
+	vmovsd %xmm2,0x88(%rsp)
+	vmovsd 0x900f(%rip),%xmm2        
 	vmovsd %xmm1,0x80(%rsp)
-	vmovsd 0x226d(%rip),%xmm1        
-	vmovsd %xmm1,0x78(%rsp)
-	vmovsd 0x2267(%rip),%xmm1        
-	vmovsd %xmm1,0x70(%rsp)
-	vmovsd 0x2261(%rip),%xmm1        
+	vmovsd %xmm6,0x78(%rsp)
+	vmovsd %xmm2,0x70(%rsp)
+	vmovsd 0x8ffa(%rip),%xmm1        
+	vmovsd %xmm15,0x100(%rsp)
+	vmovsd %xmm5,0xe0(%rsp)
 	vmovsd %xmm1,0x68(%rsp)
-	vmovsd 0x225b(%rip),%xmm1        
-	vmovsd %xmm1,0xd8(%rsp)
-	vmovsd 0x2252(%rip),%xmm1        
-	vmovsd %xmm1,0xd0(%rsp)
-	vmovsd 0x2291(%rip),%xmm1        
-	vmovsd %xmm1,0x60(%rsp)
-	vmovsd 0x228b(%rip),%xmm1        
-	vmovsd %xmm1,0x58(%rsp)
-	vmovsd 0x2285(%rip),%xmm1        
-	vmovsd %xmm1,0x50(%rsp)
-	vmovsd 0x227f(%rip),%xmm1        
-	vmovsd %xmm1,0xc8(%rsp)
-	vmovsd 0x2276(%rip),%xmm1        
-	vmovsd %xmm1,0xc0(%rsp)
-	vmovsd 0x226d(%rip),%xmm1        
-	vmovsd %xmm1,0x100(%rsp)
-	vmovsd 0x2264(%rip),%xmm1        
-	vmovsd %xmm1,0xb8(%rsp)
-	vmovsd 0x225b(%rip),%xmm1        
-	vmovsd %xmm1,0xb0(%rsp)
-	vmovsd 0x2252(%rip),%xmm1        
-	vmovsd %xmm1,0xa8(%rsp)
-	vmovsd 0x2249(%rip),%xmm1        
-	vmovsd %xmm1,0xa0(%rsp)
-	vmovsd 0x2240(%rip),%xmm1        
-	vmovsd %xmm1,0x98(%rsp)
-	vmovsd 0x2237(%rip),%xmm1        
-	vmovsd %xmm1,0xf8(%rsp)
-	vmovsd 0x222e(%rip),%xmm1        
-	vmovsd %xmm1,0x90(%rsp)
-	vmovsd 0x2225(%rip),%xmm1        
-	vmovsd %xmm1,0x48(%rsp)
-	vmovsd 0x221f(%rip),%xmm1        
-	vmovsd %xmm1,0x38(%rsp)
-	vmovsd 0x2219(%rip),%xmm1        
-	vmovsd %xmm1,0x28(%rsp)
-	vmovsd 0x2213(%rip),%xmm1        
-	vmovsd %xmm1,0x20(%rsp)
-	vmovsd 0x220d(%rip),%xmm1        
-	vmovsd %xmm1,0x18(%rsp)
-	vmovsd 0x2207(%rip),%xmm1        
-	vmovsd %xmm1,0x10(%rsp)
-	vmovsd 0x2201(%rip),%xmm1        
-	vmovq  0x23b1(%rip),%xmm13        
-	vmovsd %xmm14,0x108(%rsp)
-	vmovsd %xmm1,0x8(%rsp)
-	xchg   %ax,%ax
-	mov    %rbx,-0x8(%rdx)
-	vmovsd 0x108(%rsp),%xmm1
+	cs nopw 0x0(%rax,%rax,1)
+	vmovsd 0x10(%r11),%xmm2
 	add    $0x120,%rdx
-	add    $0x18,%rsi
-	vmovsd -0x8(%rsi),%xmm8
+	add    $0x18,%r11
 	add    $0x360,%rcx
-	vmovsd -0x18(%rsi),%xmm0
-	vmulsd -0x10(%rsi),%xmm1,%xmm3
-	vmovsd 0x110(%rsp),%xmm7
-	vmulsd %xmm1,%xmm8,%xmm8
-	vmulsd %xmm1,%xmm0,%xmm0
-	vmovsd %xmm3,-0x120(%rdx)
-	vmovsd %xmm8,-0x118(%rdx)
-	vmovsd %xmm0,-0x110(%rdx)
-	vmovsd -0x18(%rsi),%xmm4
-	vmovsd -0x10(%rsi),%xmm1
-	vmovsd -0x8(%rsi),%xmm2
-	vmulsd %xmm4,%xmm4,%xmm5
-	vmulsd %xmm7,%xmm4,%xmm4
-	vmulsd %xmm3,%xmm4,%xmm15
-	vmulsd %xmm8,%xmm4,%xmm8
-	vmovsd 0xe8(%rsp),%xmm4
-	vmulsd %xmm1,%xmm1,%xmm1
+	vmovsd -0x10(%r11),%xmm1
+	vmovsd -0x18(%r11),%xmm3
+	mov    %r13,-0x128(%rdx)
+	vmovsd 0x100(%rsp),%xmm7
+	vmovsd 0x108(%rsp),%xmm13
 	vmulsd %xmm2,%xmm2,%xmm0
-	vmovsd %xmm15,-0x108(%rdx)
-	vmovsd %xmm8,-0xf0(%rdx)
-	vaddsd %xmm1,%xmm5,%xmm12
-	vmulsd %xmm7,%xmm2,%xmm2
-	vsubsd %xmm1,%xmm5,%xmm10
-	vmulsd %xmm3,%xmm2,%xmm6
-	vfnmadd132sd %xmm0,%xmm12,%xmm4
-	vmulsd 0x30(%rsp),%xmm10,%xmm3
-	vmovsd %xmm5,%xmm5,%xmm2
-	vmulsd 0x40(%rsp),%xmm4,%xmm4
-	vmovsd %xmm6,-0x100(%rdx)
-	vmovsd %xmm6,0xe0(%rsp)
-	vfnmadd132sd %xmm9,%xmm1,%xmm2
-	vmovsd %xmm3,-0xe8(%rdx)
-	vmovsd %xmm4,-0xf8(%rdx)
-	mov    -0x10(%rsi),%rax
-	vmovsd -0x8(%rsi),%xmm6
-	vmovsd -0x18(%rsi),%xmm7
-	vmovq  %rax,%xmm11
-	vmulsd 0x88(%rsp),%xmm11,%xmm11
-	vmulsd %xmm2,%xmm11,%xmm11
-	vmulsd 0xf0(%rsp),%xmm6,%xmm2
-	vmovsd %xmm11,-0xe0(%rdx)
-	vmovsd %xmm11,0x118(%rsp)
-	vmulsd %xmm15,%xmm2,%xmm11
-	vmovsd 0x80(%rsp),%xmm2
-	vmovsd %xmm11,-0xd8(%rdx)
-	vmovq  %xmm11,%rdi
-	vmovq  %rax,%xmm11
-	vfnmadd132sd %xmm0,%xmm12,%xmm2
-	vmulsd 0x78(%rsp),%xmm2,%xmm2
-	vmulsd %xmm2,%xmm11,%xmm11
-	vmulsd %xmm2,%xmm7,%xmm2
-	vmovq  %xmm11,%rax
-	vmovsd %xmm11,-0xd0(%rdx)
-	vmovsd %xmm2,-0xc0(%rdx)
-	vmovsd 0x70(%rsp),%xmm11
-	vmulsd 0xd0(%rsp),%xmm7,%xmm7
-	vfnmadd231sd 0x58(%rsp),%xmm0,%xmm12
-	vmulsd 0x50(%rsp),%xmm12,%xmm12
-	vfnmadd132sd %xmm4,%xmm0,%xmm11
-	vmovq  %xmm11,%r8
-	vmulsd 0x68(%rsp),%xmm6,%xmm11
-	vmulsd 0xd8(%rsp),%xmm6,%xmm6
-	vmovq  %r8,%xmm14
-	vmulsd %xmm14,%xmm11,%xmm11
-	vmulsd %xmm10,%xmm6,%xmm14
-	vmovsd %xmm1,%xmm1,%xmm10
-	vfnmadd132sd %xmm9,%xmm5,%xmm10
-	vmovsd %xmm11,-0xc8(%rdx)
-	vmovsd %xmm14,-0xb8(%rdx)
-	vmovq  %xmm14,%r11
-	vmovq  %xmm11,%r9
-	vmulsd %xmm10,%xmm7,%xmm7
-	vmulsd 0x60(%rsp),%xmm15,%xmm10
-	vmulsd %xmm12,%xmm15,%xmm15
-	vmovsd %xmm7,-0xb0(%rdx)
-	vmovsd -0x8(%rsi),%xmm6
-	mov    -0x10(%rsi),%r12
-	mov    -0x18(%rsi),%r13
-	vmulsd %xmm12,%xmm3,%xmm12
-	vmovsd %xmm15,-0x98(%rdx)
-	vmovsd %xmm12,-0x78(%rdx)
-	vmulsd %xmm3,%xmm10,%xmm10
-	vmulsd %xmm9,%xmm6,%xmm14
-	vmulsd 0xc8(%rsp),%xmm6,%xmm6
+	vmulsd %xmm1,%xmm1,%xmm5
+	vmulsd %xmm7,%xmm1,%xmm4
+	vmulsd %xmm7,%xmm2,%xmm9
+	vmulsd %xmm7,%xmm3,%xmm7
+	vmovsd %xmm4,-0x120(%rdx)
+	vmulsd %xmm3,%xmm3,%xmm6
+	vmovsd %xmm9,-0x118(%rdx)
+	vmovsd %xmm7,-0x110(%rdx)
+	vmulsd %xmm13,%xmm3,%xmm7
+	vsubsd %xmm5,%xmm6,%xmm10
+	vmulsd %xmm7,%xmm4,%xmm8
+	vmulsd %xmm7,%xmm9,%xmm15
+	vmulsd %xmm13,%xmm2,%xmm7
+	vmulsd 0xd8(%rsp),%xmm1,%xmm13
+	vmovq  %xmm15,%r9
+	vmovsd %xmm15,-0xf0(%rdx)
+	vmovsd %xmm8,-0x108(%rdx)
+	vmulsd 0xb8(%rsp),%xmm2,%xmm15
+	vmulsd %xmm4,%xmm7,%xmm4
+	vmulsd 0x30(%rsp),%xmm10,%xmm7
+	vmovq  %xmm4,%r10
+	vmovsd %xmm4,-0x100(%rdx)
+	vaddsd %xmm5,%xmm6,%xmm4
+	vmovq  %xmm4,%rsi
+	vmovsd %xmm4,%xmm4,%xmm9
+	vmovsd %xmm6,%xmm6,%xmm4
+	vfnmadd231sd 0xf0(%rsp),%xmm0,%xmm9
+	vfnmadd132sd %xmm11,%xmm5,%xmm4
+	vmulsd 0x38(%rsp),%xmm9,%xmm9
+	vmovsd %xmm7,-0xe8(%rdx)
+	vmulsd %xmm4,%xmm13,%xmm13
+	vmulsd 0xe0(%rsp),%xmm2,%xmm4
+	vmovsd %xmm13,-0xe0(%rdx)
+	vmovsd %xmm9,-0xf8(%rdx)
+	vmulsd %xmm8,%xmm4,%xmm12
+	vmovq  %rsi,%xmm4
+	vfnmadd231sd 0xd0(%rsp),%xmm0,%xmm4
+	vmovsd %xmm12,-0xd8(%rdx)
+	vmovq  %xmm12,%r8
+	vmulsd 0xc8(%rsp),%xmm4,%xmm4
+	vmulsd %xmm4,%xmm1,%xmm12
+	vmulsd %xmm4,%xmm3,%xmm4
+	vmovsd %xmm12,-0xd0(%rdx)
+	vmovq  %xmm12,%r14
+	vmovsd 0xc0(%rsp),%xmm12
+	vmovsd %xmm4,-0xc0(%rdx)
+	vfnmadd132sd %xmm9,%xmm0,%xmm12
+	vmulsd %xmm12,%xmm15,%xmm12
+	vmulsd %xmm11,%xmm2,%xmm15
+	vmovq  %xmm12,%rax
+	vmovsd %xmm12,-0xc8(%rdx)
+	vmulsd 0xb0(%rsp),%xmm2,%xmm12
+	vmovq  %xmm15,%r12
+	vmulsd %xmm15,%xmm13,%xmm15
+	vmulsd %xmm10,%xmm12,%xmm12
+	vmovsd %xmm5,%xmm5,%xmm10
+	vfnmadd132sd %xmm11,%xmm6,%xmm10
+	vmovsd %xmm12,-0xb8(%rdx)
+	vmovq  %xmm12,%rdi
+	vmulsd 0xa8(%rsp),%xmm3,%xmm12
+	vmulsd %xmm10,%xmm12,%xmm12
+	vmovsd %xmm12,-0xb0(%rdx)
+	vmulsd 0x60(%rsp),%xmm8,%xmm10
+	vmovsd %xmm15,-0xa0(%rdx)
+	vmovq  %rsi,%xmm15
+	vfnmadd231sd 0x58(%rsp),%xmm0,%xmm15
+	vmulsd 0x50(%rsp),%xmm15,%xmm15
+	vmulsd %xmm7,%xmm10,%xmm10
 	vmovsd %xmm10,-0xa8(%rdx)
-	vmovq  %xmm14,%r14
-	vmulsd 0x118(%rsp),%xmm14,%xmm14
-	vmulsd %xmm11,%xmm6,%xmm6
-	vmovq  %rax,%xmm11
-	vmovsd %xmm14,-0xa0(%rdx)
-	vmovq  %r12,%xmm14
-	vfmsub231sd %xmm11,%xmm14,%xmm6
-	vmovq  %r13,%xmm14
-	vfmadd132sd %xmm14,%xmm6,%xmm2
-	vmovsd 0x100(%rsp),%xmm6
-	vmovq  %r14,%xmm14
-	vmulsd 0xc0(%rsp),%xmm2,%xmm2
-	vfnmadd132sd %xmm4,%xmm0,%xmm6
-	vmulsd 0xb8(%rsp),%xmm6,%xmm6
-	vmovsd %xmm2,-0x88(%rdx)
-	vmulsd 0xe0(%rsp),%xmm6,%xmm3
-	vmulsd %xmm6,%xmm8,%xmm8
-	vmulsd %xmm7,%xmm14,%xmm6
-	vmovq  %r13,%xmm14
-	vmovsd %xmm6,-0x70(%rdx)
-	vmulsd %xmm7,%xmm14,%xmm6
-	vmovq  %r12,%xmm14
-	vfmsub231sd 0x118(%rsp),%xmm14,%xmm6
-	vmovsd %xmm3,-0x90(%rdx)
-	vmovsd %xmm8,-0x80(%rdx)
-	vmulsd 0xb0(%rsp),%xmm6,%xmm6
-	vmovsd %xmm6,-0x68(%rdx)
-	vmovsd -0x8(%rsi),%xmm15
-	vmovsd -0x10(%rsi),%xmm12
-	mov    -0x18(%rsi),%r8
-	vmovsd 0xa8(%rsp),%xmm11
-	vmulsd 0xa0(%rsp),%xmm6,%xmm14
-	vfnmadd132sd %xmm1,%xmm5,%xmm11
-	vfmadd132sd %xmm1,%xmm14,%xmm11
-	vmulsd 0x98(%rsp),%xmm12,%xmm14
-	vmulsd %xmm11,%xmm14,%xmm14
-	vmovsd 0x90(%rsp),%xmm11
+	vmulsd %xmm15,%xmm8,%xmm8
+	vmovsd %xmm8,-0x98(%rdx)
+	vmulsd %xmm15,%xmm7,%xmm8
+	vmovq  %rax,%xmm15
+	vmovsd %xmm8,-0x78(%rdx)
+	vmulsd 0x48(%rsp),%xmm2,%xmm8
+	vmulsd %xmm15,%xmm8,%xmm8
+	vmovq  %r14,%xmm15
+	vfmsub231sd %xmm15,%xmm1,%xmm8
+	vmovq  %r10,%xmm15
+	vfmadd132sd %xmm3,%xmm8,%xmm4
+	vmovsd 0xe8(%rsp),%xmm8
+	vmulsd 0x40(%rsp),%xmm4,%xmm4
+	vfnmadd132sd %xmm9,%xmm0,%xmm8
+	vmulsd 0x10(%rsp),%xmm8,%xmm8
+	vmovsd %xmm4,-0x88(%rdx)
+	vmulsd %xmm8,%xmm15,%xmm7
+	vmovq  %r9,%xmm15
+	vmulsd %xmm8,%xmm15,%xmm15
+	vmovsd %xmm7,-0x90(%rdx)
+	vmovsd %xmm15,-0x80(%rdx)
+	vmovq  %xmm15,%r9
+	vmovq  %r12,%xmm15
+	vmulsd %xmm15,%xmm12,%xmm8
+	vmovsd 0x28(%rsp),%xmm15
+	vmovsd %xmm8,-0x70(%rdx)
+	vmulsd %xmm12,%xmm3,%xmm8
+	vfmsub231sd %xmm13,%xmm1,%xmm8
+	vmulsd 0x8(%rsp),%xmm8,%xmm8
+	vfnmadd132sd %xmm5,%xmm6,%xmm15
+	vmovq  %xmm15,%rsi
+	vmulsd 0x20(%rsp),%xmm8,%xmm15
+	vmovsd %xmm8,-0x68(%rdx)
+	vmovq  %xmm15,%r10
+	vmovq  %rsi,%xmm15
+	vmovq  %r10,%xmm14
+	vfmadd132sd %xmm5,%xmm14,%xmm15
+	vmulsd 0x18(%rsp),%xmm1,%xmm14
+	vmulsd %xmm15,%xmm14,%xmm14
+	vmovsd 0xa0(%rsp),%xmm15
 	vmovsd %xmm14,-0x60(%rdx)
-	vmulsd 0xf8(%rsp),%xmm15,%xmm14
-	vfmadd132sd %xmm4,%xmm0,%xmm11
-	vmovq  %xmm14,%rax
-	vmulsd %xmm10,%xmm14,%xmm14
+	vmulsd 0xf8(%rsp),%xmm2,%xmm14
+	vfmadd132sd %xmm9,%xmm0,%xmm15
+	vmovq  %xmm14,%rsi
+	vmulsd %xmm14,%xmm10,%xmm14
 	vmovsd %xmm14,-0x58(%rdx)
-	vmovq  %rax,%xmm14
-	vmulsd %xmm6,%xmm14,%xmm14
+	vmovq  %rsi,%xmm14
+	vmulsd %xmm14,%xmm8,%xmm14
+	vmulsd %xmm8,%xmm3,%xmm8
 	vmovsd %xmm14,-0x18(%rdx)
-	vmulsd 0x48(%rsp),%xmm11,%xmm14
-	vmulsd 0x118(%rsp),%xmm14,%xmm11
-	vmulsd %xmm7,%xmm14,%xmm7
+	vmulsd 0x98(%rsp),%xmm15,%xmm14
+	vfmsub132sd %xmm1,%xmm8,%xmm10
+	vmulsd %xmm14,%xmm12,%xmm12
+	vmulsd %xmm14,%xmm13,%xmm13
+	vmovq  %r8,%xmm14
+	vmovsd %xmm12,-0x20(%rdx)
+	vmulsd 0x90(%rsp),%xmm9,%xmm12
+	vmovsd %xmm13,-0x50(%rdx)
+	vmulsd %xmm12,%xmm14,%xmm13
 	vmovq  %rdi,%xmm14
-	vmovsd %xmm7,-0x20(%rdx)
-	vmulsd 0x38(%rsp),%xmm4,%xmm7
-	vmovsd %xmm11,-0x50(%rdx)
-	vmulsd 0x18(%rsp),%xmm4,%xmm4
-	vmulsd %xmm14,%xmm7,%xmm11
-	vmovq  %r11,%xmm14
-	vmulsd %xmm14,%xmm7,%xmm7
-	vmovsd %xmm11,-0x48(%rdx)
-	vmovsd 0x20(%rsp),%xmm11
-	vmovsd %xmm7,-0x28(%rdx)
-	vmulsd 0x28(%rsp),%xmm15,%xmm7
-	vmulsd %xmm15,%xmm0,%xmm15
-	vmulsd %xmm0,%xmm15,%xmm15
-	vmulsd %xmm3,%xmm7,%xmm3
-	vmulsd %xmm8,%xmm7,%xmm8
-	vfmadd231sd %xmm2,%xmm12,%xmm3
-	vmulsd %xmm11,%xmm3,%xmm3
-	vmovsd %xmm3,-0x40(%rdx)
-	vmovq  %r8,%xmm3
-	vfmadd132sd %xmm3,%xmm8,%xmm2
-	vmovq  %r9,%xmm3
-	vfmsub132sd %xmm3,%xmm15,%xmm4
-	vmovq  %r8,%xmm3
-	vmulsd 0x10(%rsp),%xmm4,%xmm4
-	vmulsd %xmm6,%xmm3,%xmm6
-	vmovapd 0x1a89(%rip),%ymm3        
-	vfmsub132sd %xmm10,%xmm6,%xmm12
-	vmulsd 0x8(%rsp),%xmm12,%xmm12
-	vmulsd %xmm11,%xmm2,%xmm2
-	vmovsd 0x108(%rsp),%xmm6
-	vmovsd %xmm2,-0x30(%rdx)
-	vmovsd %xmm4,-0x38(%rdx)
-	vmovsd %xmm12,-0x10(%rdx)
-	vmovupd %ymm3,-0x360(%rcx)
-	vmovsd %xmm6,-0x238(%rcx)
+	vmulsd %xmm12,%xmm14,%xmm12
+	vmovq  %r9,%xmm14
+	vmovsd %xmm13,-0x48(%rdx)
+	vmovsd %xmm12,-0x28(%rdx)
+	vmulsd 0x88(%rsp),%xmm2,%xmm12
+	vmovsd 0x80(%rsp),%xmm15
+	vmulsd 0x78(%rsp),%xmm9,%xmm9
+	vmovsd 0x108(%rsp),%xmm13
+	vmulsd 0x68(%rsp),%xmm10,%xmm10
+	vmulsd %xmm12,%xmm7,%xmm7
+	vmulsd %xmm12,%xmm14,%xmm12
+	vmovq  %rax,%xmm14
+	vfmadd231sd %xmm4,%xmm1,%xmm7
+	vfmadd132sd %xmm3,%xmm12,%xmm4
+	vmovsd %xmm10,-0x10(%rdx)
+	vmulsd %xmm15,%xmm4,%xmm4
+	vmulsd %xmm15,%xmm7,%xmm7
+	vmovsd %xmm4,-0x30(%rdx)
+	vmulsd %xmm0,%xmm2,%xmm4
+	vmovsd %xmm7,-0x40(%rdx)
+	vmulsd %xmm4,%xmm0,%xmm7
+	vfmsub132sd %xmm14,%xmm7,%xmm9
+	vmulsd 0x70(%rsp),%xmm9,%xmm9
+	vmovsd 0x100(%rsp),%xmm7
+	vmovsd %xmm9,-0x38(%rdx)
+	vmovapd 0x8822(%rip),%ymm9        
+	vmovsd %xmm7,-0x238(%rcx)
+	vmovsd %xmm7,-0x110(%rcx)
 	movq   $0x0,-0x120(%rcx)
 	movq   $0x0,-0x240(%rcx)
 	movq   $0x0,-0x230(%rcx)
 	movq   $0x0,-0x228(%rcx)
 	movq   $0x0,-0x118(%rcx)
-	vmovsd %xmm6,-0x110(%rcx)
 	movq   $0x0,-0x108(%rcx)
-	vmovsd 0x110(%rsp),%xmm7
-	vmulsd -0x120(%rdx),%xmm7,%xmm4
-	vmovsd 0x1c1e(%rip),%xmm3        
+	vmovsd 0x89f8(%rip),%xmm7        
+	vmovupd %ymm9,-0x360(%rcx)
+	vmulsd -0x120(%rdx),%xmm13,%xmm9
 	movq   $0x0,-0x338(%rcx)
-	vmovsd 0xf0(%rsp),%xmm15
-	vmovsd %xmm4,-0x340(%rcx)
-	vmulsd -0x110(%rdx),%xmm3,%xmm2
-	vmovsd %xmm2,-0x330(%rcx)
-	vmulsd -0x118(%rdx),%xmm7,%xmm3
-	vmulsd 0x1bea(%rip),%xmm2,%xmm2        
-	vmovsd %xmm3,-0x328(%rcx)
-	vmulsd -0x110(%rdx),%xmm7,%xmm6
-	vmovsd %xmm3,-0x218(%rcx)
-	vmulsd 0x1bda(%rip),%xmm3,%xmm3        
-	vmovsd %xmm4,-0xf8(%rcx)
-	vmovsd %xmm2,-0x220(%rcx)
+	vmovsd %xmm9,-0x340(%rcx)
+	vmulsd -0x110(%rdx),%xmm7,%xmm7
+	vmovsd %xmm7,-0x330(%rcx)
+	vmulsd -0x118(%rdx),%xmm13,%xmm8
+	vmulsd 0x89bd(%rip),%xmm7,%xmm7        
+	vmovsd %xmm8,-0x328(%rcx)
+	vmulsd -0x110(%rdx),%xmm13,%xmm10
+	vmovsd %xmm7,-0x220(%rcx)
+	vmovsd %xmm10,-0x320(%rcx)
+	vmovsd %xmm8,-0x218(%rcx)
+	vmulsd 0x8995(%rip),%xmm9,%xmm10        
+	vmulsd 0x8995(%rip),%xmm8,%xmm8        
+	vmovsd %xmm7,-0xe8(%rcx)
 	movq   $0x0,-0x208(%rcx)
 	movq   $0x0,-0xe0(%rcx)
 	movq   $0x0,-0x100(%rcx)
-	vmovsd %xmm2,-0xe8(%rcx)
-	vmovsd 0x1bf9(%rip),%xmm7        
-	vmovsd %xmm6,-0x320(%rcx)
-	vmulsd 0x1b81(%rip),%xmm4,%xmm6        
-	vmovsd %xmm3,-0xf0(%rcx)
-	vmovsd %xmm6,-0x210(%rcx)
-	vxorpd %xmm13,%xmm4,%xmm6
-	vmovsd %xmm6,-0x200(%rcx)
-	vmulsd -0x108(%rdx),%xmm7,%xmm2
-	vsubsd %xmm0,%xmm1,%xmm6
-	vmovsd %xmm2,-0x318(%rcx)
-	vmulsd -0x100(%rdx),%xmm15,%xmm3
-	vxorpd %xmm13,%xmm2,%xmm2
-	vmovsd %xmm3,-0x310(%rcx)
-	vmovsd 0x1ba3(%rip),%xmm7        
-	vxorpd %xmm13,%xmm3,%xmm3
-	vmulsd -0x108(%rdx),%xmm7,%xmm4
-	vmovsd 0x1b96(%rip),%xmm7        
-	vmovsd %xmm4,-0x308(%rcx)
-	vmulsd -0xf0(%rdx),%xmm7,%xmm4
-	vmovsd 0x1b86(%rip),%xmm7        
-	vmovsd %xmm4,-0x300(%rcx)
-	vfmadd132sd -0xf8(%rdx),%xmm6,%xmm7
-	vmovsd 0x1b75(%rip),%xmm4        
-	vmulsd %xmm7,%xmm4,%xmm4
-	vmovsd 0x1b49(%rip),%xmm7        
-	vmovsd %xmm4,-0x2f8(%rcx)
-	vmulsd -0xf0(%rdx),%xmm15,%xmm4
-	vmovsd %xmm4,-0x2f0(%rcx)
-	vmulsd -0xe8(%rdx),%xmm7,%xmm7
-	vmovsd %xmm4,-0x1f0(%rcx)
-	vmovsd 0x1b49(%rip),%xmm4        
-	vmovsd %xmm7,-0x2e8(%rcx)
-	vmovsd %xmm7,-0x1f8(%rcx)
-	vmovsd 0x1b29(%rip),%xmm7        
-	vfnmadd132sd -0xf8(%rdx),%xmm6,%xmm7
-	vmulsd %xmm7,%xmm4,%xmm4
-	vmovsd 0x1afc(%rip),%xmm7        
-	vmovsd %xmm4,-0x1e8(%rcx)
-	vmulsd -0x100(%rdx),%xmm7,%xmm4
-	vmovsd 0x1adc(%rip),%xmm7        
-	vmovsd %xmm4,-0x1e0(%rcx)
-	vmulsd -0x108(%rdx),%xmm7,%xmm4
-	vmovsd %xmm3,-0x1d0(%rcx)
-	vmovsd %xmm2,-0x1c8(%rcx)
+	vmovsd %xmm9,-0xf8(%rcx)
+	vmovsd 0x89ac(%rip),%xmm7        
+	vmovsd 0xe0(%rsp),%xmm15
+	vmovsd 0x89a3(%rip),%xmm13        
+	vmovsd 0x8993(%rip),%xmm14        
+	vmovsd %xmm10,-0x210(%rcx)
+	vxorpd 0x8e0b(%rip),%xmm9,%xmm10        
+	vmovsd %xmm8,-0xf0(%rcx)
+	vmovsd %xmm10,-0x200(%rcx)
+	vmulsd -0x108(%rdx),%xmm7,%xmm7
+	vmovsd 0x8983(%rip),%xmm10        
+	vmovsd %xmm7,-0x318(%rcx)
+	vmulsd -0x100(%rdx),%xmm15,%xmm9
+	vmovsd %xmm9,-0x310(%rcx)
+	vmulsd -0x108(%rdx),%xmm13,%xmm8
+	vmovsd 0x894b(%rip),%xmm13        
+	vmovsd %xmm8,-0x308(%rcx)
+	vmulsd -0xf0(%rdx),%xmm13,%xmm8
+	vmovsd 0x893b(%rip),%xmm13        
+	vmovsd %xmm8,-0x300(%rcx)
+	vsubsd %xmm0,%xmm5,%xmm8
+	vfmadd132sd -0xf8(%rdx),%xmm8,%xmm13
+	vmulsd %xmm13,%xmm10,%xmm10
+	vmovsd %xmm10,-0x2f8(%rcx)
+	vmulsd -0xf0(%rdx),%xmm15,%xmm10
+	vmovsd %xmm10,-0x2f0(%rcx)
+	vmulsd -0xe8(%rdx),%xmm14,%xmm12
+	vmovsd %xmm12,-0x2e8(%rcx)
+	vmovsd %xmm12,-0x1f8(%rcx)
+	vmovsd 0x88f9(%rip),%xmm13        
+	vmovsd %xmm10,-0x1f0(%rcx)
+	vfnmadd132sd -0xf8(%rdx),%xmm8,%xmm13
+	vmovsd 0x88e8(%rip),%xmm10        
+	vmovsd 0x88b8(%rip),%xmm14        
+	vxorpd 0x8d30(%rip),%xmm9,%xmm9        
+	vxorpd 0x8d28(%rip),%xmm7,%xmm7        
+	vmulsd %xmm13,%xmm10,%xmm10
+	vmovsd 0x88a3(%rip),%xmm13        
+	vmovsd %xmm10,-0x1e8(%rcx)
+	vmulsd -0x100(%rdx),%xmm13,%xmm10
+	vmovsd %xmm10,-0x1e0(%rcx)
+	vmulsd -0x108(%rdx),%xmm14,%xmm10
+	vmovsd %xmm9,-0x1d0(%rcx)
+	vmovsd %xmm7,-0x1c8(%rcx)
 	movq   $0x0,-0xd8(%rcx)
-	vmovsd %xmm4,-0x1d8(%rcx)
-	vmulsd -0x108(%rdx),%xmm15,%xmm2
-	vmovsd %xmm2,-0xd0(%rcx)
-	vmovsd 0x1ac1(%rip),%xmm7        
-	vmovsd 0x100(%rsp),%xmm11
-	vmulsd -0x100(%rdx),%xmm7,%xmm2
-	vmovsd 0x1ab0(%rip),%xmm7        
-	vmovsd %xmm2,-0xc8(%rcx)
-	vmulsd -0xf8(%rdx),%xmm7,%xmm2
-	vmovsd 0x1a90(%rip),%xmm7        
-	vmovsd %xmm2,-0xc0(%rcx)
-	vmulsd -0xf0(%rdx),%xmm7,%xmm2
-	vmovsd 0x1b28(%rip),%xmm7        
-	vmovsd %xmm2,-0xb8(%rcx)
-	vmulsd -0xe8(%rdx),%xmm15,%xmm2
+	vmovsd %xmm10,-0x1d8(%rcx)
+	vmulsd -0x108(%rdx),%xmm15,%xmm7
+	vmovsd %xmm7,-0xd0(%rcx)
+	vmovsd 0x8870(%rip),%xmm7        
+	vmulsd -0x100(%rdx),%xmm7,%xmm7
+	vmovsd %xmm7,-0xc8(%rcx)
+	vmovsd 0x8860(%rip),%xmm7        
+	vmulsd -0xf8(%rdx),%xmm7,%xmm7
+	vmovsd %xmm7,-0xc0(%rcx)
+	vmovsd 0x8840(%rip),%xmm7        
+	vmulsd -0xf0(%rdx),%xmm7,%xmm7
+	vmovsd %xmm7,-0xb8(%rcx)
+	vmulsd -0xe8(%rdx),%xmm15,%xmm7
 	movq   $0x0,-0xa8(%rcx)
-	vmovsd 0x1b1d(%rip),%xmm15        
-	vmovsd %xmm2,-0xb0(%rcx)
-	vmulsd -0xe0(%rdx),%xmm7,%xmm4
-	vmovsd 0x1af5(%rip),%xmm7        
-	vmovsd -0x8(%rsi),%xmm3
-	vmovsd -0x10(%rsi),%xmm2
-	vmovsd -0x18(%rsi),%xmm10
-	vmulsd 0x1ae6(%rip),%xmm2,%xmm8        
-	vmulsd 0x1af6(%rip),%xmm2,%xmm2        
-	vmovsd %xmm4,-0x2e0(%rcx)
-	vmulsd -0xd8(%rdx),%xmm7,%xmm7
-	vxorpd %xmm13,%xmm4,%xmm4
-	vmovsd %xmm7,-0x2d8(%rcx)
-	vfmadd132sd -0xf8(%rdx),%xmm1,%xmm11
-	vxorpd %xmm13,%xmm7,%xmm7
-	vmulsd %xmm11,%xmm8,%xmm11
-	vmovsd %xmm11,-0x2d0(%rcx)
-	vmulsd -0xd8(%rdx),%xmm15,%xmm11
-	vmovsd 0x1aa6(%rip),%xmm15        
-	vmovsd %xmm11,-0x2c8(%rcx)
-	vmulsd -0xc0(%rdx),%xmm15,%xmm12
-	vmovsd %xmm12,-0x2c0(%rcx)
-	vmulsd -0x100(%rdx),%xmm2,%xmm2
-	vmovsd 0x1a8e(%rip),%xmm15        
-	vfmsub231sd %xmm3,%xmm0,%xmm2
-	vfnmadd231sd -0xc8(%rdx),%xmm15,%xmm2
-	vmovsd 0x1a48(%rip),%xmm15        
-	vmulsd 0x1a78(%rip),%xmm2,%xmm2        
-	vmovsd %xmm2,-0x2b8(%rcx)
-	vmulsd 0x1a70(%rip),%xmm10,%xmm2        
+	vmovsd %xmm7,-0xb0(%rcx)
+	vmovsd 0x885d(%rip),%xmm7        
+	vmulsd -0xe0(%rdx),%xmm7,%xmm7
+	vmovsd %xmm7,-0x2e0(%rcx)
+	vmovsd 0x884d(%rip),%xmm9        
+	vmovsd 0xe8(%rsp),%xmm10
+	vmulsd -0xd8(%rdx),%xmm9,%xmm9
+	vmulsd 0x883c(%rip),%xmm1,%xmm12        
+	vmovsd 0x883c(%rip),%xmm13        
+	vmovsd 0x883c(%rip),%xmm14        
+	vmovsd 0xf0(%rsp),%xmm15
+	vmovsd %xmm9,-0x2d8(%rcx)
+	vfmadd132sd -0xf8(%rdx),%xmm5,%xmm10
+	vfnmadd132sd %xmm0,%xmm5,%xmm15
+	vmulsd %xmm10,%xmm12,%xmm10
+	vmovsd %xmm10,-0x2d0(%rcx)
+	vmulsd -0xd8(%rdx),%xmm13,%xmm13
+	vmovsd %xmm13,-0x2c8(%rcx)
+	vmulsd -0xc0(%rdx),%xmm14,%xmm10
+	vmovsd 0x8800(%rip),%xmm14        
+	vmovsd %xmm10,-0x2c0(%rcx)
+	vmulsd 0x87e8(%rip),%xmm1,%xmm10        
+	vfnmadd231sd -0x100(%rdx),%xmm10,%xmm4
 	vmovsd %xmm0,%xmm0,%xmm10
-	vfnmadd132sd %xmm9,%xmm5,%xmm10
-	vsubsd %xmm0,%xmm5,%xmm5
-	vmulsd %xmm10,%xmm2,%xmm10
+	vfnmadd132sd %xmm11,%xmm6,%xmm10
+	vsubsd %xmm0,%xmm6,%xmm6
+	vfnmadd231sd -0xc8(%rdx),%xmm14,%xmm4
+	vmovsd 0x87a1(%rip),%xmm14        
+	vmulsd 0x87c9(%rip),%xmm4,%xmm4        
+	vmovsd %xmm4,-0x2b8(%rcx)
+	vmulsd 0x87c1(%rip),%xmm3,%xmm4        
+	vmulsd %xmm10,%xmm4,%xmm10
 	vmovsd %xmm10,-0x2b0(%rcx)
-	vmovsd 0x1a16(%rip),%xmm10        
-	vmulsd -0xb8(%rdx),%xmm10,%xmm10
+	vmulsd -0xb8(%rdx),%xmm14,%xmm10
+	vmovsd 0x8764(%rip),%xmm14        
 	vmovsd %xmm10,-0x2a8(%rcx)
-	vmulsd -0xb0(%rdx),%xmm15,%xmm12
-	vmovsd 0x1a36(%rip),%xmm15        
+	vmulsd -0xb0(%rdx),%xmm14,%xmm14
 	vmovsd %xmm10,-0x1b8(%rcx)
-	vmovsd %xmm12,-0x2a0(%rcx)
-	vmovsd %xmm12,-0x1c0(%rcx)
-	vmovsd 0xe8(%rsp),%xmm12
-	vfnmadd132sd %xmm0,%xmm1,%xmm12
-	vfnmadd231sd -0xf8(%rdx),%xmm15,%xmm12
-	vmulsd %xmm12,%xmm2,%xmm2
-	vmovsd %xmm1,%xmm1,%xmm12
-	vfmsub132sd %xmm9,%xmm0,%xmm12
-	vmovsd %xmm2,-0x1b0(%rcx)
-	vmovsd 0x19f1(%rip),%xmm2        
-	vmulsd -0xc8(%rdx),%xmm2,%xmm2
-	vfmsub132sd %xmm12,%xmm2,%xmm3
-	vmulsd 0x19c4(%rip),%xmm3,%xmm3        
-	vmovsd 0x19a4(%rip),%xmm2        
-	vmovsd %xmm3,-0x1a8(%rcx)
-	vmulsd -0xd0(%rdx),%xmm2,%xmm2
-	vmovsd %xmm11,-0x198(%rcx)
-	vmovsd %xmm7,-0x188(%rcx)
-	vmovsd %xmm4,-0x180(%rcx)
+	vmovsd %xmm14,-0x2a0(%rcx)
+	vmovsd %xmm14,-0x1c0(%rcx)
+	vmovsd 0x877c(%rip),%xmm14        
+	vfnmadd231sd -0xf8(%rdx),%xmm14,%xmm15
+	vmulsd %xmm15,%xmm4,%xmm4
+	vmovsd %xmm4,-0x1b0(%rcx)
+	vmovsd 0x8766(%rip),%xmm14        
+	vmovsd %xmm5,%xmm5,%xmm4
+	vxorpd 0x8b0a(%rip),%xmm9,%xmm9        
+	vmulsd -0xc8(%rdx),%xmm14,%xmm14
+	vfmsub132sd %xmm11,%xmm0,%xmm4
+	vxorpd 0x8af5(%rip),%xmm7,%xmm7        
+	vfmsub132sd %xmm2,%xmm14,%xmm4
+	vmulsd 0x8720(%rip),%xmm4,%xmm4        
+	vmovsd %xmm4,-0x1a8(%rcx)
+	vmovsd 0x86f8(%rip),%xmm4        
+	vmulsd -0xd0(%rdx),%xmm4,%xmm4
+	vmovsd %xmm13,-0x198(%rcx)
+	vmovsd %xmm9,-0x188(%rcx)
+	vmovsd %xmm7,-0x180(%rcx)
 	movq   $0x0,-0xa0(%rcx)
-	vmovsd %xmm2,-0x1a0(%rcx)
-	vmovsd %xmm0,%xmm0,%xmm2
-	vfnmadd132sd %xmm9,%xmm1,%xmm2
-	vmulsd %xmm2,%xmm8,%xmm8
-	vmovsd %xmm8,-0x190(%rcx)
-	vmulsd -0xe0(%rdx),%xmm9,%xmm2
-	vmovsd %xmm2,-0x98(%rcx)
-	vmovsd 0x1974(%rip),%xmm4        
-	vmovsd 0x1984(%rip),%xmm7        
-	vmulsd -0xd8(%rdx),%xmm4,%xmm2
-	vmovsd 0x1964(%rip),%xmm4        
-	vmovsd 0x1974(%rip),%xmm8        
-	vmovsd %xmm2,-0x90(%rcx)
-	vmulsd -0xd0(%rdx),%xmm4,%xmm2
-	vmovsd 0x194c(%rip),%xmm4        
-	vmovsd %xmm2,-0x88(%rcx)
-	vmulsd -0xc8(%rdx),%xmm4,%xmm2
-	vmovsd 0x192c(%rip),%xmm4        
-	vmovsd %xmm2,-0x80(%rcx)
-	vmulsd -0xc0(%rdx),%xmm4,%xmm2
-	vmovsd 0x190f(%rip),%xmm4        
-	vmovsd %xmm2,-0x78(%rcx)
-	vmulsd -0xb8(%rdx),%xmm4,%xmm2
-	vmovsd %xmm2,-0x70(%rcx)
-	vmulsd -0xb0(%rdx),%xmm9,%xmm2
+	vmovsd 0x8705(%rip),%xmm7        
+	vmovsd %xmm4,-0x1a0(%rcx)
+	vmovsd %xmm0,%xmm0,%xmm4
+	vfnmadd132sd %xmm11,%xmm5,%xmm4
+	vmulsd %xmm4,%xmm12,%xmm12
+	vmovsd %xmm12,-0x190(%rcx)
+	vmulsd -0xe0(%rdx),%xmm11,%xmm4
+	vmovsd %xmm4,-0x98(%rcx)
+	vmovsd 0x86c8(%rip),%xmm4        
+	vmulsd -0xd8(%rdx),%xmm4,%xmm4
+	vmovsd %xmm4,-0x90(%rcx)
+	vmulsd -0xd0(%rdx),%xmm7,%xmm4
+	vmovsd %xmm4,-0x88(%rcx)
+	vmovsd 0x86b0(%rip),%xmm4        
+	vmulsd -0xc8(%rdx),%xmm4,%xmm4
+	vmovsd %xmm4,-0x80(%rcx)
+	vmulsd -0xc0(%rdx),%xmm7,%xmm4
+	vmovsd %xmm4,-0x78(%rcx)
+	vmovsd 0x867e(%rip),%xmm4        
+	vmulsd -0xb8(%rdx),%xmm4,%xmm4
+	vmovsd %xmm4,-0x70(%rcx)
+	vmulsd -0xb0(%rdx),%xmm11,%xmm4
+	vmovsd %xmm4,-0x68(%rcx)
 	movq   $0x0,-0x60(%rcx)
-	vmovsd %xmm2,-0x68(%rcx)
-	vmulsd -0xa8(%rdx),%xmm7,%xmm7
-	vmovsd -0x8(%rsi),%xmm4
-	vmovsd -0x10(%rsi),%xmm2
-	vmovsd -0x18(%rsi),%xmm3
-	vmulsd 0x18f1(%rip),%xmm3,%xmm3        
-	vmovsd %xmm7,-0x298(%rcx)
-	vmulsd -0xa0(%rdx),%xmm8,%xmm8
-	vxorpd %xmm13,%xmm7,%xmm7
-	vmovsd %xmm8,-0x290(%rcx)
+	vmovsd 0x86cc(%rip),%xmm7        
+	vmulsd 0x86d4(%rip),%xmm3,%xmm3        
+	vmulsd -0xa8(%rdx),%xmm7,%xmm4
+	vmovsd 0x86bc(%rip),%xmm7        
+	vmulsd 0x86ec(%rip),%xmm0,%xmm12        
+	vmulsd 0x86cc(%rip),%xmm6,%xmm6        
+	vmovsd %xmm4,-0x298(%rcx)
+	vmulsd -0xa0(%rdx),%xmm7,%xmm7
+	vmovsd %xmm7,-0x290(%rcx)
 	vmulsd -0xd0(%rdx),%xmm3,%xmm3
-	vxorpd %xmm13,%xmm8,%xmm8
-	vfmadd231sd -0x108(%rdx),%xmm1,%xmm3
-	vmulsd 0x18be(%rip),%xmm3,%xmm3        
+	vfmadd231sd -0x108(%rdx),%xmm5,%xmm3
+	vmulsd 0x868b(%rip),%xmm3,%xmm3        
 	vmovsd %xmm3,-0x288(%rcx)
-	vmovsd -0x100(%rdx),%xmm3
-	vmovsd 0x18ae(%rip),%xmm12        
-	vmulsd 0x18ae(%rip),%xmm5,%xmm5        
-	vmulsd %xmm3,%xmm0,%xmm11
-	vfmsub132sd %xmm1,%xmm11,%xmm3
-	vfmadd231sd -0xa0(%rdx),%xmm12,%xmm3
-	vmulsd 0x18ac(%rip),%xmm0,%xmm12        
-	vmulsd 0x188c(%rip),%xmm3,%xmm3        
+	vmovsd 0x8683(%rip),%xmm3        
+	vmulsd -0xa0(%rdx),%xmm3,%xmm3
+	vfmadd231sd -0x100(%rdx),%xmm8,%xmm3
+	vmulsd 0x8672(%rip),%xmm3,%xmm3        
 	vmovsd %xmm3,-0x280(%rcx)
-	vmovsd 0x1884(%rip),%xmm3        
-	vmulsd -0x98(%rdx),%xmm3,%xmm11
-	vmovsd 0x187c(%rip),%xmm3        
-	vmovsd %xmm11,-0x278(%rcx)
+	vmovsd 0x866a(%rip),%xmm3        
+	vmulsd -0x98(%rdx),%xmm3,%xmm9
+	vmovsd 0x8662(%rip),%xmm3        
+	vmovsd %xmm9,-0x278(%rcx)
 	vmulsd -0x80(%rdx),%xmm3,%xmm3
 	vmovsd %xmm3,-0x270(%rcx)
 	vmovsd -0x100(%rdx),%xmm3
-	vmulsd 0x1867(%rip),%xmm3,%xmm15        
-	vmulsd %xmm3,%xmm15,%xmm3
+	vmulsd 0x864d(%rip),%xmm3,%xmm13        
+	vmulsd %xmm3,%xmm13,%xmm3
+	vmovsd 0x8649(%rip),%xmm13        
 	vfmadd231sd %xmm12,%xmm0,%xmm3
-	vfmadd231sd -0xf8(%rdx),%xmm6,%xmm3
-	vmovsd 0x1855(%rip),%xmm12        
-	vfmadd231sd -0x78(%rdx),%xmm12,%xmm3
-	vmulsd 0x184f(%rip),%xmm3,%xmm3        
+	vfmadd231sd -0xf8(%rdx),%xmm8,%xmm3
+	vfmadd231sd -0x78(%rdx),%xmm13,%xmm3
+	vmulsd 0x8635(%rip),%xmm3,%xmm3        
 	vmovsd %xmm3,-0x268(%rcx)
-	vmulsd -0xf0(%rdx),%xmm5,%xmm5
-	vmulsd 0x183f(%rip),%xmm4,%xmm3        
-	vmovsd %xmm5,-0x260(%rcx)
-	vmulsd 0x1837(%rip),%xmm2,%xmm5        
-	vmulsd -0xe0(%rdx),%xmm5,%xmm5
-	vfmsub132sd %xmm3,%xmm5,%xmm10
+	vmulsd -0xf0(%rdx),%xmm6,%xmm6
+	vmovsd %xmm6,-0x260(%rcx)
+	vmulsd 0x8625(%rip),%xmm1,%xmm3        
+	vmulsd 0x8615(%rip),%xmm2,%xmm6        
+	vmulsd -0xe0(%rdx),%xmm3,%xmm3
+	vfmsub132sd %xmm6,%xmm3,%xmm10
 	vsubsd -0x78(%rdx),%xmm10,%xmm10
-	vmovsd 0x17bd(%rip),%xmm5        
-	vmulsd 0x181d(%rip),%xmm10,%xmm10        
+	vmovsd 0x85a3(%rip),%xmm6        
+	vmulsd 0x8603(%rip),%xmm10,%xmm10        
 	vmovsd %xmm10,-0x258(%rcx)
-	vmulsd -0x70(%rdx),%xmm5,%xmm3
-	vmovsd 0x1810(%rip),%xmm5        
+	vmulsd -0x70(%rdx),%xmm6,%xmm3
+	vmovsd 0x85f6(%rip),%xmm6        
 	vmovsd %xmm3,-0x250(%rcx)
-	vmulsd -0x68(%rdx),%xmm5,%xmm5
+	vmulsd -0x68(%rdx),%xmm6,%xmm6
 	vmovsd %xmm3,-0x170(%rcx)
-	vmulsd 0x17fb(%rip),%xmm2,%xmm3        
-	vmulsd 0x1833(%rip),%xmm6,%xmm6        
-	vmovsd %xmm5,-0x248(%rcx)
-	vmovsd %xmm5,-0x178(%rcx)
-	vmulsd 0x17e3(%rip),%xmm4,%xmm5        
-	vmulsd 0x1803(%rip),%xmm4,%xmm4        
-	vmulsd -0xb8(%rdx),%xmm5,%xmm5
-	vfmsub132sd -0xe0(%rdx),%xmm5,%xmm3
-	vmovsd 0x17da(%rip),%xmm5        
+	vmulsd 0x85e1(%rip),%xmm1,%xmm3        
+	vmovsd %xmm6,-0x248(%rcx)
+	vmovsd %xmm6,-0x178(%rcx)
+	vmulsd 0x85d1(%rip),%xmm2,%xmm6        
+	vmulsd 0x85f1(%rip),%xmm2,%xmm2        
+	vmulsd -0xb8(%rdx),%xmm6,%xmm6
+	vfmsub132sd -0xe0(%rdx),%xmm6,%xmm3
+	vmovsd 0x85c8(%rip),%xmm6        
 	vsubsd -0x78(%rdx),%xmm3,%xmm3
-	vmulsd 0x17bd(%rip),%xmm3,%xmm3        
+	vmulsd 0x85ab(%rip),%xmm3,%xmm3        
 	vmovsd %xmm3,-0x168(%rcx)
-	vmovsd 0x16f5(%rip),%xmm3        
-	vfnmadd132sd -0xf8(%rdx),%xmm1,%xmm3
-	vmulsd 0x17a4(%rip),%xmm3,%xmm3        
+	vmovsd 0x8483(%rip),%xmm3        
+	vfnmadd132sd -0xf8(%rdx),%xmm5,%xmm3
+	vmulsd 0x8592(%rip),%xmm3,%xmm3        
 	vmulsd -0xf0(%rdx),%xmm3,%xmm3
 	vmovsd %xmm3,-0x160(%rcx)
-	vmulsd -0xd0(%rdx),%xmm5,%xmm3
-	vmovsd 0x1794(%rip),%xmm5        
-	vmulsd -0xc8(%rdx),%xmm4,%xmm4
-	vfmsub231sd -0xe0(%rdx),%xmm5,%xmm3
-	vmovsd 0x170b(%rip),%xmm5        
-	vfmadd132sd %xmm3,%xmm4,%xmm2
-	vaddsd -0x68(%rdx),%xmm2,%xmm2
-	vmulsd 0x1779(%rip),%xmm2,%xmm2        
-	vmovsd %xmm2,-0x158(%rcx)
-	vmulsd -0x90(%rdx),%xmm5,%xmm2
-	vmovsd %xmm11,-0x148(%rcx)
-	vmovsd %xmm2,-0x150(%rcx)
-	vmulsd -0x100(%rdx),%xmm6,%xmm6
-	vmovsd %xmm6,-0x140(%rcx)
-	vfnmadd132sd 0x1750(%rip),%xmm1,%xmm0        
-	vmovsd 0x1658(%rip),%xmm5        
-	vfnmadd231sd -0xf8(%rdx),%xmm5,%xmm0
-	vmovsd 0x1687(%rip),%xmm5        
-	vmulsd -0x108(%rdx),%xmm5,%xmm1
-	vmovsd %xmm8,-0x130(%rcx)
-	vmovsd %xmm7,-0x128(%rcx)
+	vmulsd -0xd0(%rdx),%xmm6,%xmm3
+	vmovsd 0x8582(%rip),%xmm6        
+	vmulsd -0xc8(%rdx),%xmm2,%xmm2
+	vfmsub231sd -0xe0(%rdx),%xmm6,%xmm3
+	vfmadd132sd %xmm3,%xmm2,%xmm1
+	vaddsd -0x68(%rdx),%xmm1,%xmm1
+	vmovsd 0x84ef(%rip),%xmm2        
+	vmulsd 0x856f(%rip),%xmm8,%xmm8        
+	vfnmadd132sd 0x856e(%rip),%xmm5,%xmm0        
+	vxorpd 0x87ce(%rip),%xmm7,%xmm7        
+	vxorpd 0x87c6(%rip),%xmm4,%xmm4        
+	vmulsd 0x8546(%rip),%xmm1,%xmm1        
+	vmovsd %xmm1,-0x158(%rcx)
+	vmulsd -0x90(%rdx),%xmm2,%xmm1
+	vmovsd %xmm9,-0x148(%rcx)
+	vmovsd 0x83e6(%rip),%xmm2        
+	vmovsd %xmm1,-0x150(%rcx)
+	vmulsd -0x100(%rdx),%xmm8,%xmm8
+	vmovsd 0x846e(%rip),%xmm1        
+	vmovsd %xmm8,-0x140(%rcx)
+	vfnmadd231sd -0xf8(%rdx),%xmm2,%xmm0
+	vmulsd -0x108(%rdx),%xmm1,%xmm5
+	vmovsd %xmm7,-0x130(%rcx)
+	vmovsd %xmm4,-0x128(%rcx)
 	movq   $0x0,-0x58(%rcx)
-	vmovsd 0x1717(%rip),%xmm5        
-	vmulsd %xmm0,%xmm1,%xmm0
-	vmovsd 0xf8(%rsp),%xmm1
+	vmovsd 0x84ed(%rip),%xmm2        
+	vmovsd 0x84ed(%rip),%xmm1        
+	vmulsd %xmm0,%xmm5,%xmm0
+	vmovsd 0xf8(%rsp),%xmm5
 	vmovsd %xmm0,-0x138(%rcx)
-	vmulsd -0xa8(%rdx),%xmm1,%xmm0
+	vmulsd -0xa8(%rdx),%xmm5,%xmm0
 	vmovsd %xmm0,-0x50(%rcx)
-	vmulsd -0xa0(%rdx),%xmm5,%xmm0
-	vmovsd 0x16ed(%rip),%xmm5        
+	vmulsd -0xa0(%rdx),%xmm2,%xmm0
+	vmovsd 0x84c3(%rip),%xmm2        
 	vmovsd %xmm0,-0x48(%rcx)
-	vmulsd -0x98(%rdx),%xmm5,%xmm0
-	vmovsd 0x16e0(%rip),%xmm5        
+	vmulsd -0x98(%rdx),%xmm1,%xmm0
 	vmovsd %xmm0,-0x40(%rcx)
-	vmulsd -0x90(%rdx),%xmm5,%xmm0
-	vmovsd 0x16d3(%rip),%xmm5        
+	vmulsd -0x90(%rdx),%xmm2,%xmm0
 	vmovsd %xmm0,-0x38(%rcx)
-	vmulsd -0x88(%rdx),%xmm5,%xmm0
-	vmovsd 0x16b6(%rip),%xmm5        
+	vmovsd 0x84a4(%rip),%xmm1        
+	vmovsd 0x8484(%rip),%xmm6        
+	vmulsd -0x88(%rdx),%xmm1,%xmm0
+	vmovsd 0x847c(%rip),%xmm1        
 	vmovsd %xmm0,-0x30(%rcx)
-	vmulsd -0x80(%rdx),%xmm5,%xmm0
-	vmovsd 0x169c(%rip),%xmm5        
+	vmulsd -0x80(%rdx),%xmm2,%xmm0
 	vmovsd %xmm0,-0x28(%rcx)
-	vmulsd -0x78(%rdx),%xmm5,%xmm0
-	vmovsd 0x1682(%rip),%xmm5        
+	vmulsd -0x78(%rdx),%xmm1,%xmm0
 	vmovsd %xmm0,-0x20(%rcx)
-	vmulsd -0x70(%rdx),%xmm5,%xmm0
+	vmulsd -0x70(%rdx),%xmm6,%xmm0
 	vmovsd %xmm0,-0x18(%rcx)
-	vmulsd -0x68(%rdx),%xmm1,%xmm0
+	vmulsd -0x68(%rdx),%xmm5,%xmm0
 	movq   $0x0,-0x8(%rcx)
 	vmovsd %xmm0,-0x10(%rcx)
-	cmp    %r10,%rdx
-	jne    71e0 <cartesian_spherical_harmonics_l5._omp_fn.0+0x2b0>
+	cmp    %rdx,%rbx
+	jne    4450 <cartesian_spherical_harmonics_l5._omp_fn.0+0x2b0>
 	vzeroupper
-	add    $0x128,%rsp
+	add    $0x118,%rsp
 	pop    %rbx
 	pop    %r12
 	pop    %r13
 	pop    %r14
 	pop    %r15
 	pop    %rbp
 	ret
-	nopl   (%rax)
+	nop
 	cmp    %edx,%esi
-	jl     84e0 <cartesian_spherical_harmonics_l5._omp_fn.0+0x15b0>
+	jl     56c0 <cartesian_spherical_harmonics_l5._omp_fn.0+0x1520>
 	imul   %eax,%esi
 	add    %esi,%edx
 	lea    (%rax,%rdx,1),%ecx
 	cmp    %ecx,%edx
-	jge    7ebb <cartesian_spherical_harmonics_l5._omp_fn.0+0xf8b>
-	vmovsd 0x1364(%rip),%xmm1        
-	lea    (%rdx,%rdx,2),%esi
-	vmovsd 0x1351(%rip),%xmm14        
-	lea    (%rdx,%rdx,8),%ecx
-	movslq %esi,%rsi
-	vmovsd 0x139b(%rip),%xmm9        
+	jge    50cd <cartesian_spherical_harmonics_l5._omp_fn.0+0xf2d>
+	vmovsd 0x8154(%rip),%xmm5        
+	vmovsd 0x8144(%rip),%xmm15        
+	lea    (%rdx,%rdx,2),%ecx
 	dec    %eax
+	vmovsd 0x817f(%rip),%xmm11        
+	mov    0x8128(%rip),%r13        
+	movslq %ecx,%rcx
+	lea    (%rbx,%rcx,8),%r9
+	lea    (%rdx,%rdx,8),%ecx
 	movslq %edx,%rdx
-	lea    (%rbx,%rsi,8),%rsi
-	mov    0x132b(%rip),%rbx        
 	add    %rax,%rdx
 	shl    $0x2,%ecx
 	lea    (%rdx,%rdx,8),%rax
 	movslq %ecx,%rcx
 	shl    $0x5,%rax
 	lea    (%r12,%rcx,8),%rcx
-	lea    0x120(%r12,%rax,1),%r8
-	vmovsd %xmm1,0x110(%rsp)
-	vmovsd 0x1315(%rip),%xmm1        
-	vmovsd %xmm1,0xe8(%rsp)
-	vmovsd 0x130c(%rip),%xmm1        
-	vmovsd %xmm1,0x40(%rsp)
-	vmovsd 0x1306(%rip),%xmm1        
-	vmovsd %xmm1,0x30(%rsp)
-	vmovsd 0x1338(%rip),%xmm1        
-	vmovsd %xmm1,0x88(%rsp)
-	vmovsd 0x132f(%rip),%xmm1        
-	vmovsd %xmm1,0xf0(%rsp)
-	vmovsd 0x1326(%rip),%xmm1        
+	lea    0x120(%r12,%rax,1),%r11
+	vmovsd %xmm5,0x108(%rsp)
+	vmovsd 0x8105(%rip),%xmm5        
+	vmovsd %xmm5,0xf0(%rsp)
+	vmovsd 0x80fc(%rip),%xmm5        
+	vmovsd %xmm5,0x38(%rsp)
+	vmovsd 0x80f6(%rip),%xmm5        
+	vmovsd %xmm5,0x30(%rsp)
+	vmovsd 0x8118(%rip),%xmm5        
+	vmovsd %xmm5,0xd8(%rsp)
+	vmovsd 0x810f(%rip),%xmm5        
+	vmovsd %xmm5,0x100(%rsp)
+	vmovsd 0x8106(%rip),%xmm5        
+	vmovsd %xmm5,0xd0(%rsp)
+	vmovsd 0x80fd(%rip),%xmm5        
+	vmovsd %xmm5,0xc8(%rsp)
+	vmovsd 0x80f4(%rip),%xmm5        
+	vmovsd %xmm5,0xc0(%rsp)
+	vmovsd 0x80eb(%rip),%xmm5        
+	vmovsd %xmm5,0xb8(%rsp)
+	vmovsd 0x80e2(%rip),%xmm5        
+	vmovsd %xmm5,0xb0(%rsp)
+	vmovsd 0x80d9(%rip),%xmm5        
+	vmovsd %xmm5,0xa8(%rsp)
+	vmovsd 0x8118(%rip),%xmm5        
+	vmovsd %xmm5,0x60(%rsp)
+	vmovsd 0x8112(%rip),%xmm5        
+	vmovsd %xmm5,0x58(%rsp)
+	vmovsd 0x810c(%rip),%xmm5        
+	vmovsd %xmm5,0x50(%rsp)
+	vmovsd 0x8106(%rip),%xmm5        
+	vmovsd 0x81e6(%rip),%xmm6        
+	vmovsd %xmm5,0x48(%rsp)
+	vmovsd 0x80f8(%rip),%xmm5        
+	vmovsd %xmm6,0x70(%rsp)
+	vmovsd %xmm5,0x40(%rsp)
+	vmovsd 0x80ec(%rip),%xmm5        
+	vmovsd %xmm5,0xe8(%rsp)
+	vmovsd 0x80e3(%rip),%xmm5        
+	vmovsd %xmm5,0x10(%rsp)
+	vmovsd 0x80dd(%rip),%xmm5        
+	vmovsd %xmm5,0x8(%rsp)
+	vmovsd 0x8147(%rip),%xmm5        
+	vmovsd %xmm5,0x28(%rsp)
+	vmovsd 0x8141(%rip),%xmm5        
+	vmovsd %xmm5,0x20(%rsp)
+	vmovsd 0x813b(%rip),%xmm5        
+	vmovsd %xmm5,0x18(%rsp)
+	vmovsd 0x8135(%rip),%xmm5        
+	vmovsd %xmm5,0xf8(%rsp)
+	vmovsd 0x812c(%rip),%xmm5        
+	vmovsd %xmm5,0xa0(%rsp)
+	vmovsd 0x8123(%rip),%xmm5        
+	vmovsd %xmm5,0x98(%rsp)
+	vmovsd 0x811a(%rip),%xmm5        
+	vmovsd %xmm5,0x90(%rsp)
+	vmovsd 0x8111(%rip),%xmm5        
+	vmovsd %xmm5,0x88(%rsp)
+	vmovsd 0x8108(%rip),%xmm5        
+	vmovsd %xmm5,0x80(%rsp)
+	vmovsd 0x80ff(%rip),%xmm5        
+	vmovsd %xmm5,0x78(%rsp)
+	vmovsd 0x8101(%rip),%xmm5        
+	vmovsd %xmm11,0xe0(%rsp)
+	vmovsd %xmm15,(%rsp)
+	vmovsd %xmm5,0x68(%rsp)
+	nopl   0x0(%rax,%rax,1)
+	vmovsd 0x10(%r9),%xmm1
+	add    $0x120,%rcx
+	add    $0x18,%r9
+	vmovsd -0x18(%r9),%xmm4
+	vmovsd -0x10(%r9),%xmm2
+	mov    %r13,-0x120(%rcx)
+	vmovsd (%rsp),%xmm3
+	vmovsd 0x108(%rsp),%xmm7
+	vmulsd 0xd8(%rsp),%xmm2,%xmm8
+	vmovsd 0xc0(%rsp),%xmm14
+	vmulsd %xmm1,%xmm1,%xmm6
+	vmulsd %xmm2,%xmm2,%xmm9
+	vmulsd %xmm3,%xmm2,%xmm0
+	vmulsd %xmm3,%xmm1,%xmm5
+	vmulsd %xmm3,%xmm4,%xmm3
+	vmovsd %xmm0,-0x118(%rcx)
+	vmulsd %xmm4,%xmm4,%xmm10
+	vmovsd %xmm5,-0x110(%rcx)
+	vmovsd %xmm3,-0x108(%rcx)
+	vmulsd %xmm7,%xmm4,%xmm3
+	vaddsd %xmm9,%xmm10,%xmm15
+	vmulsd %xmm3,%xmm0,%xmm12
+	vmulsd %xmm3,%xmm5,%xmm5
+	vmulsd %xmm7,%xmm1,%xmm3
+	vmovsd %xmm5,-0xe8(%rcx)
+	vmovq  %xmm5,%r10
+	vsubsd %xmm9,%xmm10,%xmm7
+	vmulsd 0x30(%rsp),%xmm7,%xmm11
+	vmovsd %xmm12,-0x100(%rcx)
+	vmulsd %xmm0,%xmm3,%xmm5
+	vmovsd 0xe0(%rsp),%xmm3
+	vmovsd %xmm5,-0xf8(%rcx)
+	vmovq  %xmm5,%rbx
+	vmovsd 0xf0(%rsp),%xmm5
+	vmovsd %xmm3,%xmm3,%xmm0
+	vmovsd %xmm11,-0xe0(%rcx)
+	vfnmadd132sd %xmm10,%xmm9,%xmm0
+	vfnmadd132sd %xmm6,%xmm15,%xmm5
+	vmulsd 0x38(%rsp),%xmm5,%xmm5
+	vmulsd %xmm0,%xmm8,%xmm8
+	vmulsd 0x100(%rsp),%xmm1,%xmm0
+	vmovsd %xmm8,-0xd8(%rcx)
+	vfnmadd132sd %xmm5,%xmm6,%xmm14
+	vmovsd %xmm5,-0xf0(%rcx)
+	vmulsd %xmm12,%xmm0,%xmm13
+	vmovsd 0xd0(%rsp),%xmm0
+	vmovsd %xmm13,-0xd0(%rcx)
+	vmovq  %xmm13,%rdi
+	vfnmadd132sd %xmm6,%xmm15,%xmm0
+	vmulsd 0xc8(%rsp),%xmm0,%xmm0
+	vmulsd %xmm0,%xmm2,%xmm13
+	vmulsd %xmm0,%xmm4,%xmm0
+	vmovsd %xmm13,-0xc8(%rcx)
+	vmovq  %xmm13,%rsi
+	vmulsd 0xb8(%rsp),%xmm1,%xmm13
+	vmovsd %xmm0,-0xb8(%rcx)
+	vmulsd %xmm14,%xmm13,%xmm14
+	vmulsd 0xb0(%rsp),%xmm1,%xmm13
+	vmovsd %xmm14,-0xc0(%rcx)
+	vmulsd %xmm7,%xmm13,%xmm13
+	vmovsd %xmm3,%xmm3,%xmm7
+	vfnmadd132sd %xmm9,%xmm10,%xmm7
+	vmulsd %xmm3,%xmm1,%xmm3
+	vmovsd %xmm13,-0xb0(%rcx)
+	vmovq  %xmm13,%rax
+	vmulsd 0xa8(%rsp),%xmm4,%xmm13
+	vmovq  %xmm3,%r12
+	vmulsd %xmm3,%xmm8,%xmm3
+	vmulsd %xmm7,%xmm13,%xmm7
+	vmovsd %xmm7,-0xa8(%rcx)
+	vfnmadd231sd 0x58(%rsp),%xmm6,%xmm15
+	vmovsd %xmm3,-0x98(%rcx)
+	vmulsd 0x60(%rsp),%xmm12,%xmm13
+	vfnmadd231sd 0x28(%rsp),%xmm9,%xmm10
+	vmulsd 0x50(%rsp),%xmm15,%xmm3
+	vmovq  %r12,%xmm15
+	vmulsd %xmm11,%xmm13,%xmm13
+	vmovsd %xmm13,-0xa0(%rcx)
+	vmulsd %xmm3,%xmm12,%xmm12
+	vmovsd %xmm12,-0x90(%rcx)
+	vmulsd %xmm3,%xmm11,%xmm12
+	vmovq  %rsi,%xmm3
+	vmovsd %xmm12,-0x70(%rcx)
+	vmulsd 0x48(%rsp),%xmm1,%xmm12
+	vmulsd %xmm14,%xmm12,%xmm12
+	vfmsub231sd %xmm3,%xmm2,%xmm12
+	vmovq  %rbx,%xmm3
+	vfmadd132sd %xmm4,%xmm12,%xmm0
+	vmovsd 0xe8(%rsp),%xmm12
+	vmulsd 0x40(%rsp),%xmm0,%xmm0
+	vfnmadd132sd %xmm5,%xmm6,%xmm12
+	vmulsd 0x10(%rsp),%xmm12,%xmm12
+	vmovsd %xmm0,-0x80(%rcx)
+	vmulsd %xmm12,%xmm3,%xmm11
+	vmovq  %r10,%xmm3
+	vmulsd %xmm12,%xmm3,%xmm3
+	vmulsd %xmm15,%xmm7,%xmm12
+	vmovsd %xmm11,-0x88(%rcx)
+	vmovsd %xmm3,-0x78(%rcx)
+	vmovsd %xmm12,-0x68(%rcx)
+	vmulsd %xmm7,%xmm4,%xmm12
+	vfmsub231sd %xmm8,%xmm2,%xmm12
+	vmulsd 0x8(%rsp),%xmm12,%xmm12
+	vmulsd 0x20(%rsp),%xmm12,%xmm15
+	vmovsd %xmm12,-0x60(%rcx)
+	vfmadd132sd %xmm10,%xmm15,%xmm9
+	vmulsd 0x18(%rsp),%xmm2,%xmm10
+	vmulsd %xmm9,%xmm10,%xmm9
+	vmovsd %xmm9,-0x58(%rcx)
+	vmulsd 0xf8(%rsp),%xmm1,%xmm9
+	vmulsd %xmm9,%xmm13,%xmm10
+	vmulsd %xmm9,%xmm12,%xmm9
+	vmovsd %xmm9,-0x10(%rcx)
+	vmovsd 0xa0(%rsp),%xmm9
+	vmovsd %xmm10,-0x50(%rcx)
+	vfmadd132sd %xmm5,%xmm6,%xmm9
+	vmulsd 0x98(%rsp),%xmm9,%xmm9
+	vmulsd %xmm9,%xmm7,%xmm7
+	vmulsd %xmm9,%xmm8,%xmm8
+	vmovq  %rdi,%xmm9
+	vmovsd %xmm7,-0x18(%rcx)
+	vmulsd 0x90(%rsp),%xmm5,%xmm7
+	vmovsd %xmm8,-0x48(%rcx)
+	vmulsd %xmm7,%xmm9,%xmm8
+	vmovq  %rax,%xmm9
+	vmulsd %xmm7,%xmm9,%xmm7
+	vmovsd %xmm8,-0x40(%rcx)
+	vmulsd 0x88(%rsp),%xmm1,%xmm8
+	vmulsd %xmm6,%xmm1,%xmm1
+	vmovsd %xmm7,-0x20(%rcx)
+	vmulsd %xmm6,%xmm1,%xmm6
+	vmulsd %xmm8,%xmm11,%xmm7
+	vmulsd %xmm8,%xmm3,%xmm3
+	vmovsd 0x80(%rsp),%xmm11
+	vmulsd 0x78(%rsp),%xmm5,%xmm5
+	vfmadd231sd %xmm0,%xmm2,%xmm7
+	vfmadd132sd %xmm4,%xmm3,%xmm0
+	vmulsd %xmm12,%xmm4,%xmm4
+	vfmsub132sd %xmm13,%xmm4,%xmm2
+	vmulsd 0x68(%rsp),%xmm2,%xmm2
+	vmulsd %xmm11,%xmm7,%xmm7
+	vmulsd %xmm11,%xmm0,%xmm0
+	vmovsd %xmm7,-0x38(%rcx)
+	vfmsub132sd %xmm14,%xmm6,%xmm5
+	vmulsd 0x70(%rsp),%xmm5,%xmm5
+	vmovsd %xmm0,-0x28(%rcx)
+	vmovsd %xmm2,-0x8(%rcx)
+	vmovsd %xmm5,-0x30(%rcx)
+	cmp    %rcx,%r11
+	jne    5340 <cartesian_spherical_harmonics_l5._omp_fn.0+0x11a0>
+	jmp    50cd <cartesian_spherical_harmonics_l5._omp_fn.0+0xf2d>
+	nop
+	inc    %eax
+	xor    %edx,%edx
+	jmp    41ea <cartesian_spherical_harmonics_l5._omp_fn.0+0x4a>
+	nopl   0x0(%rax)
+	inc    %eax
+	xor    %edx,%edx
+	jmp    50e8 <cartesian_spherical_harmonics_l5._omp_fn.0+0xf48>
+	nopl   0x0(%rax)
+
+00000000000056d0 <cartesian_spherical_harmonics_l6._omp_fn.0>:
+cartesian_spherical_harmonics_l6._omp_fn.0():
+	push   %rbp
+	mov    %rsp,%rbp
+	push   %r15
+	push   %r14
+	mov    %rdi,%r15
+	push   %r13
+	push   %r12
+	push   %rbx
+	sub    $0x1a8,%rsp
+	mov    0x10(%rdi),%r14
+	mov    0x8(%rdi),%r12
+	mov    (%rdi),%rbx
+	call   1090 <omp_get_num_threads@plt>
+	mov    %eax,%r13d
+	call   1080 <omp_get_thread_num@plt>
+	mov    %eax,%ecx
+	mov    0x18(%r15),%eax
+	cltd
+	idiv   %r13d
+	test   %r14,%r14
+	je     6e80 <cartesian_spherical_harmonics_l6._omp_fn.0+0x17b0>
+	cmp    %edx,%ecx
+	jl     7760 <cartesian_spherical_harmonics_l6._omp_fn.0+0x2090>
+	imul   %eax,%ecx
+	add    %ecx,%edx
+	lea    (%rax,%rdx,1),%ecx
+	cmp    %ecx,%edx
+	jge    6e6b <cartesian_spherical_harmonics_l6._omp_fn.0+0x179b>
+	vmovsd 0x7b0e(%rip),%xmm2        
+	lea    (%rdx,%rdx,2),%ecx
+	movslq %edx,%rsi
+	dec    %eax
+	movslq %ecx,%rcx
+	lea    (%rbx,%rcx,8),%r8
+	imul   $0x31,%edx,%ecx
+	imul   $0x498,%rsi,%rdx
+	add    %rax,%rsi
+	imul   $0x188,%rsi,%rsi
+	movslq %ecx,%rcx
+	lea    (%r12,%rcx,8),%rcx
+	add    %r14,%rdx
+	lea    0x188(%r12,%rsi,1),%r9
+	vmovsd %xmm2,0x58(%rsp)
+	vmovsd 0x7ad3(%rip),%xmm2        
+	vmovsd %xmm2,0x188(%rsp)
+	vmovsd 0x7aca(%rip),%xmm2        
+	vmovsd %xmm2,0x180(%rsp)
+	vmovsd 0x7ac1(%rip),%xmm2        
+	vmovsd %xmm2,0x178(%rsp)
+	vmovsd 0x7ab8(%rip),%xmm2        
+	vmovsd %xmm2,0x120(%rsp)
+	vmovsd 0x7aaf(%rip),%xmm2        
+	vmovsd %xmm2,0x118(%rsp)
+	vmovsd 0x7ac6(%rip),%xmm2        
+	vmovsd %xmm2,0x190(%rsp)
+	vmovsd 0x7abd(%rip),%xmm2        
+	vmovsd %xmm2,0x98(%rsp)
+	vmovsd 0x7ab4(%rip),%xmm2        
+	vmovsd %xmm2,0x160(%rsp)
+	vmovsd 0x7aab(%rip),%xmm2        
+	vmovsd %xmm2,0x88(%rsp)
+	vmovsd 0x7aa2(%rip),%xmm2        
+	vmovsd %xmm2,0x80(%rsp)
+	vmovsd 0x7a99(%rip),%xmm2        
+	vmovsd %xmm2,0x78(%rsp)
+	vmovsd 0x7a93(%rip),%xmm2        
+	vmovsd %xmm2,0x70(%rsp)
+	vmovsd 0x7a8d(%rip),%xmm2        
+	vmovsd %xmm2,0x68(%rsp)
+	vmovsd 0x7a87(%rip),%xmm2        
+	vmovsd %xmm2,0x60(%rsp)
+	vmovsd 0x7ac9(%rip),%xmm2        
+	vmovsd %xmm2,0x110(%rsp)
+	vmovsd 0x7ac0(%rip),%xmm2        
+	vmovsd %xmm2,0x108(%rsp)
+	vmovsd 0x7ab7(%rip),%xmm2        
+	vmovsd %xmm2,0x100(%rsp)
+	vmovsd 0x7aae(%rip),%xmm2        
+	vmovsd %xmm2,0xf8(%rsp)
+	vmovsd 0x7aa5(%rip),%xmm2        
+	vmovsd %xmm2,0xf0(%rsp)
+	vmovsd 0x7a9c(%rip),%xmm2        
+	vmovsd %xmm2,0x158(%rsp)
+	vmovsd 0x7a93(%rip),%xmm2        
+	vmovsd %xmm2,0x50(%rsp)
+	vmovsd 0x7a8d(%rip),%xmm2        
+	vmovsd %xmm2,0x48(%rsp)
+	vmovsd 0x7af7(%rip),%xmm2        
+	vmovsd %xmm2,0x138(%rsp)
+	vmovsd 0x7aee(%rip),%xmm2        
+	vmovsd %xmm2,0x130(%rsp)
+	vmovsd 0x7ae5(%rip),%xmm2        
+	vmovsd %xmm2,0x128(%rsp)
+	vmovsd 0x7adc(%rip),%xmm2        
+	vmovsd %xmm2,0x170(%rsp)
+	vmovsd 0x7ad3(%rip),%xmm2        
+	vmovsd %xmm2,0xc8(%rsp)
+	vmovsd 0x7aca(%rip),%xmm2        
+	vmovsd %xmm2,0xc0(%rsp)
+	vmovsd 0x7ac1(%rip),%xmm2        
+	vmovsd %xmm2,0xb8(%rsp)
+	vmovsd 0x7ab8(%rip),%xmm2        
+	vmovsd %xmm2,0xb0(%rsp)
+	vmovsd 0x7aaf(%rip),%xmm2        
+	vmovsd %xmm2,0x168(%rsp)
+	vmovsd 0x7aa6(%rip),%xmm2        
+	vmovsd 0x7976(%rip),%xmm4        
+	vmovsd 0x7bd6(%rip),%xmm1        
+	vmovsd %xmm2,0xa8(%rsp)
+	vmovsd 0x7a8d(%rip),%xmm2        
+	vmovsd %xmm4,(%rsp)
+	vmovsd 0x7ba8(%rip),%xmm4        
+	vmovsd %xmm1,0x148(%rsp)
+	vmovsd 0x7bbf(%rip),%xmm1        
+	vmovsd %xmm2,0xa0(%rsp)
+	vmovsd 0x7a66(%rip),%xmm2        
+	vmovsd %xmm4,0x28(%rsp)
+	vmovsd 0x7b90(%rip),%xmm4        
+	vmovsd %xmm1,0x8(%rsp)
+	vmovsd %xmm2,0x90(%rsp)
+	vmovsd 0x7b39(%rip),%xmm2        
+	vmovsd %xmm4,0x18(%rsp)
+	vmovsd 0x7b83(%rip),%xmm4        
+	vmovsd %xmm2,0xd0(%rsp)
+	vmovsd 0x7b22(%rip),%xmm2        
+	vmovsd %xmm4,0xe8(%rsp)
+	vmovsd %xmm2,0x150(%rsp)
+	vmovsd 0x7b10(%rip),%xmm2        
+	vmovsd %xmm2,0x40(%rsp)
+	vmovsd 0x7b0a(%rip),%xmm2        
+	vmovsd %xmm2,0x38(%rsp)
+	vmovsd 0x7b04(%rip),%xmm2        
+	vmovsd %xmm2,0x30(%rsp)
+	vmovsd 0x7b06(%rip),%xmm2        
+	vmovsd %xmm2,0x20(%rsp)
+	vmovsd 0x7b10(%rip),%xmm2        
+	vmovsd %xmm2,0x10(%rsp)
+	vmovsd 0x7b1a(%rip),%xmm2        
+	vmovsd 0x7b1a(%rip),%xmm1        
+	vmovsd %xmm2,0xe0(%rsp)
+	vmovsd %xmm1,0xd8(%rsp)
+	add    $0x188,%rcx
+	add    $0x18,%r8
+	add    $0x498,%rdx
+	vmovsd 0x58(%rsp),%xmm7
+	vmovsd -0x10(%r8),%xmm1
+	vmovsd -0x8(%r8),%xmm2
+	vmovsd -0x18(%r8),%xmm4
+	vmovsd 0x180(%rsp),%xmm15
+	vmovsd 0x78(%rsp),%xmm11
+	vmulsd 0x98(%rsp),%xmm1,%xmm10
+	vmovsd %xmm7,-0x188(%rcx)
+	vmovsd 0x188(%rsp),%xmm7
+	vmulsd %xmm1,%xmm1,%xmm3
+	vmulsd %xmm4,%xmm4,%xmm12
+	vmulsd %xmm2,%xmm2,%xmm0
+	vaddsd %xmm12,%xmm3,%xmm14
+	vsubsd %xmm3,%xmm12,%xmm9
+	vmulsd %xmm7,%xmm1,%xmm5
+	vmulsd %xmm7,%xmm2,%xmm8
+	vmulsd %xmm7,%xmm4,%xmm6
+	vmulsd %xmm15,%xmm4,%xmm7
+	vmovsd %xmm8,-0x178(%rcx)
+	vmovsd %xmm5,-0x180(%rcx)
+	vmulsd %xmm7,%xmm8,%xmm13
+	vmovsd %xmm6,-0x170(%rcx)
+	vmovsd 0x178(%rsp),%xmm8
+	vmulsd %xmm7,%xmm5,%xmm6
+	vmulsd %xmm15,%xmm2,%xmm7
+	vmovq  %xmm13,%rdi
+	vmovsd %xmm13,-0x150(%rcx)
+	vmovsd %xmm12,%xmm12,%xmm13
+	vmovsd 0x190(%rsp),%xmm12
+	vmulsd 0x160(%rsp),%xmm2,%xmm15
+	vmovsd %xmm13,0x198(%rsp)
+	vmovsd %xmm6,-0x168(%rcx)
+	vmulsd %xmm5,%xmm7,%xmm5
+	vmovq  %xmm5,%r11
+	vfnmadd132sd %xmm0,%xmm14,%xmm8
+	vmovsd %xmm5,-0x160(%rcx)
+	vmulsd 0x118(%rsp),%xmm9,%xmm5
+	vmulsd 0x120(%rsp),%xmm8,%xmm8
+	vmulsd %xmm6,%xmm15,%xmm15
+	vmovsd %xmm15,-0x138(%rcx)
+	vmovq  %xmm5,%rax
+	vmovsd %xmm5,-0x148(%rcx)
+	vmovsd %xmm12,%xmm12,%xmm5
+	vfnmadd132sd %xmm13,%xmm3,%xmm5
+	vfnmadd132sd %xmm8,%xmm0,%xmm11
+	vmovsd %xmm8,-0x158(%rcx)
+	vmulsd %xmm5,%xmm10,%xmm10
+	vmovsd 0x88(%rsp),%xmm5
+	vmovsd %xmm11,%xmm11,%xmm7
+	vmulsd 0x70(%rsp),%xmm2,%xmm11
+	vmovsd %xmm10,-0x140(%rcx)
+	vfnmadd132sd %xmm0,%xmm14,%xmm5
+	vmulsd 0x80(%rsp),%xmm5,%xmm5
+	vmulsd %xmm7,%xmm11,%xmm7
+	vmulsd 0x68(%rsp),%xmm2,%xmm11
+	vmovsd %xmm7,-0x128(%rcx)
+	vmulsd %xmm5,%xmm1,%xmm13
+	vmulsd %xmm5,%xmm4,%xmm5
+	vmovq  %xmm13,%rsi
+	vmovsd %xmm13,-0x130(%rcx)
+	vmovsd %xmm5,-0x120(%rcx)
+	vmulsd %xmm9,%xmm11,%xmm13
+	vmovsd %xmm12,%xmm12,%xmm9
+	vmovsd %xmm13,-0x118(%rcx)
+	vfnmadd213sd 0x198(%rsp),%xmm3,%xmm9
+	vmulsd 0x60(%rsp),%xmm4,%xmm12
+	vmovq  %xmm13,%r10
+	vfnmadd231sd 0x108(%rsp),%xmm0,%xmm14
+	vmovq  %rax,%xmm13
+	vmulsd 0x110(%rsp),%xmm6,%xmm11
+	vmulsd 0x100(%rsp),%xmm14,%xmm14
+	vmulsd %xmm9,%xmm12,%xmm12
+	vmulsd 0x190(%rsp),%xmm2,%xmm9
+	vmulsd %xmm13,%xmm11,%xmm11
+	vmovsd %xmm12,-0x110(%rcx)
+	vmulsd %xmm14,%xmm6,%xmm6
+	vmovsd %xmm11,-0x108(%rcx)
+	vmovsd %xmm6,-0xf8(%rcx)
+	vmulsd 0xf8(%rsp),%xmm2,%xmm6
+	vmulsd %xmm9,%xmm10,%xmm13
+	vmovsd %xmm13,-0x100(%rcx)
+	vmovq  %xmm13,%r13
+	vmovq  %rax,%xmm13
+	vmulsd %xmm14,%xmm13,%xmm14
+	vmovq  %rsi,%xmm13
+	vmovsd %xmm14,-0xd8(%rcx)
+	vmovsd 0x158(%rsp),%xmm14
+	vmulsd %xmm7,%xmm6,%xmm6
+	vfmsub231sd %xmm13,%xmm1,%xmm6
+	vmovq  %r11,%xmm13
+	vfnmadd132sd %xmm8,%xmm0,%xmm14
+	vmulsd 0x50(%rsp),%xmm14,%xmm14
+	vfmadd132sd %xmm4,%xmm6,%xmm5
+	vmulsd 0xf0(%rsp),%xmm5,%xmm5
+	vmulsd %xmm14,%xmm13,%xmm6
+	vmovq  %rdi,%xmm13
+	vmovsd %xmm5,-0xe8(%rcx)
+	vmulsd %xmm14,%xmm13,%xmm13
+	vmovsd 0x138(%rsp),%xmm14
+	vfnmadd213sd 0x198(%rsp),%xmm3,%xmm14
+	vmovsd %xmm6,-0xf0(%rcx)
+	vmovq  %xmm6,%r15
+	vmovq  %xmm13,%rax
+	vmovsd %xmm13,-0xe0(%rcx)
+	vmulsd %xmm9,%xmm12,%xmm13
+	vmulsd %xmm12,%xmm4,%xmm9
+	vfmsub231sd %xmm10,%xmm1,%xmm9
+	vmulsd 0x48(%rsp),%xmm9,%xmm9
+	vmovsd %xmm13,-0xd0(%rcx)
+	vmovq  %xmm13,%rbx
+	vmovq  %xmm14,%rsi
+	vmulsd 0x130(%rsp),%xmm9,%xmm14
+	vmovq  %rsi,%xmm13
+	vmovsd %xmm9,-0xc8(%rcx)
+	vfmadd231sd %xmm13,%xmm3,%xmm14
+	vmulsd 0x128(%rsp),%xmm1,%xmm13
+	vmulsd %xmm14,%xmm13,%xmm13
+	vmulsd 0x170(%rsp),%xmm2,%xmm14
+	vmovq  %xmm13,%rsi
+	vmovsd %xmm13,-0xc0(%rcx)
+	vmulsd %xmm14,%xmm11,%xmm13
+	vmulsd %xmm14,%xmm9,%xmm14
+	vmovsd %xmm14,-0x78(%rcx)
+	vmovsd 0xc8(%rsp),%xmm14
+	vmovsd %xmm13,-0xb8(%rcx)
+	vfmadd132sd %xmm8,%xmm0,%xmm14
+	vmulsd 0xc0(%rsp),%xmm14,%xmm14
+	vmulsd %xmm14,%xmm10,%xmm13
+	vmulsd %xmm14,%xmm12,%xmm14
+	vmovsd %xmm13,-0xb0(%rcx)
+	vmovq  %xmm13,%r12
+	vmovsd %xmm14,-0x80(%rcx)
+	vmulsd 0xb8(%rsp),%xmm8,%xmm13
+	vmulsd 0xd0(%rsp),%xmm10,%xmm10
+	vmovq  %xmm13,%r14
+	vmulsd %xmm13,%xmm15,%xmm15
+	vmovq  %r10,%xmm13
+	vmovq  %r14,%xmm6
+	vmulsd %xmm6,%xmm13,%xmm13
+	vmovq  %r15,%xmm6
+	vmulsd %xmm12,%xmm10,%xmm10
+	vmovsd %xmm15,-0xa8(%rcx)
+	vmovsd %xmm13,-0x88(%rcx)
+	vmovq  %xmm13,%r10
+	vmulsd 0xb0(%rsp),%xmm2,%xmm13
+	vmovsd %xmm10,-0x68(%rcx)
+	vmulsd 0x150(%rsp),%xmm2,%xmm10
+	vmulsd %xmm13,%xmm6,%xmm6
+	vmovq  %xmm13,%r14
+	vmovq  %rax,%xmm13
+	vfmadd231sd %xmm5,%xmm1,%xmm6
+	vmulsd 0x168(%rsp),%xmm6,%xmm6
+	vmovsd %xmm6,0x140(%rsp)
+	vmovsd %xmm6,-0xa0(%rcx)
+	vmovq  %r14,%xmm6
+	vmulsd %xmm6,%xmm13,%xmm13
+	vfmadd132sd %xmm4,%xmm13,%xmm5
+	vmulsd %xmm0,%xmm2,%xmm13
+	vmulsd 0x168(%rsp),%xmm5,%xmm5
+	vmovq  %xmm13,%rax
+	vmulsd 0xa8(%rsp),%xmm8,%xmm13
+	vmovsd %xmm5,-0x90(%rcx)
+	vmovq  %xmm13,%r15
+	vmovq  %rax,%xmm13
+	vmulsd %xmm13,%xmm0,%xmm13
+	vmovq  %xmm13,%r14
+	vmovq  %r15,%xmm13
+	vmovq  %r14,%xmm6
+	vfmsub132sd %xmm13,%xmm6,%xmm7
+	vmulsd %xmm9,%xmm4,%xmm13
+	vmulsd 0xa0(%rsp),%xmm7,%xmm7
+	vmovsd 0x140(%rsp),%xmm6
+	vfmsub231sd %xmm11,%xmm1,%xmm13
+	vmulsd 0x90(%rsp),%xmm13,%xmm13
+	vmovsd %xmm7,-0x98(%rcx)
+	vmulsd %xmm7,%xmm2,%xmm7
+	vmovq  %xmm13,%r14
+	vmovsd %xmm13,-0x70(%rcx)
+	vmovq  %rsi,%xmm13
+	vmulsd %xmm10,%xmm13,%xmm12
+	vmovq  %r14,%xmm13
+	vmulsd %xmm10,%xmm13,%xmm10
+	vmovsd 0x40(%rsp),%xmm13
+	vmovsd %xmm12,-0x60(%rcx)
+	vmovsd %xmm10,-0x10(%rcx)
+	vmovsd 0x38(%rsp),%xmm10
+	vfmadd132sd %xmm8,%xmm0,%xmm13
+	vmulsd %xmm13,%xmm10,%xmm10
+	vmovq  %r13,%xmm13
+	vmulsd %xmm10,%xmm11,%xmm11
+	vmulsd %xmm10,%xmm9,%xmm9
+	vmovsd %xmm11,-0x58(%rcx)
+	vmovsd (%rsp),%xmm11
+	vmovsd %xmm9,-0x18(%rcx)
+	vmovsd %xmm11,%xmm11,%xmm9
+	vfmadd132sd %xmm8,%xmm0,%xmm9
+	vmulsd 0x30(%rsp),%xmm9,%xmm9
+	vmulsd %xmm9,%xmm13,%xmm10
+	vmovq  %rbx,%xmm13
+	vmulsd %xmm9,%xmm13,%xmm9
+	vmovq  %r11,%xmm13
+	vmovsd %xmm10,-0x50(%rcx)
+	vmulsd 0x28(%rsp),%xmm2,%xmm10
+	vmovsd %xmm9,-0x20(%rcx)
+	vmulsd %xmm6,%xmm4,%xmm9
+	vfmadd132sd %xmm10,%xmm9,%xmm15
+	vmulsd 0x148(%rsp),%xmm8,%xmm9
+	vmulsd 0x20(%rsp),%xmm15,%xmm15
+	vmulsd %xmm8,%xmm9,%xmm9
+	vmovsd %xmm15,-0x48(%rcx)
+	vfmsub231sd %xmm0,%xmm0,%xmm9
+	vmulsd 0x18(%rsp),%xmm9,%xmm9
+	vmulsd %xmm9,%xmm13,%xmm8
+	vmovq  %rdi,%xmm13
+	vmulsd %xmm9,%xmm13,%xmm9
+	vmovsd 0x10(%rsp),%xmm13
+	vmovsd %xmm8,-0x40(%rcx)
+	vmovsd %xmm9,-0x30(%rcx)
+	vmulsd %xmm13,%xmm1,%xmm8
+	vfmsub132sd %xmm8,%xmm7,%xmm6
+	vmulsd %xmm13,%xmm4,%xmm7
+	vmovq  %r10,%xmm13
+	vfmadd132sd %xmm7,%xmm6,%xmm5
+	vmulsd 0x8(%rsp),%xmm5,%xmm5
+	vmovsd 0x188(%rsp),%xmm7
+	vmovsd %xmm5,-0x38(%rcx)
+	vmulsd 0xe8(%rsp),%xmm2,%xmm5
+	vmulsd %xmm13,%xmm5,%xmm5
+	vmovq  %r12,%xmm13
+	vfmsub231sd %xmm13,%xmm1,%xmm5
+	vmovq  %r14,%xmm13
+	vfmadd132sd %xmm4,%xmm5,%xmm14
+	vmulsd %xmm13,%xmm4,%xmm5
+	vmulsd 0xe0(%rsp),%xmm14,%xmm14
+	vmovq  %rsi,%xmm13
+	vfmsub231sd %xmm13,%xmm1,%xmm5
+	vmulsd 0xd8(%rsp),%xmm5,%xmm5
+	vmovapd 0x6ffc(%rip),%ymm13        
+	vmovsd %xmm14,-0x28(%rcx)
+	vmovsd 0x180(%rsp),%xmm14
+	vmovsd %xmm5,-0x8(%rcx)
+	vmovupd %ymm13,-0x498(%rdx)
+	movq   $0x0,-0x188(%rdx)
+	vmovsd 0x71fe(%rip),%xmm13        
+	movq   $0x0,-0x310(%rdx)
+	vmovsd %xmm7,-0x308(%rdx)
+	movq   $0x0,-0x300(%rdx)
+	movq   $0x0,-0x2f8(%rdx)
+	movq   $0x0,-0x180(%rdx)
+	vmovsd %xmm7,-0x178(%rdx)
+	movq   $0x0,-0x170(%rdx)
+	vmulsd -0x180(%rcx),%xmm14,%xmm7
+	movq   $0x0,-0x470(%rdx)
+	vmovsd %xmm7,-0x478(%rdx)
+	vmulsd -0x170(%rcx),%xmm13,%xmm5
+	vmovsd %xmm5,-0x468(%rdx)
+	vmulsd -0x178(%rcx),%xmm14,%xmm6
+	vmovsd %xmm6,-0x460(%rdx)
+	vmulsd -0x170(%rcx),%xmm14,%xmm8
+	vmovsd %xmm8,-0x458(%rdx)
+	vmulsd 0x7174(%rip),%xmm7,%xmm8        
+	vmovsd %xmm6,-0x2e8(%rdx)
+	vmulsd 0x715c(%rip),%xmm5,%xmm5        
+	vmovsd %xmm7,-0x160(%rdx)
+	movq   $0x0,-0x2d8(%rdx)
+	movq   $0x0,-0x148(%rdx)
+	movq   $0x0,-0x168(%rdx)
+	vmulsd 0x713b(%rip),%xmm6,%xmm6        
+	vmovsd 0x160(%rsp),%xmm10
+	vmovsd %xmm8,-0x2e0(%rdx)
+	vxorpd 0x75fa(%rip),%xmm7,%xmm8        
+	vmovsd 0x716a(%rip),%xmm7        
+	vmovsd %xmm5,-0x2f0(%rdx)
+	vmovsd %xmm5,-0x150(%rdx)
+	vmovsd %xmm6,-0x158(%rdx)
+	vmovsd %xmm8,-0x2d0(%rdx)
+	vmulsd -0x168(%rcx),%xmm7,%xmm5
+	vmovsd 0x7142(%rip),%xmm7        
+	vmovsd 0x7152(%rip),%xmm8        
+	vmovsd %xmm5,-0x450(%rdx)
+	vmulsd -0x160(%rcx),%xmm10,%xmm6
+	vmovsd %xmm6,-0x448(%rdx)
+	vmulsd -0x168(%rcx),%xmm7,%xmm7
+	vmovsd %xmm7,-0x440(%rdx)
+	vmovsd 0x7112(%rip),%xmm7        
+	vmulsd -0x150(%rcx),%xmm7,%xmm7
+	vmovsd %xmm7,-0x438(%rdx)
+	vsubsd %xmm0,%xmm3,%xmm7
+	vfmadd132sd -0x158(%rcx),%xmm7,%xmm11
+	vmulsd %xmm11,%xmm8,%xmm8
+	vmovsd 0x70d8(%rip),%xmm11        
+	vmovsd %xmm8,-0x430(%rdx)
+	vmulsd -0x150(%rcx),%xmm10,%xmm8
+	vmovsd %xmm8,-0x428(%rdx)
+	vmulsd -0x148(%rcx),%xmm11,%xmm9
+	vmovsd 0x70d8(%rip),%xmm13        
+	vmovsd %xmm8,-0x2c0(%rdx)
+	vmovsd 0x70d0(%rip),%xmm8        
+	vmovsd 0x70a8(%rip),%xmm11        
+	vxorpd 0x7518(%rip),%xmm6,%xmm6        
+	vxorpd 0x7510(%rip),%xmm5,%xmm5        
+	vmovsd %xmm9,-0x420(%rdx)
+	vmovsd %xmm9,-0x2c8(%rdx)
+	vfnmadd132sd -0x158(%rcx),%xmm7,%xmm13
+	vmulsd %xmm13,%xmm8,%xmm8
+	vmovsd %xmm8,-0x2b8(%rdx)
+	vmulsd -0x160(%rcx),%xmm11,%xmm8
+	vmovsd 0x705a(%rip),%xmm11        
+	vmovsd %xmm8,-0x2b0(%rdx)
+	vmulsd -0x168(%rcx),%xmm11,%xmm8
+	vmovsd %xmm6,-0x2a0(%rdx)
+	vmovsd %xmm5,-0x298(%rdx)
+	movq   $0x0,-0x140(%rdx)
+	vmovsd 0x7057(%rip),%xmm6        
+	vmovsd %xmm8,-0x2a8(%rdx)
+	vmulsd -0x168(%rcx),%xmm10,%xmm5
+	vmovsd %xmm5,-0x138(%rdx)
+	vmulsd -0x160(%rcx),%xmm6,%xmm5
+	vmovsd 0x7037(%rip),%xmm6        
+	vmovsd %xmm5,-0x130(%rdx)
+	vmulsd -0x158(%rcx),%xmm6,%xmm5
+	vmovsd 0x7017(%rip),%xmm6        
+	vmovsd %xmm5,-0x128(%rdx)
+	vmulsd -0x150(%rcx),%xmm6,%xmm5
+	vmovsd %xmm5,-0x120(%rdx)
+	vmulsd -0x148(%rcx),%xmm10,%xmm5
+	vmovsd %xmm5,-0x118(%rdx)
+	movq   $0x0,-0x110(%rdx)
+	vmovsd 0x702c(%rip),%xmm6        
+	vmovsd 0x702c(%rip),%xmm11        
+	vmulsd -0x140(%rcx),%xmm6,%xmm6
+	vmovsd 0x158(%rsp),%xmm5
+	vmulsd 0x701b(%rip),%xmm1,%xmm10        
+	vmovsd 0x190(%rsp),%xmm15
+	vmovsd 0x6ffa(%rip),%xmm13        
+	vmovsd %xmm6,-0x418(%rdx)
+	vmulsd -0x138(%rcx),%xmm11,%xmm9
+	vmovq  %rax,%xmm11
+	vmovsd %xmm9,-0x410(%rdx)
+	vfmadd132sd -0x158(%rcx),%xmm3,%xmm5
+	vmulsd %xmm5,%xmm10,%xmm5
+	vmovsd %xmm5,-0x408(%rdx)
+	vmovsd 0x6fd8(%rip),%xmm5        
+	vmulsd -0x138(%rcx),%xmm5,%xmm8
+	vmovsd 0x6fd0(%rip),%xmm5        
+	vmovsd %xmm8,-0x400(%rdx)
+	vmulsd -0x120(%rcx),%xmm5,%xmm5
+	vmovsd %xmm5,-0x3f8(%rdx)
+	vmulsd 0x6fb8(%rip),%xmm1,%xmm5        
+	vfnmadd132sd -0x160(%rcx),%xmm11,%xmm5
+	vmovsd 0x6faf(%rip),%xmm11        
+	vfnmadd231sd -0x128(%rcx),%xmm11,%xmm5
+	vmovsd %xmm15,%xmm15,%xmm11
+	vfnmadd213sd 0x198(%rsp),%xmm0,%xmm11
+	vmulsd 0x6f97(%rip),%xmm5,%xmm5        
+	vmovsd %xmm5,-0x3f0(%rdx)
+	vmulsd 0x6f8f(%rip),%xmm4,%xmm5        
+	vmulsd %xmm11,%xmm5,%xmm11
+	vmovsd %xmm11,-0x3e8(%rdx)
+	vmovsd 0x6f42(%rip),%xmm11        
+	vmulsd -0x118(%rcx),%xmm11,%xmm11
+	vmovsd %xmm11,-0x3e0(%rdx)
+	vmulsd -0x110(%rcx),%xmm13,%xmm12
+	vmovsd %xmm12,-0x3d8(%rdx)
+	vmovsd %xmm12,-0x290(%rdx)
+	vmovsd 0x178(%rsp),%xmm12
+	vmovsd 0x6f49(%rip),%xmm13        
+	vmovsd %xmm11,-0x288(%rdx)
+	vxorpd 0x72f1(%rip),%xmm9,%xmm9        
+	vxorpd 0x72e9(%rip),%xmm6,%xmm6        
+	vfnmadd132sd %xmm0,%xmm3,%xmm12
+	vfnmadd231sd -0x158(%rcx),%xmm13,%xmm12
+	vmovsd 0x6f23(%rip),%xmm13        
+	vmulsd %xmm12,%xmm5,%xmm5
+	vmovsd %xmm5,-0x280(%rdx)
+	vmulsd -0x128(%rcx),%xmm13,%xmm12
+	vmovsd %xmm15,%xmm15,%xmm5
+	vfmsub132sd %xmm3,%xmm0,%xmm5
+	vfmsub132sd %xmm2,%xmm12,%xmm5
+	vmulsd 0x6ee0(%rip),%xmm5,%xmm5        
+	vmovsd %xmm5,-0x278(%rdx)
+	vmovsd 0x6eb8(%rip),%xmm5        
+	vmulsd -0x130(%rcx),%xmm5,%xmm5
+	vmovsd %xmm8,-0x268(%rdx)
+	vmovsd %xmm15,%xmm15,%xmm8
+	vmovsd %xmm9,-0x258(%rdx)
+	vfnmadd132sd %xmm0,%xmm3,%xmm8
+	vmovsd %xmm6,-0x250(%rdx)
+	movq   $0x0,-0x108(%rdx)
+	vmulsd %xmm8,%xmm10,%xmm10
+	vmovsd %xmm10,-0x260(%rdx)
+	vmovsd %xmm5,-0x270(%rdx)
+	vmulsd -0x140(%rcx),%xmm15,%xmm5
+	vmovsd %xmm5,-0x100(%rdx)
+	vmovsd 0x6e8e(%rip),%xmm5        
+	vmulsd -0x138(%rcx),%xmm5,%xmm5
+	vmovsd %xmm5,-0xf8(%rdx)
+	vmovsd 0x6e7e(%rip),%xmm5        
+	vmulsd -0x130(%rcx),%xmm5,%xmm5
+	vmovsd %xmm5,-0xf0(%rdx)
+	vmovsd 0x6e6e(%rip),%xmm5        
+	vmulsd -0x128(%rcx),%xmm5,%xmm5
+	vmovsd %xmm5,-0xe8(%rdx)
+	vmovsd 0x6e4e(%rip),%xmm5        
+	vmulsd -0x120(%rcx),%xmm5,%xmm5
+	vmovsd %xmm5,-0xe0(%rdx)
+	vmovsd 0x6e2e(%rip),%xmm5        
+	vmulsd 0x6ede(%rip),%xmm0,%xmm12        
+	vmulsd -0x118(%rcx),%xmm5,%xmm5
+	vmovsd %xmm5,-0xd8(%rdx)
+	vmulsd -0x110(%rcx),%xmm15,%xmm5
+	movq   $0x0,-0xc8(%rdx)
+	vmovsd %xmm5,-0xd0(%rdx)
+	vmovsd 0x6e6b(%rip),%xmm5        
+	vmulsd -0x108(%rcx),%xmm5,%xmm6
+	vmovsd 0x6e63(%rip),%xmm5        
+	vmovsd %xmm6,-0x3d0(%rdx)
+	vmulsd -0x100(%rcx),%xmm5,%xmm9
+	vmulsd 0x6e53(%rip),%xmm4,%xmm5        
+	vmovsd %xmm9,-0x3c8(%rdx)
+	vmulsd -0x130(%rcx),%xmm5,%xmm5
+	vfmadd231sd -0x168(%rcx),%xmm3,%xmm5
+	vmulsd 0x6e3a(%rip),%xmm5,%xmm5        
+	vmovsd %xmm5,-0x3c0(%rdx)
+	vmovsd 0x6e32(%rip),%xmm5        
+	vmulsd -0x100(%rcx),%xmm5,%xmm5
+	vfmadd231sd -0x160(%rcx),%xmm7,%xmm5
+	vmulsd 0x6e21(%rip),%xmm5,%xmm5        
+	vmovsd %xmm5,-0x3b8(%rdx)
+	vmovsd 0x6e19(%rip),%xmm5        
+	vmulsd -0xf8(%rcx),%xmm5,%xmm10
+	vmovsd 0x6e11(%rip),%xmm5        
+	vmovsd %xmm10,-0x3b0(%rdx)
+	vmulsd -0xe0(%rcx),%xmm5,%xmm5
+	vmovsd %xmm5,-0x3a8(%rdx)
+	vmovsd -0x160(%rcx),%xmm5
+	vmulsd 0x6df9(%rip),%xmm5,%xmm14        
+	vmulsd %xmm5,%xmm14,%xmm5
+	vfmadd231sd %xmm12,%xmm0,%xmm5
+	vfmadd231sd -0x158(%rcx),%xmm7,%xmm5
+	vmovsd 0x6de7(%rip),%xmm13        
+	vmulsd 0x6def(%rip),%xmm2,%xmm12        
+	vfmadd231sd -0xd8(%rcx),%xmm13,%xmm5
+	vmovsd 0x198(%rsp),%xmm13
+	vmulsd 0x6dcd(%rip),%xmm5,%xmm5        
+	vmovsd %xmm5,-0x3a0(%rdx)
+	vsubsd %xmm0,%xmm13,%xmm5
+	vmulsd 0x6d89(%rip),%xmm5,%xmm5        
+	vmulsd -0x150(%rcx),%xmm5,%xmm5
+	vmovsd %xmm5,-0x398(%rdx)
+	vmulsd 0x6db1(%rip),%xmm1,%xmm5        
+	vmulsd -0x140(%rcx),%xmm5,%xmm5
+	vfmsub132sd %xmm12,%xmm5,%xmm11
+	vsubsd -0xd8(%rcx),%xmm11,%xmm11
+	vmovsd 0x6d34(%rip),%xmm5        
+	vmulsd 0x6d94(%rip),%xmm11,%xmm11        
+	vmovsd %xmm11,-0x390(%rdx)
+	vmulsd -0xd0(%rcx),%xmm5,%xmm5
+	vmovsd 0x6d84(%rip),%xmm11        
+	vmovsd %xmm5,-0x388(%rdx)
+	vmulsd -0xc8(%rcx),%xmm11,%xmm11
+	vmovsd %xmm5,-0x240(%rdx)
+	vmulsd 0x6d6c(%rip),%xmm1,%xmm5        
+	vmovsd %xmm11,-0x380(%rdx)
+	vmovsd %xmm11,-0x248(%rdx)
+	vmulsd 0x6d5c(%rip),%xmm2,%xmm11        
+	vmulsd -0x118(%rcx),%xmm11,%xmm11
+	vfmsub132sd -0x140(%rcx),%xmm11,%xmm5
+	vsubsd -0xd8(%rcx),%xmm5,%xmm5
+	vmulsd 0x6d43(%rip),%xmm5,%xmm5        
+	vmovsd %xmm5,-0x238(%rdx)
+	vmovsd 0x6c1b(%rip),%xmm5        
+	vfnmadd132sd -0x158(%rcx),%xmm3,%xmm5
+	vmulsd 0x6d2a(%rip),%xmm5,%xmm5        
+	vmulsd -0x150(%rcx),%xmm5,%xmm5
+	vmovsd 0x6d2a(%rip),%xmm11        
+	vxorpd 0x6faa(%rip),%xmm9,%xmm9        
+	vxorpd 0x6fa2(%rip),%xmm6,%xmm6        
+	vmovsd 0x170(%rsp),%xmm15
+	vmovsd %xmm5,-0x230(%rdx)
+	vmovsd 0x6cf9(%rip),%xmm5        
+	vmulsd -0x130(%rcx),%xmm5,%xmm5
+	vfmsub231sd -0x140(%rcx),%xmm11,%xmm5
+	vmulsd 0x6cf0(%rip),%xmm2,%xmm11        
+	vmulsd -0x128(%rcx),%xmm11,%xmm11
+	vfmadd132sd %xmm1,%xmm11,%xmm5
+	vaddsd -0xc8(%rcx),%xmm5,%xmm5
+	vmulsd 0x6cdb(%rip),%xmm5,%xmm5        
+	vmovsd %xmm5,-0x228(%rdx)
+	vmovsd 0x6c4b(%rip),%xmm5        
+	vmulsd -0xf0(%rcx),%xmm5,%xmm5
+	vmovsd %xmm10,-0x218(%rdx)
+	vmovsd 0x6cc3(%rip),%xmm10        
+	vfnmadd132sd %xmm0,%xmm3,%xmm10
+	vmovsd %xmm5,-0x220(%rdx)
+	vmulsd 0x6ca6(%rip),%xmm7,%xmm5        
+	vmulsd -0x160(%rcx),%xmm5,%xmm5
+	vmovsd %xmm5,-0x210(%rdx)
+	vmovsd 0x6b46(%rip),%xmm5        
+	vfnmadd231sd -0x158(%rcx),%xmm5,%xmm10
+	vmovsd 0x6bd5(%rip),%xmm5        
+	vmulsd -0x168(%rcx),%xmm5,%xmm5
+	vmovsd %xmm9,-0x200(%rdx)
+	vmovsd %xmm6,-0x1f8(%rdx)
+	movq   $0x0,-0xc0(%rdx)
+	vmulsd %xmm10,%xmm5,%xmm5
+	vmovsd %xmm5,-0x208(%rdx)
+	vmulsd -0x108(%rcx),%xmm15,%xmm5
+	vmovsd %xmm5,-0xb8(%rdx)
+	vmovsd 0x6c45(%rip),%xmm5        
+	vmulsd -0x100(%rcx),%xmm5,%xmm5
+	vmovsd %xmm5,-0xb0(%rdx)
+	vmovsd 0x6c35(%rip),%xmm5        
+	vmulsd -0xf8(%rcx),%xmm5,%xmm5
+	vmovsd %xmm5,-0xa8(%rdx)
+	vmovsd 0x6c25(%rip),%xmm5        
+	vmulsd -0xf0(%rcx),%xmm5,%xmm5
+	vmovsd %xmm5,-0xa0(%rdx)
+	vmovsd 0x6c15(%rip),%xmm5        
+	vmulsd -0xe8(%rcx),%xmm5,%xmm5
+	vmovsd %xmm5,-0x98(%rdx)
+	vmovsd 0x6bf5(%rip),%xmm5        
+	vmulsd -0xe0(%rcx),%xmm5,%xmm5
+	vmovsd %xmm5,-0x90(%rdx)
+	vmovsd 0x6bd5(%rip),%xmm5        
+	vmulsd -0xd8(%rcx),%xmm5,%xmm5
+	vmovsd %xmm5,-0x88(%rdx)
+	vmovsd 0x6bb5(%rip),%xmm5        
+	vmulsd -0xd0(%rcx),%xmm5,%xmm5
+	vmovsd %xmm5,-0x80(%rdx)
+	vmulsd -0xc8(%rcx),%xmm15,%xmm5
+	movq   $0x0,-0x70(%rdx)
+	vmovsd %xmm5,-0x78(%rdx)
+	vmovsd 0x6c1b(%rip),%xmm5        
+	vmulsd -0xc0(%rcx),%xmm5,%xmm5
+	vmovsd %xmm5,-0x378(%rdx)
+	vxorpd 0x6dd3(%rip),%xmm5,%xmm5        
+	vmovsd %xmm5,-0x190(%rdx)
+	vmovsd 0x6bfb(%rip),%xmm5        
+	vmulsd -0xb8(%rcx),%xmm5,%xmm5
+	vmovsd %xmm5,-0x370(%rdx)
+	vxorpd 0x6dab(%rip),%xmm5,%xmm5        
+	vmovsd 0x148(%rsp),%xmm15
+	vmovsd 0x6bda(%rip),%xmm14        
+	vmulsd 0x6bf2(%rip),%xmm1,%xmm10        
+	vmovsd %xmm5,-0x198(%rdx)
+	vmovsd -0x160(%rcx),%xmm5
+	vmulsd %xmm15,%xmm5,%xmm6
+	vmulsd %xmm5,%xmm6,%xmm5
+	vmulsd 0x6bb9(%rip),%xmm1,%xmm6        
+	vfmsub231sd %xmm3,%xmm3,%xmm5
+	vfnmadd231sd -0xd8(%rcx),%xmm14,%xmm5
+	vmovsd 0x6bcb(%rip),%xmm14        
+	vmulsd %xmm5,%xmm6,%xmm5
+	vmovsd %xmm5,-0x368(%rdx)
+	vmovsd 0x6b97(%rip),%xmm5        
+	vmulsd -0xb8(%rcx),%xmm5,%xmm5
+	vfmadd231sd -0x138(%rcx),%xmm7,%xmm5
+	vmulsd 0x6b86(%rip),%xmm5,%xmm5        
+	vmovsd %xmm5,-0x360(%rdx)
+	vmovsd -0x158(%rcx),%xmm6
+	vmovsd -0x160(%rcx),%xmm5
+	vmulsd %xmm6,%xmm2,%xmm9
+	vfmsub132sd %xmm5,%xmm9,%xmm10
+	vmulsd 0x6b6d(%rip),%xmm1,%xmm9        
+	vmulsd %xmm3,%xmm9,%xmm9
+	vmulsd %xmm6,%xmm9,%xmm6
+	vfmadd132sd %xmm10,%xmm6,%xmm5
+	vfmadd231sd -0xa0(%rcx),%xmm14,%xmm5
+	vmovsd 0x6b77(%rip),%xmm6        
+	vmovq  %rax,%xmm14
+	vmulsd 0x6b52(%rip),%xmm5,%xmm5        
+	vfmadd132sd %xmm3,%xmm0,%xmm6
+	vmovsd %xmm5,-0x358(%rdx)
+	vmovsd 0x6b45(%rip),%xmm5        
+	vmulsd -0xa8(%rcx),%xmm5,%xmm5
+	vmovsd %xmm5,-0x350(%rdx)
+	vmovsd %xmm5,-0x1b8(%rdx)
+	vmovsd 0x6b2d(%rip),%xmm5        
+	vmulsd -0x90(%rcx),%xmm5,%xmm5
+	vmovsd %xmm5,-0x348(%rdx)
+	vmovsd 0x6b15(%rip),%xmm5        
+	vmulsd -0xa0(%rcx),%xmm5,%xmm5
+	vmovsd %xmm5,-0x1c0(%rdx)
+	vmovsd 0x6ab5(%rip),%xmm5        
+	vmovsd 0x6b0d(%rip),%xmm10        
+	vfnmadd231sd -0x158(%rcx),%xmm5,%xmm6
+	vmulsd 0x6af4(%rip),%xmm1,%xmm5        
+	vmulsd -0xf0(%rcx),%xmm5,%xmm5
+	vfmadd231sd %xmm6,%xmm14,%xmm5
+	vfmadd231sd -0x98(%rcx),%xmm10,%xmm5
+	vmovsd 0x178(%rsp),%xmm6
+	vmovsd 0x6ae5(%rip),%xmm14        
+	vmulsd 0x6ad5(%rip),%xmm5,%xmm5        
+	vfmsub132sd %xmm13,%xmm0,%xmm6
+	vsubsd %xmm3,%xmm6,%xmm6
+	vmovsd %xmm5,-0x340(%rdx)
+	vmulsd -0x70(%rcx),%xmm14,%xmm9
+	vmulsd %xmm7,%xmm4,%xmm5
+	vfmadd132sd %xmm6,%xmm9,%xmm5
+	vmulsd 0x6abe(%rip),%xmm5,%xmm5        
+	vmovsd 0x6ac6(%rip),%xmm6        
+	vmovsd %xmm5,-0x338(%rdx)
+	vmulsd 0x6aae(%rip),%xmm0,%xmm5        
+	vmulsd -0x118(%rcx),%xmm5,%xmm5
+	vfmsub231sd -0x100(%rcx),%xmm1,%xmm5
+	vfmadd231sd -0x88(%rcx),%xmm6,%xmm5
+	vmovsd 0x6aac(%rip),%xmm6        
+	vmulsd 0x6a94(%rip),%xmm5,%xmm5        
+	vmovsd %xmm5,-0x330(%rdx)
+	vmulsd 0x6a8c(%rip),%xmm2,%xmm5        
+	vmulsd -0x80(%rcx),%xmm6,%xmm6
+	vmulsd -0xd0(%rcx),%xmm5,%xmm5
+	vfmsub231sd -0x108(%rcx),%xmm1,%xmm5
+	vfmadd231sd 0x6a7d(%rip),%xmm5,%xmm6        
+	vmovsd %xmm6,-0x328(%rdx)
+	vmovsd 0x6a75(%rip),%xmm6        
+	vmulsd -0x80(%rcx),%xmm6,%xmm6
+	vfnmadd132sd 0x6a5f(%rip),%xmm6,%xmm5        
+	vmovsd 0x69a7(%rip),%xmm6        
+	vmovsd %xmm5,-0x1e0(%rdx)
+	vmulsd -0x78(%rcx),%xmm6,%xmm5
+	vmovsd 0x698a(%rip),%xmm6        
+	vmovsd %xmm5,-0x320(%rdx)
+	vmulsd -0x70(%rcx),%xmm6,%xmm6
+	vmovsd %xmm5,-0x1e8(%rdx)
+	vmulsd 0x6a35(%rip),%xmm0,%xmm5        
+	vmovsd %xmm6,-0x318(%rdx)
+	vmovsd %xmm6,-0x1f0(%rdx)
+	vmulsd -0x100(%rcx),%xmm1,%xmm6
+	vfmadd132sd -0x118(%rcx),%xmm6,%xmm5
+	vmovsd 0x6a14(%rip),%xmm6        
+	vfnmadd231sd -0x88(%rcx),%xmm6,%xmm5
+	vsubsd %xmm3,%xmm0,%xmm6
+	vmulsd 0x6a07(%rip),%xmm5,%xmm5        
+	vmovsd %xmm5,-0x1d8(%rdx)
+	vmovsd -0x160(%rcx),%xmm5
+	vmulsd -0x158(%rcx),%xmm6,%xmm6
+	vmulsd 0x69ef(%rip),%xmm5,%xmm9        
+	vfmadd132sd %xmm9,%xmm6,%xmm5
+	vmovsd 0x69ea(%rip),%xmm6        
+	vmulsd -0x90(%rcx),%xmm6,%xmm6
+	vfmadd132sd %xmm5,%xmm6,%xmm4
+	vmulsd 0x69dd(%rip),%xmm4,%xmm4        
+	vmovsd %xmm4,-0x1d0(%rdx)
+	vmovsd -0x158(%rcx),%xmm4
+	vmulsd %xmm15,%xmm4,%xmm5
+	vfmsub231sd 0x69c7(%rip),%xmm3,%xmm5        
+	vmulsd %xmm5,%xmm4,%xmm4
+	vmulsd 0x69c3(%rip),%xmm2,%xmm5        
+	vfmadd231sd %xmm0,%xmm0,%xmm4
+	vmulsd %xmm3,%xmm2,%xmm2
+	vmulsd %xmm4,%xmm5,%xmm4
+	vmovsd %xmm4,-0x1c8(%rdx)
+	vmulsd 0x69ae(%rip),%xmm3,%xmm4        
+	vfmadd132sd 0x69ad(%rip),%xmm4,%xmm13        
+	vfnmadd132sd 0x69ac(%rip),%xmm13,%xmm0        
+	vmulsd -0x130(%rcx),%xmm0,%xmm0
+	vfmadd231sd -0x160(%rcx),%xmm2,%xmm0
+	vmulsd 0x699b(%rip),%xmm0,%xmm0        
+	vmovsd %xmm0,-0x1b0(%rdx)
+	vmovsd 0x65db(%rip),%xmm4        
+	vmulsd 0x6993(%rip),%xmm3,%xmm0        
+	vfnmadd231sd -0x158(%rcx),%xmm4,%xmm7
+	vmovsd 0x150(%rsp),%xmm2
+	vmulsd 0x6971(%rip),%xmm7,%xmm7        
+	vmulsd -0x138(%rcx),%xmm7,%xmm7
+	vmulsd %xmm3,%xmm0,%xmm3
+	vmovsd %xmm7,-0x1a8(%rdx)
+	vmulsd -0x140(%rcx),%xmm8,%xmm8
+	vfmadd132sd %xmm3,%xmm8,%xmm1
+	vmovsd 0x6958(%rip),%xmm3        
+	vfmadd231sd -0xc0(%rcx),%xmm3,%xmm1
+	movq   $0x0,-0x68(%rdx)
+	vmovsd 0x694f(%rip),%xmm3        
+	vmulsd 0x693f(%rip),%xmm1,%xmm1        
+	vmovsd %xmm1,-0x1a0(%rdx)
+	vmulsd -0xc0(%rcx),%xmm2,%xmm0
+	vmovsd 0x693f(%rip),%xmm1        
+	vmovsd %xmm0,-0x60(%rdx)
+	vmulsd -0xb8(%rcx),%xmm3,%xmm0
+	vmovsd 0x6922(%rip),%xmm3        
+	vmovsd %xmm0,-0x58(%rdx)
+	vmulsd -0xb0(%rcx),%xmm3,%xmm0
+	vmovsd 0x691d(%rip),%xmm3        
+	vmovsd %xmm0,-0x50(%rdx)
+	vmulsd -0xa8(%rcx),%xmm1,%xmm0
+	vmovsd 0x6910(%rip),%xmm1        
+	vmovsd %xmm0,-0x48(%rdx)
+	vmulsd -0xa0(%rcx),%xmm3,%xmm0
+	vmovsd %xmm0,-0x40(%rdx)
+	vmulsd -0x98(%rcx),%xmm1,%xmm0
+	vmovsd %xmm0,-0x38(%rdx)
+	vmulsd -0x90(%rcx),%xmm3,%xmm0
+	vmovsd %xmm0,-0x30(%rdx)
+	vmovsd 0x68cc(%rip),%xmm3        
+	vmovsd 0x68bc(%rip),%xmm1        
+	vmulsd -0x88(%rcx),%xmm3,%xmm0
+	vmovsd 0x68a4(%rip),%xmm4        
+	vmovsd %xmm0,-0x28(%rdx)
+	vmulsd -0x80(%rcx),%xmm1,%xmm0
+	vmovsd %xmm0,-0x20(%rdx)
+	vmulsd -0x78(%rcx),%xmm4,%xmm0
+	vmovsd %xmm0,-0x18(%rdx)
+	vmulsd -0x70(%rcx),%xmm2,%xmm0
+	movq   $0x0,-0x8(%rdx)
+	vmovsd %xmm0,-0x10(%rdx)
+	cmp    %rcx,%r9
+	jne    5a80 <cartesian_spherical_harmonics_l6._omp_fn.0+0x3b0>
+	vzeroupper
+	add    $0x1a8,%rsp
+	pop    %rbx
+	pop    %r12
+	pop    %r13
+	pop    %r14
+	pop    %r15
+	pop    %rbp
+	ret
+	nopl   (%rax)
+	cmp    %edx,%ecx
+	jl     7770 <cartesian_spherical_harmonics_l6._omp_fn.0+0x20a0>
+	imul   %eax,%ecx
+	add    %ecx,%edx
+	lea    (%rax,%rdx,1),%ecx
+	cmp    %ecx,%edx
+	jge    6e6b <cartesian_spherical_harmonics_l6._omp_fn.0+0x179b>
+	vmovsd 0x63a4(%rip),%xmm4        
+	vmovsd 0x63ac(%rip),%xmm2        
+	lea    (%rdx,%rdx,2),%ecx
+	dec    %eax
+	vmovsd 0x63af(%rip),%xmm1        
+	movslq %ecx,%rcx
+	lea    (%rbx,%rcx,8),%r8
+	imul   $0x31,%edx,%ecx
+	movslq %edx,%rdx
+	add    %rax,%rdx
+	imul   $0x188,%rdx,%rdx
+	movslq %ecx,%rcx
+	lea    (%r12,%rcx,8),%rcx
+	lea    0x188(%r12,%rdx,1),%r10
+	vmovsd %xmm4,0x58(%rsp)
+	vmovsd 0x6363(%rip),%xmm4        
+	vmovsd %xmm2,0x180(%rsp)
+	vmovsd 0x6372(%rip),%xmm2        
+	vmovsd %xmm1,0x120(%rsp)
+	vmovsd 0x6391(%rip),%xmm1        
+	vmovsd %xmm4,0x188(%rsp)
+	vmovsd 0x6340(%rip),%xmm4        
+	vmovsd %xmm2,0x118(%rsp)
+	vmovsd 0x6377(%rip),%xmm2        
+	vmovsd %xmm1,0x98(%rsp)
+	vmovsd 0x6376(%rip),%xmm1        
+	vmovsd %xmm4,0x178(%rsp)
+	vmovsd 0x6345(%rip),%xmm4        
+	vmovsd %xmm2,0x160(%rsp)
+	vmovsd 0x635c(%rip),%xmm2        
 	vmovsd %xmm1,0x80(%rsp)
-	vmovsd 0x131d(%rip),%xmm1        
-	vmovsd %xmm1,0x78(%rsp)
-	vmovsd 0x1317(%rip),%xmm1        
-	vmovsd %xmm1,0x70(%rsp)
-	vmovsd 0x1311(%rip),%xmm1        
+	vmovsd 0x635b(%rip),%xmm1        
+	vmovsd %xmm4,0x190(%rsp)
+	vmovsd 0x632a(%rip),%xmm4        
+	vmovsd %xmm2,0x78(%rsp)
+	vmovsd 0x6344(%rip),%xmm2        
 	vmovsd %xmm1,0x68(%rsp)
-	vmovsd 0x130b(%rip),%xmm1        
-	vmovsd %xmm1,0xd8(%rsp)
-	vmovsd 0x1302(%rip),%xmm1        
-	vmovsd %xmm1,0xd0(%rsp)
-	vmovsd 0x1341(%rip),%xmm1        
-	vmovsd %xmm1,0x60(%rsp)
-	vmovsd 0x133b(%rip),%xmm1        
-	vmovsd %xmm1,0x58(%rsp)
-	vmovsd 0x1335(%rip),%xmm1        
-	vmovsd %xmm1,0x50(%rsp)
-	vmovsd 0x132f(%rip),%xmm1        
-	vmovsd %xmm1,0xc8(%rsp)
-	vmovsd 0x1326(%rip),%xmm1        
+	vmovsd %xmm4,0x88(%rsp)
+	vmovsd 0x631d(%rip),%xmm4        
+	vmovsd %xmm2,0x60(%rsp)
+	vmovsd %xmm4,0x70(%rsp)
+	vmovsd 0x6369(%rip),%xmm4        
+	vmovsd %xmm4,0x110(%rsp)
+	vmovsd 0x6360(%rip),%xmm1        
+	vmovsd 0x6360(%rip),%xmm2        
+	vmovsd 0x6360(%rip),%xmm4        
+	vmovsd %xmm1,0x108(%rsp)
+	vmovsd 0x6357(%rip),%xmm1        
+	vmovsd %xmm2,0x100(%rsp)
+	vmovsd 0x634e(%rip),%xmm2        
+	vmovsd %xmm4,0xf8(%rsp)
+	vmovsd 0x6345(%rip),%xmm4        
+	vmovsd %xmm1,0xf0(%rsp)
+	vmovsd 0x633c(%rip),%xmm1        
+	vmovsd %xmm2,0x158(%rsp)
+	vmovsd 0x63a3(%rip),%xmm2        
+	vmovsd %xmm4,0x50(%rsp)
+	vmovsd 0x639d(%rip),%xmm4        
+	vmovsd %xmm1,0x48(%rsp)
+	vmovsd 0x6397(%rip),%xmm1        
+	vmovsd %xmm2,0x138(%rsp)
+	vmovsd 0x638e(%rip),%xmm2        
+	vmovsd %xmm4,0x130(%rsp)
+	vmovsd 0x6385(%rip),%xmm4        
+	vmovsd %xmm1,0x128(%rsp)
+	vmovsd 0x637c(%rip),%xmm1        
+	vmovsd %xmm2,0x170(%rsp)
+	vmovsd 0x6373(%rip),%xmm2        
+	vmovsd %xmm4,0xc8(%rsp)
+	vmovsd 0x636a(%rip),%xmm4        
 	vmovsd %xmm1,0xc0(%rsp)
-	vmovsd 0x131d(%rip),%xmm1        
-	vmovsd %xmm1,0x100(%rsp)
-	vmovsd 0x1314(%rip),%xmm1        
-	vmovsd %xmm1,0xb8(%rsp)
-	vmovsd 0x130b(%rip),%xmm1        
-	vmovsd %xmm1,0xb0(%rsp)
-	vmovsd 0x1302(%rip),%xmm1        
-	vmovsd %xmm1,0xa8(%rsp)
-	vmovsd 0x12f9(%rip),%xmm1        
-	vmovsd %xmm1,0xa0(%rsp)
-	vmovsd 0x12f0(%rip),%xmm1        
-	vmovsd %xmm1,0x98(%rsp)
-	vmovsd 0x12e7(%rip),%xmm1        
-	vmovsd %xmm1,0xf8(%rsp)
-	vmovsd 0x12de(%rip),%xmm1        
+	vmovsd 0x6361(%rip),%xmm1        
+	vmovsd %xmm2,0xb8(%rsp)
+	vmovsd %xmm4,0xb0(%rsp)
+	vmovsd %xmm1,0x168(%rsp)
+	vmovsd 0x6346(%rip),%xmm2        
+	vmovsd 0x6346(%rip),%xmm4        
+	vmovsd 0x6346(%rip),%xmm1        
+	vmovsd %xmm2,0xa8(%rsp)
+	vmovsd 0x642d(%rip),%xmm2        
+	vmovsd %xmm4,0xa0(%rsp)
+	vmovsd 0x6424(%rip),%xmm4        
 	vmovsd %xmm1,0x90(%rsp)
-	vmovsd 0x12d5(%rip),%xmm1        
-	vmovsd %xmm1,0x48(%rsp)
-	vmovsd 0x12cf(%rip),%xmm1        
-	vmovsd %xmm1,0x38(%rsp)
-	vmovsd 0x12c9(%rip),%xmm1        
-	vmovsd %xmm1,0x28(%rsp)
-	vmovsd 0x12c3(%rip),%xmm1        
-	vmovsd %xmm1,0x20(%rsp)
-	vmovsd 0x12bd(%rip),%xmm1        
-	vmovsd %xmm1,0x18(%rsp)
-	vmovsd 0x12b7(%rip),%xmm1        
-	vmovsd %xmm1,0x10(%rsp)
-	vmovsd 0x12b1(%rip),%xmm1        
-	vmovsd %xmm9,0x118(%rsp)
-	vmovsd %xmm14,0x108(%rsp)
+	vmovsd 0x641b(%rip),%xmm1        
+	vmovsd %xmm2,0xd0(%rsp)
+	vmovsd 0x6412(%rip),%xmm2        
+	vmovsd %xmm4,0x150(%rsp)
+	vmovsd 0x61b9(%rip),%xmm4        
+	vmovsd %xmm1,0x40(%rsp)
+	vmovsd 0x63fb(%rip),%xmm1        
+	vmovsd %xmm2,0x38(%rsp)
+	vmovsd 0x63f5(%rip),%xmm2        
+	vmovsd %xmm4,(%rsp)
+	vmovsd 0x63f0(%rip),%xmm4        
+	vmovsd %xmm1,0x30(%rsp)
+	vmovsd 0x63ea(%rip),%xmm1        
+	vmovsd %xmm2,0x28(%rsp)
+	vmovsd 0x63e4(%rip),%xmm2        
+	vmovsd %xmm4,0x20(%rsp)
+	vmovsd 0x63de(%rip),%xmm4        
+	vmovsd %xmm1,0x148(%rsp)
+	vmovsd 0x63d5(%rip),%xmm1        
+	vmovsd %xmm2,0x18(%rsp)
+	vmovsd 0x63cf(%rip),%xmm2        
+	vmovsd %xmm4,0x10(%rsp)
 	vmovsd %xmm1,0x8(%rsp)
+	vmovsd %xmm2,0xe8(%rsp)
+	vmovsd 0x63ba(%rip),%xmm4        
+	vmovsd 0x63ba(%rip),%xmm1        
+	vmovsd %xmm4,0xe0(%rsp)
+	vmovsd %xmm1,0xd8(%rsp)
+	add    $0x188,%rcx
+	add    $0x18,%r8
+	vmovsd 0x58(%rsp),%xmm0
+	vmovsd -0x8(%r8),%xmm1
+	vmovsd -0x18(%r8),%xmm4
+	vmovsd -0x10(%r8),%xmm2
+	vmovsd 0x78(%rsp),%xmm14
+	vmulsd 0x70(%rsp),%xmm1,%xmm10
+	vmovsd %xmm0,-0x188(%rcx)
+	vmovsd 0x188(%rsp),%xmm0
+	vmulsd %xmm1,%xmm1,%xmm3
+	vmulsd %xmm2,%xmm2,%xmm9
+	vmulsd %xmm4,%xmm4,%xmm11
+	vsubsd %xmm9,%xmm11,%xmm8
+	vmulsd 0x118(%rsp),%xmm8,%xmm13
+	vmulsd %xmm0,%xmm2,%xmm15
+	vmulsd %xmm0,%xmm1,%xmm7
+	vmulsd %xmm0,%xmm4,%xmm5
+	vmovsd 0x180(%rsp),%xmm0
+	vmovsd %xmm15,-0x180(%rcx)
+	vmovsd %xmm7,-0x178(%rcx)
+	vmovsd %xmm5,-0x170(%rcx)
+	vmovsd %xmm13,-0x148(%rcx)
+	vmulsd %xmm0,%xmm4,%xmm12
+	vmulsd %xmm0,%xmm1,%xmm5
+	vaddsd %xmm9,%xmm11,%xmm0
+	vmulsd %xmm12,%xmm7,%xmm7
+	vmulsd %xmm12,%xmm15,%xmm6
+	vmovq  %xmm0,%rax
+	vmovq  %xmm7,%r15
+	vmovsd %xmm7,-0x150(%rcx)
+	vmovsd %xmm6,-0x168(%rcx)
+	vmulsd %xmm15,%xmm5,%xmm7
+	vmovsd %xmm0,%xmm0,%xmm5
+	vfnmadd231sd 0x178(%rsp),%xmm3,%xmm5
+	vmovsd 0x190(%rsp),%xmm15
+	vmovsd %xmm7,-0x160(%rcx)
+	vmovsd %xmm7,0x198(%rsp)
+	vmulsd 0x98(%rsp),%xmm2,%xmm7
+	vmulsd 0x120(%rsp),%xmm5,%xmm5
+	vmovsd %xmm15,%xmm15,%xmm0
+	vfnmadd132sd %xmm11,%xmm9,%xmm0
+	vmulsd %xmm0,%xmm7,%xmm7
+	vmulsd 0x160(%rsp),%xmm1,%xmm0
+	vmovsd %xmm5,-0x158(%rcx)
+	vfnmadd132sd %xmm5,%xmm3,%xmm14
+	vmovsd %xmm7,-0x140(%rcx)
+	vmulsd %xmm14,%xmm10,%xmm14
+	vmulsd 0x68(%rsp),%xmm1,%xmm10
+	vmulsd %xmm6,%xmm0,%xmm12
+	vmovq  %rax,%xmm0
+	vfnmadd231sd 0x88(%rsp),%xmm3,%xmm0
+	vmovsd %xmm14,-0x128(%rcx)
+	vmovq  %xmm12,%rsi
+	vmovsd %xmm12,-0x138(%rcx)
+	vmulsd 0x80(%rsp),%xmm0,%xmm0
+	vmulsd %xmm0,%xmm2,%xmm12
+	vmulsd %xmm0,%xmm4,%xmm0
+	vmovq  %xmm12,%rdx
+	vmovsd %xmm12,-0x130(%rcx)
+	vmovsd %xmm0,-0x120(%rcx)
+	vmulsd %xmm8,%xmm10,%xmm12
+	vmovsd %xmm15,%xmm15,%xmm8
+	vfnmadd132sd %xmm9,%xmm11,%xmm8
+	vmovsd %xmm12,-0x118(%rcx)
+	vmovq  %xmm12,%r13
+	vmulsd 0x60(%rsp),%xmm4,%xmm10
+	vfnmadd231sd 0x138(%rsp),%xmm9,%xmm11
+	vmulsd %xmm15,%xmm1,%xmm12
+	vmovq  %xmm12,%rbx
+	vmulsd %xmm12,%xmm7,%xmm12
+	vmovsd %xmm12,-0x100(%rcx)
+	vmovq  %xmm12,%r12
+	vmovq  %rax,%xmm12
+	vfnmadd231sd 0x108(%rsp),%xmm3,%xmm12
+	vmulsd %xmm8,%xmm10,%xmm10
+	vmulsd 0x110(%rsp),%xmm6,%xmm8
+	vmulsd 0x100(%rsp),%xmm12,%xmm12
+	vmovsd %xmm10,-0x110(%rcx)
+	vmulsd %xmm13,%xmm8,%xmm8
+	vmulsd %xmm12,%xmm6,%xmm6
+	vmovsd %xmm8,-0x108(%rcx)
+	vmovsd %xmm6,-0xf8(%rcx)
+	vmulsd %xmm12,%xmm13,%xmm6
+	vmovq  %rdx,%xmm12
+	vmovsd %xmm6,-0xd8(%rcx)
+	vmulsd 0xf8(%rsp),%xmm1,%xmm6
+	vmulsd %xmm14,%xmm6,%xmm6
+	vfmsub231sd %xmm12,%xmm2,%xmm6
+	vmovq  %r15,%xmm12
+	vfmadd132sd %xmm4,%xmm6,%xmm0
+	vmovsd 0x158(%rsp),%xmm6
+	vmulsd 0xf0(%rsp),%xmm0,%xmm0
+	vfnmadd132sd %xmm5,%xmm3,%xmm6
+	vmulsd 0x50(%rsp),%xmm6,%xmm6
+	vmovsd %xmm0,-0xe8(%rcx)
+	vmulsd 0x198(%rsp),%xmm6,%xmm13
+	vmulsd %xmm6,%xmm12,%xmm6
+	vmovsd %xmm6,-0xe0(%rcx)
+	vmovq  %xmm6,%rdi
+	vmovq  %rbx,%xmm6
+	vmovsd %xmm13,-0xf0(%rcx)
+	vmulsd %xmm6,%xmm10,%xmm6
+	vmovsd %xmm6,-0xd0(%rcx)
+	vmovq  %xmm6,%rbx
+	vmulsd %xmm10,%xmm4,%xmm6
+	vfmsub231sd %xmm7,%xmm2,%xmm6
+	vmulsd 0x48(%rsp),%xmm6,%xmm6
+	vmulsd 0x130(%rsp),%xmm6,%xmm12
+	vmovsd %xmm6,-0xc8(%rcx)
+	vfmadd132sd %xmm9,%xmm12,%xmm11
+	vmulsd 0x128(%rsp),%xmm2,%xmm9
+	vmulsd %xmm11,%xmm9,%xmm9
+	vmulsd 0x170(%rsp),%xmm1,%xmm11
+	vmovsd %xmm9,-0xc0(%rcx)
+	vmulsd %xmm11,%xmm8,%xmm12
+	vmulsd %xmm11,%xmm6,%xmm11
+	vmovsd %xmm11,-0x78(%rcx)
+	vmovsd 0xc8(%rsp),%xmm11
+	vmovsd %xmm12,-0xb8(%rcx)
+	vfmadd132sd %xmm5,%xmm3,%xmm11
+	vmulsd 0xc0(%rsp),%xmm11,%xmm11
+	vmulsd %xmm11,%xmm7,%xmm12
+	vmulsd %xmm11,%xmm10,%xmm11
+	vmovq  %xmm12,%r9
+	vmovsd %xmm11,-0x80(%rcx)
+	vmovsd %xmm11,0x140(%rsp)
+	vmovsd %xmm12,-0xb0(%rcx)
+	vmulsd 0xb8(%rsp),%xmm5,%xmm12
+	vmulsd 0xd0(%rsp),%xmm7,%xmm7
+	vmovq  %xmm12,%r14
+	vmulsd %xmm10,%xmm7,%xmm7
+	vmovq  %rsi,%xmm12
+	vmovq  %r14,%xmm15
+	vmulsd %xmm15,%xmm12,%xmm12
+	vmovq  %r13,%xmm15
+	vmovsd %xmm7,-0x68(%rcx)
+	vmulsd 0x150(%rsp),%xmm1,%xmm7
+	vmovsd %xmm12,-0xa8(%rcx)
+	vmovq  %xmm12,%rsi
+	vmovq  %r14,%xmm12
+	vmulsd %xmm12,%xmm15,%xmm15
+	vmovsd 0x168(%rsp),%xmm12
+	vmovsd %xmm15,-0x88(%rcx)
+	vmovq  %xmm15,%r11
+	vmulsd 0xb0(%rsp),%xmm1,%xmm15
+	vmulsd %xmm7,%xmm9,%xmm10
+	vmovsd %xmm10,-0x60(%rcx)
+	vmovq  %xmm15,%r13
+	vmulsd %xmm15,%xmm13,%xmm13
+	vmovq  %rdi,%xmm15
+	vmovq  %r13,%xmm11
+	vmulsd %xmm11,%xmm15,%xmm15
+	vfmadd231sd %xmm0,%xmm2,%xmm13
+	vfmadd132sd %xmm4,%xmm15,%xmm0
+	vmulsd 0xa8(%rsp),%xmm5,%xmm15
+	vmulsd %xmm12,%xmm13,%xmm13
+	vmulsd %xmm12,%xmm0,%xmm0
+	vmovsd %xmm13,-0xa0(%rcx)
+	vmovsd %xmm0,-0x90(%rcx)
+	vmovq  %xmm15,%r13
+	vmulsd %xmm3,%xmm1,%xmm15
+	vmulsd %xmm3,%xmm15,%xmm15
+	vmovq  %xmm15,%rax
+	vmovq  %r13,%xmm15
+	vmovq  %rax,%xmm12
+	vfmsub132sd %xmm15,%xmm12,%xmm14
+	vmulsd 0xa0(%rsp),%xmm14,%xmm15
+	vmulsd %xmm6,%xmm4,%xmm14
+	vfmsub231sd %xmm8,%xmm2,%xmm14
+	vmulsd 0x90(%rsp),%xmm14,%xmm14
+	vmovsd %xmm15,-0x98(%rcx)
+	vmovq  %xmm15,%rdx
+	vmovq  %rsi,%xmm15
+	vmulsd %xmm7,%xmm14,%xmm7
+	vmovsd %xmm14,-0x70(%rcx)
+	vmovsd %xmm7,-0x10(%rcx)
+	vmovsd 0x40(%rsp),%xmm7
+	vfmadd132sd %xmm5,%xmm3,%xmm7
+	vmulsd 0x38(%rsp),%xmm7,%xmm7
+	vmulsd %xmm7,%xmm6,%xmm6
+	vmulsd %xmm7,%xmm8,%xmm8
+	vmovq  %r12,%xmm7
+	vmovsd %xmm6,-0x18(%rcx)
+	vmovsd (%rsp),%xmm6
+	vmovsd %xmm8,-0x58(%rcx)
+	vfmadd132sd %xmm5,%xmm3,%xmm6
+	vmulsd 0x30(%rsp),%xmm6,%xmm6
+	vmulsd %xmm6,%xmm7,%xmm7
+	vmovsd %xmm7,-0x50(%rcx)
+	vmovq  %rbx,%xmm7
+	vmulsd %xmm6,%xmm7,%xmm6
+	vmulsd 0x28(%rsp),%xmm1,%xmm7
+	vmovsd %xmm6,-0x20(%rcx)
+	vmulsd %xmm13,%xmm4,%xmm6
+	vfmadd231sd %xmm7,%xmm15,%xmm6
+	vmulsd 0x20(%rsp),%xmm6,%xmm6
+	vmovq  %r15,%xmm7
+	vmovsd %xmm6,-0x48(%rcx)
+	vmulsd 0x148(%rsp),%xmm5,%xmm6
+	vmulsd %xmm5,%xmm6,%xmm5
+	vfmsub132sd %xmm3,%xmm5,%xmm3
+	vmulsd 0x18(%rsp),%xmm3,%xmm3
+	vmulsd 0x198(%rsp),%xmm3,%xmm5
+	vmulsd %xmm3,%xmm7,%xmm3
+	vmovsd %xmm5,-0x40(%rcx)
+	vmovsd %xmm3,-0x30(%rcx)
+	vmovsd 0x10(%rsp),%xmm7
+	vmovq  %rdx,%xmm3
+	vmulsd %xmm3,%xmm1,%xmm3
+	vmulsd 0xe8(%rsp),%xmm1,%xmm1
+	vmovsd 0x140(%rsp),%xmm11
+	vmulsd %xmm7,%xmm2,%xmm5
+	vfmsub231sd %xmm5,%xmm13,%xmm3
+	vmulsd %xmm7,%xmm4,%xmm5
+	vfmadd132sd %xmm5,%xmm3,%xmm0
+	vmovq  %r11,%xmm3
+	vmulsd 0x8(%rsp),%xmm0,%xmm0
+	vmulsd %xmm3,%xmm1,%xmm1
+	vmovq  %r9,%xmm3
+	vfmsub231sd %xmm3,%xmm2,%xmm1
+	vfmadd132sd %xmm4,%xmm1,%xmm11
+	vmulsd %xmm14,%xmm4,%xmm4
+	vmulsd 0xe0(%rsp),%xmm11,%xmm11
+	vmovsd %xmm0,-0x38(%rcx)
+	vfmsub132sd %xmm2,%xmm4,%xmm9
+	vmulsd 0xd8(%rsp),%xmm9,%xmm9
+	vmovsd %xmm11,-0x28(%rcx)
+	vmovsd %xmm9,-0x8(%rcx)
+	cmp    %rcx,%r10
+	jne    71e0 <cartesian_spherical_harmonics_l6._omp_fn.0+0x1b10>
+	jmp    6e6b <cartesian_spherical_harmonics_l6._omp_fn.0+0x179b>
+	xchg   %ax,%ax
+	inc    %eax
+	xor    %edx,%edx
+	jmp    571a <cartesian_spherical_harmonics_l6._omp_fn.0+0x4a>
+	nopl   0x0(%rax)
+	inc    %eax
+	xor    %edx,%edx
+	jmp    6e88 <cartesian_spherical_harmonics_l6._omp_fn.0+0x17b8>
+	nopl   0x0(%rax)
+
+0000000000007780 <_compute_no_dsph._omp_fn.0>:
+_compute_no_dsph._omp_fn.0():
+	push   %r15
+	push   %r14
+	push   %r13
+	push   %r12
+	push   %rbp
+	push   %rbx
+	sub    $0x68,%rsp
+	mov    0x10(%rdi),%rax
+	mov    0x1c(%rdi),%r13d
+	mov    (%rdi),%r14
+	mov    %rax,0x18(%rsp)
+	mov    0x8(%rdi),%rax
+	lea    0x1(%r13),%ebp
+	mov    %ebp,0x50(%rsp)
+	mov    %rax,0x20(%rsp)
+	mov    0x18(%rdi),%eax
+	lea    0x2(%r13),%edi
+	mov    %rdi,%rbx
+	imul   %rbp,%rdi
+	shl    $0x3,%rbp
+	shl    $0x3,%rdi
+	mov    %eax,0x14(%rsp)
+	shr    %rdi
+	call   10e0 <malloc@plt>
+	mov    %rbp,%rdi
+	mov    %rax,%r15
+	call   10e0 <malloc@plt>
+	mov    %rbp,%rdi
+	mov    %rax,%r12
+	call   10e0 <malloc@plt>
+	mov    %ebx,%edi
+	mov    0x50(%rsp),%ebx
+	mov    %rax,%rbp
+	imul   %ebx,%edi
+	shr    %edi
+	shl    $0x3,%rdi
+	call   10e0 <malloc@plt>
+	mov    %rax,0x8(%rsp)
+	test   %ebx,%ebx
+	je     7d8a <_compute_no_dsph._omp_fn.0+0x60a>
+	cmp    $0x1,%ebx
+	je     7d8a <_compute_no_dsph._omp_fn.0+0x60a>
+	vmovsd 0x5eec(%rip),%xmm1        
+	mov    0x50(%rsp),%r8d
+	vxorps %xmm5,%xmm5,%xmm5
+	mov    %rax,%rdi
+	mov    $0xffffffffffffffff,%r9
+	mov    $0x1,%r10d
+	mov    $0x1,%esi
+	nopw   0x0(%rax,%rax,1)
+	test   %r9d,%r9d
+	js     7d9c <_compute_no_dsph._omp_fn.0+0x61c>
+	movslq %r10d,%rax
+	lea    0x1(%rsi),%edx
+	lea    (%rdi,%rax,8),%rcx
+	mov    %r9,%rax
+	cs nopw 0x0(%rax,%rax,1)
+	mov    %esi,%ebx
+	lea    (%rdx,%rax,1),%r11d
+	sub    %eax,%ebx
+	imul   %ebx,%r11d
+	vcvtsi2sd %r11d,%xmm5,%xmm0
+	vdivsd %xmm0,%xmm1,%xmm0
+	vmovsd %xmm0,(%rcx,%rax,8)
+	dec    %rax
+	test   %eax,%eax
+	jns    7860 <_compute_no_dsph._omp_fn.0+0xe0>
+	mov    %edx,%esi
+	add    %edx,%r10d
+	inc    %r9
+	cmp    %r8d,%edx
+	jne    7840 <_compute_no_dsph._omp_fn.0+0xc0>
+	vmovsd 0x5e6a(%rip),%xmm2        
+	cmpl   $0x2,0x50(%rsp)
+	vmovsd %xmm1,0x10(%r15)
+	mov    $0xfffffffd,%esi
+	mov    0x50(%rsp),%r8d
+	mov    $0x3,%edx
+	mov    $0x2,%eax
+	vmovsd %xmm2,(%r15)
+	je     78e6 <_compute_no_dsph._omp_fn.0+0x166>
+	nopl   0x0(%rax)
+	movslq %edx,%rdi
+	vcvtsi2sd %esi,%xmm5,%xmm0
+	lea    (%rdx,%rax,1),%ecx
+	inc    %eax
+	vmulsd -0x8(%r15,%rdi,8),%xmm0,%xmm0
+	movslq %ecx,%rcx
+	add    %eax,%edx
+	sub    $0x2,%esi
+	vmovsd %xmm0,(%r15,%rcx,8)
+	cmp    %r8d,%eax
+	jne    78c0 <_compute_no_dsph._omp_fn.0+0x140>
+	movq   $0x0,0x0(%rbp)
+	vmovsd %xmm2,(%r12)
+	call   1090 <omp_get_num_threads@plt>
+	mov    %eax,%ebx
+	call   1080 <omp_get_thread_num@plt>
+	vxorps %xmm5,%xmm5,%xmm5
+	mov    %eax,%ecx
+	mov    0x14(%rsp),%eax
+	cltd
+	idiv   %ebx
+	cmp    %edx,%ecx
+	jl     7d81 <_compute_no_dsph._omp_fn.0+0x601>
+	imul   %eax,%ecx
+	add    %ecx,%edx
+	lea    (%rax,%rdx,1),%ecx
+	cmp    %ecx,%edx
+	jge    7d42 <_compute_no_dsph._omp_fn.0+0x5c2>
+	mov    0x50(%rsp),%ebx
+	mov    0x20(%rsp),%rdi
+	lea    (%rdx,%rdx,2),%esi
+	dec    %eax
+	movslq %esi,%rsi
+	vmovq  0x5e22(%rip),%xmm7        
+	mov    %ebx,%ecx
+	lea    (%rdi,%rsi,8),%rsi
+	imul   %ebx,%ecx
+	mov    %rsi,0x30(%rsp)
+	movslq %ecx,%rsi
+	imul   %edx,%ecx
+	movslq %edx,%rdx
+	add    %rax,%rdx
+	shl    $0x3,%rsi
+	lea    (%rdx,%rdx,2),%rax
+	mov    %rsi,0x40(%rsp)
+	mov    0x18(%rsp),%rsi
+	lea    0x18(%rdi,%rax,8),%rax
+	movslq %ecx,%rcx
+	mov    %rax,0x48(%rsp)
+	lea    -0x3(%r13),%eax
+	mov    %r14,%r13
+	mov    %eax,0x54(%rsp)
+	shr    %eax
+	lea    0x5(%rax,%rax,1),%rax
+	lea    0x30(%rsi,%rcx,8),%rsi
+	mov    %rax,0x58(%rsp)
+	mov    %ebx,%eax
+	mov    %rsi,0x38(%rsp)
+	mov    %rax,0x20(%rsp)
 	nop
-	mov    %rbx,(%rcx)
-	vmovsd 0x108(%rsp),%xmm5
-	add    $0x120,%rcx
-	add    $0x18,%rsi
-	vmovsd -0x8(%rsi),%xmm6
-	vmovsd -0x18(%rsi),%xmm0
-	vmulsd -0x10(%rsi),%xmm5,%xmm1
-	vmulsd %xmm5,%xmm6,%xmm6
-	vmulsd %xmm5,%xmm0,%xmm0
-	vmovsd 0x110(%rsp),%xmm5
-	vmovsd %xmm1,-0x118(%rcx)
-	vmovsd %xmm6,-0x110(%rcx)
-	vmovsd %xmm0,-0x108(%rcx)
-	vmovsd -0x18(%rsi),%xmm2
-	vmovsd -0x10(%rsi),%xmm3
-	vmovsd -0x8(%rsi),%xmm0
-	vmulsd %xmm2,%xmm2,%xmm11
-	vmulsd %xmm5,%xmm2,%xmm2
-	vmulsd %xmm1,%xmm2,%xmm15
-	vmulsd %xmm6,%xmm2,%xmm6
-	vmovsd 0xe8(%rsp),%xmm2
-	vmulsd %xmm3,%xmm3,%xmm3
-	vmulsd %xmm0,%xmm0,%xmm7
-	vmovsd %xmm15,-0x100(%rcx)
-	vmovsd %xmm6,-0xe8(%rcx)
-	vaddsd %xmm3,%xmm11,%xmm14
-	vsubsd %xmm3,%xmm11,%xmm8
-	vmulsd 0x30(%rsp),%xmm8,%xmm13
-	vmulsd %xmm5,%xmm0,%xmm0
-	vfnmadd132sd %xmm7,%xmm14,%xmm2
-	vmulsd 0x40(%rsp),%xmm2,%xmm2
-	vmulsd %xmm1,%xmm0,%xmm1
-	vmovsd 0x118(%rsp),%xmm0
-	vmovsd %xmm1,-0xf8(%rcx)
-	vmovsd %xmm13,-0xe0(%rcx)
-	vfnmadd132sd %xmm11,%xmm3,%xmm0
-	vmovsd %xmm2,-0xf0(%rcx)
-	vmovsd -0x10(%rsi),%xmm9
-	vmovsd -0x8(%rsi),%xmm4
-	vmulsd 0x88(%rsp),%xmm9,%xmm10
-	vmovsd -0x18(%rsi),%xmm5
-	vmulsd %xmm0,%xmm10,%xmm10
-	vmulsd 0xf0(%rsp),%xmm4,%xmm0
-	vmovsd %xmm10,-0xd8(%rcx)
-	vmulsd %xmm15,%xmm0,%xmm12
-	vmovsd 0x80(%rsp),%xmm0
-	vmovsd %xmm12,-0xd0(%rcx)
-	vmovq  %xmm12,%rdi
-	vfnmadd132sd %xmm7,%xmm14,%xmm0
-	vmulsd 0x78(%rsp),%xmm0,%xmm0
-	vmulsd %xmm0,%xmm9,%xmm9
-	vmulsd %xmm0,%xmm5,%xmm0
+	mov    0x30(%rsp),%rax
+	cmpl   $0x1,0x50(%rsp)
+	vmovsd 0x8(%rax),%xmm9
+	vmovsd (%rax),%xmm8
+	vmovsd 0x10(%rax),%xmm6
+	vmulsd %xmm9,%xmm9,%xmm4
+	vaddsd %xmm6,%xmm6,%xmm3
+	vfmadd231sd %xmm8,%xmm8,%xmm4
+	jbe    7a72 <_compute_no_dsph._omp_fn.0+0x2f2>
+	cmpl   $0xfffffffb,0x54(%rsp)
+	ja     7d77 <_compute_no_dsph._omp_fn.0+0x5f7>
+	vmovsd 0x0(%rbp),%xmm0
+	vmovsd (%r12),%xmm1
+	mov    $0x3,%edx
+	movslq %edx,%rax
+	vmulsd %xmm0,%xmm9,%xmm2
+	vmulsd %xmm0,%xmm8,%xmm0
+	vfmadd231sd %xmm1,%xmm9,%xmm0
+	vfmsub231sd %xmm1,%xmm8,%xmm2
+	vmulsd %xmm0,%xmm9,%xmm1
+	vmovsd %xmm0,-0x10(%rbp,%rdx,8)
+	vmulsd %xmm0,%xmm8,%xmm0
+	vfmsub231sd %xmm2,%xmm8,%xmm1
+	vfmadd231sd %xmm2,%xmm9,%xmm0
+	vunpcklpd %xmm1,%xmm2,%xmm10
+	vmovupd %xmm10,-0x10(%r12,%rdx,8)
+	vmovsd %xmm0,-0x8(%rbp,%rdx,8)
+	add    $0x2,%rdx
+	cmp    %rdx,0x58(%rsp)
+	jne    79e7 <_compute_no_dsph._omp_fn.0+0x267>
+	mov    0x50(%rsp),%edx
+	data16 cs nopw 0x0(%rax,%rax,1)
+	nop
+	vmovsd -0x8(%rbp,%rax,8),%xmm1
+	vmovsd -0x8(%r12,%rax,8),%xmm0
+	vmulsd %xmm1,%xmm9,%xmm2
+	vmulsd %xmm1,%xmm8,%xmm1
+	vfmsub231sd %xmm0,%xmm8,%xmm2
+	vfmadd132sd %xmm9,%xmm1,%xmm0
+	vmovsd %xmm2,(%r12,%rax,8)
+	vmovsd %xmm0,0x0(%rbp,%rax,8)
+	inc    %rax
+	cmp    %eax,%edx
+	ja     7a40 <_compute_no_dsph._omp_fn.0+0x2c0>
+	vmovsd (%r15),%xmm0
+	mov    0x38(%rsp),%rsi
+	vxorpd %xmm7,%xmm6,%xmm6
+	mov    $0x3,%r14d
+	vmulsd 0x0(%r13),%xmm0,%xmm0
+	cmpl   $0x2,0x50(%rsp)
+	mov    $0x10,%edx
+	mov    %r14d,%ebx
+	mov    %rsi,%rax
+	vmovsd %xmm0,-0x30(%rsi)
+	vmovsd 0x10(%r15),%xmm0
+	vmulsd %xmm0,%xmm6,%xmm1
+	vmovsd %xmm1,0x8(%r15)
+	vmulsd 0x8(%r13),%xmm1,%xmm1
+	vmovsd %xmm1,-0x20(%rsi)
+	vmulsd 0x10(%r13),%xmm0,%xmm0
+	vmulsd 0x8(%rbp),%xmm0,%xmm1
+	vmulsd 0x8(%r12),%xmm0,%xmm0
+	vmovsd %xmm1,-0x28(%rsi)
+	vmovsd %xmm0,-0x18(%rsi)
+	mov    $0x2,%esi
+	jbe    7d22 <_compute_no_dsph._omp_fn.0+0x5a2>
+	data16 cs nopw 0x0(%rax,%rax,1)
+	xchg   %ax,%ax
+	lea    (%rbx,%rsi,1),%ecx
+	mov    %rax,%rdi
+	mov    %esi,%r14d
+	movslq %ebx,%r8
+	movslq %ecx,%rcx
+	sub    %rdx,%rdi
+	shl    $0x3,%rcx
+	vmovsd (%r15,%rcx,1),%xmm0
+	vmulsd 0x0(%r13,%rcx,1),%xmm0,%xmm1
+	vmulsd 0x0(%rbp,%rdx,1),%xmm1,%xmm2
+	vmulsd (%r12,%rdx,1),%xmm1,%xmm1
+	vmulsd %xmm0,%xmm6,%xmm0
+	vmovsd %xmm0,-0x8(%r15,%rcx,1)
+	vmovsd %xmm2,(%rdi)
+	vmovsd %xmm1,(%rax,%rdx,1)
+	vmulsd -0x8(%r13,%rcx,1),%xmm0,%xmm0
+	mov    $0x8,%ecx
+	sub    %rdx,%rcx
+	lea    -0x2(%rsi),%edi
+	vmulsd -0x8(%rbp,%rdx,1),%xmm0,%xmm1
+	vmulsd -0x8(%r12,%rdx,1),%xmm0,%xmm0
+	vmovsd %xmm1,(%rax,%rcx,1)
+	vcvtsi2sd %esi,%xmm5,%xmm1
+	vmulsd %xmm3,%xmm1,%xmm1
+	vmovsd %xmm0,-0x8(%rax,%rdx,1)
+	test   %edi,%edi
+	je     7cd4 <_compute_no_dsph._omp_fn.0+0x554>
+	lea    -0x2(%rsi,%r8,1),%rcx
+	lea    (%r15,%rcx,8),%rcx
+	cmp    $0x4,%rsi
+	jbe    7c5e <_compute_no_dsph._omp_fn.0+0x4de>
+	lea    -0x5(%rsi),%r9d
+	lea    -0x4(%rsi),%r11d
+	mov    $0x18,%r10d
+	vmovsd 0x10(%rcx),%xmm8
+	and    $0xfffffffe,%r9d
+	sub    %rdx,%r10
+	vmovsd 0x8(%rcx),%xmm0
+	mov    %rdx,0x28(%rsp)
+	sub    %r9d,%r11d
+	lea    0x0(,%r8,8),%r9
+	add    %rax,%r10
+	lea    -0x10(%rdx),%rcx
+	mov    %r11d,0x14(%rsp)
+	mov    0x8(%rsp),%r11
+	add    %r9,%r11
+	mov    %r11,0x18(%rsp)
+	lea    (%r15,%r9,1),%r11
+	add    %r13,%r9
+	mov    0x18(%rsp),%rdx
+	vsubsd %xmm3,%xmm1,%xmm1
+	vmulsd %xmm8,%xmm4,%xmm8
+	sub    $0x2,%edi
+	add    $0x10,%r10
+	vfmadd231sd %xmm0,%xmm1,%xmm8
+	vsubsd %xmm3,%xmm1,%xmm1
+	vmulsd %xmm0,%xmm4,%xmm0
+	vmulsd (%rdx,%rcx,1),%xmm8,%xmm8
+	vmulsd (%r9,%rcx,1),%xmm8,%xmm2
+	vmulsd 0x0(%rbp,%rcx,1),%xmm2,%xmm9
+	vmulsd (%r12,%rcx,1),%xmm2,%xmm2
+	vfmadd231sd %xmm1,%xmm8,%xmm0
+	vmulsd -0x8(%rdx,%rcx,1),%xmm0,%xmm0
+	vmovsd %xmm8,(%r11,%rcx,1)
+	vmovsd %xmm9,-0x18(%r10)
+	vmovsd %xmm2,(%rax,%rcx,1)
+	vmulsd -0x8(%r9,%rcx,1),%xmm0,%xmm2
+	vmulsd -0x8(%rbp,%rcx,1),%xmm2,%xmm9
+	vmulsd -0x8(%r12,%rcx,1),%xmm2,%xmm2
+	vmovsd %xmm0,-0x8(%r11,%rcx,1)
+	vmovsd %xmm9,-0x10(%r10)
+	vmovsd %xmm2,-0x8(%rax,%rcx,1)
+	sub    $0x10,%rcx
+	cmp    %edi,0x14(%rsp)
+	jne    7bcf <_compute_no_dsph._omp_fn.0+0x44f>
+	mov    0x28(%rsp),%rdx
+	movslq %edi,%rcx
+	neg    %edi
+	lea    0x0(,%r8,8),%r10
+	movslq %edi,%rdi
+	lea    (%rax,%rdi,8),%r9
+	mov    0x8(%rsp),%rdi
+	lea    (%rdi,%r10,1),%r11
+	lea    (%r15,%r10,1),%rdi
+	add    %r13,%r10
+	data16 cs nopw 0x0(%rax,%rax,1)
+	nopl   (%rax)
+	vmulsd 0x10(%rdi,%rcx,8),%xmm4,%xmm0
+	vsubsd %xmm3,%xmm1,%xmm1
+	add    $0x8,%r9
+	vfmadd231sd 0x8(%rdi,%rcx,8),%xmm1,%xmm0
+	vmulsd (%r11,%rcx,8),%xmm0,%xmm0
+	vmovsd %xmm0,(%rdi,%rcx,8)
+	vmulsd (%r10,%rcx,8),%xmm0,%xmm0
+	vmulsd 0x0(%rbp,%rcx,8),%xmm0,%xmm2
+	vmulsd (%r12,%rcx,8),%xmm0,%xmm0
+	vmovsd %xmm2,-0x8(%r9)
+	vmovsd %xmm0,(%rax,%rcx,8)
+	dec    %rcx
+	test   %ecx,%ecx
+	jne    7c90 <_compute_no_dsph._omp_fn.0+0x510>
+	vmulsd 0x10(%r15,%r8,8),%xmm4,%xmm0
+	mov    0x8(%rsp),%rdi
+	lea    0x0(,%r8,8),%rcx
+	lea    0x1(%rbx,%r14,1),%ebx
+	inc    %rsi
+	vfmadd231sd 0x8(%r15,%r8,8),%xmm3,%xmm0
+	vmulsd (%rdi,%r8,8),%xmm0,%xmm0
+	vmovsd %xmm0,(%r15,%rcx,1)
+	vmulsd 0x0(%r13,%rcx,1),%xmm0,%xmm0
+	vmovsd %xmm0,(%rax)
+	lea    0x10(%rax,%rdx,2),%rax
+	add    $0x8,%rdx
+	cmp    %rsi,0x20(%rsp)
+	jne    7af0 <_compute_no_dsph._omp_fn.0+0x370>
+	addq   $0x18,0x30(%rsp)
+	mov    0x40(%rsp),%rsi
+	mov    0x30(%rsp),%rax
+	add    %rsi,0x38(%rsp)
+	cmp    0x48(%rsp),%rax
+	jne    79a0 <_compute_no_dsph._omp_fn.0+0x220>
+	call   1070 <GOMP_barrier@plt>
+	mov    0x8(%rsp),%rdi
+	call   1030 <free@plt>
+	mov    %r15,%rdi
+	call   1030 <free@plt>
+	mov    %r12,%rdi
+	call   1030 <free@plt>
+	add    $0x68,%rsp
+	mov    %rbp,%rdi
+	pop    %rbx
+	pop    %rbp
+	pop    %r12
+	pop    %r13
+	pop    %r14
+	pop    %r15
+	jmp    1030 <free@plt>
+	mov    $0x1,%eax
+	jmp    7a30 <_compute_no_dsph._omp_fn.0+0x2b0>
+	inc    %eax
+	xor    %edx,%edx
+	jmp    7915 <_compute_no_dsph._omp_fn.0+0x195>
+	vmovsd 0x596e(%rip),%xmm2        
+	vmovsd %xmm2,(%r15)
+	jmp    78e6 <_compute_no_dsph._omp_fn.0+0x166>
+	lea    0x1(%rsi),%edx
+	jmp    7881 <_compute_no_dsph._omp_fn.0+0x101>
+	data16 cs nopw 0x0(%rax,%rax,1)
+	nop
+
+0000000000007db0 <_compute_with_dsph._omp_fn.0>:
+_compute_with_dsph._omp_fn.0():
+	push   %r15
+	push   %r14
+	push   %r13
+	push   %r12
+	push   %rbp
+	push   %rbx
+	sub    $0xf8,%rsp
+	mov    0x18(%rdi),%rax
+	mov    0x24(%rdi),%ebp
+	mov    0x8(%rdi),%r13
+	mov    0x20(%rdi),%r12d
+	mov    %rax,(%rsp)
+	mov    0x10(%rdi),%rax
+	lea    0x1(%rbp),%r14d
+	mov    %r14d,0xe0(%rsp)
+	mov    %rax,0x10(%rsp)
+	mov    (%rdi),%rax
+	lea    0x2(%rbp),%edi
+	mov    %rdi,%rbx
+	imul   %r14,%rdi
+	shl    $0x3,%r14
+	shl    $0x3,%rdi
+	mov    %rax,0x20(%rsp)
+	shr    %rdi
+	call   10e0 <malloc@plt>
+	mov    %r14,%rdi
+	mov    %rax,0x8(%rsp)
+	call   10e0 <malloc@plt>
+	mov    %r14,%rdi
+	mov    %rax,%r15
+	call   10e0 <malloc@plt>
+	mov    %ebx,%edi
+	mov    0xe0(%rsp),%ebx
+	mov    %rax,%r14
+	imul   %ebx,%edi
+	shr    %edi
+	shl    $0x3,%rdi
+	call   10e0 <malloc@plt>
+	mov    %rax,0x50(%rsp)
+	test   %ebx,%ebx
+	je     89b2 <_compute_with_dsph._omp_fn.0+0xc02>
+	cmp    $0x1,%ebx
+	je     89b2 <_compute_with_dsph._omp_fn.0+0xc02>
+	vmovsd 0x58ad(%rip),%xmm2        
+	mov    0xe0(%rsp),%edi
+	vxorps %xmm1,%xmm1,%xmm1
+	mov    %rax,%r8
+	mov    $0xffffffffffffffff,%r9
+	mov    $0x1,%r10d
+	mov    $0x1,%esi
+	nopl   0x0(%rax,%rax,1)
+	test   %r9d,%r9d
+	js     89c8 <_compute_with_dsph._omp_fn.0+0xc18>
+	movslq %r10d,%rax
+	lea    0x1(%rsi),%edx
+	lea    (%r8,%rax,8),%rcx
+	mov    %r9,%rax
+	cs nopw 0x0(%rax,%rax,1)
+	mov    %esi,%ebx
+	lea    (%rdx,%rax,1),%r11d
+	sub    %eax,%ebx
+	imul   %ebx,%r11d
+	vcvtsi2sd %r11d,%xmm1,%xmm0
+	vdivsd %xmm0,%xmm2,%xmm0
+	vmovsd %xmm0,(%rcx,%rax,8)
+	dec    %rax
+	test   %eax,%eax
+	jns    7ea0 <_compute_with_dsph._omp_fn.0+0xf0>
+	mov    %edx,%esi
+	add    %edx,%r10d
+	inc    %r9
+	cmp    %edi,%edx
+	jne    7e80 <_compute_with_dsph._omp_fn.0+0xd0>
+	vmovsd 0x582b(%rip),%xmm3        
+	cmpl   $0x2,0xe0(%rsp)
+	mov    $0xfffffffd,%esi
+	mov    $0x3,%edx
+	mov    0x8(%rsp),%rax
+	vmovsd %xmm2,0x10(%rax)
+	vmovsd %xmm3,(%rax)
+	mov    $0x2,%eax
+	je     7f35 <_compute_with_dsph._omp_fn.0+0x185>
+	mov    0xe0(%rsp),%r9d
+	mov    0x8(%rsp),%rdi
+	nopl   0x0(%rax)
+	movslq %edx,%r8
+	vcvtsi2sd %esi,%xmm1,%xmm0
+	lea    (%rdx,%rax,1),%ecx
+	inc    %eax
+	vmulsd -0x8(%rdi,%r8,8),%xmm0,%xmm0
+	movslq %ecx,%rcx
+	add    %eax,%edx
+	sub    $0x2,%esi
+	vmovsd %xmm0,(%rdi,%rcx,8)
+	cmp    %r9d,%eax
+	jne    7f10 <_compute_with_dsph._omp_fn.0+0x160>
+	vmovsd %xmm3,(%r15)
+	movq   $0x0,(%r14)
+	call   1090 <omp_get_num_threads@plt>
+	mov    %eax,%ebx
+	call   1080 <omp_get_thread_num@plt>
+	vxorps %xmm1,%xmm1,%xmm1
+	mov    %eax,%ecx
+	mov    %r12d,%eax
+	cltd
+	idiv   %ebx
+	cmp    %edx,%ecx
+	jl     89a9 <_compute_with_dsph._omp_fn.0+0xbf9>
+	imul   %eax,%ecx
+	add    %ecx,%edx
+	lea    (%rax,%rdx,1),%ecx
+	cmp    %ecx,%edx
+	jge    894c <_compute_with_dsph._omp_fn.0+0xb9c>
+	mov    0xe0(%rsp),%ebx
+	dec    %eax
+	mov    %r14,%r12
+	mov    %ebx,%edi
+	imul   %ebx,%edi
+	lea    (%rdi,%rdi,1),%r8d
+	movslq %edi,%rcx
+	mov    %edi,%esi
+	lea    0x0(,%rcx,8),%rbx
+	imul   %edx,%esi
+	movslq %r8d,%rcx
+	mov    %rbx,0x30(%rsp)
+	lea    0x0(,%rcx,8),%rbx
+	lea    0x2(%rdi),%ecx
+	movslq %ecx,%rcx
+	mov    %rbx,0x38(%rsp)
+	lea    0x0(,%rcx,8),%rbx
+	lea    0x2(%r8),%ecx
+	movslq %ecx,%rcx
+	mov    %rbx,0xa0(%rsp)
+	lea    0x0(,%rcx,8),%rbx
+	lea    0x1(%rdi),%ecx
+	movslq %ecx,%rcx
+	mov    %rbx,0xa8(%rsp)
+	lea    0x0(,%rcx,8),%rbx
+	lea    0x1(%r8),%ecx
+	movslq %ecx,%rcx
+	mov    %rbx,0xb0(%rsp)
+	lea    0x0(,%rcx,8),%rbx
+	lea    0x3(%rdi),%ecx
+	movslq %ecx,%rcx
+	mov    %rbx,0xb8(%rsp)
+	lea    0x0(,%rcx,8),%rbx
+	lea    0x3(%r8),%ecx
+	movslq %ecx,%rcx
+	mov    %rbx,0xc0(%rsp)
+	lea    0x0(,%rcx,8),%rbx
+	lea    (%rdx,%rdx,2),%ecx
+	movslq %edx,%rdx
+	movslq %ecx,%rcx
+	mov    %rbx,0xc8(%rsp)
+	add    %rax,%rdx
+	lea    0x0(%r13,%rcx,8),%rbx
+	movslq %esi,%rcx
+	lea    (%rdx,%rdx,2),%rax
+	mov    %rbx,0x88(%rsp)
+	mov    0x10(%rsp),%rbx
+	lea    0x18(%r13,%rax,8),%rax
+	mov    %r15,%r13
+	mov    %rax,0xd8(%rsp)
+	lea    -0x3(%rbp),%eax
+	mov    %eax,0xe4(%rsp)
+	shr    %eax
+	lea    0x5(%rax,%rax,1),%rax
+	lea    0x30(%rbx,%rcx,8),%rbx
+	lea    (%r8,%rdi,1),%ecx
+	mov    %rax,0xe8(%rsp)
+	movslq %ecx,%rcx
+	mov    %rbx,0x90(%rsp)
+	lea    0x0(,%rcx,8),%rbx
+	lea    (%rsi,%rsi,2),%ecx
+	mov    %rbx,0xd0(%rsp)
+	mov    (%rsp),%rbx
+	movslq %ecx,%rcx
+	lea    0x30(%rbx,%rcx,8),%rbx
+	mov    %rbx,0x98(%rsp)
+	nopl   0x0(%rax,%rax,1)
+	mov    0x88(%rsp),%rax
+	cmpl   $0x1,0xe0(%rsp)
+	vmovsd 0x8(%rax),%xmm4
+	vmovsd (%rax),%xmm3
+	vmovsd 0x10(%rax),%xmm8
+	vmulsd %xmm4,%xmm4,%xmm6
+	vaddsd %xmm8,%xmm8,%xmm5
+	vfmadd231sd %xmm3,%xmm3,%xmm6
+	jbe    81a4 <_compute_with_dsph._omp_fn.0+0x3f4>
+	cmpl   $0xfffffffb,0xe4(%rsp)
+	ja     899f <_compute_with_dsph._omp_fn.0+0xbef>
+	vmovsd (%r12),%xmm0
+	vmovsd 0x0(%r13),%xmm2
+	mov    $0x3,%edx
+	movslq %edx,%rax
+	vmulsd %xmm0,%xmm4,%xmm7
+	vmulsd %xmm0,%xmm3,%xmm0
+	vfmadd231sd %xmm2,%xmm4,%xmm0
+	vfmsub231sd %xmm2,%xmm3,%xmm7
+	vmulsd %xmm0,%xmm4,%xmm2
+	vmovsd %xmm0,-0x10(%r12,%rdx,8)
+	vmulsd %xmm0,%xmm3,%xmm0
+	vfmsub231sd %xmm7,%xmm3,%xmm2
+	vfmadd231sd %xmm7,%xmm4,%xmm0
+	vunpcklpd %xmm2,%xmm7,%xmm9
+	vmovupd %xmm9,-0x10(%r13,%rdx,8)
+	vmovsd %xmm0,-0x8(%r12,%rdx,8)
+	add    $0x2,%rdx
+	cmp    0xe8(%rsp),%rdx
+	jne    8111 <_compute_with_dsph._omp_fn.0+0x361>
+	mov    0xe0(%rsp),%edx
+	cs nopw 0x0(%rax,%rax,1)
+	vmovsd -0x8(%r12,%rax,8),%xmm2
+	vmovsd -0x8(%r13,%rax,8),%xmm0
+	vmulsd %xmm2,%xmm4,%xmm7
+	vmulsd %xmm2,%xmm3,%xmm2
+	vfmsub231sd %xmm0,%xmm3,%xmm7
+	vfmadd132sd %xmm4,%xmm2,%xmm0
+	vmovsd %xmm7,0x0(%r13,%rax,8)
+	vmovsd %xmm0,(%r12,%rax,8)
+	inc    %rax
+	cmp    %eax,%edx
+	ja     8170 <_compute_with_dsph._omp_fn.0+0x3c0>
+	mov    0x8(%rsp),%rsi
+	mov    0x20(%rsp),%rdi
+	mov    0x90(%rsp),%rdx
+	vxorpd 0x55a2(%rip),%xmm8,%xmm7        
+	mov    0x98(%rsp),%rax
+	mov    0x30(%rsp),%rcx
+	vmovsd (%rsi),%xmm0
+	vmulsd (%rdi),%xmm0,%xmm0
+	mov    %rdx,%r14
+	mov    %rax,%rbx
+	vmovsd %xmm7,0x70(%rsp)
+	vmovsd %xmm0,-0x30(%rdx)
+	vmovsd 0x10(%rsi),%xmm0
+	movq   $0x0,-0x30(%rax)
+	movq   $0x0,-0x30(%rax,%rcx,1)
+	mov    0x38(%rsp),%rcx
+	movq   $0x0,-0x30(%rax,%rcx,1)
+	vmulsd %xmm7,%xmm0,%xmm2
+	vmovsd %xmm2,0x8(%rsi)
+	vmulsd 0x8(%rdi),%xmm2,%xmm2
+	vmovsd %xmm2,-0x20(%rdx)
+	vmulsd 0x10(%rdi),%xmm0,%xmm0
+	vmulsd 0x8(%r12),%xmm0,%xmm2
+	vmulsd 0x8(%r13),%xmm0,%xmm0
+	vmovsd %xmm2,-0x28(%rdx)
+	vmovsd %xmm0,-0x18(%rdx)
+	mov    0xa0(%rsp),%rdx
+	movq   $0x0,-0x20(%rax)
+	movq   $0x0,-0x30(%rax,%rdx,1)
+	vmovsd 0x8(%rdi),%xmm0
+	mov    0xa8(%rsp),%rdx
+	vmovsd %xmm0,-0x30(%rax,%rdx,1)
+	movq   $0x0,-0x28(%rax)
+	vmovsd 0x8(%rdi),%xmm0
+	mov    0xb0(%rsp),%rdx
+	vmovsd %xmm0,-0x30(%rax,%rdx,1)
+	mov    0xb8(%rsp),%rdx
+	cmpl   $0x2,0xe0(%rsp)
+	movq   $0x0,-0x30(%rax,%rdx,1)
+	vmovsd 0x8(%rdi),%xmm0
+	mov    0xc0(%rsp),%rdi
+	vmovsd %xmm0,-0x18(%rax)
+	movq   $0x0,-0x30(%rax,%rdi,1)
+	mov    0xc8(%rsp),%rdi
+	movq   $0x0,-0x30(%rax,%rdi,1)
+	jbe    890a <_compute_with_dsph._omp_fn.0+0xb5a>
+	mov    $0x8,%r9d
+	mov    $0xfffffffffffffff0,%r15
+	movq   $0x0,(%rsp)
+	mov    $0x2,%ebp
+	movl   $0x3,0x10(%rsp)
+	mov    %r9,%r11
+	xchg   %ax,%ax
+	mov    0x10(%rsp),%eax
+	mov    %r15,%rcx
+	mov    0x8(%rsp),%r10
+	mov    0x20(%rsp),%r8
+	neg    %rcx
+	vmovsd (%r12,%r11,1),%xmm8
+	vmovsd 0x0(%r13,%r11,1),%xmm10
+	mov    0x30(%rsp),%rdi
+	lea    (%rax,%rbp,1),%edx
+	movslq %edx,%rax
+	dec    %edx
+	shl    $0x3,%rax
+	sub    %ebp,%edx
+	vmovsd (%r10,%rax,1),%xmm2
+	lea    (%rbx,%rdi,1),%rsi
+	movslq %edx,%rdx
+	vmulsd (%r8,%rax,1),%xmm2,%xmm0
+	vmulsd 0x70(%rsp),%xmm2,%xmm2
+	mov    %rsi,0x28(%rsp)
+	vmulsd 0x8(%r12,%r11,1),%xmm0,%xmm7
+	vmovsd %xmm2,-0x8(%r10,%rax,1)
+	sub    $0x8,%rax
+	add    %r8,%rax
+	lea    -0x1(%rbp),%r8d
+	mov    %r8d,0x5c(%rsp)
+	vmovsd %xmm7,(%r14,%r15,1)
+	vmulsd 0x8(%r13,%r11,1),%xmm0,%xmm7
+	vmovsd %xmm7,(%r14,%rcx,1)
+	vcvtsi2sd %ebp,%xmm1,%xmm7
+	vmulsd %xmm7,%xmm0,%xmm0
+	vmulsd %xmm8,%xmm0,%xmm9
+	vmovsd %xmm9,(%rbx,%r15,1)
+	vmulsd %xmm10,%xmm0,%xmm9
+	vxorpd 0x53cd(%rip),%xmm0,%xmm0        
+	vmovsd %xmm9,(%rbx,%rcx,1)
+	vmovsd %xmm9,(%rsi,%r15,1)
+	mov    0x38(%rsp),%rsi
+	mov    %rdi,%rcx
+	sub    %r15,%rcx
+	sub    %r11,%rdi
+	vmovsd -0x8(%r12,%r11,1),%xmm9
+	lea    (%rbx,%rsi,1),%r9
+	vmulsd %xmm8,%xmm0,%xmm0
+	vmovsd %xmm0,(%rbx,%rcx,1)
+	mov    %rsi,%rcx
+	movq   $0x0,(%r9,%r15,1)
+	sub    %r15,%rcx
+	movq   $0x0,(%rbx,%rcx,1)
+	vmulsd (%rax),%xmm2,%xmm2
+	lea    -0x1(%rbp,%rbp,1),%ecx
+	vmulsd %xmm2,%xmm8,%xmm0
+	vmovsd %xmm0,0x8(%r14,%r15,1)
+	vmulsd %xmm2,%xmm10,%xmm0
+	vmovsd %xmm0,(%r14,%r11,1)
+	vcvtsi2sd %r8d,%xmm1,%xmm0
+	vmulsd %xmm2,%xmm0,%xmm0
+	vmulsd %xmm9,%xmm0,%xmm2
+	vmovsd %xmm2,0x8(%rbx,%r15,1)
+	vmovsd -0x8(%r13,%r11,1),%xmm2
+	vmulsd %xmm2,%xmm0,%xmm11
+	vmovsd %xmm11,(%rbx,%r11,1)
+	vmovsd %xmm11,(%rbx,%rdi,1)
+	vxorpd 0x5339(%rip),%xmm0,%xmm0        
+	mov    0x28(%rsp),%rdi
+	vmulsd %xmm9,%xmm0,%xmm0
+	vmovsd %xmm0,(%rdi,%r11,1)
+	vcvtsi2sd %ecx,%xmm1,%xmm0
+	vmulsd (%rax),%xmm0,%xmm0
+	mov    %rsi,%rax
+	sub    %r11,%rax
+	vmulsd (%r10,%rdx,8),%xmm0,%xmm0
+	vmulsd %xmm0,%xmm8,%xmm8
+	vmulsd %xmm0,%xmm10,%xmm0
+	vmovsd %xmm8,(%rbx,%rax,1)
+	mov    (%rsp),%rax
+	vmovsd %xmm0,(%r9,%r11,1)
+	vmulsd %xmm7,%xmm5,%xmm0
+	mov    %eax,%esi
+	test   %rax,%rax
+	je     8990 <_compute_with_dsph._omp_fn.0+0xbe0>
+	movslq 0x10(%rsp),%rcx
+	mov    %rax,%rdx
+	mov    %rax,%rdi
+	add    %rcx,%rdx
+	mov    %rcx,0x18(%rsp)
+	shl    $0x3,%rdx
+	lea    (%r10,%rdx,1),%rax
+	cmp    $0x4,%ebp
+	jle    8718 <_compute_with_dsph._omp_fn.0+0x968>
+	mov    0x30(%rsp),%r8
+	vmovsd 0x10(%rax),%xmm11
+	lea    -0x10(%r10,%rcx,8),%rcx
+	mov    %r11,0x78(%rsp)
+	vmovsd 0x8(%rax),%xmm10
+	mov    %rdi,%rax
+	lea    0x18(%r15),%r10
+	lea    0x10(%r15),%rdi
+	neg    %rax
+	add    0x20(%rsp),%rdx
+	mov    %r15,0x80(%rsp)
+	shl    $0x3,%rax
+	lea    (%r8,%rax,1),%rsi
+	add    0x38(%rsp),%rax
+	lea    (%rbx,%rsi,1),%r8
+	mov    $0x2,%esi
+	sub    (%rsp),%rsi
+	mov    %r8,%r11
+	mov    0x28(%rsp),%r8
+	add    %rbx,%rax
+	mov    %rax,0x60(%rsp)
+	lea    -0x5(%rbp),%eax
+	mov    0x60(%rsp),%r15
+	shr    %eax
+	lea    (%rsi,%rax,2),%rax
+	lea    0x0(,%rax,8),%rsi
+	mov    %rsi,0x68(%rsp)
+	mov    0x18(%rsp),%rsi
+	lea    0x0(,%rsi,8),%rax
+	mov    0x50(%rsp),%rsi
+	add    %rax,%rsi
+	mov    %rsi,0x48(%rsp)
+	mov    0x8(%rsp),%rsi
+	add    %rax,%rsi
+	mov    (%rsp),%rax
+	mov    %rsi,0x40(%rsp)
+	mov    0x48(%rsp),%rsi
+	vsubsd %xmm5,%xmm0,%xmm0
+	vmulsd %xmm11,%xmm6,%xmm11
+	sub    $0x10,%rdx
+	vmovsd -0x8(%r12,%rax,8),%xmm14
+	sub    $0x10,%rcx
+	add    $0x10,%r11
+	add    $0x10,%r15
+	vfmadd231sd %xmm10,%xmm0,%xmm11
+	vsubsd %xmm5,%xmm0,%xmm0
+	vmulsd %xmm10,%xmm6,%xmm10
+	vmulsd (%rsi,%rax,8),%xmm11,%xmm11
+	mov    0x40(%rsp),%rsi
+	vmulsd 0x10(%rdx),%xmm11,%xmm12
+	vmovsd %xmm11,(%rsi,%rax,8)
+	vfmadd231sd %xmm0,%xmm11,%xmm10
+	vmulsd %xmm9,%xmm12,%xmm8
+	vmovsd %xmm8,(%r14,%rdi,1)
+	vmulsd %xmm2,%xmm12,%xmm8
+	vmovsd %xmm8,(%r14,%rax,8)
+	vcvtsi2sd %eax,%xmm1,%xmm8
+	vmulsd %xmm12,%xmm8,%xmm8
+	vmovsd 0x10(%rdx),%xmm12
+	vmulsd 0x18(%rcx),%xmm12,%xmm12
+	vmulsd %xmm14,%xmm8,%xmm13
+	vmovq  %xmm13,%rsi
+	vmulsd %xmm12,%xmm3,%xmm15
+	vmulsd %xmm12,%xmm4,%xmm12
+	vfmadd231sd %xmm9,%xmm15,%xmm13
+	vmovsd %xmm13,(%rbx,%rdi,1)
+	vmovsd -0x8(%r13,%rax,8),%xmm13
+	add    $0x10,%rdi
+	vmulsd %xmm13,%xmm8,%xmm8
+	vfmadd132sd %xmm2,%xmm8,%xmm15
+	vfmadd231sd %xmm9,%xmm12,%xmm8
+	vmovsd %xmm15,(%rbx,%rax,8)
+	vmovq  %rsi,%xmm15
+	lea    0x0(%rbp,%rax,1),%esi
+	vmovsd %xmm8,-0x10(%r11)
+	vfmsub132sd %xmm2,%xmm15,%xmm12
+	vcvtsi2sd %esi,%xmm1,%xmm8
+	mov    0x48(%rsp),%rsi
+	vmovsd %xmm12,(%r8,%rax,8)
+	vmulsd 0x10(%rdx),%xmm8,%xmm8
+	vmulsd -0x8(%rsi,%rax,8),%xmm10,%xmm10
+	mov    0x40(%rsp),%rsi
+	vmulsd 0x10(%rcx),%xmm8,%xmm8
+	vmovsd %xmm10,-0x8(%rsi,%rax,8)
+	vmovsd 0x10(%rcx),%xmm12
+	lea    -0x1(%rax),%esi
+	vmulsd %xmm9,%xmm8,%xmm9
+	vmulsd %xmm2,%xmm8,%xmm8
+	vmovsd %xmm9,-0x10(%r15)
+	vmovsd %xmm8,(%r9,%rax,8)
+	vmulsd 0x8(%rdx),%xmm10,%xmm2
+	vmovsd -0x10(%r12,%rax,8),%xmm9
+	vmulsd %xmm2,%xmm14,%xmm8
+	vmovsd %xmm8,(%r14,%r10,1)
+	vmulsd %xmm2,%xmm13,%xmm8
+	vmovsd %xmm8,-0x8(%r14,%rax,8)
+	vmulsd 0x8(%rdx),%xmm12,%xmm12
+	vcvtsi2sd %esi,%xmm1,%xmm8
+	vmulsd %xmm2,%xmm8,%xmm8
+	vmulsd %xmm8,%xmm9,%xmm2
+	vmovq  %xmm2,%rsi
+	vmulsd %xmm12,%xmm3,%xmm15
+	vmulsd %xmm12,%xmm4,%xmm12
+	vfmadd231sd %xmm15,%xmm14,%xmm2
+	vmovsd %xmm2,(%rbx,%r10,1)
+	vmovsd -0x10(%r13,%rax,8),%xmm2
+	add    $0x10,%r10
+	vmulsd %xmm8,%xmm2,%xmm8
+	vfmadd132sd %xmm13,%xmm8,%xmm15
+	vfmadd231sd %xmm12,%xmm14,%xmm8
+	vmovsd %xmm15,-0x8(%rbx,%rax,8)
+	vmovq  %rsi,%xmm15
+	vmovsd %xmm8,-0x8(%r11)
+	mov    0x5c(%rsp),%esi
+	vfmsub132sd %xmm13,%xmm15,%xmm12
+	add    %eax,%esi
+	vcvtsi2sd %esi,%xmm1,%xmm8
+	lea    -0x2(%rax),%esi
+	vmovsd %xmm12,-0x8(%r8,%rax,8)
+	vmulsd 0x8(%rdx),%xmm8,%xmm8
+	vmulsd 0x8(%rcx),%xmm8,%xmm8
+	vmulsd %xmm8,%xmm14,%xmm14
+	vmulsd %xmm8,%xmm13,%xmm8
+	vmovsd %xmm14,-0x8(%r15)
+	vmovsd %xmm8,-0x8(%r9,%rax,8)
+	sub    $0x2,%rax
+	cmp    0x68(%rsp),%rdi
+	jne    8539 <_compute_with_dsph._omp_fn.0+0x789>
+	mov    0x78(%rsp),%r11
+	mov    0x80(%rsp),%r15
+	mov    %r8,0x28(%rsp)
+	mov    0x18(%rsp),%rdi
+	movslq %esi,%rax
+	neg    %esi
+	mov    %r11,0x40(%rsp)
+	mov    0x8(%rsp),%rcx
+	movslq %esi,%rsi
+	mov    0x28(%rsp),%r8
+	shl    $0x3,%rsi
+	lea    (%rax,%rdi,1),%rdx
+	shl    $0x3,%rdi
+	lea    (%rcx,%rdx,8),%rdx
+	mov    0x50(%rsp),%rcx
+	add    %rdi,%rcx
+	add    0x20(%rsp),%rdi
+	mov    %rcx,%r11
+	data16 cs nopw 0x0(%rax,%rax,1)
+	nop
+	vmulsd 0x10(%rdx),%xmm6,%xmm10
+	vsubsd %xmm5,%xmm0,%xmm0
+	vmovsd (%r12,%rax,8),%xmm8
+	mov    %rax,%rcx
+	vmovsd 0x0(%r13,%rax,8),%xmm9
+	neg    %rcx
+	lea    0x0(%rbp,%rax,1),%r10d
+	sub    $0x8,%rdx
+	shl    $0x3,%rcx
+	vfmadd231sd 0x10(%rdx),%xmm0,%xmm10
+	vmulsd (%r11,%rax,8),%xmm10,%xmm10
+	vmovsd %xmm10,0x8(%rdx)
+	vmulsd (%rdi,%rax,8),%xmm10,%xmm10
+	vmulsd %xmm10,%xmm8,%xmm2
+	vmovsd %xmm2,(%r14,%rsi,1)
+	vmulsd %xmm10,%xmm9,%xmm2
+	vmovsd %xmm2,(%r14,%rax,8)
+	vcvtsi2sd %eax,%xmm1,%xmm2
+	vmulsd %xmm10,%xmm2,%xmm2
+	vmulsd -0x8(%r12,%rax,8),%xmm2,%xmm12
+	vmovsd 0x10(%rdx,%r15,1),%xmm10
+	vmulsd (%rdi,%rax,8),%xmm10,%xmm10
+	vmulsd -0x8(%r13,%rax,8),%xmm2,%xmm2
+	vmulsd %xmm10,%xmm3,%xmm11
+	vmulsd %xmm10,%xmm4,%xmm10
+	vmovsd %xmm11,%xmm11,%xmm13
+	vfmadd132sd %xmm9,%xmm2,%xmm11
+	vfmadd132sd %xmm8,%xmm12,%xmm13
+	vfmadd231sd %xmm8,%xmm10,%xmm2
+	vfmsub132sd %xmm9,%xmm12,%xmm10
+	vmovsd %xmm13,(%rbx,%rsi,1)
+	vmovsd %xmm11,(%rbx,%rax,8)
+	vmovsd %xmm2,(%r8,%rcx,1)
+	vcvtsi2sd %r10d,%xmm1,%xmm2
+	vmovsd %xmm10,(%r8,%rax,8)
+	add    $0x8,%rsi
+	vmulsd (%rdi,%rax,8),%xmm2,%xmm2
+	vmulsd 0x8(%rdx,%r15,1),%xmm2,%xmm2
+	vmulsd %xmm8,%xmm2,%xmm8
+	vmulsd %xmm9,%xmm2,%xmm2
+	vmovsd %xmm8,(%r9,%rcx,1)
+	vmovsd %xmm2,(%r9,%rax,8)
+	dec    %rax
+	test   %eax,%eax
+	jne    8760 <_compute_with_dsph._omp_fn.0+0x9b0>
+	mov    0x40(%rsp),%r11
+	mov    0x8(%rsp),%rdi
+	mov    0x18(%rsp),%rsi
+	sub    $0x8,%r15
+	add    $0x8,%r11
+	mov    0x50(%rsp),%rdx
+	vmulsd 0x10(%rdi,%rsi,8),%xmm6,%xmm0
+	lea    0x0(,%rsi,8),%rax
+	vfmadd231sd 0x8(%rdi,%rsi,8),%xmm5,%xmm0
+	vmulsd (%rdx,%rsi,8),%xmm0,%xmm0
+	mov    0x10(%rsp),%esi
+	mov    %esi,%edx
+	sub    %ebp,%edx
+	inc    %ebp
+	lea    0x1(%rdx),%ecx
+	movslq %edx,%rdx
+	add    %ebp,%esi
+	movslq %ecx,%rcx
+	mov    %esi,0x10(%rsp)
+	vmovsd %xmm0,(%rdi,%rax,1)
+	add    0x20(%rsp),%rax
+	vmovsd (%rdi,%rcx,8),%xmm8
+	mov    0x30(%rsp),%rcx
+	vmulsd (%rax),%xmm0,%xmm0
+	vmovsd %xmm0,(%r14)
+	vmulsd (%rax),%xmm3,%xmm2
+	vmulsd %xmm8,%xmm2,%xmm2
+	vmovsd %xmm2,(%rbx)
+	vmulsd (%rax),%xmm4,%xmm0
+	vmulsd %xmm8,%xmm0,%xmm0
+	vmovsd %xmm0,(%rbx,%rcx,1)
+	vmulsd (%rax),%xmm7,%xmm7
+	mov    0x38(%rsp),%rax
+	vmulsd (%rdi,%rdx,8),%xmm7,%xmm7
+	mov    (%rsp),%rdi
+	vmovsd %xmm7,(%rbx,%rax,1)
+	mov    %rdi,%rax
+	inc    %rdi
+	shl    $0x4,%rax
+	mov    %rdi,(%rsp)
+	lea    0x30(%r14,%rax,1),%r14
+	lea    0x30(%rbx,%rax,1),%rbx
+	cmp    0xe0(%rsp),%ebp
+	jne    82f0 <_compute_with_dsph._omp_fn.0+0x540>
+	addq   $0x18,0x88(%rsp)
+	mov    0x30(%rsp),%rdi
+	mov    0x88(%rsp),%rax
+	add    %rdi,0x90(%rsp)
+	mov    0xd0(%rsp),%rdi
+	add    %rdi,0x98(%rsp)
+	cmp    0xd8(%rsp),%rax
+	jne    80c0 <_compute_with_dsph._omp_fn.0+0x310>
+	mov    %r13,%r15
+	mov    %r12,%r14
+	call   1070 <GOMP_barrier@plt>
+	mov    0x50(%rsp),%rdi
+	call   1030 <free@plt>
+	mov    0x8(%rsp),%rdi
+	call   1030 <free@plt>
+	mov    %r15,%rdi
+	call   1030 <free@plt>
+	add    $0xf8,%rsp
+	mov    %r14,%rdi
+	pop    %rbx
+	pop    %rbp
+	pop    %r12
+	pop    %r13
+	pop    %r14
+	pop    %r15
+	jmp    1030 <free@plt>
+	cs nopw 0x0(%rax,%rax,1)
+	movslq 0x10(%rsp),%rax
+	mov    %rax,0x18(%rsp)
+	jmp    884c <_compute_with_dsph._omp_fn.0+0xa9c>
+	mov    $0x1,%eax
+	jmp    815f <_compute_with_dsph._omp_fn.0+0x3af>
+	inc    %eax
+	xor    %edx,%edx
+	jmp    7f61 <_compute_with_dsph._omp_fn.0+0x1b1>
+	vmovsd 0x4d46(%rip),%xmm3        
+	mov    0x8(%rsp),%rax
+	vmovsd %xmm3,(%rax)
+	jmp    7f35 <_compute_with_dsph._omp_fn.0+0x185>
+	lea    0x1(%rsi),%edx
+	jmp    7ec1 <_compute_with_dsph._omp_fn.0+0x111>
+
+00000000000089d0 <_compute_highl_no_dsph._omp_fn.0>:
+_compute_highl_no_dsph._omp_fn.0():
+	push   %r15
+	push   %r14
+	push   %r13
+	push   %r12
+	push   %rbp
+	push   %rbx
+	sub    $0xa8,%rsp
+	mov    0x10(%rdi),%rax
+	mov    0x18(%rdi),%ebx
+	mov    (%rdi),%r14
+	mov    %rax,0x18(%rsp)
+	mov    0x8(%rdi),%rax
+	mov    %ebx,0x8(%rsp)
+	mov    %rax,0x20(%rsp)
+	mov    0x1c(%rdi),%eax
+	lea    0x1(%rax),%ebp
+	lea    0x2(%rax),%edi
+	mov    %eax,0x28(%rsp)
+	mov    %rdi,%rbx
+	imul   %rbp,%rdi
+	mov    %ebp,0x90(%rsp)
+	shl    $0x3,%rbp
+	shl    $0x3,%rdi
+	shr    %rdi
+	call   10e0 <malloc@plt>
+	mov    %rbp,%rdi
+	mov    %rax,%r15
+	call   10e0 <malloc@plt>
+	mov    %rbp,%rdi
+	mov    %rax,%r12
+	call   10e0 <malloc@plt>
+	mov    %ebx,%edi
+	mov    0x90(%rsp),%ebx
+	mov    %rax,%r13
+	imul   %ebx,%edi
+	shr    %edi
+	shl    $0x3,%rdi
+	call   10e0 <malloc@plt>
+	cmp    $0x6,%ebx
+	vxorps %xmm14,%xmm14,%xmm14
+	mov    %rax,%rbp
+	jbe    9894 <_compute_highl_no_dsph._omp_fn.0+0xec4>
+	vmovsd 0x4c97(%rip),%xmm1        
+	mov    0x90(%rsp),%r8d
+	mov    $0x4,%r10d
+	mov    $0x6,%esi
+	mov    $0x15,%r9d
+	nopw   0x0(%rax,%rax,1)
+	movslq %r9d,%rax
+	lea    0x1(%rsi),%ecx
+	lea    0x0(%rbp,%rax,8),%rdi
+	mov    %r10,%rax
+	xchg   %ax,%ax
+	mov    %esi,%r11d
+	lea    (%rcx,%rax,1),%edx
+	sub    %eax,%r11d
+	imul   %r11d,%edx
+	vcvtsi2sd %edx,%xmm14,%xmm0
+	vdivsd %xmm0,%xmm1,%xmm0
+	vmovsd %xmm0,(%rdi,%rax,8)
+	dec    %rax
+	test   %eax,%eax
+	jns    8aa0 <_compute_highl_no_dsph._omp_fn.0+0xd0>
+	mov    %ecx,%esi
+	add    %ecx,%r9d
+	inc    %r10
+	cmp    %r8d,%ecx
+	jne    8a90 <_compute_highl_no_dsph._omp_fn.0+0xc0>
+	vmovsd 0x4c2a(%rip),%xmm2        
+	vmovsd %xmm1,0x10(%r15)
+	vmovsd %xmm2,(%r15)
+	mov    0x90(%rsp),%r8d
+	mov    $0xfffffffd,%esi
+	mov    $0x3,%edx
+	mov    $0x2,%eax
+	nopl   0x0(%rax,%rax,1)
+	movslq %edx,%rdi
+	vcvtsi2sd %esi,%xmm14,%xmm0
+	lea    (%rdx,%rax,1),%ecx
+	inc    %eax
+	vmulsd -0x8(%r15,%rdi,8),%xmm0,%xmm0
+	movslq %ecx,%rcx
+	add    %eax,%edx
+	sub    $0x2,%esi
+	vmovsd %xmm0,(%r15,%rcx,8)
+	cmp    %r8d,%eax
+	jne    8b00 <_compute_highl_no_dsph._omp_fn.0+0x130>
+	vmovsd %xmm2,(%r12)
+	vmovsd %xmm2,0x10(%rsp)
+	movq   $0x0,0x0(%r13)
+	call   1090 <omp_get_num_threads@plt>
+	mov    %eax,%ebx
+	call   1080 <omp_get_thread_num@plt>
+	vmovsd 0x10(%rsp),%xmm2
+	vxorps %xmm14,%xmm14,%xmm14
+	mov    %eax,%ecx
+	mov    0x8(%rsp),%eax
+	cltd
+	idiv   %ebx
+	cmp    %edx,%ecx
+	jl     988b <_compute_highl_no_dsph._omp_fn.0+0xebb>
+	imul   %eax,%ecx
+	add    %ecx,%edx
+	lea    (%rax,%rdx,1),%ecx
+	cmp    %ecx,%edx
+	jge    984b <_compute_highl_no_dsph._omp_fn.0+0xe7b>
+	vmovsd 0xc8(%rbp),%xmm6
+	mov    0x90(%rsp),%edi
+	lea    (%rdx,%rdx,2),%esi
+	dec    %eax
+	mov    0x20(%rsp),%r11
+	movslq %esi,%rsi
+	vmovsd %xmm2,0x30(%rsp)
+	mov    %edi,%ecx
+	imul   %edi,%ecx
+	lea    (%r11,%rsi,8),%rbx
+	mov    %rbx,0x48(%rsp)
+	vmovsd %xmm6,0x68(%rsp)
+	vmovsd 0xc0(%rbp),%xmm6
+	movslq %ecx,%rsi
+	imul   %edx,%ecx
+	movslq %edx,%rdx
+	lea    0x0(,%rsi,8),%rbx
+	add    %rax,%rdx
+	mov    %rbx,0x60(%rsp)
+	mov    0x18(%rsp),%rbx
+	lea    (%rdx,%rdx,2),%rax
+	movslq %ecx,%rcx
+	lea    (%r11,%rax,8),%rax
+	mov    %rax,0x58(%rsp)
+	mov    0x28(%rsp),%eax
+	lea    0x1c0(%rbx,%rcx,8),%rbx
+	vmovsd %xmm6,0x70(%rsp)
+	vmovsd 0xb8(%rbp),%xmm6
+	sub    $0x9,%eax
+	mov    %eax,0x94(%rsp)
+	shr    %eax
+	lea    0xb(%rax,%rax,1),%rax
+	mov    %rax,0x98(%rsp)
+	mov    %edi,%eax
+	mov    %rax,0x38(%rsp)
+	mov    0x48(%rsp),%rax
+	vmovsd %xmm6,0x78(%rsp)
+	vmovsd 0xb0(%rbp),%xmm6
+	vmovsd %xmm6,0x80(%rsp)
+	vmovsd 0xa8(%rbp),%xmm6
+	vmovsd %xmm6,0x88(%rsp)
+	vxorpd %xmm6,%xmm6,%xmm6
+	vmovsd %xmm6,0x40(%rsp)
+	nop
+	vmovsd (%rax),%xmm0
+	vmulsd 0x45ec(%rip),%xmm0,%xmm7        
+	vmovsd 0x8(%rax),%xmm3
+	vmovsd 0x10(%rax),%xmm6
+	mov    0x45d3(%rip),%rdi        
+	mov    %rbx,%rax
+	vmulsd 0x45d0(%rip),%xmm3,%xmm4        
+	vmovsd 0x4628(%rip),%xmm12        
+	vmulsd 0x45c0(%rip),%xmm6,%xmm8        
+	mov    %rdi,-0x1c0(%rbx)
+	vmulsd %xmm0,%xmm0,%xmm13
+	vmulsd %xmm3,%xmm3,%xmm11
+	vaddsd %xmm6,%xmm6,%xmm1
+	vmulsd %xmm6,%xmm6,%xmm5
+	vmovsd %xmm7,-0x1a8(%rbx)
+	vmulsd 0x45a1(%rip),%xmm0,%xmm7        
+	vsubsd %xmm11,%xmm13,%xmm10
+	vaddsd %xmm11,%xmm13,%xmm2
+	vmulsd 0x45a7(%rip),%xmm10,%xmm9        
+	vmovsd %xmm4,-0x1b8(%rbx)
+	vmovsd %xmm8,-0x1b0(%rbx)
+	vfnmadd132sd %xmm5,%xmm2,%xmm12
+	vmulsd %xmm7,%xmm4,%xmm15
+	vmulsd %xmm7,%xmm8,%xmm7
+	vmovsd 0x4572(%rip),%xmm8        
+	vmovq  %xmm9,%rdi
+	vmovsd %xmm9,-0x180(%rbx)
+	vmovsd 0x4595(%rip),%xmm9        
+	vmovsd %xmm7,0x10(%rsp)
+	vmovsd %xmm7,-0x188(%rbx)
+	vmulsd 0x453f(%rip),%xmm6,%xmm7        
+	vmovsd %xmm15,-0x1a0(%rbx)
+	vfnmadd132sd %xmm5,%xmm2,%xmm8
+	vmulsd 0x453a(%rip),%xmm8,%xmm8        
+	vfnmadd132sd %xmm13,%xmm11,%xmm9
+	vmulsd %xmm4,%xmm7,%xmm4
+	vmovsd %xmm4,0x18(%rsp)
+	vmovsd %xmm4,-0x198(%rbx)
+	vmovsd %xmm9,%xmm9,%xmm4
+	vmulsd 0x454f(%rip),%xmm3,%xmm9        
+	vmovsd %xmm8,-0x190(%rbx)
+	vmulsd %xmm4,%xmm9,%xmm9
+	vmulsd 0x4543(%rip),%xmm6,%xmm4        
+	vmovsd %xmm9,0x8(%rsp)
+	vmovsd %xmm9,-0x178(%rbx)
+	vmulsd %xmm15,%xmm4,%xmm9
+	vmovsd 0x4538(%rip),%xmm4        
+	vmovq  %xmm9,%rdx
+	vmovsd %xmm9,-0x170(%rbx)
+	vmulsd %xmm12,%xmm4,%xmm4
+	vmulsd %xmm4,%xmm3,%xmm9
+	vmulsd %xmm4,%xmm0,%xmm4
+	vmovsd %xmm9,-0x168(%rbx)
+	vmovsd %xmm4,-0x158(%rbx)
+	vmovsd 0x450e(%rip),%xmm12        
 	vmovq  %xmm9,%r9
-	vmovsd %xmm0,-0xb8(%rcx)
-	vmovsd %xmm9,-0xc8(%rcx)
-	vmovsd 0x70(%rsp),%xmm9
-	vmulsd 0x68(%rsp),%xmm4,%xmm12
-	vmulsd 0xd8(%rsp),%xmm4,%xmm4
-	vmulsd 0xd0(%rsp),%xmm5,%xmm5
-	vfnmadd231sd 0x58(%rsp),%xmm7,%xmm14
-	vfnmadd132sd %xmm2,%xmm7,%xmm9
-	vmulsd %xmm8,%xmm4,%xmm4
-	vmovsd 0x118(%rsp),%xmm8
+	vmovq  %rdi,%xmm9
+	vfnmadd132sd %xmm8,%xmm5,%xmm12
+	vmovsd %xmm12,%xmm12,%xmm7
+	vmulsd 0x44fb(%rip),%xmm6,%xmm12        
+	vmulsd %xmm7,%xmm12,%xmm7
+	vmulsd 0x44f7(%rip),%xmm6,%xmm12        
+	vmovsd %xmm7,-0x160(%rbx)
+	vmulsd %xmm10,%xmm12,%xmm10
+	vmulsd 0x44ea(%rip),%xmm0,%xmm12        
+	vmovq  %xmm10,%r8
+	vmovsd %xmm10,-0x150(%rbx)
+	vmovsd 0x4495(%rip),%xmm10        
+	vfnmadd132sd %xmm11,%xmm13,%xmm10
+	vfnmadd231sd 0x45c7(%rip),%xmm11,%xmm13        
+	vmulsd %xmm10,%xmm12,%xmm12
+	vmulsd 0x450a(%rip),%xmm15,%xmm10        
+	vmovsd %xmm12,-0x148(%rbx)
+	vmulsd %xmm9,%xmm10,%xmm10
+	vmulsd 0x4465(%rip),%xmm6,%xmm9        
+	vmovsd %xmm10,-0x140(%rbx)
+	vmovq  %xmm9,%r11
+	vmulsd 0x8(%rsp),%xmm9,%xmm9
+	vmovq  %xmm9,%rsi
+	vmovsd %xmm9,-0x138(%rbx)
+	vmovsd 0x44d5(%rip),%xmm9        
+	vfnmadd132sd %xmm5,%xmm2,%xmm9
+	vmulsd 0x44d0(%rip),%xmm9,%xmm9        
+	vmulsd %xmm9,%xmm15,%xmm15
+	vmovq  %xmm9,%r10
+	vmovq  %rdi,%xmm9
+	vmovsd %xmm15,-0x130(%rbx)
+	vmovq  %r10,%xmm15
+	vmulsd %xmm15,%xmm9,%xmm15
+	vmovq  %r9,%xmm9
+	vmovsd %xmm15,-0x110(%rbx)
+	vmulsd 0x44a2(%rip),%xmm6,%xmm15        
+	vmulsd %xmm7,%xmm15,%xmm15
+	vfmsub231sd %xmm9,%xmm3,%xmm15
+	vfmadd132sd %xmm0,%xmm15,%xmm4
+	vmovsd 0x449c(%rip),%xmm15        
+	vmulsd 0x448c(%rip),%xmm4,%xmm4        
+	vfnmadd132sd %xmm8,%xmm5,%xmm15
+	vmulsd 0x448f(%rip),%xmm15,%xmm15        
+	vmovsd %xmm4,-0x120(%rbx)
+	vmulsd 0x18(%rsp),%xmm15,%xmm9
+	vmovq  %xmm9,%rdi
+	vmovsd %xmm9,-0x128(%rbx)
+	vmulsd 0x10(%rsp),%xmm15,%xmm9
+	vmulsd %xmm12,%xmm0,%xmm15
+	vfmsub231sd 0x8(%rsp),%xmm3,%xmm15
+	vmulsd 0x4462(%rip),%xmm15,%xmm15        
+	vmovq  %xmm9,%r9
+	vmovsd %xmm9,-0x118(%rbx)
+	vmovq  %r11,%xmm9
 	vmulsd %xmm9,%xmm12,%xmm9
-	vmulsd 0x60(%rsp),%xmm15,%xmm12
-	vmovsd %xmm4,-0xb0(%rcx)
-	vmovq  %xmm4,%r10
-	vmovsd %xmm9,-0xc0(%rcx)
-	vmovsd %xmm8,%xmm8,%xmm4
-	vfnmadd132sd %xmm3,%xmm11,%xmm4
-	vfnmadd231sd 0xa8(%rsp),%xmm3,%xmm11
-	vmulsd %xmm13,%xmm12,%xmm12
-	vmulsd %xmm4,%xmm5,%xmm5
-	vmovsd %xmm5,-0xa8(%rcx)
-	vmovsd -0x8(%rsi),%xmm4
-	mov    -0x10(%rsi),%rdx
-	mov    -0x18(%rsi),%r13
-	vmovsd %xmm12,-0xa0(%rcx)
+	vmovq  %xmm9,%r11
+	vmovsd %xmm9,-0x108(%rbx)
+	vmulsd 0x44b6(%rip),%xmm15,%xmm9        
+	vmovsd %xmm15,-0x100(%rbx)
+	vfmadd132sd %xmm11,%xmm9,%xmm13
+	vmulsd 0x44a9(%rip),%xmm3,%xmm11        
+	vmulsd %xmm13,%xmm11,%xmm13
+	vmovsd %xmm13,0x20(%rsp)
+	vmovsd %xmm13,-0xf8(%rbx)
+	vmulsd 0x4496(%rip),%xmm6,%xmm13        
+	vmulsd %xmm13,%xmm10,%xmm9
+	vmulsd %xmm13,%xmm15,%xmm13
+	vmovsd %xmm13,-0xb0(%rbx)
+	vmovsd 0x4484(%rip),%xmm13        
+	vmovsd %xmm9,-0xf0(%rbx)
+	vfmadd132sd %xmm8,%xmm5,%xmm13
+	vmulsd 0x4477(%rip),%xmm13,%xmm13        
+	vmulsd 0x8(%rsp),%xmm13,%xmm9
+	vmulsd %xmm13,%xmm12,%xmm13
+	vmovq  %xmm13,%rcx
+	vmovsd %xmm13,-0xb8(%rbx)
+	vmulsd 0x445f(%rip),%xmm8,%xmm13        
+	vmovq  %xmm9,%r10
+	vmovsd %xmm9,-0xe8(%rbx)
+	vmovq  %rdx,%xmm9
+	vmulsd %xmm13,%xmm9,%xmm9
+	vmovq  %xmm9,%rdx
+	vmovsd %xmm9,-0xe0(%rbx)
+	vmovq  %r8,%xmm9
+	vmulsd %xmm13,%xmm9,%xmm9
+	vmulsd 0x4431(%rip),%xmm6,%xmm13        
+	vmovsd %xmm9,0x28(%rsp)
+	vmovsd %xmm9,-0xc0(%rbx)
+	vmovq  %xmm13,%r8
+	vmovq  %rdi,%xmm13
+	vmovq  %r8,%xmm9
+	vmovq  %r8,%xmm11
+	vmulsd %xmm9,%xmm13,%xmm13
+	vmovq  %r9,%xmm9
+	vmulsd %xmm11,%xmm9,%xmm9
+	vmulsd 0x4408(%rip),%xmm8,%xmm11        
+	vfmadd231sd %xmm4,%xmm3,%xmm13
+	vmulsd 0x43f3(%rip),%xmm13,%xmm13        
+	vfmadd132sd %xmm0,%xmm9,%xmm4
+	vmulsd 0x43e6(%rip),%xmm4,%xmm4        
+	vmovq  %xmm11,%r9
+	vmulsd %xmm5,%xmm6,%xmm11
+	vmovsd %xmm13,-0xd8(%rbx)
+	vmulsd %xmm5,%xmm11,%xmm11
+	vmovsd %xmm4,-0xc8(%rbx)
+	vmovq  %xmm11,%r8
+	vmovq  %r9,%xmm11
+	vmovq  %r8,%xmm9
+	vfmsub132sd %xmm11,%xmm9,%xmm7
+	vmulsd %xmm15,%xmm0,%xmm11
+	vmulsd 0x43b8(%rip),%xmm7,%xmm7        
+	vmovsd %xmm11,%xmm11,%xmm9
+	vfmsub231sd %xmm10,%xmm3,%xmm9
+	vmulsd 0x43ae(%rip),%xmm9,%xmm11        
+	vmovsd %xmm7,-0xd0(%rbx)
+	vmulsd %xmm7,%xmm6,%xmm7
+	vmovq  %xmm11,%rdi
+	vmovsd %xmm11,-0xa8(%rbx)
+	vmovsd 0x8(%rsp),%xmm11
+	vmulsd 0x447f(%rip),%xmm11,%xmm9        
+	vmovq  %rdi,%xmm11
+	vmulsd %xmm12,%xmm9,%xmm9
+	vmovsd %xmm9,-0xa0(%rbx)
+	vmulsd 0x446d(%rip),%xmm6,%xmm9        
+	vmulsd 0x20(%rsp),%xmm9,%xmm12
+	vmulsd %xmm9,%xmm11,%xmm9
+	vmovq  %rdx,%xmm11
+	vmovsd %xmm9,-0x48(%rbx)
+	vmovsd %xmm12,-0x98(%rbx)
+	vmovsd 0x4450(%rip),%xmm12        
+	vmovsd 0x4450(%rip),%xmm9        
+	vfmadd132sd %xmm8,%xmm5,%xmm12
+	vmulsd %xmm12,%xmm9,%xmm9
+	vmulsd %xmm9,%xmm10,%xmm10
+	vmulsd %xmm9,%xmm15,%xmm9
+	vmovsd %xmm10,-0x90(%rbx)
+	vmovsd 0x41e4(%rip),%xmm10        
+	vmovsd %xmm9,-0x50(%rbx)
+	vmovsd 0x4427(%rip),%xmm9        
+	vfmadd132sd %xmm8,%xmm5,%xmm10
+	vmulsd %xmm10,%xmm9,%xmm9
+	vmovq  %rsi,%xmm10
+	vmulsd %xmm9,%xmm10,%xmm10
+	vmovsd %xmm10,-0x88(%rbx)
+	vmovq  %r11,%xmm10
+	vmulsd %xmm9,%xmm10,%xmm9
+	vmulsd 0x4401(%rip),%xmm6,%xmm10        
+	vmovsd %xmm9,-0x58(%rbx)
+	vmulsd %xmm13,%xmm0,%xmm9
+	vfmadd231sd %xmm10,%xmm11,%xmm9
+	vmulsd 0x43f2(%rip),%xmm9,%xmm9        
+	vmovsd 0x20(%rsp),%xmm11
+	vmovsd %xmm9,-0x80(%rbx)
+	vmulsd 0x43e7(%rip),%xmm8,%xmm9        
+	vmulsd %xmm8,%xmm9,%xmm8
+	vfmsub231sd %xmm5,%xmm5,%xmm8
+	vmulsd 0x43dd(%rip),%xmm8,%xmm8        
+	vmulsd 0x18(%rsp),%xmm8,%xmm5
+	vmulsd 0x10(%rsp),%xmm8,%xmm8
+	vmovsd %xmm5,-0x78(%rbx)
+	vmulsd 0x43cc(%rip),%xmm3,%xmm5        
+	vmovsd %xmm8,-0x68(%rbx)
+	vfmsub231sd %xmm5,%xmm13,%xmm7
+	vmulsd 0x43ba(%rip),%xmm0,%xmm5        
+	vfmadd231sd %xmm5,%xmm4,%xmm7
+	vmulsd 0x43bd(%rip),%xmm6,%xmm4        
+	vmulsd 0x43ad(%rip),%xmm7,%xmm7        
+	vmovsd 0x30(%rsp),%xmm5
+	vmulsd 0x28(%rsp),%xmm4,%xmm13
+	vmovsd %xmm7,-0x70(%rbx)
+	vmovq  %r10,%xmm7
+	vfmsub231sd %xmm7,%xmm3,%xmm13
+	vmovq  %rcx,%xmm7
+	vfmadd231sd %xmm7,%xmm0,%xmm13
+	vmovq  %rdi,%xmm7
+	vmulsd 0x438b(%rip),%xmm13,%xmm13        
+	vmulsd %xmm7,%xmm0,%xmm4
+	vmovsd 0x40(%rsp),%xmm7
+	vfmsub132sd %xmm3,%xmm4,%xmm11
+	vmulsd 0x437c(%rip),%xmm11,%xmm11        
+	vmulsd %xmm7,%xmm3,%xmm4
+	vmulsd %xmm7,%xmm0,%xmm7
+	vmovsd %xmm13,-0x60(%rbx)
+	vfmadd231sd %xmm5,%xmm3,%xmm7
+	vfmsub231sd %xmm5,%xmm0,%xmm4
+	vmovsd %xmm11,-0x40(%rbx)
+	vmulsd %xmm7,%xmm3,%xmm8
+	vmovsd %xmm7,0x8(%r13)
+	vmovsd %xmm4,0x8(%r12)
+	vmulsd %xmm7,%xmm0,%xmm7
+	vfmsub231sd %xmm4,%xmm0,%xmm8
+	vfmadd132sd %xmm3,%xmm7,%xmm4
+	vmovsd %xmm8,0x10(%r12)
+	cmpl   $0x7,0x90(%rsp)
+	vmulsd %xmm4,%xmm3,%xmm5
+	vmovsd %xmm4,0x10(%r13)
+	vmulsd %xmm4,%xmm0,%xmm4
+	vfmsub231sd %xmm8,%xmm0,%xmm5
+	vfmadd132sd %xmm3,%xmm4,%xmm8
+	vmovsd %xmm5,0x18(%r12)
+	vmulsd %xmm8,%xmm3,%xmm7
+	vmovsd %xmm8,0x18(%r13)
+	vmulsd %xmm8,%xmm0,%xmm8
+	vfmsub231sd %xmm5,%xmm0,%xmm7
+	vfmadd132sd %xmm3,%xmm8,%xmm5
+	vmovsd %xmm7,0x20(%r12)
+	vmulsd %xmm5,%xmm3,%xmm4
+	vmovsd %xmm5,0x20(%r13)
+	vmulsd %xmm5,%xmm0,%xmm5
+	vfmsub231sd %xmm7,%xmm0,%xmm4
+	vfmadd132sd %xmm3,%xmm5,%xmm7
+	vmovsd %xmm4,0x28(%r12)
+	vmulsd %xmm7,%xmm3,%xmm5
+	vmovsd %xmm7,0x28(%r13)
+	vmulsd %xmm7,%xmm0,%xmm7
+	vfmsub231sd %xmm4,%xmm0,%xmm5
+	vfmadd132sd %xmm3,%xmm7,%xmm4
+	vmovsd %xmm5,0x30(%r12)
+	vmovsd %xmm4,0x30(%r13)
+	jbe    9384 <_compute_highl_no_dsph._omp_fn.0+0x9b4>
+	cmpl   $0xfffffff5,0x94(%rsp)
+	ja     9881 <_compute_highl_no_dsph._omp_fn.0+0xeb1>
+	mov    $0x9,%ecx
+	vmulsd %xmm4,%xmm3,%xmm7
+	vmulsd %xmm4,%xmm0,%xmm4
+	movslq %ecx,%rdx
+	vfmadd231sd %xmm5,%xmm3,%xmm4
+	vfmsub231sd %xmm5,%xmm0,%xmm7
+	vmulsd %xmm4,%xmm3,%xmm5
+	vmovsd %xmm4,-0x10(%r13,%rcx,8)
+	vmulsd %xmm4,%xmm0,%xmm4
+	vfmsub231sd %xmm7,%xmm0,%xmm5
+	vfmadd231sd %xmm7,%xmm3,%xmm4
+	vunpcklpd %xmm5,%xmm7,%xmm8
+	vmovupd %xmm8,-0x10(%r12,%rcx,8)
+	vmovsd %xmm4,-0x8(%r13,%rcx,8)
+	add    $0x2,%rcx
+	cmp    %rcx,0x98(%rsp)
+	jne    92f3 <_compute_highl_no_dsph._omp_fn.0+0x923>
+	mov    0x90(%rsp),%ecx
+	nopl   0x0(%rax,%rax,1)
+	vmovsd -0x8(%r13,%rdx,8),%xmm5
+	vmovsd -0x8(%r12,%rdx,8),%xmm4
+	vmulsd %xmm5,%xmm3,%xmm7
+	vmulsd %xmm5,%xmm0,%xmm5
+	vfmsub231sd %xmm4,%xmm0,%xmm7
+	vfmadd132sd %xmm3,%xmm5,%xmm4
+	vmovsd %xmm7,(%r12,%rdx,8)
+	vmovsd %xmm4,0x0(%r13,%rdx,8)
+	inc    %rdx
+	cmp    %edx,%ecx
+	ja     9350 <_compute_highl_no_dsph._omp_fn.0+0x980>
+	vmovsd 0x3f9c(%rip),%xmm4        
+	vmovsd 0xd8(%r15),%xmm3
+	vxorpd 0x43c3(%rip),%xmm6,%xmm6        
+	cmpl   $0x7,0x90(%rsp)
+	vfmsub132sd %xmm1,%xmm1,%xmm4
+	vmulsd %xmm3,%xmm6,%xmm0
+	vmulsd %xmm3,%xmm2,%xmm3
+	vmovsd %xmm0,0xd0(%r15)
+	vfmadd231sd %xmm4,%xmm0,%xmm3
+	vmulsd 0x68(%rsp),%xmm3,%xmm3
+	vsubsd %xmm1,%xmm4,%xmm4
+	vmulsd %xmm0,%xmm2,%xmm0
+	vfmadd231sd %xmm4,%xmm3,%xmm0
+	vmulsd 0x70(%rsp),%xmm0,%xmm0
+	vsubsd %xmm1,%xmm4,%xmm4
+	vmovsd %xmm3,0xc8(%r15)
+	vmulsd %xmm3,%xmm2,%xmm3
+	vfmadd231sd %xmm4,%xmm0,%xmm3
+	vmulsd 0x78(%rsp),%xmm3,%xmm3
+	vsubsd %xmm1,%xmm4,%xmm4
+	vmovsd %xmm0,0xc0(%r15)
+	vmulsd %xmm0,%xmm2,%xmm0
+	vfmadd231sd %xmm4,%xmm3,%xmm0
+	vmulsd 0x80(%rsp),%xmm0,%xmm0
+	vsubsd %xmm1,%xmm4,%xmm4
+	vmovsd %xmm3,0xb8(%r15)
+	vmulsd %xmm3,%xmm2,%xmm3
+	vmovsd %xmm0,0xb0(%r15)
+	vfmadd132sd %xmm4,%xmm3,%xmm0
+	vmulsd 0x88(%rsp),%xmm0,%xmm0
+	vmovsd %xmm0,0xa8(%r15)
+	jbe    980a <_compute_highl_no_dsph._omp_fn.0+0xe3a>
+	vmovsd 0x10(%r12),%xmm5
+	mov    $0x1c,%r11d
+	mov    %rbx,0x50(%rsp)
+	mov    $0x38,%edx
+	vmovsd 0x28(%r13),%xmm13
+	mov    %rbp,%rbx
+	mov    $0x7,%edi
+	mov    %r11d,%ebp
+	vmovsd 0x28(%r12),%xmm12
+	vmovsd 0x20(%r13),%xmm11
+	vmovsd 0x20(%r12),%xmm10
+	vmovsd 0x18(%r13),%xmm9
+	vmovsd 0x18(%r12),%xmm8
+	vmovsd 0x10(%r13),%xmm7
+	vmovsd %xmm5,0x20(%rsp)
+	vmovsd 0x8(%r13),%xmm5
+	vmovsd %xmm5,0x28(%rsp)
+	vmovsd 0x8(%r12),%xmm5
+	vmovsd %xmm5,0x30(%rsp)
+	nopl   0x0(%rax)
+	lea    0x0(%rbp,%rdi,1),%ecx
+	mov    %rax,%rsi
+	lea    -0x2(%rdi),%r8d
+	mov    %edi,0x8(%rsp)
+	movslq %ecx,%rcx
+	sub    %rdx,%rsi
+	mov    %r8d,%r11d
+	shl    $0x3,%rcx
+	vmovsd (%r15,%rcx,1),%xmm0
+	vmulsd (%r14,%rcx,1),%xmm0,%xmm3
+	vmulsd 0x0(%r13,%rdx,1),%xmm3,%xmm4
+	vmulsd (%r12,%rdx,1),%xmm3,%xmm3
+	vmulsd %xmm0,%xmm6,%xmm0
+	vmovsd %xmm0,-0x8(%r15,%rcx,1)
+	vmovsd %xmm4,(%rsi)
+	vmovsd %xmm3,(%rax,%rdx,1)
+	vmulsd -0x8(%r14,%rcx,1),%xmm0,%xmm0
+	mov    $0x8,%ecx
+	sub    %rdx,%rcx
+	vmulsd -0x8(%r13,%rdx,1),%xmm0,%xmm3
+	vmulsd -0x8(%r12,%rdx,1),%xmm0,%xmm0
+	vmovsd %xmm3,(%rax,%rcx,1)
+	vmovsd %xmm0,-0x8(%rax,%rdx,1)
+	vcvtsi2sd %edi,%xmm14,%xmm0
+	vmulsd %xmm1,%xmm0,%xmm0
+	cmp    $0x5,%r8d
+	je     96a7 <_compute_highl_no_dsph._omp_fn.0+0xcd7>
+	movslq %ebp,%rsi
+	lea    -0x2(%rdi,%rsi,1),%rcx
+	lea    (%r15,%rcx,8),%rcx
+	cmp    $0x9,%rdi
+	jbe    9841 <_compute_highl_no_dsph._omp_fn.0+0xe71>
+	mov    %edi,%r9d
+	lea    -0x4(%rdi),%r8d
+	mov    $0x18,%r10d
+	vmovsd 0x10(%rcx),%xmm4
+	sub    $0xa,%r9d
+	sub    %rdx,%r10
+	vmovsd 0x8(%rcx),%xmm3
+	mov    %rdx,0x40(%rsp)
+	and    $0xfffffffe,%r9d
+	add    %rax,%r10
+	lea    -0x10(%rdx),%rcx
+	sub    %r9d,%r8d
+	lea    0x0(,%rsi,8),%r9
+	mov    %r8d,0x10(%rsp)
+	lea    (%rbx,%r9,1),%r8
+	mov    %r8,0x18(%rsp)
+	lea    (%r15,%r9,1),%r8
+	add    %r14,%r9
+	mov    0x18(%rsp),%rdx
+	vsubsd %xmm1,%xmm0,%xmm0
+	vmulsd %xmm4,%xmm2,%xmm4
+	sub    $0x2,%r11d
+	add    $0x10,%r10
+	vfmadd231sd %xmm3,%xmm0,%xmm4
+	vsubsd %xmm1,%xmm0,%xmm0
+	vmulsd %xmm3,%xmm2,%xmm3
+	vmulsd (%rdx,%rcx,1),%xmm4,%xmm4
+	vmulsd (%r9,%rcx,1),%xmm4,%xmm5
+	vmulsd 0x0(%r13,%rcx,1),%xmm5,%xmm15
+	vmulsd (%r12,%rcx,1),%xmm5,%xmm5
+	vfmadd231sd %xmm0,%xmm4,%xmm3
+	vmulsd -0x8(%rdx,%rcx,1),%xmm3,%xmm3
+	vmovsd %xmm4,(%r8,%rcx,1)
+	vmovsd %xmm15,-0x18(%r10)
+	vmovsd %xmm5,(%rax,%rcx,1)
+	vmulsd -0x8(%r9,%rcx,1),%xmm3,%xmm5
+	vmulsd -0x8(%r13,%rcx,1),%xmm5,%xmm15
+	vmulsd -0x8(%r12,%rcx,1),%xmm5,%xmm5
+	vmovsd %xmm3,-0x8(%r8,%rcx,1)
+	vmovsd %xmm15,-0x10(%r10)
+	vmovsd %xmm5,-0x8(%rax,%rcx,1)
+	sub    $0x10,%rcx
+	cmp    0x10(%rsp),%r11d
+	jne    95a7 <_compute_highl_no_dsph._omp_fn.0+0xbd7>
+	mov    0x40(%rsp),%rdx
+	movslq 0x10(%rsp),%rcx
+	shl    $0x3,%rsi
+	lea    (%rbx,%rsi,1),%r10
+	mov    %rcx,%r11
+	neg    %r11d
+	movslq %r11d,%r8
+	lea    (%rax,%r8,8),%r9
+	lea    (%r15,%rsi,1),%r8
+	add    %r14,%rsi
+	nopw   0x0(%rax,%rax,1)
+	vmulsd 0x10(%r8,%rcx,8),%xmm2,%xmm3
+	vsubsd %xmm1,%xmm0,%xmm0
+	add    $0x8,%r9
+	vfmadd231sd 0x8(%r8,%rcx,8),%xmm0,%xmm3
+	vmulsd (%r10,%rcx,8),%xmm3,%xmm3
+	vmovsd %xmm3,(%r8,%rcx,8)
+	vmulsd (%rsi,%rcx,8),%xmm3,%xmm3
+	vmulsd 0x0(%r13,%rcx,8),%xmm3,%xmm4
+	vmulsd (%r12,%rcx,8),%xmm3,%xmm3
+	vmovsd %xmm4,-0x8(%r9)
+	vmovsd %xmm3,(%rax,%rcx,8)
+	dec    %rcx
+	cmp    $0x5,%ecx
+	jne    9660 <_compute_highl_no_dsph._omp_fn.0+0xc90>
+	lea    0x5(%rbp),%ecx
+	vsubsd %xmm1,%xmm0,%xmm0
+	inc    %rdi
+	movslq %ecx,%rcx
+	shl    $0x3,%rcx
+	vmulsd 0x10(%r15,%rcx,1),%xmm2,%xmm4
+	lea    0x8(%r15,%rcx,1),%r8
+	vfmadd231sd (%r8),%xmm0,%xmm4
+	vsubsd %xmm1,%xmm0,%xmm0
+	vmulsd (%rbx,%rcx,1),%xmm4,%xmm4
+	vmulsd (%r14,%rcx,1),%xmm4,%xmm3
+	vmovsd %xmm4,(%r15,%rcx,1)
+	vmulsd %xmm13,%xmm3,%xmm5
+	vmulsd %xmm12,%xmm3,%xmm3
+	vmovsd %xmm3,0x28(%rax)
+	vmulsd (%r8),%xmm2,%xmm3
+	vmovsd %xmm5,-0x28(%rax)
+	vfmadd231sd %xmm0,%xmm4,%xmm3
+	vmulsd -0x8(%rbx,%rcx,1),%xmm3,%xmm3
+	vsubsd %xmm1,%xmm0,%xmm0
+	vmulsd %xmm4,%xmm2,%xmm4
+	vmulsd -0x8(%r14,%rcx,1),%xmm3,%xmm5
+	vfmadd231sd %xmm3,%xmm0,%xmm4
+	vmulsd -0x10(%rbx,%rcx,1),%xmm4,%xmm4
+	vsubsd %xmm1,%xmm0,%xmm0
+	vmovsd %xmm3,-0x8(%r15,%rcx,1)
+	vmulsd %xmm3,%xmm2,%xmm3
+	vmulsd %xmm11,%xmm5,%xmm15
+	vmulsd %xmm10,%xmm5,%xmm5
+	vmovsd %xmm15,-0x20(%rax)
+	vmovsd %xmm5,0x20(%rax)
+	vmulsd -0x10(%r14,%rcx,1),%xmm4,%xmm5
+	vfmadd231sd %xmm4,%xmm0,%xmm3
+	vmulsd -0x18(%rbx,%rcx,1),%xmm3,%xmm3
+	vmovsd %xmm4,-0x10(%r15,%rcx,1)
+	vsubsd %xmm1,%xmm0,%xmm0
+	vmulsd %xmm4,%xmm2,%xmm4
+	vmulsd %xmm9,%xmm5,%xmm15
+	vmulsd %xmm8,%xmm5,%xmm5
+	vmovsd %xmm15,-0x18(%rax)
+	vfmadd132sd %xmm3,%xmm4,%xmm0
+	vmovsd %xmm5,0x18(%rax)
+	vmulsd -0x18(%r14,%rcx,1),%xmm3,%xmm5
+	vmovsd %xmm3,-0x18(%r15,%rcx,1)
+	vmulsd -0x20(%rbx,%rcx,1),%xmm0,%xmm0
+	vmulsd %xmm3,%xmm2,%xmm3
+	vmulsd %xmm7,%xmm5,%xmm15
+	vmulsd 0x20(%rsp),%xmm5,%xmm5
+	vmovsd %xmm0,-0x20(%r15,%rcx,1)
+	vmovsd %xmm15,-0x10(%rax)
+	vmovsd %xmm5,0x10(%rax)
+	vmulsd -0x20(%r14,%rcx,1),%xmm0,%xmm4
+	vfmadd132sd %xmm1,%xmm3,%xmm0
+	vmulsd -0x28(%rbx,%rcx,1),%xmm0,%xmm0
+	vmulsd 0x28(%rsp),%xmm4,%xmm5
+	vmulsd 0x30(%rsp),%xmm4,%xmm4
+	vmovsd %xmm5,-0x8(%rax)
+	vmovsd %xmm4,0x8(%rax)
+	vmovsd %xmm0,-0x28(%r15,%rcx,1)
+	vmulsd -0x28(%r14,%rcx,1),%xmm0,%xmm0
+	mov    0x8(%rsp),%esi
+	lea    0x1(%rbp,%rsi,1),%ebp
+	vmovsd %xmm0,(%rax)
+	lea    0x10(%rax,%rdx,2),%rax
+	add    $0x8,%rdx
+	cmp    %rdi,0x38(%rsp)
+	jne    94c0 <_compute_highl_no_dsph._omp_fn.0+0xaf0>
+	mov    %rbx,%rbp
+	mov    0x50(%rsp),%rbx
+	add    0x60(%rsp),%rbx
+	mov    0x48(%rsp),%rax
+	cmp    %rax,0x58(%rsp)
+	je     984b <_compute_highl_no_dsph._omp_fn.0+0xe7b>
+	vmovsd (%r12),%xmm6
+	add    $0x18,%rax
+	mov    %rax,0x48(%rsp)
+	vmovsd %xmm6,0x30(%rsp)
+	vmovsd 0x0(%r13),%xmm6
+	vmovsd %xmm6,0x40(%rsp)
+	jmp    8c50 <_compute_highl_no_dsph._omp_fn.0+0x280>
+	mov    %r8d,0x10(%rsp)
+	jmp    9639 <_compute_highl_no_dsph._omp_fn.0+0xc69>
+	call   1070 <GOMP_barrier@plt>
+	mov    %rbp,%rdi
+	call   1030 <free@plt>
+	mov    %r15,%rdi
+	call   1030 <free@plt>
+	mov    %r12,%rdi
+	call   1030 <free@plt>
+	add    $0xa8,%rsp
+	mov    %r13,%rdi
+	pop    %rbx
+	pop    %rbp
+	pop    %r12
+	pop    %r13
+	pop    %r14
+	pop    %r15
+	jmp    1030 <free@plt>
+	mov    $0x7,%edx
+	jmp    9341 <_compute_highl_no_dsph._omp_fn.0+0x971>
+	inc    %eax
+	xor    %edx,%edx
+	jmp    8b62 <_compute_highl_no_dsph._omp_fn.0+0x192>
+	vmovsd 0x3e64(%rip),%xmm2        
+	cmpl   $0x1,0x90(%rsp)
+	vmovsd %xmm2,(%r15)
+	jbe    8b26 <_compute_highl_no_dsph._omp_fn.0+0x156>
+	cmpl   $0x2,0x90(%rsp)
+	mov    0x3e4a(%rip),%rax        
+	mov    %rax,0x10(%r15)
+	je     8b26 <_compute_highl_no_dsph._omp_fn.0+0x156>
+	jmp    8ae1 <_compute_highl_no_dsph._omp_fn.0+0x111>
+	nopl   (%rax)
+
+00000000000098d0 <_compute_highl_with_dsph._omp_fn.0>:
+_compute_highl_with_dsph._omp_fn.0():
+	push   %rbp
+	mov    %rsp,%rbp
+	push   %r15
+	push   %r14
+	push   %r13
+	push   %r12
+	push   %rbx
+	sub    $0x158,%rsp
+	mov    0x18(%rdi),%rax
+	mov    0x24(%rdi),%r12d
+	mov    0x20(%rdi),%r14d
+	mov    %rax,0x140(%rsp)
+	mov    0x10(%rdi),%rax
+	lea    0x1(%r12),%r15d
+	mov    %r15d,0x84(%rsp)
+	mov    %rax,0x130(%rsp)
+	mov    0x8(%rdi),%rax
+	mov    %rax,0x128(%rsp)
+	mov    (%rdi),%rax
+	lea    0x2(%r12),%edi
+	mov    %rdi,%rbx
+	imul   %r15,%rdi
+	shl    $0x3,%r15
+	shl    $0x3,%rdi
+	mov    %rax,0x110(%rsp)
+	shr    %rdi
+	call   10e0 <malloc@plt>
+	mov    %r15,%rdi
+	mov    %rax,0x138(%rsp)
+	call   10e0 <malloc@plt>
+	mov    %r15,%rdi
+	mov    %rax,%r13
+	call   10e0 <malloc@plt>
+	mov    %ebx,%edi
+	mov    0x84(%rsp),%ebx
+	mov    %rax,%r15
+	imul   %ebx,%edi
+	shr    %edi
+	shl    $0x3,%rdi
+	call   10e0 <malloc@plt>
+	cmp    $0x6,%ebx
+	vxorps %xmm15,%xmm15,%xmm15
+	mov    %rax,0xe0(%rsp)
+	jbe    bc71 <_compute_highl_with_dsph._omp_fn.0+0x23a1>
+	vmovsd 0x3d71(%rip),%xmm1        
+	mov    %rax,%r8
+	mov    $0x4,%r10d
+	mov    $0x6,%esi
+	mov    0x84(%rsp),%edi
+	mov    $0x15,%r9d
+	data16 cs nopw 0x0(%rax,%rax,1)
+	nopl   (%rax)
+	movslq %r9d,%rax
+	lea    0x1(%rsi),%edx
+	lea    (%r8,%rax,8),%rcx
+	mov    %r10,%rax
+	nopl   (%rax)
+	mov    %esi,%ebx
+	lea    (%rdx,%rax,1),%r11d
+	sub    %eax,%ebx
+	imul   %ebx,%r11d
+	vcvtsi2sd %r11d,%xmm15,%xmm0
+	vdivsd %xmm0,%xmm1,%xmm0
+	vmovsd %xmm0,(%rcx,%rax,8)
+	dec    %rax
+	test   %eax,%eax
+	jns    99d0 <_compute_highl_with_dsph._omp_fn.0+0x100>
+	mov    %edx,%esi
+	add    %edx,%r9d
+	inc    %r10
+	cmp    %edi,%edx
+	jne    99c0 <_compute_highl_with_dsph._omp_fn.0+0xf0>
+	vmovsd 0x3cfb(%rip),%xmm2        
+	mov    0x138(%rsp),%rax
+	vmovsd %xmm1,0x10(%rax)
+	vmovsd %xmm2,(%rax)
+	mov    0x84(%rsp),%r9d
+	mov    $0xfffffffd,%esi
+	mov    $0x3,%edx
+	mov    $0x2,%eax
+	mov    0x138(%rsp),%rdi
+	data16 cs nopw 0x0(%rax,%rax,1)
+	movslq %edx,%r8
+	vcvtsi2sd %esi,%xmm15,%xmm0
+	lea    (%rdx,%rax,1),%ecx
+	inc    %eax
+	vmulsd -0x8(%rdi,%r8,8),%xmm0,%xmm0
+	movslq %ecx,%rcx
+	add    %eax,%edx
+	sub    $0x2,%esi
+	vmovsd %xmm0,(%rdi,%rcx,8)
+	cmp    %r9d,%eax
+	jne    9a40 <_compute_highl_with_dsph._omp_fn.0+0x170>
+	vmovsd %xmm2,0x0(%r13)
+	movq   $0x0,(%r15)
+	vmovsd %xmm2,0x148(%rsp)
+	call   1090 <omp_get_num_threads@plt>
+	mov    %eax,%ebx
+	call   1080 <omp_get_thread_num@plt>
+	vmovsd 0x148(%rsp),%xmm2
+	vxorps %xmm15,%xmm15,%xmm15
+	mov    %eax,%ecx
+	mov    %r14d,%eax
+	cltd
+	idiv   %ebx
+	cmp    %edx,%ecx
+	jl     bc68 <_compute_highl_with_dsph._omp_fn.0+0x2398>
+	imul   %eax,%ecx
+	add    %ecx,%edx
+	lea    (%rax,%rdx,1),%ecx
+	cmp    %ecx,%edx
+	jge    bc1e <_compute_highl_with_dsph._omp_fn.0+0x234e>
+	mov    0x84(%rsp),%ecx
+	mov    0x128(%rsp),%r10
+	dec    %eax
+	vmovsd %xmm2,0x120(%rsp)
+	mov    0x130(%rsp),%rbx
+	mov    %ecx,%esi
+	imul   %ecx,%esi
+	lea    (%rsi,%rsi,1),%r9d
+	movslq %esi,%r8
+	movslq %r9d,%rcx
+	lea    0x0(,%r8,8),%r14
+	shl    $0x3,%rcx
+	mov    %r14,0xb8(%rsp)
+	mov    %rcx,0xa8(%rsp)
+	mov    0xe0(%rsp),%rcx
+	vmovsd 0xc8(%rcx),%xmm3
+	vmovsd %xmm3,0x28(%rsp)
+	vmovsd 0xc0(%rcx),%xmm3
+	vmovsd %xmm3,0x20(%rsp)
+	vmovsd 0xb8(%rcx),%xmm3
+	vmovsd %xmm3,0x18(%rsp)
+	vmovsd 0xb0(%rcx),%xmm3
+	vmovsd %xmm3,0x10(%rsp)
+	vmovsd 0xa8(%rcx),%xmm3
+	lea    (%rdx,%rdx,2),%ecx
+	movslq %ecx,%rcx
+	lea    (%r10,%rcx,8),%rcx
+	mov    %rcx,0x68(%rsp)
+	mov    %esi,%ecx
+	add    %r9d,%esi
+	imul   %edx,%ecx
+	movslq %esi,%rsi
+	movslq %edx,%rdx
+	shl    $0x3,%rsi
+	add    %rax,%rdx
+	mov    %rsi,0x30(%rsp)
+	mov    %r8,%rsi
+	lea    (%rdx,%rdx,2),%rax
+	movslq %ecx,%rdi
+	lea    (%rcx,%rcx,2),%ecx
+	shl    $0x4,%rsi
+	lea    (%r10,%rax,8),%rax
+	lea    (%rbx,%rdi,8),%rbx
+	movslq %ecx,%rcx
+	mov    %rax,0x38(%rsp)
+	lea    -0x9(%r12),%eax
+	mov    %rbx,0x70(%rsp)
+	mov    0x140(%rsp),%rbx
+	shl    $0x3,%rcx
+	mov    %eax,0x80(%rsp)
+	add    %rcx,%rsi
+	shr    %eax
+	vmovsd %xmm3,0x8(%rsp)
+	vxorpd %xmm3,%xmm3,%xmm3
+	lea    0xb(%rax,%rax,1),%rax
+	vmovsd %xmm3,0x118(%rsp)
+	mov    %rax,(%rsp)
+	lea    -0x1(%r12),%eax
+	add    %rbx,%rsi
+	mov    %rax,0x90(%rsp)
+	mov    %r15,%rax
+	mov    %r13,%r15
+	mov    %rsi,0x48(%rsp)
+	lea    (%r14,%rcx,1),%rsi
+	add    %rbx,%rcx
+	mov    %rax,%r13
+	add    %rbx,%rsi
+	mov    %rcx,0x78(%rsp)
+	mov    %rsi,0x40(%rsp)
+	lea    (%rdi,%rdi,2),%rsi
+	lea    0x0(,%rsi,8),%rcx
+	lea    0x4(%r14,%rsi,4),%rsi
+	lea    0x8(%r14,%rcx,1),%rdi
+	lea    (%rbx,%rsi,2),%rsi
+	lea    0x20(%rbx,%rcx,1),%rcx
+	add    %rbx,%rdi
+	mov    %rsi,0x58(%rsp)
+	mov    %rcx,0x60(%rsp)
+	mov    %rdi,0x50(%rsp)
+	mov    0x68(%rsp),%rax
+	nopw   0x0(%rax,%rax,1)
+	vmovsd (%rax),%xmm2
+	vmovsd 0x10(%rax),%xmm4
+	vmulsd 0x35f7(%rip),%xmm4,%xmm9        
+	vmulsd 0x35f7(%rip),%xmm2,%xmm8        
+	vmovsd 0x8(%rax),%xmm1
+	mov    0x70(%rsp),%r9
+	mov    0x35d6(%rip),%rax        
+	vmulsd 0x35d6(%rip),%xmm1,%xmm6        
+	vmulsd 0x35ce(%rip),%xmm2,%xmm7        
+	vmulsd 0x3616(%rip),%xmm1,%xmm11        
+	mov    %rax,(%r9)
+	vmulsd %xmm2,%xmm2,%xmm13
+	vaddsd %xmm4,%xmm4,%xmm14
+	vmulsd %xmm1,%xmm1,%xmm5
+	vmulsd %xmm8,%xmm9,%xmm12
+	vmovsd %xmm9,0x10(%r9)
+	vmovsd 0x35b4(%rip),%xmm9        
+	vsubsd %xmm5,%xmm13,%xmm10
+	vmovq  %xmm12,%r14
+	vmovsd %xmm12,0x38(%r9)
+	vmulsd 0x35ad(%rip),%xmm10,%xmm12        
+	vmovsd %xmm7,0x18(%r9)
+	vmovsd %xmm6,0x8(%r9)
+	vaddsd %xmm13,%xmm5,%xmm3
+	vmulsd %xmm8,%xmm6,%xmm7
+	vmulsd 0x3577(%rip),%xmm4,%xmm8        
+	vmulsd %xmm4,%xmm4,%xmm0
+	vmovsd %xmm7,0x20(%r9)
+	vfnmadd132sd %xmm0,%xmm3,%xmm9
+	vmulsd 0x3570(%rip),%xmm9,%xmm9        
+	vmovq  %xmm12,%rcx
+	vmovsd %xmm12,0x40(%r9)
+	vmovsd 0x358d(%rip),%xmm12        
+	vmulsd %xmm6,%xmm8,%xmm6
+	vmovsd %xmm6,0x28(%r9)
+	vmovsd %xmm6,0x130(%rsp)
+	vfnmadd132sd %xmm13,%xmm5,%xmm12
+	vmovsd %xmm9,0x30(%r9)
+	vmulsd %xmm12,%xmm11,%xmm6
+	vmovq  %rcx,%xmm11
+	vmovsd %xmm6,0x48(%r9)
+	vmovsd %xmm6,0x148(%rsp)
+	vmulsd 0x355e(%rip),%xmm4,%xmm6        
+	vmulsd %xmm7,%xmm6,%xmm12
+	vmovsd 0x3562(%rip),%xmm6        
+	vmovq  %xmm12,%rdx
+	vmovsd %xmm12,0x50(%r9)
+	vmovsd 0x3547(%rip),%xmm12        
+	vfnmadd132sd %xmm0,%xmm3,%xmm12
+	vmulsd %xmm12,%xmm6,%xmm6
+	vmulsd %xmm6,%xmm1,%xmm12
+	vmulsd %xmm6,%xmm2,%xmm6
+	vmovsd %xmm12,0x58(%r9)
+	vmovsd %xmm6,0x68(%r9)
+	vmovsd 0x3531(%rip),%xmm8        
+	vmovq  %xmm12,%rax
+	vmovsd %xmm13,0x140(%rsp)
+	vmulsd 0x3523(%rip),%xmm4,%xmm12        
+	vfnmadd132sd %xmm9,%xmm0,%xmm8
+	vmulsd %xmm8,%xmm12,%xmm8
+	vmulsd 0x3519(%rip),%xmm4,%xmm12        
+	vmovsd %xmm8,0x60(%r9)
+	vmulsd %xmm10,%xmm12,%xmm12
+	vmovsd 0x34ce(%rip),%xmm10        
+	vmovq  %xmm12,%rsi
+	vmovsd %xmm12,0x70(%r9)
+	vmulsd 0x354b(%rip),%xmm7,%xmm12        
+	vfnmadd132sd %xmm5,%xmm13,%xmm10
+	vmulsd 0x34ee(%rip),%xmm2,%xmm13        
+	vmulsd %xmm11,%xmm12,%xmm12
+	vmovsd %xmm12,0x80(%r9)
+	vmulsd %xmm10,%xmm13,%xmm13
+	vmulsd 0x3493(%rip),%xmm4,%xmm10        
+	vmulsd 0x148(%rsp),%xmm10,%xmm11
+	vmovsd %xmm13,0x78(%r9)
+	vmovsd %xmm11,0x88(%r9)
+	vmovq  %xmm11,%r10
+	vmovsd 0x3506(%rip),%xmm11        
+	vfnmadd132sd %xmm0,%xmm3,%xmm11
+	vmulsd 0x3501(%rip),%xmm11,%xmm11        
+	vmulsd %xmm11,%xmm7,%xmm7
+	vmovq  %xmm11,%rdi
+	vmovq  %rcx,%xmm11
+	vmovsd %xmm7,0x90(%r9)
+	vmovq  %rdi,%xmm7
+	vmulsd %xmm7,%xmm11,%xmm7
+	vmovq  %rax,%xmm11
+	vmovsd %xmm7,0xb0(%r9)
+	vmulsd 0x34d2(%rip),%xmm4,%xmm7        
+	vmulsd %xmm8,%xmm7,%xmm7
+	vfmsub231sd %xmm11,%xmm1,%xmm7
+	vfmadd132sd %xmm2,%xmm7,%xmm6
+	vmulsd 0x34c3(%rip),%xmm6,%xmm7        
+	vmovsd %xmm7,0xa0(%r9)
+	vmovsd %xmm7,0x128(%rsp)
+	vmovsd 0x34b1(%rip),%xmm7        
+	vfnmadd132sd %xmm9,%xmm0,%xmm7
+	vmulsd 0x34ac(%rip),%xmm7,%xmm11        
+	vmulsd 0x130(%rsp),%xmm11,%xmm7
+	vmovq  %xmm11,%rax
+	vmovq  %r14,%xmm11
+	vmovq  %rax,%xmm6
+	vmulsd %xmm6,%xmm11,%xmm11
+	vmulsd %xmm10,%xmm13,%xmm6
+	vmovsd %xmm7,0x98(%r9)
+	vmulsd %xmm13,%xmm2,%xmm10
+	vfmsub231sd 0x148(%rsp),%xmm1,%xmm10
+	vmovq  %xmm11,%rax
+	vmovsd %xmm11,0xa8(%r9)
+	vmovsd 0x34dd(%rip),%xmm11        
+	vmovsd %xmm6,0xb8(%r9)
+	vmovq  %xmm6,%r11
+	vmulsd 0x344f(%rip),%xmm10,%xmm10        
+	vmovsd %xmm10,0xc0(%r9)
+	vfnmadd213sd 0x140(%rsp),%xmm5,%xmm11
+	vmulsd 0x34b4(%rip),%xmm10,%xmm6        
+	vfmadd132sd %xmm5,%xmm6,%xmm11
+	vmulsd 0x34af(%rip),%xmm1,%xmm6        
+	vmulsd %xmm11,%xmm6,%xmm6
+	vmovsd 0x34b2(%rip),%xmm11        
+	vmovsd %xmm6,0xc8(%r9)
+	vmovq  %xmm6,%r8
+	vmulsd 0x3494(%rip),%xmm4,%xmm6        
+	vfmadd132sd %xmm9,%xmm0,%xmm11
+	vmovq  %xmm6,%rcx
+	vmulsd %xmm6,%xmm12,%xmm6
+	vmovsd %xmm6,0xd0(%r9)
+	vmovq  %rcx,%xmm6
+	vmulsd %xmm6,%xmm10,%xmm6
+	vmovsd %xmm6,0x110(%r9)
+	vmulsd 0x3473(%rip),%xmm11,%xmm6        
+	vmovq  %xmm6,%rcx
+	vmulsd 0x148(%rsp),%xmm6,%xmm6
+	vmovsd %xmm6,0xd8(%r9)
+	vmovq  %xmm6,%rbx
+	vmovq  %rcx,%xmm6
+	vmulsd %xmm6,%xmm13,%xmm6
+	vmovsd %xmm6,0x108(%r9)
+	vmovq  %xmm6,%r12
+	vmulsd 0x3440(%rip),%xmm9,%xmm6        
+	vmovq  %xmm6,%rdi
+	vmovq  %rdx,%xmm6
+	vmovq  %rdi,%xmm11
+	vmulsd %xmm11,%xmm6,%xmm6
+	vmovsd %xmm6,0xe0(%r9)
+	vmovq  %xmm6,%rdx
+	vmovq  %rsi,%xmm6
+	vmulsd %xmm11,%xmm6,%xmm6
+	vmovsd %xmm6,0x100(%r9)
+	vmovq  %xmm6,%rdi
+	vmulsd 0x3406(%rip),%xmm4,%xmm6        
+	vmovq  %xmm6,%rsi
+	vmulsd %xmm6,%xmm7,%xmm7
+	vmovq  %rax,%xmm6
+	vfmadd231sd 0x128(%rsp),%xmm1,%xmm7
+	vmovq  %rsi,%xmm11
+	vmulsd %xmm11,%xmm6,%xmm6
+	vfmadd231sd 0x128(%rsp),%xmm2,%xmm6
+	vmulsd 0x33da(%rip),%xmm7,%xmm7        
+	vmulsd 0x33d2(%rip),%xmm6,%xmm11        
+	vmovsd %xmm7,0xe8(%r9)
+	vmovsd %xmm11,0xf8(%r9)
+	vmovsd %xmm11,0x128(%rsp)
+	vmulsd %xmm0,%xmm4,%xmm11
+	vmovq  %xmm11,%rcx
+	vmulsd 0x33ae(%rip),%xmm9,%xmm11        
+	vmovq  %xmm11,%rsi
+	vmovq  %rcx,%xmm11
+	vmulsd %xmm11,%xmm0,%xmm11
+	vmovq  %xmm11,%rax
+	vmovq  %rsi,%xmm11
+	vmovq  %rax,%xmm6
+	mov    %r9,%rax
+	vfmsub132sd %xmm11,%xmm6,%xmm8
+	vmulsd %xmm10,%xmm2,%xmm6
+	vmulsd 0x3383(%rip),%xmm8,%xmm8        
+	vmovsd %xmm6,%xmm6,%xmm11
+	vfmsub231sd %xmm12,%xmm1,%xmm11
+	vmulsd 0x337a(%rip),%xmm11,%xmm6        
+	vmovsd %xmm8,0xf0(%r9)
 	vmulsd %xmm8,%xmm4,%xmm8
-	vmulsd 0xc8(%rsp),%xmm4,%xmm4
-	vmovq  %xmm8,%r14
+	vmovq  %xmm6,%r9
+	vmovsd %xmm6,0x118(%rax)
+	vmovsd 0x148(%rsp),%xmm6
+	vmulsd 0x3446(%rip),%xmm6,%xmm11        
+	vmovq  %r8,%xmm6
+	vmulsd %xmm13,%xmm11,%xmm11
+	vmovsd %xmm11,0x120(%rax)
+	vmulsd 0x3434(%rip),%xmm4,%xmm11        
+	vmulsd %xmm11,%xmm6,%xmm13
+	vmovq  %r9,%xmm6
+	vmulsd %xmm11,%xmm6,%xmm11
+	vmovq  %r10,%xmm6
+	vmovsd %xmm13,0x128(%rax)
+	mov    0x48(%rsp),%rsi
+	vmovsd %xmm11,0x178(%rax)
+	vmovsd 0x340b(%rip),%xmm11        
+	vfmadd132sd %xmm9,%xmm0,%xmm11
+	vmulsd 0x3406(%rip),%xmm11,%xmm11        
+	vmulsd %xmm11,%xmm10,%xmm10
+	vmulsd %xmm11,%xmm12,%xmm12
+	vmovsd %xmm10,0x170(%rax)
+	vmovsd 0x31a4(%rip),%xmm10        
+	vmovsd %xmm12,0x130(%rax)
+	vmovq  %rcx,%xmm12
+	vfmadd132sd %xmm9,%xmm0,%xmm10
+	vmulsd 0x33da(%rip),%xmm10,%xmm10        
+	vmulsd %xmm10,%xmm6,%xmm11
+	vmovq  %r11,%xmm6
+	vmulsd %xmm10,%xmm6,%xmm10
+	vmovq  %rdx,%xmm6
+	vmovsd %xmm11,0x138(%rax)
+	vmulsd 0x33be(%rip),%xmm4,%xmm11        
+	vmovsd %xmm10,0x168(%rax)
+	vmulsd %xmm7,%xmm2,%xmm10
+	vfmadd231sd %xmm11,%xmm6,%xmm10
+	vmulsd 0x33ad(%rip),%xmm10,%xmm10        
+	vmovq  %r14,%xmm6
+	vmovsd %xmm10,0x140(%rax)
+	vmulsd 0x33a0(%rip),%xmm9,%xmm10        
+	vmulsd %xmm9,%xmm10,%xmm9
+	vfmsub231sd %xmm0,%xmm0,%xmm9
+	vmulsd 0x3396(%rip),%xmm9,%xmm9        
+	vmulsd 0x130(%rsp),%xmm9,%xmm10
+	vmulsd %xmm9,%xmm6,%xmm9
+	vmulsd 0x3398(%rip),%xmm4,%xmm6        
+	vmovsd %xmm9,0x158(%rax)
+	vmulsd 0x3378(%rip),%xmm1,%xmm9        
+	vmovsd %xmm10,0x148(%rax)
+	vfmsub231sd %xmm9,%xmm7,%xmm8
+	vmulsd 0x3363(%rip),%xmm2,%xmm7        
+	vfmadd231sd 0x128(%rsp),%xmm7,%xmm8
+	vmovq  %rdi,%xmm7
+	vmulsd %xmm7,%xmm6,%xmm6
+	vmovq  %rbx,%xmm7
+	vfmsub231sd %xmm7,%xmm1,%xmm6
+	vmovq  %r12,%xmm7
+	vmulsd 0x3341(%rip),%xmm8,%xmm8        
+	vfmadd231sd %xmm7,%xmm2,%xmm6
+	vmulsd 0x3344(%rip),%xmm6,%xmm6        
+	vmovq  %r8,%xmm7
+	vmovsd %xmm8,0x150(%rax)
+	vmovsd %xmm6,0x160(%rax)
+	vmovq  %r9,%xmm6
+	vmulsd %xmm6,%xmm2,%xmm6
+	vfmsub231sd %xmm7,%xmm1,%xmm6
+	vmulsd 0x3321(%rip),%xmm6,%xmm6        
+	vmovsd %xmm6,0x180(%rax)
+	movq   $0x0,(%rsi)
+	mov    0x40(%rsp),%rsi
+	movq   $0x0,(%rsi)
+	mov    0x78(%rsp),%rsi
+	vmovapd 0x2db1(%rip),%ymm6        
+	mov    0x50(%rsp),%rbx
+	mov    0x58(%rsp),%rdx
+	vmovsd 0x2faf(%rip),%xmm7        
+	vmovupd %ymm6,(%rsi)
+	mov    0x2f9c(%rip),%rsi        
+	vmovsd 0x2f9c(%rip),%xmm6        
+	movq   $0x0,0x8(%rbx)
+	movq   $0x0,0x10(%rbx)
+	mov    %rsi,(%rbx)
+	mov    %rsi,0x8(%rdx)
+	movq   $0x0,(%rdx)
+	mov    0x60(%rsp),%rsi
+	movq   $0x0,0x10(%rdx)
+	vmulsd 0x8(%rax),%xmm6,%xmm6
+	movq   $0x0,0x8(%rsi)
+	vmovsd %xmm6,(%rsi)
+	vmovsd 0x2f78(%rip),%xmm6        
+	vmulsd 0x18(%rax),%xmm6,%xmm6
+	vmovsd %xmm6,0x10(%rsi)
+	vmulsd 0x10(%rax),%xmm7,%xmm7
+	vmulsd 0x2f69(%rip),%xmm6,%xmm6        
+	vmovsd %xmm7,0x18(%rsi)
+	vmovsd 0x2f34(%rip),%xmm7        
+	vmulsd 0x18(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0x20(%rsi)
+	vmovsd %xmm6,0x18(%rbx)
+	vmovsd 0x18(%rsi),%xmm6
+	vmovsd %xmm6,0x20(%rbx)
+	vmovsd 0x2f43(%rip),%xmm6        
+	vmulsd (%rsi),%xmm6,%xmm6
+	vmovsd %xmm6,0x28(%rbx)
+	movq   $0x0,0x30(%rbx)
+	vmovsd (%rsi),%xmm6
+	vmovsd 0x2f96(%rip),%xmm7        
+	vxorpd 0x33fe(%rip),%xmm6,%xmm6        
+	vmovsd %xmm6,0x38(%rbx)
+	movq   $0x0,0x38(%rdx)
+	movq   $0x0,0x18(%rdx)
+	vmovsd (%rsi),%xmm6
+	vmovsd %xmm6,0x20(%rdx)
+	vmovsd 0x2f00(%rip),%xmm6        
+	vmulsd 0x18(%rsi),%xmm6,%xmm6
+	vmovsd %xmm6,0x28(%rdx)
+	vmovsd 0x18(%rbx),%xmm6
+	vmovsd %xmm6,0x30(%rdx)
+	vmovsd 0x2f34(%rip),%xmm6        
+	vmulsd 0x20(%rax),%xmm6,%xmm6
+	vmovsd %xmm6,0x28(%rsi)
+	vmovsd 0x2eea(%rip),%xmm6        
+	vmulsd 0x28(%rax),%xmm6,%xmm6
+	vmovsd %xmm6,0x30(%rsi)
+	vmovsd 0x2f18(%rip),%xmm6        
+	vmulsd 0x20(%rax),%xmm6,%xmm6
+	vmovsd %xmm6,0x38(%rsi)
+	vmovsd 0x2f0e(%rip),%xmm6        
+	vmulsd 0x38(%rax),%xmm6,%xmm6
+	vmovsd %xmm6,0x40(%rsi)
+	vsubsd %xmm0,%xmm5,%xmm6
+	vfmadd132sd 0x30(%rax),%xmm6,%xmm7
+	vmulsd 0x2f02(%rip),%xmm7,%xmm7        
+	vmovsd %xmm7,0x48(%rsi)
+	vmovsd 0x2e9d(%rip),%xmm7        
+	vmulsd 0x38(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0x50(%rsi)
+	vmovsd 0x2ec3(%rip),%xmm7        
+	vmulsd 0x40(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0x58(%rsi)
+	vmovsd %xmm7,0x40(%rbx)
+	vmovsd 0x50(%rsi),%xmm7
+	vmovsd %xmm7,0x48(%rbx)
+	vmovsd 0x2eca(%rip),%xmm7        
+	vfnmadd132sd 0x30(%rax),%xmm6,%xmm7
+	vmulsd 0x2ec4(%rip),%xmm7,%xmm7        
+	vmovsd %xmm7,0x50(%rbx)
+	vmovsd 0x2e97(%rip),%xmm7        
+	vmulsd 0x28(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0x58(%rbx)
+	vmovsd 0x2e7d(%rip),%xmm7        
+	vmulsd 0x20(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0x60(%rbx)
+	vmovsd 0x30(%rsi),%xmm7
+	vxorpd 0x32e6(%rip),%xmm7,%xmm7        
+	vmovsd %xmm7,0x68(%rbx)
+	vmovsd 0x28(%rsi),%xmm7
+	vxorpd 0x32d4(%rip),%xmm7,%xmm7        
+	vmovsd %xmm7,0x70(%rbx)
+	vmovsd 0x2e07(%rip),%xmm7        
+	movq   $0x0,0x40(%rdx)
+	vmulsd 0x20(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0x48(%rdx)
+	vmovsd 0x2e5d(%rip),%xmm7        
+	vmulsd 0x28(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0x50(%rdx)
+	vmovsd 0x2e53(%rip),%xmm7        
+	vmulsd 0x30(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0x58(%rdx)
+	vmovsd 0x2e39(%rip),%xmm7        
+	vmulsd 0x38(%rax),%xmm7,%xmm7
+	vmulsd 0x2e8c(%rip),%xmm1,%xmm8        
+	vmovsd 0x140(%rsp),%xmm13
+	vmovsd 0x2d9b(%rip),%xmm9        
+	vmovsd %xmm7,0x60(%rdx)
+	vmovsd 0x2d9e(%rip),%xmm7        
+	vfnmadd132sd %xmm0,%xmm13,%xmm9
+	vmulsd 0x40(%rax),%xmm7,%xmm7
+	movq   $0x0,0x70(%rdx)
+	vmovsd %xmm7,0x68(%rdx)
+	vmovsd 0x2e3f(%rip),%xmm7        
+	vmulsd 0x48(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0x60(%rsi)
+	vmovsd 0x2e35(%rip),%xmm7        
+	vmulsd 0x50(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0x68(%rsi)
+	vmovsd 0x2e03(%rip),%xmm7        
+	vfmadd132sd 0x30(%rax),%xmm5,%xmm7
+	vmulsd %xmm7,%xmm8,%xmm7
+	vmovsd %xmm7,0x70(%rsi)
+	vmovsd 0x2e1c(%rip),%xmm7        
+	vmulsd 0x50(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0x78(%rsi)
+	vmovsd 0x2e12(%rip),%xmm7        
+	vmulsd 0x68(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0x80(%rsi)
+	vmulsd 0x2e05(%rip),%xmm1,%xmm7        
+	vfnmadd132sd 0x28(%rax),%xmm12,%xmm7
+	vmovsd 0x2dff(%rip),%xmm12        
+	vfnmadd231sd 0x60(%rax),%xmm12,%xmm7
+	vmulsd 0x2df9(%rip),%xmm7,%xmm7        
+	vmovsd %xmm7,0x88(%rsi)
+	vmulsd 0x2df1(%rip),%xmm2,%xmm7        
+	vmulsd %xmm9,%xmm7,%xmm9
+	vmovsd %xmm9,0x90(%rsi)
+	vmovsd 0x2da4(%rip),%xmm12        
+	vmulsd 0x70(%rax),%xmm12,%xmm9
+	vmovsd 0x2d8f(%rip),%xmm12        
+	vmovsd %xmm9,0x98(%rsi)
+	vmulsd 0x78(%rax),%xmm12,%xmm9
+	vmovsd 0x2dc2(%rip),%xmm12        
+	vmovsd %xmm9,0xa0(%rsi)
+	vmovsd %xmm9,0x78(%rbx)
+	vmovsd 0x98(%rsi),%xmm9
+	vmovsd %xmm9,0x80(%rbx)
+	vmovsd 0x2c4d(%rip),%xmm9        
+	vfnmadd132sd %xmm0,%xmm5,%xmm9
+	vfnmadd231sd 0x30(%rax),%xmm12,%xmm9
+	vmovsd 0x2d92(%rip),%xmm12        
+	vmulsd %xmm9,%xmm7,%xmm7
+	vmovsd %xmm7,0x88(%rbx)
+	vmovsd 0x2c5d(%rip),%xmm7        
+	vmulsd 0x60(%rax),%xmm12,%xmm9
+	vfmsub132sd %xmm5,%xmm0,%xmm7
+	vfmsub132sd %xmm4,%xmm9,%xmm7
+	vmulsd 0x2d4e(%rip),%xmm7,%xmm7        
+	vmovsd 0x2c3e(%rip),%xmm9        
+	vfnmadd132sd %xmm0,%xmm5,%xmm9
+	vmovsd %xmm7,0x90(%rbx)
+	vmovsd 0x2d19(%rip),%xmm7        
+	vmulsd 0x58(%rax),%xmm7,%xmm7
+	vmulsd %xmm9,%xmm8,%xmm8
+	vmovsd %xmm7,0x98(%rbx)
+	vmovsd 0x78(%rsi),%xmm7
+	vmovsd %xmm8,0xa8(%rbx)
+	vmovsd %xmm7,0xa0(%rbx)
+	vmovsd 0x68(%rsi),%xmm7
+	vxorpd 0x30c5(%rip),%xmm7,%xmm7        
+	vmovsd %xmm7,0xb0(%rbx)
+	vmovsd 0x60(%rsi),%xmm7
+	vxorpd 0x30b0(%rip),%xmm7,%xmm7        
+	vmovsd %xmm7,0xb8(%rbx)
+	movq   $0x0,0x78(%rdx)
+	vmovsd 0x2bc8(%rip),%xmm7        
+	vmulsd 0x48(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0x80(%rdx)
+	vmovsd 0x2cdb(%rip),%xmm7        
+	vmulsd 0x50(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0x88(%rdx)
+	vmovsd 0x2cce(%rip),%xmm7        
+	vmulsd 0x58(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0x90(%rdx)
+	vmovsd 0x2cc1(%rip),%xmm7        
+	vmulsd 0x60(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0x98(%rdx)
+	vmovsd 0x2ca4(%rip),%xmm7        
+	vmulsd 0x68(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0xa0(%rdx)
+	vmovsd 0x2c87(%rip),%xmm7        
+	vmulsd 0x70(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0xa8(%rdx)
+	vmovsd 0x2b4a(%rip),%xmm7        
+	vmulsd 0x78(%rax),%xmm7,%xmm7
+	movq   $0x0,0xb8(%rdx)
+	vmovsd %xmm7,0xb0(%rdx)
+	vmovsd 0x2cca(%rip),%xmm7        
+	vmulsd 0x80(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0xa8(%rsi)
+	vmovsd 0x2cba(%rip),%xmm7        
+	vmulsd 0x88(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0xb0(%rsi)
+	vmulsd 0x2caa(%rip),%xmm2,%xmm7        
+	vmulsd 0x58(%rax),%xmm7,%xmm7
+	vfmadd231sd 0x20(%rax),%xmm5,%xmm7
+	vmulsd 0x2c9f(%rip),%xmm7,%xmm7        
+	vmovsd %xmm7,0xb8(%rsi)
+	vmovsd 0x2c97(%rip),%xmm7        
+	vmovsd 0x2cbf(%rip),%xmm12        
+	vmulsd 0x88(%rax),%xmm7,%xmm7
+	vfmadd231sd 0x28(%rax),%xmm6,%xmm7
+	vmulsd 0x2c81(%rip),%xmm7,%xmm7        
+	vmovsd %xmm7,0xc0(%rsi)
+	vmovsd 0x2c79(%rip),%xmm7        
+	vmulsd 0x90(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0xc8(%rsi)
+	vmovsd 0x2c69(%rip),%xmm7        
+	vmulsd 0xa8(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0xd0(%rsi)
+	vmovsd 0x28(%rax),%xmm10
+	vmulsd 0x2c54(%rip),%xmm0,%xmm7        
+	vmulsd 0x2c54(%rip),%xmm10,%xmm8        
 	vmulsd %xmm10,%xmm8,%xmm8
-	vmovsd %xmm8,-0x98(%rcx)
-	vmulsd 0x50(%rsp),%xmm14,%xmm8
-	vmulsd %xmm9,%xmm4,%xmm4
-	vmulsd %xmm8,%xmm15,%xmm15
-	vmovsd %xmm15,-0x90(%rcx)
-	vmulsd %xmm8,%xmm13,%xmm15
-	vmovq  %rdx,%xmm13
-	vmovq  %r9,%xmm8
-	vfmsub231sd %xmm8,%xmm13,%xmm4
-	vmovq  %r13,%xmm13
-	vmovsd %xmm15,-0x70(%rcx)
-	vfmadd231sd %xmm0,%xmm13,%xmm4
-	vmovsd 0x100(%rsp),%xmm0
-	vmulsd 0xc0(%rsp),%xmm4,%xmm14
-	vmulsd %xmm5,%xmm13,%xmm4
-	vfnmadd132sd %xmm2,%xmm7,%xmm0
-	vmulsd 0xb8(%rsp),%xmm0,%xmm0
-	vmovsd %xmm14,-0x80(%rcx)
-	vmulsd %xmm0,%xmm1,%xmm1
-	vmulsd %xmm0,%xmm6,%xmm6
-	vmovq  %r14,%xmm0
+	vfmadd132sd %xmm0,%xmm8,%xmm7
+	vfmadd231sd 0x30(%rax),%xmm6,%xmm7
+	vmulsd 0x2c5c(%rip),%xmm1,%xmm8        
+	vfmadd231sd 0xb0(%rax),%xmm12,%xmm7
+	vmulsd 0x2c3b(%rip),%xmm7,%xmm7        
+	vmovsd %xmm7,0xd8(%rsi)
+	vsubsd %xmm0,%xmm13,%xmm7
+	vmulsd 0x2bf7(%rip),%xmm7,%xmm7        
+	vmulsd 0x38(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0xe0(%rsi)
+	vmulsd 0x2c1a(%rip),%xmm4,%xmm7        
+	vmulsd 0x48(%rax),%xmm8,%xmm8
+	vfmsub132sd 0x98(%rsi),%xmm8,%xmm7
+	vsubsd 0xb0(%rax),%xmm7,%xmm7
+	vmulsd 0x2c0c(%rip),%xmm7,%xmm7        
+	vmovsd %xmm7,0xe8(%rsi)
+	vmovsd 0x2b94(%rip),%xmm7        
+	vmulsd 0xb8(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0xf0(%rsi)
+	vmovsd 0x2bec(%rip),%xmm7        
+	vmulsd 0x2bf4(%rip),%xmm4,%xmm8        
+	vmulsd 0xc0(%rax),%xmm7,%xmm7
+	vmovsd 0x2c04(%rip),%xmm12        
+	vmovsd %xmm7,0xf8(%rsi)
+	vmovsd %xmm7,0xc0(%rbx)
+	vmovsd 0xf0(%rsi),%xmm7
+	vmovsd %xmm7,0xc8(%rbx)
+	vmulsd 0x2bb4(%rip),%xmm1,%xmm7        
+	vmulsd 0x70(%rax),%xmm8,%xmm8
+	vfmsub132sd 0x48(%rax),%xmm8,%xmm7
+	vmulsd 0x2bd1(%rip),%xmm4,%xmm8        
+	vsubsd 0xb0(%rax),%xmm7,%xmm7
+	vmulsd 0x2ba1(%rip),%xmm7,%xmm7        
+	vmovsd %xmm7,0xd0(%rbx)
+	vmovsd 0x2a79(%rip),%xmm7        
+	vfnmadd132sd 0x30(%rax),%xmm5,%xmm7
+	vmulsd 0x2b8b(%rip),%xmm7,%xmm7        
+	vmulsd 0x38(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0xd8(%rbx)
+	vmovsd 0x2b7e(%rip),%xmm7        
+	vmulsd 0x60(%rax),%xmm8,%xmm8
+	vmulsd 0x58(%rax),%xmm7,%xmm7
+	vfmsub231sd 0x48(%rax),%xmm12,%xmm7
+	vfmadd132sd %xmm1,%xmm8,%xmm7
+	vaddsd 0xc0(%rax),%xmm7,%xmm7
+	vmulsd 0x2b71(%rip),%xmm7,%xmm7        
+	vmovsd %xmm7,0xe0(%rbx)
+	vmovsd 0x2ae1(%rip),%xmm7        
+	vmulsd 0x98(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0xe8(%rbx)
+	vmovsd 0xc8(%rsi),%xmm7
+	vmovsd %xmm7,0xf0(%rbx)
+	vmulsd 0x2b41(%rip),%xmm6,%xmm7        
+	vmovsd 0x2b41(%rip),%xmm8        
+	vmulsd 0x28(%rax),%xmm7,%xmm7
+	vfnmadd132sd %xmm0,%xmm5,%xmm8
+	vmovsd %xmm7,0xf8(%rbx)
+	vmovsd 0x29d7(%rip),%xmm7        
+	vfnmadd231sd 0x30(%rax),%xmm7,%xmm8
+	vmovsd 0x2a69(%rip),%xmm7        
+	vmulsd 0x20(%rax),%xmm7,%xmm7
+	vmulsd %xmm8,%xmm7,%xmm7
+	vmovsd %xmm7,0x100(%rbx)
+	vmovsd 0xb0(%rsi),%xmm7
+	vxorpd 0x2d5f(%rip),%xmm7,%xmm7        
+	vmovsd %xmm7,0x108(%rbx)
+	vmovsd 0xa8(%rsi),%xmm7
+	vxorpd 0x2d47(%rip),%xmm7,%xmm7        
+	vmovsd %xmm7,0x110(%rbx)
+	vmovsd 0x29bf(%rip),%xmm7        
+	movq   $0x0,0xc0(%rdx)
+	vmulsd 0x80(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0xc8(%rdx)
+	vmovsd 0x2ab4(%rip),%xmm7        
+	vmulsd 0x88(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0xd0(%rdx)
+	vmovsd 0x2aa4(%rip),%xmm7        
+	vmulsd 0x90(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0xd8(%rdx)
+	vmovsd 0x2a94(%rip),%xmm7        
+	vmulsd 0x98(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0xe0(%rdx)
+	vmovsd 0x2a84(%rip),%xmm7        
+	vmulsd 0xa0(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0xe8(%rdx)
+	vmovsd 0x2a64(%rip),%xmm7        
+	vmulsd 0xa8(%rax),%xmm7,%xmm7
+	vmovsd 0x2ae4(%rip),%xmm12        
+	vmovsd %xmm7,0xf0(%rdx)
+	vmovsd 0x2a3c(%rip),%xmm7        
+	vmulsd 0xb0(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0xf8(%rdx)
+	vmovsd 0x2a1c(%rip),%xmm7        
+	vmulsd 0xb8(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0x100(%rdx)
+	vmovsd 0x28ec(%rip),%xmm7        
+	vmulsd 0xc0(%rax),%xmm7,%xmm7
+	movq   $0x0,0x110(%rdx)
+	vmovsd %xmm7,0x108(%rdx)
+	vmovsd 0x2a71(%rip),%xmm7        
+	vmulsd 0xc8(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0x100(%rsi)
+	vxorpd 0x2c29(%rip),%xmm7,%xmm7        
+	vmovsd %xmm7,0x178(%rbx)
+	vmovsd 0x2a51(%rip),%xmm7        
+	vmulsd 0xd0(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0x108(%rsi)
+	vxorpd 0x2c01(%rip),%xmm7,%xmm7        
+	vmovsd %xmm7,0x170(%rbx)
+	vmovsd 0x28(%rax),%xmm8
+	vmulsd 0x29e4(%rip),%xmm8,%xmm7        
+	vmulsd %xmm8,%xmm7,%xmm7
+	vmulsd 0x2a27(%rip),%xmm1,%xmm8        
+	vfmsub231sd %xmm5,%xmm5,%xmm7
+	vfnmadd231sd 0xb0(%rax),%xmm12,%xmm7
+	vmulsd %xmm7,%xmm8,%xmm7
+	vmovsd %xmm7,0x110(%rsi)
+	vmovsd 0x2a0d(%rip),%xmm7        
+	vmulsd 0xd0(%rax),%xmm7,%xmm7
+	vfmadd231sd 0x50(%rax),%xmm6,%xmm7
+	vmulsd 0x29ff(%rip),%xmm7,%xmm7        
+	vmovsd %xmm7,0x118(%rsi)
+	vmovsd 0x30(%rax),%xmm11
+	vmulsd 0x29f2(%rip),%xmm1,%xmm10        
+	vmovsd 0x28(%rax),%xmm7
+	vmovsd 0x29f5(%rip),%xmm12        
+	vmulsd %xmm11,%xmm4,%xmm8
+	vfmsub132sd %xmm7,%xmm8,%xmm10
+	vmulsd 0x29db(%rip),%xmm1,%xmm8        
+	vmulsd %xmm5,%xmm8,%xmm8
+	vmulsd %xmm11,%xmm8,%xmm8
+	vfmadd132sd %xmm10,%xmm8,%xmm7
+	vfmadd231sd 0xe8(%rax),%xmm12,%xmm7
+	vmovsd 0x29e4(%rip),%xmm8        
+	vmovq  %rcx,%xmm12
+	vmulsd 0x29bf(%rip),%xmm7,%xmm7        
+	vfmadd132sd %xmm5,%xmm0,%xmm8
+	vmovsd %xmm7,0x120(%rsi)
+	vmovsd 0x29b2(%rip),%xmm7        
+	vmulsd 0xe0(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0x128(%rsi)
+	vmovsd %xmm7,0x150(%rbx)
+	vmovsd 0x299a(%rip),%xmm7        
+	vmulsd 0xf8(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0x130(%rsi)
+	vmovsd 0x2982(%rip),%xmm7        
+	vmulsd 0xe8(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0x148(%rbx)
+	vmovsd 0x2922(%rip),%xmm7        
+	vfnmadd231sd 0x30(%rax),%xmm7,%xmm8
+	vmulsd 0x296c(%rip),%xmm1,%xmm7        
+	vmulsd 0x98(%rax),%xmm7,%xmm7
+	vfmadd231sd %xmm8,%xmm12,%xmm7
+	vmovsd 0x295f(%rip),%xmm12        
+	vmovsd 0x25af(%rip),%xmm8        
+	vfmadd231sd 0xf0(%rax),%xmm12,%xmm7
+	vmovsd 0x2956(%rip),%xmm12        
+	vmulsd 0x2946(%rip),%xmm7,%xmm7        
+	vfmsub132sd %xmm13,%xmm0,%xmm8
+	vsubsd %xmm5,%xmm8,%xmm8
+	vmovsd %xmm7,0x138(%rsi)
+	vmulsd 0x118(%rax),%xmm12,%xmm10
+	vmulsd %xmm6,%xmm2,%xmm7
+	vfmadd132sd %xmm8,%xmm10,%xmm7
+	vmulsd 0x292c(%rip),%xmm7,%xmm7        
+	vmovsd %xmm7,0x140(%rsi)
+	vmulsd 0x2924(%rip),%xmm0,%xmm7        
+	vmovsd 0x2924(%rip),%xmm12        
+	vmulsd 0x70(%rax),%xmm7,%xmm7
+	vfmsub231sd 0x88(%rax),%xmm1,%xmm7
+	vfmadd231sd 0x100(%rax),%xmm12,%xmm7
+	vmovsd 0x291d(%rip),%xmm12        
+	vmulsd 0x2905(%rip),%xmm7,%xmm7        
+	vmovsd %xmm7,0x148(%rsi)
+	vmulsd 0x28fd(%rip),%xmm4,%xmm7        
+	vmulsd 0x108(%rax),%xmm12,%xmm8
+	vmovsd 0x2905(%rip),%xmm12        
+	vmulsd 0xb8(%rax),%xmm7,%xmm7
+	vfmsub231sd 0x80(%rax),%xmm1,%xmm7
+	vfmadd231sd 0x28e3(%rip),%xmm7,%xmm8        
+	vmovsd %xmm8,0x150(%rsi)
+	vmulsd 0x108(%rax),%xmm12,%xmm8
+	vmovsd 0x28e3(%rip),%xmm12        
+	vfnmadd132sd 0x28c2(%rip),%xmm8,%xmm7        
+	vmovsd %xmm7,0x128(%rbx)
+	vmovsd 0x2802(%rip),%xmm7        
+	vmulsd 0x110(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0x158(%rsi)
+	vmovsd 0x27e2(%rip),%xmm7        
+	vmulsd 0x118(%rax),%xmm7,%xmm7
+	vmovsd %xmm7,0x160(%rsi)
+	vmovsd %xmm7,0x118(%rbx)
+	vmovsd 0x158(%rsi),%xmm7
+	vmovsd %xmm7,0x120(%rbx)
+	vmulsd 0x287a(%rip),%xmm0,%xmm7        
+	vmulsd 0x88(%rax),%xmm1,%xmm8
+	vfmadd132sd 0x70(%rax),%xmm8,%xmm7
+	vsubsd %xmm5,%xmm0,%xmm8
+	vfnmadd231sd 0x100(%rax),%xmm12,%xmm7
+	vmulsd 0x2867(%rip),%xmm7,%xmm7        
+	vmovsd 0x286f(%rip),%xmm12        
+	vmovsd %xmm7,0x130(%rbx)
+	vmovsd 0x28(%rax),%xmm7
+	vmulsd 0x30(%rax),%xmm8,%xmm8
+	vmulsd 0x284d(%rip),%xmm7,%xmm10        
+	vfmadd132sd %xmm10,%xmm8,%xmm7
+	vmulsd 0xf8(%rax),%xmm12,%xmm8
+	vmovsd 0x2868(%rip),%xmm12        
+	vfmadd132sd %xmm2,%xmm8,%xmm7
+	vmulsd 0x283b(%rip),%xmm7,%xmm7        
+	vmovsd %xmm7,0x138(%rbx)
+	vmovsd 0x30(%rax),%xmm7
+	vmulsd 0x26fe(%rip),%xmm7,%xmm8        
+	vfmsub231sd 0x2825(%rip),%xmm5,%xmm8        
+	vmulsd %xmm8,%xmm7,%xmm7
+	vmulsd 0x2820(%rip),%xmm4,%xmm8        
+	vfmadd231sd %xmm0,%xmm0,%xmm7
+	vmulsd %xmm7,%xmm8,%xmm7
+	vmulsd 0x2817(%rip),%xmm5,%xmm8        
+	vmovsd %xmm7,0x140(%rbx)
+	vmulsd %xmm5,%xmm4,%xmm7
+	vfmadd231sd %xmm13,%xmm12,%xmm8
+	vfnmadd231sd 0x280d(%rip),%xmm0,%xmm8        
+	vmovsd 0x245d(%rip),%xmm0        
+	vmulsd 0x58(%rax),%xmm8,%xmm8
+	vfmadd231sd 0x28(%rax),%xmm7,%xmm8
+	vmulsd 0x27fa(%rip),%xmm8,%xmm8        
+	vmovsd %xmm8,0x158(%rbx)
+	vfnmadd231sd 0x30(%rax),%xmm0,%xmm6
+	vmulsd 0x27f4(%rip),%xmm5,%xmm0        
+	vmulsd 0x27e4(%rip),%xmm6,%xmm6        
+	vmulsd 0x50(%rax),%xmm6,%xmm6
 	vmulsd %xmm5,%xmm0,%xmm0
-	vmovsd %xmm1,-0x88(%rcx)
-	vmovsd %xmm6,-0x78(%rcx)
-	vmovsd %xmm0,-0x68(%rcx)
-	vmovq  %rdx,%xmm0
-	vfmsub231sd %xmm10,%xmm0,%xmm4
-	vmulsd 0xb0(%rsp),%xmm4,%xmm4
-	vmovsd %xmm4,-0x60(%rcx)
-	vmovsd -0x8(%rsi),%xmm0
-	vmovsd -0x10(%rsi),%xmm15
-	vmovsd -0x18(%rsi),%xmm13
-	vmulsd 0xa0(%rsp),%xmm4,%xmm8
-	vfmadd132sd %xmm11,%xmm8,%xmm3
-	vmulsd 0x98(%rsp),%xmm15,%xmm11
-	vmulsd %xmm3,%xmm11,%xmm3
-	vmovsd %xmm3,-0x58(%rcx)
-	vmulsd 0xf8(%rsp),%xmm0,%xmm3
-	vmulsd %xmm12,%xmm3,%xmm11
-	vmulsd %xmm4,%xmm3,%xmm3
-	vmovsd %xmm3,-0x10(%rcx)
-	vmovsd 0x90(%rsp),%xmm3
-	vmulsd %xmm4,%xmm13,%xmm4
-	vmovsd %xmm11,-0x50(%rcx)
-	vfmadd132sd %xmm2,%xmm7,%xmm3
-	vmulsd 0x48(%rsp),%xmm3,%xmm3
-	vmulsd %xmm10,%xmm3,%xmm10
-	vmulsd %xmm5,%xmm3,%xmm3
-	vmovq  %rdi,%xmm5
-	vmovsd %xmm3,-0x18(%rcx)
-	vmulsd 0x38(%rsp),%xmm2,%xmm3
-	vmulsd 0x18(%rsp),%xmm2,%xmm2
-	vmovsd %xmm10,-0x48(%rcx)
-	vmulsd %xmm5,%xmm3,%xmm5
-	vmovsd %xmm5,-0x40(%rcx)
-	vmovq  %r10,%xmm5
-	vmulsd %xmm5,%xmm3,%xmm3
-	vmovsd 0x20(%rsp),%xmm5
-	vmovsd %xmm3,-0x20(%rcx)
-	vmulsd 0x28(%rsp),%xmm0,%xmm3
+	vmovsd %xmm6,0x160(%rbx)
+	vmulsd 0x48(%rax),%xmm9,%xmm9
+	vmovsd 0x27d6(%rip),%xmm6        
+	vfmadd132sd %xmm1,%xmm9,%xmm0
+	vfmadd231sd 0xc8(%rax),%xmm6,%xmm0
+	vmulsd 0x27c8(%rip),%xmm0,%xmm0        
+	vmovsd %xmm0,0x168(%rbx)
+	movq   $0x0,0x118(%rdx)
+	vmovsd 0x2605(%rip),%xmm0        
+	vmulsd 0xc8(%rax),%xmm0,%xmm0
+	vmovsd %xmm0,0x120(%rdx)
+	vmovsd 0x279d(%rip),%xmm0        
+	vmulsd 0xd0(%rax),%xmm0,%xmm0
+	vmovsd %xmm0,0x128(%rdx)
+	vmovsd 0x278d(%rip),%xmm0        
+	vmulsd 0xd8(%rax),%xmm0,%xmm0
+	vmovsd %xmm0,0x130(%rdx)
+	vmovsd 0x277d(%rip),%xmm0        
+	vmulsd 0xe0(%rax),%xmm0,%xmm0
+	vmovsd %xmm0,0x138(%rdx)
+	vmovsd 0x276d(%rip),%xmm0        
+	vmulsd 0xe8(%rax),%xmm0,%xmm0
+	vmovsd %xmm0,0x140(%rdx)
+	vmovsd 0x275d(%rip),%xmm0        
+	vmulsd 0xf0(%rax),%xmm0,%xmm0
+	vmovsd %xmm0,0x148(%rdx)
+	vmovsd 0x273d(%rip),%xmm0        
+	vmulsd 0xf8(%rax),%xmm0,%xmm0
+	vmovsd %xmm0,0x150(%rdx)
+	vmovsd 0x271d(%rip),%xmm0        
+	vmulsd 0x100(%rax),%xmm0,%xmm0
+	vmovsd %xmm0,0x158(%rdx)
+	vmovsd 0x26fd(%rip),%xmm0        
+	vmulsd 0x108(%rax),%xmm0,%xmm0
+	vmovsd %xmm0,0x160(%rdx)
+	vmovsd 0x26dd(%rip),%xmm0        
+	vmulsd 0x110(%rax),%xmm0,%xmm0
+	vmovsd %xmm0,0x168(%rdx)
+	vmovsd 0x2515(%rip),%xmm0        
+	vmulsd 0x118(%rax),%xmm0,%xmm0
+	vmovsd %xmm0,0x170(%rdx)
+	vmovsd 0x118(%rsp),%xmm6
+	vmovsd 0x120(%rsp),%xmm5
+	movq   $0x0,0x178(%rdx)
+	cmpl   $0x7,0x84(%rsp)
+	vmulsd %xmm6,%xmm1,%xmm0
+	vmulsd %xmm6,%xmm2,%xmm6
+	vfmadd231sd %xmm5,%xmm1,%xmm6
+	vfmsub231sd %xmm5,%xmm2,%xmm0
+	vmulsd %xmm6,%xmm1,%xmm7
+	vmovsd %xmm6,0x8(%r13)
+	vmovsd %xmm0,0x8(%r15)
+	vmulsd %xmm6,%xmm2,%xmm6
+	vfmsub231sd %xmm0,%xmm2,%xmm7
+	vfmadd132sd %xmm1,%xmm6,%xmm0
+	vmovsd %xmm7,0x10(%r15)
+	vmulsd %xmm0,%xmm1,%xmm5
+	vmovsd %xmm0,0x10(%r13)
+	vmulsd %xmm0,%xmm2,%xmm0
+	vfmsub231sd %xmm7,%xmm2,%xmm5
+	vfmadd132sd %xmm1,%xmm0,%xmm7
+	vmovsd %xmm5,0x18(%r15)
+	vmulsd %xmm7,%xmm1,%xmm6
+	vmovsd %xmm7,0x18(%r13)
+	vmulsd %xmm7,%xmm2,%xmm7
+	vfmsub231sd %xmm5,%xmm2,%xmm6
+	vfmadd132sd %xmm1,%xmm7,%xmm5
+	vmovsd %xmm6,0x20(%r15)
+	vmulsd %xmm5,%xmm1,%xmm0
+	vmovsd %xmm5,0x20(%r13)
+	vmulsd %xmm5,%xmm2,%xmm5
+	vfmsub231sd %xmm6,%xmm2,%xmm0
+	vfmadd132sd %xmm1,%xmm5,%xmm6
+	vmovsd %xmm0,0x28(%r15)
+	vmulsd %xmm6,%xmm1,%xmm5
+	vmovsd %xmm6,0x28(%r13)
+	vmulsd %xmm6,%xmm2,%xmm6
+	vfmsub231sd %xmm0,%xmm2,%xmm5
+	vfmadd132sd %xmm1,%xmm6,%xmm0
+	vmovsd %xmm5,0x30(%r15)
+	vmovsd %xmm0,0x30(%r13)
+	jbe    b1a4 <_compute_highl_with_dsph._omp_fn.0+0x18d4>
+	cmpl   $0xfffffff5,0x80(%rsp)
+	ja     bc5e <_compute_highl_with_dsph._omp_fn.0+0x238e>
+	mov    $0x9,%edx
+	vmulsd %xmm0,%xmm1,%xmm6
+	vmulsd %xmm0,%xmm2,%xmm0
+	movslq %edx,%rax
+	vfmadd231sd %xmm5,%xmm1,%xmm0
+	vfmsub231sd %xmm5,%xmm2,%xmm6
+	vmulsd %xmm0,%xmm1,%xmm5
+	vmovsd %xmm0,-0x10(%r13,%rdx,8)
+	vmulsd %xmm0,%xmm2,%xmm0
+	vfmsub231sd %xmm6,%xmm2,%xmm5
+	vfmadd231sd %xmm6,%xmm1,%xmm0
+	vunpcklpd %xmm5,%xmm6,%xmm7
+	vmovupd %xmm7,-0x10(%r15,%rdx,8)
+	vmovsd %xmm0,-0x8(%r13,%rdx,8)
+	add    $0x2,%rdx
+	cmp    %rdx,(%rsp)
+	jne    b115 <_compute_highl_with_dsph._omp_fn.0+0x1845>
+	mov    0x84(%rsp),%edx
+	cs nopw 0x0(%rax,%rax,1)
+	vmovsd -0x8(%r13,%rax,8),%xmm5
+	vmovsd -0x8(%r15,%rax,8),%xmm0
+	vmulsd %xmm5,%xmm1,%xmm6
+	vmulsd %xmm5,%xmm2,%xmm5
+	vfmsub231sd %xmm0,%xmm2,%xmm6
+	vfmadd132sd %xmm1,%xmm5,%xmm0
+	vmovsd %xmm6,(%r15,%rax,8)
+	vmovsd %xmm0,0x0(%r13,%rax,8)
+	inc    %rax
+	cmp    %eax,%edx
+	ja     b170 <_compute_highl_with_dsph._omp_fn.0+0x18a0>
+	mov    0x138(%rsp),%rax
+	vmovsd 0x2174(%rip),%xmm5        
+	vxorpd 0x25a4(%rip),%xmm4,%xmm0        
+	cmpl   $0x7,0x84(%rsp)
+	vmovsd 0xd8(%rax),%xmm4
+	vfmsub132sd %xmm14,%xmm14,%xmm5
+	vmovsd %xmm0,0xb0(%rsp)
+	vmulsd %xmm0,%xmm4,%xmm0
+	vmulsd %xmm4,%xmm3,%xmm4
+	vfmadd231sd %xmm5,%xmm0,%xmm4
+	vmulsd 0x28(%rsp),%xmm4,%xmm4
+	vsubsd %xmm14,%xmm5,%xmm5
+	vmovsd %xmm0,0xd0(%rax)
+	vmulsd %xmm0,%xmm3,%xmm0
+	vfmadd231sd %xmm5,%xmm4,%xmm0
+	vmulsd 0x20(%rsp),%xmm0,%xmm0
+	vsubsd %xmm14,%xmm5,%xmm5
+	vmovsd %xmm4,0xc8(%rax)
+	vmulsd %xmm4,%xmm3,%xmm4
+	vfmadd231sd %xmm5,%xmm0,%xmm4
+	vmulsd 0x18(%rsp),%xmm4,%xmm4
+	vsubsd %xmm14,%xmm5,%xmm5
+	vmovsd %xmm0,0xc0(%rax)
+	vmulsd %xmm0,%xmm3,%xmm0
+	vfmadd231sd %xmm5,%xmm4,%xmm0
+	vmulsd 0x10(%rsp),%xmm0,%xmm0
+	vmovsd %xmm4,0xb8(%rax)
+	vsubsd %xmm14,%xmm5,%xmm5
+	vmulsd %xmm4,%xmm3,%xmm4
+	vmovsd %xmm0,0xb0(%rax)
+	vfmadd132sd %xmm5,%xmm4,%xmm0
+	vmulsd 0x8(%rsp),%xmm0,%xmm0
+	vmovsd %xmm0,0xa8(%rax)
+	mov    0x70(%rsp),%rax
+	lea    0x1c0(%rax),%r12
+	mov    0x78(%rsp),%rax
+	lea    0x1c0(%rax),%r8
+	jbe    bb59 <_compute_highl_with_dsph._omp_fn.0+0x2289>
+	vmovsd 0x28(%r15),%xmm0
+	mov    0xa8(%rsp),%rax
+	mov    $0x7,%r14d
+	mov    $0xffffffffffffffc8,%rdi
+	mov    %r14,0x130(%rsp)
+	movq   $0x5,0x140(%rsp)
+	movl   $0x1c,0x128(%rsp)
+	mov    %rdi,%r14
+	mov    %rax,0x118(%rsp)
+	mov    %rax,0x120(%rsp)
+	mov    0xb8(%rsp),%rax
+	vmovsd %xmm0,0xa0(%rsp)
+	vmovsd 0x28(%r13),%xmm0
+	mov    %rax,0xe8(%rsp)
+	mov    %rax,0x100(%rsp)
+	vmovsd %xmm0,0x98(%rsp)
+	nopl   0x0(%rax,%rax,1)
+	mov    0x130(%rsp),%rbx
+	mov    0x128(%rsp),%edx
+	mov    0x138(%rsp),%r10
+	mov    0x110(%rsp),%rdi
+	mov    0x100(%rsp),%r9
+	mov    0xe8(%rsp),%r11
+	lea    0x0(,%rbx,8),%rsi
+	vmovsd -0x8(%r15,%rbx,8),%xmm7
+	mov    %ebx,0x148(%rsp)
+	mov    %ebx,0xd4(%rsp)
+	add    %ebx,%edx
+	lea    -0x8(%rsi),%rcx
+	movslq %edx,%rax
+	dec    %edx
+	shl    $0x3,%rax
+	vmovsd (%r10,%rax,1),%xmm0
+	vmulsd (%rdi,%rax,1),%xmm0,%xmm4
+	vmulsd 0xb0(%rsp),%xmm0,%xmm0
+	vmulsd 0x0(%r13,%rbx,8),%xmm4,%xmm5
+	vmovsd %xmm0,-0x8(%r10,%rax,1)
+	sub    $0x8,%rax
+	add    %rdi,%rax
+	mov    %rbx,%rdi
+	mov    %rax,0x108(%rsp)
+	sub    %edi,%edx
+	vmovsd %xmm5,(%r12,%r14,1)
+	vmulsd (%r15,%rbx,8),%xmm4,%xmm5
+	movslq %edx,%rdx
+	vmovsd %xmm5,(%r12,%rsi,1)
+	vcvtsi2sd %ebx,%xmm15,%xmm5
+	vmulsd %xmm5,%xmm4,%xmm4
+	vmovsd %xmm5,%xmm5,%xmm12
+	vmovsd %xmm5,0xd8(%rsp)
+	vmovsd -0x8(%r13,%rbx,8),%xmm5
+	neg    %rbx
+	shl    $0x3,%rbx
+	vmulsd %xmm5,%xmm4,%xmm6
+	vmovsd %xmm6,(%r8,%r14,1)
+	vmulsd %xmm7,%xmm4,%xmm6
+	vxorpd 0x2371(%rip),%xmm4,%xmm4        
+	vmovsd %xmm6,(%r8,%rsi,1)
+	mov    0x120(%rsp),%rsi
+	vmovsd %xmm6,-0x38(%r8,%r9,1)
+	vmulsd %xmm5,%xmm4,%xmm4
+	vmovsd %xmm4,0x38(%r8,%r11,1)
+	movq   $0x0,-0x38(%r8,%rsi,1)
+	mov    0x118(%rsp),%rsi
+	movq   $0x0,0x38(%r8,%rsi,1)
+	vmulsd (%rax),%xmm0,%xmm4
+	mov    %edi,%eax
+	dec    %eax
+	vmulsd %xmm4,%xmm5,%xmm0
+	vmovsd %xmm0,0x8(%r12,%rbx,1)
+	vmulsd %xmm4,%xmm7,%xmm0
+	vmovsd %xmm0,(%r12,%rcx,1)
+	mov    %eax,0xd0(%rsp)
+	vmovsd -0x10(%r13,%rdi,8),%xmm6
+	vcvtsi2sd %eax,%xmm15,%xmm0
+	vmulsd %xmm4,%xmm0,%xmm0
+	mov    0x120(%rsp),%rsi
+	cmpq   $0x5,0x140(%rsp)
+	movslq 0x128(%rsp),%rax
+	vmulsd %xmm6,%xmm0,%xmm4
+	vmovsd %xmm4,0x8(%r8,%rbx,1)
+	vmovsd -0x10(%r15,%rdi,8),%xmm4
+	vmulsd %xmm4,%xmm0,%xmm8
+	vxorpd 0x22cd(%rip),%xmm0,%xmm0        
+	vmovsd %xmm8,(%r8,%rcx,1)
+	lea    -0x1(%rdi,%rdi,1),%ecx
+	vmovsd %xmm8,-0x30(%r8,%r9,1)
+	lea    -0x2(%rdi),%r9d
+	vmulsd %xmm6,%xmm0,%xmm0
+	vmovsd %xmm0,0x30(%r8,%r11,1)
+	vcvtsi2sd %ecx,%xmm15,%xmm0
+	mov    0x108(%rsp),%rcx
+	vmulsd (%rcx),%xmm0,%xmm0
+	vmulsd (%r10,%rdx,8),%xmm0,%xmm0
+	vmulsd %xmm0,%xmm5,%xmm5
 	vmulsd %xmm0,%xmm7,%xmm0
-	vmulsd %xmm7,%xmm0,%xmm7
-	vfmsub132sd %xmm9,%xmm7,%xmm2
-	vmulsd 0x10(%rsp),%xmm2,%xmm2
-	vmulsd %xmm1,%xmm3,%xmm1
-	vmulsd %xmm6,%xmm3,%xmm6
-	vfmadd231sd %xmm14,%xmm15,%xmm1
-	vfmsub132sd %xmm12,%xmm4,%xmm15
-	vmulsd 0x8(%rsp),%xmm15,%xmm15
-	vfmadd231sd %xmm14,%xmm13,%xmm6
-	vmovsd %xmm2,-0x30(%rcx)
-	vmulsd %xmm5,%xmm1,%xmm1
-	vmulsd %xmm5,%xmm6,%xmm6
-	vmovsd %xmm1,-0x38(%rcx)
-	vmovsd %xmm6,-0x28(%rcx)
-	vmovsd %xmm15,-0x8(%rcx)
-	cmp    %rcx,%r8
-	jne    8130 <cartesian_spherical_harmonics_l5._omp_fn.0+0x1200>
-	jmp    7ebb <cartesian_spherical_harmonics_l5._omp_fn.0+0xf8b>
-	nopw   0x0(%rax,%rax,1)
-	inc    %eax
+	vmovsd %xmm5,-0x30(%r8,%rsi,1)
+	mov    0x118(%rsp),%rsi
+	vmovsd %xmm0,0x30(%r8,%rsi,1)
+	vmulsd %xmm12,%xmm14,%xmm0
+	je     bbd0 <_compute_highl_with_dsph._omp_fn.0+0x2300>
+	mov    0x140(%rsp),%rsi
+	mov    %rax,%rcx
+	mov    %rax,0x108(%rsp)
+	mov    %rsi,%rax
+	add    $0x2,%esi
+	add    %rcx,%rax
+	mov    0x138(%rsp),%rcx
+	lea    0x0(,%rax,8),%rdx
+	add    %rdx,%rcx
+	cmp    $0x9,%esi
+	jbe    bbf5 <_compute_highl_with_dsph._omp_fn.0+0x2325>
+	mov    0x130(%rsp),%r9
+	vmovsd 0x10(%rcx),%xmm8
+	mov    %r10,%rsi
+	mov    %r14,0x88(%rsp)
+	vmovsd 0x8(%rcx),%xmm7
+	mov    0x120(%rsp),%rcx
+	add    0x110(%rsp),%rdx
+	sub    %r9,%rax
+	lea    (%r10,%rax,8),%rdi
+	mov    0x100(%rsp),%rax
+	lea    0x10(%rbx),%r10
+	add    $0x18,%rbx
+	lea    -0x28(%r8,%rcx,1),%r11
+	mov    0x148(%rsp),%ecx
+	lea    -0x28(%r8,%rax,1),%rax
+	mov    %rax,0xc0(%rsp)
+	lea    -0xa(%rcx),%eax
+	mov    $0x4,%ecx
+	mov    0xc0(%rsp),%r14
+	sub    %r9,%rcx
+	shr    %eax
+	lea    (%rcx,%rax,2),%rax
+	lea    0x0(,%rax,8),%rcx
+	mov    %rcx,0xc8(%rsp)
+	mov    0x108(%rsp),%rcx
+	lea    0x0(,%rcx,8),%rax
+	mov    0xe0(%rsp),%rcx
+	add    %rax,%rcx
+	add    %rsi,%rax
+	mov    %rcx,0xf0(%rsp)
+	mov    0xb8(%rsp),%rcx
+	mov    %rax,0xf8(%rsp)
+	mov    0x140(%rsp),%rax
+	lea    (%r8,%rcx,1),%rsi
+	mov    0xa8(%rsp),%rcx
+	add    %r8,%rcx
+	mov    0xf0(%rsp),%r9
+	vsubsd %xmm14,%xmm0,%xmm0
+	vmulsd %xmm8,%xmm3,%xmm8
+	vmovsd -0x8(%r13,%rax,8),%xmm10
+	sub    $0x10,%rdx
+	sub    $0x10,%rdi
+	add    $0x10,%r14
+	add    $0x10,%r11
+	vfmadd231sd %xmm7,%xmm0,%xmm8
+	vsubsd %xmm14,%xmm0,%xmm0
+	vmulsd %xmm7,%xmm3,%xmm7
+	vmulsd (%r9,%rax,8),%xmm8,%xmm8
+	mov    0xf8(%rsp),%r9
+	vmulsd 0x10(%rdx),%xmm8,%xmm9
+	vmovsd %xmm8,(%r9,%rax,8)
+	mov    0x148(%rsp),%r9d
+	vfmadd231sd %xmm0,%xmm8,%xmm7
+	vmulsd %xmm6,%xmm9,%xmm5
+	add    %eax,%r9d
+	vmovsd %xmm5,(%r12,%r10,1)
+	vmulsd %xmm4,%xmm9,%xmm5
+	vmovsd %xmm5,(%r12,%rax,8)
+	vmovsd 0x10(%rdx),%xmm11
+	vcvtsi2sd %eax,%xmm15,%xmm5
+	vmulsd %xmm9,%xmm5,%xmm5
+	vmulsd 0x18(%rdi),%xmm11,%xmm11
+	vmulsd %xmm10,%xmm5,%xmm12
+	vmulsd %xmm11,%xmm2,%xmm13
+	vmulsd %xmm11,%xmm1,%xmm11
+	vmovsd %xmm13,%xmm13,%xmm9
+	vfmadd132sd %xmm6,%xmm12,%xmm9
+	vmovsd %xmm9,(%r8,%r10,1)
+	vmovsd -0x8(%r15,%rax,8),%xmm9
+	add    $0x10,%r10
+	vmulsd %xmm9,%xmm5,%xmm5
+	vfmadd132sd %xmm4,%xmm5,%xmm13
+	vfmadd231sd %xmm6,%xmm11,%xmm5
+	vfmsub132sd %xmm4,%xmm12,%xmm11
+	vmovsd %xmm13,(%r8,%rax,8)
+	vmovsd %xmm5,-0x10(%r14)
+	vcvtsi2sd %r9d,%xmm15,%xmm5
+	mov    0xf0(%rsp),%r9
+	vmovsd %xmm11,(%rsi,%rax,8)
+	vmulsd 0x10(%rdx),%xmm5,%xmm5
+	vmulsd -0x8(%r9,%rax,8),%xmm7,%xmm7
+	mov    0xf8(%rsp),%r9
+	vmulsd 0x10(%rdi),%xmm5,%xmm5
+	vmovsd %xmm7,-0x8(%r9,%rax,8)
+	vmovsd 0x10(%rdi),%xmm11
+	lea    -0x1(%rax),%r9d
+	vmulsd %xmm6,%xmm5,%xmm6
+	vmulsd %xmm4,%xmm5,%xmm5
+	vmovsd %xmm6,-0x10(%r11)
+	vmovsd -0x10(%r13,%rax,8),%xmm6
+	vmovsd %xmm5,(%rcx,%rax,8)
+	vmulsd 0x8(%rdx),%xmm7,%xmm4
+	vmulsd %xmm4,%xmm10,%xmm5
+	vmovsd %xmm5,(%r12,%rbx,1)
+	vmulsd %xmm4,%xmm9,%xmm5
+	vmovsd %xmm5,-0x8(%r12,%rax,8)
+	vmulsd 0x8(%rdx),%xmm11,%xmm11
+	vcvtsi2sd %r9d,%xmm15,%xmm5
+	vmulsd %xmm4,%xmm5,%xmm5
+	vmovsd %xmm10,%xmm10,%xmm4
+	vmulsd %xmm5,%xmm6,%xmm12
+	vmulsd %xmm11,%xmm2,%xmm13
+	vmulsd %xmm11,%xmm1,%xmm11
+	vfmadd132sd %xmm13,%xmm12,%xmm4
+	vmovsd %xmm4,(%r8,%rbx,1)
+	vmovsd -0x10(%r15,%rax,8),%xmm4
+	add    $0x10,%rbx
+	vmulsd %xmm5,%xmm4,%xmm5
+	vfmadd132sd %xmm9,%xmm5,%xmm13
+	vfmadd231sd %xmm11,%xmm10,%xmm5
+	vfmsub132sd %xmm9,%xmm12,%xmm11
+	vmovsd %xmm13,-0x8(%r8,%rax,8)
+	mov    0xd0(%rsp),%r9d
+	vmovsd %xmm5,-0x8(%r14)
+	vmovsd %xmm11,-0x8(%rsi,%rax,8)
+	add    %eax,%r9d
+	vcvtsi2sd %r9d,%xmm15,%xmm5
+	vmulsd 0x8(%rdx),%xmm5,%xmm5
+	lea    -0x2(%rax),%r9d
+	vmulsd 0x8(%rdi),%xmm5,%xmm5
+	vmulsd %xmm5,%xmm10,%xmm10
+	vmulsd %xmm5,%xmm9,%xmm5
+	vmovsd %xmm10,-0x8(%r11)
+	vmovsd %xmm5,-0x8(%rcx,%rax,8)
+	sub    $0x2,%rax
+	cmp    %r10,0xc8(%rsp)
+	jne    b5fd <_compute_highl_with_dsph._omp_fn.0+0x1d2d>
+	mov    0x88(%rsp),%r14
+	mov    0x108(%rsp),%rdi
+	movslq %r9d,%rax
+	mov    0x138(%rsp),%rbx
+	neg    %r9d
+	movslq %r9d,%r9
+	shl    $0x3,%r9
+	lea    0x0(,%rdi,8),%r10
+	lea    (%rax,%rdi,1),%rdx
+	mov    0xe0(%rsp),%rdi
+	lea    (%rbx,%rdx,8),%rdx
+	lea    (%rdi,%r10,1),%rbx
+	add    0x110(%rsp),%r10
+	cs nopw 0x0(%rax,%rax,1)
+	vmulsd 0x10(%rdx),%xmm3,%xmm4
+	vsubsd %xmm14,%xmm0,%xmm0
+	vmovsd 0x0(%r13,%rax,8),%xmm5
+	mov    %rax,%rdi
+	vmovsd (%r15,%rax,8),%xmm6
+	mov    0x148(%rsp),%r11d
+	neg    %rdi
+	sub    $0x8,%rdx
+	shl    $0x3,%rdi
+	vfmadd231sd 0x10(%rdx),%xmm0,%xmm4
+	add    %eax,%r11d
+	vmulsd (%rbx,%rax,8),%xmm4,%xmm4
+	vmulsd (%r10,%rax,8),%xmm4,%xmm7
+	vmovsd %xmm4,0x8(%rdx)
+	vmulsd %xmm7,%xmm5,%xmm4
+	vmovsd %xmm4,(%r12,%r9,1)
+	vmulsd %xmm7,%xmm6,%xmm4
+	vmovsd %xmm4,(%r12,%rax,8)
+	vcvtsi2sd %eax,%xmm15,%xmm4
+	vmulsd %xmm7,%xmm4,%xmm4
+	vmulsd -0x8(%r13,%rax,8),%xmm4,%xmm9
+	vmovsd 0x10(%rdx,%r14,1),%xmm7
+	vmulsd (%r10,%rax,8),%xmm7,%xmm7
+	vmulsd -0x8(%r15,%rax,8),%xmm4,%xmm4
+	vmulsd %xmm7,%xmm2,%xmm8
+	vmulsd %xmm7,%xmm1,%xmm7
+	vmovsd %xmm8,%xmm8,%xmm10
+	vfmadd132sd %xmm6,%xmm4,%xmm8
+	vfmadd132sd %xmm5,%xmm9,%xmm10
+	vfmadd231sd %xmm5,%xmm7,%xmm4
+	vfmsub132sd %xmm6,%xmm9,%xmm7
+	vmovsd %xmm10,(%r8,%r9,1)
+	vmovsd %xmm8,(%r8,%rax,8)
+	vmovsd %xmm4,(%rsi,%rdi,1)
+	vcvtsi2sd %r11d,%xmm15,%xmm4
+	vmovsd %xmm7,(%rsi,%rax,8)
+	add    $0x8,%r9
+	vmulsd (%r10,%rax,8),%xmm4,%xmm4
+	vmulsd 0x8(%rdx,%r14,1),%xmm4,%xmm4
+	vmulsd %xmm5,%xmm4,%xmm5
+	vmulsd %xmm6,%xmm4,%xmm4
+	vmovsd %xmm5,(%rcx,%rdi,1)
+	vmovsd %xmm4,(%rcx,%rax,8)
+	dec    %rax
+	cmp    $0x5,%eax
+	jne    b830 <_compute_highl_with_dsph._omp_fn.0+0x1f60>
+	mov    0x108(%rsp),%rbx
+	mov    0x138(%rsp),%rdx
+	vmovsd 0xa0(%rsp),%xmm9
+	vmovsd 0x98(%rsp),%xmm8
+	mov    0x110(%rsp),%r9
+	mov    %rbx,%rax
+	sub    0x130(%rsp),%rax
+	shl    $0x3,%rbx
+	mov    %rbx,0x108(%rsp)
+	lea    0x28(%rdx,%rax,8),%rdi
+	mov    %rbx,%rax
+	mov    0xe0(%rsp),%rbx
+	add    %rax,%rdx
+	add    %rax,%r9
+	mov    %rdx,%r10
 	xor    %edx,%edx
-	jmp    6f7a <cartesian_spherical_harmonics_l5._omp_fn.0+0x4a>
-	nopl   0x0(%rax)
+	add    %rax,%rbx
+	mov    $0x5,%eax
+	vmulsd 0x10(%r10,%rax,8),%xmm3,%xmm4
+	vsubsd %xmm14,%xmm0,%xmm0
+	mov    0x148(%rsp),%r11d
+	sub    $0x8,%rdi
+	vfmadd231sd 0x8(%r10,%rax,8),%xmm0,%xmm4
+	add    %eax,%r11d
+	vmulsd (%rbx,%rax,8),%xmm4,%xmm4
+	vmulsd (%r9,%rax,8),%xmm4,%xmm5
+	vmovsd %xmm4,(%r10,%rax,8)
+	vmulsd %xmm8,%xmm5,%xmm4
+	vmovsd %xmm4,-0x28(%r12,%rdx,1)
+	vmulsd %xmm9,%xmm5,%xmm4
+	vmovsd %xmm4,(%r12,%rax,8)
+	vmovsd (%r9,%rax,8),%xmm7
+	vcvtsi2sd %eax,%xmm15,%xmm4
+	vmulsd %xmm5,%xmm4,%xmm4
+	vmulsd 0x10(%rdi),%xmm7,%xmm7
+	vmovsd %xmm8,%xmm8,%xmm5
+	vmovsd -0x8(%r13,%rax,8),%xmm8
+	vmulsd %xmm8,%xmm4,%xmm10
+	vmulsd %xmm7,%xmm2,%xmm11
+	vmulsd %xmm7,%xmm1,%xmm7
+	vmovsd %xmm11,%xmm11,%xmm6
+	vfmadd132sd %xmm5,%xmm10,%xmm6
+	vmovsd %xmm6,-0x28(%r8,%rdx,1)
+	vmovsd %xmm9,%xmm9,%xmm6
+	vmovsd -0x8(%r15,%rax,8),%xmm9
+	vmulsd %xmm9,%xmm4,%xmm4
+	vfmadd132sd %xmm6,%xmm4,%xmm11
+	vfmadd231sd %xmm5,%xmm7,%xmm4
+	vfmsub132sd %xmm6,%xmm10,%xmm7
+	vmovsd %xmm11,(%r8,%rax,8)
+	vmovsd %xmm4,-0x28(%rsi,%rdx,1)
+	vcvtsi2sd %r11d,%xmm15,%xmm4
+	vmovsd %xmm7,(%rsi,%rax,8)
+	vmulsd (%r9,%rax,8),%xmm4,%xmm4
+	vmulsd 0x8(%rdi),%xmm4,%xmm4
+	vmulsd %xmm5,%xmm4,%xmm5
+	vmulsd %xmm6,%xmm4,%xmm4
+	vmovsd %xmm5,-0x28(%rcx,%rdx,1)
+	vmovsd %xmm4,(%rcx,%rax,8)
+	add    $0x8,%rdx
+	dec    %rax
+	jne    b97c <_compute_highl_with_dsph._omp_fn.0+0x20ac>
+	mov    0x138(%rsp),%rdi
+	mov    0x108(%rsp),%rax
+	sub    $0x8,%r14
+	subq   $0x8,0x100(%rsp)
+	addq   $0x8,0xe8(%rsp)
+	subq   $0x8,0x120(%rsp)
+	addq   $0x8,0x118(%rsp)
+	vmulsd 0x10(%rdi,%rax,1),%xmm3,%xmm0
+	vfmadd231sd 0x8(%rdi,%rax,1),%xmm14,%xmm0
+	vmulsd (%rbx),%xmm0,%xmm0
+	mov    0x128(%rsp),%ebx
+	mov    %ebx,%eax
+	sub    0xd4(%rsp),%eax
+	lea    0x1(%rax),%edx
+	cltq
+	vmovsd %xmm0,(%r10)
+	vmulsd (%r9),%xmm0,%xmm0
+	movslq %edx,%rdx
+	vmovsd (%rdi,%rdx,8),%xmm5
+	vmovsd %xmm0,(%r12)
+	vmulsd (%r9),%xmm2,%xmm4
+	vmulsd %xmm5,%xmm4,%xmm4
+	vmovsd %xmm4,(%r8)
+	vmulsd (%r9),%xmm1,%xmm0
+	vmulsd %xmm5,%xmm0,%xmm0
+	vmovsd %xmm0,(%rsi)
+	vmovsd 0xd8(%rsp),%xmm0
+	vmulsd (%r9),%xmm0,%xmm0
+	vmulsd (%rdi,%rax,8),%xmm0,%xmm0
+	mov    0x148(%rsp),%eax
+	lea    0x1(%rbx,%rax,1),%eax
+	mov    %eax,0x128(%rsp)
+	mov    0x130(%rsp),%rax
+	inc    %rax
+	mov    %rax,%rdx
+	mov    %rax,0x130(%rsp)
+	vmovsd %xmm0,(%rcx)
+	incq   0x140(%rsp)
+	shl    $0x4,%rdx
+	mov    0x140(%rsp),%rax
+	add    %rdx,%r12
+	add    %rdx,%r8
+	cmp    %rax,0x90(%rsp)
+	jne    b310 <_compute_highl_with_dsph._omp_fn.0+0x1a40>
+	mov    0x30(%rsp),%rax
+	mov    0xb8(%rsp),%rcx
+	add    %rax,0x48(%rsp)
+	add    %rcx,0x70(%rsp)
+	add    %rax,0x78(%rsp)
+	add    %rax,0x50(%rsp)
+	add    %rax,0x58(%rsp)
+	add    %rax,0x60(%rsp)
+	mov    0x68(%rsp),%rcx
+	cmp    %rcx,0x38(%rsp)
+	je     bc12 <_compute_highl_with_dsph._omp_fn.0+0x2342>
+	add    $0x18,%rcx
+	vmovsd (%r15),%xmm3
+	add    %rax,0x40(%rsp)
+	mov    %rcx,0x68(%rsp)
+	mov    %rcx,%rax
+	vmovsd %xmm3,0x120(%rsp)
+	vmovsd 0x0(%r13),%xmm3
+	vmovsd %xmm3,0x118(%rsp)
+	jmp    9c40 <_compute_highl_with_dsph._omp_fn.0+0x370>
+	nopw   0x0(%rax,%rax,1)
+	mov    %rax,0x108(%rsp)
+	mov    0xb8(%rsp),%rax
+	lea    (%r8,%rax,1),%rsi
+	mov    0xa8(%rsp),%rax
+	lea    (%r8,%rax,1),%rcx
+	jmp    b918 <_compute_highl_with_dsph._omp_fn.0+0x2048>
+	mov    0xb8(%rsp),%rax
+	lea    (%r8,%rax,1),%rsi
+	mov    0xa8(%rsp),%rax
+	lea    (%r8,%rax,1),%rcx
+	jmp    b7e5 <_compute_highl_with_dsph._omp_fn.0+0x1f15>
+	mov    %r13,%rax
+	mov    %r15,%r13
+	mov    %rax,%r15
+	vzeroupper
+	call   1070 <GOMP_barrier@plt>
+	mov    0xe0(%rsp),%rdi
+	call   1030 <free@plt>
+	mov    0x138(%rsp),%rdi
+	call   1030 <free@plt>
+	mov    %r13,%rdi
+	call   1030 <free@plt>
+	add    $0x158,%rsp
+	mov    %r15,%rdi
+	pop    %rbx
+	pop    %r12
+	pop    %r13
+	pop    %r14
+	pop    %r15
+	pop    %rbp
+	jmp    1030 <free@plt>
+	mov    $0x7,%eax
+	jmp    b15f <_compute_highl_with_dsph._omp_fn.0+0x188f>
 	inc    %eax
 	xor    %edx,%edx
-	jmp    7ed8 <cartesian_spherical_harmonics_l5._omp_fn.0+0xfa8>
+	jmp    9aa5 <_compute_highl_with_dsph._omp_fn.0+0x1d5>
+	vmovsd 0x1a87(%rip),%xmm2        
+	cmpl   $0x1,0x84(%rsp)
+	mov    0x138(%rsp),%rax
+	vmovsd %xmm2,(%rax)
+	jbe    9a65 <_compute_highl_with_dsph._omp_fn.0+0x195>
+	cmpl   $0x2,0x84(%rsp)
+	mov    0x1a66(%rip),%rcx        
+	mov    %rcx,0x10(%rax)
+	je     9a65 <_compute_highl_with_dsph._omp_fn.0+0x195>
+	jmp    9a16 <_compute_highl_with_dsph._omp_fn.0+0x146>
+	data16 cs nopw 0x0(%rax,%rax,1)
 	nopl   0x0(%rax)
 
-00000000000084f0 <compute_sph_prefactors>:
+000000000000bcc0 <compute_sph_prefactors>:
 compute_sph_prefactors():
 	push   %r15
 	push   %r14
 	vxorps %xmm3,%xmm3,%xmm3
 	xor    %edx,%edx
 	push   %r13
 	push   %r12
 	mov    %rsi,%r13
 	xor    %r12d,%r12d
 	push   %rbp
 	push   %rbx
 	vxorpd %xmm2,%xmm2,%xmm2
 	mov    $0x1,%r15d
 	sub    $0x28,%rsp
-	vmovsd 0x1014(%rip),%xmm7        
-	vmovsd 0x1014(%rip),%xmm6        
-	vmovsd 0xd64(%rip),%xmm4        
-	vmovq  0x104c(%rip),%xmm5        
+	vmovsd 0x1a24(%rip),%xmm7        
+	vmovsd 0x1a24(%rip),%xmm6        
+	vmovsd 0x1a04(%rip),%xmm4        
+	vmovq  0x1a5c(%rip),%xmm5        
 	data16 cs nopw 0x0(%rax,%rax,1)
 	nop
 	lea    0x1(%rdx,%rdx,1),%eax
 	vcvtsi2sd %rax,%xmm3,%xmm1
 	vdivsd %xmm7,%xmm1,%xmm1
 	vucomisd %xmm1,%xmm2
-	ja     86cf <compute_sph_prefactors+0x1df>
+	ja     be9f <compute_sph_prefactors+0x1df>
 	vsqrtsd %xmm1,%xmm1,%xmm0
 	vmulsd %xmm6,%xmm0,%xmm0
 	mov    %r12d,%eax
 	lea    0x1(%rdx),%ebp
 	vmovsd %xmm0,0x0(%r13,%rax,8)
 	test   %edx,%edx
-	je     85d6 <compute_sph_prefactors+0xe6>
+	je     bda6 <compute_sph_prefactors+0xe6>
 	mov    %edx,%r14d
 	mov    $0x1,%ebx
 	imul   %ebp,%r14d
-	jmp    8594 <compute_sph_prefactors+0xa4>
+	jmp    bd64 <compute_sph_prefactors+0xa4>
 	xchg   %ax,%ax
 	vucomisd %xmm1,%xmm2
-	ja     85ff <compute_sph_prefactors+0x10f>
+	ja     bdcf <compute_sph_prefactors+0x10f>
 	vsqrtsd %xmm1,%xmm1,%xmm0
 	inc    %ebx
 	vmovsd %xmm0,(%rax)
 	cmp    %ebp,%ebx
-	je     85d6 <compute_sph_prefactors+0xe6>
+	je     bda6 <compute_sph_prefactors+0xe6>
 	mov    %r15d,%eax
 	sub    %ebx,%eax
 	imul   %ebx,%eax
 	add    %r14d,%eax
 	vcvtsi2sd %rax,%xmm3,%xmm0
 	vdivsd %xmm0,%xmm4,%xmm0
 	lea    (%r12,%rbx,1),%eax
 	lea    0x0(%r13,%rax,8),%rax
 	vmulsd %xmm0,%xmm1,%xmm1
 	test   $0x1,%bl
-	je     8580 <compute_sph_prefactors+0x90>
+	je     bd50 <compute_sph_prefactors+0x90>
 	vucomisd %xmm1,%xmm2
-	ja     8667 <compute_sph_prefactors+0x177>
+	ja     be37 <compute_sph_prefactors+0x177>
 	vsqrtsd %xmm1,%xmm1,%xmm0
 	vxorpd %xmm5,%xmm0,%xmm0
 	inc    %ebx
 	vmovsd %xmm0,(%rax)
 	cmp    %ebp,%ebx
-	jne    8594 <compute_sph_prefactors+0xa4>
+	jne    bd64 <compute_sph_prefactors+0xa4>
 	lea    0x1(%r12,%rdx,1),%r12d
 	cmp    %ebp,%edi
-	jb     85f0 <compute_sph_prefactors+0x100>
+	jb     bdc0 <compute_sph_prefactors+0x100>
 	mov    %ebp,%edx
-	jmp    8540 <compute_sph_prefactors+0x50>
+	jmp    bd10 <compute_sph_prefactors+0x50>
 	cs nopw 0x0(%rax,%rax,1)
 	add    $0x28,%rsp
 	pop    %rbx
 	pop    %rbp
 	pop    %r12
 	pop    %r13
 	pop    %r14
 	pop    %r15
 	ret
 	vmovsd %xmm1,%xmm1,%xmm0
 	mov    %edi,0x1c(%rsp)
 	mov    %rax,0x10(%rsp)
 	mov    %edx,0x18(%rsp)
 	vmovsd %xmm1,0x8(%rsp)
-	call   10f0 <sqrt@plt>
+	call   1140 <sqrt@plt>
 	vxorps %xmm3,%xmm3,%xmm3
 	vxorpd %xmm2,%xmm2,%xmm2
-	mov    0xc66(%rip),%rax        
-	vmovq  0xf4e(%rip),%xmm5        
+	mov    0x1906(%rip),%rax        
+	vmovq  0x195e(%rip),%xmm5        
 	vmovsd 0x8(%rsp),%xmm1
 	mov    0x1c(%rsp),%edi
 	mov    0x18(%rsp),%edx
 	vmovq  %rax,%xmm4
-	mov    0xeec(%rip),%rax        
+	mov    0x18fc(%rip),%rax        
 	vmovq  %rax,%xmm6
-	mov    0xed8(%rip),%rax        
+	mov    0x18e8(%rip),%rax        
 	vmovq  %rax,%xmm7
 	mov    0x10(%rsp),%rax
-	jmp    858a <compute_sph_prefactors+0x9a>
+	jmp    bd5a <compute_sph_prefactors+0x9a>
 	vmovsd %xmm1,%xmm1,%xmm0
 	mov    %edi,0x1c(%rsp)
 	mov    %rax,0x10(%rsp)
 	mov    %edx,0x18(%rsp)
 	vmovsd %xmm1,0x8(%rsp)
-	call   10f0 <sqrt@plt>
+	call   1140 <sqrt@plt>
 	vxorps %xmm3,%xmm3,%xmm3
 	vxorpd %xmm2,%xmm2,%xmm2
-	mov    0xbfe(%rip),%rax        
-	vmovq  0xee6(%rip),%xmm5        
+	mov    0x189e(%rip),%rax        
+	vmovq  0x18f6(%rip),%xmm5        
 	vmovsd 0x8(%rsp),%xmm1
 	mov    0x1c(%rsp),%edi
 	mov    0x18(%rsp),%edx
 	vmovq  %rax,%xmm4
-	mov    0xe84(%rip),%rax        
+	mov    0x1894(%rip),%rax        
 	vmovq  %rax,%xmm6
-	mov    0xe70(%rip),%rax        
+	mov    0x1880(%rip),%rax        
 	vmovq  %rax,%xmm7
 	mov    0x10(%rsp),%rax
-	jmp    85c8 <compute_sph_prefactors+0xd8>
+	jmp    bd98 <compute_sph_prefactors+0xd8>
 	vmovsd %xmm1,%xmm1,%xmm0
 	mov    %edi,0x10(%rsp)
 	mov    %edx,0x18(%rsp)
 	vmovsd %xmm1,0x8(%rsp)
-	call   10f0 <sqrt@plt>
-	mov    0xba3(%rip),%rax        
+	call   1140 <sqrt@plt>
+	mov    0x1843(%rip),%rax        
 	vxorps %xmm3,%xmm3,%xmm3
 	vxorpd %xmm2,%xmm2,%xmm2
-	vmovq  0xe83(%rip),%xmm5        
+	vmovq  0x1893(%rip),%xmm5        
 	vmovsd 0x8(%rsp),%xmm1
 	mov    0x10(%rsp),%edi
 	mov    0x18(%rsp),%edx
 	vmovq  %rax,%xmm4
-	mov    0xe21(%rip),%rax        
+	mov    0x1831(%rip),%rax        
 	vmovq  %rax,%xmm6
-	mov    0xe0d(%rip),%rax        
+	mov    0x181d(%rip),%rax        
 	vmovq  %rax,%xmm7
-	jmp    855b <compute_sph_prefactors+0x6b>
+	jmp    bd2b <compute_sph_prefactors+0x6b>
 	nopl   (%rax)
 
-0000000000008730 <cartesian_spherical_harmonics_l0>:
+000000000000bf00 <cartesian_spherical_harmonics_l0>:
 cartesian_spherical_harmonics_l0():
 	sub    $0x28,%rsp
 	vmovq  %rdx,%xmm1
 	xor    %edx,%edx
 	vpinsrq $0x1,%rcx,%xmm1,%xmm0
 	mov    %edi,0x10(%rsp)
 	mov    %rsp,%rsi
 	xor    %ecx,%ecx
-	lea    -0x7571(%rip),%rdi        
+	lea    -0xacf1(%rip),%rdi        
 	vmovdqa %xmm0,(%rsp)
-	call   1100 <GOMP_parallel@plt>
+	call   1150 <GOMP_parallel@plt>
 	add    $0x28,%rsp
 	ret
 
-0000000000008760 <cartesian_spherical_harmonics_l1>:
+000000000000bf30 <cartesian_spherical_harmonics_l1>:
 cartesian_spherical_harmonics_l1():
 	sub    $0x28,%rsp
 	vmovq  %rsi,%xmm1
 	mov    %rcx,0x10(%rsp)
 	vpinsrq $0x1,%rdx,%xmm1,%xmm0
 	mov    %edi,0x18(%rsp)
 	mov    %rsp,%rsi
 	xor    %ecx,%ecx
 	xor    %edx,%edx
-	lea    -0x7366(%rip),%rdi        
+	lea    -0xaae6(%rip),%rdi        
 	vmovdqa %xmm0,(%rsp)
-	call   1100 <GOMP_parallel@plt>
+	call   1150 <GOMP_parallel@plt>
 	add    $0x28,%rsp
 	ret
 	data16 cs nopw 0x0(%rax,%rax,1)
 
-00000000000087a0 <cartesian_spherical_harmonics_l2>:
+000000000000bf70 <cartesian_spherical_harmonics_l2>:
 cartesian_spherical_harmonics_l2():
 	sub    $0x28,%rsp
 	vmovq  %rsi,%xmm1
 	mov    %rcx,0x10(%rsp)
 	vpinsrq $0x1,%rdx,%xmm1,%xmm0
 	mov    %edi,0x18(%rsp)
 	mov    %rsp,%rsi
 	xor    %ecx,%ecx
 	xor    %edx,%edx
-	lea    -0x6a76(%rip),%rdi        
+	lea    -0xa206(%rip),%rdi        
 	vmovdqa %xmm0,(%rsp)
-	call   1100 <GOMP_parallel@plt>
+	call   1150 <GOMP_parallel@plt>
 	add    $0x28,%rsp
 	ret
 	data16 cs nopw 0x0(%rax,%rax,1)
 
-00000000000087e0 <cartesian_spherical_harmonics_l3>:
+000000000000bfb0 <cartesian_spherical_harmonics_l3>:
 cartesian_spherical_harmonics_l3():
 	sub    $0x28,%rsp
 	vmovq  %rsi,%xmm1
 	mov    %rcx,0x10(%rsp)
 	vpinsrq $0x1,%rdx,%xmm1,%xmm0
 	mov    %edi,0x18(%rsp)
 	mov    %rsp,%rsi
 	xor    %ecx,%ecx
 	xor    %edx,%edx
-	lea    -0x5916(%rip),%rdi        
+	lea    -0x9e96(%rip),%rdi        
 	vmovdqa %xmm0,(%rsp)
-	call   1100 <GOMP_parallel@plt>
+	call   1150 <GOMP_parallel@plt>
 	add    $0x28,%rsp
 	ret
 	data16 cs nopw 0x0(%rax,%rax,1)
 
-0000000000008820 <cartesian_spherical_harmonics_l4>:
+000000000000bff0 <cartesian_spherical_harmonics_l4>:
 cartesian_spherical_harmonics_l4():
 	sub    $0x28,%rsp
 	vmovq  %rsi,%xmm1
 	mov    %rcx,0x10(%rsp)
 	vpinsrq $0x1,%rdx,%xmm1,%xmm0
 	mov    %edi,0x18(%rsp)
 	mov    %rsp,%rsi
 	xor    %ecx,%ecx
 	xor    %edx,%edx
-	lea    -0x2676(%rip),%rdi        
+	lea    -0x8b96(%rip),%rdi        
 	vmovdqa %xmm0,(%rsp)
-	call   1100 <GOMP_parallel@plt>
+	call   1150 <GOMP_parallel@plt>
 	add    $0x28,%rsp
 	ret
 	data16 cs nopw 0x0(%rax,%rax,1)
 
-0000000000008860 <cartesian_spherical_harmonics_l5>:
+000000000000c030 <cartesian_spherical_harmonics_l5>:
 cartesian_spherical_harmonics_l5():
 	sub    $0x28,%rsp
 	vmovq  %rsi,%xmm1
 	mov    %rcx,0x10(%rsp)
 	vpinsrq $0x1,%rdx,%xmm1,%xmm0
 	mov    %edi,0x18(%rsp)
 	mov    %rsp,%rsi
 	xor    %ecx,%ecx
 	xor    %edx,%edx
-	lea    -0x1956(%rip),%rdi        
+	lea    -0x7eb6(%rip),%rdi        
 	vmovdqa %xmm0,(%rsp)
-	call   1100 <GOMP_parallel@plt>
+	call   1150 <GOMP_parallel@plt>
 	add    $0x28,%rsp
 	ret
 	data16 cs nopw 0x0(%rax,%rax,1)
 
-00000000000088a0 <cartesian_spherical_harmonics_generic>:
-cartesian_spherical_harmonics_generic():
+000000000000c070 <cartesian_spherical_harmonics_l6>:
+cartesian_spherical_harmonics_l6():
+	sub    $0x28,%rsp
+	vmovq  %rsi,%xmm1
+	mov    %rcx,0x10(%rsp)
+	vpinsrq $0x1,%rdx,%xmm1,%xmm0
+	mov    %edi,0x18(%rsp)
+	mov    %rsp,%rsi
+	xor    %ecx,%ecx
+	xor    %edx,%edx
+	lea    -0x69c6(%rip),%rdi        
+	vmovdqa %xmm0,(%rsp)
+	call   1150 <GOMP_parallel@plt>
+	add    $0x28,%rsp
+	ret
+	data16 cs nopw 0x0(%rax,%rax,1)
+
+000000000000c0b0 <_compute_no_dsph>:
+_compute_no_dsph():
+	vmovq  %rdx,%xmm1
+	sub    $0x28,%rsp
+	vmovd  %edi,%xmm2
+	xor    %edx,%edx
+	vpinsrq $0x1,%rcx,%xmm1,%xmm0
+	lea    -0x494c(%rip),%rdi        
+	xor    %ecx,%ecx
+	mov    %r8,0x10(%rsp)
+	vmovdqa %xmm0,(%rsp)
+	vpinsrd $0x1,%esi,%xmm2,%xmm0
+	mov    %rsp,%rsi
+	vmovq  %xmm0,0x18(%rsp)
+	call   1150 <GOMP_parallel@plt>
+	add    $0x28,%rsp
+	ret
+	data16 cs nopw 0x0(%rax,%rax,1)
+	nopl   0x0(%rax)
+
+000000000000c100 <_compute_with_dsph>:
+_compute_with_dsph():
 	push   %rbp
 	vmovq  %rdx,%xmm3
 	vmovq  %r8,%xmm2
 	vmovd  %edi,%xmm4
 	mov    %rsp,%rbp
 	vpinsrq $0x1,%rcx,%xmm3,%xmm0
 	and    $0xffffffffffffffe0,%rsp
 	vpinsrq $0x1,%r9,%xmm2,%xmm1
 	sub    $0x40,%rsp
 	vinserti128 $0x1,%xmm1,%ymm0,%ymm0
 	xor    %ecx,%ecx
 	xor    %edx,%edx
 	vmovdqa %ymm0,(%rsp)
-	lea    -0x67dc(%rip),%rdi        
+	lea    -0x438c(%rip),%rdi        
 	vpinsrd $0x1,%esi,%xmm4,%xmm0
 	mov    %rsp,%rsi
 	vmovq  %xmm0,0x20(%rsp)
 	vzeroupper
-	call   1100 <GOMP_parallel@plt>
+	call   1150 <GOMP_parallel@plt>
 	leave
 	ret
 	data16 cs nopw 0x0(%rax,%rax,1)
 
-0000000000008900 <cartesian_spherical_harmonics>:
-cartesian_spherical_harmonics():
-	mov    %rdx,%rax
-	mov    %rcx,%r10
-	mov    %r8,%rdx
-	mov    %r9,%rcx
-	cmp    $0x5,%esi
-	ja     8940 <cartesian_spherical_harmonics+0x40>
-	je     89c0 <cartesian_spherical_harmonics+0xc0>
-	cmp    $0x4,%esi
-	je     89a0 <cartesian_spherical_harmonics+0xa0>
-	cmp    $0x3,%esi
-	je     89d0 <cartesian_spherical_harmonics+0xd0>
-	cmp    $0x2,%esi
-	je     89e0 <cartesian_spherical_harmonics+0xe0>
-	cmp    $0x1,%esi
-	mov    %r10,%rsi
-	je     89b0 <cartesian_spherical_harmonics+0xb0>
-	jmp    10c0 <cartesian_spherical_harmonics_l0@plt>
-	nop
+000000000000c160 <cartesian_spherical_harmonics_generic>:
+cartesian_spherical_harmonics_generic():
+	test   %r9,%r9
+	je     c170 <cartesian_spherical_harmonics_generic+0x10>
+	jmp    10a0 <_compute_with_dsph@plt>
+	nopw   0x0(%rax,%rax,1)
+	jmp    10b0 <_compute_no_dsph@plt>
+	data16 cs nopw 0x0(%rax,%rax,1)
+
+000000000000c180 <_compute_highl_no_dsph>:
+_compute_highl_no_dsph():
+	vmovq  %rdx,%xmm1
+	sub    $0x28,%rsp
+	vmovd  %edi,%xmm2
+	xor    %edx,%edx
+	vpinsrq $0x1,%rcx,%xmm1,%xmm0
+	lea    -0x37cc(%rip),%rdi        
+	xor    %ecx,%ecx
+	mov    %r8,0x10(%rsp)
+	vmovdqa %xmm0,(%rsp)
+	vpinsrd $0x1,%esi,%xmm2,%xmm0
+	mov    %rsp,%rsi
+	vmovq  %xmm0,0x18(%rsp)
+	call   1150 <GOMP_parallel@plt>
+	add    $0x28,%rsp
+	ret
+	data16 cs nopw 0x0(%rax,%rax,1)
+	nopl   0x0(%rax)
+
+000000000000c1d0 <_compute_highl_with_dsph>:
+_compute_highl_with_dsph():
 	push   %rbp
+	vmovq  %rdx,%xmm3
 	vmovq  %r8,%xmm2
-	vmovq  %rax,%xmm3
 	vmovd  %edi,%xmm4
 	mov    %rsp,%rbp
-	vpinsrq $0x1,%r9,%xmm2,%xmm0
+	vpinsrq $0x1,%rcx,%xmm3,%xmm0
 	and    $0xffffffffffffffe0,%rsp
-	vpinsrq $0x1,%r10,%xmm3,%xmm1
+	vpinsrq $0x1,%r9,%xmm2,%xmm1
 	sub    $0x40,%rsp
-	vinserti128 $0x1,%xmm0,%ymm1,%ymm0
+	vinserti128 $0x1,%xmm1,%ymm0,%ymm0
 	xor    %ecx,%ecx
 	xor    %edx,%edx
 	vmovdqa %ymm0,(%rsp)
-	lea    -0x470c(%rip),%rdi        
+	lea    -0x293c(%rip),%rdi        
 	vpinsrd $0x1,%esi,%xmm4,%xmm0
 	mov    %rsp,%rsi
 	vmovq  %xmm0,0x20(%rsp)
 	vzeroupper
-	call   1100 <GOMP_parallel@plt>
+	call   1150 <GOMP_parallel@plt>
 	leave
 	ret
 	data16 cs nopw 0x0(%rax,%rax,1)
+
+000000000000c230 <cartesian_spherical_harmonics>:
+cartesian_spherical_harmonics():
+	mov    %rcx,%r10
+	cmp    $0x6,%esi
+	ja     c270 <cartesian_spherical_harmonics+0x40>
+	mov    %r9,%rcx
+	mov    %r8,%rdx
+	je     c280 <cartesian_spherical_harmonics+0x50>
+	cmp    $0x5,%esi
+	je     c2a0 <cartesian_spherical_harmonics+0x70>
+	cmp    $0x4,%esi
+	je     c2b0 <cartesian_spherical_harmonics+0x80>
+	cmp    $0x3,%esi
+	je     c2d0 <cartesian_spherical_harmonics+0xa0>
+	cmp    $0x2,%esi
+	je     c2e0 <cartesian_spherical_harmonics+0xb0>
+	cmp    $0x1,%esi
 	mov    %r10,%rsi
-	jmp    10e0 <cartesian_spherical_harmonics_l4@plt>
+	je     c2c0 <cartesian_spherical_harmonics+0x90>
+	jmp    1100 <cartesian_spherical_harmonics_l0@plt>
+	nopl   0x0(%rax)
+	test   %r9,%r9
+	je     c290 <cartesian_spherical_harmonics+0x60>
+	jmp    10f0 <_compute_highl_with_dsph@plt>
+	nopw   0x0(%rax,%rax,1)
+	mov    %r10,%rsi
+	jmp    1130 <cartesian_spherical_harmonics_l6@plt>
 	nopl   0x0(%rax,%rax,1)
-	jmp    1040 <cartesian_spherical_harmonics_l1@plt>
+	jmp    10d0 <_compute_highl_no_dsph@plt>
 	data16 cs nopw 0x0(%rax,%rax,1)
 	mov    %r10,%rsi
 	jmp    1060 <cartesian_spherical_harmonics_l5@plt>
 	nopl   0x0(%rax,%rax,1)
 	mov    %r10,%rsi
+	jmp    1120 <cartesian_spherical_harmonics_l4@plt>
+	nopl   0x0(%rax,%rax,1)
+	jmp    1040 <cartesian_spherical_harmonics_l1@plt>
+	data16 cs nopw 0x0(%rax,%rax,1)
+	mov    %r10,%rsi
 	jmp    1050 <cartesian_spherical_harmonics_l3@plt>
 	nopl   0x0(%rax,%rax,1)
 	mov    %r10,%rsi
-	jmp    10d0 <cartesian_spherical_harmonics_l2@plt>
+	jmp    1110 <cartesian_spherical_harmonics_l2@plt>
```

### objdump --line-numbers --disassemble --demangle --reloc --no-show-raw-insn --section=.fini {}

```diff
@@ -1,10 +1,10 @@
 
 
 
 Disassembly of section .fini:
 
-00000000000089e8 <_fini>:
+000000000000c2e8 <_fini>:
 _fini():
 	sub    $0x8,%rsp
 	add    $0x8,%rsp
 	ret
```

### readelf --wide --decompress --hex-dump=.rodata {}

```diff
@@ -1,105 +1,135 @@
 
 Hex dump of section '.rodata':
-  0x00009000 6a9b4250 d70dd23f 6a9b4250 d70dd23f j.BP...?j.BP...?
-  0x00009010 6a9b4250 d70dd23f 6a9b4250 d70dd23f j.BP...?j.BP...?
-  0x00009020 9b745778 4345df3f 9b745778 4345df3f .tWxCE.?.tWxCE.?
-  0x00009030 9b745778 4345df3f 9b745778 4345df3f .tWxCE.?.tWxCE.?
-  0x00009040 00000000 00000000 00000000 00000000 ................
-  0x00009050 00000000 00000000 9b745778 4345df3f .........tWxCE.?
-  0x00009060 00000000 00000000 9b745778 4345df3f .........tWxCE.?
-  0x00009070 00000000 00000000 00000000 00000000 ................
-  0x00009080 00000000 00000000 00000000 00000000 ................
-  0x00009090 9b745778 4345df3f 00000000 00000000 .tWxCE.?........
-  0x000090a0 a8f4979b 77e30140 a8f4979b 77e30140 ....w..@....w..@
-  0x000090b0 a8f4979b 77e30140 a8f4979b 77e30140 ....w..@....w..@
-  0x000090c0 00000000 00000040 00000000 00000040 .......@.......@
-  0x000090d0 00000000 00000040 00000000 00000040 .......@.......@
-  0x000090e0 9a678c1a 602fd4bf 9a678c1a 602fd4bf .g..`/...g..`/..
-  0x000090f0 9a678c1a 602fd4bf 9a678c1a 602fd4bf .g..`/...g..`/..
-  0x00009100 98062b10 147be13f 98062b10 147be13f ..+..{.?..+..{.?
-  0x00009110 98062b10 147be13f 98062b10 147be13f ..+..{.?..+..{.?
-  0x00009120 00000000 00000840 00000000 00000840 .......@.......@
-  0x00009130 00000000 00000840 00000000 00000840 .......@.......@
-  0x00009140 1b613e18 a3e1e2bf 1b613e18 a3e1e2bf .a>......a>.....
-  0x00009150 1b613e18 a3e1e2bf 1b613e18 a3e1e2bf .a>......a>.....
-  0x00009160 e8f8d2a9 7f2a0540 e8f8d2a9 7f2a0540 .....*.@.....*.@
-  0x00009170 e8f8d2a9 7f2a0540 e8f8d2a9 7f2a0540 .....*.@.....*.@
-  0x00009180 00000000 00001040 00000000 00001040 .......@.......@
-  0x00009190 00000000 00001040 00000000 00001040 .......@.......@
-  0x000091a0 ee565e06 3d40ddbf ee565e06 3d40ddbf .V^.=@...V^.=@..
-  0x000091b0 ee565e06 3d40ddbf ee565e06 3d40ddbf .V^.=@...V^.=@..
-  0x000091c0 437f1ff7 22060340 437f1ff7 22060340 C..."..@C..."..@
-  0x000091d0 437f1ff7 22060340 437f1ff7 22060340 C..."..@C..."..@
-  0x000091e0 a96807fc 1ee2f7bf a96807fc 1ee2f7bf .h.......h......
-  0x000091f0 a96807fc 1ee2f7bf a96807fc 1ee2f7bf .h.......h......
-  0x00009200 3bad5ce4 f81ff73f 3bad5ce4 f81ff73f ;.\....?;.\....?
-  0x00009210 3bad5ce4 f81ff73f 3bad5ce4 f81ff73f ;.\....?;.\....?
-  0x00009220 1b613e18 a3e1e23f 1b613e18 a3e1e23f .a>....?.a>....?
-  0x00009230 1b613e18 a3e1e23f 1b613e18 a3e1e23f .a>....?.a>....?
-  0x00009240 6a9b4250 d70dd23f 9b745778 4345df3f j.BP...?.tWxCE.?
-  0x00009250 a8f4979b 77e30140 00000000 00000040 ....w..@.......@
-  0x00009260 9a678c1a 602fd4bf 98062b10 147be13f .g..`/....+..{.?
-  0x00009270 a5348acb e9a7f4bf b74c58e8 7ab6fbbf .4.......LX.z...
-  0x00009280 1e339045 a779e2bf 15339045 a779f23f .3.E.y...3.E.y.?
-  0x00009290 00000000 0000f03f 00000000 0000f0bf .......?........
-  0x000092a0 00000000 00000840 1b613e18 a3e1e2bf .......@.a>.....
-  0x000092b0 e8f8d2a9 7f2a0540 00000000 00001040 .....*.@.......@
-  0x000092c0 ee565e06 3d40ddbf 437f1ff7 22060340 .V^.=@..C..."..@
-  0x000092d0 a96807fc 1ee2f7bf 3bad5ce4 f81ff73f .h......;.\....?
-  0x000092e0 1b613e18 a3e1e23f 6412264a 47ec0940 .a>....?d.&JG..@
-  0x000092f0 20b37a3f ebc5eabf 3ba125aa 266500c0  .z?....;.%.&e..
-  0x00009300 387f1ff7 22061340 dc565e06 3d40ed3f 8..."..@.V^.=@.?
-  0x00009310 e7fe29f4 835df93f dc565e06 3d40edbf ..)..].?.V^.=@..
-  0x00009320 f3b27a3f ebc50a40 04e94ac8 ad650c40 ..z?...@..J..e.@
-  0x00009330 5bd32c87 0ec71040 00000000 00001840 [.,....@.......@
-  0x00009340 ae4c58e8 7ab6ebbf 3e2c0c70 bd20fa3f .LX.z...>,.p. .?
-  0x00009350 a30ffc1a 3d38e6bf 3c7f1ff7 22061340 ....=8..<..."..@
-  0x00009360 2e210914 8e98f3bf d86cdfcc 76f8f0bf .!.......l..v...
-  0x00009370 9a999999 9999c93f 1242812f d990d93f .......?.B./...?
-  0x00009380 c563d82d 5a412a40 346ffd93 72880a40 .c.-ZA*@4o..r..@
-  0x00009390 fda9c6a2 02e9e03f 6713feee 55e61340 .......?g...U..@
-  0x000093a0 2761a479 23081540 0f494862 133de43f 'a.y#..@.IHb.=.?
-  0x000093b0 0ae6f610 02d6f63f a759b7ac 46520c40 .......?.Y..FR.@
-  0x000093c0 d644a59d 5774f63f f8566ac9 ebc7f0bf .D..Wt.?.Vj.....
-  0x000093d0 d96cdfcc 76f81040 c5b10d1e d5640d40 .l..v..@.....d.@
-  0x000093e0 679bd227 1047fe3f c20ffc1a 3d38f6bf g..'.G.?....=8..
-  0x000093f0 c20ffc1a 3d3806c0 782b33a1 8cf70540 ....=8..x+3....@
-  0x00009400 19de7743 04141040 9a92024c d468f5bf ..wC...@...L.h..
-  0x00009410 679bd227 1047febf f9fe29f4 835df93f g..'.G....)..].?
-  0x00009420 787d4aaf 0570f53f c00fdb61 626c0f40 x}J..p.?...abl.@
-  0x00009430 759aba91 f2901140 edf9fd6c 6d241240 u......@...lm$.@
-  0x00009440 b3ecc4bb e6f91440 a7565459 fcc21240 .......@.VTY...@
-  0x00009450 e308280d 7caf0c40 bca82391 aea80c40 ..(.|..@..#....@
-  0x00009460 030ee050 36c0d33f e3d3d621 c88c21c0 ...P6..?...!..!.
-  0x00009470 3fc1832c 3ea3febf 993bb14f def70bc0 ?..,>....;.O....
-  0x00009480 ce34bb78 d5e9ca3f fda9c6a2 02e9f03f .4.x...?.......?
-  0x00009490 761cc771 1cc7e13f b41c0af9 d23b21c0 v..q...?.....;!.
-  0x000094a0 55a066d5 175ebb3f 2df80ce0 9186d43f U.f..^.?-......?
-  0x000094b0 8ff06949 cbae14c0 b6ecc4bb e6f91440 ..iI...........@
-  0x000094c0 2c2460e5 ce1ae13f 29b53c41 ecf2e43f ,$`....?).<A...?
-  0x000094d0 ab207fbe c0d108c0 e2d3d621 c88c21c0 . .........!..!.
-  0x000094e0 2afca85d 826e2040 d46cdfcc 76f80040 *..].n @.l..v..@
-  0x000094f0 fdee6369 33d51a40 6c702d2f ef28e73f ..ci3..@lp-/.(.?
-  0x00009500 e2d3d621 c88c2140 00000000 00001440 ...!..!@.......@
-  0x00009510 cdf4a862 4cb01140 5ec24749 d1431440 ...bL..@^.GI.C.@
-  0x00009520 ba4a9e9d 02aa1540 0032537b 5f1c1640 .J.....@.2S{_..@
-  0x00009530 182d4454 fb211940 cd3b7f66 9ea0e63f .-DT.!.@.;.f...?
-  0x00009540 9b745778 4345df3f 9b745778 4345df3f .tWxCE.?.tWxCE.?
-  0x00009550 6a9b4250 d70dd23f 6a9b4250 d70dd23f j.BP...?j.BP...?
-  0x00009560 00000000 00000000 9b745778 4345df3f .........tWxCE.?
-  0x00009570 9b745778 4345df3f 00000000 00000000 .tWxCE.?........
-  0x00009580 00000000 00000080 00000000 00000000 ................
-  0x00009590 a8f4979b 77e30140 a8f4979b 77e30140 ....w..@....w..@
-  0x000095a0 00000000 00000040 00000000 00000040 .......@.......@
-  0x000095b0 9a678c1a 602fd4bf 9a678c1a 602fd4bf .g..`/...g..`/..
-  0x000095c0 98062b10 147be13f 98062b10 147be13f ..+..{.?..+..{.?
-  0x000095d0 00000000 00000840 00000000 00000840 .......@.......@
-  0x000095e0 1b613e18 a3e1e2bf 1b613e18 a3e1e2bf .a>......a>.....
-  0x000095f0 e8f8d2a9 7f2a0540 e8f8d2a9 7f2a0540 .....*.@.....*.@
-  0x00009600 00000000 00001040 00000000 00001040 .......@.......@
-  0x00009610 ee565e06 3d40ddbf ee565e06 3d40ddbf .V^.=@...V^.=@..
-  0x00009620 437f1ff7 22060340 437f1ff7 22060340 C..."..@C..."..@
-  0x00009630 a96807fc 1ee2f7bf a96807fc 1ee2f7bf .h.......h......
-  0x00009640 3bad5ce4 f81ff73f 3bad5ce4 f81ff73f ;.\....?;.\....?
-  0x00009650 1b613e18 a3e1e23f 1b613e18 a3e1e23f .a>....?.a>....?
+  0x0000d000 6a9b4250 d70dd23f 6a9b4250 d70dd23f j.BP...?j.BP...?
+  0x0000d010 6a9b4250 d70dd23f 6a9b4250 d70dd23f j.BP...?j.BP...?
+  0x0000d020 9b745778 4345df3f 9b745778 4345df3f .tWxCE.?.tWxCE.?
+  0x0000d030 9b745778 4345df3f 9b745778 4345df3f .tWxCE.?.tWxCE.?
+  0x0000d040 00000000 00000000 00000000 00000000 ................
+  0x0000d050 00000000 00000000 9b745778 4345df3f .........tWxCE.?
+  0x0000d060 00000000 00000000 9b745778 4345df3f .........tWxCE.?
+  0x0000d070 00000000 00000000 00000000 00000000 ................
+  0x0000d080 00000000 00000000 00000000 00000000 ................
+  0x0000d090 9b745778 4345df3f 00000000 00000000 .tWxCE.?........
+  0x0000d0a0 a8f4979b 77e30140 a8f4979b 77e30140 ....w..@....w..@
+  0x0000d0b0 a8f4979b 77e30140 a8f4979b 77e30140 ....w..@....w..@
+  0x0000d0c0 00000000 00000040 00000000 00000040 .......@.......@
+  0x0000d0d0 00000000 00000040 00000000 00000040 .......@.......@
+  0x0000d0e0 9a678c1a 602fd4bf 9a678c1a 602fd4bf .g..`/...g..`/..
+  0x0000d0f0 9a678c1a 602fd4bf 9a678c1a 602fd4bf .g..`/...g..`/..
+  0x0000d100 98062b10 147be13f 98062b10 147be13f ..+..{.?..+..{.?
+  0x0000d110 98062b10 147be13f 98062b10 147be13f ..+..{.?..+..{.?
+  0x0000d120 00000000 00000840 00000000 00000840 .......@.......@
+  0x0000d130 00000000 00000840 00000000 00000840 .......@.......@
+  0x0000d140 1b613e18 a3e1e2bf 1b613e18 a3e1e2bf .a>......a>.....
+  0x0000d150 1b613e18 a3e1e2bf 1b613e18 a3e1e2bf .a>......a>.....
+  0x0000d160 e8f8d2a9 7f2a0540 e8f8d2a9 7f2a0540 .....*.@.....*.@
+  0x0000d170 e8f8d2a9 7f2a0540 e8f8d2a9 7f2a0540 .....*.@.....*.@
+  0x0000d180 00000000 00001040 00000000 00001040 .......@.......@
+  0x0000d190 00000000 00001040 00000000 00001040 .......@.......@
+  0x0000d1a0 ee565e06 3d40ddbf ee565e06 3d40ddbf .V^.=@...V^.=@..
+  0x0000d1b0 ee565e06 3d40ddbf ee565e06 3d40ddbf .V^.=@...V^.=@..
+  0x0000d1c0 437f1ff7 22060340 437f1ff7 22060340 C..."..@C..."..@
+  0x0000d1d0 437f1ff7 22060340 437f1ff7 22060340 C..."..@C..."..@
+  0x0000d1e0 a96807fc 1ee2f7bf a96807fc 1ee2f7bf .h.......h......
+  0x0000d1f0 a96807fc 1ee2f7bf a96807fc 1ee2f7bf .h.......h......
+  0x0000d200 3bad5ce4 f81ff73f 3bad5ce4 f81ff73f ;.\....?;.\....?
+  0x0000d210 3bad5ce4 f81ff73f 3bad5ce4 f81ff73f ;.\....?;.\....?
+  0x0000d220 1b613e18 a3e1e23f 1b613e18 a3e1e23f .a>....?.a>....?
+  0x0000d230 1b613e18 a3e1e23f 1b613e18 a3e1e23f .a>....?.a>....?
+  0x0000d240 6a9b4250 d70dd23f 9b745778 4345df3f j.BP...?.tWxCE.?
+  0x0000d250 a8f4979b 77e30140 00000000 00000040 ....w..@.......@
+  0x0000d260 9a678c1a 602fd4bf 98062b10 147be13f .g..`/....+..{.?
+  0x0000d270 a5348acb e9a7f4bf b74c58e8 7ab6fbbf .4.......LX.z...
+  0x0000d280 1e339045 a779e2bf 15339045 a779f23f .3.E.y...3.E.y.?
+  0x0000d290 00000000 00000840 1b613e18 a3e1e2bf .......@.a>.....
+  0x0000d2a0 e8f8d2a9 7f2a0540 00000000 00001040 .....*.@.......@
+  0x0000d2b0 ee565e06 3d40ddbf 437f1ff7 22060340 .V^.=@..C..."..@
+  0x0000d2c0 a96807fc 1ee2f7bf 3bad5ce4 f81ff73f .h......;.\....?
+  0x0000d2d0 1b613e18 a3e1e23f 6412264a 47ec0940 .a>....?d.&JG..@
+  0x0000d2e0 20b37a3f ebc5eabf 3ba125aa 266500c0  .z?....;.%.&e..
+  0x0000d2f0 387f1ff7 22061340 dc565e06 3d40ed3f 8..."..@.V^.=@.?
+  0x0000d300 e7fe29f4 835df93f dc565e06 3d40edbf ..)..].?.V^.=@..
+  0x0000d310 f3b27a3f ebc50a40 04e94ac8 ad650c40 ..z?...@..J..e.@
+  0x0000d320 5bd32c87 0ec71040 00000000 00001840 [.,....@.......@
+  0x0000d330 ae4c58e8 7ab6ebbf 3e2c0c70 bd20fa3f .LX.z...>,.p. .?
+  0x0000d340 a30ffc1a 3d38e6bf 3c7f1ff7 22061340 ....=8..<..."..@
+  0x0000d350 2e210914 8e98f3bf d86cdfcc 76f8f0bf .!.......l..v...
+  0x0000d360 d96cdfcc 76f81040 c5b10d1e d5640d40 .l..v..@.....d.@
+  0x0000d370 679bd227 1047fe3f c20ffc1a 3d38f6bf g..'.G.?....=8..
+  0x0000d380 c20ffc1a 3d3806c0 782b33a1 8cf70540 ....=8..x+3....@
+  0x0000d390 19de7743 04141040 9a92024c d468f5bf ..wC...@...L.h..
+  0x0000d3a0 679bd227 1047febf f9fe29f4 835df93f g..'.G....)..].?
+  0x0000d3b0 787d4aaf 0570f53f c00fdb61 626c0f40 x}J..p.?...abl.@
+  0x0000d3c0 759aba91 f2901140 edf9fd6c 6d241240 u......@...lm$.@
+  0x0000d3d0 9a999999 9999c93f 1242812f d990d93f .......?.B./...?
+  0x0000d3e0 c563d82d 5a412a40 346ffd93 72880a40 .c.-ZA*@4o..r..@
+  0x0000d3f0 fda9c6a2 02e9e03f 6713feee 55e61340 .......?g...U..@
+  0x0000d400 2761a479 23081540 0f494862 133de43f 'a.y#..@.IHb.=.?
+  0x0000d410 0ae6f610 02d6f63f a759b7ac 46520c40 .......?.Y..FR.@
+  0x0000d420 d644a59d 5774f63f f8566ac9 ebc7f0bf .D..Wt.?.Vj.....
+  0x0000d430 b3ecc4bb e6f91440 a7565459 fcc21240 .......@.VTY...@
+  0x0000d440 e308280d 7caf0c40 bca82391 aea80c40 ..(.|..@..#....@
+  0x0000d450 030ee050 36c0d33f e3d3d621 c88c21c0 ...P6..?...!..!.
+  0x0000d460 3fc1832c 3ea3febf 993bb14f def70bc0 ?..,>....;.O....
+  0x0000d470 ce34bb78 d5e9ca3f fda9c6a2 02e9f03f .4.x...?.......?
+  0x0000d480 761cc771 1cc7e13f b41c0af9 d23b21c0 v..q...?.....;!.
+  0x0000d490 55a066d5 175ebb3f 2df80ce0 9186d43f U.f..^.?-......?
+  0x0000d4a0 8ff06949 cbae14c0 b6ecc4bb e6f91440 ..iI...........@
+  0x0000d4b0 2c2460e5 ce1ae13f 29b53c41 ecf2e43f ,$`....?).<A...?
+  0x0000d4c0 ab207fbe c0d108c0 e2d3d621 c88c21c0 . .........!..!.
+  0x0000d4d0 2afca85d 826e2040 d46cdfcc 76f80040 *..].n @.l..v..@
+  0x0000d4e0 fdee6369 33d51a40 6c702d2f ef28e73f ..ci3..@lp-/.(.?
+  0x0000d4f0 e2d3d621 c88c2140 00000000 00001440 ...!..!@.......@
+  0x0000d500 cdf4a862 4cb01140 5ec24749 d1431440 ...bL..@^.GI.C.@
+  0x0000d510 ba4a9e9d 02aa1540 0032537b 5f1c1640 .J.....@.2S{_..@
+  0x0000d520 10609960 a8650f40 f3596144 2bd80c40 .`.`.e.@.YaD+..@
+  0x0000d530 f9fe29f4 835dd93f 54c402ff 99cc1940 ..)..].?T......@
+  0x0000d540 c237e780 40a7f03f e6f7a7e6 9130d83f .7..@..?.....0.?
+  0x0000d550 fa0c9eaa 3b450040 66732d38 52c11040 ....;E.@fs-8R..@
+  0x0000d560 008099c9 cc9819c0 93348acb e9a7e43f .........4.....?
+  0x0000d570 770dde4a d264f1bf 352c0c70 bd20fa3f w..J.d..5,.p. .?
+  0x0000d580 8ab6c353 8320eebf b037e780 40a7f0bf ...S. ...7..@...
+  0x0000d590 8ad35ac1 e0fa1840 eb12b2bb b2cd1640 ..Z....@.......@
+  0x0000d5a0 7b54784b 43230540 05dc6a4a 652520c0 {TxKC#.@..jJe% .
+  0x0000d5b0 de3abce9 21b6d03f ef479b0e 18982ec0 .:..!..?.G......
+  0x0000d5c0 1e339045 a779e23f ca08e46a c54ed73f .3.E.y.?...j.N.?
+  0x0000d5d0 c4a9395e 6849d43f b580afc0 5b0a4040 ..9^hI.?....[.@@
+  0x0000d5e0 301014de 677203c0 af187f03 6dd710c0 0...gr......m...
+  0x0000d5f0 acaaaaaa aaaafa3f c10d919d c9edf33f .......?.......?
+  0x0000d600 0dd4189d 8b80fc3f 53013f8e d5a41240 .......?S.?....@
+  0x0000d610 ea5ad978 3348d23f 1fa2d073 837a2d40 .Z.x3H.?...s.z-@
+  0x0000d620 2e210914 8e98f33f a14ea9bf bd8afd3f .!.....?.N.....?
+  0x0000d630 8ad35ac1 e0fa0840 cc3b7f66 9ea0f63f ..Z....@.;.f...?
+  0x0000d640 207021dc 79c01840 81c402ff 99ccf93f  p!.y..@.......?
+  0x0000d650 1ba06b3d 51801040 33210914 8e98f3bf ..k=Q..@3!......
+  0x0000d660 b2c8980c a5b9f13f 8ad35ac1 e0fa08c0 .......?..Z.....
+  0x0000d670 f9fe29f4 835df9bf d0a3a537 2d48c63f ..)..].....7-H.?
+  0x0000d680 4991fa4e dc5d2740 7654784b 43231540 I..N.]'@vTxKC#.@
+  0x0000d690 00825e55 40f71bc0 1009280d 7cafdc3f ..^U@.....(.|..?
+  0x0000d6a0 605bc508 a81fc3bf 605bc508 a81fe33f `[......`[.....?
+  0x0000d6b0 2d0032f4 41fb2a40 f1479b0e 18981e40 -.2.A.*@.G.....@
+  0x0000d6c0 c5ce63c0 d135ce3f da5406ac 6f42c13f ..c..5.?.T..oB.?
+  0x0000d6d0 eb12b2bb b2cd2640 2f1014de 67721340 ......&@/...gr.@
+  0x0000d6e0 e7c8d27e 62981640 41b0e790 3d991840 ...~b..@A...=..@
+  0x0000d6f0 e191a2ce cfb91940 35144d70 3b171a40 .......@5.Mp;..@
+  0x0000d700 00000000 0000f03f 00000000 0000f0bf .......?........
+  0x0000d710 182d4454 fb211940 cd3b7f66 9ea0e63f .-DT.!.@.;.f...?
+  0x0000d720 9b745778 4345df3f 9b745778 4345df3f .tWxCE.?.tWxCE.?
+  0x0000d730 6a9b4250 d70dd23f 6a9b4250 d70dd23f j.BP...?j.BP...?
+  0x0000d740 00000000 00000000 9b745778 4345df3f .........tWxCE.?
+  0x0000d750 9b745778 4345df3f 00000000 00000000 .tWxCE.?........
+  0x0000d760 00000000 00000080 00000000 00000000 ................
+  0x0000d770 a8f4979b 77e30140 a8f4979b 77e30140 ....w..@....w..@
+  0x0000d780 00000000 00000040 00000000 00000040 .......@.......@
+  0x0000d790 9a678c1a 602fd4bf 9a678c1a 602fd4bf .g..`/...g..`/..
+  0x0000d7a0 98062b10 147be13f 98062b10 147be13f ..+..{.?..+..{.?
+  0x0000d7b0 00000000 00000840 00000000 00000840 .......@.......@
+  0x0000d7c0 1b613e18 a3e1e2bf 1b613e18 a3e1e2bf .a>......a>.....
+  0x0000d7d0 e8f8d2a9 7f2a0540 e8f8d2a9 7f2a0540 .....*.@.....*.@
+  0x0000d7e0 00000000 00001040 00000000 00001040 .......@.......@
+  0x0000d7f0 ee565e06 3d40ddbf ee565e06 3d40ddbf .V^.=@...V^.=@..
+  0x0000d800 437f1ff7 22060340 437f1ff7 22060340 C..."..@C..."..@
+  0x0000d810 a96807fc 1ee2f7bf a96807fc 1ee2f7bf .h.......h......
+  0x0000d820 3bad5ce4 f81ff73f 3bad5ce4 f81ff73f ;.\....?;.\....?
+  0x0000d830 1b613e18 a3e1e23f 1b613e18 a3e1e23f .a>....?.a>....?
```

### readelf --wide --decompress --hex-dump=.eh_frame_hdr {}

```diff
@@ -1,13 +1,17 @@
 
 Hex dump of section '.eh_frame_hdr':
-  0x00009660 011b033b 9c000000 12000000 c079ffff ...;.........y..
-  0x00009670 b8000000 807bffff e0000000 c07dffff .....{.......}..
-  0x00009680 0c010000 f086ffff 4c010000 a08affff ........L.......
-  0x00009690 84010000 9098ffff b4010000 10acffff ................
-  0x000096a0 ec010000 70cbffff 1c020000 d0d8ffff ....p...........
-  0x000096b0 4c020000 90eeffff 7c020000 d0f0ffff L.......|.......
-  0x000096c0 c8020000 00f1ffff e0020000 40f1ffff ............@...
-  0x000096d0 f8020000 80f1ffff 10030000 c0f1ffff ................
-  0x000096e0 28030000 00f2ffff 40030000 40f2ffff (.......@...@...
-  0x000096f0 58030000 a0f2ffff 78030000          X.......x...
+  0x0000d840 011b033b dc000000 1a000000 e037ffff ...;.........7..
+  0x0000d850 f8000000 f039ffff 20010000 303cffff .....9.. ...0<..
+  0x0000d860 4c010000 5045ffff 8c010000 0049ffff L...PE.......I..
+  0x0000d870 c4010000 405cffff fc010000 6069ffff ....@\......`i..
+  0x0000d880 2c020000 907effff 5c020000 409fffff ,....~..\...@...
+  0x0000d890 8c020000 70a5ffff dc020000 90b1ffff ....p...........
+  0x0000d8a0 2c030000 90c0ffff 7c030000 80e4ffff ,.......|.......
+  0x0000d8b0 ac030000 c0e6ffff f8030000 f0e6ffff ................
+  0x0000d8c0 10040000 30e7ffff 28040000 70e7ffff ....0...(...p...
+  0x0000d8d0 40040000 b0e7ffff 58040000 f0e7ffff @.......X.......
+  0x0000d8e0 70040000 30e8ffff 88040000 70e8ffff p...0.......p...
+  0x0000d8f0 a0040000 c0e8ffff b8040000 20e9ffff ............ ...
+  0x0000d900 d8040000 40e9ffff ec040000 90e9ffff ....@...........
+  0x0000d910 04050000 f0e9ffff 24050000          ........$...
```

### readelf --wide --decompress --hex-dump=.eh_frame {}

```diff
@@ -1,51 +1,73 @@
 
 Hex dump of section '.eh_frame':
-  0x00009700 14000000 00000000 017a5200 01781001 .........zR..x..
-  0x00009710 1b0c0708 90010000 24000000 1c000000 ........$.......
-  0x00009720 0079ffff 00010000 000e1046 0e184a0f .y.........F..J.
-  0x00009730 0b770880 003f1a3b 2a332422 00000000 .w...?.;*3$"....
-  0x00009740 28000000 44000000 987affff 38020000 (...D....z..8...
-  0x00009750 00410e10 8602430d 06448d03 8c044883 .A....C..D....H.
-  0x00009760 05031e01 0a0c0708 420b0000 3c000000 ........B...<...
-  0x00009770 70000000 ac7cffff 2e090000 00410e10 p....|.......A..
-  0x00009780 8602430d 06448f03 8e04508d 058c0683 ..C..D....P.....
-  0x00009790 0703e304 0a0c0708 450b02aa 0a0c0708 ........E.......
-  0x000097a0 460b03c0 020a0c07 08500b00 34000000 F........P..4...
-  0x000097b0 b0000000 9c85ffff a9030000 00410e10 .............A..
-  0x000097c0 8602430d 06448f03 8e044c8d 058c0683 ..C..D....L.....
-  0x000097d0 07035602 0a0c0708 460b031a 010a0c07 ..V.....F.......
-  0x000097e0 08460b00 2c000000 e8000000 1489ffff .F..,...........
-  0x000097f0 e20d0000 00410e10 8602430d 06548f03 .....A....C..T..
-  0x00009800 8e048d05 8c068307 03ca060a 0c07084e ...............N
-  0x00009810 0b000000 34000000 18010000 d496ffff ....4...........
-  0x00009820 80130000 00410e10 8602430d 06448f03 .....A....C..D..
-  0x00009830 8e04538d 058c0683 07030e05 0a0c0708 ..S.............
-  0x00009840 470b0303 0c0a0c07 084d0b00 2c000000 G........M..,...
-  0x00009850 50010000 1caaffff 5c1f0000 00410e10 P.......\....A..
-  0x00009860 8602430d 06548f03 8e048d05 8c068307 ..C..T..........
-  0x00009870 03e41e0a 0c070845 0b000000 2c000000 .......E....,...
-  0x00009880 80010000 4cc9ffff 590d0000 00410e10 ....L...Y....A..
-  0x00009890 8602430d 06448f03 8e044f8d 058c0683 ..C..D....O.....
-  0x000098a0 07033b09 0a0c0708 4e0b0000 2c000000 ..;.....N...,...
-  0x000098b0 b0010000 7cd6ffff b9150000 00410e10 ....|........A..
-  0x000098c0 8602430d 06448f03 8e044f8d 058c0683 ..C..D....O.....
-  0x000098d0 0703850f 0a0c0708 440b0000 48000000 ........D...H...
-  0x000098e0 e0010000 0cecffff 3d020000 00420e10 ........=....B..
-  0x000098f0 8f02420e 188e0348 0e208d04 420e288c ..B....H. ..B.(.
-  0x00009900 05470e30 8606410e 3883074e 0e6002e0 .G.0..A.8..N.`..
-  0x00009910 0a0e3841 0e30410e 28420e20 420e1842 ..8A.0A.(B. B..B
-  0x00009920 0e10420e 08410b00 14000000 2c020000 ..B..A......,...
-  0x00009930 00eeffff 30000000 00440e30 6b0e0800 ....0....D.0k...
-  0x00009940 14000000 44020000 18eeffff 35000000 ....D.......5...
-  0x00009950 00440e30 700e0800 14000000 5c020000 .D.0p.......\...
-  0x00009960 40eeffff 35000000 00440e30 700e0800 @...5....D.0p...
-  0x00009970 14000000 74020000 68eeffff 35000000 ....t...h...5...
-  0x00009980 00440e30 700e0800 14000000 8c020000 .D.0p...........
-  0x00009990 90eeffff 35000000 00440e30 700e0800 ....5....D.0p...
-  0x000099a0 14000000 a4020000 b8eeffff 35000000 ............5...
-  0x000099b0 00440e30 700e0800 1c000000 bc020000 .D.0p...........
-  0x000099c0 e0eeffff 55000000 00410e10 8602510d ....U....A....Q.
-  0x000099d0 0602420c 07080000 20000000 dc020000 ..B..... .......
-  0x000099e0 20efffff e8000000 0002410e 10860251  .........A....Q
-  0x000099f0 0d060242 0c07084c c6000000 00000000 ...B...L........
+  0x0000d920 14000000 00000000 017a5200 01781001 .........zR..x..
+  0x0000d930 1b0c0708 90010000 24000000 1c000000 ........$.......
+  0x0000d940 e036ffff 50010000 000e1046 0e184a0f .6..P......F..J.
+  0x0000d950 0b770880 003f1a3b 2a332422 00000000 .w...?.;*3$"....
+  0x0000d960 28000000 44000000 c838ffff 38020000 (...D....8..8...
+  0x0000d970 00410e10 8602430d 06448d03 8c044883 .A....C..D....H.
+  0x0000d980 05031e01 0a0c0708 420b0000 3c000000 ........B...<...
+  0x0000d990 70000000 dc3affff 18090000 00410e10 p....:.......A..
+  0x0000d9a0 8602430d 06448f03 8e04508d 058c0683 ..C..D....P.....
+  0x0000d9b0 0703d904 0a0c0708 4f0b02a3 0a0c0708 ........O.......
+  0x0000d9c0 4d0b03b7 020a0c07 08490b00 34000000 M........I..4...
+  0x0000d9d0 b0000000 bc43ffff a9030000 00410e10 .....C.......A..
+  0x0000d9e0 8602430d 06448f03 8e044c8d 058c0683 ..C..D....L.....
+  0x0000d9f0 07034f02 0a0c0708 4d0b0310 010a0c07 ..O.....M.......
+  0x0000da00 08500b00 34000000 e8000000 3447ffff .P..4.......4G..
+  0x0000da10 39130000 00410e10 8602430d 06448f03 9....A....C..D..
+  0x0000da20 8e04538d 058c0683 0703f904 0a0c0708 ..S.............
+  0x0000da30 4c0b03e5 0b0a0c07 084b0b00 2c000000 L........K..,...
+  0x0000da40 20010000 3c5affff 190d0000 00410e10  ...<Z.......A..
+  0x0000da50 8602430d 06448f03 8e044f8d 058c0683 ..C..D....O.....
+  0x0000da60 07030909 0a0c0708 500b0000 2c000000 ........P...,...
+  0x0000da70 50010000 2c67ffff 29150000 00410e10 P...,g..)....A..
+  0x0000da80 8602430d 06448f03 8e044f8d 058c0683 ..C..D....O.....
+  0x0000da90 0703270f 0a0c0708 420b0000 2c000000 ..'.....B...,...
+  0x0000daa0 80010000 2c7cffff a9200000 00410e10 ....,|... ...A..
+  0x0000dab0 8602430d 06448f03 8e044f8d 058c0683 ..C..D....O.....
+  0x0000dac0 07039517 0a0c0708 440b0000 4c000000 ........D...L...
+  0x0000dad0 b0010000 ac9cffff 24060000 00420e10 ........$....B..
+  0x0000dae0 8f02420e 188e0342 0e208d04 420e288c ..B....B. ..B.(.
+  0x0000daf0 05410e30 8606410e 38830744 0ea00103 .A.0..A.8..D....
+  0x0000db00 d7050a0e 38440e30 410e2842 0e20420e ....8D.0A.(B. B.
+  0x0000db10 18420e10 420e0845 0b000000 4c000000 .B..B..E....L...
+  0x0000db20 00020000 8ca2ffff 200c0000 00420e10 ........ ....B..
+  0x0000db30 8f02420e 188e0342 0e208d04 420e288c ..B....B. ..B.(.
+  0x0000db40 05410e30 8606410e 38830747 0eb00203 .A.0..A.8..G....
+  0x0000db50 b30b0a0e 38440e30 410e2842 0e20420e ....8D.0A.(B. B.
+  0x0000db60 18420e10 420e084f 0b000000 4c000000 .B..B..O....L...
+  0x0000db70 50020000 5caeffff fd0e0000 00420e10 P...\........B..
+  0x0000db80 8f02420e 188e0342 0e208d04 420e288c ..B....B. ..B.(.
+  0x0000db90 05410e30 8606410e 38830747 0ee00103 .A.0..A.8..G....
+  0x0000dba0 8e0e0a0e 38440e30 410e2842 0e20420e ....8D.0A.(B. B.
+  0x0000dbb0 18420e10 420e0845 0b000000 2c000000 .B..B..E....,...
+  0x0000dbc0 a0020000 0cbdffff e1230000 00410e10 .........#...A..
+  0x0000dbd0 8602430d 06508f03 8e048d05 8c068307 ..C..P..........
+  0x0000dbe0 0375230a 0c070845 0b000000 48000000 .u#....E....H...
+  0x0000dbf0 d0020000 cce0ffff 3d020000 00420e10 ........=....B..
+  0x0000dc00 8f02420e 188e0348 0e208d04 420e288c ..B....H. ..B.(.
+  0x0000dc10 05470e30 8606410e 3883074e 0e6002e0 .G.0..A.8..N.`..
+  0x0000dc20 0a0e3841 0e30410e 28420e20 420e1842 ..8A.0A.(B. B..B
+  0x0000dc30 0e10420e 08410b00 14000000 1c030000 ..B..A..........
+  0x0000dc40 c0e2ffff 30000000 00440e30 6b0e0800 ....0....D.0k...
+  0x0000dc50 14000000 34030000 d8e2ffff 35000000 ....4.......5...
+  0x0000dc60 00440e30 700e0800 14000000 4c030000 .D.0p.......L...
+  0x0000dc70 00e3ffff 35000000 00440e30 700e0800 ....5....D.0p...
+  0x0000dc80 14000000 64030000 28e3ffff 35000000 ....d...(...5...
+  0x0000dc90 00440e30 700e0800 14000000 7c030000 .D.0p.......|...
+  0x0000dca0 50e3ffff 35000000 00440e30 700e0800 P...5....D.0p...
+  0x0000dcb0 14000000 94030000 78e3ffff 35000000 ........x...5...
+  0x0000dcc0 00440e30 700e0800 14000000 ac030000 .D.0p...........
+  0x0000dcd0 a0e3ffff 35000000 00440e30 700e0800 ....5....D.0p...
+  0x0000dce0 14000000 c4030000 c8e3ffff 41000000 ............A...
+  0x0000dcf0 00490e30 770e0800 1c000000 dc030000 .I.0w...........
+  0x0000dd00 00e4ffff 55000000 00410e10 8602510d ....U....A....Q.
+  0x0000dd10 0602420c 07080000 10000000 fc030000 ..B.............
+  0x0000dd20 40e4ffff 15000000 00000000 14000000 @...............
+  0x0000dd30 10040000 4ce4ffff 41000000 00490e30 ....L...A....I.0
+  0x0000dd40 770e0800 1c000000 28040000 84e4ffff w.......(.......
+  0x0000dd50 55000000 00410e10 8602510d 0602420c U....A....Q...B.
+  0x0000dd60 07080000 10000000 48040000 c4e4ffff ........H.......
+  0x0000dd70 b8000000 00000000 00000000          ............
```

### readelf --wide --decompress --hex-dump=.init_array {}

```diff
@@ -1,4 +1,4 @@
 
 Hex dump of section '.init_array':
-  0x0000add8 d0110000 00000000                   ........
+  0x0000edd8 20120000 00000000                    .......
```

### readelf --wide --decompress --hex-dump=.fini_array {}

```diff
@@ -1,4 +1,4 @@
 
 Hex dump of section '.fini_array':
-  0x0000ade0 90110000 00000000                   ........
+  0x0000ede0 e0110000 00000000                   ........
```

### readelf --wide --decompress --hex-dump=.data.rel.ro {}

```diff
@@ -1,4 +1,4 @@
 
 Hex dump of section '.data.rel.ro':
-  0x0000ade8 e8ad0000 00000000                   ........
+  0x0000ede8 e8ed0000 00000000                   ........
```

### readelf --wide --decompress --hex-dump=.got {}

```diff
@@ -1,5 +1,5 @@
 
 Hex dump of section '.got':
-  0x0000afe0 00000000 00000000 00000000 00000000 ................
-  0x0000aff0 00000000 00000000 00000000 00000000 ................
+  0x0000efe0 00000000 00000000 00000000 00000000 ................
+  0x0000eff0 00000000 00000000 00000000 00000000 ................
```

### readelf --wide --decompress --hex-dump=.got.plt {}

```diff
@@ -1,13 +1,16 @@
 
 Hex dump of section '.got.plt':
  NOTE: This section has relocations against it, but these have NOT been applied to this dump.
-  0x0000b000 f0ad0000 00000000 00000000 00000000 ................
-  0x0000b010 00000000 00000000 36100000 00000000 ........6.......
-  0x0000b020 46100000 00000000 56100000 00000000 F.......V.......
-  0x0000b030 66100000 00000000 76100000 00000000 f.......v.......
-  0x0000b040 86100000 00000000 96100000 00000000 ................
-  0x0000b050 a6100000 00000000 b6100000 00000000 ................
-  0x0000b060 c6100000 00000000 d6100000 00000000 ................
-  0x0000b070 e6100000 00000000 f6100000 00000000 ................
-  0x0000b080 06110000 00000000 16110000 00000000 ................
+  0x0000f000 f0ed0000 00000000 00000000 00000000 ................
+  0x0000f010 00000000 00000000 36100000 00000000 ........6.......
+  0x0000f020 46100000 00000000 56100000 00000000 F.......V.......
+  0x0000f030 66100000 00000000 76100000 00000000 f.......v.......
+  0x0000f040 86100000 00000000 96100000 00000000 ................
+  0x0000f050 a6100000 00000000 b6100000 00000000 ................
+  0x0000f060 c6100000 00000000 d6100000 00000000 ................
+  0x0000f070 e6100000 00000000 f6100000 00000000 ................
+  0x0000f080 06110000 00000000 16110000 00000000 ................
+  0x0000f090 26110000 00000000 36110000 00000000 &.......6.......
+  0x0000f0a0 46110000 00000000 56110000 00000000 F.......V.......
+  0x0000f0b0 66110000 00000000                   f.......
```

### readelf --wide --decompress --hex-dump=.strtab {}

```diff
@@ -16,60 +16,72 @@
   0x000000d0 74657369 616e5f73 70686572 6963616c tesian_spherical
   0x000000e0 5f686172 6d6f6e69 63735f6c 312e5f6f _harmonics_l1._o
   0x000000f0 6d705f66 6e2e3000 63617274 65736961 mp_fn.0.cartesia
   0x00000100 6e5f7370 68657269 63616c5f 6861726d n_spherical_harm
   0x00000110 6f6e6963 735f6c32 2e5f6f6d 705f666e onics_l2._omp_fn
   0x00000120 2e300063 61727465 7369616e 5f737068 .0.cartesian_sph
   0x00000130 65726963 616c5f68 61726d6f 6e696373 erical_harmonics
-  0x00000140 5f67656e 65726963 2e5f6f6d 705f666e _generic._omp_fn
-  0x00000150 2e300063 61727465 7369616e 5f737068 .0.cartesian_sph
-  0x00000160 65726963 616c5f68 61726d6f 6e696373 erical_harmonics
-  0x00000170 5f6c332e 5f6f6d70 5f666e2e 30006361 _l3._omp_fn.0.ca
-  0x00000180 72746573 69616e5f 73706865 72696361 rtesian_spherica
-  0x00000190 6c5f6861 726d6f6e 6963732e 5f6f6d70 l_harmonics._omp
-  0x000001a0 5f666e2e 30006361 72746573 69616e5f _fn.0.cartesian_
-  0x000001b0 73706865 72696361 6c5f6861 726d6f6e spherical_harmon
-  0x000001c0 6963735f 6c342e5f 6f6d705f 666e2e30 ics_l4._omp_fn.0
-  0x000001d0 00636172 74657369 616e5f73 70686572 .cartesian_spher
-  0x000001e0 6963616c 5f686172 6d6f6e69 63735f6c ical_harmonics_l
-  0x000001f0 352e5f6f 6d705f66 6e2e3000 5f5f4652 5._omp_fn.0.__FR
-  0x00000200 414d455f 454e445f 5f005f5f 64736f5f AME_END__.__dso_
-  0x00000210 68616e64 6c65005f 44594e41 4d494300 handle._DYNAMIC.
-  0x00000220 5f5f474e 555f4548 5f465241 4d455f48 __GNU_EH_FRAME_H
-  0x00000230 4452005f 5f544d43 5f454e44 5f5f005f DR.__TMC_END__._
-  0x00000240 474c4f42 414c5f4f 46465345 545f5441 GLOBAL_OFFSET_TA
-  0x00000250 424c455f 00667265 65404047 4c494243 BLE_.free@@GLIBC
-  0x00000260 5f322e32 2e350063 61727465 7369616e _2.2.5.cartesian
-  0x00000270 5f737068 65726963 616c5f68 61726d6f _spherical_harmo
-  0x00000280 6e696373 005f4954 4d5f6465 72656769 nics._ITM_deregi
-  0x00000290 73746572 544d436c 6f6e6554 61626c65 sterTMCloneTable
-  0x000002a0 00636172 74657369 616e5f73 70686572 .cartesian_spher
-  0x000002b0 6963616c 5f686172 6d6f6e69 63735f6c ical_harmonics_l
-  0x000002c0 31006361 72746573 69616e5f 73706865 1.cartesian_sphe
-  0x000002d0 72696361 6c5f6861 726d6f6e 6963735f rical_harmonics_
-  0x000002e0 6c330063 61727465 7369616e 5f737068 l3.cartesian_sph
-  0x000002f0 65726963 616c5f68 61726d6f 6e696373 erical_harmonics
-  0x00000300 5f6c3500 474f4d50 5f626172 72696572 _l5.GOMP_barrier
-  0x00000310 4040474f 4d505f31 2e30006f 6d705f67 @@GOMP_1.0.omp_g
-  0x00000320 65745f74 68726561 645f6e75 6d40404f et_thread_num@@O
-  0x00000330 4d505f31 2e300063 6f6d7075 74655f73 MP_1.0.compute_s
-  0x00000340 70685f70 72656661 63746f72 73005f66 ph_prefactors._f
-  0x00000350 696e6900 6f6d705f 6765745f 6e756d5f ini.omp_get_num_
-  0x00000360 74687265 61647340 404f4d50 5f312e30 threads@@OMP_1.0
-  0x00000370 005f5f67 6d6f6e5f 73746172 745f5f00 .__gmon_start__.
-  0x00000380 6d616c6c 6f634040 474c4942 435f322e malloc@@GLIBC_2.
-  0x00000390 322e3500 63617274 65736961 6e5f7370 2.5.cartesian_sp
-  0x000003a0 68657269 63616c5f 6861726d 6f6e6963 herical_harmonic
-  0x000003b0 735f6c30 00636172 74657369 616e5f73 s_l0.cartesian_s
-  0x000003c0 70686572 6963616c 5f686172 6d6f6e69 pherical_harmoni
-  0x000003d0 63735f6c 32006361 72746573 69616e5f cs_l2.cartesian_
-  0x000003e0 73706865 72696361 6c5f6861 726d6f6e spherical_harmon
-  0x000003f0 6963735f 6c340073 71727400 63617274 ics_l4.sqrt.cart
-  0x00000400 65736961 6e5f7370 68657269 63616c5f esian_spherical_
-  0x00000410 6861726d 6f6e6963 735f6765 6e657269 harmonics_generi
-  0x00000420 63005f49 544d5f72 65676973 74657254 c._ITM_registerT
-  0x00000430 4d436c6f 6e655461 626c6500 474f4d50 MCloneTable.GOMP
-  0x00000440 5f706172 616c6c65 6c404047 4f4d505f _parallel@@GOMP_
-  0x00000450 342e3000 5f5f6378 615f6669 6e616c69 4.0.__cxa_finali
-  0x00000460 7a654040 474c4942 435f322e 322e3500 ze@@GLIBC_2.2.5.
-  0x00000470 5f696e69 7400                       _init.
+  0x00000140 5f6c332e 5f6f6d70 5f666e2e 30006361 _l3._omp_fn.0.ca
+  0x00000150 72746573 69616e5f 73706865 72696361 rtesian_spherica
+  0x00000160 6c5f6861 726d6f6e 6963735f 6c342e5f l_harmonics_l4._
+  0x00000170 6f6d705f 666e2e30 00636172 74657369 omp_fn.0.cartesi
+  0x00000180 616e5f73 70686572 6963616c 5f686172 an_spherical_har
+  0x00000190 6d6f6e69 63735f6c 352e5f6f 6d705f66 monics_l5._omp_f
+  0x000001a0 6e2e3000 63617274 65736961 6e5f7370 n.0.cartesian_sp
+  0x000001b0 68657269 63616c5f 6861726d 6f6e6963 herical_harmonic
+  0x000001c0 735f6c36 2e5f6f6d 705f666e 2e30005f s_l6._omp_fn.0._
+  0x000001d0 636f6d70 7574655f 6e6f5f64 7370682e compute_no_dsph.
+  0x000001e0 5f6f6d70 5f666e2e 30005f63 6f6d7075 _omp_fn.0._compu
+  0x000001f0 74655f77 6974685f 64737068 2e5f6f6d te_with_dsph._om
+  0x00000200 705f666e 2e30005f 636f6d70 7574655f p_fn.0._compute_
+  0x00000210 68696768 6c5f6e6f 5f647370 682e5f6f highl_no_dsph._o
+  0x00000220 6d705f66 6e2e3000 5f636f6d 70757465 mp_fn.0._compute
+  0x00000230 5f686967 686c5f77 6974685f 64737068 _highl_with_dsph
+  0x00000240 2e5f6f6d 705f666e 2e30005f 5f465241 ._omp_fn.0.__FRA
+  0x00000250 4d455f45 4e445f5f 005f5f64 736f5f68 ME_END__.__dso_h
+  0x00000260 616e646c 65005f44 594e414d 4943005f andle._DYNAMIC._
+  0x00000270 5f474e55 5f45485f 4652414d 455f4844 _GNU_EH_FRAME_HD
+  0x00000280 52005f5f 544d435f 454e445f 5f005f47 R.__TMC_END__._G
+  0x00000290 4c4f4241 4c5f4f46 46534554 5f544142 LOBAL_OFFSET_TAB
+  0x000002a0 4c455f00 66726565 4040474c 4942435f LE_.free@@GLIBC_
+  0x000002b0 322e322e 35006361 72746573 69616e5f 2.2.5.cartesian_
+  0x000002c0 73706865 72696361 6c5f6861 726d6f6e spherical_harmon
+  0x000002d0 69637300 5f49544d 5f646572 65676973 ics._ITM_deregis
+  0x000002e0 74657254 4d436c6f 6e655461 626c6500 terTMCloneTable.
+  0x000002f0 63617274 65736961 6e5f7370 68657269 cartesian_spheri
+  0x00000300 63616c5f 6861726d 6f6e6963 735f6c31 cal_harmonics_l1
+  0x00000310 00636172 74657369 616e5f73 70686572 .cartesian_spher
+  0x00000320 6963616c 5f686172 6d6f6e69 63735f6c ical_harmonics_l
+  0x00000330 33006361 72746573 69616e5f 73706865 3.cartesian_sphe
+  0x00000340 72696361 6c5f6861 726d6f6e 6963735f rical_harmonics_
+  0x00000350 6c350047 4f4d505f 62617272 69657240 l5.GOMP_barrier@
+  0x00000360 40474f4d 505f312e 30006f6d 705f6765 @GOMP_1.0.omp_ge
+  0x00000370 745f7468 72656164 5f6e756d 40404f4d t_thread_num@@OM
+  0x00000380 505f312e 3000636f 6d707574 655f7370 P_1.0.compute_sp
+  0x00000390 685f7072 65666163 746f7273 005f6669 h_prefactors._fi
+  0x000003a0 6e69006f 6d705f67 65745f6e 756d5f74 ni.omp_get_num_t
+  0x000003b0 68726561 64734040 4f4d505f 312e3000 hreads@@OMP_1.0.
+  0x000003c0 5f636f6d 70757465 5f776974 685f6473 _compute_with_ds
+  0x000003d0 7068005f 636f6d70 7574655f 6e6f5f64 ph._compute_no_d
+  0x000003e0 73706800 5f5f676d 6f6e5f73 74617274 sph.__gmon_start
+  0x000003f0 5f5f005f 636f6d70 7574655f 68696768 __._compute_high
+  0x00000400 6c5f6e6f 5f647370 68006d61 6c6c6f63 l_no_dsph.malloc
+  0x00000410 4040474c 4942435f 322e322e 35005f63 @@GLIBC_2.2.5._c
+  0x00000420 6f6d7075 74655f68 6967686c 5f776974 ompute_highl_wit
+  0x00000430 685f6473 70680063 61727465 7369616e h_dsph.cartesian
+  0x00000440 5f737068 65726963 616c5f68 61726d6f _spherical_harmo
+  0x00000450 6e696373 5f6c3000 63617274 65736961 nics_l0.cartesia
+  0x00000460 6e5f7370 68657269 63616c5f 6861726d n_spherical_harm
+  0x00000470 6f6e6963 735f6c32 00636172 74657369 onics_l2.cartesi
+  0x00000480 616e5f73 70686572 6963616c 5f686172 an_spherical_har
+  0x00000490 6d6f6e69 63735f6c 34006361 72746573 monics_l4.cartes
+  0x000004a0 69616e5f 73706865 72696361 6c5f6861 ian_spherical_ha
+  0x000004b0 726d6f6e 6963735f 6c360073 71727400 rmonics_l6.sqrt.
+  0x000004c0 63617274 65736961 6e5f7370 68657269 cartesian_spheri
+  0x000004d0 63616c5f 6861726d 6f6e6963 735f6765 cal_harmonics_ge
+  0x000004e0 6e657269 63005f49 544d5f72 65676973 neric._ITM_regis
+  0x000004f0 74657254 4d436c6f 6e655461 626c6500 terTMCloneTable.
+  0x00000500 474f4d50 5f706172 616c6c65 6c404047 GOMP_parallel@@G
+  0x00000510 4f4d505f 342e3000 5f5f6378 615f6669 OMP_4.0.__cxa_fi
+  0x00000520 6e616c69 7a654040 474c4942 435f322e nalize@@GLIBC_2.
+  0x00000530 322e3500 5f696e69 7400              2.5._init.
```

### readelf --wide --decompress --hex-dump=.gnu.hash {}

```diff
@@ -1,8 +1,10 @@
 
 Hex dump of section '.gnu.hash':
-  0x0000c028 03000000 0c000000 01000000 06000000 ................
-  0x0000c038 00804000 1004e01f 0c000000 0f000000 ..@.............
-  0x0000c048 14000000 7ceda124 3a6e3c6f 376e3c6f ....|..$:n<o7n<o
-  0x0000c058 386e3c6f a435d002 3a6e3c6f b8fe3a6f 8n<o.5..:n<o..:o
-  0x0000c068 b98df10e 3c6e3c6f ead3ef0e 396e3c6f ....<n<o....9n<o
+  0x00010028 03000000 0c000000 02000000 07000000 ................
+  0x00010038 00084058 1008a03f 00040044 800c0010 ..@X...?...D....
+  0x00010048 0c000000 12000000 19000000 7ceda124 ............|..$
+  0x00010058 3a6e3c6f 4a8fa8b9 168fb2cb 366e3c6f :n<oJ.......6n<o
+  0x00010068 3d6e3c6f 386e3c6f a435d002 6aaffed7 =n<o8n<o.5..j...
+  0x00010078 b405d369 3a6e3c6f b8fe3a6f b98df10e ...i:n<o..:o....
+  0x00010088 3c6e3c6f ead3ef0e 396e3c6f          <n<o....9n<o
```

### readelf --wide --decompress --hex-dump=.dynstr {}

```diff
@@ -1,42 +1,49 @@
 
 Hex dump of section '.dynstr':
-  0x0000d428 005f5f67 6d6f6e5f 73746172 745f5f00 .__gmon_start__.
-  0x0000d438 5f696e69 74005f66 696e6900 5f49544d _init._fini._ITM
-  0x0000d448 5f646572 65676973 74657254 4d436c6f _deregisterTMClo
-  0x0000d458 6e655461 626c6500 5f49544d 5f726567 neTable._ITM_reg
-  0x0000d468 69737465 72544d43 6c6f6e65 5461626c isterTMCloneTabl
-  0x0000d478 65005f5f 6378615f 66696e61 6c697a65 e.__cxa_finalize
-  0x0000d488 006f6d70 5f676574 5f6e756d 5f746872 .omp_get_num_thr
-  0x0000d498 65616473 006f6d70 5f676574 5f746872 eads.omp_get_thr
-  0x0000d4a8 6561645f 6e756d00 6d616c6c 6f630047 ead_num.malloc.G
-  0x0000d4b8 4f4d505f 62617272 69657200 66726565 OMP_barrier.free
-  0x0000d4c8 00636f6d 70757465 5f737068 5f707265 .compute_sph_pre
-  0x0000d4d8 66616374 6f727300 73717274 00636172 factors.sqrt.car
-  0x0000d4e8 74657369 616e5f73 70686572 6963616c tesian_spherical
-  0x0000d4f8 5f686172 6d6f6e69 63735f6c 3000474f _harmonics_l0.GO
-  0x0000d508 4d505f70 6172616c 6c656c00 63617274 MP_parallel.cart
-  0x0000d518 65736961 6e5f7370 68657269 63616c5f esian_spherical_
-  0x0000d528 6861726d 6f6e6963 735f6c31 00636172 harmonics_l1.car
-  0x0000d538 74657369 616e5f73 70686572 6963616c tesian_spherical
-  0x0000d548 5f686172 6d6f6e69 63735f6c 32006361 _harmonics_l2.ca
-  0x0000d558 72746573 69616e5f 73706865 72696361 rtesian_spherica
-  0x0000d568 6c5f6861 726d6f6e 6963735f 6c330063 l_harmonics_l3.c
-  0x0000d578 61727465 7369616e 5f737068 65726963 artesian_spheric
-  0x0000d588 616c5f68 61726d6f 6e696373 5f6c3400 al_harmonics_l4.
-  0x0000d598 63617274 65736961 6e5f7370 68657269 cartesian_spheri
-  0x0000d5a8 63616c5f 6861726d 6f6e6963 735f6c35 cal_harmonics_l5
-  0x0000d5b8 00636172 74657369 616e5f73 70686572 .cartesian_spher
-  0x0000d5c8 6963616c 5f686172 6d6f6e69 63735f67 ical_harmonics_g
-  0x0000d5d8 656e6572 69630063 61727465 7369616e eneric.cartesian
-  0x0000d5e8 5f737068 65726963 616c5f68 61726d6f _spherical_harmo
-  0x0000d5f8 6e696373 006c6962 676f6d70 2e736f2e nics.libgomp.so.
-  0x0000d608 31006c69 62707468 72656164 2e736f2e 1.libpthread.so.
-  0x0000d618 30006c69 62632e73 6f2e3600 6c696273 0.libc.so.6.libs
-  0x0000d628 70686572 69636172 742e736f 00474f4d phericart.so.GOM
-  0x0000d638 505f342e 3000474f 4d505f31 2e300047 P_4.0.GOMP_1.0.G
-  0x0000d648 4c494243 5f322e32 2e35006c 6962676f LIBC_2.2.5.libgo
-  0x0000d658 6d702d61 33346233 3233332e 736f2e31 mp-a34b3233.so.1
-  0x0000d668 2e302e30 00244f52 4947494e 2f2e2e2f .0.0.$ORIGIN/../
-  0x0000d678 2e2e2f73 70686572 69636172 742e6c69 ../sphericart.li
-  0x0000d688 627300                              bs.
+  0x000114a0 005f5f67 6d6f6e5f 73746172 745f5f00 .__gmon_start__.
+  0x000114b0 5f696e69 74005f66 696e6900 5f49544d _init._fini._ITM
+  0x000114c0 5f646572 65676973 74657254 4d436c6f _deregisterTMClo
+  0x000114d0 6e655461 626c6500 5f49544d 5f726567 neTable._ITM_reg
+  0x000114e0 69737465 72544d43 6c6f6e65 5461626c isterTMCloneTabl
+  0x000114f0 65005f5f 6378615f 66696e61 6c697a65 e.__cxa_finalize
+  0x00011500 006f6d70 5f676574 5f6e756d 5f746872 .omp_get_num_thr
+  0x00011510 65616473 006f6d70 5f676574 5f746872 eads.omp_get_thr
+  0x00011520 6561645f 6e756d00 6d616c6c 6f630047 ead_num.malloc.G
+  0x00011530 4f4d505f 62617272 69657200 66726565 OMP_barrier.free
+  0x00011540 00636f6d 70757465 5f737068 5f707265 .compute_sph_pre
+  0x00011550 66616374 6f727300 73717274 00636172 factors.sqrt.car
+  0x00011560 74657369 616e5f73 70686572 6963616c tesian_spherical
+  0x00011570 5f686172 6d6f6e69 63735f6c 3000474f _harmonics_l0.GO
+  0x00011580 4d505f70 6172616c 6c656c00 63617274 MP_parallel.cart
+  0x00011590 65736961 6e5f7370 68657269 63616c5f esian_spherical_
+  0x000115a0 6861726d 6f6e6963 735f6c31 00636172 harmonics_l1.car
+  0x000115b0 74657369 616e5f73 70686572 6963616c tesian_spherical
+  0x000115c0 5f686172 6d6f6e69 63735f6c 32006361 _harmonics_l2.ca
+  0x000115d0 72746573 69616e5f 73706865 72696361 rtesian_spherica
+  0x000115e0 6c5f6861 726d6f6e 6963735f 6c330063 l_harmonics_l3.c
+  0x000115f0 61727465 7369616e 5f737068 65726963 artesian_spheric
+  0x00011600 616c5f68 61726d6f 6e696373 5f6c3400 al_harmonics_l4.
+  0x00011610 63617274 65736961 6e5f7370 68657269 cartesian_spheri
+  0x00011620 63616c5f 6861726d 6f6e6963 735f6c35 cal_harmonics_l5
+  0x00011630 00636172 74657369 616e5f73 70686572 .cartesian_spher
+  0x00011640 6963616c 5f686172 6d6f6e69 63735f6c ical_harmonics_l
+  0x00011650 36005f63 6f6d7075 74655f6e 6f5f6473 6._compute_no_ds
+  0x00011660 7068005f 636f6d70 7574655f 77697468 ph._compute_with
+  0x00011670 5f647370 68006361 72746573 69616e5f _dsph.cartesian_
+  0x00011680 73706865 72696361 6c5f6861 726d6f6e spherical_harmon
+  0x00011690 6963735f 67656e65 72696300 5f636f6d ics_generic._com
+  0x000116a0 70757465 5f686967 686c5f6e 6f5f6473 pute_highl_no_ds
+  0x000116b0 7068005f 636f6d70 7574655f 68696768 ph._compute_high
+  0x000116c0 6c5f7769 74685f64 73706800 63617274 l_with_dsph.cart
+  0x000116d0 65736961 6e5f7370 68657269 63616c5f esian_spherical_
+  0x000116e0 6861726d 6f6e6963 73006c69 62676f6d harmonics.libgom
+  0x000116f0 702e736f 2e31006c 69627074 68726561 p.so.1.libpthrea
+  0x00011700 642e736f 2e30006c 6962632e 736f2e36 d.so.0.libc.so.6
+  0x00011710 006c6962 73706865 72696361 72742e73 .libsphericart.s
+  0x00011720 6f00474f 4d505f34 2e300047 4f4d505f o.GOMP_4.0.GOMP_
+  0x00011730 312e3000 474c4942 435f322e 322e3500 1.0.GLIBC_2.2.5.
+  0x00011740 6c696267 6f6d702d 61333462 33323333 libgomp-a34b3233
+  0x00011750 2e736f2e 312e302e 3000244f 52494749 .so.1.0.0.$ORIGI
+  0x00011760 4e2f2e2e 2f2e2e2f 73706865 72696361 N/../../spherica
+  0x00011770 72742e6c 69627300                   rt.libs.
```

## Comparing `sphericart-0.1.2.dist-info/LICENSE` & `sphericart-0.2.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `sphericart-0.1.2.dist-info/METADATA` & `sphericart-0.2.0.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: sphericart
-Version: 0.1.2
+Version: 0.2.0
 Summary: sphericart, a package to calculate spherical harmonics efficiently in Cartesian coordinates
 Description-Content-Type: text/markdown
 License-File: LICENSE
 
 # sphericart
 
 This is sphericart, a multi-language library for the efficient calculation of the
```

## Comparing `sphericart-0.1.2.dist-info/RECORD` & `sphericart-0.2.0.dist-info/RECORD`

 * *Files 17% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 sphericart.libs/libgomp-a34b3233.so.1.0.0,sha256=On6uznIxkRvi-7Gz58tMtcLg-E4MK7c3OUcrWh_uyME,168193
-sphericart-0.1.2.dist-info/top_level.txt,sha256=yVM-yuc0CBRqc1chiCzf0T9h-riRdTTRtd8jE1kcLfc,11
-sphericart-0.1.2.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-sphericart-0.1.2.dist-info/WHEEL,sha256=D79CBkaJekx7HMK1NaBe_KU1GVla4HlolbFXT3at6fg,148
-sphericart-0.1.2.dist-info/METADATA,sha256=ZGi4tci7D8g5WWDr7dBplDy-iAizBI4GT0-avlpvlNI,792
-sphericart-0.1.2.dist-info/RECORD,,
+sphericart-0.2.0.dist-info/top_level.txt,sha256=yVM-yuc0CBRqc1chiCzf0T9h-riRdTTRtd8jE1kcLfc,11
+sphericart-0.2.0.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
+sphericart-0.2.0.dist-info/WHEEL,sha256=D79CBkaJekx7HMK1NaBe_KU1GVla4HlolbFXT3at6fg,148
+sphericart-0.2.0.dist-info/METADATA,sha256=N_f2ZLt785bIYDClQO2AJAcXwU2HIDve9JUdVf6ESQ0,792
+sphericart-0.2.0.dist-info/RECORD,,
 sphericart/__init__.py,sha256=lNEJ_rSgSBZiLSngOsyOz7cfJvHnKXAY2dwTjqTl4Ng,52
 sphericart/wrappers.py,sha256=NuNe6VCJTkoUv-G7KIFUuHHiLhPQb3rvtQy7IgC57kY,1033
 sphericart/library.py,sha256=cVAET3O5GPMajk_2BXuRjoBNutfhcYN_Kpp4krmJLZc,744
 sphericart/spherical_harmonics.py,sha256=sIS5ClcmIvhA7RUJALuzja_6iKW05eLZI028l6rbav4,2391
-sphericart/lib/libsphericart.so,sha256=5QPzH1JC1oOq2_2-HYJSH0VWuxkIlWAs57roZhvoWC8,54929
+sphericart/lib/libsphericart.so,sha256=qANBjv72YOWU-Tda0mHzIezoFNFmJ0-AnbCxTYWS9Fs,71545
```

