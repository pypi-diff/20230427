# Comparing `tmp/laboneq-2.4.0-py3-none-any.whl.zip` & `tmp/laboneq-2.5.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,90 +1,90 @@
-Zip file size: 946465 bytes, number of entries: 239
--rw-rw-rw-  2.0 unx        5 b- defN 23-Apr-13 09:53 laboneq/VERSION.txt
--rw-r--r--  2.0 unx      306 b- defN 23-Feb-13 10:47 laboneq/__init__.py
+Zip file size: 955846 bytes, number of entries: 248
+-rw-rw-rw-  2.0 unx        5 b- defN 23-Apr-27 08:13 laboneq/VERSION.txt
+-rw-r--r--  2.0 unx      306 b- defN 23-Feb-02 07:13 laboneq/__init__.py
 -rw-r--r--  2.0 unx     2829 b- defN 23-Feb-02 07:13 laboneq/_token.py
 -rw-r--r--  2.0 unx      238 b- defN 23-Feb-02 07:13 laboneq/_version.py
--rw-r--r--  2.0 unx     1392 b- defN 23-Feb-02 07:13 laboneq/simple.py
+-rw-r--r--  2.0 unx     1411 b- defN 23-Apr-27 08:13 laboneq/simple.py
 -rw-r--r--  2.0 unx      184 b- defN 23-Feb-02 07:13 laboneq/_observability/__init__.py
 -rw-r--r--  2.0 unx      538 b- defN 23-Feb-02 07:13 laboneq/_observability/tracing/__init__.py
 -rw-r--r--  2.0 unx      893 b- defN 23-Feb-16 12:45 laboneq/_observability/tracing/_noop_tracer.py
 -rw-r--r--  2.0 unx     2309 b- defN 23-Feb-16 12:45 laboneq/_observability/tracing/_tracer.py
 -rw-r--r--  2.0 unx      444 b- defN 23-Feb-02 07:13 laboneq/compiler/__init__.py
 -rw-r--r--  2.0 unx      204 b- defN 23-Feb-02 07:13 laboneq/compiler/fastlogging.py
--rw-rw-rw-  2.0 unx    22524 b- defN 23-Apr-06 14:15 laboneq/compiler/qccs-schema_2_5_0.json
+-rw-rw-rw-  2.0 unx    22524 b- defN 23-Apr-25 11:23 laboneq/compiler/qccs-schema_2_5_0.json
 -rw-r--r--  2.0 unx      666 b- defN 23-Feb-02 07:13 laboneq/compiler/remote.py
 -rw-r--r--  2.0 unx      654 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/__init__.py
 -rw-r--r--  2.0 unx    18645 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/analyze_events.py
 -rw-r--r--  2.0 unx    28581 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/analyze_playback.py
--rw-r--r--  2.0 unx    64112 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/code_generator.py
+-rw-r--r--  2.0 unx    64112 b- defN 23-Apr-25 11:23 laboneq/compiler/code_generator/code_generator.py
 -rw-r--r--  2.0 unx     4026 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/command_table_tracker.py
--rw-r--r--  2.0 unx     2727 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/compressor.py
+-rw-r--r--  2.0 unx     2880 b- defN 23-Apr-25 11:23 laboneq/compiler/code_generator/compressor.py
 -rw-r--r--  2.0 unx     1414 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/feedback_register_allocator.py
 -rw-r--r--  2.0 unx    10355 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/interval_calculator.py
 -rw-r--r--  2.0 unx    18617 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/measurement_calculator.py
--rw-r--r--  2.0 unx    29598 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/sampled_event_handler.py
--rw-r--r--  2.0 unx    18104 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/seq_c_generator.py
--rw-r--r--  2.0 unx     6129 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/seqc_tracker.py
+-rw-r--r--  2.0 unx    29598 b- defN 23-Apr-25 11:23 laboneq/compiler/code_generator/sampled_event_handler.py
+-rw-r--r--  2.0 unx    18188 b- defN 23-Apr-25 11:23 laboneq/compiler/code_generator/seq_c_generator.py
+-rw-r--r--  2.0 unx     6129 b- defN 23-Apr-25 11:23 laboneq/compiler/code_generator/seqc_tracker.py
 -rw-r--r--  2.0 unx     7741 b- defN 23-Apr-06 14:15 laboneq/compiler/code_generator/signatures.py
--rw-r--r--  2.0 unx     3500 b- defN 23-Mar-02 10:50 laboneq/compiler/code_generator/utils.py
+-rw-r--r--  2.0 unx     3500 b- defN 23-Feb-28 13:10 laboneq/compiler/code_generator/utils.py
 -rw-r--r--  2.0 unx     1476 b- defN 23-Feb-28 13:10 laboneq/compiler/code_generator/wave_index_tracker.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/compiler/common/__init__.py
 -rw-r--r--  2.0 unx     1093 b- defN 23-Apr-06 14:15 laboneq/compiler/common/awg_info.py
 -rw-r--r--  2.0 unx     1903 b- defN 23-Apr-06 14:15 laboneq/compiler/common/awg_sampled_event.py
 -rw-r--r--  2.0 unx      480 b- defN 23-Feb-02 07:13 laboneq/compiler/common/awg_signal_type.py
 -rw-r--r--  2.0 unx     3983 b- defN 23-Apr-06 14:15 laboneq/compiler/common/compiler_settings.py
--rw-r--r--  2.0 unx     4547 b- defN 23-Feb-16 12:45 laboneq/compiler/common/device_type.py
+-rw-r--r--  2.0 unx     4708 b- defN 23-Apr-25 11:23 laboneq/compiler/common/device_type.py
 -rw-r--r--  2.0 unx     1532 b- defN 23-Feb-15 13:56 laboneq/compiler/common/event_type.py
 -rw-r--r--  2.0 unx      229 b- defN 23-Mar-07 13:19 laboneq/compiler/common/play_wave_type.py
 -rw-r--r--  2.0 unx      580 b- defN 23-Apr-06 14:15 laboneq/compiler/common/pulse_parameters.py
--rw-r--r--  2.0 unx     2052 b- defN 23-Apr-06 14:15 laboneq/compiler/common/signal_obj.py
+-rw-r--r--  2.0 unx     2594 b- defN 23-Apr-25 11:23 laboneq/compiler/common/signal_obj.py
 -rw-r--r--  2.0 unx      400 b- defN 23-Feb-02 07:13 laboneq/compiler/common/trigger_mode.py
 -rw-r--r--  2.0 unx      154 b- defN 23-Feb-02 07:13 laboneq/compiler/experiment_access/__init__.py
 -rw-r--r--  2.0 unx      222 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/acquire_info.py
 -rw-r--r--  2.0 unx      602 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/cache.py
--rw-r--r--  2.0 unx      349 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/device_info.py
--rw-r--r--  2.0 unx    42040 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/dsl_loader.py
--rw-r--r--  2.0 unx    16297 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/experiment_dao.py
--rw-r--r--  2.0 unx    13923 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/json_dumper.py
--rw-r--r--  2.0 unx    20960 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/json_loader.py
--rw-r--r--  2.0 unx     6182 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/loader_base.py
+-rw-r--r--  2.0 unx      349 b- defN 23-Apr-25 11:23 laboneq/compiler/experiment_access/device_info.py
+-rw-r--r--  2.0 unx    44686 b- defN 23-Apr-25 11:23 laboneq/compiler/experiment_access/dsl_loader.py
+-rw-r--r--  2.0 unx    16529 b- defN 23-Apr-25 11:23 laboneq/compiler/experiment_access/experiment_dao.py
+-rw-r--r--  2.0 unx    14106 b- defN 23-Apr-25 11:23 laboneq/compiler/experiment_access/json_dumper.py
+-rw-r--r--  2.0 unx    21004 b- defN 23-Apr-25 11:23 laboneq/compiler/experiment_access/json_loader.py
+-rw-r--r--  2.0 unx     6182 b- defN 23-Apr-25 11:23 laboneq/compiler/experiment_access/loader_base.py
 -rw-r--r--  2.0 unx      270 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/marker.py
--rw-r--r--  2.0 unx      260 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/oscillator_info.py
+-rw-r--r--  2.0 unx      286 b- defN 23-Apr-25 11:23 laboneq/compiler/experiment_access/oscillator_info.py
 -rw-r--r--  2.0 unx      197 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/param_ref.py
 -rw-r--r--  2.0 unx     1263 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/pulse_def.py
 -rw-r--r--  2.0 unx    21550 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/section_graph.py
 -rw-r--r--  2.0 unx      851 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/section_info.py
 -rw-r--r--  2.0 unx     1069 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/section_signal_pulse.py
 -rw-r--r--  2.0 unx      387 b- defN 23-Apr-06 14:15 laboneq/compiler/experiment_access/signal_info.py
--rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 14:48 laboneq/compiler/new_scheduler/__init__.py
--rw-r--r--  2.0 unx     3269 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/case_schedule.py
--rw-r--r--  2.0 unx     7443 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/interval_schedule.py
--rw-r--r--  2.0 unx     3331 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/loop_iteration_schedule.py
--rw-r--r--  2.0 unx     8588 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/loop_schedule.py
--rw-r--r--  2.0 unx     7197 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/match_schedule.py
--rw-r--r--  2.0 unx     2252 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/oscillator_schedule.py
--rw-r--r--  2.0 unx     1765 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/phase_reset_schedule.py
+-rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 14:57 laboneq/compiler/new_scheduler/__init__.py
+-rw-r--r--  2.0 unx     3269 b- defN 23-Apr-25 11:23 laboneq/compiler/new_scheduler/case_schedule.py
+-rw-r--r--  2.0 unx     7443 b- defN 23-Apr-25 11:23 laboneq/compiler/new_scheduler/interval_schedule.py
+-rw-r--r--  2.0 unx     3331 b- defN 23-Apr-25 11:23 laboneq/compiler/new_scheduler/loop_iteration_schedule.py
+-rw-r--r--  2.0 unx     8588 b- defN 23-Apr-25 11:23 laboneq/compiler/new_scheduler/loop_schedule.py
+-rw-r--r--  2.0 unx     8075 b- defN 23-Apr-25 11:23 laboneq/compiler/new_scheduler/match_schedule.py
+-rw-r--r--  2.0 unx     2252 b- defN 23-Apr-25 11:23 laboneq/compiler/new_scheduler/oscillator_schedule.py
+-rw-r--r--  2.0 unx     1765 b- defN 23-Apr-25 11:23 laboneq/compiler/new_scheduler/phase_reset_schedule.py
 -rw-r--r--  2.0 unx     1820 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/preorder_map.py
 -rw-r--r--  2.0 unx     3821 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/pulse_phase.py
--rw-r--r--  2.0 unx     6962 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/pulse_schedule.py
--rw-r--r--  2.0 unx      625 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/reserve_schedule.py
--rw-r--r--  2.0 unx     1375 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/root_schedule.py
--rw-r--r--  2.0 unx     1016 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/schedule_data.py
--rw-r--r--  2.0 unx    39737 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/scheduler.py
--rw-r--r--  2.0 unx    13207 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/section_schedule.py
--rw-r--r--  2.0 unx      757 b- defN 23-Apr-06 14:15 laboneq/compiler/new_scheduler/utils.py
+-rw-r--r--  2.0 unx     6962 b- defN 23-Apr-25 11:23 laboneq/compiler/new_scheduler/pulse_schedule.py
+-rw-r--r--  2.0 unx      625 b- defN 23-Apr-25 11:23 laboneq/compiler/new_scheduler/reserve_schedule.py
+-rw-r--r--  2.0 unx     1375 b- defN 23-Apr-25 11:23 laboneq/compiler/new_scheduler/root_schedule.py
+-rw-r--r--  2.0 unx     1016 b- defN 23-Apr-25 11:23 laboneq/compiler/new_scheduler/schedule_data.py
+-rw-r--r--  2.0 unx    40991 b- defN 23-Apr-25 11:23 laboneq/compiler/new_scheduler/scheduler.py
+-rw-r--r--  2.0 unx    13207 b- defN 23-Apr-25 11:23 laboneq/compiler/new_scheduler/section_schedule.py
+-rw-r--r--  2.0 unx      757 b- defN 23-Apr-25 11:23 laboneq/compiler/new_scheduler/utils.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/compiler/scheduler/__init__.py
 -rw-r--r--  2.0 unx    12943 b- defN 23-Apr-06 14:15 laboneq/compiler/scheduler/event_graph.py
 -rw-r--r--  2.0 unx    24682 b- defN 23-Feb-02 07:13 laboneq/compiler/scheduler/event_graph_builder.py
--rw-r--r--  2.0 unx     1949 b- defN 23-Feb-09 09:38 laboneq/compiler/scheduler/sampling_rate_tracker.py
--rw-r--r--  2.0 unx   115572 b- defN 23-Apr-06 14:15 laboneq/compiler/scheduler/scheduler.py
+-rw-r--r--  2.0 unx     1949 b- defN 23-Feb-09 09:31 laboneq/compiler/scheduler/sampling_rate_tracker.py
+-rw-r--r--  2.0 unx   115572 b- defN 23-Apr-25 11:23 laboneq/compiler/scheduler/scheduler.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/compiler/workflow/__init__.py
--rw-r--r--  2.0 unx    48911 b- defN 23-Apr-06 14:15 laboneq/compiler/workflow/compiler.py
+-rw-r--r--  2.0 unx    49793 b- defN 23-Apr-25 11:23 laboneq/compiler/workflow/compiler.py
 -rw-r--r--  2.0 unx    12424 b- defN 23-Feb-28 13:10 laboneq/compiler/workflow/precompensation_helpers.py
--rw-r--r--  2.0 unx    11747 b- defN 23-Apr-06 14:15 laboneq/compiler/workflow/recipe_generator.py
+-rw-r--r--  2.0 unx    12229 b- defN 23-Apr-25 11:23 laboneq/compiler/workflow/recipe_generator.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/__init__.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/bloch_simulator_pulse_plotter/__init__.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/bloch_simulator_pulse_plotter/inspector/__init__.py
 -rw-r--r--  2.0 unx     4511 b- defN 23-Apr-06 14:15 laboneq/contrib/bloch_simulator_pulse_plotter/inspector/update_inspect.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/bloch_simulator_pulse_plotter/plotter/__init__.py
 -rw-r--r--  2.0 unx     3379 b- defN 23-Apr-06 14:15 laboneq/contrib/bloch_simulator_pulse_plotter/plotter/plot_funs.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/bloch_simulator_pulse_plotter/pulse_simulator/__init__.py
@@ -95,147 +95,156 @@
 -rw-r--r--  2.0 unx     3581 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/qubit_helper.py
 -rw-r--r--  2.0 unx     8830 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/randomized_benchmarking_helper.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/data_analysis/__init__.py
 -rw-r--r--  2.0 unx     6670 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/data_analysis/data_analysis.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/descriptors/__init__.py
 -rw-r--r--  2.0 unx      502 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/descriptors/hdawg.py
 -rw-r--r--  2.0 unx      956 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/descriptors/hdawg_uhfqa_pqsc.py
--rw-r--r--  2.0 unx     1345 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/descriptors/shfqc.py
--rw-r--r--  2.0 unx     1377 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/descriptors/shfsg.py
--rw-r--r--  2.0 unx     1930 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_hdawg_pqsc.py
--rw-r--r--  2.0 unx     1618 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_pqsc.py
--rw-r--r--  2.0 unx     2383 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_shfqc_hdawg_pqsc.py
+-rw-r--r--  2.0 unx     1345 b- defN 23-Apr-26 08:59 laboneq/contrib/example_helpers/descriptors/shfqc.py
+-rw-r--r--  2.0 unx     1377 b- defN 23-Apr-26 08:59 laboneq/contrib/example_helpers/descriptors/shfsg.py
+-rw-r--r--  2.0 unx     1930 b- defN 23-Apr-26 08:59 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_hdawg_pqsc.py
+-rw-r--r--  2.0 unx     1618 b- defN 23-Apr-26 08:59 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_pqsc.py
+-rw-r--r--  2.0 unx     2383 b- defN 23-Apr-26 08:59 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_shfqc_hdawg_pqsc.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Apr-06 14:15 laboneq/contrib/example_helpers/plotting/__init__.py
--rw-r--r--  2.0 unx     6620 b- defN 23-Apr-06 15:01 laboneq/contrib/example_helpers/plotting/plot_helpers.py
+-rw-r--r--  2.0 unx     6620 b- defN 23-Apr-27 08:13 laboneq/contrib/example_helpers/plotting/plot_helpers.py
 -rw-r--r--  2.0 unx      308 b- defN 23-Feb-13 10:57 laboneq/controller/__init__.py
 -rw-r--r--  2.0 unx     1479 b- defN 23-Feb-02 07:13 laboneq/controller/cache.py
--rw-r--r--  2.0 unx    14819 b- defN 23-Apr-13 09:53 laboneq/controller/communication.py
--rw-r--r--  2.0 unx    33283 b- defN 23-Apr-13 09:53 laboneq/controller/controller.py
+-rw-r--r--  2.0 unx    13536 b- defN 23-Apr-25 11:23 laboneq/controller/communication.py
+-rw-r--r--  2.0 unx    32890 b- defN 23-Apr-25 11:23 laboneq/controller/controller.py
 -rw-r--r--  2.0 unx     4504 b- defN 23-Apr-06 14:15 laboneq/controller/laboneq_logging.py
 -rw-r--r--  2.0 unx      337 b- defN 23-Feb-02 07:13 laboneq/controller/protected_session.py
--rw-r--r--  2.0 unx    14870 b- defN 23-Apr-06 14:15 laboneq/controller/recipe_1_4_0.py
+-rw-r--r--  2.0 unx    15011 b- defN 23-Apr-25 11:23 laboneq/controller/recipe_1_4_0.py
 -rw-r--r--  2.0 unx      638 b- defN 23-Feb-02 07:13 laboneq/controller/recipe_enums.py
--rw-r--r--  2.0 unx    19575 b- defN 23-Apr-06 14:15 laboneq/controller/recipe_processor.py
+-rw-r--r--  2.0 unx    19876 b- defN 23-Apr-25 11:23 laboneq/controller/recipe_processor.py
 -rw-r--r--  2.0 unx     1917 b- defN 23-Feb-02 07:13 laboneq/controller/results.py
 -rw-r--r--  2.0 unx     1594 b- defN 23-Feb-13 10:57 laboneq/controller/toolkit_adapter.py
 -rw-r--r--  2.0 unx      624 b- defN 23-Apr-06 14:15 laboneq/controller/util.py
 -rw-r--r--  2.0 unx      281 b- defN 23-Mar-07 07:28 laboneq/controller/versioning.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/controller/devices/__init__.py
--rw-r--r--  2.0 unx    15231 b- defN 23-Apr-13 09:53 laboneq/controller/devices/device_collection.py
--rw-r--r--  2.0 unx     1173 b- defN 23-Feb-13 10:57 laboneq/controller/devices/device_factory.py
--rw-r--r--  2.0 unx    23560 b- defN 23-Apr-06 14:15 laboneq/controller/devices/device_hdawg.py
--rw-r--r--  2.0 unx     1234 b- defN 23-Feb-13 10:57 laboneq/controller/devices/device_nonqc.py
--rw-r--r--  2.0 unx     8260 b- defN 23-Apr-06 14:15 laboneq/controller/devices/device_pqsc.py
--rw-r--r--  2.0 unx     2830 b- defN 23-Apr-06 14:15 laboneq/controller/devices/device_setup_dao.py
--rw-r--r--  2.0 unx    40121 b- defN 23-Apr-06 14:15 laboneq/controller/devices/device_shfqa.py
--rw-r--r--  2.0 unx    20516 b- defN 23-Apr-06 14:15 laboneq/controller/devices/device_shfsg.py
--rw-r--r--  2.0 unx    28707 b- defN 23-Apr-06 14:15 laboneq/controller/devices/device_uhfqa.py
--rw-r--r--  2.0 unx    42463 b- defN 23-Apr-13 09:53 laboneq/controller/devices/device_zi.py
--rw-r--r--  2.0 unx    30874 b- defN 23-Apr-13 09:53 laboneq/controller/devices/zi_emulator.py
--rw-r--r--  2.0 unx     9837 b- defN 23-Apr-06 14:15 laboneq/controller/devices/zi_node_monitor.py
+-rw-r--r--  2.0 unx    15400 b- defN 23-Apr-26 08:59 laboneq/controller/devices/device_collection.py
+-rw-r--r--  2.0 unx     1275 b- defN 23-Apr-25 11:23 laboneq/controller/devices/device_factory.py
+-rw-r--r--  2.0 unx    23542 b- defN 23-Apr-26 08:59 laboneq/controller/devices/device_hdawg.py
+-rw-r--r--  2.0 unx      491 b- defN 23-Apr-25 11:23 laboneq/controller/devices/device_nonqc.py
+-rw-r--r--  2.0 unx     8115 b- defN 23-Apr-26 08:59 laboneq/controller/devices/device_pqsc.py
+-rw-r--r--  2.0 unx     4137 b- defN 23-Apr-26 08:59 laboneq/controller/devices/device_setup_dao.py
+-rw-r--r--  2.0 unx     3758 b- defN 23-Apr-25 11:23 laboneq/controller/devices/device_shfppc.py
+-rw-r--r--  2.0 unx    40101 b- defN 23-Apr-26 08:59 laboneq/controller/devices/device_shfqa.py
+-rw-r--r--  2.0 unx    20509 b- defN 23-Apr-26 08:59 laboneq/controller/devices/device_shfsg.py
+-rw-r--r--  2.0 unx    28521 b- defN 23-Apr-26 08:59 laboneq/controller/devices/device_uhfqa.py
+-rw-r--r--  2.0 unx    36707 b- defN 23-Apr-26 08:59 laboneq/controller/devices/device_zi.py
+-rw-r--r--  2.0 unx    29590 b- defN 23-Apr-25 11:23 laboneq/controller/devices/zi_emulator.py
+-rw-r--r--  2.0 unx    10358 b- defN 23-Apr-26 08:59 laboneq/controller/devices/zi_node_monitor.py
 -rw-r--r--  2.0 unx       97 b- defN 23-Feb-02 07:13 laboneq/core/__init__.py
--rw-r--r--  2.0 unx     1998 b- defN 23-Feb-02 07:13 laboneq/core/path.py
+-rw-r--r--  2.0 unx     2015 b- defN 23-Apr-26 08:59 laboneq/core/path.py
 -rw-r--r--  2.0 unx     1338 b- defN 23-Feb-02 07:13 laboneq/core/validators.py
 -rw-r--r--  2.0 unx      126 b- defN 23-Feb-02 07:13 laboneq/core/exceptions/__init__.py
 -rw-r--r--  2.0 unx      123 b- defN 23-Feb-02 07:13 laboneq/core/exceptions/laboneq_exception.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/core/serialization/__init__.py
 -rw-r--r--  2.0 unx    19090 b- defN 23-Apr-06 14:15 laboneq/core/serialization/simple_serialization.py
 -rw-r--r--  2.0 unx      161 b- defN 23-Feb-02 07:13 laboneq/core/types/__init__.py
 -rw-r--r--  2.0 unx     5138 b- defN 23-Feb-28 13:10 laboneq/core/types/compiled_experiment.py
 -rw-r--r--  2.0 unx     1473 b- defN 23-Feb-02 07:13 laboneq/core/types/uid.py
 -rw-r--r--  2.0 unx      660 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/__init__.py
--rw-r--r--  2.0 unx      934 b- defN 23-Feb-07 17:52 laboneq/core/types/enums/acquisition_type.py
+-rw-r--r--  2.0 unx      934 b- defN 23-Feb-07 16:25 laboneq/core/types/enums/acquisition_type.py
 -rw-r--r--  2.0 unx      213 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/averaging_mode.py
 -rw-r--r--  2.0 unx      188 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/carrier_type.py
 -rw-r--r--  2.0 unx      227 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/dsl_version.py
 -rw-r--r--  2.0 unx      185 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/execution_type.py
 -rw-r--r--  2.0 unx      223 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/high_pass_compensation_clearing.py
 -rw-r--r--  2.0 unx      157 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/io_direction.py
--rw-r--r--  2.0 unx      252 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/io_signal_type.py
+-rw-r--r--  2.0 unx      268 b- defN 23-Apr-25 11:23 laboneq/core/types/enums/io_signal_type.py
 -rw-r--r--  2.0 unx      316 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/mixer_type.py
 -rw-r--r--  2.0 unx      200 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/modulation_type.py
 -rw-r--r--  2.0 unx      152 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/port_mode.py
 -rw-r--r--  2.0 unx      188 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/reference_clock_source.py
 -rw-r--r--  2.0 unx      198 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/repetition_mode.py
 -rw-r--r--  2.0 unx      170 b- defN 23-Feb-02 07:13 laboneq/core/types/enums/section_alignment.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/core/utilities/__init__.py
 -rw-r--r--  2.0 unx     8039 b- defN 23-Apr-06 14:15 laboneq/core/utilities/pulse_sampler.py
 -rw-r--r--  2.0 unx     9808 b- defN 23-Apr-06 14:15 laboneq/core/utilities/replace_pulse.py
 -rw-r--r--  2.0 unx      178 b- defN 23-Feb-02 07:13 laboneq/dsl/__init__.py
--rw-r--r--  2.0 unx     2929 b- defN 23-Apr-06 14:15 laboneq/dsl/laboneq_facade.py
+-rw-r--r--  2.0 unx     2929 b- defN 23-Apr-25 11:23 laboneq/dsl/laboneq_facade.py
 -rw-r--r--  2.0 unx     2552 b- defN 23-Feb-15 13:56 laboneq/dsl/parameter.py
--rw-r--r--  2.0 unx    25670 b- defN 23-Apr-06 14:15 laboneq/dsl/session.py
+-rw-r--r--  2.0 unx    25670 b- defN 23-Apr-25 11:23 laboneq/dsl/session.py
 -rw-r--r--  2.0 unx     2296 b- defN 23-Feb-02 07:13 laboneq/dsl/utils.py
--rw-r--r--  2.0 unx      487 b- defN 23-Feb-02 07:13 laboneq/dsl/calibration/__init__.py
+-rw-r--r--  2.0 unx      529 b- defN 23-Apr-25 11:23 laboneq/dsl/calibration/__init__.py
+-rw-r--r--  2.0 unx     1017 b- defN 23-Apr-25 11:23 laboneq/dsl/calibration/amplifier_pump.py
 -rw-r--r--  2.0 unx      545 b- defN 23-Feb-02 07:13 laboneq/dsl/calibration/calibratable.py
--rw-r--r--  2.0 unx     1886 b- defN 23-Feb-02 07:13 laboneq/dsl/calibration/calibration.py
+-rw-r--r--  2.0 unx     1886 b- defN 23-Apr-25 16:53 laboneq/dsl/calibration/calibration.py
 -rw-r--r--  2.0 unx      111 b- defN 23-Feb-02 07:13 laboneq/dsl/calibration/calibration_item.py
 -rw-r--r--  2.0 unx      992 b- defN 23-Feb-27 16:33 laboneq/dsl/calibration/mixer_calibration.py
 -rw-r--r--  2.0 unx     3403 b- defN 23-Feb-02 07:13 laboneq/dsl/calibration/observable.py
 -rw-r--r--  2.0 unx     1716 b- defN 23-Feb-27 16:33 laboneq/dsl/calibration/oscillator.py
 -rw-r--r--  2.0 unx     2650 b- defN 23-Feb-27 16:33 laboneq/dsl/calibration/precompensation.py
--rw-r--r--  2.0 unx     5363 b- defN 23-Feb-27 16:33 laboneq/dsl/calibration/signal_calibration.py
+-rw-r--r--  2.0 unx     5607 b- defN 23-Apr-25 11:23 laboneq/dsl/calibration/signal_calibration.py
 -rw-r--r--  2.0 unx      553 b- defN 23-Feb-02 07:13 laboneq/dsl/calibration/units.py
 -rw-r--r--  2.0 unx      363 b- defN 23-Feb-02 07:13 laboneq/dsl/device/__init__.py
--rw-r--r--  2.0 unx    42448 b- defN 23-Apr-06 14:15 laboneq/dsl/device/_device_setup_generator.py
+-rw-r--r--  2.0 unx    45826 b- defN 23-Apr-25 11:23 laboneq/dsl/device/_device_setup_generator.py
 -rw-r--r--  2.0 unx      601 b- defN 23-Feb-02 07:13 laboneq/dsl/device/connection.py
--rw-r--r--  2.0 unx    11946 b- defN 23-Apr-13 09:53 laboneq/dsl/device/device_setup.py
+-rw-r--r--  2.0 unx    13663 b- defN 23-Apr-26 08:59 laboneq/dsl/device/device_setup.py
 -rw-r--r--  2.0 unx     2551 b- defN 23-Apr-06 14:15 laboneq/dsl/device/device_setup_helper.py
--rw-r--r--  2.0 unx     1296 b- defN 23-Feb-02 07:13 laboneq/dsl/device/instrument.py
+-rw-r--r--  2.0 unx     1362 b- defN 23-Apr-26 08:59 laboneq/dsl/device/instrument.py
 -rw-r--r--  2.0 unx     1893 b- defN 23-Feb-02 07:13 laboneq/dsl/device/logical_signal_group.py
 -rw-r--r--  2.0 unx     1729 b- defN 23-Feb-02 07:13 laboneq/dsl/device/physical_channel_group.py
 -rw-r--r--  2.0 unx      538 b- defN 23-Feb-02 07:13 laboneq/dsl/device/ports.py
--rw-r--r--  2.0 unx     4312 b- defN 23-Apr-13 09:47 laboneq/dsl/device/qubits.py
+-rw-r--r--  2.0 unx     4453 b- defN 23-Apr-27 08:13 laboneq/dsl/device/qubits.py
 -rw-r--r--  2.0 unx      215 b- defN 23-Feb-02 07:13 laboneq/dsl/device/server.py
--rw-r--r--  2.0 unx      291 b- defN 23-Feb-13 10:57 laboneq/dsl/device/instruments/__init__.py
+-rw-r--r--  2.0 unx      328 b- defN 23-Apr-25 11:23 laboneq/dsl/device/instruments/__init__.py
 -rw-r--r--  2.0 unx     1778 b- defN 23-Feb-02 07:13 laboneq/dsl/device/instruments/hdawg.py
 -rw-r--r--  2.0 unx      466 b- defN 23-Feb-13 10:57 laboneq/dsl/device/instruments/nonqc.py
 -rw-r--r--  2.0 unx      948 b- defN 23-Feb-02 07:13 laboneq/dsl/device/instruments/pqsc.py
--rw-r--r--  2.0 unx     2248 b- defN 23-Feb-06 16:30 laboneq/dsl/device/instruments/shfqa.py
--rw-r--r--  2.0 unx     1659 b- defN 23-Feb-06 16:30 laboneq/dsl/device/instruments/shfsg.py
+-rw-r--r--  2.0 unx      927 b- defN 23-Apr-25 11:23 laboneq/dsl/device/instruments/shfppc.py
+-rw-r--r--  2.0 unx     2248 b- defN 23-Feb-06 17:42 laboneq/dsl/device/instruments/shfqa.py
+-rw-r--r--  2.0 unx     1659 b- defN 23-Feb-06 17:42 laboneq/dsl/device/instruments/shfsg.py
 -rw-r--r--  2.0 unx     2312 b- defN 23-Feb-16 12:45 laboneq/dsl/device/instruments/uhfqa.py
 -rw-r--r--  2.0 unx      888 b- defN 23-Feb-13 10:57 laboneq/dsl/device/instruments/zi_standard_instrument.py
 -rw-r--r--  2.0 unx      187 b- defN 23-Feb-02 07:13 laboneq/dsl/device/io_units/__init__.py
--rw-r--r--  2.0 unx    12288 b- defN 23-Apr-06 14:15 laboneq/dsl/device/io_units/logical_signal.py
--rw-r--r--  2.0 unx     3608 b- defN 23-Feb-02 07:13 laboneq/dsl/device/io_units/physical_channel.py
+-rw-r--r--  2.0 unx    12750 b- defN 23-Apr-25 11:23 laboneq/dsl/device/io_units/logical_signal.py
+-rw-r--r--  2.0 unx     3811 b- defN 23-Apr-26 08:59 laboneq/dsl/device/io_units/physical_channel.py
 -rw-r--r--  2.0 unx      114 b- defN 23-Feb-02 07:13 laboneq/dsl/device/servers/__init__.py
 -rw-r--r--  2.0 unx      704 b- defN 23-Feb-02 07:13 laboneq/dsl/device/servers/data_server.py
 -rw-r--r--  2.0 unx      718 b- defN 23-Feb-02 07:13 laboneq/dsl/enums/__init__.py
 -rw-r--r--  2.0 unx      508 b- defN 23-Feb-02 07:13 laboneq/dsl/experiment/__init__.py
 -rw-r--r--  2.0 unx      972 b- defN 23-Feb-02 07:13 laboneq/dsl/experiment/acquire.py
 -rw-r--r--  2.0 unx      814 b- defN 23-Feb-02 07:13 laboneq/dsl/experiment/call.py
 -rw-r--r--  2.0 unx      780 b- defN 23-Feb-02 07:13 laboneq/dsl/experiment/delay.py
--rw-r--r--  2.0 unx    41433 b- defN 23-Apr-06 15:01 laboneq/dsl/experiment/experiment.py
--rw-r--r--  2.0 unx     7754 b- defN 23-Apr-06 14:15 laboneq/dsl/experiment/experiment_signal.py
+-rw-r--r--  2.0 unx    39779 b- defN 23-Apr-25 11:23 laboneq/dsl/experiment/experiment.py
+-rw-r--r--  2.0 unx     8216 b- defN 23-Apr-25 11:23 laboneq/dsl/experiment/experiment_signal.py
 -rw-r--r--  2.0 unx      401 b- defN 23-Feb-02 07:13 laboneq/dsl/experiment/operation.py
 -rw-r--r--  2.0 unx     1647 b- defN 23-Feb-28 13:10 laboneq/dsl/experiment/play_pulse.py
 -rw-r--r--  2.0 unx     3568 b- defN 23-Apr-03 11:23 laboneq/dsl/experiment/pulse.py
 -rw-r--r--  2.0 unx     7932 b- defN 23-Mar-13 15:23 laboneq/dsl/experiment/pulse_library.py
 -rw-r--r--  2.0 unx      890 b- defN 23-Feb-16 12:45 laboneq/dsl/experiment/reserve.py
--rw-r--r--  2.0 unx    11366 b- defN 23-Feb-28 13:10 laboneq/dsl/experiment/section.py
+-rw-r--r--  2.0 unx    11431 b- defN 23-Apr-25 11:23 laboneq/dsl/experiment/section.py
 -rw-r--r--  2.0 unx      640 b- defN 23-Feb-02 07:13 laboneq/dsl/experiment/set.py
--rw-r--r--  2.0 unx      151 b- defN 23-Feb-14 14:41 laboneq/dsl/result/__init__.py
+-rw-r--r--  2.0 unx      323 b- defN 23-Apr-25 11:23 laboneq/dsl/experiment/utils.py
+-rw-r--r--  2.0 unx      151 b- defN 23-Feb-14 15:16 laboneq/dsl/result/__init__.py
 -rw-r--r--  2.0 unx     1766 b- defN 23-Feb-02 07:13 laboneq/dsl/result/acquired_result.py
 -rw-r--r--  2.0 unx     7240 b- defN 23-Feb-02 07:13 laboneq/dsl/result/results.py
 -rw-r--r--  2.0 unx      113 b- defN 23-Feb-02 07:13 laboneq/dsl/serialization/__init__.py
--rw-r--r--  2.0 unx     5243 b- defN 23-Feb-27 13:39 laboneq/dsl/serialization/serializer.py
+-rw-r--r--  2.0 unx     5339 b- defN 23-Apr-27 08:13 laboneq/dsl/serialization/serializer.py
 -rw-r--r--  2.0 unx       77 b- defN 23-Feb-02 07:13 laboneq/executor/__init__.py
 -rw-r--r--  2.0 unx     3819 b- defN 23-Feb-16 12:45 laboneq/executor/execution_from_experiment.py
 -rw-r--r--  2.0 unx     8152 b- defN 23-Apr-06 14:15 laboneq/executor/executor.py
--rw-r--r--  2.0 unx      145 b- defN 23-Feb-14 14:41 laboneq/openqasm3/__init__.py
--rw-r--r--  2.0 unx    10897 b- defN 23-Feb-16 12:45 laboneq/openqasm3/openqasm3_importer.py
+-rw-r--r--  2.0 unx      145 b- defN 23-Feb-14 15:16 laboneq/openqasm3/__init__.py
+-rw-r--r--  2.0 unx     2488 b- defN 23-Apr-27 08:13 laboneq/openqasm3/expression.py
+-rw-r--r--  2.0 unx     1929 b- defN 23-Apr-27 08:13 laboneq/openqasm3/gate_store.py
+-rw-r--r--  2.0 unx    10789 b- defN 23-Apr-27 08:13 laboneq/openqasm3/openqasm3_importer.py
+-rw-r--r--  2.0 unx     1732 b- defN 23-Apr-25 11:23 laboneq/openqasm3/openqasm_error.py
+-rw-r--r--  2.0 unx     5136 b- defN 23-Apr-27 08:13 laboneq/openqasm3/reset_gate_factory.py
+-rw-r--r--  2.0 unx     3069 b- defN 23-Apr-27 08:13 laboneq/openqasm3/variable_store.py
 -rw-r--r--  2.0 unx      127 b- defN 23-Feb-02 07:13 laboneq/pulse_sheet_viewer/__init__.py
 -rw-r--r--  2.0 unx     2059 b- defN 23-Feb-16 12:45 laboneq/pulse_sheet_viewer/event_graph_viewer.py
 -rw-r--r--  2.0 unx     2692 b- defN 23-Feb-02 14:48 laboneq/pulse_sheet_viewer/interactive_psv.py
 -rw-r--r--  2.0 unx     3288 b- defN 23-Feb-02 14:48 laboneq/pulse_sheet_viewer/pulse_sheet_viewer.py
 -rw-rw-rw-  2.0 unx  1443040 b- defN 23-Apr-06 14:15 laboneq/pulse_sheet_viewer/pulse_sheet_viewer_template.html
--rw-r--r--  2.0 unx      152 b- defN 23-Feb-14 14:41 laboneq/simulator/__init__.py
+-rw-r--r--  2.0 unx      152 b- defN 23-Feb-14 15:16 laboneq/simulator/__init__.py
 -rw-r--r--  2.0 unx     5904 b- defN 23-Feb-02 14:48 laboneq/simulator/output_simulator.py
--rw-r--r--  2.0 unx    39230 b- defN 23-Apr-06 14:15 laboneq/simulator/seqc_parser.py
+-rw-r--r--  2.0 unx    39230 b- defN 23-Apr-25 11:23 laboneq/simulator/seqc_parser.py
 -rw-r--r--  2.0 unx    12081 b- defN 23-Apr-06 14:15 laboneq/simulator/wave_scroller.py
--rw-rw-rw-  2.0 unx       22 b- defN 23-Apr-13 09:53 laboneq-2.4.0.dist-info/AUTHORS
--rw-rw-rw-  2.0 unx    11358 b- defN 23-Apr-13 09:53 laboneq-2.4.0.dist-info/LICENSE
--rw-r--r--  2.0 unx     3188 b- defN 23-Apr-13 09:53 laboneq-2.4.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Apr-13 09:53 laboneq-2.4.0.dist-info/WHEEL
--rw-r--r--  2.0 unx        8 b- defN 23-Apr-13 09:53 laboneq-2.4.0.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    23450 b- defN 23-Apr-13 09:53 laboneq-2.4.0.dist-info/RECORD
-239 files, 2962254 bytes uncompressed, 908361 bytes compressed:  69.3%
+-rw-rw-rw-  2.0 unx       22 b- defN 23-Apr-27 08:14 laboneq-2.5.0.dist-info/AUTHORS
+-rw-rw-rw-  2.0 unx    11358 b- defN 23-Apr-27 08:14 laboneq-2.5.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     3188 b- defN 23-Apr-27 08:14 laboneq-2.5.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Apr-27 08:14 laboneq-2.5.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx        8 b- defN 23-Apr-27 08:14 laboneq-2.5.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    24287 b- defN 23-Apr-27 08:14 laboneq-2.5.0.dist-info/RECORD
+248 files, 2988946 bytes uncompressed, 916406 bytes compressed:  69.4%
```

## zipnote {}

```diff
@@ -375,14 +375,17 @@
 
 Filename: laboneq/controller/devices/device_pqsc.py
 Comment: 
 
 Filename: laboneq/controller/devices/device_setup_dao.py
 Comment: 
 
+Filename: laboneq/controller/devices/device_shfppc.py
+Comment: 
+
 Filename: laboneq/controller/devices/device_shfqa.py
 Comment: 
 
 Filename: laboneq/controller/devices/device_shfsg.py
 Comment: 
 
 Filename: laboneq/controller/devices/device_uhfqa.py
@@ -495,14 +498,17 @@
 
 Filename: laboneq/dsl/utils.py
 Comment: 
 
 Filename: laboneq/dsl/calibration/__init__.py
 Comment: 
 
+Filename: laboneq/dsl/calibration/amplifier_pump.py
+Comment: 
+
 Filename: laboneq/dsl/calibration/calibratable.py
 Comment: 
 
 Filename: laboneq/dsl/calibration/calibration.py
 Comment: 
 
 Filename: laboneq/dsl/calibration/calibration_item.py
@@ -567,14 +573,17 @@
 
 Filename: laboneq/dsl/device/instruments/nonqc.py
 Comment: 
 
 Filename: laboneq/dsl/device/instruments/pqsc.py
 Comment: 
 
+Filename: laboneq/dsl/device/instruments/shfppc.py
+Comment: 
+
 Filename: laboneq/dsl/device/instruments/shfqa.py
 Comment: 
 
 Filename: laboneq/dsl/device/instruments/shfsg.py
 Comment: 
 
 Filename: laboneq/dsl/device/instruments/uhfqa.py
@@ -636,14 +645,17 @@
 
 Filename: laboneq/dsl/experiment/section.py
 Comment: 
 
 Filename: laboneq/dsl/experiment/set.py
 Comment: 
 
+Filename: laboneq/dsl/experiment/utils.py
+Comment: 
+
 Filename: laboneq/dsl/result/__init__.py
 Comment: 
 
 Filename: laboneq/dsl/result/acquired_result.py
 Comment: 
 
 Filename: laboneq/dsl/result/results.py
@@ -663,17 +675,32 @@
 
 Filename: laboneq/executor/executor.py
 Comment: 
 
 Filename: laboneq/openqasm3/__init__.py
 Comment: 
 
+Filename: laboneq/openqasm3/expression.py
+Comment: 
+
+Filename: laboneq/openqasm3/gate_store.py
+Comment: 
+
 Filename: laboneq/openqasm3/openqasm3_importer.py
 Comment: 
 
+Filename: laboneq/openqasm3/openqasm_error.py
+Comment: 
+
+Filename: laboneq/openqasm3/reset_gate_factory.py
+Comment: 
+
+Filename: laboneq/openqasm3/variable_store.py
+Comment: 
+
 Filename: laboneq/pulse_sheet_viewer/__init__.py
 Comment: 
 
 Filename: laboneq/pulse_sheet_viewer/event_graph_viewer.py
 Comment: 
 
 Filename: laboneq/pulse_sheet_viewer/interactive_psv.py
@@ -693,26 +720,26 @@
 
 Filename: laboneq/simulator/seqc_parser.py
 Comment: 
 
 Filename: laboneq/simulator/wave_scroller.py
 Comment: 
 
-Filename: laboneq-2.4.0.dist-info/AUTHORS
+Filename: laboneq-2.5.0.dist-info/AUTHORS
 Comment: 
 
-Filename: laboneq-2.4.0.dist-info/LICENSE
+Filename: laboneq-2.5.0.dist-info/LICENSE
 Comment: 
 
-Filename: laboneq-2.4.0.dist-info/METADATA
+Filename: laboneq-2.5.0.dist-info/METADATA
 Comment: 
 
-Filename: laboneq-2.4.0.dist-info/WHEEL
+Filename: laboneq-2.5.0.dist-info/WHEEL
 Comment: 
 
-Filename: laboneq-2.4.0.dist-info/top_level.txt
+Filename: laboneq-2.5.0.dist-info/top_level.txt
 Comment: 
 
-Filename: laboneq-2.4.0.dist-info/RECORD
+Filename: laboneq-2.5.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## laboneq/VERSION.txt

```diff
@@ -1 +1 @@
-2.4.0
+2.5.0
```

## laboneq/simple.py

```diff
@@ -6,14 +6,15 @@
 """
 
 from laboneq._token import install_token
 from laboneq.controller import laboneq_logging
 from laboneq.core.types.compiled_experiment import CompiledExperiment
 from laboneq.dsl import LinearSweepParameter, SweepParameter
 from laboneq.dsl.calibration import (
+    AmplifierPump,
     BounceCompensation,
     Calibratable,
     Calibration,
     ExponentialCompensation,
     FIRCompensation,
     HighPassCompensation,
     MixerCalibration,
```

## laboneq/compiler/code_generator/compressor.py

```diff
@@ -48,44 +48,47 @@
         next_seen_index = next_seen_map.get(c)
         if next_seen_index is None:
             offsets.append(None)
         else:
             offsets.append(next_seen_index - i)
         next_seen_map[c] = i
 
-    offsets = offsets[::-1]
+    offsets = reversed(offsets)
 
     runs = defaultdict(list)  # word -> List[(start, Run)]
+    best_run = None
+    best_run_start, best_run_end = None, None
+    best_cost = 0
     for index, offset in enumerate(offsets):
+        if best_run_end is not None and index > best_run_end:
+            # the remainder of the plaintext will be handled in tail recursion below
+            break
         if offset is None:
             continue
         word = tuple(plaintext[index : index + offset])
         if any(start < index <= start + r.span for start, r in runs[word]):
             continue
 
         run_length = 1
         while index + (run_length + 1) * offset <= len(plaintext) and word == tuple(
             plaintext[index + run_length * offset : index + (run_length + 1) * offset]
         ):
             run_length += 1
-        runs[word].append((index, Run(word, run_length)))
+        this_run = Run(word, run_length)
+        runs[word].append((index, this_run))
+        this_cost = cost_function(this_run)
+        if this_cost < best_cost:
+            best_run = this_run
+            best_cost = this_cost
+            best_run_start, best_run_end = index, index + best_run.span
 
-    runs_flat = [(start, run) for run_list in runs.values() for start, run in run_list]
-
-    if len(runs_flat) == 0:
-        return plaintext
-
-    runs_flat.sort(key=lambda x: cost_function(x[1]))
-    best_run_start, best_run = runs_flat[0]
-    best_run_end = best_run_start + best_run.span
-
-    if cost_function(best_run) > 0:
+    if best_run is None:
         return plaintext
 
     if recurse:
         best_run.word = compressor_core(best_run.word, cost_function, recurse)
 
     return [
-        *compressor_core(plaintext[:best_run_start], cost_function, recurse),
+        *plaintext[:best_run_start],
         best_run,
         *compressor_core(plaintext[best_run_end:], cost_function, recurse),
     ]
```

## laboneq/compiler/code_generator/seq_c_generator.py

```diff
@@ -490,9 +490,12 @@
                 retval.add_repeat(cg.count, body.compressed())
             else:
                 retval.append_statements_from(generator_by_hash[cg])
 
         # optional: we might add a 2nd pass here on the merged generator, finding patterns
         # that partially span across multiple of the original parts.
         # retval = retval.compressed()
+    else:
+        for g in generators:
+            retval.append_statements_from(g)
 
     return retval
```

## laboneq/compiler/common/device_type.py

```diff
@@ -1,12 +1,13 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from dataclasses import asdict, dataclass
 from enum import Enum
+from typing import Optional
 
 
 @dataclass(eq=True, frozen=True)
 class DeviceTraits:
     str_value: str
     sampling_rate: float
     min_play_wave: int
@@ -19,14 +20,15 @@
     supports_precompensation: bool
     channels_per_awg: int
     sampling_rate_2GHz: float = None
     num_integration_units_per_acquire_signal: int = None
     oscillator_set_latency: float = 0.0
     reset_osc_duration: float = 0.0
     supports_oscillator_switching: bool = False
+    lo_frequency_granularity: Optional[float] = None
 
 
 class DeviceType(DeviceTraits, Enum):
     def __new__(cls, value: DeviceTraits):
         # This is needed to ensure DeviceType(<str_value>) resolves to the corresponding enum
         obj = object.__new__(cls)
         obj._value_ = value.str_value
@@ -92,14 +94,15 @@
         supports_digital_iq_modulation=False,
         supports_precompensation=False,
         channels_per_awg=1,
         num_integration_units_per_acquire_signal=1,
         oscillator_set_latency=88e-9,
         # Verified by PW (2022-10-13) on dev12093, rev 68689. Observed ~50 ns.
         reset_osc_duration=56e-9,
+        lo_frequency_granularity=100e6,
         supports_oscillator_switching=False,
     )
     SHFSG = DeviceTraits(
         str_value="shfsg",
         sampling_rate=2.0e9,
         min_play_wave=32,
         sample_multiple=16,
@@ -110,13 +113,14 @@
         supports_digital_iq_modulation=True,
         supports_precompensation=False,
         channels_per_awg=1,
         oscillator_set_latency=88e-9,
         # todo (PW): exact worst-case runtime unknown.
         # Verified by PW (2022-10-13) on dev12117, rev 68689. Observed ~35 ns.
         reset_osc_duration=56e-9,
+        lo_frequency_granularity=100e6,
         supports_oscillator_switching=True,
     )
 
     def __repr__(self):
         cls_name = self.__class__.__name__
         return f"{cls_name}.{self.name}"
```

## laboneq/compiler/common/signal_obj.py

```diff
@@ -15,36 +15,44 @@
 
 @dataclass(init=True, repr=True, order=True)
 class SignalObj:
     """A collection of a signal's properties relevant for code generation. The delay
     fields are in seconds and their meaning is as follows:
     - start_delay: the delay from the trigger to the start of the sequence (lead time),
       realized as initial playZeros; includes lead time and precompensation
-    - delay_signal: user-defined additional delay, realized by adding to the initial
+    - delay_signal: user-defined additional delays, realized by adding to the initial
       playZeros; rounded to the sequencer grid (sample_multiple)
+    - base_delay_signal: in case of an acquisition pulse, the delay_signal of the
+      corresponding measure pulse on the same AWG
     - total_delay: the sum of the above two fields, plus delays generated during code
       generation, e.g., relative delay between a play and acquire pulse
     - on_device_delay: delay on the device, realized by delay nodes and independent
       from the sequencer, generated during code generation, e.g., relative delay between
       a play and acquire pulse; in addition to potential port delays specified via the
-      calibration
+      calibration; a list which can contain multiple values due to the way we handle
+      acquisition delays (the delay of the measure pulse channel is added to the delay
+      of the acquire pulse channel)
     - port_delay: port delay specified via the calibration; realized via the device node
-      in addition to potential on-device delays
+      in addition to potential on-device delays.
+    - base_port_delay: in case of an acquisition pulse, the port_delay of the
+      corresponding measure pulse on the same AWG
     """
 
     id: str
     sampling_rate: float
     start_delay: float
     delay_signal: float
     signal_type: str
     device_id: str
     device_type: DeviceType
+    base_delay_signal: Optional[float] = None
     oscillator_frequency: float = None  # for software modulation only
     pulses: List = field(default_factory=list)
     channels: List = field(default_factory=list)
     awg: AWGInfo = None
     total_delay: float = None
     on_device_delay: float = 0
     port_delay: float = 0
+    base_port_delay: Optional[float] = None
     mixer_type: Optional[MixerType] = None
     hw_oscillator: Optional[str] = None
     is_qc: Optional[bool] = None
```

## laboneq/compiler/experiment_access/dsl_loader.py

```diff
@@ -4,15 +4,15 @@
 from __future__ import annotations
 
 import copy
 import logging
 import typing
 import uuid
 from types import SimpleNamespace
-from typing import Any, Callable, Dict, Tuple
+from typing import Any, Callable, Dict, Tuple, Union
 
 from laboneq.compiler.experiment_access.acquire_info import AcquireInfo
 from laboneq.compiler.experiment_access.loader_base import LoaderBase
 from laboneq.compiler.experiment_access.marker import Marker
 from laboneq.compiler.experiment_access.param_ref import ParamRef
 from laboneq.compiler.experiment_access.pulse_def import PulseDef
 from laboneq.compiler.experiment_access.section_info import SectionInfo
@@ -48,21 +48,21 @@
 
         for server in device_setup.servers.values():
             if hasattr(server, "leader_uid"):
                 global_leader_device_id = server.leader_uid
             self.add_server(server.uid, server.host, server.port, server.api_level)
 
         dest_path_devices = {}
+        ppc_connections = {}
 
         reference_clock = None
         for device in device_setup.instruments:
             if hasattr(device, "reference_clock"):
                 reference_clock = device.reference_clock
 
-        multiplexed_signals = {}
         for device in sorted(device_setup.instruments, key=lambda x: x.uid):
 
             server = device.server_uid
 
             driver = type(device).__name__.lower()
             serial = device.address
             interface = device.interface
@@ -83,14 +83,24 @@
                 reference_clock_source=None
                 if reference_clock_source is None
                 else reference_clock_source.value,
                 is_qc=is_qc,
             )
 
             for connection in device.connections:
+                if connection.signal_type == IOSignalType.PPC:
+                    port = next(
+                        p for p in device.ports if p.uid == connection.local_port
+                    )
+                    ppc_connections[connection.remote_path] = (
+                        device.uid,
+                        int(port.physical_port_ids[0]),
+                    )
+                    continue
+
                 multiplex_key = (
                     device.uid,
                     connection.local_port,
                     connection.direction.value,
                 )
 
                 if connection.remote_path in dest_path_devices:
@@ -115,30 +125,28 @@
                             connection.signal_type.value
                             if connection.signal_type is not None
                             else None
                         ],
                         "multiplex_keys": [multiplex_key],
                     }
 
-                if multiplex_key not in multiplexed_signals:
-                    multiplexed_signals[multiplex_key] = []
-                multiplexed_signals[multiplex_key].append(connection.remote_path)
-
         ls_map = {}
         modulated_paths = {}
         ls_voltage_offsets = {}
         ls_mixer_calibrations = {}
         ls_precompensations = {}
         ls_lo_frequencies = {}
         ls_ranges = {}
         ls_range_units = {}
         ls_port_delays = {}
         ls_delays_signal = {}
         ls_port_modes = {}
         ls_thresholds = {}
+        ls_amplifier_pumps = {}
+        self._nt_only_params = []
 
         all_logical_signals = [
             ls
             for lsg in device_setup.logical_signal_groups.values()
             for ls in lsg.logical_signals.values()
         ]
         for ls in all_logical_signals:
@@ -323,14 +331,50 @@
                     hasattr(calibration, "port_mode")
                     and calibration.port_mode is not None
                 ):
                     ls_port_modes[ls.path] = calibration.port_mode.value
 
                 ls_thresholds[ls.path] = getattr(calibration, "threshold", None)
 
+                def amplifier_pump_to_dict(amplifier_pump) -> Dict[str, Any]:
+                    def opt_param(val) -> Union[str, float]:
+                        if val is None or isinstance(val, float):
+                            return val
+                        self._nt_only_params.append(val.uid)
+                        return val.uid
+
+                    return {
+                        "pump_freq": opt_param(amplifier_pump.pump_freq),
+                        "pump_power": opt_param(amplifier_pump.pump_power),
+                        "cancellation": amplifier_pump.cancellation,
+                        "alc_engaged": amplifier_pump.alc_engaged,
+                        "use_probe": amplifier_pump.use_probe,
+                        "probe_frequency": opt_param(amplifier_pump.probe_frequency),
+                        "probe_power": opt_param(amplifier_pump.probe_power),
+                    }
+
+                if calibration.amplifier_pump is not None:
+                    if ls.direction != IODirection.IN:
+                        _logger.warning(
+                            "'amplifier_pump' calibration for logical signal %s will be ignored - "
+                            "only applicable to acquire lines",
+                            ls.path,
+                        )
+                    elif ls.path not in ppc_connections:
+                        _logger.warning(
+                            "'amplifier_pump' calibration for logical signal %s will be ignored - "
+                            "no PPC is connected to it",
+                            ls.path,
+                        )
+                    else:
+                        ls_amplifier_pumps[ls.path] = (
+                            *ppc_connections[ls.path],
+                            amplifier_pump_to_dict(calibration.amplifier_pump),
+                        )
+
         for signal in sorted(experiment.signals.values(), key=lambda x: x.uid):
             dev_sig_types = []
             if signal.mapped_logical_signal_path is not None:
                 dev_sig_types = dest_path_devices[signal.mapped_logical_signal_path][
                     "types"
                 ]
             signal_type = (
@@ -417,14 +461,15 @@
                     "lo_frequency": ls_lo_frequencies.get(lsuid),
                     "range": ls_ranges.get(lsuid),
                     "range_unit": ls_range_units.get(lsuid),
                     "port_delay": ls_port_delays.get(lsuid),
                     "delay_signal": ls_delays_signal.get(lsuid),
                     "port_mode": ls_port_modes.get(lsuid),
                     "threshold": ls_thresholds.get(lsuid),
+                    "amplifier_pump": ls_amplifier_pumps.get(lsuid),
                 },
             )
 
         open_inputs = {}
         for instrument in device_setup.instruments:
             for input_obj in instrument.ports:
                 if input_obj.direction == IODirection.IN:
@@ -598,14 +643,23 @@
                     count = parameter.count
                 elif hasattr(parameter, "values"):
                     count = len(parameter.values)
                 if count < 1:
                     raise Exception(
                         f"Repeat count must be at least 1, but section {section.uid} has count={count}"
                     )
+                if (
+                    section.execution_type is not None
+                    and section.execution_type.value == "hardware"
+                    and parameter.uid in self._nt_only_params
+                ):
+                    raise Exception(
+                        f"Parameter {parameter.uid} can't be swept in real-time, it is bound to a value "
+                        f"that can only be set in near-time"
+                    )
 
         execution_type = None
         if section.execution_type is not None:
             execution_type = section.execution_type.value
 
         align = "left"
         if exchanger_map(section).alignment is not None:
```

## laboneq/compiler/experiment_access/experiment_dao.py

```diff
@@ -64,14 +64,15 @@
             "lo_frequency": None,
             "range": None,
             "range_unit": None,
             "port_delay": None,
             "delay_signal": None,
             "port_mode": None,
             "threshold": None,
+            "amplifier_pump": None,
         }
 
     def _load_experiment(self, experiment):
         loader = JsonLoader()
         try:
             validator = loader.schema_validator()
             validator.validate(experiment)
@@ -99,15 +100,15 @@
 
     def server_infos(self):
         return copy.deepcopy(list(self._data["servers"].values()))
 
     def signals(self):
         return sorted([s["signal_id"] for s in self._data["signals"].values()])
 
-    def devices(self):
+    def devices(self) -> List[str]:
         return [d["id"] for d in self._data["devices"].values()]
 
     def global_leader_device(self) -> str:
         try:
             return next(
                 d for d in self._data["devices"].values() if d.get("is_global_leader")
             )["id"]
@@ -320,24 +321,24 @@
         pulse = self._data["pulses"].get(pulse_id)
         return pulse
 
     @classmethod
     def _oscillator_info_fields(cls):
         return ["id", "frequency", "frequency_param", "hardware"]
 
-    def oscillator_info(self, oscillator_id):
+    def oscillator_info(self, oscillator_id) -> OscillatorInfo:
         oscillator = self._data["oscillators"].get(oscillator_id)
         if oscillator is None:
             return None
         return OscillatorInfo(
             **{k: oscillator[k] for k in self._oscillator_info_fields()}
         )
 
-    def hardware_oscillators(self):
-        oscillator_infos = []
+    def hardware_oscillators(self) -> List[OscillatorInfo]:
+        oscillator_infos: List[OscillatorInfo] = []
         for device in self.devices():
             device_oscillators = self.device_oscillators(device)
             for oscillator_id in device_oscillators:
                 info = self.oscillator_info(oscillator_id)
                 if info is not None and info.hardware:
                     info.device_id = device
                     oscillator_infos.append(info)
@@ -380,14 +381,17 @@
 
     def port_mode(self, signal_id):
         return self._data["signal_connections"][signal_id]["port_mode"]
 
     def threshold(self, signal_id):
         return self._data["signal_connections"][signal_id]["threshold"]
 
+    def amplifier_pump(self, signal_id):
+        return self._data["signal_connections"][signal_id]["amplifier_pump"]
+
     def section_pulses(self, section_id, signal_id):
         retval = self._section_pulses_raw(section_id, signal_id)
         for sp in retval:
             pulse_id = sp.pulse_id
             if pulse_id is not None:
                 pulse_def = self._data["pulses"].get(pulse_id)
                 if pulse_def is not None:
```

## laboneq/compiler/experiment_access/json_dumper.py

```diff
@@ -177,14 +177,18 @@
         if port_delay is not None:
             signal_connection["port_delay"] = port_delay
 
         threshold = experiment_dao.threshold(signal_info.signal_id)
         if threshold is not None:
             signal_connection["threshold"] = threshold
 
+        amplifier_pump = experiment_dao.amplifier_pump(signal_info.signal_id)
+        if amplifier_pump is not None:
+            signal_connection["amplifier_pump"] = amplifier_pump
+
         delay_signal = signal_info.delay_signal
         if delay_signal is not None:
             signal_connection["delay_signal"] = delay_signal
 
         signal_connections.append(signal_connection)
 
     retval["signal_connections"] = signal_connections
```

## laboneq/compiler/experiment_access/json_loader.py

```diff
@@ -194,14 +194,15 @@
                     "lo_frequency": lo_frequency,
                     "range": range,
                     "range_unit": range_unit,
                     "port_delay": port_delay,
                     "delay_signal": delay_signal,
                     "port_mode": None,
                     "threshold": None,
+                    "amplifier_pump": None,
                 },
             )
 
     def _load_pulses(self, experiment):
         for pulse in experiment["pulses"]:
             samples = pulse.get("samples", None)
```

## laboneq/compiler/experiment_access/oscillator_info.py

```diff
@@ -8,7 +8,8 @@
 
 @dataclass
 class OscillatorInfo:
     id: str
     frequency: float
     frequency_param: str
     hardware: bool
+    device_id: str = None
```

## laboneq/compiler/new_scheduler/match_schedule.py

```diff
@@ -1,12 +1,13 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
+import math
 from typing import TYPE_CHECKING, Dict, Iterable, Iterator, List
 
 from attrs import define
 from zhinst.utils.feedback_model import (
     FeedbackPath,
     PQSCMode,
     QAType,
@@ -21,14 +22,21 @@
 from laboneq.compiler.new_scheduler.section_schedule import SectionSchedule
 from laboneq.compiler.new_scheduler.utils import ceil_to_grid
 from laboneq.core.exceptions.laboneq_exception import LabOneQException
 
 if TYPE_CHECKING:
     from laboneq.compiler.new_scheduler.schedule_data import ScheduleData
 
+# Copy from device_zi.py (without checks)
+def _get_total_rounded_delay_samples(
+    port_delays, sample_frequency_hz, granularity_samples
+):
+    delay = sum(round((d or 0) * sample_frequency_hz) for d in port_delays)
+    return (math.ceil(delay / granularity_samples + 0.5) - 1) * granularity_samples
+
 
 def _compute_start_with_latency(
     schedule_data: ScheduleData,
     start: int,
     local: bool,
     handle: str,
     section: str,
@@ -54,16 +62,18 @@
     earliest_execute_table_entry = 0
 
     # Calculate the end of the integration in samples from trigger. The following
     # elements need to be considered:
     # - The start time (in samples from trigger) of the acquisition
     # - The length of the integration kernel
     # - The lead time of the acquisition AWG
-    # - The setting of the delay_signal parameter for the acquisition AWG
-    # - The setting of the port_delay parameter for the acquisition device
+    # - The sum of the settings of the delay_signal parameter for the acquisition AWG
+    #   for measure and acquire pulse
+    # - The sum of the settings of the port_delay parameter for the acquisition device
+    #   for measure and acquire pulse
 
     qa_signal_obj = schedule_data.signal_objects[acquire_pulse.pulse.signal_id]
 
     qa_device_type = qa_signal_obj.device_type
     qa_sampling_rate = qa_signal_obj.sampling_rate
 
     if qa_signal_obj.is_qc:
@@ -76,18 +86,34 @@
         raise LabOneQException("Feedback not supported for an aquisition on a UHFQA.")
 
     acq_start = acquire_pulse.absolute_start * schedule_data.TINYSAMPLE
     acq_length = acquire_pulse.length * schedule_data.TINYSAMPLE
     qa_lead_time = qa_signal_obj.start_delay or 0.0
     qa_delay_signal = qa_signal_obj.delay_signal or 0.0
     qa_port_delay = qa_signal_obj.port_delay or 0.0
+    qa_base_delay_signal = qa_signal_obj.base_delay_signal or 0.0
+    qa_base_port_delay = qa_signal_obj.base_port_delay or 0.0
+    qa_total_port_delay = _get_total_rounded_delay_samples(
+        (qa_base_port_delay, qa_port_delay),
+        qa_sampling_rate,
+        qa_device_type.sample_multiple,
+    )
 
-    acquire_end_in_samples = round(
-        (acq_start + acq_length + qa_lead_time + qa_delay_signal + qa_port_delay)
-        * qa_sampling_rate
+    acquire_end_in_samples = (
+        round(
+            (
+                acq_start
+                + acq_length
+                + qa_lead_time
+                + qa_delay_signal
+                + qa_base_delay_signal
+            )
+            * qa_sampling_rate
+        )
+        + qa_total_port_delay
     )
 
     for signal in signals:
         sg_signal_obj = schedule_data.signal_objects[signal]
         sg_device_type = sg_signal_obj.device_type
         if sg_signal_obj.is_qc:
             toolkit_sgtype = SGType.SHFQC
```

## laboneq/compiler/new_scheduler/scheduler.py

```diff
@@ -431,28 +431,40 @@
                 self._experiment_dao.device_info(device).device_type
             )
             if not device_type.supports_reset_osc_phase:
                 continue
             duration = device_type.reset_osc_duration / self._TINYSAMPLE
             hw_osc_devices[device] = duration
             length = max(length, duration)
+            if device_type.lo_frequency_granularity is not None:
+                # The frequency of Grimsel's LO in RF mode is a multiple of 100 MHz.
+                # By aligning the grid with this (10 ns) we make sure the LO's phase is
+                # consistent after the reset of the NCO.
+                df = device_type.lo_frequency_granularity
+                lo_granularity_tinysamples = round(1 / df / self._TINYSAMPLE)
+                grid = lcm(grid, lo_granularity_tinysamples)
+                _logger.info(
+                    f"Phase reset in section '{section_id}' has extended the section's "
+                    f"timing grid to {grid*self._TINYSAMPLE*1e9:.2f} ns, so to be "
+                    f"commensurate with the local oscillator."
+                )
 
         hw_osc_devices = [(k, v) for k, v in hw_osc_devices.items()]
         length = ceil_to_grid(length, grid)
 
         if reset_sw_oscillators:
             sw_signals = signals
         else:
             sw_signals = ()
 
         return [
             PhaseResetSchedule(
                 grid=grid,
                 length=length,
-                signals=set((*hw_signals, *sw_signals)),
+                signals={*hw_signals, *sw_signals},
                 section=section_id,
                 hw_osc_devices=hw_osc_devices,
                 reset_sw_oscillators=reset_sw_oscillators,
             )
         ]
 
     def _schedule_loop_iteration(
@@ -526,14 +538,18 @@
                     grid,
                     section_id,
                 ),
             ]
         else:
             osc_sweep = []
 
+        if osc_phase_reset and osc_phase_reset[0].grid != grid:
+            # On SHFxx, we align the phase reset with the LO granularity (100 MHz)
+            grid = osc_phase_reset[0].grid
+
         children_schedules = [*osc_phase_reset, *osc_sweep, *children_schedules]
         schedule = self._schedule_children(
             section_id, section_info, children_schedules, grid
         )
         return LoopIterationSchedule.from_section_schedule(
             schedule,
             iteration=iteration,
@@ -767,25 +783,34 @@
                 f"Local feedback not possible across devices {acquire_device} and {', '.join(match_devices)}"
             )
 
         play_after = section_info.play_after or []
         if isinstance(play_after, str):
             play_after = [play_after]
 
+        compressed_loop_grid = round(
+            (
+                (8 if local else 200)
+                / self._sampling_rate_tracker.sampling_rate_for_device(acquire_device)
+                / self._TINYSAMPLE
+            )
+        )
+
         return MatchSchedule(
             grid=grid,
             length=to_tinysample(section_info.length, self._schedule_data.TINYSAMPLE),
             sequencer_grid=grid,
             signals=signals,
             children=children_schedules,
             right_aligned=False,
             section=section_id,
             play_after=play_after,
             handle=handle,
             local=local,
+            compressed_loop_grid=compressed_loop_grid,
         )
 
     def _schedule_case(self, section_id, current_parameters) -> CaseSchedule:
         try:
             # todo: do not hash the entire current_parameters dict, but just the param values
             # todo: reduce key to those parameters actually required by the section
             return copy.deepcopy(
```

## laboneq/compiler/workflow/compiler.py

```diff
@@ -13,15 +13,15 @@
 from laboneq._observability.tracing import trace
 from laboneq.compiler.code_generator import CodeGenerator
 from laboneq.compiler.code_generator.measurement_calculator import (
     IntegrationTimes,
     SignalDelays,
 )
 from laboneq.compiler.common import compiler_settings
-from laboneq.compiler.common.awg_info import AWGInfo
+from laboneq.compiler.common.awg_info import AWGInfo, AwgKey
 from laboneq.compiler.common.awg_signal_type import AWGSignalType
 from laboneq.compiler.common.device_type import DeviceType
 from laboneq.compiler.common.signal_obj import SignalObj
 from laboneq.compiler.common.trigger_mode import TriggerMode
 from laboneq.compiler.experiment_access.device_info import DeviceInfo
 from laboneq.compiler.experiment_access.experiment_dao import ExperimentDAO
 from laboneq.compiler.new_scheduler.scheduler import Scheduler as NewScheduler
@@ -62,15 +62,15 @@
         self._sampling_rate_tracker: SamplingRateTracker = None
         self.Scheduler = Scheduler
         if self._settings.USE_EXPERIMENTAL_SCHEDULER:
             self.Scheduler = NewScheduler
         self._scheduler: Compiler.Scheduler = None
 
         self._leader_properties = LeaderProperties()
-        self._clock_settings = {}
+        self._clock_settings: Dict[str, Any] = {}
         self._integration_unit_allocation = None
         self._awgs: _AWGMapping = {}
         self._precompensations: Dict[
             str, Dict[str, Union[Dict[str, Any], float]]
         ] = None
         self._signal_objects: Dict[str, SignalObj] = {}
 
@@ -485,14 +485,22 @@
             self._experiment_dao,
             self._clock_settings["use_2GHz_for_HDAWG"],
         )
         return precompensations
 
     def _generate_signal_objects(self):
         signal_objects = {}
+
+        @dataclass
+        class DelayInfo:
+            port_delay_gen: Optional[float] = None
+            delay_signal_gen: Optional[float] = None
+
+        delay_measure_acquire: Dict[AwgKey, DelayInfo] = {}
+
         for signal_id in self._experiment_dao.signals():
 
             signal_info = self._experiment_dao.signal_info(signal_id)
             delay_signal = signal_info.delay_signal
 
             device_type = DeviceType(signal_info.device_type)
             device_id = signal_info.device_id
@@ -567,31 +575,44 @@
                 and oscillator_info
                 and oscillator_info.hardware
             ):
                 mixer_type = MixerType.UHFQA_ENVELOPE
             elif signal_type in ("single",):
                 mixer_type = None
 
+            port_delay = self._experiment_dao.port_delay(signal_id)
+            if signal_type != "integration":
+                delay_info = delay_measure_acquire.setdefault(awg.key, DelayInfo())
+                delay_info.port_delay_gen = port_delay
+                delay_info.delay_signal_gen = delay_signal
+
             signal_obj = SignalObj(
                 id=signal_id,
                 sampling_rate=sampling_rate,
                 start_delay=start_delay,
                 delay_signal=delay_signal,
                 signal_type=signal_type,
                 device_id=device_id,
                 awg=awg,
                 device_type=device_type,
                 oscillator_frequency=oscillator_frequency,
                 channels=channels,
-                port_delay=self._experiment_dao.port_delay(signal_id),
+                port_delay=port_delay,
                 mixer_type=mixer_type,
                 hw_oscillator=hw_oscillator,
                 is_qc=device_info.is_qc,
             )
             signal_objects[signal_id] = signal_obj
+        for s in signal_objects.values():
+            try:
+                delay_info = delay_measure_acquire[s.awg.key]
+                s.base_port_delay = delay_info.port_delay_gen
+                s.base_delay_signal = delay_info.delay_signal_gen
+            except KeyError:
+                _logger.debug("No measurement pulse signal for acquire signal %s", s.id)
         return signal_objects
 
     def calc_outputs(self, signal_delays: SignalDelays):
         all_channels = {}
 
         flipper = [1, 0]
```

## laboneq/compiler/workflow/recipe_generator.py

```diff
@@ -1,14 +1,14 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 import logging
-from typing import TYPE_CHECKING, Dict, Optional
+from typing import TYPE_CHECKING, Any, Dict, Optional
 
 from laboneq.compiler.code_generator.measurement_calculator import IntegrationTimes
 from laboneq.compiler.common.device_type import DeviceType
 from laboneq.compiler.experiment_access.experiment_dao import ExperimentDAO
 
 if TYPE_CHECKING:
     from laboneq.compiler.workflow.compiler import LeaderProperties
@@ -26,15 +26,15 @@
         self._recipe["header"] = {
             "version": "1.4.0",
             "unit": {"time": "s", "frequency": "Hz", "phase": "rad"},
             "epsilon": {"time": 1e-12},
         }
         self._recipe["experiment"] = {}
 
-    def add_oscillator_params(self, experiment_dao):
+    def add_oscillator_params(self, experiment_dao: ExperimentDAO):
         hw_oscillators = {}
         for oscillator in experiment_dao.hardware_oscillators():
             hw_oscillators[oscillator.id] = oscillator
 
         oscillator_params = []
         for signal_id in experiment_dao.signals():
             signal_info = experiment_dao.signal_info(signal_id)
@@ -111,15 +111,15 @@
                 return initialization
         return None
 
     def add_connectivity_from_experiment(
         self,
         experiment_dao: ExperimentDAO,
         leader_properties: LeaderProperties,
-        clock_settings,
+        clock_settings: Dict[str, Any],
     ):
         if leader_properties.global_leader is not None:
             initialization = self._find_initialization(leader_properties.global_leader)
             initialization["config"]["repetitions"] = 1
             initialization["config"]["holdoff"] = 0
             if leader_properties.is_desktop_setup:
                 initialization["config"]["dio_mode"] = "hdawg_leader"
@@ -148,14 +148,22 @@
                 ] = device.reference_clock_source
 
             if device.device_type == "hdawg" and clock_settings["use_2GHz_for_HDAWG"]:
                 initialization["config"][
                     "sampling_rate"
                 ] = DeviceType.HDAWG.sampling_rate_2GHz
 
+            if device.device_type == "shfppc":
+                ppchannels = {}
+                for signal in experiment_dao.signals():
+                    amplifier_pump = experiment_dao.amplifier_pump(signal)
+                    if amplifier_pump is not None and amplifier_pump[0] == device_uid:
+                        ppchannels[amplifier_pump[1]] = amplifier_pump[2]
+                initialization["ppchannels"] = ppchannels
+
             for follower in experiment_dao.dio_followers():
                 initialization = self._find_initialization(follower)
                 if not leader_properties.is_desktop_setup:
                     initialization["config"]["dio_mode"] = "hdawg"
                 else:
                     initialization["config"][
                         "dio_mode"
@@ -270,15 +278,15 @@
         }
         initialization["awgs"].append(awg)
 
     def from_experiment(
         self,
         experiment_dao: ExperimentDAO,
         leader_properties: LeaderProperties,
-        clock_settings,
+        clock_settings: Dict[str, Any],
     ):
         self.add_devices_from_experiment(experiment_dao)
         self.add_connectivity_from_experiment(
             experiment_dao, leader_properties, clock_settings
         )
 
     def add_simultaneous_acquires(
```

## laboneq/controller/communication.py

```diff
@@ -194,15 +194,14 @@
     ignore_version_mismatch: bool = False
 
 
 class DaqWrapper(ZiApiWrapperBase):
     def __init__(self, name, server_qualifier: ServerQualifier):
         super().__init__(name)
         self._server_qualifier = server_qualifier
-        self._awg_module_wrappers: List[AwgModuleWrapper] = []
         self._is_valid = False
         self._dataserver_version = LabOneVersion.LATEST
         self._vector_counter = 0
         self.node_monitor = None
 
         if not server_qualifier.dry_run:
             from laboneq._token import token_check
@@ -274,24 +273,14 @@
             connection=self._zi_api_object,
         )
 
     @property
     def server_qualifier(self):
         return self._server_qualifier
 
-    def create_awg_module(self, name):
-        _logger.info("Create AWG module %s", name)
-        self._awg_module_wrappers = [
-            wrapper for wrapper in self._awg_module_wrappers if wrapper.name != name
-        ]
-
-        module = AwgModuleWrapper(name, self._zi_api_object.awgModule())
-        self._awg_module_wrappers.append(module)
-        return module
-
     def is_valid(self):
         return self._is_valid
 
     @property
     def dataserver_version(self):
         return self._dataserver_version
 
@@ -394,42 +383,14 @@
         )
 
     def set_emulation_option(self, serial: str, option: str, value: Any):
         assert isinstance(self._zi_api_object, ziDAQServerEmulator)
         self._zi_api_object.set_option(serial, option, value)
 
 
-class AwgModuleWrapper(ZiApiWrapperBase):
-    def __init__(self, name, zi_awg_module):
-        super().__init__(name)
-        self._zi_api_object = zi_awg_module
-
-    def _api_wrapper(self, method_name, *args, **kwargs):
-        api_method = getattr(self._zi_api_object, method_name)
-        res = api_method(*args, **kwargs)
-        return res
-
-    @property
-    def progress(self):
-        return self._zi_api_object.progress()
-
-    @property
-    def elf_status(self):
-        return self._zi_api_object.getInt("elf/status")
-
-    def _api_reply_to_val_history_dict(self, daq_reply):
-        """Converts AWG module reply with flat=True to path-value_history dict
-        e.g. { path: [ val1, val2 ] } to { path: [ val1, val2 ] }
-        """
-        res = {}
-        for path in daq_reply:
-            res[path] = daq_reply[path]
-        return res
-
-
 def batch_set(all_actions: List[DaqNodeAction]):
     split_actions: Dict[DaqWrapper, List[DaqNodeAction]] = {}
     for daq_action in all_actions:
         daq_actions = split_actions.setdefault(daq_action.daq, [])
         daq_actions.append(daq_action)
     for daq, daq_actions in split_actions.items():
         daq.batch_set(daq_actions)
```

## laboneq/controller/controller.py

```diff
@@ -106,42 +106,41 @@
         self._results: Results = None
 
         _logger.debug("Controller created")
         _logger.debug("Controller debug logging is on")
 
         _logger.info("VERSION: laboneq %s", __version__)
 
-        # TODO: Remove this option and support of AWG module.
-        self._is_using_standalone_compiler = os.environ.get(
-            "LABONEQ_STANDALONE_AWG", "1"
-        ).lower() in ("1", "true")
-
     def _allocate_resources(self):
         self._devices.free_allocations()
         osc_params = self._recipe_data.recipe.experiment.oscillator_params
         for osc_param in sorted(osc_params, key=lambda p: p.id):
             self._devices.find_by_uid(osc_param.device_id).allocate_osc(osc_param)
 
+        for initialization in self._recipe_data.recipe.experiment.initializations:
+            device = self._devices.find_by_uid(initialization.device_uid)
+            device.allocate_params(initialization)
+
     def _reset_to_idle_state(self):
         reset_nodes = []
         for _, device in self._devices.all:
             reset_nodes.extend(device.collect_reset_nodes())
         batch_set(reset_nodes)
 
     def _wait_for_conditions_to_start(self):
         for initialization in self._recipe_data.initializations:
             device = self._devices.find_by_uid(initialization.device_uid)
             device.wait_for_conditions_to_start()
 
-    def _initialize_device_outputs(self):
+    def _apply_recipe_initializations(self):
         nodes_to_initialize: List[DaqNodeAction] = []
         for initialization in self._recipe_data.initializations:
             device = self._devices.find_by_uid(initialization.device_uid)
             nodes_to_initialize.extend(
-                device.collect_output_initialization_nodes(
+                device.collect_initialization_nodes(
                     self._recipe_data.device_settings[initialization.device_uid],
                     initialization,
                 )
             )
             nodes_to_initialize.extend(device.collect_osc_initialization_nodes())
 
         batch_set(nodes_to_initialize)
@@ -154,15 +153,15 @@
                 device.collect_awg_before_upload_nodes(
                     initialization, self._recipe_data
                 )
             )
         batch_set(nodes_to_initialize)
 
     @tracing.trace("awg-program-handler")
-    def _upload_awg_programs_standalone(self):
+    def _upload_awg_programs(self):
         @dataclass
         class UploadItem:
             awg_index: int
             seqc_code: str
             seqc_filename: str
             waves: List[Any]
             command_table: Dict[Any]
@@ -277,22 +276,14 @@
 
                 _logger.debug("Started upload of waveforms...")
                 with tracing.get_tracer().start_span("upload-waveforms") as _:
                     for daq, nodes in wf_node_settings.items():
                         daq.batch_set(nodes)
         _logger.debug("Finished upload.")
 
-    def _upload_awg_programs(self):
-        if self._is_using_standalone_compiler:
-            return self._upload_awg_programs_standalone()
-
-        for initialization in self._recipe_data.initializations:
-            device = self._devices.find_by_uid(initialization.device_uid)
-            device.upload_awg_program(initialization, self._recipe_data)
-
     def _set_nodes_after_awg_program_upload(self):
         nodes_to_initialize = []
         for initialization in self._recipe_data.initializations:
             device = self._devices.find_by_uid(initialization.device_uid)
             nodes_to_initialize.extend(
                 device.collect_awg_after_upload_nodes(initialization)
             )
@@ -346,15 +337,15 @@
             )
 
         batch_set(nodes_to_configure_triggers)
 
     def _initialize_devices(self):
         self._reset_to_idle_state()
         self._allocate_resources()
-        self._initialize_device_outputs()
+        self._apply_recipe_initializations()
         self._initialize_awgs()
         self._configure_leaders()
         self._configure_followers()
         self._configure_triggers()
         self._wait_for_conditions_to_start()
 
     def _execute_one_step_followers(self):
@@ -439,15 +430,15 @@
 
     def connect(self):
         now = time.time()
         if (
             self._last_connect_check_ts is None
             or now - self._last_connect_check_ts > CONNECT_CHECK_HOLDOFF
         ):
-            self._devices.connect(self._is_using_standalone_compiler)
+            self._devices.connect()
         self._last_connect_check_ts = now
 
     def disable_outputs(
         self,
         device_uids: List[str] = None,
         logical_signals: List[str] = None,
         unused_only: bool = False,
```

## laboneq/controller/recipe_1_4_0.py

```diff
@@ -298,15 +298,15 @@
     class Data:
         op_type: OperationType = None
         operation: str = None
         args: Dict[str, Any] = None
 
     op_type = OperationTypeField(required=True)
     operation = fields.Str(required=True)
-    args = fields.Dict(None, required=False)
+    args = fields.Dict(required=False, allow_none=True)
 
 
 class Execution(QCCSSchema):
     class Meta:
         fields = ("type", "count", "parameters", "children")
         ordered = True
 
@@ -412,34 +412,37 @@
             "device_uid",
             "config",
             "awgs",
             "ports",
             "outputs",
             "inputs",
             "measurements",
+            "ppchannels",
         )
         ordered = True
 
     @dataclass
     class Data:
         device_uid: AnyStr
         config: Config.Data
         awgs: List[AWG.Data] = None
         ports: List[Port.Data] = None
         outputs: List[IO.Data] = None
         inputs: List[IO.Data] = None
         measurements: List[Measurement.Data] = field(default_factory=list)
+        ppchannels: Dict[int, Any] = None
 
     device_uid = fields.Str()
     config = fields.Nested(Config)
     awgs = fields.List(fields.Nested(AWG), required=False)
     ports = fields.List(fields.Nested(Port), required=False)
     outputs = fields.List(fields.Nested(IO), required=False)
     inputs = fields.List(fields.Nested(IO), required=False)
     measurements = fields.List(fields.Nested(Measurement), required=False)
+    ppchannels = fields.Dict(required=False, allow_none=True)
 
 
 class OscillatorParam(QCCSSchema):
     class Meta:
         fields = ("id", "device_id", "channel", "frequency", "param")
         ordered = True
```

## laboneq/controller/recipe_processor.py

```diff
@@ -20,15 +20,15 @@
     LoopType,
     Sequence,
     Statement,
 )
 
 from .recipe_1_4_0 import IO
 from .recipe_1_4_0 import Experiment as RecipeExperiment
-from .recipe_1_4_0 import Initialization, OscillatorParam, Recipe
+from .recipe_1_4_0 import Initialization, Recipe
 from .recipe_enums import SignalType
 
 if TYPE_CHECKING:
     from laboneq.core.types import CompiledExperiment
 
 
 @dataclass
@@ -461,21 +461,29 @@
                 awg_config.result_length = (
                     len(any_awg_signal_result_map) * mapping_repeats
                 )
 
     return awg_configs
 
 
-def _pre_process_oscillator_params(
-    oscillator_params: List[OscillatorParam.Data],
-) -> Dict[str, List[str]]:
-    param_to_device_map: Dict[str, List[str]] = {}
+def _pre_process_params(
+    experiment: RecipeExperiment.Data,
+) -> Dict[str, Set[str]]:
+    param_to_device_map: Dict[str, Set[str]] = defaultdict(set)
+
+    oscillator_params = experiment.oscillator_params
     for oscillator_param in oscillator_params:
-        param_bindings = param_to_device_map.setdefault(oscillator_param.param, [])
-        param_bindings.append(oscillator_param.device_id)
+        param_to_device_map[oscillator_param.param].add(oscillator_param.device_id)
+
+    for initialization in experiment.initializations:
+        ppchannels = initialization.ppchannels or {}
+        for settings in ppchannels.values():
+            for key in ["pump_freq", "pump_power", "probe_frequency", "probe_power"]:
+                if isinstance(settings[key], str):
+                    param_to_device_map[settings[key]].add(initialization.device_uid)
     return param_to_device_map
 
 
 def pre_process_compiled(compiled_experiment: CompiledExperiment) -> RecipeData:
     recipe: Recipe.Data = Recipe().load(compiled_experiment.recipe)
 
     device_settings: DeviceSettings = defaultdict(DeviceRecipeData)
@@ -483,17 +491,15 @@
         device_settings[initialization.device_uid] = DeviceRecipeData(
             iq_settings=_pre_process_iq_settings_hdawg(initialization)
         )
 
     execution = ExecutionFactoryFromExperiment().make(compiled_experiment.experiment)
     result_shapes, rt_execution_infos = _calculate_result_shapes(execution)
     awg_configs = _calculate_awg_configs(rt_execution_infos, recipe.experiment)
-    param_to_device_map = _pre_process_oscillator_params(
-        recipe.experiment.oscillator_params
-    )
+    param_to_device_map = _pre_process_params(recipe.experiment)
 
     recipe_data = RecipeData(
         compiled=compiled_experiment,
         recipe=recipe,
         execution=execution,
         result_shapes=result_shapes,
         rt_execution_infos=rt_execution_infos,
```

## laboneq/controller/devices/device_collection.py

```diff
@@ -3,25 +3,15 @@
 
 from __future__ import annotations
 
 import logging
 import re
 from collections import defaultdict
 from copy import deepcopy
-from typing import (
-    TYPE_CHECKING,
-    Callable,
-    Dict,
-    Iterator,
-    List,
-    Optional,
-    Set,
-    Tuple,
-    cast,
-)
+from typing import TYPE_CHECKING, Callable, Iterator, cast
 
 from zhinst.utils.api_compatibility import check_dataserver_device_compatibility
 
 from laboneq.controller.communication import (
     CachingStrategy,
     DaqNodeSetAction,
     DaqWrapper,
@@ -63,30 +53,30 @@
         device_setup: DeviceSetup,
         dry_run: bool,
         ignore_version_mismatch: bool = False,
     ):
         self._ds = DeviceSetupDAO(deepcopy(device_setup))
         self._dry_run = dry_run
         self._ignore_version_mismatch = ignore_version_mismatch
-        self._daqs: Dict[str, DaqWrapper] = {}
-        self._devices: Dict[str, DeviceZI] = {}
+        self._daqs: dict[str, DaqWrapper] = {}
+        self._devices: dict[str, DeviceZI] = {}
 
     @property
-    def all(self) -> Iterator[Tuple[str, DeviceZI]]:
+    def all(self) -> Iterator[tuple[str, DeviceZI]]:
         for uid, device in self._devices.items():
             yield uid, device
 
     @property
-    def leaders(self) -> Iterator[Tuple[str, DeviceZI]]:
+    def leaders(self) -> Iterator[tuple[str, DeviceZI]]:
         for uid, device in self._devices.items():
             if device.is_leader():
                 yield uid, device
 
     @property
-    def followers(self) -> Iterator[Tuple[str, DeviceZI]]:
+    def followers(self) -> Iterator[tuple[str, DeviceZI]]:
         for uid, device in self._devices.items():
             if device.is_follower():
                 yield uid, device
 
     def find_by_uid(self, device_uid) -> DeviceZI:
         device = self._devices.get(device_uid)
         if device is None:
@@ -103,87 +93,90 @@
             )
         serial = m.group(1).lower()
         for dev in self._devices.values():
             if dev.serial == serial:
                 return dev
         raise LabOneQControllerException(f"Could not find device for the path '{path}'")
 
-    def connect(self, is_using_standalone_compiler: bool = True):
+    def connect(self):
         self._prepare_daqs()
-        self._prepare_devices(is_using_standalone_compiler)
+        self._prepare_devices()
         for device in self._devices.values():
             device.connect()
         self.start_monitor()
-        self.init_device_setup()
+        self.configure_device_setup()
         self.stop_monitor()
 
     def _configure_parallel(
         self,
-        devices: List[DeviceZI],
-        control_nodes_getter: Callable([DeviceZI], List[NodeControlBase]),
+        devices: list[DeviceZI],
+        control_nodes_getter: Callable([DeviceZI], list[NodeControlBase]),
         config_name: str,
     ):
         response_waiter = ResponseWaiter()
-        set_nodes: List[DaqNodeSetAction] = []
+        set_nodes: list[DaqNodeSetAction] = []
         for device in devices:
             dev_nodes = control_nodes_getter(device)
 
             conditions_checker = ConditionsChecker()
             conditions_checker.add(
                 target=device.daq.node_monitor,
-                conditions=filter_conditions(dev_nodes),
+                conditions={n.path: n.value for n in filter_conditions(dev_nodes)},
             )
             failed_path, _ = conditions_checker.check_all()
             if failed_path is None:
                 continue
 
             set_nodes.extend(
                 [
                     DaqNodeSetAction(
                         daq=device.daq,
-                        path=path,
-                        value=val,
+                        path=node.path,
+                        value=node.raw_value,
                         caching_strategy=CachingStrategy.NO_CACHE,
                     )
-                    for path, val in filter_commands(dev_nodes).items()
+                    for node in filter_commands(dev_nodes)
                 ]
             )
             response_waiter.add(
                 target=device.daq.node_monitor,
-                conditions=filter_responses(dev_nodes),
+                conditions={n.path: n.value for n in filter_responses(dev_nodes)},
             )
 
         if len(set_nodes) is None:
             return
 
         batch_set(set_nodes)
-        timeout = 5
+        timeout = 10
         if not response_waiter.wait_all(timeout=timeout):
             raise LabOneQControllerException(
                 f"Internal error: {config_name} for devices "
                 f"{[d.dev_repr for d in devices]} is not complete within {timeout}s. "
                 f"Not fulfilled:\n{response_waiter.remaining_str()}"
             )
 
         failed_path, expected = conditions_checker.check_all()
         if failed_path is not None:
             raise LabOneQControllerException(
                 f"Internal error: {config_name} for devices "
                 f"{[d.dev_repr for d in devices]} failed at {failed_path} != {expected}."
             )
 
-    def init_device_setup(self):
-        _logger.info("Configuring device setup")
+    def configure_device_setup(self):
+        _logger.info("Configuring the device setup")
         configs = {
             "Reference clock switching": lambda d: cast(
                 DeviceZI, d
             ).clock_source_control_nodes(),
             "System frequency switching": lambda d: cast(
                 DeviceZI, d
             ).system_freq_control_nodes(),
+            "Setting RF channel offsets": lambda d: cast(
+                DeviceZI, d
+            ).rf_offset_control_nodes(),
         }
         # Wait until clock status is available for all devices
         response_waiter = ResponseWaiter()
         for device in self._devices.values():
             target_node_monitor = device.daq.node_monitor
             control_nodes = []
             for control_nodes_getter in configs.values():
@@ -213,33 +206,33 @@
             children = []
             for parent_dev in parents:
                 for _, dev_ref in parent_dev._downlinks.values():
                     dev = dev_ref()
                     if dev is not None:
                         children.append(dev)
             parents = children
-        _logger.info("Device setup configured")
+        _logger.info("The device setup is configured")
 
     def disconnect(self):
         self.reset_monitor()
         for device in self._devices.values():
             device.disconnect()
         self._devices = {}
         self._daqs = {}
 
     def disable_outputs(
         self,
-        device_uids: List[str] = None,
-        logical_signals: List[str] = None,
+        device_uids: list[str] = None,
+        logical_signals: list[str] = None,
         unused_only: bool = False,
     ):
         # Set of outputs to disable or skip (depending on the 'invert' param) per device.
         # Rationale for the logic: the actual number of outputs is only known by the connected
         # device object, here we can only determine the outputs mapped in the device setup.
-        outputs_per_device: Dict[str, Optional[Set[int]]] = {}
+        outputs_per_device: dict[str, set[int] | None] = {}
 
         if logical_signals is None:
             invert = True
             known_device_uids = [uid for uid, _ in self.all]
             if device_uids is None:
                 device_uids = known_device_uids
             else:
@@ -254,15 +247,15 @@
             invert = False
             assert device_uids is None and not unused_only
             for ls_path in logical_signals:
                 device_uid, outputs = self._ds.resolve_ls_path_outputs(ls_path)
                 if device_uid is not None:
                     outputs_per_device.setdefault(device_uid, set()).update(outputs)
 
-        all_actions: List[DaqNodeSetAction] = []
+        all_actions: list[DaqNodeSetAction] = []
         for device_uid, outputs in outputs_per_device.items():
             device = self.find_by_uid(device_uid)
             all_actions.extend(device.disable_outputs(outputs, invert))
         batch_set(all_actions)
 
     def shut_down(self):
         for device in self._devices.values():
@@ -299,39 +292,38 @@
                 try:
                     check_dataserver_device_compatibility(
                         self._daqs.get(daq_uid)._zi_api_object, dev_addrs
                     )
                 except Exception as error:
                     raise LabOneQControllerException(str(error)) from error
 
-    def _prepare_devices(self, is_using_standalone_compiler):
+    def _prepare_devices(self):
         self._validate_dataserver_device_fw_compatibility()
 
         def make_device_qualifier(
             instrument: ZIStandardInstrument, daq: DaqWrapper, gen2: bool
         ) -> DeviceQualifier:
             driver = instrument.calc_driver()
             options = DeviceOptions(
                 **instrument.calc_options(),
-                is_using_standalone_compiler=is_using_standalone_compiler,
                 gen2=gen2,
             )
             if len(instrument.connections) == 0:
                 # Treat devices without connections as non-QC
                 if options.dev_type is None:
                     options.dev_type = driver
                 if options.is_qc is None:
                     options.is_qc = False
                 driver = "NONQC"
 
             return DeviceQualifier(
                 dry_run=self._dry_run, driver=driver, server=daq, options=options
             )
 
-        updated_devices: Dict[str, DeviceZI] = {}
+        updated_devices: dict[str, DeviceZI] = {}
         for instrument in self._ds.instruments:
             daq = self._daqs.get(instrument.server_uid)
             device_qualifier = make_device_qualifier(instrument, daq, self._ds.has_shf)
 
             if device_qualifier.dry_run:
                 dry_run_daq: DaqWrapperDryRun = daq
                 dry_run_daq.map_device_type(device_qualifier)
@@ -356,35 +348,42 @@
                             f"the port '{connection.local_port}' connection of the "
                             f"device '{instrument.uid}'"
                         )
                     to_port = f"{connection.signal_type.name}/{connection.remote_port}"
                     from_dev.add_downlink(from_port, to_dev_uid, to_dev)
                     to_dev.add_uplink(to_port, from_dev)
 
-        # Set clock source (external by default)
+        # Move various device settings from device setup
         for instrument in self._ds.instruments:
             dev = self._devices[instrument.uid]
-            force_internal: Optional[bool] = None
+
+            # Set clock source (external by default)
+            force_internal: bool | None = None
             if instrument.reference_clock_source is not None:
                 force_internal = (
                     instrument.reference_clock_source == ReferenceClockSource.INTERNAL
                 )
             dev.update_clock_source(force_internal)
 
+            # Set RF channel offsets
+            dev.update_rf_offsets(
+                self._ds.get_device_rf_voltage_offsets(instrument.uid)
+            )
+
     def _prepare_daqs(self):
         def make_server_qualifier(server: DataServer):
             return ServerQualifier(
                 dry_run=self._dry_run,
                 host=server.host,
                 port=int(server.port),
                 api_level=int(server.api_level),
                 ignore_version_mismatch=self._ignore_version_mismatch,
             )
 
-        updated_daqs: Dict[str, DaqWrapper] = {}
+        updated_daqs: dict[str, DaqWrapper] = {}
         for server_uid, server in self._ds.servers:
             server_qualifier = make_server_qualifier(server)
             existing = self._daqs.get(server_uid)
             if existing is not None and existing.server_qualifier == server_qualifier:
                 existing.node_monitor.reset()
                 updated_daqs[server_uid] = existing
                 continue
```

## laboneq/controller/devices/device_factory.py

```diff
@@ -1,13 +1,14 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from laboneq.controller.devices.device_hdawg import DeviceHDAWG
 from laboneq.controller.devices.device_nonqc import DeviceNonQC
 from laboneq.controller.devices.device_pqsc import DevicePQSC
+from laboneq.controller.devices.device_shfppc import DeviceSHFPPC
 from laboneq.controller.devices.device_shfqa import DeviceSHFQA
 from laboneq.controller.devices.device_shfsg import DeviceSHFSG
 from laboneq.controller.devices.device_uhfqa import DeviceUHFQA
 from laboneq.controller.devices.device_zi import DeviceQualifier, DeviceZI
 from laboneq.controller.util import LabOneQControllerException
 
 
@@ -15,14 +16,15 @@
     @staticmethod
     def create(device_qualifier: DeviceQualifier) -> DeviceZI:
         dev_class = {
             "HDAWG": DeviceHDAWG,
             "UHFQA": DeviceUHFQA,
             "SHFQA": DeviceSHFQA,
             "SHFSG": DeviceSHFSG,
+            "SHFPPC": DeviceSHFPPC,
             "PQSC": DevicePQSC,
             "NONQC": DeviceNonQC,
         }.get(device_qualifier.driver.upper())
         if dev_class is None:
             raise LabOneQControllerException(
                 f"Unknown device driver {device_qualifier.driver}"
             )
```

## laboneq/controller/devices/device_hdawg.py

```diff
@@ -1,27 +1,28 @@
 # Copyright 2019 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 import logging
 from enum import IntEnum
-from typing import Any, Dict, List, Optional, Set, Tuple
+from typing import Any
 
 import numpy as np
 
 from laboneq.controller.communication import (
     CachingStrategy,
     DaqNodeAction,
     DaqNodeSetAction,
 )
 from laboneq.controller.devices.device_zi import DeviceZI
 from laboneq.controller.devices.zi_node_monitor import (
     Command,
     Condition,
+    FloatWithTolerance,
     NodeControlBase,
     Prepare,
     Response,
 )
 from laboneq.controller.recipe_1_4_0 import Initialization
 from laboneq.controller.recipe_enums import DIOConfigType, SignalType
 from laboneq.controller.recipe_processor import DeviceRecipeData, RecipeData
@@ -89,63 +90,61 @@
     def _osc_group_by_channel(self, channel: int) -> int:
         # For LabOne Q SW, the AWG oscillator control is always on, in which
         # case every pair of output channels share the same set of oscillators
         return channel // 2
 
     def _get_next_osc_index(
         self, osc_group: int, previously_allocated: int
-    ) -> Optional[int]:
+    ) -> int | None:
         # With MF option 4 oscillators per channel pair are available,
         # and only 1 oscillator per channel pair without MF option.
         max_per_group = 4 if self._multi_freq else 1
         if previously_allocated >= max_per_group:
             return None
         osc_index_base = osc_group * max_per_group
         return osc_index_base + previously_allocated
 
     def disable_outputs(
-        self, outputs: Set[int], invert: bool
-    ) -> List[DaqNodeSetAction]:
-        channels_to_disable: List[DaqNodeSetAction] = []
+        self, outputs: set[int], invert: bool
+    ) -> list[DaqNodeSetAction]:
+        channels_to_disable: list[DaqNodeSetAction] = []
         for ch in range(self._channels):
             if (ch in outputs) != invert:
                 channels_to_disable.append(
                     DaqNodeSetAction(
                         self._daq,
                         f"/{self.serial}/sigouts/{ch}/on",
                         0,
                         caching_strategy=CachingStrategy.NO_CACHE,
                     )
                 )
         return channels_to_disable
 
-    def _nodes_to_monitor_impl(self) -> List[str]:
-        nodes = []
-        nodes.extend([node.path for node in self.clock_source_control_nodes()])
-        nodes.extend([node.path for node in self.system_freq_control_nodes()])
+    def _nodes_to_monitor_impl(self) -> list[str]:
+        nodes = super()._nodes_to_monitor_impl()
         for awg in range(self._get_num_awgs()):
             nodes.append(f"/{self.serial}/awgs/{awg}/enable")
             nodes.append(f"/{self.serial}/awgs/{awg}/ready")
         return nodes
 
-    def update_clock_source(self, force_internal: Optional[bool]):
+    def update_clock_source(self, force_internal: bool | None):
         if force_internal or force_internal is None and self.is_standalone():
             # Internal specified explicitly or
             # the source is not specified, but HDAWG is a standalone device
             self._reference_clock_source = ReferenceClockSourceHDAWG.INTERNAL
         elif self.is_leader() or self.is_standalone():
             # If HDAWG is a leader or standalone (and not explicitly forced to internal),
             # external is the default (or explicit)
             self._reference_clock_source = ReferenceClockSourceHDAWG.EXTERNAL
         else:
             # If HDAWG is a follower (and not explicitly forced to internal),
             # ZSync is the default (explicit external is also treated as ZSync in this case)
             self._reference_clock_source = ReferenceClockSourceHDAWG.ZSYNC
 
-    def clock_source_control_nodes(self) -> List[NodeControlBase]:
+    def clock_source_control_nodes(self) -> list[NodeControlBase]:
         expected_freq = {
             ReferenceClockSourceHDAWG.INTERNAL: None,
             ReferenceClockSourceHDAWG.EXTERNAL: 10e6,
             ReferenceClockSourceHDAWG.ZSYNC: 100e6,
         }[self._reference_clock_source]
         source = self._reference_clock_source.value
 
@@ -153,15 +152,15 @@
             Condition(
                 f"/{self.serial}/system/clocks/referenceclock/freq", expected_freq
             ),
             Command(f"/{self.serial}/system/clocks/referenceclock/source", source),
             Response(f"/{self.serial}/system/clocks/referenceclock/status", 0),
         ]
 
-    def system_freq_control_nodes(self) -> List[NodeControlBase]:
+    def system_freq_control_nodes(self) -> list[NodeControlBase]:
         nodes = []
         # If we do not turn all channels off, we get the following error message from
         # the server/device: 'An error happened on device dev8330 during the execution
         # of the experiment. Error message: Reinitialized signal output delay on
         # channel 0 (numbered from 0)'
         # See also https://zhinst.atlassian.net/browse/HBAR-1374?focusedCommentId=41373
         for channel in range(self._channels):
@@ -173,14 +172,28 @@
                     self._sampling_rate,
                 ),
                 Response(f"/{self.serial}/system/clocks/sampleclock/status", 0),
             ]
         )
         return nodes
 
+    def rf_offset_control_nodes(self) -> list[NodeControlBase]:
+        nodes = []
+        for channel, offset in self._rf_offsets.items():
+            nodes.extend(
+                [
+                    Command(f"/{self.serial}/sigouts/{channel}/on", 1),
+                    Command(
+                        f"/{self.serial}/sigouts/{channel}/offset",
+                        FloatWithTolerance(offset, 0.0001),
+                    ),
+                ]
+            )
+        return nodes
+
     def collect_awg_after_upload_nodes(self, initialization: Initialization.Data):
         nodes_to_configure_phase = []
 
         for awg in initialization.awgs or []:
             _logger.debug(
                 "%s: Configure modulation phase depending on IQ enabling on awg %d.",
                 self.dev_repr,
@@ -198,34 +211,34 @@
                 DaqNodeSetAction(
                     self._daq, f"/{self.serial}/sines/{awg.awg * 2 + 1}/phaseshift", 0
                 )
             )
 
         return nodes_to_configure_phase
 
-    def conditions_for_execution_ready(self) -> Dict[str, Any]:
-        conditions: Dict[str, Any] = {}
+    def conditions_for_execution_ready(self) -> dict[str, Any]:
+        conditions: dict[str, Any] = {}
         for awg_index in self._allocated_awgs:
             conditions[f"/{self.serial}/awgs/{awg_index}/enable"] = 1
         return conditions
 
     def conditions_for_execution_done(
         self, acquisition_type: AcquisitionType
-    ) -> Dict[str, Any]:
-        conditions: Dict[str, Any] = {}
+    ) -> dict[str, Any]:
+        conditions: dict[str, Any] = {}
         for awg_index in self._allocated_awgs:
             conditions[f"/{self.serial}/awgs/{awg_index}/enable"] = 0
         return conditions
 
-    def collect_output_initialization_nodes(
+    def collect_initialization_nodes(
         self, device_recipe_data: DeviceRecipeData, initialization: Initialization.Data
-    ) -> List[DaqNodeAction]:
+    ) -> list[DaqNodeAction]:
         _logger.debug("%s: Initializing device...", self.dev_repr)
 
-        nodes: List[Tuple[str, Any]] = []
+        nodes: list[tuple[str, Any]] = []
 
         outputs = initialization.outputs or []
         for output in outputs:
 
             awg_idx = output.channel // 2
             self._allocated_awgs.add(awg_idx)
 
@@ -418,27 +431,27 @@
             DaqNodeSetAction(
                 self._daq, f"/{self.serial}/raw/system/awg/runtimechecks/enable", 1
             ),
         ]
 
         return device_specific_initialization_nodes
 
-    def add_command_table_header(self, body: dict) -> Dict:
+    def add_command_table_header(self, body: dict) -> dict:
         return {
             "$schema": "https://docs.zhinst.com/hdawg/commandtable/v1_0/schema",
             "header": {"version": "1.0.0"},
             "table": body,
         }
 
     def command_table_path(self, awg_index: int) -> str:
         return f"/{self.serial}/awgs/{awg_index}/commandtable/"
 
     def collect_trigger_configuration_nodes(
         self, initialization: Initialization.Data, recipe_data: RecipeData
-    ) -> List[DaqNodeAction]:
+    ) -> list[DaqNodeAction]:
         _logger.debug("%s: Configuring trigger configuration nodes.", self.dev_repr)
         nodes_to_configure_triggers = []
 
         dio_mode = initialization.config.dio_mode
         if dio_mode == DIOConfigType.ZSYNC_DIO:
             _logger.debug(
                 "%s: Configuring DIO mode: ZSync pass-through.", self.dev_repr
@@ -576,18 +589,7 @@
                 nodes_to_configure_triggers.append(
                     DaqNodeSetAction(
                         self._daq, f"/{self.serial}/awgs/{awg_index}/dio/mask/shift", 1
                     )
                 )
 
         return nodes_to_configure_triggers
-
-    def configure_as_leader(self, initialization: Initialization.Data):
-        pass
-
-    def collect_follower_configuration_nodes(
-        self, initialization: Initialization.Data
-    ) -> List[DaqNodeAction]:
-        return []
-
-    def initialize_sweep_setting(self, setting):
-        raise LabOneQControllerException("HDAWG doesn't support sweeping")
```

## laboneq/controller/devices/device_nonqc.py

```diff
@@ -1,44 +1,22 @@
 # Copyright 2019 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
-from typing import List
-
 from laboneq.controller.communication import DaqNodeAction
 from laboneq.controller.devices.device_zi import DeviceZI
-from laboneq.controller.recipe_1_4_0 import Initialization
-from laboneq.controller.recipe_processor import DeviceRecipeData, RecipeData
 
 
 class DeviceNonQC(DeviceZI):
     def is_leader(self):
         return False
 
     def is_follower(self):
         return False
 
     def is_standalone(self):
         return False
 
-    def collect_follower_configuration_nodes(
-        self, initialization: Initialization.Data
-    ) -> List[DaqNodeAction]:
-        return []
-
-    def collect_output_initialization_nodes(
-        self, device_recipe_data: DeviceRecipeData, initialization: Initialization.Data
-    ) -> List[DaqNodeAction]:
-        return []
-
-    def collect_trigger_configuration_nodes(
-        self, initialization: Initialization.Data, recipe_data: RecipeData
-    ) -> List[DaqNodeAction]:
-        return []
-
-    def configure_as_leader(self, initialization: Initialization.Data):
-        pass
-
     def check_errors(self):
         pass
 
-    def collect_reset_nodes(self) -> List[DaqNodeAction]:
+    def collect_reset_nodes(self) -> list[DaqNodeAction]:
         return []
```

## laboneq/controller/devices/device_pqsc.py

```diff
@@ -1,12 +1,14 @@
 # Copyright 2019 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
+from __future__ import annotations
+
 import logging
-from typing import Any, Dict, List, Optional
+from typing import Any
 
 from laboneq.controller.communication import (
     CachingStrategy,
     DaqNodeAction,
     DaqNodeSetAction,
 )
 from laboneq.controller.devices.device_zi import DeviceZI
@@ -30,23 +32,23 @@
 class DevicePQSC(DeviceZI):
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
         self.dev_type = "PQSC"
         self.dev_opts = []
         self._use_internal_clock = False
 
-    def _nodes_to_monitor_impl(self) -> List[str]:
-        nodes = [node.path for node in self.clock_source_control_nodes()]
+    def _nodes_to_monitor_impl(self) -> list[str]:
+        nodes = super()._nodes_to_monitor_impl()
         nodes.append(f"/{self.serial}/execution/enable")
         return nodes
 
-    def update_clock_source(self, force_internal: Optional[bool]):
+    def update_clock_source(self, force_internal: bool | None):
         self._use_internal_clock = force_internal is True
 
-    def clock_source_control_nodes(self) -> List[NodeControlBase]:
+    def clock_source_control_nodes(self) -> list[NodeControlBase]:
         source = (
             REFERENCE_CLOCK_SOURCE_INTERNAL
             if self._use_internal_clock
             else REFERENCE_CLOCK_SOURCE_EXTERNAL
         )
         expected_freq = None if self._use_internal_clock else 10e6
         return [
@@ -56,20 +58,20 @@
             Command(f"/{self.serial}/system/clocks/referenceclock/in/source", source),
             Response(
                 f"/{self.serial}/system/clocks/referenceclock/in/sourceactual", source
             ),
             Response(f"/{self.serial}/system/clocks/referenceclock/in/status", 0),
         ]
 
-    def collect_output_initialization_nodes(
+    def collect_initialization_nodes(
         self, device_recipe_data: DeviceRecipeData, initialization: Initialization.Data
-    ) -> List[DaqNodeAction]:
+    ) -> list[DaqNodeAction]:
         return []
 
-    def configure_feedback(self, recipe_data: RecipeData) -> List[DaqNodeAction]:
+    def configure_feedback(self, recipe_data: RecipeData) -> list[DaqNodeAction]:
         # TODO(2K): Code duplication with Controller._wait_execution_to_stop
         # Make this mandatory in the recipe instead.
         min_wait_time = recipe_data.recipe.experiment.total_execution_time
         if min_wait_time is None:
             min_wait_time = 10.0
         # This is required because PQSC is only receiving the feedback events
         # during the holdoff time, even for a single trigger.
@@ -126,20 +128,20 @@
                 1,
                 caching_strategy=CachingStrategy.NO_CACHE,
             ),
         ]
 
     def conditions_for_execution_done(
         self, acquisition_type: AcquisitionType
-    ) -> Dict[str, Any]:
+    ) -> dict[str, Any]:
         return {f"/{self.serial}/execution/enable": 0}
 
     def collect_trigger_configuration_nodes(
         self, initialization: Initialization.Data, recipe_data: RecipeData
-    ) -> List[DaqNodeAction]:
+    ) -> list[DaqNodeAction]:
         # Ensure ZSync links are established
         # TODO(2K): This is rather a hotfix, waiting to be done in parallel for all devices with
         # subscription / poll
         # TODO(2K): Verify also the downlink device serial (.../connection/serial) matches
         for port in self._downlinks:
             self._wait_for_node(
                 f"/{self.serial}/{port.lower()}/connection/status", 2, timeout=10
@@ -179,15 +181,15 @@
             )
         )
 
         return nodes_to_configure_triggers
 
     def collect_follower_configuration_nodes(
         self, initialization: Initialization.Data
-    ) -> List[DaqNodeAction]:
+    ) -> list[DaqNodeAction]:
         raise LabOneQControllerException("PQSC cannot be configured as follower")
 
     def configure_as_leader(self, initialization: Initialization.Data):
         _logger.debug("%s: Configuring as leader...", self.dev_repr)
         _logger.debug("%s: Enabling reference clock...", self.dev_repr)
 
         _logger.debug(
@@ -211,10 +213,7 @@
                 DaqNodeSetAction(
                     self._daq,
                     f"/{self.serial}/system/clocks/referenceclock/out/freq",
                     initialization.config.reference_clock,
                 )
             ]
         )
-
-    def initialize_sweep_setting(self, setting):
-        raise LabOneQControllerException("PQSC doesn't support sweeping")
```

## laboneq/controller/devices/device_setup_dao.py

```diff
@@ -1,70 +1,102 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
+import logging
+import math
 from functools import cached_property
-from typing import Iterator, Set, Tuple
+from typing import Iterator
 
+from laboneq.core.types.enums.io_signal_type import IOSignalType
 from laboneq.dsl.device.device_setup import DeviceSetup
 from laboneq.dsl.device.instruments.shfqa import SHFQA
 from laboneq.dsl.device.instruments.shfsg import SHFSG
 from laboneq.dsl.device.instruments.zi_standard_instrument import ZIStandardInstrument
 from laboneq.dsl.device.servers.data_server import DataServer
 
+_logger = logging.getLogger(__name__)
+
+
+def _port_outputs(instrument: ZIStandardInstrument, local_port_path: str) -> list[int]:
+    output_port = instrument.output_by_uid(local_port_path)
+    dev_outputs = (
+        []
+        if output_port is None or output_port.physical_port_ids is None
+        else output_port.physical_port_ids
+    )
+    return [int(o) for o in dev_outputs]
+
 
 class DeviceSetupDAO:
     def __init__(self, device_setup: DeviceSetup):
         self._device_setup = device_setup
 
     @property
     def instruments(self) -> Iterator[ZIStandardInstrument]:
         for instrument in self._device_setup.instruments:
             if isinstance(instrument, ZIStandardInstrument):
                 yield instrument
 
     @property
-    def servers(self) -> Iterator[Tuple[str, DataServer]]:
+    def servers(self) -> Iterator[tuple[str, DataServer]]:
         return self._device_setup.servers.items()
 
     @cached_property
     def has_shf(self):
         for instrument in self._device_setup.instruments:
             if isinstance(instrument, (SHFQA, SHFSG)):
                 return True
         return False
 
-    def resolve_ls_path_outputs(self, ls_path: str) -> Tuple[str, Set[int]]:
+    def resolve_ls_path_outputs(self, ls_path: str) -> tuple[str, set[int]]:
         device_uid: str = None
-        outputs: Set[int] = set()
+        outputs: set[int] = set()
         for instrument in self._device_setup.instruments:
             for conn in instrument.connections:
                 if conn.remote_path == ls_path:
                     if device_uid is None:
                         device_uid = instrument.uid
-                    output_port = instrument.output_by_uid(conn.local_port)
-                    dev_outputs = (
-                        []
-                        if output_port is None or output_port.physical_port_ids is None
-                        else output_port.physical_port_ids
-                    )
-                    outputs.update([int(o) for o in dev_outputs])
+                    outputs.update(_port_outputs(instrument, conn.local_port))
             if device_uid is not None:
                 # ignore the never-should-happen case when ls is mapped to multiple devices
                 break
         return device_uid, outputs
 
-    def get_device_used_outputs(self, device_uid: str) -> Set[int]:
-        used_outputs: Set[int] = set()
-        for instrument in self._device_setup.instruments:
-            if instrument.uid == device_uid:
-                for conn in instrument.connections:
-                    output_port = instrument.output_by_uid(conn.local_port)
-                    dev_outputs = (
-                        []
-                        if output_port is None or output_port.physical_port_ids is None
-                        else output_port.physical_port_ids
-                    )
-                    used_outputs.update([int(o) for o in dev_outputs])
-                break
+    def get_device_used_outputs(self, device_uid: str) -> set[int]:
+        used_outputs: set[int] = set()
+        instrument = self._device_setup.instrument_by_uid(device_uid)
+        if instrument is not None:
+            for conn in instrument.connections:
+                used_outputs.update(_port_outputs(instrument, conn.local_port))
         return used_outputs
+
+    def get_device_rf_voltage_offsets(self, device_uid: str) -> dict[int, float]:
+        "Returns map: <sigout index> -> <voltage_offset>"
+        voltage_offsets: dict[int, float] = {}
+
+        def add_voltage_offset(sigout: int, voltage_offset: float):
+            if sigout in voltage_offsets:
+                if not math.isclose(voltage_offsets[sigout], voltage_offset):
+                    _logger.warning(
+                        "Ambiguous 'voltage_offset' for the output %s of device %s: %s != %s, "
+                        "will use %s",
+                        sigout,
+                        device_uid,
+                        voltage_offsets[sigout],
+                        voltage_offset,
+                        voltage_offsets[sigout],
+                    )
+            else:
+                voltage_offsets[sigout] = voltage_offset
+
+        instrument = self._device_setup.instrument_by_uid(device_uid)
+        if instrument is not None:
+            for conn in instrument.connections:
+                if conn.signal_type == IOSignalType.RF:
+                    calib = self._device_setup._get_calibration(conn.remote_path)
+                    if calib is not None and calib.voltage_offset is not None:
+                        outputs = _port_outputs(instrument, conn.local_port)
+                        if len(outputs) == 1:
+                            add_voltage_offset(int(outputs[0]), calib.voltage_offset)
+        return voltage_offsets
```

## laboneq/controller/devices/device_shfqa.py

```diff
@@ -1,15 +1,15 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 import logging
 import time
-from typing import Any, Dict, List, Optional, Set, Tuple
+from typing import Any
 
 import numpy as np
 from numpy import typing as npt
 
 from laboneq.controller.communication import (
     CachingStrategy,
     DaqNodeAction,
@@ -129,40 +129,40 @@
             )
 
     def _osc_group_by_channel(self, channel: int) -> int:
         return channel
 
     def _get_next_osc_index(
         self, osc_group: int, previously_allocated: int
-    ) -> Optional[int]:
+    ) -> int | None:
         if previously_allocated >= 1:
             return None
         return previously_allocated
 
     def _make_osc_path(self, channel: int, index: int) -> str:
         return f"/{self.serial}/qachannels/{channel}/oscs/{index}/freq"
 
     def disable_outputs(
-        self, outputs: Set[int], invert: bool
-    ) -> List[DaqNodeSetAction]:
-        channels_to_disable: List[DaqNodeSetAction] = []
+        self, outputs: set[int], invert: bool
+    ) -> list[DaqNodeSetAction]:
+        channels_to_disable: list[DaqNodeSetAction] = []
         for ch in range(self._channels):
             if (ch in outputs) != invert:
                 channels_to_disable.append(
                     DaqNodeSetAction(
                         self._daq,
                         f"/{self.serial}/qachannels/{ch}/output/on",
                         0,
                         caching_strategy=CachingStrategy.NO_CACHE,
                     )
                 )
         return channels_to_disable
 
-    def _nodes_to_monitor_impl(self) -> List[str]:
-        nodes = []
+    def _nodes_to_monitor_impl(self) -> list[str]:
+        nodes = super()._nodes_to_monitor_impl()
         for awg in range(self._get_num_awgs()):
             nodes.extend(
                 [
                     f"/{self.serial}/qachannels/{awg}/generator/enable",
                     f"/{self.serial}/qachannels/{awg}/generator/ready",
                     f"/{self.serial}/qachannels/{awg}/spectroscopy/result/enable",
                     f"/{self.serial}/qachannels/{awg}/readout/result/enable",
@@ -170,19 +170,19 @@
             )
         return nodes
 
     def configure_acquisition(
         self,
         awg_key: AwgKey,
         awg_config: AwgConfig,
-        integrator_allocations: List[IntegratorAllocation.Data],
+        integrator_allocations: list[IntegratorAllocation.Data],
         averages: int,
         averaging_mode: AveragingMode,
         acquisition_type: AcquisitionType,
-    ) -> List[DaqNodeAction]:
+    ) -> list[DaqNodeAction]:
 
         average_mode = 0 if averaging_mode == AveragingMode.CYCLIC else 1
         nodes = [
             *self._configure_readout(
                 acquisition_type,
                 awg_key,
                 awg_config,
@@ -207,15 +207,15 @@
         return nodes
 
     def _configure_readout(
         self,
         acquisition_type: AcquisitionType,
         awg_key: AwgKey,
         awg_config: AwgConfig,
-        integrator_allocations: List[IntegratorAllocation.Data],
+        integrator_allocations: list[IntegratorAllocation.Data],
         averages: int,
         average_mode: int,
     ):
         enable = acquisition_type in [
             AcquisitionType.INTEGRATION,
             AcquisitionType.DISCRIMINATION,
         ]
@@ -411,30 +411,30 @@
                     else f"/{self.serial}/system/swtriggers/0/single",
                     1,
                     caching_strategy=CachingStrategy.NO_CACHE,
                 )
             ]
         return []
 
-    def conditions_for_execution_ready(self) -> Dict[str, Any]:
+    def conditions_for_execution_ready(self) -> dict[str, Any]:
         # TODO(janl): Not sure whether we need this condition this on the SHFQA (including SHFQC)
         # as well. The state of the generator enable wasn't always pickup up reliably, so we
         # only check in cases where we rely on external triggering mechanisms.
-        conditions: Dict[str, Any] = {}
+        conditions: dict[str, Any] = {}
         if self._wait_for_awgs:
             for awg_index in self._allocated_awgs:
                 conditions[
                     f"/{self.serial}/qachannels/{awg_index}/generator/enable"
                 ] = 1
         return conditions
 
     def conditions_for_execution_done(
         self, acquisition_type: AcquisitionType
-    ) -> Dict[str, Any]:
-        conditions: Dict[str, Any] = {}
+    ) -> dict[str, Any]:
+        conditions: dict[str, Any] = {}
         for awg_index in self._allocated_awgs:
             conditions[f"/{self.serial}/qachannels/{awg_index}/generator/enable"] = 0
             if acquisition_type == AcquisitionType.SPECTROSCOPY:
                 conditions[
                     f"/{self.serial}/qachannels/{awg_index}/spectroscopy/result/enable"
                 ] = 0
             elif acquisition_type in [
@@ -442,20 +442,20 @@
                 AcquisitionType.DISCRIMINATION,
             ]:
                 conditions[
                     f"/{self.serial}/qachannels/{awg_index}/readout/result/enable"
                 ] = 0
         return conditions
 
-    def collect_output_initialization_nodes(
+    def collect_initialization_nodes(
         self, device_recipe_data: DeviceRecipeData, initialization: Initialization.Data
-    ) -> List[DaqNodeSetAction]:
+    ) -> list[DaqNodeSetAction]:
         _logger.debug("%s: Initializing device...", self.dev_repr)
 
-        nodes_to_initialize_output: List[DaqNodeSetAction] = []
+        nodes_to_initialize_output: list[DaqNodeSetAction] = []
 
         outputs = initialization.outputs or []
         for output in outputs:
             self._warn_for_unsupported_param(
                 output.offset is None or output.offset == 0,
                 "voltage_offsets",
                 output.channel,
@@ -535,18 +535,18 @@
             filename=filename,
             caching_strategy=CachingStrategy.NO_CACHE,
         )
 
     def prepare_upload_all_binary_waves(
         self,
         awg_index,
-        waves: List[Tuple[str, npt.ArrayLike]],
+        waves: list[tuple[str, npt.ArrayLike]],
         acquisition_type: AcquisitionType,
     ):
-        waves_upload: List[DaqNodeSetAction] = []
+        waves_upload: list[DaqNodeSetAction] = []
         has_spectroscopy_envelope = False
         if acquisition_type == AcquisitionType.SPECTROSCOPY:
             if len(waves) > 1:
                 raise LabOneQControllerException(
                     f"{self.dev_repr}: Only one envelope waveform per channel is possible in "
                     f"spectroscopy mode. Check play commands for channel {awg_index}."
                 )
@@ -601,15 +601,15 @@
         )
         return waves_upload
 
     def _configure_readout_mode_nodes(
         self,
         dev_input: IO.Data,
         dev_output: IO.Data,
-        measurement: Optional[Measurement.Data],
+        measurement: Measurement.Data | None,
         device_uid: str,
         recipe_data: RecipeData,
     ):
         _logger.debug("%s: Setting measurement mode to 'Readout'.", self.dev_repr)
 
         measurement_delay_output = 0
         if dev_output is not None:
@@ -686,15 +686,15 @@
                     filename=wave_name,
                     caching_strategy=CachingStrategy.CACHE,
                 )
             )
         return nodes_to_set_for_readout_mode
 
     def _configure_spectroscopy_mode_nodes(
-        self, dev_input, measurement: Optional[Measurement.Data]
+        self, dev_input, measurement: Measurement.Data | None
     ):
         _logger.debug("%s: Setting measurement mode to 'Spectroscopy'.", self.dev_repr)
 
         measurement_delay_rounded = (
             self._get_total_rounded_delay_samples(
                 dev_input,
                 SAMPLE_FREQUENCY_HZ,
@@ -835,15 +835,15 @@
                 )
             )
 
         return nodes_to_initialize_measurement
 
     def collect_trigger_configuration_nodes(
         self, initialization: Initialization.Data, recipe_data: RecipeData
-    ) -> List[DaqNodeAction]:
+    ) -> list[DaqNodeAction]:
         _logger.debug("Configuring triggers...")
         self._wait_for_awgs = True
         self._emit_trigger = False
 
         nodes_to_configure_triggers = []
 
         dio_mode = initialization.config.dio_mode
@@ -892,15 +892,15 @@
         return nodes_to_configure_triggers
 
     def configure_as_leader(self, initialization: Initialization.Data):
         raise LabOneQControllerException("SHFQA cannot be configured as leader")
 
     def collect_follower_configuration_nodes(
         self, initialization: Initialization.Data
-    ) -> List[DaqNodeAction]:
+    ) -> list[DaqNodeAction]:
         dio_mode = initialization.config.dio_mode
         _logger.debug("%s: Configuring as a follower...", self.dev_repr)
 
         nodes_to_configure_as_follower = []
 
         if dio_mode == DIOConfigType.ZSYNC_DIO:
             _logger.debug(
@@ -918,15 +918,15 @@
 
         return nodes_to_configure_as_follower
 
     def get_measurement_data(
         self,
         channel: int,
         acquisition_type: AcquisitionType,
-        result_indices: List[int],
+        result_indices: list[int],
         num_results: int,
         hw_averages: int,
     ):
         assert len(result_indices) == 1
         result_path = f"/{self.serial}/qachannels/{channel}/" + (
             "spectroscopy/result/data/wave"
             if acquisition_type == AcquisitionType.SPECTROSCOPY
@@ -987,15 +987,15 @@
             raise LabOneQControllerException(
                 f"The number of measurements ({actual_results}) executed for device {self.serial} "
                 f"on channel {channel} does not match the number of measurements "
                 f"defined ({expected_results}). Probably the time between measurements or within "
                 f"a loop is too short. Please contact Zurich Instruments."
             )
 
-    def collect_reset_nodes(self) -> List[DaqNodeAction]:
+    def collect_reset_nodes(self) -> list[DaqNodeAction]:
         reset_nodes = super().collect_reset_nodes()
         reset_nodes.append(
             DaqNodeSetAction(
                 self._daq,
                 f"/{self.serial}/qachannels/*/generator/enable",
                 0,
                 caching_strategy=CachingStrategy.NO_CACHE,
```

## laboneq/controller/devices/device_shfsg.py

```diff
@@ -1,14 +1,14 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 import logging
-from typing import Any, Dict, List, Optional, Set
+from typing import Any
 
 import numpy
 from numpy import typing as npt
 
 from laboneq.controller.communication import (
     CachingStrategy,
     DaqNodeAction,
@@ -119,40 +119,40 @@
             )
 
     def _osc_group_by_channel(self, channel: int) -> int:
         return channel
 
     def _get_next_osc_index(
         self, osc_group: int, previously_allocated: int
-    ) -> Optional[int]:
+    ) -> int | None:
         if previously_allocated >= 8:
             return None
         return previously_allocated
 
     def _make_osc_path(self, channel: int, index: int) -> str:
         return f"/{self.serial}/sgchannels/{channel}/oscs/{index}/freq"
 
     def disable_outputs(
-        self, outputs: Set[int], invert: bool
-    ) -> List[DaqNodeSetAction]:
-        channels_to_disable: List[DaqNodeSetAction] = []
+        self, outputs: set[int], invert: bool
+    ) -> list[DaqNodeSetAction]:
+        channels_to_disable: list[DaqNodeSetAction] = []
         for ch in range(self._channels):
             if (ch in outputs) != invert:
                 channels_to_disable.append(
                     DaqNodeSetAction(
                         self._daq,
                         f"/{self.serial}/sgchannels/{ch}/output/on",
                         0,
                         caching_strategy=CachingStrategy.NO_CACHE,
                     )
                 )
         return channels_to_disable
 
-    def _nodes_to_monitor_impl(self) -> List[str]:
-        nodes = []
+    def _nodes_to_monitor_impl(self) -> list[str]:
+        nodes = super()._nodes_to_monitor_impl()
         for awg in range(self._get_num_awgs()):
             nodes.append(f"/{self.serial}/sgchannels/{awg}/awg/enable")
             nodes.append(f"/{self.serial}/sgchannels/{awg}/awg/ready")
         return nodes
 
     def collect_execution_nodes(self):
         _logger.debug("Starting execution...")
@@ -174,35 +174,35 @@
                     f"/{self.serial}/system/internaltrigger/enable",
                     1,
                     caching_strategy=CachingStrategy.NO_CACHE,
                 )
             ]
         return []
 
-    def conditions_for_execution_ready(self) -> Dict[str, Any]:
-        conditions: Dict[str, Any] = {}
+    def conditions_for_execution_ready(self) -> dict[str, Any]:
+        conditions: dict[str, Any] = {}
         if self._wait_for_awgs:
             for awg_index in self._allocated_awgs:
                 conditions[f"/{self.serial}/sgchannels/{awg_index}/awg/enable"] = 1
         return conditions
 
     def conditions_for_execution_done(
         self, acquisition_type: AcquisitionType
-    ) -> Dict[str, Any]:
-        conditions: Dict[str, Any] = {}
+    ) -> dict[str, Any]:
+        conditions: dict[str, Any] = {}
         for awg_index in self._allocated_awgs:
             conditions[f"/{self.serial}/sgchannels/{awg_index}/awg/enable"] = 0
         return conditions
 
-    def collect_output_initialization_nodes(
+    def collect_initialization_nodes(
         self, device_recipe_data: DeviceRecipeData, initialization: Initialization.Data
-    ) -> List[DaqNodeSetAction]:
+    ) -> list[DaqNodeSetAction]:
         _logger.debug("%s: Initializing device...", self.dev_repr)
 
-        nodes_to_initialize_output: List[DaqNodeSetAction] = []
+        nodes_to_initialize_output: list[DaqNodeSetAction] = []
 
         outputs = initialization.outputs or []
 
         for output in outputs:
             self._warn_for_unsupported_param(
                 output.offset is None or output.offset == 0,
                 "voltage_offsets",
@@ -329,15 +329,15 @@
         )
 
     def collect_awg_before_upload_nodes(
         self, initialization: Initialization.Data, recipe_data: RecipeData
     ):
         nodes_to_initialize_measurement = []
 
-        center_frequencies: Dict[int, IO.Data] = {}
+        center_frequencies: dict[int, IO.Data] = {}
 
         def get_synth_idx(io: IO.Data):
             if io.channel >= self._channels:
                 raise LabOneQControllerException(
                     f"{self.dev_repr}: Attempt to configure channel {io.channel + 1} on a device "
                     f"with {self._channels} channels. Verify your device setup."
                 )
@@ -391,15 +391,15 @@
                     )
                 )
 
         return nodes_to_initialize_measurement
 
     def collect_trigger_configuration_nodes(
         self, initialization: Initialization.Data, recipe_data: RecipeData
-    ) -> List[DaqNodeAction]:
+    ) -> list[DaqNodeAction]:
         _logger.debug("Configuring triggers...")
         self._wait_for_awgs = True
         self._emit_trigger = False
 
         ntc = []
 
         for awg_key, awg_config in recipe_data.awg_configs.items():
@@ -485,30 +485,30 @@
             )
 
         nodes_to_configure_triggers = [
             DaqNodeSetAction(self._daq, f"/{self.serial}/{node}", v) for node, v in ntc
         ]
         return nodes_to_configure_triggers
 
-    def add_command_table_header(self, body: dict) -> Dict:
+    def add_command_table_header(self, body: dict) -> dict:
         return {
             "$schema": "https://docs.zhinst.com/shfsg/commandtable/v1_1/schema",
             "header": {"version": "1.1.0"},
             "table": body,
         }
 
     def command_table_path(self, awg_index: int) -> str:
         return f"/{self.serial}/sgchannels/{awg_index}/awg/commandtable/"
 
     def configure_as_leader(self, initialization: Initialization.Data):
         raise LabOneQControllerException("SHFSG cannot be configured as leader")
 
     def collect_follower_configuration_nodes(
         self, initialization: Initialization.Data
-    ) -> List[DaqNodeAction]:
+    ) -> list[DaqNodeAction]:
         if self.options.qc_with_qa:
             return []  # QC follower config is done over it's QA part
 
         dio_mode = initialization.config.dio_mode
         _logger.debug("%s: Configuring as a follower...", self.dev_repr)
 
         nodes_to_configure_as_follower = []
@@ -528,15 +528,15 @@
         else:
             raise LabOneQControllerException(
                 f"Unsupported DIO mode: {dio_mode} for device type SHFSG."
             )
 
         return nodes_to_configure_as_follower
 
-    def collect_reset_nodes(self) -> List[DaqNodeAction]:
+    def collect_reset_nodes(self) -> list[DaqNodeAction]:
         reset_nodes = super().collect_reset_nodes()
         reset_nodes.append(
             DaqNodeSetAction(
                 self._daq,
                 f"/{self.serial}/sgchannels/*/awg/enable",
                 0,
                 caching_strategy=CachingStrategy.NO_CACHE,
```

## laboneq/controller/devices/device_uhfqa.py

```diff
@@ -1,14 +1,14 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 import logging
-from typing import Any, Dict, List, Optional, Set
+from typing import Any
 
 import numpy as np
 
 from laboneq.controller.communication import (
     CachingStrategy,
     DaqNodeAction,
     DaqNodeGetAction,
@@ -52,37 +52,37 @@
         return 1
 
     def _osc_group_by_channel(self, channel: int) -> int:
         return channel
 
     def _get_next_osc_index(
         self, osc_group: int, previously_allocated: int
-    ) -> Optional[int]:
+    ) -> int | None:
         if previously_allocated >= 1:
             return None
         return previously_allocated
 
     def disable_outputs(
-        self, outputs: Set[int], invert: bool
-    ) -> List[DaqNodeSetAction]:
-        channels_to_disable: List[DaqNodeSetAction] = []
+        self, outputs: set[int], invert: bool
+    ) -> list[DaqNodeSetAction]:
+        channels_to_disable: list[DaqNodeSetAction] = []
         for ch in range(self._channels):
             if (ch in outputs) != invert:
                 channels_to_disable.append(
                     DaqNodeSetAction(
                         self._daq,
                         f"/{self.serial}/sigouts/{ch}/on",
                         0,
                         caching_strategy=CachingStrategy.NO_CACHE,
                     )
                 )
         return channels_to_disable
 
-    def _nodes_to_monitor_impl(self) -> List[str]:
-        nodes = [f"/{self.serial}/system/extclk"]
+    def _nodes_to_monitor_impl(self) -> list[str]:
+        nodes = super()._nodes_to_monitor_impl()
         for awg in range(self._get_num_awgs()):
             nodes.append(f"/{self.serial}/awgs/{awg}/enable")
             nodes.append(f"/{self.serial}/awgs/{awg}/ready")
         return nodes
 
     def _error_as_leader(self):
         raise LabOneQControllerException(
@@ -92,15 +92,15 @@
 
     def _error_ambiguous_upstream(self):
         raise LabOneQControllerException(
             f"{self.dev_repr}: Can't determine unambiguously upstream device for UHFQA, ensure "
             f"correct DIO connection in the device setup"
         )
 
-    def update_clock_source(self, force_internal: Optional[bool]):
+    def update_clock_source(self, force_internal: bool | None):
         if len(self._uplinks) == 0:
             self._error_as_leader()
         if len(self._uplinks) > 1:
             self._error_ambiguous_upstream()
         upstream = next(iter(self._uplinks.values()))()
         if upstream is None:
             self._error_ambiguous_upstream()
@@ -108,33 +108,33 @@
             upstream.device_qualifier.driver.upper() == "HDAWG"
         )
         # For non-desktop, always use external clock,
         # for desktop - internal is the default (force_internal is None),
         # but allow override to external.
         self._use_internal_clock = is_desktop and (force_internal is not False)
 
-    def clock_source_control_nodes(self) -> List[NodeControlBase]:
+    def clock_source_control_nodes(self) -> list[NodeControlBase]:
         source = (
             REFERENCE_CLOCK_SOURCE_INTERNAL
             if self._use_internal_clock
             else REFERENCE_CLOCK_SOURCE_EXTERNAL
         )
         return [
             Command(f"/{self.serial}/system/extclk", source),
         ]
 
     def configure_acquisition(
         self,
         awg_key: AwgKey,
         awg_config: AwgConfig,
-        integrator_allocations: List[IntegratorAllocation.Data],
+        integrator_allocations: list[IntegratorAllocation.Data],
         averages: int,
         averaging_mode: AveragingMode,
         acquisition_type: AcquisitionType,
-    ) -> List[DaqNodeAction]:
+    ) -> list[DaqNodeAction]:
         nodes = [
             *self._configure_result_logger(
                 awg_key,
                 awg_config,
                 integrator_allocations,
                 averages,
                 averaging_mode,
@@ -148,15 +148,15 @@
         ]
         return nodes
 
     def _configure_result_logger(
         self,
         awg_key: AwgKey,
         awg_config: AwgConfig,
-        integrator_allocations: List[IntegratorAllocation.Data],
+        integrator_allocations: list[IntegratorAllocation.Data],
         averages: int,
         averaging_mode: AveragingMode,
         acquisition_type: AcquisitionType,
     ):
         nodes_to_initialize_result_acquisition = []
 
         enable = acquisition_type != AcquisitionType.RAW
@@ -236,24 +236,24 @@
             DaqNodeSetAction(
                 self._daq, f"/{self.serial}/qas/0/monitor/enable", 1 if enable else 0
             )
         )
 
         return nodes_to_initialize_input_monitor
 
-    def conditions_for_execution_ready(self) -> Dict[str, Any]:
-        conditions: Dict[str, Any] = {}
+    def conditions_for_execution_ready(self) -> dict[str, Any]:
+        conditions: dict[str, Any] = {}
         for awg_index in self._allocated_awgs:
             conditions[f"/{self.serial}/awgs/{awg_index}/enable"] = 1
         return conditions
 
     def conditions_for_execution_done(
         self, acquisition_type: AcquisitionType
-    ) -> Dict[str, Any]:
-        conditions: Dict[str, Any] = {}
+    ) -> dict[str, Any]:
+        conditions: dict[str, Any] = {}
         for awg_index in self._allocated_awgs:
             conditions[f"/{self.serial}/awgs/{awg_index}/enable"] = 0
         return conditions
 
     def _validate_range(self, io: IO.Data, is_out: bool):
         if io.range is None:
             return
@@ -278,20 +278,20 @@
                 self.dev_repr,
                 label,
                 io.channel,
                 io.range,
                 range_list,
             )
 
-    def collect_output_initialization_nodes(
+    def collect_initialization_nodes(
         self, device_recipe_data: DeviceRecipeData, initialization: Initialization.Data
-    ) -> List[DaqNodeAction]:
+    ) -> list[DaqNodeAction]:
         _logger.debug("%s: Initializing device...", self.dev_repr)
 
-        nodes_to_initialize_output: List[DaqNodeAction] = []
+        nodes_to_initialize_output: list[DaqNodeAction] = []
 
         outputs = initialization.outputs or []
         for output in outputs:
             self._warn_for_unsupported_param(
                 output.gains is None, "correction_matrix", output.channel
             )
 
@@ -569,15 +569,15 @@
                 )
             )
 
         return nodes_to_initialize_measurement
 
     def collect_trigger_configuration_nodes(
         self, initialization: Initialization.Data, recipe_data: RecipeData
-    ) -> List[DaqNodeAction]:
+    ) -> list[DaqNodeAction]:
         _logger.debug("Configuring triggers...")
         _logger.debug("Configuring strobe index: 16.")
         _logger.debug("Configuring strobe slope: 0.")
         _logger.debug("Configuring valid polarity: 2.")
         _logger.debug("Configuring valid index: 16.")
         _logger.debug("Configuring dios mode: 2.")
         _logger.debug("Configuring dios drive: 0x3.")
@@ -640,19 +640,14 @@
             )
 
         return nodes_to_configure_triggers
 
     def configure_as_leader(self, initialization: Initialization.Data):
         self._error_as_leader()
 
-    def collect_follower_configuration_nodes(
-        self, initialization: Initialization.Data
-    ) -> List[DaqNodeAction]:
-        return []
-
     def _get_integrator_measurement_data(
         self, result_index, num_results, averages_divider: int
     ):
         result_path = f"/{self.serial}/qas/0/result/data/{result_index}/wave"
         # @TODO(andreyk): replace the raw daq reply parsing on site here and hide it inside
         # Communication class
         data_node_query = self._daq.get_raw(result_path)
@@ -663,15 +658,15 @@
         )
         return data_node_query[result_path][0]["vector"] / averages_divider
 
     def get_measurement_data(
         self,
         channel: int,
         acquisition_type: AcquisitionType,
-        result_indices: List[int],
+        result_indices: list[int],
         num_results: int,
         hw_averages: int,
     ):
         averages_divider = (
             1 if acquisition_type == AcquisitionType.DISCRIMINATION else hw_averages
         )
         assert len(result_indices) <= 2
```

## laboneq/controller/devices/device_zi.py

```diff
@@ -6,30 +6,29 @@
 import json
 import logging
 import math
 import os
 import os.path
 import re
 import time
-from abc import ABC, abstractmethod
+from abc import ABC
 from copy import deepcopy
 from dataclasses import dataclass
 from enum import Enum
 from math import floor
-from typing import TYPE_CHECKING, Any, Dict, List, Optional, Set, Tuple, Union
+from typing import TYPE_CHECKING, Any
 from weakref import ReferenceType, ref
 
 import numpy as np
 import zhinst.core
 import zhinst.utils
 from numpy import typing as npt
 from zhinst.core.errors import CoreError as LabOneCoreError  # pylint: disable=E0401
 
 from laboneq.controller.communication import (
-    AwgModuleWrapper,
     CachingStrategy,
     DaqNodeAction,
     DaqNodeGetAction,
     DaqNodeSetAction,
     DaqWrapper,
 )
 from laboneq.controller.devices.zi_node_monitor import NodeControlBase
@@ -39,15 +38,14 @@
     OscillatorParam,
 )
 from laboneq.controller.recipe_processor import (
     AwgConfig,
     AwgKey,
     DeviceRecipeData,
     RecipeData,
-    RtExecutionInfo,
 )
 from laboneq.controller.util import LabOneQControllerException
 from laboneq.core.types.enums.acquisition_type import AcquisitionType
 from laboneq.core.types.enums.averaging_mode import AveragingMode
 
 if TYPE_CHECKING:
     from laboneq.core.types import CompiledExperiment
@@ -65,64 +63,58 @@
     ERROR = 1
     WARNING = 2
 
 
 @dataclass
 class AllocatedOscillator:
     group: int
-    channels: Set[int]
+    channels: set[int]
     index: int
     id: str
     frequency: float
     param: str
 
 
 @dataclass
 class DeviceOptions:
     serial: str
     interface: str
-    dev_type: Optional[str] = None
+    dev_type: str | None = None
     is_qc: bool = False
     qc_with_qa: bool = False
-    is_using_standalone_compiler: bool = True
     gen2: bool = False
 
 
 @dataclass
 class DeviceQualifier:
     dry_run: bool = True
     driver: str = None
     server: DaqWrapper = None
     options: DeviceOptions = None
 
 
 class DeviceZI(ABC):
     def __init__(self, device_qualifier: DeviceQualifier):
         self._device_qualifier: DeviceQualifier = device_qualifier
-        self._downlinks: Dict[str, Tuple[str, ReferenceType[DeviceZI]]] = {}
-        self._uplinks: Dict[str, ReferenceType[DeviceZI]] = {}
+        self._downlinks: dict[str, tuple[str, ReferenceType[DeviceZI]]] = {}
+        self._uplinks: dict[str, ReferenceType[DeviceZI]] = {}
+        self._rf_offsets: dict[int, float] = []
 
         self._daq: DaqWrapper = device_qualifier.server
         self.dev_type: str = None
-        self.dev_opts: List[str] = []
+        self.dev_opts: list[str] = []
         self._connected = False
-        self._allocated_oscs: List[AllocatedOscillator] = []
-        self._allocated_awgs: Set[int] = set()
+        self._allocated_oscs: list[AllocatedOscillator] = []
+        self._allocated_awgs: set[int] = set()
         self._nodes_to_monitor = None
         self._sampling_rate = None
 
-        self._is_using_standalone_compiler = (
-            device_qualifier.options.is_using_standalone_compiler
-        )
-
         if self._daq is None:
             raise LabOneQControllerException("ZI devices need daq")
 
-        self._awg_modules: List[AwgModuleWrapper] = []
-
         if self.serial is None:
             raise LabOneQControllerException(
                 "ZI device must be provided with serial number via options"
             )
 
         if self.interface is None or self.interface == "":
             raise LabOneQControllerException(
@@ -157,15 +149,15 @@
     def interface(self):
         return self.options.interface.lower()
 
     @property
     def daq(self):
         return self._daq
 
-    def add_command_table_header(self, body: Dict) -> Dict:
+    def add_command_table_header(self, body: dict) -> dict:
         # Stub, implement in sub-class
         _logger.debug("Command table unavailable on device %s", self.dev_repr)
         return {}
 
     def command_table_path(self, awg_index: int) -> str:
         # Stub, implement in sub-class
         _logger.debug("No command table available for device %s", self.dev_repr)
@@ -185,23 +177,23 @@
 
     def _process_dev_opts(self):
         pass
 
     def _get_sequencer_type(self) -> str:
         return "auto-detect"
 
-    def _get_sequencer_path_patterns(self) -> Dict[str, str]:
+    def _get_sequencer_path_patterns(self) -> dict[str, str]:
         return {
             "elf": "/{serial}/awgs/{index}/elf/data",
             "progress": "/{serial}/awgs/{index}/elf/progress",
             "enable": "/{serial}/awgs/{index}/enable",
             "ready": "/{serial}/awgs/{index}/ready",
         }
 
-    def get_sequencer_paths(self, index: int) -> Dict[str, str]:
+    def get_sequencer_paths(self, index: int) -> dict[str, str]:
         props = {
             "serial": self.serial,
             "index": index,
         }
         patterns = self._get_sequencer_path_patterns()
         return {k: v.format(**props) for k, v in patterns.items()}
 
@@ -222,35 +214,31 @@
     def is_follower(self):
         # Treat standalone devices as followers
         return len(self._uplinks) > 0 or self.is_standalone()
 
     def is_standalone(self):
         return len(self._uplinks) == 0 and len(self._downlinks) == 0
 
-    @abstractmethod
-    def collect_output_initialization_nodes(
+    def collect_initialization_nodes(
         self, device_recipe_data: DeviceRecipeData, initialization: Initialization.Data
-    ) -> List[DaqNodeAction]:
-        ...
+    ) -> list[DaqNodeAction]:
+        return []
 
-    @abstractmethod
     def collect_trigger_configuration_nodes(
         self, initialization: Initialization.Data, recipe_data: RecipeData
-    ) -> List[DaqNodeAction]:
-        ...
+    ) -> list[DaqNodeAction]:
+        return []
 
-    @abstractmethod
     def configure_as_leader(self, initialization: Initialization.Data):
-        ...
+        pass
 
-    @abstractmethod
     def collect_follower_configuration_nodes(
         self, initialization: Initialization.Data
-    ) -> List[DaqNodeAction]:
-        ...
+    ) -> list[DaqNodeAction]:
+        return []
 
     def _connect_to_data_server(self):
         if self._connected:
             return
 
         _logger.debug("%s: Connecting to %s interface.", self.dev_repr, self.interface)
         try:
@@ -274,63 +262,30 @@
         dev_opts = dev_traits.get(dev_opts_path)
         if isinstance(dev_type, str):
             self.dev_type = dev_type
         if isinstance(dev_opts, str):
             self.dev_opts = dev_opts.split("\n")
         self._process_dev_opts()
 
-        if not self._is_using_standalone_compiler:
-            for i in range(self._get_num_awgs()):
-                awg_module = self._daq.create_awg_module(
-                    f"{self.serial}:awg_module{str(i)}"
-                )
-                self._awg_modules.append(awg_module)
-                awg_config = [
-                    DaqNodeSetAction(awg_module, "/index", i),
-                    DaqNodeSetAction(awg_module, "/device", self.serial),
-                ]
-                if self.options.is_qc:
-                    awg_config.append(
-                        DaqNodeSetAction(
-                            awg_module, "/sequencertype", self._get_sequencer_type()
-                        )
-                    )
-                awg_module.batch_set(awg_config)
-                awg_module.execute()
-                _logger.debug("%s: Creating AWG Module #%d", self.dev_repr, i)
-
         self._connected = True
 
     def connect(self):
         self._connect_to_data_server()
         self._daq.node_monitor.add_nodes(self.nodes_to_monitor())
 
     def disconnect(self):
         if not self._connected:
             return
 
-        if not self._is_using_standalone_compiler:
-            for awg_module in self._awg_modules:
-                # Hack, but soon awg modules will be removed entirely,
-                # making proper interface is not feasible
-                self._daq._awg_module_wrappers = [
-                    wrapper
-                    for wrapper in self._daq._awg_module_wrappers
-                    if wrapper.name != awg_module.name
-                ]
-                awg_module._api_wrapper("finish")
-                awg_module._api_wrapper("clear")
-            self._awg_modules = []
-
         self._daq.disconnectDevice(self.serial)
         self._connected = False
 
     def disable_outputs(
-        self, outputs: Set[int], invert: bool
-    ) -> List[DaqNodeSetAction]:
+        self, outputs: set[int], invert: bool
+    ) -> list[DaqNodeSetAction]:
         """Returns actions to disable the specified outputs for the device.
 
         outputs: set(int)
             - When 'invert' is False: set of outputs to disable.
             - When 'invert' is True: set of used outputs to be skipped, remaining
             outputs will be disabled.
 
@@ -346,36 +301,46 @@
         )
 
     def free_allocations(self):
         self._allocated_oscs.clear()
         self._allocated_awgs.clear()
 
     def _nodes_to_monitor_impl(self):
-        return []
+        nodes = []
+        nodes.extend([node.path for node in self.clock_source_control_nodes()])
+        nodes.extend([node.path for node in self.system_freq_control_nodes()])
+        nodes.extend([node.path for node in self.rf_offset_control_nodes()])
+        return nodes
 
-    def update_clock_source(self, force_internal: Optional[bool]):
+    def update_clock_source(self, force_internal: bool | None):
         pass
 
-    def clock_source_control_nodes(self) -> List[NodeControlBase]:
+    def update_rf_offsets(self, rf_offsets: dict[int, float]):
+        self._rf_offsets = rf_offsets
+
+    def clock_source_control_nodes(self) -> list[NodeControlBase]:
         return []
 
-    def system_freq_control_nodes(self) -> List[NodeControlBase]:
+    def system_freq_control_nodes(self) -> list[NodeControlBase]:
         return []
 
-    def nodes_to_monitor(self) -> List[str]:
+    def rf_offset_control_nodes(self) -> list[NodeControlBase]:
+        return []
+
+    def nodes_to_monitor(self) -> list[str]:
         if self._nodes_to_monitor is None:
             self._nodes_to_monitor = self._nodes_to_monitor_impl()
         return self._nodes_to_monitor
 
     def _osc_group_by_channel(self, channel: int) -> int:
         return channel
 
     def _get_next_osc_index(
         self, osc_group: int, previously_allocated: int
-    ) -> Optional[int]:
+    ) -> int | None:
         return None
 
     def _make_osc_path(self, channel: int, index: int) -> str:
         return f"/{self.serial}/oscs/{index}/freq"
 
     def allocate_osc(self, osc_param: OscillatorParam.Data):
         osc_group = self._osc_group_by_channel(osc_param.channel)
@@ -403,50 +368,53 @@
             if same_id_osc.frequency != osc_param.frequency:
                 raise LabOneQControllerException(
                     f"{self.dev_repr}: ambiguous frequency in recipe for oscillator "
                     f"'{osc_param.id}': {same_id_osc.frequency} != {osc_param.frequency}"
                 )
             same_id_osc.channels.add(osc_param.channel)
 
-    def configure_feedback(self, recipe_data: RecipeData) -> List[DaqNodeAction]:
+    def allocate_params(self, initialization: Initialization.Data):
+        pass
+
+    def configure_feedback(self, recipe_data: RecipeData) -> list[DaqNodeAction]:
         return []
 
     def configure_acquisition(
         self,
         awg_key: AwgKey,
         awg_config: AwgConfig,
-        integrator_allocations: List[IntegratorAllocation.Data],
+        integrator_allocations: list[IntegratorAllocation.Data],
         averages: int,
         averaging_mode: AveragingMode,
         acquisition_type: AcquisitionType,
-    ) -> List[DaqNodeAction]:
+    ) -> list[DaqNodeAction]:
         return []
 
     def get_measurement_data(
         self,
         channel: int,
         acquisition_type: AcquisitionType,
-        result_indices: List[int],
+        result_indices: list[int],
         num_results: int,
         hw_averages: int,
     ):
         return None  # default -> no results available from the device
 
     def get_input_monitor_data(self, channel: int, num_results: int):
         return None  # default -> no results available from the device
 
     def wait_for_conditions_to_start(self):
         pass
 
-    def conditions_for_execution_ready(self) -> Dict[str, Any]:
+    def conditions_for_execution_ready(self) -> dict[str, Any]:
         return {}
 
     def conditions_for_execution_done(
         self, acquisition_type: AcquisitionType
-    ) -> Dict[str, Any]:
+    ) -> dict[str, Any]:
         return {}
 
     def check_results_acquired_status(
         self, channel, acquisition_type: AcquisitionType, result_length, hw_averages
     ):
         pass
 
@@ -604,97 +572,37 @@
                     f"Requested source: {source}, actual: {sourceactual}, status: {status}, "
                     f"expected frequency: {expected_freqs}, actual: {freq}"
                 )
 
     def _adjust_frequency(self, freq):
         return freq
 
-    def collect_prepare_sweep_step_nodes_for_param(self, param: str, value: float):
-        nodes_to_set: List[DaqNodeAction] = []
+    def collect_prepare_sweep_step_nodes_for_param(
+        self, param: str, value: float
+    ) -> list[DaqNodeAction]:
+        nodes_to_set: list[DaqNodeAction] = []
         for osc in self._allocated_oscs:
             if osc.param == param:
                 freq_value = self._adjust_frequency(value)
                 nodes_to_set.append(
                     DaqNodeSetAction(
                         self._daq,
                         self._make_osc_path(next(iter(osc.channels)), osc.index),
                         freq_value,
                     )
                 )
         return nodes_to_set
 
-    def _wait_for_elf_upload(self, awg_index):
-        awg_module = self._awg_modules[awg_index]
-
-        # this cannot use batch_get because these two nodes are 'special'
-        while awg_module.progress < 1.0 and (awg_module.elf_status != 1):
-            pass
-
-        if awg_module.elf_status != 0:
-            status_string = awg_module.get(
-                DaqNodeGetAction(
-                    awg_module,
-                    "/compiler/statusstring",
-                    caching_strategy=CachingStrategy.NO_CACHE,
-                )
-            )
-            _logger.error("ELF upload error:\n%s", status_string)
-            raise LabOneQControllerException(
-                "ELF file upload to the instrument failed."
-            )
-
-    def _check_awg_compiler_status(self, awg_index):
-        _logger.debug(
-            "%s: Checking the status of compilation for AWG #%d...",
-            self.dev_repr,
-            awg_index,
-        )
-        while True:
-            awg_module = self._awg_modules[awg_index]
-            compiler_status = awg_module.get(
-                DaqNodeGetAction(
-                    awg_module,
-                    "/compiler/status",
-                    caching_strategy=CachingStrategy.NO_CACHE,
-                )
-            )
-
-            if compiler_status == AwgCompilerStatus.SUCCESS.value:
-                _logger.debug(
-                    "%s: Compilation successful on AWG #%d with no warnings, will upload the "
-                    "program to the instrument.",
-                    self.dev_repr,
-                    awg_index,
-                )
-                break
-
-            status_string = awg_module.get(
-                DaqNodeGetAction(
-                    awg_module,
-                    "/compiler/statusstring",
-                    caching_strategy=CachingStrategy.NO_CACHE,
-                )
-            )
-
-            if compiler_status in (
-                AwgCompilerStatus.ERROR.value,
-                AwgCompilerStatus.WARNING.value,
-            ):
-                raise LabOneQControllerException(
-                    f"{self.dev_repr}: AWG compilation failed, compiler output:\n{status_string}"
-                )
-            time.sleep(0.1)
-
     @staticmethod
     def _contains_only_zero_or_one(a):
         if a is None:
             return True
         return not np.any(a * (1 - a))
 
-    def _prepare_wave_iq(self, waves, sig: str) -> Tuple[str, npt.ArrayLike]:
+    def _prepare_wave_iq(self, waves, sig: str) -> tuple[str, npt.ArrayLike]:
         wave_i = next((w for w in waves if w["filename"] == f"{sig}_i.wave"), None)
         if not wave_i:
             raise LabOneQControllerException(
                 f"I wave not found, IQ wave signature '{sig}'"
             )
 
         wave_q = next((w for w in waves if w["filename"] == f"{sig}_q.wave"), None)
@@ -749,15 +657,15 @@
             zhinst.utils.convert_awg_waveform(
                 np.clip(wave_i["samples"], -1, 1),
                 np.clip(wave_q["samples"], -1, 1),
                 markers=marker_samples,
             ),
         )
 
-    def _prepare_wave_single(self, waves, sig: str) -> Tuple[str, npt.ArrayLike]:
+    def _prepare_wave_single(self, waves, sig: str) -> tuple[str, npt.ArrayLike]:
         wave = next((w for w in waves if w["filename"] == f"{sig}.wave"), None)
         marker_samples = None
         try:
             marker_samples = next(
                 (w for w in waves if w["filename"] == f"{sig}_marker1.wave")
             )["samples"]
         except StopIteration:
@@ -771,30 +679,30 @@
         if not wave:
             raise LabOneQControllerException(f"Wave not found, signature '{sig}'")
 
         return sig, zhinst.utils.convert_awg_waveform(
             np.clip(wave["samples"], -1, 1), markers=marker_samples
         )
 
-    def _prepare_wave_complex(self, waves, sig: str) -> Tuple[str, npt.ArrayLike]:
+    def _prepare_wave_complex(self, waves, sig: str) -> tuple[str, npt.ArrayLike]:
         filename_to_find = f"{sig}.wave"
         wave = next((w for w in waves if w["filename"] == filename_to_find), None)
 
         if not wave:
             raise LabOneQControllerException(
                 f"Wave not found, signature '{sig}' filename '{filename_to_find}'"
             )
 
         return sig, np.array(wave["samples"], dtype=np.complex128)
 
     def _prepare_waves(
         self, compiled: CompiledExperiment, seqc_filename: str
-    ) -> List[Tuple[str, npt.ArrayLike]]:
+    ) -> list[tuple[str, npt.ArrayLike]]:
         wave_indices_filename = os.path.splitext(seqc_filename)[0] + "_waveindices.csv"
-        wave_indices: Dict[str, List[Union[int, str]]] = next(
+        wave_indices: dict[str, list[int | str]] = next(
             (
                 i
                 for i in compiled.wave_indices
                 if i["filename"] == wave_indices_filename
             ),
             {"value": {}},
         )["value"]
@@ -810,24 +718,24 @@
                 waves_by_index[idx] = self._prepare_wave_complex(waves, sig)
             else:
                 raise LabOneQControllerException(
                     f"Unexpected signal type for binary wave for '{sig}' in '{seqc_filename}' - "
                     f"'{sig_type}', should be one of [iq, double, multi, single, complex]"
                 )
 
-        bin_waves: List[Tuple[str, npt.ArrayLike]] = []
+        bin_waves: list[tuple[str, npt.ArrayLike]] = []
         idx = 0
         while idx in waves_by_index:
             bin_waves.append(waves_by_index[idx])
             idx += 1
         return bin_waves
 
     def _prepare_command_table(
         self, compiled: CompiledExperiment, seqc_filename: str
-    ) -> Optional[Dict]:
+    ) -> dict | None:
         command_table_body = next(
             (ct["ct"] for ct in compiled.command_tables if ct["seqc"] == seqc_filename),
             None,
         )
 
         if command_table_body is None:
             return None
@@ -840,21 +748,21 @@
             oscillator_uid = entry["oscillatorSelect"]["value"]["$ref"]
             entry["oscillatorSelect"]["value"] = oscillator_map[oscillator_uid]
 
         return self.add_command_table_header(command_table_body)
 
     def prepare_seqc(
         self, seqc_filename: str, compiled: CompiledExperiment
-    ) -> Tuple[str, List[Tuple[str, npt.ArrayLike]], Dict[Any]]:
+    ) -> tuple[str, list[tuple[str, npt.ArrayLike]], dict[Any]]:
         """
         `compiled` expected to have the following members:
-         - `src`   -> List[Dict[str, str]]
+         - `src`   -> list[dict[str, str]]
                         `filename` -> `<seqc_filename>`
                         `text`     -> `<seqc_content>`
-         - `waves` -> List[Dict[str, str]]
+         - `waves` -> list[dict[str, str]]
                         `filename` -> `<wave_filename_csv>`
                         `text`     -> `<wave_content_csv>`
 
         Returns a tuple of
          1. str: seqc text to pass to the awg compiler
          2. list[(str, array)]: waves(id, samples) to upload to the instrument (ordered by index)
          3. dict: command table
@@ -908,15 +816,15 @@
             filename=filename,
             caching_strategy=CachingStrategy.NO_CACHE,
         )
 
     def prepare_upload_all_binary_waves(
         self,
         awg_index,
-        waves: List[Tuple[str, npt.ArrayLike]],
+        waves: list[tuple[str, npt.ArrayLike]],
         acquisition_type: AcquisitionType,
     ):
         # Default implementation for "old" devices, override for newer devices
         return [
             self.prepare_upload_binary_wave(
                 filename=filename,
                 waveform=waveform,
@@ -926,32 +834,32 @@
             )
             for wave_index, [filename, waveform] in enumerate(waves)
         ]
 
     def _upload_all_binary_waves(
         self,
         awg_index,
-        waves: List[Tuple[str, npt.ArrayLike]],
+        waves: list[tuple[str, npt.ArrayLike]],
         acquisition_type: AcquisitionType,
     ):
         waves_upload = self.prepare_upload_all_binary_waves(
             awg_index, waves, acquisition_type
         )
         self._daq.batch_set(waves_upload)
 
-    def prepare_upload_command_table(self, awg_index, command_table: Dict):
+    def prepare_upload_command_table(self, awg_index, command_table: dict):
         command_table_path = self.command_table_path(awg_index)
         return DaqNodeSetAction(
             self._daq,
             command_table_path + "data",
             json.dumps(command_table, sort_keys=True),
             caching_strategy=CachingStrategy.NO_CACHE,
         )
 
-    def upload_command_table(self, awg_index, command_table: Dict):
+    def upload_command_table(self, awg_index, command_table: dict):
         command_table_path = self.command_table_path(awg_index)
         self._daq.batch_set(
             [self.prepare_upload_command_table(awg_index, command_table)]
         )
 
         status_path = command_table_path + "status"
 
@@ -968,46 +876,14 @@
 
         if status & 0b1000 != 0:
             raise LabOneQControllerException("Failed to parse command table JSON")
         if not self.dry_run:
             if status & 0b0001 == 0:
                 raise LabOneQControllerException("Failed to upload command table")
 
-    def _compile_and_upload_seqc(
-        self, code: str, awg_index: int, filename_hint: str = None
-    ):
-        try:
-            _logger.debug(
-                "%s: Running AWG compiler on AWG #%d...",
-                self.dev_repr,
-                awg_index,
-            )
-            awg_module = self._awg_modules[awg_index]
-            awg_module.batch_set(
-                [
-                    DaqNodeSetAction(
-                        awg_module,
-                        "/compiler/sourcestring",
-                        code,
-                        filename=filename_hint,
-                        caching_strategy=CachingStrategy.NO_CACHE,  # if only external waves changed
-                    )
-                ]
-            )
-        except LabOneQControllerException as exc:
-            raise LabOneQControllerException(
-                f"Exception raised while uploading program from file {filename_hint} "
-                f"to AWG #{awg_index}\nSeqC code:\n{code}"
-            ) from exc
-
-        # TODO(2K): handle timeout, emit:
-        # f"{str(exp)}\nAWG compiler timed out while trying to compile:\n{data}\n"
-        self._check_awg_compiler_status(awg_index)
-        self._wait_for_elf_upload(awg_index)
-
     def compile_seqc(self, code: str, awg_index: int, filename_hint: str = None):
         _logger.debug(
             "%s: Compiling sequence for AWG #%d...",
             self.dev_repr,
             awg_index,
         )
         sequencer = self._get_sequencer_type()
@@ -1039,50 +915,18 @@
             "%s: Compilation successful on AWG #%d with no warnings.",
             self.dev_repr,
             awg_index,
         )
 
         return elf
 
-    def upload_awg_program(
-        self, initialization: Initialization.Data, recipe_data: RecipeData
-    ):
-        assert not self._is_using_standalone_compiler
-
-        if initialization.awgs is None:
-            return
-
-        acquisition_type = RtExecutionInfo.get_acquisition_type(
-            recipe_data.rt_execution_infos
-        )
-
-        for awg_obj in initialization.awgs:
-            awg_index = awg_obj.awg
-
-            _logger.debug(
-                "%s: Starting to compile and upload AWG program '%s' to AWG #%d",
-                self.dev_repr,
-                awg_obj.seqc,
-                awg_index,
-            )
-
-            data, waves, command_table = self.prepare_seqc(
-                awg_obj.seqc, recipe_data.compiled
-            )
-
-            self._compile_and_upload_seqc(data, awg_index, filename_hint=awg_obj.seqc)
-
-            self._upload_all_binary_waves(awg_index, waves, acquisition_type)
-            if command_table is not None:
-                self.upload_command_table(awg_index, command_table)
-
     def _get_num_awgs(self):
         return 0
 
-    def collect_osc_initialization_nodes(self) -> List[DaqNodeAction]:
+    def collect_osc_initialization_nodes(self) -> list[DaqNodeAction]:
         nodes_to_initialize_oscs = []
         osc_inits = {
             self._make_osc_path(ch, osc.index): osc.frequency
             for osc in self._allocated_oscs
             for ch in osc.channels
         }
         for path, freq in osc_inits.items():
@@ -1126,15 +970,15 @@
         error_node = f"/{self.serial}/raw/error/json/errors"
         all_errors = self._daq.get_raw(error_node)
         if not self.dry_run:
             # for proper testing of the logic we have to mock the data server better.
             # Currently is returns 0 for all nodes...
             check_errors(all_errors[error_node], self.dev_repr)
 
-    def collect_reset_nodes(self) -> List[DaqNodeAction]:
+    def collect_reset_nodes(self) -> list[DaqNodeAction]:
         return [DaqNodeSetAction(self._daq, f"/{self.serial}/raw/error/clear", 1)]
 
     def _get_total_rounded_delay_samples(
         self,
         port,
         sample_frequency_hz,
         granularity_samples,
```

## laboneq/controller/devices/zi_emulator.py

```diff
@@ -8,15 +8,15 @@
 import re
 import sched
 import time
 from abc import ABC, abstractmethod
 from dataclasses import dataclass, field
 from enum import Enum
 from functools import partial
-from typing import Any, Callable, Dict, List, Optional, Tuple, Union, overload
+from typing import Any, Callable, overload
 
 import numpy as np
 from numpy import typing as npt
 
 
 @dataclass
 class NodeBase:
@@ -91,15 +91,15 @@
     DYNAMIC = NodeDynamic
 
 
 @dataclass
 class NodeInfo:
     "Node descriptor to use in node definitions."
     type: NodeType = NodeType.FLOAT
-    default: Optional[Any] = None
+    default: Any | None = None
     read_only: bool = False
     handler: Callable[[NodeBase], None] = None
     # For DYNAMIC nodes
     getter: Callable[[], Any] = None
     setter: Callable[[Any], None] = None
 
     def make_node(self) -> NodeBase:
@@ -135,28 +135,28 @@
     timestamp: int = None
     value: Any = None
 
 
 class DevEmu(ABC):
     "Base class emulating a device, specialized per device type."
 
-    def __init__(self, scheduler: sched.scheduler, dev_opts: Dict[str, Any]):
+    def __init__(self, scheduler: sched.scheduler, dev_opts: dict[str, Any]):
         self._scheduler = scheduler
         self._dev_opts = dev_opts
-        self._node_tree: Dict[str, NodeBase] = {}
-        self._poll_queue: List[PollEvent] = []
+        self._node_tree: dict[str, NodeBase] = {}
+        self._poll_queue: list[PollEvent] = []
         self._total_subscribed: int = 0
         self._cached_node_def = functools.lru_cache(maxsize=None)(self._node_def)
 
     @abstractmethod
     def serial(self) -> str:
         ...
 
     @abstractmethod
-    def _node_def(self) -> Dict[str, NodeInfo]:
+    def _node_def(self) -> dict[str, NodeInfo]:
         ...
 
     def _full_path(self, dev_path: str) -> str:
         return f"/{self.serial().lower()}/{dev_path}"
 
     def _make_node(self, dev_path: str):
         node_def = self._cached_node_def()
@@ -205,15 +205,15 @@
 
     def getAsEvent(self, dev_path: str):
         node = self._get_node(dev_path)
         self._poll_queue.append(
             PollEvent(path=self._full_path(dev_path), value=node.value)
         )
 
-    def poll(self) -> List[PollEvent]:
+    def poll(self) -> list[PollEvent]:
         output = self._poll_queue[:]
         self._poll_queue.clear()
         return output
 
 
 class DevEmuZI(DevEmu):
     def serial(self) -> str:
@@ -225,15 +225,15 @@
 
     def _devices_connected(self) -> str:
         devices = [
             d.serial().upper() for d in self.server._devices.values() if d != self
         ]
         return ",".join(devices)
 
-    def _node_def(self) -> Dict[str, NodeInfo]:
+    def _node_def(self) -> dict[str, NodeInfo]:
         return {
             "about/version": NodeInfo(
                 type=NodeType.STR, default="23.02", read_only=True
             ),
             "about/revision": NodeInfo(
                 type=NodeType.STR, default="99999", read_only=True
             ),
@@ -244,25 +244,25 @@
                 type=NodeType.DYNAMIC, read_only=True, getter=self._devices_connected
             ),
         }
 
 
 class DevEmuHW(DevEmu):
     def __init__(
-        self, serial: str, scheduler: sched.scheduler, dev_opts: Dict[str, Any]
+        self, serial: str, scheduler: sched.scheduler, dev_opts: dict[str, Any]
     ):
         super().__init__(scheduler, dev_opts)
         self._serial = serial
 
     def serial(self) -> str:
         return self._serial
 
 
 class DevEmuDummy(DevEmuHW):
-    def _node_def(self) -> Dict[str, NodeInfo]:
+    def _node_def(self) -> dict[str, NodeInfo]:
         return {}
 
 
 class DevEmuHDAWG(DevEmuHW):
     def _awg_stop(self, awg_idx):
         self._set_val(f"awgs/{awg_idx}/enable", 0)
 
@@ -296,15 +296,15 @@
         self._scheduler.enter(
             delay=0.001,
             priority=0,
             action=self._ref_clock_switched,
             argument=(node.value,),
         )
 
-    def _node_def(self) -> Dict[str, NodeInfo]:
+    def _node_def(self) -> dict[str, NodeInfo]:
         nd = {
             "features/devtype": NodeInfo(
                 type=NodeType.STR,
                 default=self._dev_opts.get("features/devtype", "HDAWG8"),
             ),
             "features/options": NodeInfo(
                 type=NodeType.STR,
@@ -337,15 +337,15 @@
     """Emulated UHFQA.
 
     Supported emulation options:
         - user_readout_data - callable matching the following signature:
             user_readout_data(
                 result_index: int,
                 length: int,
-                averages: int) -> ArrayLike | List[float]
+                averages: int) -> ArrayLike | list[float]
             The function is called after every AWG execution, once for every integrator with the
             corresponding 'result_index'. It must return the vector of values of size 'length',
             that will be set to the corresponding '<devN>/qas/0/result/data/<result_index>/wave'
             node.
             The argument 'averages' is provided for convenience, as the real device returns the
             sum of all the averaged readouts. The function may also return None, in which case
             the emulator falls back to the default emulated results for this integrator.
@@ -378,15 +378,15 @@
     def _awg_ready(self):
         self._set_val("awgs/0/ready", 1)
 
     def _elf_upload(self, node: NodeBase):
         self._set_val("awgs/0/ready", 0)
         self._scheduler.enter(delay=0.001, priority=0, action=self._awg_ready)
 
-    def _node_def(self) -> Dict[str, NodeInfo]:
+    def _node_def(self) -> dict[str, NodeInfo]:
         nd = {
             "features/devtype": NodeInfo(
                 type=NodeType.STR,
                 default=self._dev_opts.get("features/devtype", "UHFQA"),
             ),
             "features/options": NodeInfo(
                 type=NodeType.STR,
@@ -426,15 +426,15 @@
         self._scheduler.enter(
             delay=0.001,
             priority=0,
             action=self._ref_clock_switched,
             argument=(node_int.value,),
         )
 
-    def _node_def(self) -> Dict[str, NodeInfo]:
+    def _node_def(self) -> dict[str, NodeInfo]:
         return {
             "execution/enable": NodeInfo(
                 type=NodeType.INT, default=0, handler=DevEmuPQSC._trig_execute
             ),
             "system/clocks/referenceclock/in/source": NodeInfo(
                 type=NodeType.INT, default=0, handler=DevEmuPQSC._ref_clock
             ),
@@ -503,15 +503,15 @@
                 )
 
     def _awg_execute_qa(self, node: NodeBase, channel: int):
         self._scheduler.enter(
             delay=0.001, priority=0, action=self._awg_stop_qa, argument=(channel,)
         )
 
-    def _node_def_qa(self) -> Dict[str, NodeInfo]:
+    def _node_def_qa(self) -> dict[str, NodeInfo]:
         nd = {}
         for channel in range(4):
             nd[f"qachannels/{channel}/generator/enable"] = NodeInfo(
                 type=NodeType.INT,
                 default=0,
                 handler=partial(DevEmuSHFQABase._awg_execute_qa, channel=channel),
             )
@@ -532,15 +532,15 @@
                 nd[f"scopes/0/channels/{scope_ch}/wave"] = NodeInfo(
                     type=NodeType.VECTOR_COMPLEX
                 )
         return nd
 
 
 class DevEmuSHFQA(DevEmuSHFQABase):
-    def _node_def(self) -> Dict[str, NodeInfo]:
+    def _node_def(self) -> dict[str, NodeInfo]:
         nd = {
             "features/devtype": NodeInfo(
                 type=NodeType.STR,
                 default=self._dev_opts.get("features/devtype", "SHFQA4"),
             ),
             "features/options": NodeInfo(
                 type=NodeType.STR,
@@ -556,27 +556,27 @@
         self._set_val(f"sgchannels/{channel}/awg/enable", 0)
 
     def _awg_execute_sg(self, node: NodeBase, channel: int):
         self._scheduler.enter(
             delay=0.001, priority=0, action=self._awg_stop_sg, argument=(channel,)
         )
 
-    def _node_def_sg(self) -> Dict[str, NodeInfo]:
+    def _node_def_sg(self) -> dict[str, NodeInfo]:
         nd = {}
         for channel in range(8):
             nd[f"sgchannels/{channel}/awg/enable"] = NodeInfo(
                 type=NodeType.INT,
                 default=0,
                 handler=partial(DevEmuSHFSGBase._awg_execute_sg, channel=channel),
             )
         return nd
 
 
 class DevEmuSHFSG(DevEmuSHFSGBase):
-    def _node_def(self) -> Dict[str, NodeInfo]:
+    def _node_def(self) -> dict[str, NodeInfo]:
         nd = {
             "features/devtype": NodeInfo(
                 type=NodeType.STR,
                 default=self._dev_opts.get("features/devtype", "SHFSG8"),
             ),
             "features/options": NodeInfo(
                 type=NodeType.STR,
@@ -584,15 +584,15 @@
             ),
         }
         nd.update(self._node_def_sg())
         return nd
 
 
 class DevEmuSHFQC(DevEmuSHFQABase, DevEmuSHFSGBase):
-    def _node_def(self) -> Dict[str, NodeInfo]:
+    def _node_def(self) -> dict[str, NodeInfo]:
         nd = {
             "features/devtype": NodeInfo(
                 type=NodeType.STR,
                 default=self._dev_opts.get("features/devtype", "SHFQC"),
             ),
             "features/options": NodeInfo(
                 type=NodeType.STR,
@@ -601,15 +601,15 @@
         }
         nd.update(self._node_def_qa())
         nd.update(self._node_def_sg())
         return nd
 
 
 class DevEmuNONQC(DevEmuHW):
-    def _node_def(self) -> Dict[str, NodeInfo]:
+    def _node_def(self) -> dict[str, NodeInfo]:
         return {}
 
 
 def _serial_to_device_type(serial: str):
     m = re.match(pattern="DEV([0-9]+)[0-9]{3}", string=serial.upper())
     if m:
         num = int(m.group(1))
@@ -625,15 +625,15 @@
             return DevEmuSHFQA
         else:
             return DevEmuDummy
     else:
         return DevEmuDummy
 
 
-def _canonical_path_list(path: Union[str, List[str]]) -> List[str]:
+def _canonical_path_list(path: str | list[str]) -> list[str]:
     if isinstance(path, list):
         paths = path
     else:
         paths = path.split(",")
     return paths
 
 
@@ -644,20 +644,20 @@
 
     def __init__(self, host: str, port: int, api_level: int):
         if api_level is None:
             api_level = 6
         assert api_level == 6
         super().__init__()
         self._scheduler = sched.scheduler()
-        self._device_type_map: Dict[str, str] = {}
+        self._device_type_map: dict[str, str] = {}
         # TODO(2K): Defer "ZI" device initialization to allow passing options
-        self._devices: Dict[str, DevEmu] = {
+        self._devices: dict[str, DevEmu] = {
             "ZI": DevEmuZI(self._scheduler, {"emu_server": self})
         }
-        self._options: Dict[str, Dict[str, Any]] = {}
+        self._options: dict[str, dict[str, Any]] = {}
 
     def map_device_type(self, serial: str, type: str):
         self._device_type_map[serial.upper()] = type.upper()
 
     def set_option(self, serial: str, option: str, value: Any):
         dev_opts = self._options.setdefault(serial.upper(), {})
         dev_opts[option] = value
@@ -687,15 +687,15 @@
         serial = serial.upper()
         device = self._devices.get(serial)
         if device is None and create:
             device = self._device_factory(serial)
             self._devices[serial] = device
         return device
 
-    def _resolve_dev(self, path: str) -> Tuple[List[DevEmu], str]:
+    def _resolve_dev(self, path: str) -> tuple[list[DevEmu], str]:
         if path.startswith("/"):
             path = path[1:]
         path_parts = path.split("/")
         devices = []
         dev_path = ""
         if "*" in path_parts[0]:
             serial_pattern = re.compile(
@@ -708,17 +708,17 @@
                 dev_path = "*"
         else:
             devices.append(self._device_lookup(path_parts[0]))
             dev_path = "/".join(path_parts[1:]).lower()
         return devices, dev_path
 
     def _resolve_paths_and_perform(
-        self, path: Union[str, List[str]], handler: Callable
-    ) -> Dict[str, NodeBase]:
-        results: Dict[str, NodeBase] = {}
+        self, path: str | list[str], handler: Callable
+    ) -> dict[str, NodeBase]:
+        results: dict[str, NodeBase] = {}
         for p in _canonical_path_list(path):
             devices, dev_path = self._resolve_dev(p)
             dev_path_suffix = "" if len(dev_path) == 0 else f"/{dev_path}"
             for device in devices:
                 results[f"/{device.serial().lower()}{dev_path_suffix}"] = handler(
                     device, dev_path
                 )
@@ -751,30 +751,28 @@
         # TODO(2K): handle flags
         raw_results = self._resolve_paths_and_perform(paths, self._get)
         # TODO(2K): reshape results
         assert flat is True
         # TODO(2K): emulate timestamp
         return raw_results
 
-    def _set(self, device: DevEmu, dev_path: str, value_dict: Dict[str, Any]):
+    def _set(self, device: DevEmu, dev_path: str, value_dict: dict[str, Any]):
         full_path = device._full_path(dev_path)
         value = value_dict[full_path]
         device.set(dev_path, value)
 
     @overload
     def set(self, path: str, value: Any):
         ...
 
     @overload
-    def set(self, items: List[List[Any]]):
+    def set(self, items: list[list[Any]]):
         ...
 
-    def set(
-        self, path_or_items: Union[str, List[List[Any]]], value: Optional[Any] = None
-    ):
+    def set(self, path_or_items: str | list[list[Any]], value: Any | None = None):
         self._progress_scheduler()
         if isinstance(path_or_items, str):
             pass
             # TODO(2K): stub
         else:
             items = path_or_items
             value_dict = {v[0].lower(): v[1] for v in items}
@@ -800,22 +798,22 @@
         for r in results.values():
             combined_result.update(r)
         return json.dumps(combined_result)
 
     def _subscribe(self, device: DevEmu, dev_path: str):
         device.subscribe(dev_path)
 
-    def subscribe(self, path: Union[str, List[str]]):
+    def subscribe(self, path: str | list[str]):
         self._progress_scheduler()
         self._resolve_paths_and_perform(path, self._subscribe)
 
     def _unsubscribe(self, device: DevEmu, dev_path: str):
         device.unsubscribe(dev_path)
 
-    def unsubscribe(self, path: Union[str, List[str]]):
+    def unsubscribe(self, path: str | list[str]):
         self._progress_scheduler()
         self._resolve_paths_and_perform(path, self._unsubscribe)
 
     def _getAsEvent(self, device: DevEmu, dev_path: str):
         device.getAsEvent(dev_path)
 
     def getAsEvent(self, path: str):
@@ -830,29 +828,25 @@
         self,
         recording_time_s: float,
         timeout_ms: int,
         flags: int = 0,
         flat: bool = False,
     ) -> Any:
         self._progress_scheduler(wait_time=recording_time_s)
-        events: List[PollEvent] = []
+        events: list[PollEvent] = []
         for dev in self._devices.values():
             events.extend(dev.poll())
         result = {}
         # TODO(2K): reshape results
         assert flat is True
         for event in events:
             path_res = result.setdefault(event.path, {"value": []})
             path_res["value"].append(event.value)
         return result
 
-    def awgModule(self) -> AWGModuleEmulator:
-        self._progress_scheduler()
-        return AWGModuleEmulator(self)
-
     def _progress_scheduler(self, wait_time: float = 0.0):
         def _delay(delay: float):
             # time.sleep is not accurate for short waits, skip for delays below 10ms
             if delay > 0.01:
                 time.sleep(delay)
 
         start = time.perf_counter()
@@ -860,51 +854,7 @@
             delay_till_next_event = self._scheduler.run(blocking=False)
             elapsed = time.perf_counter() - start
             remaining = wait_time - elapsed
             if delay_till_next_event is None or delay_till_next_event > remaining:
                 _delay(remaining)
                 break
             _delay(delay_till_next_event)
-
-
-class AWGModuleEmulator:
-    def __init__(self, parent_conn: ziDAQServerEmulator):
-        self._parent_conn = parent_conn
-
-    @overload
-    def set(self, path: str, value: Any):
-        ...
-
-    @overload
-    def set(self, items: List[List[Any]]):
-        ...
-
-    def set(
-        self, path_or_items: Union[str, List[List[Any]]], value: Optional[Any] = None
-    ):
-        if isinstance(path_or_items, str):
-            _ = path_or_items
-        else:
-            _ = path_or_items
-        # TODO(2K): stub
-
-    def get(self, path: str, flat: bool = False):
-        # TODO(2K): stub
-        results = {}
-        for p in _canonical_path_list(path):
-            if p == "/directory":
-                val = "/"
-            else:
-                val = 0
-            results[p] = [val]
-        # TODO(2K): reshape results
-        assert flat is True
-        return results
-
-    def getInt(self, path: str) -> int:
-        return 0  # TODO(2K): stub
-
-    def execute(self):
-        pass  # TODO(2K): stub
-
-    def progress(self) -> float:
-        return 1.0  # TODO(2K): stub
```

## laboneq/controller/devices/zi_node_monitor.py

```diff
@@ -1,48 +1,67 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
+from __future__ import annotations
+
 import logging
+import math
 import time
 from dataclasses import dataclass, field
 from enum import Enum, auto
-from typing import Any, Dict, Iterable, List, Optional, Tuple
+from typing import Any, Iterable
 
 from laboneq._observability.tracing import trace
 
 _logger = logging.getLogger(__name__)
 
 
 @dataclass
 class Node:
     path: str
-    values: List[Any] = field(default_factory=list)
-    last: Optional[Any] = None
+    values: list[Any] = field(default_factory=list)
+    last: Any | None = None
 
     def flush(self):
         self.values.clear()
 
-    def peek(self) -> Optional[Any]:
+    def peek(self) -> Any | None:
         return None if len(self.values) == 0 else self.values[0]
 
-    def pop(self) -> Optional[Any]:
+    def pop(self) -> Any | None:
         return None if len(self.values) == 0 else self.values.pop(0)
 
-    def get_last(self) -> Optional[Any]:
+    def get_last(self) -> Any | None:
         return self.last
 
-    def append(self, val: Dict[str, Any]):
+    def append(self, val: dict[str, Any]):
         self.values.extend(val["value"])
         self.last = self.values[-1]
 
 
+def _is_expected(val: Any, expected: list[Any | None]) -> bool:
+    for e in expected:
+        if e is None:
+            # No specific value expected, any update matches
+            return True
+        if isinstance(e, FloatWithTolerance) and math.isclose(
+            val, e.val, abs_tol=e.abs_tol
+        ):
+            # Float with given tolerance
+            return True
+        if val == e:
+            # Otherwise exact match
+            return True
+    return False
+
+
 class NodeMonitor:
     def __init__(self, daq):
         self._daq = daq
-        self._nodes: Dict[str, Node] = {}
+        self._nodes: dict[str, Node] = {}
 
     def _log_missing_node(self, path: str):
         _logger.warning(
             "Internal error: Node %s is not registered for monitoring", path
         )
 
     def _get_node(self, path: str) -> Node:
@@ -52,25 +71,25 @@
             return Node(path)
         return node
 
     def reset(self):
         self.stop()
         self._nodes.clear()
 
-    def add_nodes(self, paths: List[str]):
+    def add_nodes(self, paths: list[str]):
         for path in paths:
             if path not in self._nodes:
                 self._nodes[path] = Node(path)
 
     def start(self):
         all_paths = [p for p in self._nodes.keys()]
         if len(all_paths) > 0:
             self._daq.subscribe(all_paths)
 
-    def fetch(self, paths: List[str]):
+    def fetch(self, paths: list[str]):
         for path in paths:
             self._daq.getAsEvent(path)
 
     def stop(self):
         self._daq.unsubscribe("*")
         self.flush()
 
@@ -83,38 +102,38 @@
                 self._get_node(path).append(val)
 
     def flush(self):
         self._daq.sync()
         for node in self._nodes.values():
             node.flush()
 
-    def peek(self, path: str) -> Optional[Any]:
+    def peek(self, path: str) -> Any | None:
         return self._get_node(path).peek()
 
-    def pop(self, path: str) -> Optional[Any]:
+    def pop(self, path: str) -> Any | None:
         return self._get_node(path).pop()
 
-    def get_last(self, path: str) -> Optional[Any]:
+    def get_last(self, path: str) -> Any | None:
         return self._get_node(path).get_last()
 
-    def check_last_for_conditions(self, conditions: Dict[str, Any]) -> str:
+    def check_last_for_conditions(self, conditions: dict[str, Any]) -> str:
         for path, expected in conditions.items():
             if path not in self._nodes:
                 self._log_missing_node(path)
                 return path
             # expected may be None, single value or a list
             all_expected = expected if isinstance(expected, Iterable) else [expected]
             val = self.get_last(path)
             if val is None:
                 return path
-            if expected is not None and val not in all_expected:
+            if not _is_expected(val, all_expected):
                 return path
         return None
 
-    def poll_and_check_conditions(self, conditions: Dict[str, Any]) -> Dict[str, Any]:
+    def poll_and_check_conditions(self, conditions: dict[str, Any]) -> dict[str, Any]:
         self.poll()
         remaining = {}
         for path, expected in conditions.items():
             if path not in self._nodes:
                 self._log_missing_node(path)
                 continue
             # expected may be None, single value or a list
@@ -122,40 +141,38 @@
             while True:
                 val = self.pop(path)
                 if val is None:
                     # No further updates for the path,
                     # keep condition as is for the next check iteration
                     remaining[path] = expected
                     break
-                if expected is None or val in all_expected:
-                    # No specific value expected (any update matches) or
-                    # received value matches expected -> condition fulfilled
+                if _is_expected(val, all_expected):
                     break
         return remaining
 
 
 class MultiDeviceHandlerBase:
     def __init__(self):
-        self._conditions: Dict[NodeMonitor, Dict[str, Any]] = {}
+        self._conditions: dict[NodeMonitor, dict[str, Any]] = {}
 
-    def add(self, target: NodeMonitor, conditions: Dict[str, Any]):
-        daq_conditions: Dict[str, Any] = self._conditions.setdefault(target, {})
+    def add(self, target: NodeMonitor, conditions: dict[str, Any]):
+        daq_conditions: dict[str, Any] = self._conditions.setdefault(target, {})
         daq_conditions.update(conditions)
 
 
 class ConditionsChecker(MultiDeviceHandlerBase):
     """Non-blocking checker, ensures all conditions for multiple
     devices are fulfilled. Uses the last known node values, no additional
     polling for updates!
 
     This class must be prepared in same way as the AllRepliesWaiter,
     see AllRepliesWaiter for details.
     """
 
-    def check_all(self) -> Tuple[str, Any]:
+    def check_all(self) -> tuple[str, Any]:
         for node_monitor, daq_conditions in self._conditions.items():
             failed_path = node_monitor.check_last_for_conditions(daq_conditions)
             if failed_path is not None:
                 return failed_path, daq_conditions[failed_path]
         return None, None
 
 
@@ -212,27 +229,27 @@
         super().__init__()
         self._timer = time.time
 
     @trace("wait-for-all-nodes", disable_tracing_during=True)
     def wait_all(self, timeout: float) -> bool:
         start = self._timer()
         while True:
-            remaining: Dict[NodeMonitor, Dict[str, Any]] = {}
+            remaining: dict[NodeMonitor, dict[str, Any]] = {}
             for node_monitor, daq_conditions in self._conditions.items():
                 daq_remaining = node_monitor.poll_and_check_conditions(daq_conditions)
                 if len(daq_remaining) > 0:
                     remaining[node_monitor] = daq_remaining
             if len(remaining) == 0:
                 return True
             if self._timer() - start > timeout:
                 return False
             self._conditions = remaining
 
-    def remaining(self) -> Dict[str, Any]:
-        all_conditions: Dict[str, Any] = {}
+    def remaining(self) -> dict[str, Any]:
+        all_conditions: dict[str, Any] = {}
         for daq_conditions in self._conditions.values():
             all_conditions.update(daq_conditions)
         return all_conditions
 
     def remaining_str(self) -> str:
         return "\n".join([f"{p}={v}" for p, v in self.remaining().items()])
 
@@ -241,19 +258,31 @@
     Condition = auto()
     Command = auto()
     Response = auto()
     Prepare = auto()
 
 
 @dataclass
+class FloatWithTolerance:
+    val: float
+    abs_tol: float
+
+
+@dataclass
 class NodeControlBase:
     path: str
     value: Any
     kind: NodeControlKind = None
 
+    @property
+    def raw_value(self):
+        return (
+            self.value.val if isinstance(self.value, FloatWithTolerance) else self.value
+        )
+
 
 @dataclass
 class Condition(NodeControlBase):
     """Represents a condition to be fulfilled. Condition node may not
     necessarily receive an update after executing Command(s), if it has
     already the right value, for instance extref freq, but still must be
     verified."""
@@ -286,34 +315,26 @@
     a preparation before the main Command(s), but shouldn't be touched
     or be in a specific state otherwise."""
 
     def __post_init__(self):
         self.kind = NodeControlKind.Prepare
 
 
-def filter_commands(nodes: List[NodeControlBase]) -> Dict[str, Any]:
-    return {
-        n.path: n.value
-        for n in nodes
-        if n.kind in [NodeControlKind.Prepare, NodeControlKind.Command]
-    }
+def _filter_nodes(
+    nodes: list[NodeControlBase], filter: list[NodeControlKind]
+) -> list[NodeControlBase]:
+    return [n for n in nodes if n.kind in filter]
 
 
-def filter_responses(nodes: List[NodeControlBase]) -> Dict[str, Any]:
-    return {
-        n.path: n.value
-        for n in nodes
-        if n.kind in [NodeControlKind.Command, NodeControlKind.Response]
-    }
+def filter_commands(nodes: list[NodeControlBase]) -> list[NodeControlBase]:
+    return _filter_nodes(nodes, [NodeControlKind.Prepare, NodeControlKind.Command])
 
 
-def filter_conditions(nodes: List[NodeControlBase]) -> Dict[str, Any]:
-    return {
-        n.path: n.value
-        for n in nodes
-        if n.kind
-        in [
-            NodeControlKind.Condition,
-            NodeControlKind.Command,
-            NodeControlKind.Response,
-        ]
-    }
+def filter_responses(nodes: list[NodeControlBase]) -> list[NodeControlBase]:
+    return _filter_nodes(nodes, [NodeControlKind.Command, NodeControlKind.Response])
+
+
+def filter_conditions(nodes: list[NodeControlBase]) -> list[NodeControlBase]:
+    return _filter_nodes(
+        nodes,
+        [NodeControlKind.Condition, NodeControlKind.Command, NodeControlKind.Response],
+    )
```

## laboneq/core/path.py

```diff
@@ -39,17 +39,18 @@
 
     Arguments:
         path: The path string to split.
 
     Returns:
         A list of path elements.
     """
-    if is_abs(Separator):
-        path = path[1:]
-    return path.split(Separator)
+    parts = path.split(Separator)
+    if parts[0] == "":
+        parts = parts[1:]
+    return parts
 
 
 def starts_with(path: str, prefix: str, ignore_abs_path: bool = False):
     """Test if a path string starts with a given prefix.
 
     Args:
         path: The path to test for prefix.
```

## laboneq/core/types/enums/io_signal_type.py

```diff
@@ -9,7 +9,8 @@
     Q = "Q"
     IQ = "IQ"
     RF = "RF"
     SINGLE = "SINGLE"
     LO = "LO"
     DIO = "DIO"
     ZSYNC = "ZSYNC"
+    PPC = "PPC"
```

## laboneq/dsl/calibration/__init__.py

```diff
@@ -1,10 +1,11 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
+from .amplifier_pump import AmplifierPump
 from .calibratable import Calibratable
 from .calibration import Calibration
 from .calibration_item import CalibrationItem
 from .mixer_calibration import MixerCalibration
 from .oscillator import Oscillator
 from .precompensation import (
     BounceCompensation,
```

## laboneq/dsl/calibration/signal_calibration.py

```diff
@@ -1,14 +1,15 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from dataclasses import dataclass
 from typing import Optional, Union
 
 from laboneq.core.types.enums import PortMode
+from laboneq.dsl.calibration.amplifier_pump import AmplifierPump
 from laboneq.dsl.calibration.mixer_calibration import MixerCalibration
 from laboneq.dsl.calibration.observable import Observable
 from laboneq.dsl.calibration.oscillator import Oscillator
 from laboneq.dsl.calibration.precompensation import Precompensation
 
 
 @dataclass(init=False, order=True)
@@ -45,41 +46,45 @@
     #: The output or input range setting for the logical signal
     range: Union[int, float, None]
     #: The state discrimination threshold
     #: - only relevant for acquisition type signals on UHFQA and SHFQA/SHFQC
     threshold: Optional[float]
     #: (Not Implemented) Amplitude multiplying all waveforms played on a signal line
     amplitude: Optional[float]
+    #: (Not Implemented) Parametric Pump Controller settings
+    amplifier_pump: Optional[AmplifierPump]
 
     def __init__(
         self,
         amplitude=None,
         delay_signal=None,
         local_oscillator=None,
         voltage_offset=None,
         mixer_calibration=None,
         precompensation=None,
         oscillator=None,
         port_delay=None,
         port_mode=None,
         range=None,
         threshold=None,
+        amplifier_pump=None,
     ):
         super().__init__()
         self.amplitude = amplitude
         self.delay_signal = delay_signal
         self.local_oscillator = local_oscillator
         self.voltage_offset = voltage_offset
         self._mixer_calibration = mixer_calibration
         self._precompensation = precompensation
         self.oscillator = oscillator
         self.port_delay = port_delay
         self.port_mode = port_mode
         self.range = range
         self.threshold = threshold
+        self.amplifier_pump = amplifier_pump
         super().__post_init__()
         if self._mixer_calibration is not None:
             self._mixer_calibration.has_changed().connect(
                 self._mixer_calibration_changed_callback
             )
         if self._precompensation is not None:
             self._precompensation.has_changed().connect(
```

## laboneq/dsl/device/_device_setup_generator.py

```diff
@@ -9,15 +9,23 @@
 from typing import Callable, Dict, Iterator, List, Optional, Tuple, Union
 
 import laboneq.core.path as qct_path
 from laboneq.core.exceptions import LabOneQException
 from laboneq.core.types.enums import ReferenceClockSource
 from laboneq.dsl.device import Instrument
 from laboneq.dsl.device.connection import Connection
-from laboneq.dsl.device.instruments import HDAWG, PQSC, SHFQA, SHFSG, UHFQA, NonQC
+from laboneq.dsl.device.instruments import (
+    HDAWG,
+    PQSC,
+    SHFPPC,
+    SHFQA,
+    SHFSG,
+    UHFQA,
+    NonQC,
+)
 from laboneq.dsl.device.io_units import (
     LogicalSignal,
     PhysicalChannel,
     PhysicalChannelType,
 )
 from laboneq.dsl.device.logical_signal_group import LogicalSignalGroup
 from laboneq.dsl.device.physical_channel_group import PhysicalChannelGroup
@@ -29,21 +37,23 @@
 
 # Terminal Symbols
 T_HDAWG_DEVICE = "HDAWG"
 T_UHFQA_DEVICE = "UHFQA"
 T_SHFQA_DEVICE = "SHFQA"
 T_SHFSG_DEVICE = "SHFSG"
 T_SHFQC_DEVICE = "SHFQC"
+T_SHFPPC_DEVICE = "SHFPPC"
 T_PQSC_DEVICE = "PQSC"
 T_ALL_DEVICE_TYPES = [
     T_HDAWG_DEVICE,
     T_UHFQA_DEVICE,
     T_SHFQA_DEVICE,
     T_SHFSG_DEVICE,
     T_SHFQC_DEVICE,
+    T_SHFPPC_DEVICE,
     T_PQSC_DEVICE,
 ]
 T_UID = "uid"
 T_ADDRESS = "address"
 T_INTERFACE = "interface"
 T_IQ_SIGNAL = "iq_signal"
 T_ACQUIRE_SIGNAL = "acquire_signal"
@@ -446,17 +456,15 @@
                     is_qc
                     and len(local_ports) == 1
                     and local_ports[0].upper().startswith("SGCHANNELS/")
                 ):
                     continue  # Skip over SG ports for QA part of QC
                 _SHFQAProcessor._validate_local_ports(local_ports, remote_path)
                 ls_candidate = _path_to_signal(remote_path)
-                is_output = True
-                if signal_type_keyword == T_ACQUIRE_SIGNAL:
-                    is_output = False
+                is_output = signal_type_keyword != T_ACQUIRE_SIGNAL
 
                 if ls_candidate is not None:
                     logical_signals_candidates.append(
                         {
                             "lsg_uid": ls_candidate[0],
                             "signal_id": ls_candidate[1],
                             "dir": IODirection.OUT if is_output else IODirection.IN,
@@ -708,14 +716,95 @@
                 physical_signals,
                 is_qc=True,
             )
             if qa_dev is not None:
                 yield qa_dev
 
 
+class _SHFPPCProcessor(_ProcessorBase):
+    @classmethod
+    def process(
+        cls,
+        instruments: InstrumentsType,
+        connections: ConnectionsType,
+        server_finder: Callable[[str], str],
+        logical_signals_candidates,
+        physical_signals,
+    ) -> Iterator[Instrument]:
+        for uid, address, interface in _iterate_over_descriptors_of_type(
+            instruments, T_SHFPPC_DEVICE
+        ):
+            yield cls.make_device(
+                uid,
+                address,
+                interface,
+                connections,
+                server_finder,
+                logical_signals_candidates,
+                physical_signals,
+            )
+
+    @staticmethod
+    def make_device(
+        uid,
+        address,
+        interface,
+        connections: ConnectionsType,
+        server_finder: Callable[[str], str],
+        logical_signals_candidates,
+        physical_signals,
+    ) -> Instrument:
+        device_connections = []
+        external_clock_signal = None
+        if uid in connections:
+            for port_desc in connections[uid]:
+                signal_type_keyword, remote_path, local_ports = _port_decoder(
+                    port_desc, [T_EXTCLK], to_ls=True
+                )
+
+                if signal_type_keyword == T_EXTCLK:
+                    external_clock_signal = ReferenceClockSource.EXTERNAL
+                    continue
+                _SHFPPCProcessor._validate_local_ports(local_ports, remote_path)
+                device_connections.append(
+                    Connection(
+                        local_port=local_ports[0],
+                        remote_path=remote_path,
+                        remote_port=None,
+                        signal_type=IOSignalType.PPC,
+                    )
+                )
+
+        return SHFPPC(
+            **_skip_nones(
+                server_uid=server_finder(uid),
+                uid=uid,
+                address=address,
+                interface=interface,
+                connections=device_connections,
+                reference_clock_source=external_clock_signal,
+            )
+        )
+
+    @staticmethod
+    def _validate_local_ports(local_ports: List[str], remote_path):
+        if len(local_ports) != 1:
+            raise LabOneQException(
+                f"{T_SHFPPC_DEVICE} signals require exactly one port, but got {local_ports} for {remote_path}"
+            )
+        dummy_device = SHFPPC()
+        available_ports = [port.uid for port in dummy_device.ports]
+        for local_port in local_ports:
+            if local_port not in available_ports:
+                raise LabOneQException(
+                    f"Device {T_SHFPPC_DEVICE} has no port with uid {local_port}. Available port uids are: {available_ports}.",
+                    _logger,
+                )
+
+
 class _PQSCProcessor:
     @classmethod
     def process(
         cls,
         instruments: InstrumentsType,
         out_instrument_list,
         connections: ConnectionsType,
@@ -820,15 +909,17 @@
                             address=descriptor[T_ADDRESS],
                             interface=descriptor.get(T_INTERFACE),
                             dev_type=dev_type,
                         )
                     )
 
 
-def _port_decoder(port_desc, additional_switch_keys=None) -> Tuple[str, str, List[str]]:
+def _port_decoder(
+    port_desc, additional_switch_keys=None, to_ls=False
+) -> Tuple[str, str, List[str]]:
     if additional_switch_keys is None:
         additional_switch_keys = []
     if isinstance(port_desc, dict):
         port_desc = dict(port_desc)  # make a copy
     else:
         port_desc = {port_desc: None}
 
@@ -845,15 +936,16 @@
             local_ports = [port]
     elif isinstance(ports, str):
         local_ports = [ports]
     else:
         local_ports = ports
 
     signal_keys = [T_IQ_SIGNAL, T_ACQUIRE_SIGNAL, T_RF_SIGNAL]
-    trigger_keys = [T_TO]
+    trigger_keys = []
+    (signal_keys if to_ls else trigger_keys).append(T_TO)
     path_keys = signal_keys + trigger_keys
     all_keys = path_keys + additional_switch_keys
 
     signal_type_keyword = None
     remote_path = None
     for key in all_keys:
         if key in port_desc:
@@ -864,20 +956,27 @@
     if signal_type_keyword is None:
         raise LabOneQException(
             "Missing signal type: Expected one of the following keywords: "
             + ", ".join(all_keys)
         )
     if signal_type_keyword in path_keys and not remote_path:
         raise LabOneQException(
-            f"Missing path: specify '{signal_type_keyword}: <group>/<line>'"
+            f"Missing path: specify '{signal_type_keyword}: <group>{qct_path.Separator}<line>'"
         )
-
     if signal_type_keyword in signal_keys:
+        if len(remote_path.split(qct_path.Separator)) != 2:
+            raise LabOneQException(
+                f"Invalid path: specify '{signal_type_keyword}: <group>{qct_path.Separator}<line>'"
+            )
+        if not all(remote_path.split(qct_path.Separator)):
+            raise LabOneQException(
+                f"Invalid path: specify '{signal_type_keyword}: <group>{qct_path.Separator}<line>'"
+            )
         remote_path = qct_path.Separator.join(
-            ["", "logical_signal_groups", remote_path]
+            ["", qct_path.LogicalSignalGroups_Path, remote_path]
         )
 
     if port_desc:
         raise LabOneQException(f"Unknown keyword found: {list(port_desc.keys())[0]}")
 
     return signal_type_keyword, remote_path, local_ports
 
@@ -1024,15 +1123,14 @@
             for info in instrument_info:
                 instrument_uids.append(info["uid"])
         if len(instrument_uids) > len(set(instrument_uids)):
             raise LabOneQException("Device setup instrument UIDs must be unique.")
 
         if connections is None:
             connections = {}
-
         if setup_name is None:
             setup_name = "unknown"
 
         if server_host is not None:
             if dataservers is not None:
                 _logger.warning(
                     "Servers definition in the descriptor will be overridden by the server passed to the constructor."
@@ -1093,14 +1191,15 @@
 
         processors: List[_ProcessorBase] = [
             _HDAWGProcessor,
             _UHFQAProcessor,
             _SHFQAProcessor,
             _SHFSGProcessor,
             _SHFQCProcessor,
+            _SHFPPCProcessor,
             _NonQCProcessor,
         ]
 
         # Define instruments
         out_instruments: List[Instrument] = []
         logical_signals_candidates = []
         physical_signals = {}  # device_uid -> PhysicalChannel
```

## laboneq/dsl/device/device_setup.py

```diff
@@ -1,14 +1,14 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
 from dataclasses import dataclass, field
-from typing import TYPE_CHECKING, Any, Dict, List
+from typing import TYPE_CHECKING, Any, Dict, List, Optional, Union
 
 from laboneq.core import path as qct_path
 from laboneq.core.exceptions import LabOneQException
 from laboneq.dsl.calibration import Calibratable, Calibration, CalibrationItem
 from laboneq.dsl.device.logical_signal_group import LogicalSignalGroup
 from laboneq.dsl.device.physical_channel_group import PhysicalChannelGroup
 from laboneq.dsl.serialization import Serializer
@@ -17,14 +17,15 @@
     ConnectionsType,
     DataServersType,
     InstrumentsType,
     _DeviceSetupGenerator,
 )
 
 if TYPE_CHECKING:
+    from laboneq.dsl.device.logical_signal_group import LogicalSignal
     from laboneq.dsl.device.servers import DataServer
 
     from .instrument import Instrument
 
 
 @dataclass(init=True, repr=True, order=True)
 class DeviceSetup:
@@ -44,16 +45,34 @@
     physical_channel_groups: Dict[str, PhysicalChannelGroup] = field(
         default_factory=dict
     )
 
     #: Logical signal groups of this device setup, by name of the group.
     logical_signal_groups: Dict[str, LogicalSignalGroup] = field(default_factory=dict)
 
-    def instrument_by_uid(self, uid: str) -> Instrument:
-        return next(i for i in self.instruments if i.uid == uid)
+    def instrument_by_uid(self, uid: str) -> Instrument | None:
+        return next((i for i in self.instruments if i.uid == uid), None)
+
+    def logical_signal_by_uid(self, uid: str) -> LogicalSignal:
+        """Get logical signal by uid.
+
+        Args:
+            uid: UID of the signal.
+        Returns:
+            Logical signal with the UID.
+        Raises:
+            KeyError: Logical signal UID was not found.
+
+        .. versionadded:: 2.5.0
+        """
+        for grp in self.logical_signal_groups.values():
+            for sig in grp.logical_signals.values():
+                if uid == sig.uid:
+                    return sig
+        raise KeyError(f"Logical signal UID '{uid}' not found.")
 
     def _set_calibration(
         self,
         calibration_item: CalibrationItem,
         root_collection: Dict[str, Any],
         path_elements: List[str],
         path: str,
@@ -285,14 +304,44 @@
         """
         return DeviceSetup(
             **_DeviceSetupGenerator.from_yaml(
                 filepath, server_host, server_port, setup_name
             )
         )
 
+    @classmethod
+    def from_dict(
+        cls,
+        data: Dict[str, Any],
+        server_host: Optional[str] = None,
+        server_port: Optional[Union[str, int]] = None,
+        setup_name: Optional[str] = None,
+    ) -> "DeviceSetup":
+        """Construct the device setup from a Python dictionary.
+
+        Args:
+            data: Device setup data.
+            server_host: Server host of the setup that should be created.
+            server_port: Port of the server that should be created.
+            setup_name: Name of the setup that should be created.
+
+        .. versionadded:: 2.5.0
+        """
+        return cls(
+            **_DeviceSetupGenerator.from_dicts(
+                instrument_list=data.get("instrument_list"),
+                instruments=data.get("instruments"),
+                connections=data.get("connections"),
+                dataservers=data.get("dataservers"),
+                server_host=server_host,
+                server_port=server_port,
+                setup_name=setup_name,
+            )
+        )
+
     @staticmethod
     def from_dicts(
         *,
         instrument_list: InstrumentsType = None,
         instruments: InstrumentsType = None,
         connections: ConnectionsType = None,
         dataservers: DataServersType = None,
```

## laboneq/dsl/device/instrument.py

```diff
@@ -1,10 +1,12 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
+from __future__ import annotations
+
 import typing
 from dataclasses import dataclass, field
 from typing import List
 
 from laboneq.core.types.enums.io_direction import IODirection
 from laboneq.dsl.device.ports import Port
 
@@ -20,21 +22,21 @@
 
     #: Interface of this instrument. The default is 1GbE (1 Gbit ethernet)
     interface: str = field(default="1GbE")
 
     #: Connections of this instrument.
     connections: typing.List[Connection] = field(default_factory=list)
 
-    def output_by_uid(self, uid):
+    def output_by_uid(self, uid) -> Port | None:
         for o in self.ports:
             if o.uid == uid and o.direction == IODirection.OUT:
                 return o
         return None
 
-    def input_by_uid(self, uid):
+    def input_by_uid(self, uid) -> Port | None:
         for i in self.ports:
             if i.uid == uid and i.direction == IODirection.IN:
                 return i
         return None
 
     def calc_options(self):
         return {}
```

## laboneq/dsl/device/qubits.py

```diff
@@ -1,20 +1,24 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
+import os
+import uuid
 from abc import ABC
 from copy import copy
 from dataclasses import dataclass
-from typing import Any, Dict
+from typing import Any, Dict, Union
+
+from laboneq.dsl.serialization import Serializer
 
 from .io_units import LogicalSignal
 from .logical_signal_group import LogicalSignalGroup
 
 
-@dataclass(init=False, repr=True, order=True)
+@dataclass(init=False, repr=True)
 class QuantumElement(ABC):
     """An abstract base class for quantum elements."""
 
     uid: str
     signals: Dict[str, str]
     parameters: Dict[str, Any]
 
@@ -30,101 +34,105 @@
 
         Args:
             uid: A unique identifier for the quantum element.
             logical_signals: A dictionary of logical signals associated with the quantum element.
             logical_signal_group: A logical signal group associated with the quantum element.
             parameters: A dictionary of parameters associated with the quantum element.
         """
-        self.uid = uid
+        if uid is None:
+            self.uid = uuid.uuid4().hex
+        else:
+            self.uid = uid
         self.signals = {} if signals is None else signals
 
         self._parameters = {} if parameters is None else parameters
 
         if logical_signal_group is not None:
             if signals:
                 raise ValueError("Cannot have both signals and logical signal_group")
             else:
                 self.signals = self._parse_signals(logical_signal_group)
 
+    def __hash__(self):
+        return hash(self.uid)
+
+    @property
+    def parameters(self):
+        return copy(self._parameters)
+
+    @classmethod
+    def load(cls, filename: Union[str, bytes, os.PathLike]) -> "QuantumElement":
+        """
+        Loads a QuantumElement object from a JSON file.
+
+        Args:
+            filename: The name of the JSON file to load the QuantumElement object from.
+        """
+        return cls.from_json(filename)
+
+    @classmethod
+    def from_json(cls, filename: Union[str, bytes, os.PathLike]) -> "QuantumElement":
+        """Loads a QuantumElement object from a JSON file.
+
+        Args:
+            filename: The name of the JSON file to load the QuantumElement object from.
+        """
+        return Serializer.from_json_file(filename, cls)
+
     def _parse_signals(
         self, logical_signal_group: LogicalSignalGroup
     ) -> Dict[str, str]:
         return {k: v.uid for (k, v) in logical_signal_group.logical_signals.items()}
 
     def add_signals(self, signals: Dict[str, LogicalSignal]):
         """
         Adds logical signals to the quantum element.
 
         Args:
             signals: A dictionary of logical signals to add to the quantum element.
         """
         self.signals.update({k: v.uid for (k, v) in signals.items()})
 
-    def get_signal(self, signal_name: str, device_setup) -> LogicalSignal:
-        """
-        Retrieves a logical signal from the quantum element.
-
-        Args:
-            signal_name: The name of the logical signal to retrieve.
-            device_setup: The device setup object containing the logical signal.
-
-        Returns:
-            The logical signal object associated with the specified name.
-        """
-        signal = self.signals.get(signal_name)
-        group, signal = signal.split("/", 1)
-        ls = device_setup.logical_signal_groups.get(group).logical_signals[signal]
-        return ls
-
     def set_signal_group(self, logical_signal_group: LogicalSignalGroup):
         """
         Sets the logical signal group for the quantum element.
 
         Args:
             logical_signal_group: The logical signal group to set for the quantum element.
         """
         self.signals.update(self._parse_signal(logical_signal_group))
 
-    @property
-    def parameters(self):
-        return copy(self._parameters)
-
     def set_parameters(self, parameters: Dict[str, Any]):
         """
         Sets the parameters for the quantum element.
         Allowed datatypes for the parameters are the following: Integer, Boolean, Float, Complex numbers,
         Numpy arrays of the above, Strings, Dictionaries of the above, LabOne Q types and None.
 
         Args:
             parameters: A dictionary of parameters to set for the quantum element.
         """
         self._parameters.update(parameters)
 
-    @staticmethod
-    def load(filename):
+    def save(self, filename: Union[str, bytes, os.PathLike]):
         """
-        Loads a QuantumElement object from a JSON file.
+        Save a QuantumElement object to a JSON file.
 
         Args:
-            filename: The name of the JSON file to load the QuantumElement object from.
+            filename: The name of the JSON file to save the QuantumElement object.
         """
-        from laboneq.dsl.serialization import Serializer
+        self.to_json(filename)
 
-        return Serializer.from_json_file(filename, QuantumElement)
-
-    def save(self, filename):
+    def to_json(self, filename: Union[str, bytes, os.PathLike]):
         """
         Save a QuantumElement object to a JSON file.
 
         Args:
             filename: The name of the JSON file to save the QuantumElement object.
         """
-        from laboneq.dsl.serialization import Serializer
-
         Serializer.to_json_file(self, filename)
 
 
-@dataclass(init=False, repr=True, order=True)
+@dataclass(init=False, repr=True, eq=False)
 class Qubit(QuantumElement):
     """A class for generic qubits."""
 
     ...
```

## laboneq/dsl/device/instruments/__init__.py

```diff
@@ -1,11 +1,12 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from .hdawg import HDAWG
 from .nonqc import NonQC
 from .pqsc import PQSC
+from .shfppc import SHFPPC
 from .shfqa import SHFQA
 from .shfsg import SHFSG
 from .uhfqa import UHFQA
 
-__all__ = ["HDAWG", "PQSC", "SHFQA", "SHFSG", "UHFQA", "NonQC"]
+__all__ = ["HDAWG", "PQSC", "SHFQA", "SHFSG", "UHFQA", "NonQC", "SHFPPC"]
```

## laboneq/dsl/device/io_units/logical_signal.py

```diff
@@ -4,14 +4,15 @@
 from contextlib import contextmanager
 from dataclasses import dataclass
 from typing import Optional, Union
 
 from laboneq.core.exceptions.laboneq_exception import LabOneQException
 from laboneq.core.types.enums import IODirection
 from laboneq.dsl.calibration import MixerCalibration, SignalCalibration
+from laboneq.dsl.calibration.amplifier_pump import AmplifierPump
 from laboneq.dsl.calibration.calibratable import Calibratable
 from laboneq.dsl.device.io_units.physical_channel import (
     PHYSICAL_CHANNEL_CALIBRATION_FIELDS,
     PhysicalChannel,
 )
 
 
@@ -215,14 +216,25 @@
     def threshold(self, value: float):
         if not self.is_calibrated():
             self.calibration = SignalCalibration(threshold=value)
         else:
             self.calibration.threshold = value
 
     @property
+    def amplifier_pump(self) -> AmplifierPump:
+        return self.calibration.amplifier_pump if self.is_calibrated() else None
+
+    @amplifier_pump.setter
+    def amplifier_pump(self, value: AmplifierPump):
+        if not self.is_calibrated():
+            self.calibration = SignalCalibration(amplifier_pump=value)
+        else:
+            self.calibration.amplifier_pump = value
+
+    @property
     def calibration(self) -> SignalCalibration:
         return self._calibration
 
     @calibration.setter
     def calibration(self, new_calib: Optional[SignalCalibration]):
         if new_calib is self._calibration:
             return
```

## laboneq/dsl/device/io_units/physical_channel.py

```diff
@@ -25,25 +25,29 @@
     "mixer_calibration",
     "precompensation",
 )
 
 
 @dataclass(init=False, repr=False, order=True)
 class PhysicalChannel(Calibratable):
-    #: Unique identifier.
+    #: Unique identifier. Typically of the form
+    # ``<device uid>/<channel name>``.
     uid: str
 
-    #: The name of the channel.
+    #: The name of the channel, == <channel name>.
+    # Computed from the HW channel ids like:
+    # [SIGOUTS/0, SIGOUTS/1] -> "sigouts_0_1"
+    # [SIGOUTS/2] -> "sigouts_2"
     name: Optional[str]
 
     #: The type of the channel.
     type: Optional[PhysicalChannelType]
 
     #: Logical path to the channel. Typically of the form
-    # ``/<device name>/<channel name>``.
+    # ``/<device uid>/<channel name>``.
     path: Optional[str]
     _calibration: Optional[SignalCalibration]
 
     def __init__(
         self,
         uid,
         name: str = None,
```

## laboneq/dsl/experiment/experiment.py

```diff
@@ -667,56 +667,14 @@
         def __enter__(self):
             self.exp._push_section(self.acquire_shots)
             return self.acquire_shots
 
         def __exit__(self, exc_type, exc_val, exc_tb):
             self.exp._pop_and_add_section()
 
-    def for_(self, timing, parameters=None, count=0, uid=None):
-        return Experiment._ForSectionContext(
-            self, timing=timing, parameters=parameters, count=count, uid=uid
-        )
-
-    class _ForSectionContext:
-        def __init__(self, experiment, timing, uid, parameters=None, count=0):
-            if parameters is None:
-                parameters = []
-            self.exp = experiment
-
-            if parameters and not count:
-                self.average = None
-                if uid is None:
-                    self.sweep = Sweep(
-                        parameters=parameters, reset_oscillator_phase=False
-                    )
-                else:
-                    self.sweep = Sweep(
-                        uid=uid, parameters=parameters, reset_oscillator_phase=False
-                    )
-                self.sweep.execution_type = timing
-            elif count and not parameters:
-                self.sweep = None
-                args = {"count": count}
-                if uid is not None:
-                    args["uid"] = uid
-                if timing == ExecutionType.NEAR_TIME:
-                    self.average = AcquireLoopNt(**args)
-                else:
-                    self.average = AcquireLoopRt(**args)
-            else:
-                raise LabOneQException(
-                    "Invalid parameters: Either use kwarg 'count' or 'parameters', but not both and not none."
-                )
-
-        def __enter__(self):
-            self.exp._push_section(self.sweep if self.sweep else self.average)
-
-        def __exit__(self, exc_type, exc_val, exc_tb):
-            self.exp._pop_and_add_section()
-
     def section(
         self,
         length=None,
         alignment=None,
         uid=None,
         on_system_grid=None,
         play_after: Optional[Union[str, List[str]]] = None,
```

## laboneq/dsl/experiment/experiment_signal.py

```diff
@@ -1,14 +1,15 @@
 # Copyright 2022 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from dataclasses import dataclass
 from typing import Optional
 
 from laboneq.dsl.calibration import MixerCalibration, SignalCalibration
+from laboneq.dsl.calibration.amplifier_pump import AmplifierPump
 from laboneq.dsl.device.io_units.logical_signal import (
     LogicalSignalRef,
     resolve_logical_signal_ref,
 )
 
 experiment_signal_id = 0
 
@@ -234,12 +235,23 @@
     @threshold.setter
     def threshold(self, value: float):
         if not self.is_calibrated():
             self.calibration = SignalCalibration(threshold=value)
         else:
             self.calibration.threshold = value
 
+    @property
+    def amplifier_pump(self) -> AmplifierPump:
+        return self.calibration.amplifier_pump if self.is_calibrated() else None
+
+    @amplifier_pump.setter
+    def amplifier_pump(self, value: AmplifierPump):
+        if not self.is_calibrated():
+            self.calibration = SignalCalibration(amplifier_pump=value)
+        else:
+            self.calibration.amplifier_pump = value
+
     def is_calibrated(self):
         return self.calibration is not None
 
     def reset_calibration(self, calibration=None):
         self.calibration = calibration
```

## laboneq/dsl/experiment/section.py

```diff
@@ -21,41 +21,33 @@
 from .acquire import Acquire
 from .call import Call
 from .delay import Delay
 from .operation import Operation
 from .play_pulse import PlayPulse
 from .reserve import Reserve
 from .set import Set
+from .utils import id_generator
 
 if TYPE_CHECKING:
     from .. import Parameter
 
-section_id = 0
-
-
-def section_id_generator():
-    global section_id
-    retval = f"s_{section_id}"
-    section_id += 1
-    return retval
-
 
 @dataclass(init=True, repr=True, order=True)
 class Section:
     """Representation of a section. A section is a logical concept that groups multiple operations into a single entity
     that can be though of a container. A section can either contain other sections or a list of operations (but not both
     at the same time). Operations within a section can be aligned in various ways (left, right). Sections can have a offset
     and/or a predefined length, and they can be specified to play after another section.
 
     .. versionchanged:: 2.0.0
         Removed `offset` member variable.
     """
 
     #: Unique identifier of the section.
-    uid: str = field(default_factory=section_id_generator)
+    uid: str = field(default=None)
 
     #: Alignment of operations and subsections within this section.
     alignment: SectionAlignment = field(default=SectionAlignment.LEFT)
 
     execution_type: Optional[ExecutionType] = field(default=None)
 
     #: Minimal length of the section in seconds. The scheduled section might be slightly longer, as its length is rounded to the next multiple of the section timing grid.
@@ -74,15 +66,15 @@
 
     #: Whether to escalate to the system grid even if tighter alignment is possible.
     #: See :meth:`~.Experiment.section`.
     on_system_grid: Optional[bool] = field(default=False)
 
     def __post_init__(self):
         if self.uid is None:
-            self.uid = section_id_generator()
+            self.uid = id_generator("s")
 
     def add(self, section: Section):
         """Add a subsection, a sweep or a loop to the section.
 
         Args:
             section: Section that is added.
         """
@@ -246,14 +238,15 @@
     repetition_mode: RepetitionMode = field(default=RepetitionMode.FASTEST)
     #: The repetition time, when :py:attr:`repetition_mode` is :py:attr:`~.RepetitionMode.CONSTANT`
     repetition_time: float = field(default=None)
     #: When True, reset all oscillators at the start of every step.
     reset_oscillator_phase: bool = field(default=False)
 
     def __post_init__(self):
+        super().__post_init__()
         if self.repetition_mode == RepetitionMode.CONSTANT:
             if self.repetition_time is None:
                 raise LabOneQException(
                     f"AcquireLoopRt with uid {self.uid} has RepetitionMode.CONSTANT but repetition_time is not set"
                 )
 
 
@@ -312,7 +305,12 @@
 
     state: int = 0
 
     def add(self, obj):
         raise LabOneQException(
             f"Trying to add object to section {self.uid}. Only ``play`` and ``delay`` are allowed."
         )
+
+    @classmethod
+    def from_section(cls, section, state):
+        """Down-cast from Section."""
+        return cls(**section.__dict__, state=state)  # type: ignore
```

## laboneq/dsl/serialization/serializer.py

```diff
@@ -8,14 +8,15 @@
 
 from laboneq.core.exceptions import LabOneQException
 from laboneq.core.serialization.simple_serialization import (
     deserialize_from_dict_with_ref,
     module_classes,
     serialize_to_dict_with_ref,
 )
+from laboneq.dsl.calibration.amplifier_pump import AmplifierPump
 from laboneq.dsl.calibration.mixer_calibration import MixerCalibration
 from laboneq.dsl.calibration.oscillator import Oscillator
 from laboneq.dsl.calibration.precompensation import Precompensation
 from laboneq.dsl.device import Instrument, LogicalSignalGroup, Server
 from laboneq.dsl.device.physical_channel_group import (
     PhysicalChannel,
     PhysicalChannelGroup,
@@ -32,14 +33,15 @@
             (
                 Section,
                 Parameter,
                 Pulse,
                 Oscillator,
                 MixerCalibration,
                 Precompensation,
+                AmplifierPump,
                 Instrument,
                 LogicalSignalGroup,
                 PhysicalChannelGroup,
                 PhysicalChannel,
                 Server,
             )
         )
```

## laboneq/openqasm3/openqasm3_importer.py

```diff
@@ -1,126 +1,61 @@
 # Copyright 2023 Zurich Instruments AG
 # SPDX-License-Identifier: Apache-2.0
 
 from __future__ import annotations
 
-import sys
-from dataclasses import dataclass, field
-from typing import Dict, Optional, TextIO, Tuple, Union
+from collections import deque
+from typing import Optional, TextIO, Union
 
 import openpulse
 import openpulse.ast as ast
 
 import openqasm3.visitor
 from laboneq.dsl.experiment import Section
+from laboneq.dsl.experiment.utils import id_generator
+from laboneq.openqasm3.expression import eval_expression
+from laboneq.openqasm3.gate_store import GateStore
+from laboneq.openqasm3.openqasm_error import OpenQasmException
+from laboneq.openqasm3.variable_store import VariableStore
 
 ALLOWED_NODE_TYPES = {
     ast.Program,
     ast.QuantumGate,
+    ast.Box,
     ast.Identifier,
+    ast.IntegerLiteral,
+    ast.FloatLiteral,
+    ast.DurationLiteral,
+    ast.BitstringLiteral,
+    ast.BooleanLiteral,
+    ast.ImaginaryLiteral,
+    ast.BinaryExpression,
+    ast.BinaryOperator,
+    ast.UnaryExpression,
+    ast.UnaryOperator,
     ast.Span,
     ast.QubitDeclaration,
     ast.AliasStatement,
     ast.IndexExpression,
     ast.Include,
-    ast.IntegerLiteral,
     ast.RangeDefinition,
     ast.IndexedIdentifier,
     ast.QuantumReset,
 }
 
 
 class AllowedNodeTypesVisitor(openqasm3.visitor.QASMVisitor):
     def generic_visit(self, node: ast.QASMNode, context=None):
         if type(node) not in ALLOWED_NODE_TYPES:
-            raise TypeError(f"Node type {type(node)} not yet supported")
+            raise OpenQasmException(
+                f"Node type {type(node)} not yet supported", mark=node.span
+            )
         super().generic_visit(node, context)
 
 
-@dataclass
-class ArrayVariable:
-    size: int
-    qubit_start_index: int
-
-
-@dataclass
-class Variable:
-    qubit_index: int
-
-
-@dataclass
-class VariableInArray:
-    array: ArrayVariable
-    array_index: int
-
-
-@dataclass
-class VariableStore:
-    qubit_map: Dict[int, int] = field(default_factory=dict)
-    variables: Dict[str, Union[ArrayVariable, Variable, VariableInArray]] = field(
-        default_factory=dict
-    )
-    current_index = 0
-
-    def add_array_variable(self, name, size):
-        if name in self.variables:
-            raise ValueError(f"Variable '{name}' already exists.")
-        self.variables[name] = ArrayVariable(size, self.current_index)
-        self.current_index += size
-
-    def add_variable(self, name):
-        if name in self.variables:
-            raise ValueError(f"Variable '{name}' already exists.")
-        self.variables[name] = Variable(self.current_index)
-        self.current_index += 1
-
-    def add_alias(self, name, target, index=None):
-        # todo: Alias multiple qubits of an array to a new array
-        if name in self.variables:
-            raise ValueError(f"Variable '{name}' already exists.")
-        try:
-            if index is None:
-                self.variables[name] = self.variables[target]
-            else:
-                target_var = self.variables[target]
-                if not isinstance(target_var, ArrayVariable):
-                    if index == 0:
-                        self.variables[name] = self.variables[target]
-                        return
-                    else:
-                        raise ValueError(f"Variable '{target}' is not an array.")
-                if index >= target_var.size:
-                    raise ValueError(f"Index {index} out of range for array {target}.")
-                self.variables[name] = VariableInArray(target_var, index)
-        except KeyError:
-            raise ValueError(f"Alias target '{target}' not found.")
-
-    def get_qubit_number(self, name, index=None):
-        try:
-            variable = self.variables[name]
-        except KeyError as e:
-            raise KeyError(f"Variable '{name}' not found.") from e
-        if isinstance(variable, Variable):
-            if index is not None and index > 0:
-                raise ValueError(f"Variable '{name}' is not an array.")
-            qubit = variable.qubit_index
-        elif isinstance(variable, VariableInArray):
-            if index is not None:
-                raise ValueError(f"Variable '{name}' is not an array.")
-            qubit = variable.array.qubit_start_index + variable.array_index
-        else:
-            assert isinstance(variable, ArrayVariable)
-            if index is None:
-                raise ValueError(f"Index required for array variable {name}.")
-            if index >= variable.size:
-                raise ValueError(f"Index {index} out of range for array {name}.")
-            qubit = variable.qubit_start_index + index
-        return self.qubit_map.get(qubit, qubit)
-
-
 def get_collection_and_single_index(
     expression: Union[ast.IndexExpression, ast.IndexedIdentifier]
 ):
     # todo: DiscreteSet as index
     if isinstance(expression, ast.IndexExpression):
         name_identifier = expression.collection
         if len(expression.index) != 1:
@@ -149,138 +84,199 @@
     else:
         return collection, None
 
 
 class OpenQasm3Importer:
     def __init__(
         self,
-        gate_store: Dict[Tuple[str, Tuple[int, ...]], Section],
-        *,
-        gate_map: Optional[Dict[str, str]] = None,
-        qubit_map: Optional[Dict[int, int]] = None,
+        gate_store: GateStore,
     ):
         self.gate_store = gate_store
-        self.gate_map = gate_map or {}
-        self.variables = VariableStore(qubit_map or {})
+        self.scoped_variables = deque([VariableStore({})])
 
     def __call__(
         self,
         text: Optional[str] = None,
         file: Optional[TextIO] = None,
         filename: Optional[str] = None,
         stream: Optional[TextIO] = None,
     ) -> Section:
-        if [bool(arg) for arg in [text, file, filename, stream]].count(True) != 1:
+        if [arg is not None for arg in [text, file, filename, stream]].count(True) != 1:
             raise ValueError(
                 "Must specify exactly one of text, file, filename, or stream"
             )
         if filename:
             with open(filename, "r") as f:
                 return self._import_text(f.read())
         elif file:
             return self._import_text(file.read())
         elif stream:
             return self._import_text(stream.read())
         else:
             return self._import_text(text)
 
+    def _merge_scoped_variables(self):
+        result = VariableStore()
+        for vars in self.scoped_variables:
+            result.variables.update(vars.variables)
+            result.current_index += vars.current_index
+        return result
+
     def _import_text(self, text) -> Section:
         tree = openpulse.parse(text)
         assert isinstance(tree, ast.Program)
         AllowedNodeTypesVisitor().visit(tree, None)
+        try:
+            return self.transpile(tree, uid_hint="root")
+        except OpenQasmException as e:
+            e.source = text
+            raise
+
+    def transpile(self, parent: Union[ast.Program, ast.Box], uid_hint="") -> Section:
+        sect = Section(uid=id_generator(uid_hint))
+        self.scoped_variables.append(VariableStore({}))
 
-        root = Section()
         try:
-            for statement in tree.statements:
-                if isinstance(statement, ast.QubitDeclaration):
-                    self._handle_qubit_declaration(statement)
-                elif isinstance(statement, ast.AliasStatement):
-                    self._handle_alias_statement(statement)
-                elif isinstance(statement, ast.Include):
-                    self._handle_include(statement)
-                elif isinstance(statement, ast.QuantumGate):
-                    self._handle_quantum_gate(statement, root)
-                elif isinstance(statement, ast.QuantumReset):
-                    self._handle_quantum_reset(statement, root)
+            body = parent.statements
+        except AttributeError:
+            body = parent.body
+
+        for child in body:
+            try:
+                if isinstance(child, ast.QubitDeclaration):
+                    self._handle_qubit_declaration(child)
+                elif isinstance(child, ast.AliasStatement):
+                    self._handle_alias_statement(child)
+                elif isinstance(child, ast.Include):
+                    self._handle_include(child)
+                elif isinstance(child, ast.QuantumGate):
+                    self._handle_quantum_gate(child, sect)
+                elif isinstance(child, ast.Box):
+                    self._handle_box(child, sect)
+                elif isinstance(child, ast.QuantumReset):
+                    self._handle_quantum_reset(child, sect)
                 else:
-                    raise ValueError(f"Statement type {type(statement)} not supported")
-
-            return root
-        except Exception as e:
-            if sys.version_info >= (3, 11):
-                e.add_note(
-                    "See line(s) {statement.span.start_line}--{statement.span.end_line}."
-                )
-            raise
+                    raise OpenQasmException(
+                        f"Statement type {type(child)} not supported",
+                        mark=child.span,
+                    )
+            except OpenQasmException:
+                raise
+            except Exception as e:
+                mark = child.span
+                raise OpenQasmException("Failed to process statement", mark) from e
+        return sect
 
     def _handle_qubit_declaration(self, statement: ast.QubitDeclaration):
         name = statement.qubit.name
-        if statement.size is not None:
-            if not isinstance(statement.size, ast.IntegerLiteral):
-                raise ValueError("Qubit declaration size must be an integer.")
-            self.variables.add_array_variable(name, statement.size.value)
-        else:
-            self.variables.add_variable(name)
+        try:
+            if statement.size is not None:
+                if not isinstance(statement.size, ast.IntegerLiteral):
+                    raise OpenQasmException(
+                        "Qubit declaration size must be an integer.",
+                        mark=statement.span,
+                    )
+                self.scoped_variables[-1].add_array_variable(name, statement.size.value)
+            else:
+                self.scoped_variables[-1].add_variable(name)
+        except ValueError as e:
+            raise OpenQasmException(str(e), mark=statement.span) from e
 
     def _handle_alias_statement(self, statement: ast.AliasStatement):
         if not isinstance(statement.target, ast.Identifier):
-            raise ValueError("Alias target must be an identifier.")
+            raise OpenQasmException(
+                "Alias target must be an identifier.", mark=statement.span
+            )
         name = statement.target.name
         if isinstance(statement.value, ast.IndexExpression):
             collection, idx = get_collection_and_single_index(statement.value)
             if collection is None:
-                raise ValueError("Array name must be an identifier.")
+                raise OpenQasmException(
+                    "Array name must be an identifier.", statement.span
+                )
             if idx is None:
-                raise ValueError("Alias index must be a single integer.")
-            self.variables.add_alias(name, collection, idx)
+                raise OpenQasmException(
+                    "Alias index must be a single integer.", mark=statement.span
+                )
+            try:
+                self.scoped_variables[-1].add_alias(name, collection, idx)
+            except ValueError as e:
+                raise OpenQasmException(str(e), mark=statement.span) from e
         elif isinstance(statement.value, ast.Identifier):
-            self.variables.add_alias(name, statement.value.name)
+            try:
+                self.scoped_variables[-1].add_alias(name, statement.value.name)
+            except ValueError as e:
+                raise OpenQasmException(str(e), mark=statement.span) from e
         else:
-            raise ValueError("Alias value must be an identifier or index expression.")
+            raise OpenQasmException(
+                "Alias value must be an identifier or index expression.",
+                mark=statement.span,
+            )
 
-    def _handle_quantum_gate(self, statement: ast.QuantumGate, root: Section):
-        # todo: phase
-        if statement.modifiers or statement.arguments or statement.duration:
-            raise ValueError(
-                "Gate modifiers, arguments, and duration not yet supported."
+    def _handle_quantum_gate(self, statement: ast.QuantumGate, parent: Section):
+        args = tuple(eval_expression(arg) for arg in statement.arguments)
+        if statement.modifiers or statement.duration:
+            raise OpenQasmException(
+                "Gate modifiers and duration not yet supported.",
+                mark=statement.span,
             )
         if not isinstance(statement.name, ast.Identifier):
-            raise ValueError("Gate name must be an identifier.")
+            raise OpenQasmException(
+                "Gate name must be an identifier.", mark=statement.span
+            )
         name = statement.name.name
         qubit_indices = tuple(self._get_qubit_index(q) for q in statement.qubits)
         try:
-            root.add(
-                self.gate_store[self.gate_map.get(name, name), tuple(qubit_indices)]
-            )
+            parent.add(self.gate_store.lookup_gate(name, qubit_indices, args=args))
+        except KeyError as e:
+            raise OpenQasmException(
+                f"Gate '{name}' for qubit indices {qubit_indices} not found.",
+                mark=statement.span,
+            ) from e
+
+    def _handle_box(self, statement: ast.Box, parent: Section):
+        if statement.duration:
+            raise ValueError("Box duration not yet supported.")
+        try:
+            parent.add(self.transpile(statement, uid_hint="box"))
         except KeyError:
-            raise ValueError(
-                f"Gate '{name}' for qubit indices {qubit_indices} not found."
-            )
+            raise ValueError(f"Unable to add box for {parent}.")
 
     def _handle_include(self, statement: ast.Include):
         if statement.filename != "stdgates.inc":
-            raise ValueError(
-                f"Only 'stdgates.inc' is supported for include, found '{statement.filename}'."
+            raise OpenQasmException(
+                f"Only 'stdgates.inc' is supported for include, found '{statement.filename}'.",
+                mark=statement.span,
             )
 
-    def _handle_quantum_reset(self, statement: ast.QuantumReset, root: Section):
+    def _handle_quantum_reset(self, statement: ast.QuantumReset, parent: Section):
         # Although ``qubits`` is plural, only a single qubit is allowed.
         qubit_index = self._get_qubit_index(statement.qubits)
         try:
-            root.add(
-                self.gate_store[self.gate_map.get("reset", "reset"), (qubit_index,)]
-            )
-        except KeyError:
-            raise ValueError(f"Reset gate for qubit index {qubit_index} not found.")
+            parent.add(self.gate_store.lookup_gate("reset", (qubit_index,)))
+        except KeyError as e:
+            raise OpenQasmException(
+                f"Reset gate for qubit index {qubit_index} not found.",
+                mark=statement.span,
+            ) from e
 
     def _get_qubit_index(self, q: Union[ast.IndexedIdentifier, ast.Identifier]):
         if isinstance(q, ast.Identifier):
-            return self.variables.get_qubit_number(q.name)
+            try:
+                return self._merge_scoped_variables().get_qubit_number(q.name)
+            except (KeyError, ValueError) as e:
+                raise OpenQasmException(str(e), mark=q.span) from e
         elif isinstance(q, ast.IndexedIdentifier):
             collection, idx = get_collection_and_single_index(q)
             if collection is None:
-                raise ValueError("Qubit name must be an identifier.")
+                raise OpenQasmException(
+                    "Qubit name must be an identifier.", mark=q.span
+                )
             if idx is None:
-                raise ValueError("Qubit index must be a single integer.")
-            return self.variables.get_qubit_number(collection, idx)
+                raise OpenQasmException(
+                    "Qubit index must be a single integer.", mark=q.span
+                )
+            return self._merge_scoped_variables().get_qubit_number(collection, idx)
         else:
-            raise ValueError("Qubit names must be identifiers or index expressions.")
+            raise OpenQasmException(
+                "Qubit names must be identifiers or index expressions.", mark=q.span
+            )
```

## Comparing `laboneq-2.4.0.dist-info/LICENSE` & `laboneq-2.5.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `laboneq-2.4.0.dist-info/METADATA` & `laboneq-2.5.0.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: laboneq
-Version: 2.4.0
+Version: 2.5.0
 Summary: Zurich Instruments LabOne Q software framework for quantum computing control
 Author-email: Zurich Instruments Development Team <info@zhinst.com>
 License: Apache 2.0
 Project-URL: Homepage, https://github.com/zhinst/laboneq
 Keywords: quantum,sdk,zhinst
 Classifier: Environment :: Console
 Classifier: Intended Audience :: Developers
```

## Comparing `laboneq-2.4.0.dist-info/RECORD` & `laboneq-2.5.0.dist-info/RECORD`

 * *Files 3% similar despite different names*

```diff
@@ -1,89 +1,89 @@
-laboneq/VERSION.txt,sha256=B7cWS4CxDuWfVq1kZeO2ws8Se_7Cb8K3FjgCCxnX9cg,5
+laboneq/VERSION.txt,sha256=8OovyZ87edMyuqkbiNTk5GnLa58slmabO07I8Nb1uGM,5
 laboneq/__init__.py,sha256=xb0bbmhv6-zquNTknTRURgHIU1VG11TJVgz5svWkvzI,306
 laboneq/_token.py,sha256=D2wS1TbZ6-CzF73l5kd6Wilcm18IPyymygB6VakHyRc,2829
 laboneq/_version.py,sha256=zaxeCShR641vx5bH27_dVdirv71bA2i9ciFcH4A2krE,238
-laboneq/simple.py,sha256=C_pJmGq56erohy1tXvTNVhPypqlf0xsl4Anz1qLXJrY,1392
+laboneq/simple.py,sha256=vSMPWUdUX4e9b8P8fifLMlXHtKCde280kf4kh3HMPhk,1411
 laboneq/_observability/__init__.py,sha256=rcsPn8d52W6G9ZGkI8TPrEtwSJ2WbQN_Urc2DiIaUDg,184
 laboneq/_observability/tracing/__init__.py,sha256=rEFK2BFplAYa8ZHwQpiaVKv9EaSDrUWKHBplg-AmzGE,538
 laboneq/_observability/tracing/_noop_tracer.py,sha256=z7yhOOaTwCbWTQVQJ3i0SPCYsvd2wdbngf7ygoPJVCE,893
 laboneq/_observability/tracing/_tracer.py,sha256=vqgWJiy17tpzSMIOFXgkXHg9oQotbM8Jd-cWjNyVvk0,2309
 laboneq/compiler/__init__.py,sha256=PQOZ0TyWFSH0U7NJZnaYtO62iQW7DGgEV5KQD0lyKVw,444
 laboneq/compiler/fastlogging.py,sha256=SCJykQ5V_qvRPvWkkDZOqFexmazzhW-fbP2jkglOUkA,204
 laboneq/compiler/qccs-schema_2_5_0.json,sha256=YauxP1Z39AGXi5lUB7eKRLsRxsllayxNlzeyHQBGOSY,22524
 laboneq/compiler/remote.py,sha256=Fyb1RaWU-JBudPSv3LN56yQhYndduOchiai2brTE1WA,666
 laboneq/compiler/code_generator/__init__.py,sha256=s8ihwbuWxGpCAMjnsBXQ0kdoXGqT-B8doSsk850gQA0,654
 laboneq/compiler/code_generator/analyze_events.py,sha256=xA7nDePKXzxQHeR4m95cOmN0CBTR6KY5T3mccT7bBM8,18645
 laboneq/compiler/code_generator/analyze_playback.py,sha256=x4GitPjYDZuSsDWxAeQgFD-2fCltVFiYWTPDnsCdaJw,28581
 laboneq/compiler/code_generator/code_generator.py,sha256=Y16IhjEpk4Xo6d1wTsoLXtz18XVBoCIG6Rmd3bt2isM,64112
 laboneq/compiler/code_generator/command_table_tracker.py,sha256=jXD4Ep8SMIgS_DNqgdfnGujma-oRhRZcvFcIa-AkAXc,4026
-laboneq/compiler/code_generator/compressor.py,sha256=LH8CQY53TbJzcZ5ckroZnFgoAFT3rL81cKXWVHELxVM,2727
+laboneq/compiler/code_generator/compressor.py,sha256=sIbtla_ju0NM1FL1oWGV7SMyxpZoNKwMzHKvbyb3Ut8,2880
 laboneq/compiler/code_generator/feedback_register_allocator.py,sha256=iXuwHFa9g5YQriNqLHXoHIzkBanyR8XnD9C0mw6sPQU,1414
 laboneq/compiler/code_generator/interval_calculator.py,sha256=7dyk02iUdPHyzS4DU6JvkTKn36yWpUE2lhvUynY0aYQ,10355
 laboneq/compiler/code_generator/measurement_calculator.py,sha256=LkgLsVU-majR3ogXvGyuCItb7iNW6Q9QrssJS1gX-Rk,18617
 laboneq/compiler/code_generator/sampled_event_handler.py,sha256=c9JocBLk6H_kdQpeVbpGfdQW87FjkMfPh-odBvh1Wvg,29598
-laboneq/compiler/code_generator/seq_c_generator.py,sha256=ZQfRlFHAK2nKefoy4cJD6d9SZvGGFsXJ5iYLjoDi6Zk,18104
+laboneq/compiler/code_generator/seq_c_generator.py,sha256=-5EXgBoH89KbEIYp5hsZ1wkDSm1HkVZ2QOATaEC81B0,18188
 laboneq/compiler/code_generator/seqc_tracker.py,sha256=a2Jmd7ZZmG3eYleoaqDKEq1H4ntydacdpU59PBTbjVg,6129
 laboneq/compiler/code_generator/signatures.py,sha256=2Ez4Tw_IbmQ2pwkpVMoWKsAuyy6h0mpRIWVUNVMb6-E,7741
 laboneq/compiler/code_generator/utils.py,sha256=KJtRJg6wE8FPALrG4B8H7GRZa_7WqOrXroWW8kgSdBA,3500
 laboneq/compiler/code_generator/wave_index_tracker.py,sha256=700LQq60nX9Btcn9bj2SDn674qRmsxy_Nz6yy0qx1Y0,1476
 laboneq/compiler/common/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
 laboneq/compiler/common/awg_info.py,sha256=djhjq5t8JruHRi9hKk4rtBVH4KfMWRkuamcypmhP6WA,1093
 laboneq/compiler/common/awg_sampled_event.py,sha256=IWSNsuACjHMJIvQpwSOY4-yMfQEyAyB9rY1myA1xcJc,1903
 laboneq/compiler/common/awg_signal_type.py,sha256=aXiZ_K-yaG1pPPUMh5IpOXn2rQJngQnTzwqP1LExtT8,480
 laboneq/compiler/common/compiler_settings.py,sha256=KKBWEH8ZQ10AGaniDKZvpE9sv2eicYNlnYweORJ6EYs,3983
-laboneq/compiler/common/device_type.py,sha256=qKT5nHiHA9RrmX-NzAOXMo6ubQ_BKOdjC0PngAXHET0,4547
+laboneq/compiler/common/device_type.py,sha256=Mp6_bsBycpaT2gCeHjl6NRbcqy8ZKaqz_PK6a88cxEk,4708
 laboneq/compiler/common/event_type.py,sha256=VJiiMUTbZHTetjnBPEPyoSVREczPAjTTxA7d7GbjN9M,1532
 laboneq/compiler/common/play_wave_type.py,sha256=9olrAuZqSSq-3fDpUCwbH2IC2F1mYaZ64H_NG0J6eXM,229
 laboneq/compiler/common/pulse_parameters.py,sha256=zhIljy4MHaBGSFYR-28ksDetM39C5p006e8flU21ZWE,580
-laboneq/compiler/common/signal_obj.py,sha256=IW9XWj_z2rL3yKR9IOpwJsqRs7_yQnjg2zyhzDNxyHs,2052
+laboneq/compiler/common/signal_obj.py,sha256=UBrf78oTS_MyH3YaPZudNqDvFJzoY5_Fw-MJIUcOXVA,2594
 laboneq/compiler/common/trigger_mode.py,sha256=PfV_HskFUlk99bsngdjYz-b137e2qA6e1TNqA0Bjvbs,400
 laboneq/compiler/experiment_access/__init__.py,sha256=mb9ULouZiKIforKo2d458L6pvf0LmV4PXhmKhPBUj7g,154
 laboneq/compiler/experiment_access/acquire_info.py,sha256=bQrMObuyxABUpGTc0ubuUvOs15KzKJzos1dPw4B_PYs,222
 laboneq/compiler/experiment_access/cache.py,sha256=aCJLqqHMPPNk7k-ngo3GaeWQWMYq8THvSv-UL8gUVHs,602
 laboneq/compiler/experiment_access/device_info.py,sha256=HQBj1WpSt8TwHX5G_kE-1m5ulJ06-j_hdIIVamxHQDI,349
-laboneq/compiler/experiment_access/dsl_loader.py,sha256=1rg_cs1axD4PWt-djJIY9AtFdHLRNzkjRMTCSj2Z9vk,42040
-laboneq/compiler/experiment_access/experiment_dao.py,sha256=5MG64Xs14smIr0WgBREpoasfn6S1mpQBIAINJlBj4oc,16297
-laboneq/compiler/experiment_access/json_dumper.py,sha256=hxoXcg22dxPkSKiLwvfUSby3eKiHRglHQkPb7DZxycI,13923
-laboneq/compiler/experiment_access/json_loader.py,sha256=khRSAonzS8_9xZe28ib0BkkzFTwvLAsrpds5XadgmP4,20960
+laboneq/compiler/experiment_access/dsl_loader.py,sha256=0wH-Q6LPuX9wjWPlUb97ISl-8UZNMmj50Jot67jl5hw,44686
+laboneq/compiler/experiment_access/experiment_dao.py,sha256=NW5Kc-2TOPVCFWLffHCCF4iFvA1FSMm51ETYPpnZMyA,16529
+laboneq/compiler/experiment_access/json_dumper.py,sha256=Yds37AhZV8nre6u_a50bVmkYrJCQF6WIqIs2MzB2m48,14106
+laboneq/compiler/experiment_access/json_loader.py,sha256=iyPOMYATaqjSxSCabHqsKGBbtEf5ttclYAH0Ajpfvqc,21004
 laboneq/compiler/experiment_access/loader_base.py,sha256=FEFxOs-_tS8ZMbLRAeaY7jDkFV6EmJvgxoKirI7kFo8,6182
 laboneq/compiler/experiment_access/marker.py,sha256=2Okj9Q_Ukk02B-Z7_WDM6nHN-nuXw3qFjUNaw8LUMsI,270
-laboneq/compiler/experiment_access/oscillator_info.py,sha256=15pG8WPRsSvJYgsX5Z3GiOWnABVCRXY5n6jLEZfewzw,260
+laboneq/compiler/experiment_access/oscillator_info.py,sha256=VvEyOttSTDd7-oxpbim4xmPJUwYEzjrsDXup9xLwI0k,286
 laboneq/compiler/experiment_access/param_ref.py,sha256=wqyyzAiSIEu2GVeNdZc-MtvdhdSDp1Quch8qBVIPppw,197
 laboneq/compiler/experiment_access/pulse_def.py,sha256=HgUWmq0wyU1HWjBz2pADa8WhrQSnTsQN62zbkzbK_vA,1263
 laboneq/compiler/experiment_access/section_graph.py,sha256=0bIQle4g1adY8Ke7DjBG143Y4eWbTakO6YXdHzS3Tw8,21550
 laboneq/compiler/experiment_access/section_info.py,sha256=vRIw7KvrlNhXjh8ynUjGUer_DVJPxdo9FGBdDMWVuUY,851
 laboneq/compiler/experiment_access/section_signal_pulse.py,sha256=ZGgbvNW3v-qIgyvcW34Lk31hyhFeNb_UjE6uIUXd8os,1069
 laboneq/compiler/experiment_access/signal_info.py,sha256=HLkN-Kq2vZrh5tg92RA3ZSSYaiRXXQecw01-NtXGR_Q,387
 laboneq/compiler/new_scheduler/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
 laboneq/compiler/new_scheduler/case_schedule.py,sha256=hx2y33Cwjm484ZW3fYzheuQEjgg1dvJHMxfRzWIITR8,3269
 laboneq/compiler/new_scheduler/interval_schedule.py,sha256=x9ZbMhVZxoDjLHs5SbbgTpvf7YhDsIFJCr75ATr-_Io,7443
 laboneq/compiler/new_scheduler/loop_iteration_schedule.py,sha256=oWQaNGxixdxnkSDbdxfNMboMxTwD0GWf3V80kaeKcpg,3331
 laboneq/compiler/new_scheduler/loop_schedule.py,sha256=kUzQ3v-2Ca-w5f0nqxM1yIUjeYWKL5o6HPe7LNe9qyA,8588
-laboneq/compiler/new_scheduler/match_schedule.py,sha256=_cl7dYmEKLf7Y7KU306aUSXeUHQrE1yyeTY4pT2l3IM,7197
+laboneq/compiler/new_scheduler/match_schedule.py,sha256=D0Qs7K8HwOKhnrlXPSmmXO5g_SQ5LnzdTDSuAkRy_mw,8075
 laboneq/compiler/new_scheduler/oscillator_schedule.py,sha256=80LLDWtu12iseHHvKoysfzDRCYnK8EkJjK2sgZFdcqA,2252
 laboneq/compiler/new_scheduler/phase_reset_schedule.py,sha256=lVXrMB-CFdC4_QLeFiqsp2C0iX2BIpRavuJj1tp-lsI,1765
 laboneq/compiler/new_scheduler/preorder_map.py,sha256=0e1zQEuUs6sc9PWRzl0cTHhvKAwx549njQtGQ8BFhLM,1820
 laboneq/compiler/new_scheduler/pulse_phase.py,sha256=poXl-PKFIO7X_xN3Qjqo-NWC-svaom3dWjetfKEsw8c,3821
 laboneq/compiler/new_scheduler/pulse_schedule.py,sha256=kw_8NWNRTNcSqGCdHxyhjwwTfAMlhsJ3KrtKcyzPRRY,6962
 laboneq/compiler/new_scheduler/reserve_schedule.py,sha256=ML-aqZlwj8_TpUV8lVdZuvdEtr3JahjYGIu6EvUXM38,625
 laboneq/compiler/new_scheduler/root_schedule.py,sha256=ni57ni5v4d5sBTYolt364x0mM_BIKA_dcifP2w8lnp8,1375
 laboneq/compiler/new_scheduler/schedule_data.py,sha256=qt6GHxcfsYPiCgM9doBV48XFTkcje-w1D7B8A2KyNXU,1016
-laboneq/compiler/new_scheduler/scheduler.py,sha256=ZDAvf3cAq_kOz3R-1IvNr3x-R3eZ_NKmk7vElvdAxX4,39737
+laboneq/compiler/new_scheduler/scheduler.py,sha256=ni0eNCApwJLGG9RuzBxgWGwmJEoFuHgRpwyT5BI7VYM,40991
 laboneq/compiler/new_scheduler/section_schedule.py,sha256=6x2PPJykhWnIBaclojjpkp54eY8XPN3rpXTxB1KkblE,13207
 laboneq/compiler/new_scheduler/utils.py,sha256=buFGd2oxNFr3hfGc8fx_dyMCbxTwimiSOuxCqeqSDRk,757
 laboneq/compiler/scheduler/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
 laboneq/compiler/scheduler/event_graph.py,sha256=N3jMW3wW_aX4123B3WxKMIcDr-CmZvZqshc-mTE0Vh0,12943
 laboneq/compiler/scheduler/event_graph_builder.py,sha256=aoT1FIXGZ601gGL-d4awtztWmEtdglOcZyXYEJC4EcE,24682
 laboneq/compiler/scheduler/sampling_rate_tracker.py,sha256=taR4AdTTaYNXfaEgM5hZNhL2VbcGnJCkx9gt4xAJg9E,1949
 laboneq/compiler/scheduler/scheduler.py,sha256=W0rMofmnGEeG9pbFQMcfPDd5BUZCQ4O3zBqzT_boZRI,115572
 laboneq/compiler/workflow/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
-laboneq/compiler/workflow/compiler.py,sha256=75atImHpWlSUC3Jc9LjivpSFl-ypFjzi9vfdx4ES4Nw,48911
+laboneq/compiler/workflow/compiler.py,sha256=grSiCLvvP6t_zzDhK7C8njwWfjHlw50a_CNy3X7YBm8,49793
 laboneq/compiler/workflow/precompensation_helpers.py,sha256=dpRw6dGJcsDAv0uI48cfzso75IYHNVfP1NUkRhD-giI,12424
-laboneq/compiler/workflow/recipe_generator.py,sha256=a0cNO2fAOVhrJCm8M28qqmFe7MuAC0jTbPTSe5atSEo,11747
+laboneq/compiler/workflow/recipe_generator.py,sha256=MEUGD0x8aGQaUZYDTcGeaIbfOykbvaz1bBa7xiV8GTI,12229
 laboneq/contrib/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
 laboneq/contrib/bloch_simulator_pulse_plotter/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
 laboneq/contrib/bloch_simulator_pulse_plotter/inspector/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
 laboneq/contrib/bloch_simulator_pulse_plotter/inspector/update_inspect.py,sha256=dII-ZVAa3HumwKfHYGiARVBDCjaqJhGFy55XAjOPiaM,4511
 laboneq/contrib/bloch_simulator_pulse_plotter/plotter/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
 laboneq/contrib/bloch_simulator_pulse_plotter/plotter/plot_funs.py,sha256=3RjtFb3sxYokBP92COK53gCmBrCk9ubs8_xOb75fem4,3379
 laboneq/contrib/bloch_simulator_pulse_plotter/pulse_simulator/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
@@ -103,40 +103,41 @@
 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_hdawg_pqsc.py,sha256=mDvjBkffwNTOI0ZZggySTmVdjFejzZx3nGdwQctLTZY,1930
 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_pqsc.py,sha256=N6W7sxG0HnjqS4xbfxqeUK60b4eYdrnN-57qk7Xkkiw,1618
 laboneq/contrib/example_helpers/descriptors/shfsg_shfqa_shfqc_hdawg_pqsc.py,sha256=kZcUW_hQ_yUziYa7aPNi0iRZ5wWwTcYxqD8DDQYQnNg,2383
 laboneq/contrib/example_helpers/plotting/__init__.py,sha256=7Yt1BeCJ-am29jPA5s55Otv83hbYF3ZZum1MZabcNMk,77
 laboneq/contrib/example_helpers/plotting/plot_helpers.py,sha256=YH0AJlCXvV7ixAu9y61tXIiDWLcnZG2loQSAcigpePs,6620
 laboneq/controller/__init__.py,sha256=gPuU9BwcRA-VFMRLtIzd9Y-KvLQhYv0czaGuo-uimjc,308
 laboneq/controller/cache.py,sha256=sI4qtTQurYPWzMp7iW1oKwQp_GVftQX9isDkTNZ-bDE,1479
-laboneq/controller/communication.py,sha256=nZux8F5Y18777VqLMk3_nwhJB3H1iDIvinoDuo4ZOAA,14819
-laboneq/controller/controller.py,sha256=ahN7Lb-9gUSv-W5ALUGNGXjwhLmtpuvpngsklZdIYTk,33283
+laboneq/controller/communication.py,sha256=CxB46hJHKIVMtA55mSjGCOyjScFOpl5EFBwZYee5K1M,13536
+laboneq/controller/controller.py,sha256=rUZz3QllUDpKGbPBfivDJnlTyRkvKdeih6G5OucSRXw,32890
 laboneq/controller/laboneq_logging.py,sha256=esE9zHGFnANO-cBb2Im6s1UtyL2loZU-VMdpBUchPvk,4504
 laboneq/controller/protected_session.py,sha256=v4T5NsQxE57E22hJltIumOnLAoBms0D7ZTtUYjGHGGM,337
-laboneq/controller/recipe_1_4_0.py,sha256=xzds1pM2-nZxO756G8zbGd2itWhdvyh2N2tXh2ZHYK0,14870
+laboneq/controller/recipe_1_4_0.py,sha256=lD4WDlE9_iZJeHpI21Dy6u88LdF-AHCc61yaSrochnw,15011
 laboneq/controller/recipe_enums.py,sha256=uNjZPJci2KCleSh2zNYTOkUEfBpBK0spOU16GvaWj6Y,638
-laboneq/controller/recipe_processor.py,sha256=sXyHnvZJEABG5enAHGm-2VYq6lfQ2lsYLE5_jKUnsng,19575
+laboneq/controller/recipe_processor.py,sha256=L2MBGJoaYFLLFqI53vuETuuzP6FHOfHMb6nJI7CatTA,19876
 laboneq/controller/results.py,sha256=b9Oy_F0GqSzHulNSWqt6ltUzXpYZ4JmC0BVIE176Qzc,1917
 laboneq/controller/toolkit_adapter.py,sha256=moZzwjnRUUbyT-7JL31EBtBh39VD3USx1SRolFS8v-g,1594
 laboneq/controller/util.py,sha256=UuAnPes0F2VXm_3nw0NCAVRNRhsOSUorkTN0gjHMcsw,624
 laboneq/controller/versioning.py,sha256=IcmXytxA6OtbudyM2aK8gCgWLcuLbweru5wIafolpnU,281
 laboneq/controller/devices/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
-laboneq/controller/devices/device_collection.py,sha256=BJ4SEWVi2DYZD2XcUzmVK6NofRZqwh7dxWwBAORxzcU,15231
-laboneq/controller/devices/device_factory.py,sha256=10RUKOTxniQDFM9NOjgLkLk33b7hdsNiOZhXyfXTxoQ,1173
-laboneq/controller/devices/device_hdawg.py,sha256=eWePSboxqiHm71uuE9FS55_CuWbEKlxcrnAJI8SYbvM,23560
-laboneq/controller/devices/device_nonqc.py,sha256=N2EHsj1Gsf6n1nBZVBdAKU1k-bltgfMb1kqcmtTAVf0,1234
-laboneq/controller/devices/device_pqsc.py,sha256=_Al4lmalT89zbcbevTIaKHOP_I2WWN95SnxkfEcrPOg,8260
-laboneq/controller/devices/device_setup_dao.py,sha256=oP7CPZdylqRRfJEGonw8J0DTLO1Dpjz0zBt2GMRaSLo,2830
-laboneq/controller/devices/device_shfqa.py,sha256=DgT_kcG-EVHu0B5XSYWY_FwcqSZKDfQwxAHwKq6ftL8,40121
-laboneq/controller/devices/device_shfsg.py,sha256=bHqk2Z7yQhLorhjWbxVDu5i-6fNlJgYl5o5mPIM_cQc,20516
-laboneq/controller/devices/device_uhfqa.py,sha256=8L64mqOBZQm8O3cG9PEoDRuDoNrNiRWqE97zOYYvw2U,28707
-laboneq/controller/devices/device_zi.py,sha256=gmyR5LlYSRBQjWg3bxhWauH1_skwZ_0z-CBt7NzHwOQ,42463
-laboneq/controller/devices/zi_emulator.py,sha256=Uqs0jrOfGPuZ6vEZhZvaUM7Dqr8ThND9kqz15XtadGU,30874
-laboneq/controller/devices/zi_node_monitor.py,sha256=1b2fraKJar4w6rp3LeRohgWXayLY0lj35rPFQJO795Q,9837
+laboneq/controller/devices/device_collection.py,sha256=OFIBllNQnuWNz31EelrkkOvGL6v4l47ZZsXM6V0uR1U,15400
+laboneq/controller/devices/device_factory.py,sha256=CQmdrldqyhI7wCFw2aObszp9g3XhPaJZv9Y8U_VAdMY,1275
+laboneq/controller/devices/device_hdawg.py,sha256=YgFUX9SjFp7Eer4_6sD4aCdeF6PZffRV8i5UyumTJPA,23542
+laboneq/controller/devices/device_nonqc.py,sha256=m1rpD0XgwgNChmIkzdOBFiyg4bbPWY-1b0ysrMLqLNs,491
+laboneq/controller/devices/device_pqsc.py,sha256=FkH6ZaKqQDoX_WmROL1czc_dTU5DP0nU6IkqShA30fo,8115
+laboneq/controller/devices/device_setup_dao.py,sha256=daW-WJHaqCuxxNF3Wtnzr0_ebL2X9cYo-WHTv_U0Bas,4137
+laboneq/controller/devices/device_shfppc.py,sha256=ARsbwvxvTDFcvTdRZi463l-fvNDWVlsFZbM7qiU4Dzo,3758
+laboneq/controller/devices/device_shfqa.py,sha256=fq7WrGNIaYvStoojzqr0-YuSWpYEd1qT-hYihXpvN1c,40101
+laboneq/controller/devices/device_shfsg.py,sha256=KTOAkTEslNQ4GanZI9Frh-bFcSwkQPckus-zejKk230,20509
+laboneq/controller/devices/device_uhfqa.py,sha256=SxKhhfaTQ2QUKYB2uJAGQ-3HRRO-XY83nxa4Rb85pVk,28521
+laboneq/controller/devices/device_zi.py,sha256=RNYRX1ljsLtyHYj4A04BlLK5eJ5djJM_7KffvtxA2ig,36707
+laboneq/controller/devices/zi_emulator.py,sha256=Y2uZuFe020_fmG8fG_dyFk6HlUpK36fxwG6hrBMr4Lk,29590
+laboneq/controller/devices/zi_node_monitor.py,sha256=2N2Q79sP-USY9-ovk5DHOXiO6Sov9QSzBGqdsyAPnuA,10358
 laboneq/core/__init__.py,sha256=nx0-aqsC4hdoO7jIj0Ut7yNTQbe5dme7jodU9wkd4N4,97
-laboneq/core/path.py,sha256=QEND23yk_IXftMdZaDszUVCdezZACDYwyxPOD9AoVVo,1998
+laboneq/core/path.py,sha256=ZDMafOg44r5I3T-sW-iY6j7xrjYMbx12UsLoqbhg3Vw,2015
 laboneq/core/validators.py,sha256=pmtl8RdlBr-49CkxJseW1VrDtJU2gqLVBWSZdLrRpWc,1338
 laboneq/core/exceptions/__init__.py,sha256=8ZaME3lWkRJ7BZw1qVWGbt91jaklPd67iyIZ-zXoBpE,126
 laboneq/core/exceptions/laboneq_exception.py,sha256=bWRVbnLJiBszdNeEglRFp-z1Q3bb-irTIzf2vgTaBK0,123
 laboneq/core/serialization/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
 laboneq/core/serialization/simple_serialization.py,sha256=03qj5sZYadGGsqmd7qyCGmDizeRr8d91edo2Er6FT1Y,19090
 laboneq/core/types/__init__.py,sha256=fvF9SQu_JVfxc3et0G1RWE-FZvliRnYc_m6Ym6oavto,161
 laboneq/core/types/compiled_experiment.py,sha256=zeLm821a4hn5hbDzEAT-NnhPbQP-aP6OVP4vQoybz3E,5138
@@ -145,95 +146,103 @@
 laboneq/core/types/enums/acquisition_type.py,sha256=PpK4El9Gvmt7ojw6tCcTSkfrDkJxmpvZyE2wbkPooLg,934
 laboneq/core/types/enums/averaging_mode.py,sha256=skosaedPnNxrW_UGRpksM1uiT7tCRLNx-9I3SuvdlMY,213
 laboneq/core/types/enums/carrier_type.py,sha256=PEbKKDkeBlQuUJCF-TFytQHjZf_enLJUDOvImdwVBH8,188
 laboneq/core/types/enums/dsl_version.py,sha256=Ba_d-Bw4wPQOb7Nv6Uy1S5XFCvDBXkNWzOoiPokiVxs,227
 laboneq/core/types/enums/execution_type.py,sha256=5AndgsShuhqkXr64g3IOuXal_TvhCrVMl7PkblOrZ1U,185
 laboneq/core/types/enums/high_pass_compensation_clearing.py,sha256=1M6A-f1hF6O5AJuLiRiBxgMyerYajqq7y3CmBKzkaKk,223
 laboneq/core/types/enums/io_direction.py,sha256=RwJfnTnkhC6GyuoQ-SbdpySgeSkDreMpWkWlNGWwwY0,157
-laboneq/core/types/enums/io_signal_type.py,sha256=f6pgWPxUNiGUAl0wcnVolrbOjMgYFb3Ng9wcvgkKmBs,252
+laboneq/core/types/enums/io_signal_type.py,sha256=eZbqdP51PHnH77vn6MUup7igCrS3pnx-15x8MO50MAo,268
 laboneq/core/types/enums/mixer_type.py,sha256=iXF4i8-ovwBfJkppv4iB98ZmeV6bvpsZTRPr-emjwPM,316
 laboneq/core/types/enums/modulation_type.py,sha256=S7wsc5w0UiiGkgrI9uIbY2ICpn8G1syuE19h57OJtvk,200
 laboneq/core/types/enums/port_mode.py,sha256=1CdF7cSNb15P8ZgY54iPIOdwZuuDHwlC1HaJfSxchFk,152
 laboneq/core/types/enums/reference_clock_source.py,sha256=hN1gZKxh_ElHZOq3zl0nHyJaaKoCgixTc0fKcCKUy7E,188
 laboneq/core/types/enums/repetition_mode.py,sha256=hRnj_stjpVRDGTCHoN7q5kPffAm6OoTX9BWcoerl3A8,198
 laboneq/core/types/enums/section_alignment.py,sha256=nYuTh1r0PL35aQoLUgeOGTnZoAb6XhGPgVY4a70UMgc,170
 laboneq/core/utilities/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
 laboneq/core/utilities/pulse_sampler.py,sha256=eKdg1IcTwjoVmp7mKSSAu6eV80mYPgHaMUUr9AIWkZ4,8039
 laboneq/core/utilities/replace_pulse.py,sha256=LEWhHoF3s8klVXSaVO26gkthLuyJE_A5NRcZW8WGTx4,9808
 laboneq/dsl/__init__.py,sha256=gsR9dv88edpbJLrwc_X2jj147IfVWpnTT10td01fPkY,178
 laboneq/dsl/laboneq_facade.py,sha256=xfeHLO9ywCpClZ1Jl_I_Z_IC5wDpr2tckFsJhPuy8PY,2929
 laboneq/dsl/parameter.py,sha256=AbR78048B3-jyYvq_A5rmBqaeg4v0C601f9EGFJzRN0,2552
 laboneq/dsl/session.py,sha256=P-mOhpv3-u5stl3oeRSjTn97b4Nm4M42gxw24HYzsT4,25670
 laboneq/dsl/utils.py,sha256=v0qlt2XA2CXiGK3Rpi_PC45YZGeQriRz-ShovaTXMBE,2296
-laboneq/dsl/calibration/__init__.py,sha256=LX2pS3IGkA0uTtVK-3SncxddLT4hLHssivSlAPFqz7M,487
+laboneq/dsl/calibration/__init__.py,sha256=3becZcLdza9jTczHmfBgbbaH238UfP9uPakbhe5kwto,529
+laboneq/dsl/calibration/amplifier_pump.py,sha256=A4QI8YE-lRGaUv_yE6q7Osn3JfFSEuO-PzHyeowtaD0,1017
 laboneq/dsl/calibration/calibratable.py,sha256=DEx55rhplLTxoaf8-bGnmZqyO4eZdIyMptiLAGKEp7M,545
 laboneq/dsl/calibration/calibration.py,sha256=2js2bMMwX6pYrRFlWv3NRyeJOE5pwxDRqg3qVff6X5c,1886
 laboneq/dsl/calibration/calibration_item.py,sha256=JlPu54zS2NfivokgD4ICOhrw5e3Rhs5DO7pB0iDazpY,111
 laboneq/dsl/calibration/mixer_calibration.py,sha256=_ivXcsDgELxaC8zZ7E5caMhE-HZYSuuDyR5odaVImKw,992
 laboneq/dsl/calibration/observable.py,sha256=5zf7HE7e4MnrnHcgwAWMKkejOiVTZs4UCtlRiVn8OVw,3403
 laboneq/dsl/calibration/oscillator.py,sha256=H2_32nckXQLraVZzq15Y-NLMB9U3BJp3lQW1QI3QxLs,1716
 laboneq/dsl/calibration/precompensation.py,sha256=N-GduIP4AVdKfxDH2rQ3zbYEarKx1rYrxO2Egb70Q9A,2650
-laboneq/dsl/calibration/signal_calibration.py,sha256=cZwGkQ_SkjsI6K7V3oY9VwdNBmpXxuNwDo3S-n5TCAM,5363
+laboneq/dsl/calibration/signal_calibration.py,sha256=_SpbINwf-0i8vr_-r0smIL5v0cmN1cyLNZAw5n3E0GA,5607
 laboneq/dsl/calibration/units.py,sha256=9W7YXV75G2VgNGSNserL_rsnEdjQugCuzg1gQmkvutU,553
 laboneq/dsl/device/__init__.py,sha256=uqx0Rho0xQ0vHzcP4no8R0OfjkK2ZdPllpVsZoAuH6Y,363
-laboneq/dsl/device/_device_setup_generator.py,sha256=GGyGsmpKJXuJGFLyeH3i1uEKZaiiYH-kVV3XZh9KP3U,42448
+laboneq/dsl/device/_device_setup_generator.py,sha256=sA2j1IKi3pId3yg5Ct4sp_tvkd4aZ7o8FX7fDdpKIgg,45826
 laboneq/dsl/device/connection.py,sha256=e_uMDO-7YrMKJkZEbizlTQZITsXU1--ceOYOZ0m40Xc,601
-laboneq/dsl/device/device_setup.py,sha256=mjBjKj7cK9ZCDgHhaoq6alsy_l_sSwao0wXokxx5euA,11946
+laboneq/dsl/device/device_setup.py,sha256=hDYGDooO-rFxHsC7i1HD5kyzPvXzNSjrXBWkCTg0dMk,13663
 laboneq/dsl/device/device_setup_helper.py,sha256=KRaya8xtzjqzdn1SZ_NMCU7p_V-76Aj_S0evSzuey7c,2551
-laboneq/dsl/device/instrument.py,sha256=XDt_ixh4XcmWRW2cOKMC67yGszm-LaLqnUbpY7bAKk8,1296
+laboneq/dsl/device/instrument.py,sha256=XjaPAcpKdPQx1z-QpAFwHLFERoK65-Rgb7SjIyW_zy8,1362
 laboneq/dsl/device/logical_signal_group.py,sha256=i12USV4K1ij8y_3SOYStnZE_z3Bo6G0-f03RtuBjO-w,1893
 laboneq/dsl/device/physical_channel_group.py,sha256=1u4c9TyfC5WZWkgQGTpDcbIc6hXcgKuNdE8AJcxbaRk,1729
 laboneq/dsl/device/ports.py,sha256=-jVPCUfRq1e2PHpPBrcHuUQcrrfv7kylzDUF9rZWTnQ,538
-laboneq/dsl/device/qubits.py,sha256=__NDOuQ6y2VTnlL5cKL20VJ2gF8JOuUXjH-zfcRPpm4,4312
+laboneq/dsl/device/qubits.py,sha256=OZ7LO7MaX_9-Qm2um-jC1EQwmBh3mqBQM4vxhCiBGlc,4453
 laboneq/dsl/device/server.py,sha256=JOM2xKKWMwFWYPcAjoCoFIuF_4ZC73_fMiZXUhNSZPk,215
-laboneq/dsl/device/instruments/__init__.py,sha256=OUWD15vkNAclXPCAWL-VCx5beiwzT7un6v_UK_qmtpA,291
+laboneq/dsl/device/instruments/__init__.py,sha256=sl302P7-HQO6Y8NXCcN2-r5mfbGastN7Ugs6PfRA1wg,328
 laboneq/dsl/device/instruments/hdawg.py,sha256=xLmo7LJhGC61PDkv_ZYn37VD0bnRxC1Ag54ET_KRLE4,1778
 laboneq/dsl/device/instruments/nonqc.py,sha256=j6jLNrFifaKe1QDcQJcTVWMdQR7eBI345V7S-iWqhts,466
 laboneq/dsl/device/instruments/pqsc.py,sha256=JQrg31Gj6HRjUOYjDyG5m2A9ngrQOFcX0mHw_2BwsGk,948
+laboneq/dsl/device/instruments/shfppc.py,sha256=E_-2fesNBJ0E-qrrwSA5MK1TdL0Daht9OX2U0BeBtkg,927
 laboneq/dsl/device/instruments/shfqa.py,sha256=C6yaZvxr1xZwUegOILTNC8_B7a28O_GqsIYag-dCvYo,2248
 laboneq/dsl/device/instruments/shfsg.py,sha256=MCJkySVlx7ls33IPHrf2ZmKBRuBXQDPGwVw7o_JXfmk,1659
 laboneq/dsl/device/instruments/uhfqa.py,sha256=sHidPdFcZHTOXXSFJFcCD__K90IkEogpZPiai5dt8Us,2312
 laboneq/dsl/device/instruments/zi_standard_instrument.py,sha256=IcDKOIMU_Yi9niyZlq9aw1xKXVLGd2VO0mO9qRW8lDI,888
 laboneq/dsl/device/io_units/__init__.py,sha256=UOI3L_V5_3lji95HUdB3KvWoAQkja0pR8bGBshRnRr4,187
-laboneq/dsl/device/io_units/logical_signal.py,sha256=Pju-ynSMfqI-HuOvOvZFT1TrFZD8v-thiJVDD2ZS5vQ,12288
-laboneq/dsl/device/io_units/physical_channel.py,sha256=1C7QrHbUBIUXD0gzR6Z5RpazDAA_WJJb6qSqY44_xeY,3608
+laboneq/dsl/device/io_units/logical_signal.py,sha256=Q1TH8nwOfUJFI6XnnnHtUMXEDNrTsv_BEyJZvfwH8wQ,12750
+laboneq/dsl/device/io_units/physical_channel.py,sha256=ruwynMdZx1fDgXeE_WOSHdeQrJWdmyNrRDmvcn7UgJ0,3811
 laboneq/dsl/device/servers/__init__.py,sha256=ZeYikalTjZXb_HDjfdGe6YHUuZAlDv0qqHZ0d1JLOE8,114
 laboneq/dsl/device/servers/data_server.py,sha256=URgMXwwmzNAPF3PrQBTE11dU7QLxGaJa0tIdi8F2BiQ,704
 laboneq/dsl/enums/__init__.py,sha256=GeDXWBzskaPr4MxVoeJp6kj-X5kVZA1yrbUw7wcV2F0,718
 laboneq/dsl/experiment/__init__.py,sha256=N159QRiB6rNL_RH6vzZwYqi4B91GTlX-JmmysAoQgMM,508
 laboneq/dsl/experiment/acquire.py,sha256=g4Pvm6T0qu8tH8LRTHhCZ1wb2K4Drc1rawNeNTRkS_E,972
 laboneq/dsl/experiment/call.py,sha256=eATarAz81C0QC5Ih-Uuh9PrS0g4rEF_vbQsrav_-I6Q,814
 laboneq/dsl/experiment/delay.py,sha256=98P3AePai3fqH1csDnWSxUN3EGJchuysX_2qnkCF2-Y,780
-laboneq/dsl/experiment/experiment.py,sha256=-UF5dmsIlhhGmA98LXQB7CR1qUCaf_RKh5ixHUyeK8g,41433
-laboneq/dsl/experiment/experiment_signal.py,sha256=YUofWe1v4XUuwzaKU9RyLDLbV0tKqmS3PD5gM2P_-OA,7754
+laboneq/dsl/experiment/experiment.py,sha256=pr5g9l1DEHEWSrqVCwqiIoENt-hbwQXcChywV9e4ppg,39779
+laboneq/dsl/experiment/experiment_signal.py,sha256=eHDHAu7Hv9xTSF-f9-YsJ1suZmZfaevS9anyLaBiOPY,8216
 laboneq/dsl/experiment/operation.py,sha256=kJPLIjNTFf_lJkVsOmASPi7GZVJ9CCZySdA2YDCmswU,401
 laboneq/dsl/experiment/play_pulse.py,sha256=yGd_-jzkuOK_i4A65mfoPfeG1IRKK8ZaDQE-E627Idw,1647
 laboneq/dsl/experiment/pulse.py,sha256=WH8cUpm40dv-xUTi-B4s542QU3c3BF4Dpwm-QtYTwOw,3568
 laboneq/dsl/experiment/pulse_library.py,sha256=cvLbQXr4lUPeXDY-09iNuWyqhdAvtTAROTcJbiPZD8I,7932
 laboneq/dsl/experiment/reserve.py,sha256=tn1YEkW6E7BbBuG4SKveCmiAXrsYm2IeMUI2iDnwazs,890
-laboneq/dsl/experiment/section.py,sha256=zC0Dgxsr3wbrnyfpDsRmYTNuE5AXogvZAkZrayK7KMI,11366
+laboneq/dsl/experiment/section.py,sha256=0gg3PscVUPEoTEhYaE4bsX8qsTvxgXQ4RyKb_gop5q8,11431
 laboneq/dsl/experiment/set.py,sha256=4hEgxT9iYWNgDEEAFDS4D1GlgTsInRK3regArR4cnaU,640
+laboneq/dsl/experiment/utils.py,sha256=TiO1tKG5F8Zqx1lUz1rUPc3lNVE6UMPnniuLNoyMql8,323
 laboneq/dsl/result/__init__.py,sha256=XAUfjo82SDzPK0s8ZZSJPTVRIF8b4smFBWhI5rwqBAQ,151
 laboneq/dsl/result/acquired_result.py,sha256=yNCpd1C8BnKeWbMCJHSVFOQzcYoy00-eLdLwjAEcFQk,1766
 laboneq/dsl/result/results.py,sha256=79EozB9G1ExCYAY8dFjEQdpDL82G5tJGKTdMH1XWRn8,7240
 laboneq/dsl/serialization/__init__.py,sha256=XVKLzoqNC9_psuftSgRNbbNmrcvTeJmWW5bIa-bmwRU,113
-laboneq/dsl/serialization/serializer.py,sha256=2kDD18vlzK8_OVt-1XhQFlqBen4Eu9Ipo147qDruMbA,5243
+laboneq/dsl/serialization/serializer.py,sha256=f-eflHyxkv4dvli2WctR-dAP-ykUR-1PcEiyLtyeF9E,5339
 laboneq/executor/__init__.py,sha256=FVNdflrImH-vSDDkoz05G5rNUUDB7mf4sgoOZHttkBQ,77
 laboneq/executor/execution_from_experiment.py,sha256=eE1lzSHYQqZZqlM2TAyjm0ibP3ifeeNTIOazin9z96M,3819
 laboneq/executor/executor.py,sha256=xvJwDB-9hlPjD4dTPqfxN2uNVB_2o8ZoKLNWPQBgpQc,8152
 laboneq/openqasm3/__init__.py,sha256=zIfFQa39Ko4nUcnnLBmRilnUVJ9eeg022QoLpodiv2o,145
-laboneq/openqasm3/openqasm3_importer.py,sha256=zcIj4WzcTiEZZxMSaGAEH8jNL_mOUzH7jjF6aXTK2EM,10897
+laboneq/openqasm3/expression.py,sha256=2X5JNUQKnVL0aST5QcrTuwvn3UTRRp36Do1dSxBP6UI,2488
+laboneq/openqasm3/gate_store.py,sha256=9OSAaIZhUUYCCl-I8vq5aSoTWpIZwYy_eOOUkbMX6oY,1929
+laboneq/openqasm3/openqasm3_importer.py,sha256=Z3Vp_SeHG0RLVeaogO7CQkWJw884VHztxzwRamk-XIQ,10789
+laboneq/openqasm3/openqasm_error.py,sha256=rgkp6fT1tNrhVX8eCV-q1PLJUfGxkmT4gXEErJcSB-8,1732
+laboneq/openqasm3/reset_gate_factory.py,sha256=zmIZK4huifimAN-SSj4ww6UJ_2Ix1-7n-K99JaWWQZU,5136
+laboneq/openqasm3/variable_store.py,sha256=lj4duVPjDjalsdwzt3cm6HKGcyiM8UJx36CwGA3ClTY,3069
 laboneq/pulse_sheet_viewer/__init__.py,sha256=F_gdqvR3iTbFH2-iGtGWPp2v2XpMu0c4SXEPEIJyQb0,127
 laboneq/pulse_sheet_viewer/event_graph_viewer.py,sha256=hKBUzFzimfz9YAFUYNYwrhwMscXHa-4M3BNa6id6SHE,2059
 laboneq/pulse_sheet_viewer/interactive_psv.py,sha256=D7pEX9C8mP9EZofE5L3aAAkX3lNFaEoHwBc_l2AHyec,2692
 laboneq/pulse_sheet_viewer/pulse_sheet_viewer.py,sha256=_O53T2cm8KWDhbUKoONuRb_9JOKyKvOqEMtQgrwlQPI,3288
 laboneq/pulse_sheet_viewer/pulse_sheet_viewer_template.html,sha256=TsX3r0W8qf_PKAw1pYreXQEcexRfzgL_FmbvOAFh06s,1443040
 laboneq/simulator/__init__.py,sha256=BuPOsR4Dwi6tSLAsG0lBeHzpOZFnCsNn93ohr-v9mZ8,152
 laboneq/simulator/output_simulator.py,sha256=OjbHVNNkrYITwZaJ58HaqAeM-ETeLP4y_ifA0aQXrGE,5904
 laboneq/simulator/seqc_parser.py,sha256=Ru8TnmLX49vX9jhY_o8hbZ6iy3FgL5EuB1XHgmAjFgg,39230
 laboneq/simulator/wave_scroller.py,sha256=j3lQLcCuqv8b2UTbViAtXIDvEa2mXADApPmhj570fdU,12081
-laboneq-2.4.0.dist-info/AUTHORS,sha256=Uu7pMg_oQJSHTrzjG8G3ApfutLIKqdOdjmtf5VZQILs,22
-laboneq-2.4.0.dist-info/LICENSE,sha256=z8d0m5b2O9McPEK1xHG_dWgUBT6EfBDz6wA0F7xSPTA,11358
-laboneq-2.4.0.dist-info/METADATA,sha256=izEbJfyerp_UbO7Uwbddccf_pILC4K2v3RnR8X3l0KY,3188
-laboneq-2.4.0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-laboneq-2.4.0.dist-info/top_level.txt,sha256=oZ0o6Elw6GJcR44azoSi8l6opKF-v5Ks1MLYbqpXJGA,8
-laboneq-2.4.0.dist-info/RECORD,,
+laboneq-2.5.0.dist-info/AUTHORS,sha256=Uu7pMg_oQJSHTrzjG8G3ApfutLIKqdOdjmtf5VZQILs,22
+laboneq-2.5.0.dist-info/LICENSE,sha256=z8d0m5b2O9McPEK1xHG_dWgUBT6EfBDz6wA0F7xSPTA,11358
+laboneq-2.5.0.dist-info/METADATA,sha256=nUWf4JIKgsC1hS2kCVv8aIAHvCjOGu1g6dgPLLM7yAo,3188
+laboneq-2.5.0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+laboneq-2.5.0.dist-info/top_level.txt,sha256=oZ0o6Elw6GJcR44azoSi8l6opKF-v5Ks1MLYbqpXJGA,8
+laboneq-2.5.0.dist-info/RECORD,,
```

